id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/root-project/root/issues/8893:110,testability,simpl,simplest,110,"Problem here is that `Describe` defined in `tree/dataframe/inc/ROOT/RDF/RInterface.hxx` returns a string. The simplest solution is to call `print(df.Describe())` to format properly the string. ""Fixing"" the desired output would change the existing usage of `Describe()` - returned type change from string to void and printing inside of the Describe. This is what is going on:. ```python. def foo(): # returns string. return ""a\nb"". def bar(): # void. print(""a\nb""). foo() # this is our case, giving excplicitly ""a\nb"". bar() # this is good. print(foo()) # this is good. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8893
https://github.com/root-project/root/issues/8893:110,usability,simpl,simplest,110,"Problem here is that `Describe` defined in `tree/dataframe/inc/ROOT/RDF/RInterface.hxx` returns a string. The simplest solution is to call `print(df.Describe())` to format properly the string. ""Fixing"" the desired output would change the existing usage of `Describe()` - returned type change from string to void and printing inside of the Describe. This is what is going on:. ```python. def foo(): # returns string. return ""a\nb"". def bar(): # void. print(""a\nb""). foo() # this is our case, giving excplicitly ""a\nb"". bar() # this is good. print(foo()) # this is good. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8893
https://github.com/root-project/root/issues/8893:298,integrability,pub,published,298,"As per the discussion at https://mattermost.web.cern.ch/root/pl/9yqt4pm4qtfs38n3pc5stkhp5a , we want to change Describe's behavior so that by default it prints to stdout. The signature should be:. ```cpp. void Describe(std::ostream &out = std::cout);. ```. We need to do this before the feature is published in v6.26.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8893
https://github.com/root-project/root/issues/8893:175,security,sign,signature,175,"As per the discussion at https://mattermost.web.cern.ch/root/pl/9yqt4pm4qtfs38n3pc5stkhp5a , we want to change Describe's behavior so that by default it prints to stdout. The signature should be:. ```cpp. void Describe(std::ostream &out = std::cout);. ```. We need to do this before the feature is published in v6.26.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8893
https://github.com/root-project/root/issues/8893:122,usability,behavi,behavior,122,"As per the discussion at https://mattermost.web.cern.ch/root/pl/9yqt4pm4qtfs38n3pc5stkhp5a , we want to change Describe's behavior so that by default it prints to stdout. The signature should be:. ```cpp. void Describe(std::ostream &out = std::cout);. ```. We need to do this before the feature is published in v6.26.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8893
https://github.com/root-project/root/issues/8895:62,availability,replic,replicate,62,"Hi @bleve ,. the test does not fail in our builds, how can we replicate the issue on our side?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8895
https://github.com/root-project/root/issues/8895:31,deployability,fail,fail,31,"Hi @bleve ,. the test does not fail in our builds, how can we replicate the issue on our side?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8895
https://github.com/root-project/root/issues/8895:43,deployability,build,builds,43,"Hi @bleve ,. the test does not fail in our builds, how can we replicate the issue on our side?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8895
https://github.com/root-project/root/issues/8895:22,reliability,doe,does,22,"Hi @bleve ,. the test does not fail in our builds, how can we replicate the issue on our side?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8895
https://github.com/root-project/root/issues/8895:31,reliability,fail,fail,31,"Hi @bleve ,. the test does not fail in our builds, how can we replicate the issue on our side?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8895
https://github.com/root-project/root/issues/8895:17,safety,test,test,17,"Hi @bleve ,. the test does not fail in our builds, how can we replicate the issue on our side?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8895
https://github.com/root-project/root/issues/8895:17,testability,test,test,17,"Hi @bleve ,. the test does not fail in our builds, how can we replicate the issue on our side?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8895
https://github.com/root-project/root/issues/8895:18,deployability,build,build,18,Have you tried to build on tmpfs?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8895
https://github.com/root-project/root/issues/8895:92,deployability,build,build,92,EL8 is tricky: there is a liburing but the kernel doesn't enable uring. Does it work if you build with `cmake -During=off`?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8895
https://github.com/root-project/root/issues/8895:50,reliability,doe,doesn,50,EL8 is tricky: there is a liburing but the kernel doesn't enable uring. Does it work if you build with `cmake -During=off`?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8895
https://github.com/root-project/root/issues/8895:72,reliability,Doe,Does,72,EL8 is tricky: there is a liburing but the kernel doesn't enable uring. Does it work if you build with `cmake -During=off`?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8895
https://github.com/root-project/root/issues/8895:104,reliability,doe,doesn,104,Disabling uring works. So problem is just epel - It must disable uring support for epel8 because kernel doesn't have support. Thank you I Add this information to epel8 bug report.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8895
https://github.com/root-project/root/issues/8895:71,usability,support,support,71,Disabling uring works. So problem is just epel - It must disable uring support for epel8 because kernel doesn't have support. Thank you I Add this information to epel8 bug report.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8895
https://github.com/root-project/root/issues/8895:117,usability,support,support,117,Disabling uring works. So problem is just epel - It must disable uring support for epel8 because kernel doesn't have support. Thank you I Add this information to epel8 bug report.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8895
https://github.com/root-project/root/pull/8896:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8896
https://github.com/root-project/root/pull/8896:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu2004/default with flags -Dtmva-sofie=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8896
https://github.com/root-project/root/pull/8897:90,safety,test,test,90,Hi Jakob! At this point with all the v1 machinery in place would it be possible to have a test for back-filled columns?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8897
https://github.com/root-project/root/pull/8897:90,testability,test,test,90,Hi Jakob! At this point with all the v1 machinery in place would it be possible to have a test for back-filled columns?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8897
https://github.com/root-project/root/pull/8897:81,deployability,releas,release,81,Reviewing this week. I think it would be good to merge this before the next ROOT release.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8897
https://github.com/root-project/root/pull/8897:0,safety,Review,Reviewing,0,Reviewing this week. I think it would be good to merge this before the next ROOT release.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8897
https://github.com/root-project/root/pull/8897:0,testability,Review,Reviewing,0,Reviewing this week. I think it would be good to merge this before the next ROOT release.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8897
https://github.com/root-project/root/issues/8899:0,usability,Confirm,Confirmed,0,Confirmed in master / upcoming 6.26.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8899
https://github.com/root-project/root/issues/8901:104,usability,support,support,104,Many thanks for the report! Enums are generally still unsupported but they are on the list of things to support.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8901
https://github.com/root-project/root/issues/8901:15,deployability,updat,update,15,"Thanks for the update Jakob. Do you have any kind of estimation when this could be supported? I have a feeling we may have many enums like this in our EDM. . Cheers, Marcin",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8901
https://github.com/root-project/root/issues/8901:53,energy efficiency,estimat,estimation,53,"Thanks for the update Jakob. Do you have any kind of estimation when this could be supported? I have a feeling we may have many enums like this in our EDM. . Cheers, Marcin",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8901
https://github.com/root-project/root/issues/8901:15,safety,updat,update,15,"Thanks for the update Jakob. Do you have any kind of estimation when this could be supported? I have a feeling we may have many enums like this in our EDM. . Cheers, Marcin",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8901
https://github.com/root-project/root/issues/8901:15,security,updat,update,15,"Thanks for the update Jakob. Do you have any kind of estimation when this could be supported? I have a feeling we may have many enums like this in our EDM. . Cheers, Marcin",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8901
https://github.com/root-project/root/issues/8901:83,usability,support,supported,83,"Thanks for the update Jakob. Do you have any kind of estimation when this could be supported? I have a feeling we may have many enums like this in our EDM. . Cheers, Marcin",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8901
https://github.com/root-project/root/issues/8901:471,deployability,Build,Build,471,"It turns out that `TClass::GetListOfDataMembers()` returns an item for the constants in old, unscoped enums (anonymous or not) that are defined in the class. For instance, in the example above, `GetListOfDataMembers()` returns an item for `EnumField1` and `EnumField2`. This is not the case for an `enum class`. I'm wondering if this is the expected bahavior? If it is, I consider the following approach to distinguish an enum declaration from an actual data member:. 1. Build a set of pointers from `GetListOfRealData()` ... `GetDataMember()`. 2. Filter out from `GetListOfDataMembers()` those that are not in the set of 1. NB: This approach does not work with `GetListOfRealData()` ... `GetName()` because the list of real data also has the members from base classes and the following example:. ```. struct A : {. int E;. };. struct B : A {. enum { E };. };. ```. @pcanal Does that make sense?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8901
https://github.com/root-project/root/issues/8901:548,integrability,Filter,Filter,548,"It turns out that `TClass::GetListOfDataMembers()` returns an item for the constants in old, unscoped enums (anonymous or not) that are defined in the class. For instance, in the example above, `GetListOfDataMembers()` returns an item for `EnumField1` and `EnumField2`. This is not the case for an `enum class`. I'm wondering if this is the expected bahavior? If it is, I consider the following approach to distinguish an enum declaration from an actual data member:. 1. Build a set of pointers from `GetListOfRealData()` ... `GetDataMember()`. 2. Filter out from `GetListOfDataMembers()` those that are not in the set of 1. NB: This approach does not work with `GetListOfRealData()` ... `GetName()` because the list of real data also has the members from base classes and the following example:. ```. struct A : {. int E;. };. struct B : A {. enum { E };. };. ```. @pcanal Does that make sense?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8901
https://github.com/root-project/root/issues/8901:643,reliability,doe,does,643,"It turns out that `TClass::GetListOfDataMembers()` returns an item for the constants in old, unscoped enums (anonymous or not) that are defined in the class. For instance, in the example above, `GetListOfDataMembers()` returns an item for `EnumField1` and `EnumField2`. This is not the case for an `enum class`. I'm wondering if this is the expected bahavior? If it is, I consider the following approach to distinguish an enum declaration from an actual data member:. 1. Build a set of pointers from `GetListOfRealData()` ... `GetDataMember()`. 2. Filter out from `GetListOfDataMembers()` those that are not in the set of 1. NB: This approach does not work with `GetListOfRealData()` ... `GetName()` because the list of real data also has the members from base classes and the following example:. ```. struct A : {. int E;. };. struct B : A {. enum { E };. };. ```. @pcanal Does that make sense?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8901
https://github.com/root-project/root/issues/8901:874,reliability,Doe,Does,874,"It turns out that `TClass::GetListOfDataMembers()` returns an item for the constants in old, unscoped enums (anonymous or not) that are defined in the class. For instance, in the example above, `GetListOfDataMembers()` returns an item for `EnumField1` and `EnumField2`. This is not the case for an `enum class`. I'm wondering if this is the expected bahavior? If it is, I consider the following approach to distinguish an enum declaration from an actual data member:. 1. Build a set of pointers from `GetListOfRealData()` ... `GetDataMember()`. 2. Filter out from `GetListOfDataMembers()` those that are not in the set of 1. NB: This approach does not work with `GetListOfRealData()` ... `GetName()` because the list of real data also has the members from base classes and the following example:. ```. struct A : {. int E;. };. struct B : A {. enum { E };. };. ```. @pcanal Does that make sense?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8901
https://github.com/root-project/root/issues/8901:179,availability,fault,fault,179,"@pcanal One more question: if I use `GetListOfRealData` on a class hierarchy where I only have a dictionary for the derived class but not for the base class, I get a segmentation fault. Is it expected?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8901
https://github.com/root-project/root/issues/8901:179,energy efficiency,fault,fault,179,"@pcanal One more question: if I use `GetListOfRealData` on a class hierarchy where I only have a dictionary for the derived class but not for the base class, I get a segmentation fault. Is it expected?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8901
https://github.com/root-project/root/issues/8901:179,performance,fault,fault,179,"@pcanal One more question: if I use `GetListOfRealData` on a class hierarchy where I only have a dictionary for the derived class but not for the base class, I get a segmentation fault. Is it expected?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8901
https://github.com/root-project/root/issues/8901:179,reliability,fault,fault,179,"@pcanal One more question: if I use `GetListOfRealData` on a class hierarchy where I only have a dictionary for the derived class but not for the base class, I get a segmentation fault. Is it expected?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8901
https://github.com/root-project/root/issues/8901:179,safety,fault,fault,179,"@pcanal One more question: if I use `GetListOfRealData` on a class hierarchy where I only have a dictionary for the derived class but not for the base class, I get a segmentation fault. Is it expected?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8901
https://github.com/root-project/root/issues/8901:152,availability,fault,fault,152,"> if I use GetListOfRealData on a class hierarchy where I only have a dictionary for the derived class but not for the base class, I get a segmentation fault. Is it expected? No it is not.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8901
https://github.com/root-project/root/issues/8901:152,energy efficiency,fault,fault,152,"> if I use GetListOfRealData on a class hierarchy where I only have a dictionary for the derived class but not for the base class, I get a segmentation fault. Is it expected? No it is not.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8901
https://github.com/root-project/root/issues/8901:152,performance,fault,fault,152,"> if I use GetListOfRealData on a class hierarchy where I only have a dictionary for the derived class but not for the base class, I get a segmentation fault. Is it expected? No it is not.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8901
https://github.com/root-project/root/issues/8901:152,reliability,fault,fault,152,"> if I use GetListOfRealData on a class hierarchy where I only have a dictionary for the derived class but not for the base class, I get a segmentation fault. Is it expected? No it is not.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8901
https://github.com/root-project/root/issues/8901:152,safety,fault,fault,152,"> if I use GetListOfRealData on a class hierarchy where I only have a dictionary for the derived class but not for the base class, I get a segmentation fault. Is it expected? No it is not.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8901
https://github.com/root-project/root/issues/8902:129,deployability,build,build,129,"Trivial file tst.py. ```. import ROOT . e = ROOT.RooCategory. ```. execute as . ```. python -Werror tst.py. ```. one gets:. ```. build$ python -Werror tst.py. Traceback (most recent call last):. File ""/afs/cern.ch/user/i/ibelyaev/cmtuser/RELEASE/ostap/build/tst.py"", line 1, in <module>. import ROOT. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py"", line 69, in <module>. module = importlib.import_module(pyz.__name__ + '.' + module_name). File ""/cvmfs/sft-nightlies.cern.ch/lcg/latest/Python/3.9.6-b0f98/x86_64-centos7-gcc11-opt/lib/python3.9/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/__init__.py"", line 26, in <module>. from ._roocategory import RooCategory. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/_roocategory.py"", line 18. """"""Constructor of RooCategory takes a map as an argument also supports python dictionaries. ^. SyntaxError: invalid escape sequence \c. ```. (I run my tests with `-Werror flag`)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8902
https://github.com/root-project/root/issues/8902:238,deployability,RELEAS,RELEASE,238,"Trivial file tst.py. ```. import ROOT . e = ROOT.RooCategory. ```. execute as . ```. python -Werror tst.py. ```. one gets:. ```. build$ python -Werror tst.py. Traceback (most recent call last):. File ""/afs/cern.ch/user/i/ibelyaev/cmtuser/RELEASE/ostap/build/tst.py"", line 1, in <module>. import ROOT. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py"", line 69, in <module>. module = importlib.import_module(pyz.__name__ + '.' + module_name). File ""/cvmfs/sft-nightlies.cern.ch/lcg/latest/Python/3.9.6-b0f98/x86_64-centos7-gcc11-opt/lib/python3.9/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/__init__.py"", line 26, in <module>. from ._roocategory import RooCategory. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/_roocategory.py"", line 18. """"""Constructor of RooCategory takes a map as an argument also supports python dictionaries. ^. SyntaxError: invalid escape sequence \c. ```. (I run my tests with `-Werror flag`)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8902
https://github.com/root-project/root/issues/8902:252,deployability,build,build,252,"Trivial file tst.py. ```. import ROOT . e = ROOT.RooCategory. ```. execute as . ```. python -Werror tst.py. ```. one gets:. ```. build$ python -Werror tst.py. Traceback (most recent call last):. File ""/afs/cern.ch/user/i/ibelyaev/cmtuser/RELEASE/ostap/build/tst.py"", line 1, in <module>. import ROOT. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py"", line 69, in <module>. module = importlib.import_module(pyz.__name__ + '.' + module_name). File ""/cvmfs/sft-nightlies.cern.ch/lcg/latest/Python/3.9.6-b0f98/x86_64-centos7-gcc11-opt/lib/python3.9/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/__init__.py"", line 26, in <module>. from ._roocategory import RooCategory. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/_roocategory.py"", line 18. """"""Constructor of RooCategory takes a map as an argument also supports python dictionaries. ^. SyntaxError: invalid escape sequence \c. ```. (I run my tests with `-Werror flag`)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8902
https://github.com/root-project/root/issues/8902:279,deployability,modul,module,279,"Trivial file tst.py. ```. import ROOT . e = ROOT.RooCategory. ```. execute as . ```. python -Werror tst.py. ```. one gets:. ```. build$ python -Werror tst.py. Traceback (most recent call last):. File ""/afs/cern.ch/user/i/ibelyaev/cmtuser/RELEASE/ostap/build/tst.py"", line 1, in <module>. import ROOT. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py"", line 69, in <module>. module = importlib.import_module(pyz.__name__ + '.' + module_name). File ""/cvmfs/sft-nightlies.cern.ch/lcg/latest/Python/3.9.6-b0f98/x86_64-centos7-gcc11-opt/lib/python3.9/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/__init__.py"", line 26, in <module>. from ._roocategory import RooCategory. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/_roocategory.py"", line 18. """"""Constructor of RooCategory takes a map as an argument also supports python dictionaries. ^. SyntaxError: invalid escape sequence \c. ```. (I run my tests with `-Werror flag`)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8902
https://github.com/root-project/root/issues/8902:416,deployability,modul,module,416,"Trivial file tst.py. ```. import ROOT . e = ROOT.RooCategory. ```. execute as . ```. python -Werror tst.py. ```. one gets:. ```. build$ python -Werror tst.py. Traceback (most recent call last):. File ""/afs/cern.ch/user/i/ibelyaev/cmtuser/RELEASE/ostap/build/tst.py"", line 1, in <module>. import ROOT. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py"", line 69, in <module>. module = importlib.import_module(pyz.__name__ + '.' + module_name). File ""/cvmfs/sft-nightlies.cern.ch/lcg/latest/Python/3.9.6-b0f98/x86_64-centos7-gcc11-opt/lib/python3.9/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/__init__.py"", line 26, in <module>. from ._roocategory import RooCategory. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/_roocategory.py"", line 18. """"""Constructor of RooCategory takes a map as an argument also supports python dictionaries. ^. SyntaxError: invalid escape sequence \c. ```. (I run my tests with `-Werror flag`)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8902
https://github.com/root-project/root/issues/8902:425,deployability,modul,module,425,"Trivial file tst.py. ```. import ROOT . e = ROOT.RooCategory. ```. execute as . ```. python -Werror tst.py. ```. one gets:. ```. build$ python -Werror tst.py. Traceback (most recent call last):. File ""/afs/cern.ch/user/i/ibelyaev/cmtuser/RELEASE/ostap/build/tst.py"", line 1, in <module>. import ROOT. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py"", line 69, in <module>. module = importlib.import_module(pyz.__name__ + '.' + module_name). File ""/cvmfs/sft-nightlies.cern.ch/lcg/latest/Python/3.9.6-b0f98/x86_64-centos7-gcc11-opt/lib/python3.9/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/__init__.py"", line 26, in <module>. from ._roocategory import RooCategory. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/_roocategory.py"", line 18. """"""Constructor of RooCategory takes a map as an argument also supports python dictionaries. ^. SyntaxError: invalid escape sequence \c. ```. (I run my tests with `-Werror flag`)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8902
https://github.com/root-project/root/issues/8902:847,deployability,modul,module,847,"Trivial file tst.py. ```. import ROOT . e = ROOT.RooCategory. ```. execute as . ```. python -Werror tst.py. ```. one gets:. ```. build$ python -Werror tst.py. Traceback (most recent call last):. File ""/afs/cern.ch/user/i/ibelyaev/cmtuser/RELEASE/ostap/build/tst.py"", line 1, in <module>. import ROOT. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py"", line 69, in <module>. module = importlib.import_module(pyz.__name__ + '.' + module_name). File ""/cvmfs/sft-nightlies.cern.ch/lcg/latest/Python/3.9.6-b0f98/x86_64-centos7-gcc11-opt/lib/python3.9/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/__init__.py"", line 26, in <module>. from ._roocategory import RooCategory. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/_roocategory.py"", line 18. """"""Constructor of RooCategory takes a map as an argument also supports python dictionaries. ^. SyntaxError: invalid escape sequence \c. ```. (I run my tests with `-Werror flag`)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8902
https://github.com/root-project/root/issues/8902:279,modifiability,modul,module,279,"Trivial file tst.py. ```. import ROOT . e = ROOT.RooCategory. ```. execute as . ```. python -Werror tst.py. ```. one gets:. ```. build$ python -Werror tst.py. Traceback (most recent call last):. File ""/afs/cern.ch/user/i/ibelyaev/cmtuser/RELEASE/ostap/build/tst.py"", line 1, in <module>. import ROOT. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py"", line 69, in <module>. module = importlib.import_module(pyz.__name__ + '.' + module_name). File ""/cvmfs/sft-nightlies.cern.ch/lcg/latest/Python/3.9.6-b0f98/x86_64-centos7-gcc11-opt/lib/python3.9/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/__init__.py"", line 26, in <module>. from ._roocategory import RooCategory. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/_roocategory.py"", line 18. """"""Constructor of RooCategory takes a map as an argument also supports python dictionaries. ^. SyntaxError: invalid escape sequence \c. ```. (I run my tests with `-Werror flag`)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8902
https://github.com/root-project/root/issues/8902:416,modifiability,modul,module,416,"Trivial file tst.py. ```. import ROOT . e = ROOT.RooCategory. ```. execute as . ```. python -Werror tst.py. ```. one gets:. ```. build$ python -Werror tst.py. Traceback (most recent call last):. File ""/afs/cern.ch/user/i/ibelyaev/cmtuser/RELEASE/ostap/build/tst.py"", line 1, in <module>. import ROOT. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py"", line 69, in <module>. module = importlib.import_module(pyz.__name__ + '.' + module_name). File ""/cvmfs/sft-nightlies.cern.ch/lcg/latest/Python/3.9.6-b0f98/x86_64-centos7-gcc11-opt/lib/python3.9/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/__init__.py"", line 26, in <module>. from ._roocategory import RooCategory. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/_roocategory.py"", line 18. """"""Constructor of RooCategory takes a map as an argument also supports python dictionaries. ^. SyntaxError: invalid escape sequence \c. ```. (I run my tests with `-Werror flag`)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8902
https://github.com/root-project/root/issues/8902:425,modifiability,modul,module,425,"Trivial file tst.py. ```. import ROOT . e = ROOT.RooCategory. ```. execute as . ```. python -Werror tst.py. ```. one gets:. ```. build$ python -Werror tst.py. Traceback (most recent call last):. File ""/afs/cern.ch/user/i/ibelyaev/cmtuser/RELEASE/ostap/build/tst.py"", line 1, in <module>. import ROOT. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py"", line 69, in <module>. module = importlib.import_module(pyz.__name__ + '.' + module_name). File ""/cvmfs/sft-nightlies.cern.ch/lcg/latest/Python/3.9.6-b0f98/x86_64-centos7-gcc11-opt/lib/python3.9/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/__init__.py"", line 26, in <module>. from ._roocategory import RooCategory. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/_roocategory.py"", line 18. """"""Constructor of RooCategory takes a map as an argument also supports python dictionaries. ^. SyntaxError: invalid escape sequence \c. ```. (I run my tests with `-Werror flag`)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8902
https://github.com/root-project/root/issues/8902:693,modifiability,pac,package,693,"Trivial file tst.py. ```. import ROOT . e = ROOT.RooCategory. ```. execute as . ```. python -Werror tst.py. ```. one gets:. ```. build$ python -Werror tst.py. Traceback (most recent call last):. File ""/afs/cern.ch/user/i/ibelyaev/cmtuser/RELEASE/ostap/build/tst.py"", line 1, in <module>. import ROOT. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py"", line 69, in <module>. module = importlib.import_module(pyz.__name__ + '.' + module_name). File ""/cvmfs/sft-nightlies.cern.ch/lcg/latest/Python/3.9.6-b0f98/x86_64-centos7-gcc11-opt/lib/python3.9/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/__init__.py"", line 26, in <module>. from ._roocategory import RooCategory. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/_roocategory.py"", line 18. """"""Constructor of RooCategory takes a map as an argument also supports python dictionaries. ^. SyntaxError: invalid escape sequence \c. ```. (I run my tests with `-Werror flag`)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8902
https://github.com/root-project/root/issues/8902:847,modifiability,modul,module,847,"Trivial file tst.py. ```. import ROOT . e = ROOT.RooCategory. ```. execute as . ```. python -Werror tst.py. ```. one gets:. ```. build$ python -Werror tst.py. Traceback (most recent call last):. File ""/afs/cern.ch/user/i/ibelyaev/cmtuser/RELEASE/ostap/build/tst.py"", line 1, in <module>. import ROOT. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py"", line 69, in <module>. module = importlib.import_module(pyz.__name__ + '.' + module_name). File ""/cvmfs/sft-nightlies.cern.ch/lcg/latest/Python/3.9.6-b0f98/x86_64-centos7-gcc11-opt/lib/python3.9/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/__init__.py"", line 26, in <module>. from ._roocategory import RooCategory. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/_roocategory.py"", line 18. """"""Constructor of RooCategory takes a map as an argument also supports python dictionaries. ^. SyntaxError: invalid escape sequence \c. ```. (I run my tests with `-Werror flag`)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8902
https://github.com/root-project/root/issues/8902:279,safety,modul,module,279,"Trivial file tst.py. ```. import ROOT . e = ROOT.RooCategory. ```. execute as . ```. python -Werror tst.py. ```. one gets:. ```. build$ python -Werror tst.py. Traceback (most recent call last):. File ""/afs/cern.ch/user/i/ibelyaev/cmtuser/RELEASE/ostap/build/tst.py"", line 1, in <module>. import ROOT. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py"", line 69, in <module>. module = importlib.import_module(pyz.__name__ + '.' + module_name). File ""/cvmfs/sft-nightlies.cern.ch/lcg/latest/Python/3.9.6-b0f98/x86_64-centos7-gcc11-opt/lib/python3.9/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/__init__.py"", line 26, in <module>. from ._roocategory import RooCategory. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/_roocategory.py"", line 18. """"""Constructor of RooCategory takes a map as an argument also supports python dictionaries. ^. SyntaxError: invalid escape sequence \c. ```. (I run my tests with `-Werror flag`)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8902
https://github.com/root-project/root/issues/8902:416,safety,modul,module,416,"Trivial file tst.py. ```. import ROOT . e = ROOT.RooCategory. ```. execute as . ```. python -Werror tst.py. ```. one gets:. ```. build$ python -Werror tst.py. Traceback (most recent call last):. File ""/afs/cern.ch/user/i/ibelyaev/cmtuser/RELEASE/ostap/build/tst.py"", line 1, in <module>. import ROOT. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py"", line 69, in <module>. module = importlib.import_module(pyz.__name__ + '.' + module_name). File ""/cvmfs/sft-nightlies.cern.ch/lcg/latest/Python/3.9.6-b0f98/x86_64-centos7-gcc11-opt/lib/python3.9/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/__init__.py"", line 26, in <module>. from ._roocategory import RooCategory. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/_roocategory.py"", line 18. """"""Constructor of RooCategory takes a map as an argument also supports python dictionaries. ^. SyntaxError: invalid escape sequence \c. ```. (I run my tests with `-Werror flag`)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8902
https://github.com/root-project/root/issues/8902:425,safety,modul,module,425,"Trivial file tst.py. ```. import ROOT . e = ROOT.RooCategory. ```. execute as . ```. python -Werror tst.py. ```. one gets:. ```. build$ python -Werror tst.py. Traceback (most recent call last):. File ""/afs/cern.ch/user/i/ibelyaev/cmtuser/RELEASE/ostap/build/tst.py"", line 1, in <module>. import ROOT. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py"", line 69, in <module>. module = importlib.import_module(pyz.__name__ + '.' + module_name). File ""/cvmfs/sft-nightlies.cern.ch/lcg/latest/Python/3.9.6-b0f98/x86_64-centos7-gcc11-opt/lib/python3.9/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/__init__.py"", line 26, in <module>. from ._roocategory import RooCategory. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/_roocategory.py"", line 18. """"""Constructor of RooCategory takes a map as an argument also supports python dictionaries. ^. SyntaxError: invalid escape sequence \c. ```. (I run my tests with `-Werror flag`)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8902
https://github.com/root-project/root/issues/8902:847,safety,modul,module,847,"Trivial file tst.py. ```. import ROOT . e = ROOT.RooCategory. ```. execute as . ```. python -Werror tst.py. ```. one gets:. ```. build$ python -Werror tst.py. Traceback (most recent call last):. File ""/afs/cern.ch/user/i/ibelyaev/cmtuser/RELEASE/ostap/build/tst.py"", line 1, in <module>. import ROOT. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py"", line 69, in <module>. module = importlib.import_module(pyz.__name__ + '.' + module_name). File ""/cvmfs/sft-nightlies.cern.ch/lcg/latest/Python/3.9.6-b0f98/x86_64-centos7-gcc11-opt/lib/python3.9/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/__init__.py"", line 26, in <module>. from ._roocategory import RooCategory. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/_roocategory.py"", line 18. """"""Constructor of RooCategory takes a map as an argument also supports python dictionaries. ^. SyntaxError: invalid escape sequence \c. ```. (I run my tests with `-Werror flag`)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8902
https://github.com/root-project/root/issues/8902:1183,safety,test,tests,1183,"Trivial file tst.py. ```. import ROOT . e = ROOT.RooCategory. ```. execute as . ```. python -Werror tst.py. ```. one gets:. ```. build$ python -Werror tst.py. Traceback (most recent call last):. File ""/afs/cern.ch/user/i/ibelyaev/cmtuser/RELEASE/ostap/build/tst.py"", line 1, in <module>. import ROOT. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py"", line 69, in <module>. module = importlib.import_module(pyz.__name__ + '.' + module_name). File ""/cvmfs/sft-nightlies.cern.ch/lcg/latest/Python/3.9.6-b0f98/x86_64-centos7-gcc11-opt/lib/python3.9/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/__init__.py"", line 26, in <module>. from ._roocategory import RooCategory. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/_roocategory.py"", line 18. """"""Constructor of RooCategory takes a map as an argument also supports python dictionaries. ^. SyntaxError: invalid escape sequence \c. ```. (I run my tests with `-Werror flag`)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8902
https://github.com/root-project/root/issues/8902:159,testability,Trace,Traceback,159,"Trivial file tst.py. ```. import ROOT . e = ROOT.RooCategory. ```. execute as . ```. python -Werror tst.py. ```. one gets:. ```. build$ python -Werror tst.py. Traceback (most recent call last):. File ""/afs/cern.ch/user/i/ibelyaev/cmtuser/RELEASE/ostap/build/tst.py"", line 1, in <module>. import ROOT. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py"", line 69, in <module>. module = importlib.import_module(pyz.__name__ + '.' + module_name). File ""/cvmfs/sft-nightlies.cern.ch/lcg/latest/Python/3.9.6-b0f98/x86_64-centos7-gcc11-opt/lib/python3.9/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/__init__.py"", line 26, in <module>. from ._roocategory import RooCategory. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/_roocategory.py"", line 18. """"""Constructor of RooCategory takes a map as an argument also supports python dictionaries. ^. SyntaxError: invalid escape sequence \c. ```. (I run my tests with `-Werror flag`)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8902
https://github.com/root-project/root/issues/8902:1183,testability,test,tests,1183,"Trivial file tst.py. ```. import ROOT . e = ROOT.RooCategory. ```. execute as . ```. python -Werror tst.py. ```. one gets:. ```. build$ python -Werror tst.py. Traceback (most recent call last):. File ""/afs/cern.ch/user/i/ibelyaev/cmtuser/RELEASE/ostap/build/tst.py"", line 1, in <module>. import ROOT. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py"", line 69, in <module>. module = importlib.import_module(pyz.__name__ + '.' + module_name). File ""/cvmfs/sft-nightlies.cern.ch/lcg/latest/Python/3.9.6-b0f98/x86_64-centos7-gcc11-opt/lib/python3.9/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/__init__.py"", line 26, in <module>. from ._roocategory import RooCategory. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/_roocategory.py"", line 18. """"""Constructor of RooCategory takes a map as an argument also supports python dictionaries. ^. SyntaxError: invalid escape sequence \c. ```. (I run my tests with `-Werror flag`)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8902
https://github.com/root-project/root/issues/8902:214,usability,user,user,214,"Trivial file tst.py. ```. import ROOT . e = ROOT.RooCategory. ```. execute as . ```. python -Werror tst.py. ```. one gets:. ```. build$ python -Werror tst.py. Traceback (most recent call last):. File ""/afs/cern.ch/user/i/ibelyaev/cmtuser/RELEASE/ostap/build/tst.py"", line 1, in <module>. import ROOT. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py"", line 69, in <module>. module = importlib.import_module(pyz.__name__ + '.' + module_name). File ""/cvmfs/sft-nightlies.cern.ch/lcg/latest/Python/3.9.6-b0f98/x86_64-centos7-gcc11-opt/lib/python3.9/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/__init__.py"", line 26, in <module>. from ._roocategory import RooCategory. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/_roocategory.py"", line 18. """"""Constructor of RooCategory takes a map as an argument also supports python dictionaries. ^. SyntaxError: invalid escape sequence \c. ```. (I run my tests with `-Werror flag`)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8902
https://github.com/root-project/root/issues/8902:1094,usability,support,supports,1094,"Trivial file tst.py. ```. import ROOT . e = ROOT.RooCategory. ```. execute as . ```. python -Werror tst.py. ```. one gets:. ```. build$ python -Werror tst.py. Traceback (most recent call last):. File ""/afs/cern.ch/user/i/ibelyaev/cmtuser/RELEASE/ostap/build/tst.py"", line 1, in <module>. import ROOT. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py"", line 69, in <module>. module = importlib.import_module(pyz.__name__ + '.' + module_name). File ""/cvmfs/sft-nightlies.cern.ch/lcg/latest/Python/3.9.6-b0f98/x86_64-centos7-gcc11-opt/lib/python3.9/importlib/__init__.py"", line 127, in import_module. return _bootstrap._gcd_import(name[level:], package, level). File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/__init__.py"", line 26, in <module>. from ._roocategory import RooCategory. File ""/cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Thu/x86_64-centos7-gcc11-opt/lib/ROOT/pythonization/_roofit/_roocategory.py"", line 18. """"""Constructor of RooCategory takes a map as an argument also supports python dictionaries. ^. SyntaxError: invalid escape sequence \c. ```. (I run my tests with `-Werror flag`)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8902
https://github.com/root-project/root/issues/8902:145,deployability,stack,stackoverflow,145,"I see. @guitargeek this seems to be a consequence of https://bugs.python.org/issue27364 , leading to problems such as those described in https://stackoverflow.com/questions/61497292/getting-pep8-invalid-escape-sequence-warning-trying-to-escape-parentheses-in-a . in `_roocategory.py`, line 18, we have `\code{.py}` which causes the problem. I think that docstring needs to be made a raw string?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8902
https://github.com/root-project/root/pull/8903:11,deployability,build,build,11,@phsft-bot build please,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:45,availability,error,errors,45,"(the CI is having some network issues, these errors are not really due to the changes in the PR, will trigger another build when things go back to normal)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:118,deployability,build,build,118,"(the CI is having some network issues, these errors are not really due to the changes in the PR, will trigger another build when things go back to normal)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:23,performance,network,network,23,"(the CI is having some network issues, these errors are not really due to the changes in the PR, will trigger another build when things go back to normal)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:45,performance,error,errors,45,"(the CI is having some network issues, these errors are not really due to the changes in the PR, will trigger another build when things go back to normal)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:45,safety,error,errors,45,"(the CI is having some network issues, these errors are not really due to the changes in the PR, will trigger another build when things go back to normal)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:23,security,network,network,23,"(the CI is having some network issues, these errors are not really due to the changes in the PR, will trigger another build when things go back to normal)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:45,usability,error,errors,45,"(the CI is having some network issues, these errors are not really due to the changes in the PR, will trigger another build when things go back to normal)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:195,deployability,Updat,Updated,195,"> please also add an example with the new signature to the docs of `Sum`, maybe actually using `PtEtaPhiMVector`s since it's 1. really cool and 2. gives users an idea of the possibilities smile. Updated the documentation. Rearranged the commits to separate the code and test changes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:135,energy efficiency,cool,cool,135,"> please also add an example with the new signature to the docs of `Sum`, maybe actually using `PtEtaPhiMVector`s since it's 1. really cool and 2. gives users an idea of the possibilities smile. Updated the documentation. Rearranged the commits to separate the code and test changes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:195,safety,Updat,Updated,195,"> please also add an example with the new signature to the docs of `Sum`, maybe actually using `PtEtaPhiMVector`s since it's 1. really cool and 2. gives users an idea of the possibilities smile. Updated the documentation. Rearranged the commits to separate the code and test changes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:270,safety,test,test,270,"> please also add an example with the new signature to the docs of `Sum`, maybe actually using `PtEtaPhiMVector`s since it's 1. really cool and 2. gives users an idea of the possibilities smile. Updated the documentation. Rearranged the commits to separate the code and test changes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:42,security,sign,signature,42,"> please also add an example with the new signature to the docs of `Sum`, maybe actually using `PtEtaPhiMVector`s since it's 1. really cool and 2. gives users an idea of the possibilities smile. Updated the documentation. Rearranged the commits to separate the code and test changes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:195,security,Updat,Updated,195,"> please also add an example with the new signature to the docs of `Sum`, maybe actually using `PtEtaPhiMVector`s since it's 1. really cool and 2. gives users an idea of the possibilities smile. Updated the documentation. Rearranged the commits to separate the code and test changes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:270,testability,test,test,270,"> please also add an example with the new signature to the docs of `Sum`, maybe actually using `PtEtaPhiMVector`s since it's 1. really cool and 2. gives users an idea of the possibilities smile. Updated the documentation. Rearranged the commits to separate the code and test changes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:153,usability,user,users,153,"> please also add an example with the new signature to the docs of `Sum`, maybe actually using `PtEtaPhiMVector`s since it's 1. really cool and 2. gives users an idea of the possibilities smile. Updated the documentation. Rearranged the commits to separate the code and test changes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:207,usability,document,documentation,207,"> please also add an example with the new signature to the docs of `Sum`, maybe actually using `PtEtaPhiMVector`s since it's 1. really cool and 2. gives users an idea of the possibilities smile. Updated the documentation. Rearranged the commits to separate the code and test changes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:11,deployability,build,build,11,@phsft-bot build please,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:36,availability,failur,failures,36,"Hi @ShamrockLee , these compilation failures are real, there is a missing include in `vecops_rvec.cxx` for `PtEtaPhiE4D` plus some other minor issues.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:36,deployability,fail,failures,36,"Hi @ShamrockLee , these compilation failures are real, there is a missing include in `vecops_rvec.cxx` for `PtEtaPhiE4D` plus some other minor issues.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:36,performance,failur,failures,36,"Hi @ShamrockLee , these compilation failures are real, there is a missing include in `vecops_rvec.cxx` for `PtEtaPhiE4D` plus some other minor issues.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:36,reliability,fail,failures,36,"Hi @ShamrockLee , these compilation failures are real, there is a missing include in `vecops_rvec.cxx` for `PtEtaPhiE4D` plus some other minor issues.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:94,safety,test,tests,94,@eguiraud Oops! That's a typo in `vecops_rvec.cxx`. Sorry for that. Is there a way to run the tests locally so that I can test it before pushing up the changes?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:122,safety,test,test,122,@eguiraud Oops! That's a typo in `vecops_rvec.cxx`. Sorry for that. Is there a way to run the tests locally so that I can test it before pushing up the changes?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:94,testability,test,tests,94,@eguiraud Oops! That's a typo in `vecops_rvec.cxx`. Sorry for that. Is there a way to run the tests locally so that I can test it before pushing up the changes?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:122,testability,test,test,122,@eguiraud Oops! That's a typo in `vecops_rvec.cxx`. Sorry for that. Is there a way to run the tests locally so that I can test it before pushing up the changes?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:85,deployability,build,builddirectory,85,Yes you just have to compile ROOT with `-Dtesting=ON` and you find that test under `<builddirectory>/math/vecops/test`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:72,safety,test,test,72,Yes you just have to compile ROOT with `-Dtesting=ON` and you find that test under `<builddirectory>/math/vecops/test`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:113,safety,test,test,113,Yes you just have to compile ROOT with `-Dtesting=ON` and you find that test under `<builddirectory>/math/vecops/test`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:72,testability,test,test,72,Yes you just have to compile ROOT with `-Dtesting=ON` and you find that test under `<builddirectory>/math/vecops/test`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:113,testability,test,test,113,Yes you just have to compile ROOT with `-Dtesting=ON` and you find that test under `<builddirectory>/math/vecops/test`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:156,availability,servic,services,156,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:286,availability,servic,services,286,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:416,availability,servic,services,416,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:555,availability,servic,services,555,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:694,availability,servic,services,694,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:822,availability,servic,services,822,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:22,deployability,build,builds,22,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:156,deployability,servic,services,156,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:208,deployability,build,build,208,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:286,deployability,servic,services,286,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:338,deployability,build,build,338,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:416,deployability,servic,services,416,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:468,deployability,build,build,468,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:555,deployability,servic,services,555,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:607,deployability,build,build,607,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:694,deployability,servic,services,694,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:746,deployability,build,build,746,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:822,deployability,servic,services,822,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:874,deployability,build,build,874,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:156,integrability,servic,services,156,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:286,integrability,servic,services,286,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:416,integrability,servic,services,416,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:555,integrability,servic,services,555,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:694,integrability,servic,services,694,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:822,integrability,servic,services,822,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:156,modifiability,servic,services,156,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:286,modifiability,servic,services,286,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:416,modifiability,servic,services,416,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:555,modifiability,servic,services,555,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:694,modifiability,servic,services,694,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:822,modifiability,servic,services,822,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:80,performance,perform,performance-,80,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:80,usability,perform,performance-,80,All the above Jenkins builds have now passed. Please take a look. `#125133 ROOT-performance-centos8-multicore/default ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125133/. `#125134 mac1014/python3 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125134/. `#125135 windows10/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125135/. `#125136 ROOT-ubuntu16/nortcxxmod ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125136/. `#125137 ROOT-debian10-i386/cxx14 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125137/. `#125138 mac11.0/cxx17 ShamrockLee PR #8903`. https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/125138/,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:30,availability,failur,failures,30,"Hi @ShamrockLee , these build failures are transient and unrelated. I will give one last look to the PR before merging in the following days.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:24,deployability,build,build,24,"Hi @ShamrockLee , these build failures are transient and unrelated. I will give one last look to the PR before merging in the following days.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:30,deployability,fail,failures,30,"Hi @ShamrockLee , these build failures are transient and unrelated. I will give one last look to the PR before merging in the following days.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:30,performance,failur,failures,30,"Hi @ShamrockLee , these build failures are transient and unrelated. I will give one last look to the PR before merging in the following days.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/pull/8903:30,reliability,fail,failures,30,"Hi @ShamrockLee , these build failures are transient and unrelated. I will give one last look to the PR before merging in the following days.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8903
https://github.com/root-project/root/issues/8904:496,deployability,resourc,resource-dir,496,"```. root [1] .I. -I. /usr/share/root. -I. /usr/share/root/cling. -I. /usr/include/root. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/x86_64-redhat-linux. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/backward. -isystem. /usr/local/include. -isystem. /usr/share/root/cling/lib/clang/9.0.1/include. -extern-c-isystem. /include. -extern-c-isystem. /usr/include. -resource-dir. /usr/share/root/cling/lib/clang/9.0.1. -nostdinc++. root [2] . ```. I have a stock system, everything comes from repositories.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904
https://github.com/root-project/root/issues/8904:496,energy efficiency,resourc,resource-dir,496,"```. root [1] .I. -I. /usr/share/root. -I. /usr/share/root/cling. -I. /usr/include/root. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/x86_64-redhat-linux. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/backward. -isystem. /usr/local/include. -isystem. /usr/share/root/cling/lib/clang/9.0.1/include. -extern-c-isystem. /include. -extern-c-isystem. /usr/include. -resource-dir. /usr/share/root/cling/lib/clang/9.0.1. -nostdinc++. root [2] . ```. I have a stock system, everything comes from repositories.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904
https://github.com/root-project/root/issues/8904:623,integrability,repositor,repositories,623,"```. root [1] .I. -I. /usr/share/root. -I. /usr/share/root/cling. -I. /usr/include/root. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/x86_64-redhat-linux. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/backward. -isystem. /usr/local/include. -isystem. /usr/share/root/cling/lib/clang/9.0.1/include. -extern-c-isystem. /include. -extern-c-isystem. /usr/include. -resource-dir. /usr/share/root/cling/lib/clang/9.0.1. -nostdinc++. root [2] . ```. I have a stock system, everything comes from repositories.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904
https://github.com/root-project/root/issues/8904:27,interoperability,share,share,27,"```. root [1] .I. -I. /usr/share/root. -I. /usr/share/root/cling. -I. /usr/include/root. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/x86_64-redhat-linux. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/backward. -isystem. /usr/local/include. -isystem. /usr/share/root/cling/lib/clang/9.0.1/include. -extern-c-isystem. /include. -extern-c-isystem. /usr/include. -resource-dir. /usr/share/root/cling/lib/clang/9.0.1. -nostdinc++. root [2] . ```. I have a stock system, everything comes from repositories.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904
https://github.com/root-project/root/issues/8904:48,interoperability,share,share,48,"```. root [1] .I. -I. /usr/share/root. -I. /usr/share/root/cling. -I. /usr/include/root. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/x86_64-redhat-linux. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/backward. -isystem. /usr/local/include. -isystem. /usr/share/root/cling/lib/clang/9.0.1/include. -extern-c-isystem. /include. -extern-c-isystem. /usr/include. -resource-dir. /usr/share/root/cling/lib/clang/9.0.1. -nostdinc++. root [2] . ```. I have a stock system, everything comes from repositories.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904
https://github.com/root-project/root/issues/8904:391,interoperability,share,share,391,"```. root [1] .I. -I. /usr/share/root. -I. /usr/share/root/cling. -I. /usr/include/root. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/x86_64-redhat-linux. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/backward. -isystem. /usr/local/include. -isystem. /usr/share/root/cling/lib/clang/9.0.1/include. -extern-c-isystem. /include. -extern-c-isystem. /usr/include. -resource-dir. /usr/share/root/cling/lib/clang/9.0.1. -nostdinc++. root [2] . ```. I have a stock system, everything comes from repositories.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904
https://github.com/root-project/root/issues/8904:515,interoperability,share,share,515,"```. root [1] .I. -I. /usr/share/root. -I. /usr/share/root/cling. -I. /usr/include/root. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/x86_64-redhat-linux. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/backward. -isystem. /usr/local/include. -isystem. /usr/share/root/cling/lib/clang/9.0.1/include. -extern-c-isystem. /include. -extern-c-isystem. /usr/include. -resource-dir. /usr/share/root/cling/lib/clang/9.0.1. -nostdinc++. root [2] . ```. I have a stock system, everything comes from repositories.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904
https://github.com/root-project/root/issues/8904:623,interoperability,repositor,repositories,623,"```. root [1] .I. -I. /usr/share/root. -I. /usr/share/root/cling. -I. /usr/include/root. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/x86_64-redhat-linux. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/backward. -isystem. /usr/local/include. -isystem. /usr/share/root/cling/lib/clang/9.0.1/include. -extern-c-isystem. /include. -extern-c-isystem. /usr/include. -resource-dir. /usr/share/root/cling/lib/clang/9.0.1. -nostdinc++. root [2] . ```. I have a stock system, everything comes from repositories.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904
https://github.com/root-project/root/issues/8904:496,performance,resourc,resource-dir,496,"```. root [1] .I. -I. /usr/share/root. -I. /usr/share/root/cling. -I. /usr/include/root. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/x86_64-redhat-linux. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/backward. -isystem. /usr/local/include. -isystem. /usr/share/root/cling/lib/clang/9.0.1/include. -extern-c-isystem. /include. -extern-c-isystem. /usr/include. -resource-dir. /usr/share/root/cling/lib/clang/9.0.1. -nostdinc++. root [2] . ```. I have a stock system, everything comes from repositories.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904
https://github.com/root-project/root/issues/8904:496,safety,resourc,resource-dir,496,"```. root [1] .I. -I. /usr/share/root. -I. /usr/share/root/cling. -I. /usr/include/root. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/x86_64-redhat-linux. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/backward. -isystem. /usr/local/include. -isystem. /usr/share/root/cling/lib/clang/9.0.1/include. -extern-c-isystem. /include. -extern-c-isystem. /usr/include. -resource-dir. /usr/share/root/cling/lib/clang/9.0.1. -nostdinc++. root [2] . ```. I have a stock system, everything comes from repositories.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904
https://github.com/root-project/root/issues/8904:496,testability,resourc,resource-dir,496,"```. root [1] .I. -I. /usr/share/root. -I. /usr/share/root/cling. -I. /usr/include/root. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/x86_64-redhat-linux. -cxx-isystem. /usr/lib/gcc/x86_64-redhat-linux/8/../../../../include/c++/8/backward. -isystem. /usr/local/include. -isystem. /usr/share/root/cling/lib/clang/9.0.1/include. -extern-c-isystem. /include. -extern-c-isystem. /usr/include. -resource-dir. /usr/share/root/cling/lib/clang/9.0.1. -nostdinc++. root [2] . ```. I have a stock system, everything comes from repositories.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904
https://github.com/root-project/root/issues/8904:156,availability,echo,echo,156,"Are you running from `/usr/bin/`, i.e. is that your current working directory? If so, I can reproduce that with GCC:. ```. $ cat map. #!/usr/bin/perl -w. $ echo '#include <map>' | g++ -x c++ -I. -fsyntax-only -. In file included from <stdin>:1:. ./map:1:2: error: invalid preprocessing directive #! 1 | #!/usr/bin/perl -w. | ^. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904
https://github.com/root-project/root/issues/8904:257,availability,error,error,257,"Are you running from `/usr/bin/`, i.e. is that your current working directory? If so, I can reproduce that with GCC:. ```. $ cat map. #!/usr/bin/perl -w. $ echo '#include <map>' | g++ -x c++ -I. -fsyntax-only -. In file included from <stdin>:1:. ./map:1:2: error: invalid preprocessing directive #! 1 | #!/usr/bin/perl -w. | ^. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904
https://github.com/root-project/root/issues/8904:52,energy efficiency,current,current,52,"Are you running from `/usr/bin/`, i.e. is that your current working directory? If so, I can reproduce that with GCC:. ```. $ cat map. #!/usr/bin/perl -w. $ echo '#include <map>' | g++ -x c++ -I. -fsyntax-only -. In file included from <stdin>:1:. ./map:1:2: error: invalid preprocessing directive #! 1 | #!/usr/bin/perl -w. | ^. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904
https://github.com/root-project/root/issues/8904:257,performance,error,error,257,"Are you running from `/usr/bin/`, i.e. is that your current working directory? If so, I can reproduce that with GCC:. ```. $ cat map. #!/usr/bin/perl -w. $ echo '#include <map>' | g++ -x c++ -I. -fsyntax-only -. In file included from <stdin>:1:. ./map:1:2: error: invalid preprocessing directive #! 1 | #!/usr/bin/perl -w. | ^. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904
https://github.com/root-project/root/issues/8904:257,safety,error,error,257,"Are you running from `/usr/bin/`, i.e. is that your current working directory? If so, I can reproduce that with GCC:. ```. $ cat map. #!/usr/bin/perl -w. $ echo '#include <map>' | g++ -x c++ -I. -fsyntax-only -. In file included from <stdin>:1:. ./map:1:2: error: invalid preprocessing directive #! 1 | #!/usr/bin/perl -w. | ^. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904
https://github.com/root-project/root/issues/8904:257,usability,error,error,257,"Are you running from `/usr/bin/`, i.e. is that your current working directory? If so, I can reproduce that with GCC:. ```. $ cat map. #!/usr/bin/perl -w. $ echo '#include <map>' | g++ -x c++ -I. -fsyntax-only -. In file included from <stdin>:1:. ./map:1:2: error: invalid preprocessing directive #! 1 | #!/usr/bin/perl -w. | ^. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904
https://github.com/root-project/root/issues/8904:139,deployability,updat,updates,139,"Hi @Axel-Naumann ,. no, I was running just from home directory. But, let me have a look if 1) this behaviour will be seen after the recent updates of root in EPEL. 2)if I'm able to provide a simple reproducer. Best regards,. Andrii.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904
https://github.com/root-project/root/issues/8904:139,safety,updat,updates,139,"Hi @Axel-Naumann ,. no, I was running just from home directory. But, let me have a look if 1) this behaviour will be seen after the recent updates of root in EPEL. 2)if I'm able to provide a simple reproducer. Best regards,. Andrii.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904
https://github.com/root-project/root/issues/8904:139,security,updat,updates,139,"Hi @Axel-Naumann ,. no, I was running just from home directory. But, let me have a look if 1) this behaviour will be seen after the recent updates of root in EPEL. 2)if I'm able to provide a simple reproducer. Best regards,. Andrii.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904
https://github.com/root-project/root/issues/8904:191,testability,simpl,simple,191,"Hi @Axel-Naumann ,. no, I was running just from home directory. But, let me have a look if 1) this behaviour will be seen after the recent updates of root in EPEL. 2)if I'm able to provide a simple reproducer. Best regards,. Andrii.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904
https://github.com/root-project/root/issues/8904:99,usability,behavi,behaviour,99,"Hi @Axel-Naumann ,. no, I was running just from home directory. But, let me have a look if 1) this behaviour will be seen after the recent updates of root in EPEL. 2)if I'm able to provide a simple reproducer. Best regards,. Andrii.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904
https://github.com/root-project/root/issues/8904:191,usability,simpl,simple,191,"Hi @Axel-Naumann ,. no, I was running just from home directory. But, let me have a look if 1) this behaviour will be seen after the recent updates of root in EPEL. 2)if I'm able to provide a simple reproducer. Best regards,. Andrii.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904
https://github.com/root-project/root/issues/8904:220,deployability,build,build-in,220,"OK,. now I see I had /usr/bin appended to the ROOT_INCLUDE_PATH in the script that called the executable. Removing /usr/bin from resolves the problem. Sorry for not reporting it earlier. In theory, one could expect that build-in paths should take precedence over ROOT_INCLUDE_PATH, so I'm not sure if this is 100% false alarm, but ""my problem"" is resolved, so I would not object to closing this issue. Best regards,. Andrii.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904
https://github.com/root-project/root/issues/8904:16,usability,confirm,confirmation,16,"Thanks for your confirmation. I believe we're just following the precedence provided by clang (the compiler library cling is based upon), so I'll close this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904
https://github.com/root-project/root/issues/8904:146,usability,close,close,146,"Thanks for your confirmation. I believe we're just following the precedence provided by clang (the compiler library cling is based upon), so I'll close this.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8904
https://github.com/root-project/root/issues/8917:17,integrability,buffer,buffer-overflow,17,I think the heap-buffer-overflow has been addressed by https://github.com/root-project/roottest/pull/897. I think what remains is the translation to CMake.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8917
https://github.com/root-project/root/issues/8917:134,integrability,translat,translation,134,I think the heap-buffer-overflow has been addressed by https://github.com/root-project/roottest/pull/897. I think what remains is the translation to CMake.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8917
https://github.com/root-project/root/issues/8917:134,interoperability,translat,translation,134,I think the heap-buffer-overflow has been addressed by https://github.com/root-project/roottest/pull/897. I think what remains is the translation to CMake.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8917
https://github.com/root-project/root/issues/8923:340,availability,Error,Error,340,"Dear @eguiraud,. I tried to play a bit with it and apparently one of the problem is that `CMAKE_SOURCE_DIR` and `CMAKE_BINARY_DIR` have to be changed to `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in some places. I'm able to enter in the configuration step but then it crashes because of `RootMacros.cmake` :. ```cmake. CMake Error at build/_deps/root-src/cmake/modules/RootMacros.cmake:442 (message):. Cannot find header ROOT/TErrorDefaultHandler.hxx to generate dictionary. G__Core for. Did you forget to set the INCLUDE_DIRECTORIES property for. the current directory? Call Stack (most recent call first):. build/_deps/root-src/core/CMakeLists.txt:237 (ROOT_GENERATE_DICTIONARY). ```. I tried to change them in `RootMacros.cmake` but it is a difficult part. . At least the use of `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in the right places should solve a lot of errors.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:897,availability,error,errors,897,"Dear @eguiraud,. I tried to play a bit with it and apparently one of the problem is that `CMAKE_SOURCE_DIR` and `CMAKE_BINARY_DIR` have to be changed to `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in some places. I'm able to enter in the configuration step but then it crashes because of `RootMacros.cmake` :. ```cmake. CMake Error at build/_deps/root-src/cmake/modules/RootMacros.cmake:442 (message):. Cannot find header ROOT/TErrorDefaultHandler.hxx to generate dictionary. G__Core for. Did you forget to set the INCLUDE_DIRECTORIES property for. the current directory? Call Stack (most recent call first):. build/_deps/root-src/core/CMakeLists.txt:237 (ROOT_GENERATE_DICTIONARY). ```. I tried to change them in `RootMacros.cmake` but it is a difficult part. . At least the use of `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in the right places should solve a lot of errors.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:252,deployability,configurat,configuration,252,"Dear @eguiraud,. I tried to play a bit with it and apparently one of the problem is that `CMAKE_SOURCE_DIR` and `CMAKE_BINARY_DIR` have to be changed to `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in some places. I'm able to enter in the configuration step but then it crashes because of `RootMacros.cmake` :. ```cmake. CMake Error at build/_deps/root-src/cmake/modules/RootMacros.cmake:442 (message):. Cannot find header ROOT/TErrorDefaultHandler.hxx to generate dictionary. G__Core for. Did you forget to set the INCLUDE_DIRECTORIES property for. the current directory? Call Stack (most recent call first):. build/_deps/root-src/core/CMakeLists.txt:237 (ROOT_GENERATE_DICTIONARY). ```. I tried to change them in `RootMacros.cmake` but it is a difficult part. . At least the use of `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in the right places should solve a lot of errors.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:349,deployability,build,build,349,"Dear @eguiraud,. I tried to play a bit with it and apparently one of the problem is that `CMAKE_SOURCE_DIR` and `CMAKE_BINARY_DIR` have to be changed to `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in some places. I'm able to enter in the configuration step but then it crashes because of `RootMacros.cmake` :. ```cmake. CMake Error at build/_deps/root-src/cmake/modules/RootMacros.cmake:442 (message):. Cannot find header ROOT/TErrorDefaultHandler.hxx to generate dictionary. G__Core for. Did you forget to set the INCLUDE_DIRECTORIES property for. the current directory? Call Stack (most recent call first):. build/_deps/root-src/core/CMakeLists.txt:237 (ROOT_GENERATE_DICTIONARY). ```. I tried to change them in `RootMacros.cmake` but it is a difficult part. . At least the use of `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in the right places should solve a lot of errors.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:376,deployability,modul,modules,376,"Dear @eguiraud,. I tried to play a bit with it and apparently one of the problem is that `CMAKE_SOURCE_DIR` and `CMAKE_BINARY_DIR` have to be changed to `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in some places. I'm able to enter in the configuration step but then it crashes because of `RootMacros.cmake` :. ```cmake. CMake Error at build/_deps/root-src/cmake/modules/RootMacros.cmake:442 (message):. Cannot find header ROOT/TErrorDefaultHandler.hxx to generate dictionary. G__Core for. Did you forget to set the INCLUDE_DIRECTORIES property for. the current directory? Call Stack (most recent call first):. build/_deps/root-src/core/CMakeLists.txt:237 (ROOT_GENERATE_DICTIONARY). ```. I tried to change them in `RootMacros.cmake` but it is a difficult part. . At least the use of `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in the right places should solve a lot of errors.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:591,deployability,Stack,Stack,591,"Dear @eguiraud,. I tried to play a bit with it and apparently one of the problem is that `CMAKE_SOURCE_DIR` and `CMAKE_BINARY_DIR` have to be changed to `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in some places. I'm able to enter in the configuration step but then it crashes because of `RootMacros.cmake` :. ```cmake. CMake Error at build/_deps/root-src/cmake/modules/RootMacros.cmake:442 (message):. Cannot find header ROOT/TErrorDefaultHandler.hxx to generate dictionary. G__Core for. Did you forget to set the INCLUDE_DIRECTORIES property for. the current directory? Call Stack (most recent call first):. build/_deps/root-src/core/CMakeLists.txt:237 (ROOT_GENERATE_DICTIONARY). ```. I tried to change them in `RootMacros.cmake` but it is a difficult part. . At least the use of `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in the right places should solve a lot of errors.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:624,deployability,build,build,624,"Dear @eguiraud,. I tried to play a bit with it and apparently one of the problem is that `CMAKE_SOURCE_DIR` and `CMAKE_BINARY_DIR` have to be changed to `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in some places. I'm able to enter in the configuration step but then it crashes because of `RootMacros.cmake` :. ```cmake. CMake Error at build/_deps/root-src/cmake/modules/RootMacros.cmake:442 (message):. Cannot find header ROOT/TErrorDefaultHandler.hxx to generate dictionary. G__Core for. Did you forget to set the INCLUDE_DIRECTORIES property for. the current directory? Call Stack (most recent call first):. build/_deps/root-src/core/CMakeLists.txt:237 (ROOT_GENERATE_DICTIONARY). ```. I tried to change them in `RootMacros.cmake` but it is a difficult part. . At least the use of `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in the right places should solve a lot of errors.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:567,energy efficiency,current,current,567,"Dear @eguiraud,. I tried to play a bit with it and apparently one of the problem is that `CMAKE_SOURCE_DIR` and `CMAKE_BINARY_DIR` have to be changed to `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in some places. I'm able to enter in the configuration step but then it crashes because of `RootMacros.cmake` :. ```cmake. CMake Error at build/_deps/root-src/cmake/modules/RootMacros.cmake:442 (message):. Cannot find header ROOT/TErrorDefaultHandler.hxx to generate dictionary. G__Core for. Did you forget to set the INCLUDE_DIRECTORIES property for. the current directory? Call Stack (most recent call first):. build/_deps/root-src/core/CMakeLists.txt:237 (ROOT_GENERATE_DICTIONARY). ```. I tried to change them in `RootMacros.cmake` but it is a difficult part. . At least the use of `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in the right places should solve a lot of errors.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:645,energy efficiency,core,core,645,"Dear @eguiraud,. I tried to play a bit with it and apparently one of the problem is that `CMAKE_SOURCE_DIR` and `CMAKE_BINARY_DIR` have to be changed to `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in some places. I'm able to enter in the configuration step but then it crashes because of `RootMacros.cmake` :. ```cmake. CMake Error at build/_deps/root-src/cmake/modules/RootMacros.cmake:442 (message):. Cannot find header ROOT/TErrorDefaultHandler.hxx to generate dictionary. G__Core for. Did you forget to set the INCLUDE_DIRECTORIES property for. the current directory? Call Stack (most recent call first):. build/_deps/root-src/core/CMakeLists.txt:237 (ROOT_GENERATE_DICTIONARY). ```. I tried to change them in `RootMacros.cmake` but it is a difficult part. . At least the use of `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in the right places should solve a lot of errors.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:252,integrability,configur,configuration,252,"Dear @eguiraud,. I tried to play a bit with it and apparently one of the problem is that `CMAKE_SOURCE_DIR` and `CMAKE_BINARY_DIR` have to be changed to `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in some places. I'm able to enter in the configuration step but then it crashes because of `RootMacros.cmake` :. ```cmake. CMake Error at build/_deps/root-src/cmake/modules/RootMacros.cmake:442 (message):. Cannot find header ROOT/TErrorDefaultHandler.hxx to generate dictionary. G__Core for. Did you forget to set the INCLUDE_DIRECTORIES property for. the current directory? Call Stack (most recent call first):. build/_deps/root-src/core/CMakeLists.txt:237 (ROOT_GENERATE_DICTIONARY). ```. I tried to change them in `RootMacros.cmake` but it is a difficult part. . At least the use of `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in the right places should solve a lot of errors.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:406,integrability,messag,message,406,"Dear @eguiraud,. I tried to play a bit with it and apparently one of the problem is that `CMAKE_SOURCE_DIR` and `CMAKE_BINARY_DIR` have to be changed to `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in some places. I'm able to enter in the configuration step but then it crashes because of `RootMacros.cmake` :. ```cmake. CMake Error at build/_deps/root-src/cmake/modules/RootMacros.cmake:442 (message):. Cannot find header ROOT/TErrorDefaultHandler.hxx to generate dictionary. G__Core for. Did you forget to set the INCLUDE_DIRECTORIES property for. the current directory? Call Stack (most recent call first):. build/_deps/root-src/core/CMakeLists.txt:237 (ROOT_GENERATE_DICTIONARY). ```. I tried to change them in `RootMacros.cmake` but it is a difficult part. . At least the use of `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in the right places should solve a lot of errors.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:406,interoperability,messag,message,406,"Dear @eguiraud,. I tried to play a bit with it and apparently one of the problem is that `CMAKE_SOURCE_DIR` and `CMAKE_BINARY_DIR` have to be changed to `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in some places. I'm able to enter in the configuration step but then it crashes because of `RootMacros.cmake` :. ```cmake. CMake Error at build/_deps/root-src/cmake/modules/RootMacros.cmake:442 (message):. Cannot find header ROOT/TErrorDefaultHandler.hxx to generate dictionary. G__Core for. Did you forget to set the INCLUDE_DIRECTORIES property for. the current directory? Call Stack (most recent call first):. build/_deps/root-src/core/CMakeLists.txt:237 (ROOT_GENERATE_DICTIONARY). ```. I tried to change them in `RootMacros.cmake` but it is a difficult part. . At least the use of `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in the right places should solve a lot of errors.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:252,modifiability,configur,configuration,252,"Dear @eguiraud,. I tried to play a bit with it and apparently one of the problem is that `CMAKE_SOURCE_DIR` and `CMAKE_BINARY_DIR` have to be changed to `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in some places. I'm able to enter in the configuration step but then it crashes because of `RootMacros.cmake` :. ```cmake. CMake Error at build/_deps/root-src/cmake/modules/RootMacros.cmake:442 (message):. Cannot find header ROOT/TErrorDefaultHandler.hxx to generate dictionary. G__Core for. Did you forget to set the INCLUDE_DIRECTORIES property for. the current directory? Call Stack (most recent call first):. build/_deps/root-src/core/CMakeLists.txt:237 (ROOT_GENERATE_DICTIONARY). ```. I tried to change them in `RootMacros.cmake` but it is a difficult part. . At least the use of `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in the right places should solve a lot of errors.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:376,modifiability,modul,modules,376,"Dear @eguiraud,. I tried to play a bit with it and apparently one of the problem is that `CMAKE_SOURCE_DIR` and `CMAKE_BINARY_DIR` have to be changed to `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in some places. I'm able to enter in the configuration step but then it crashes because of `RootMacros.cmake` :. ```cmake. CMake Error at build/_deps/root-src/cmake/modules/RootMacros.cmake:442 (message):. Cannot find header ROOT/TErrorDefaultHandler.hxx to generate dictionary. G__Core for. Did you forget to set the INCLUDE_DIRECTORIES property for. the current directory? Call Stack (most recent call first):. build/_deps/root-src/core/CMakeLists.txt:237 (ROOT_GENERATE_DICTIONARY). ```. I tried to change them in `RootMacros.cmake` but it is a difficult part. . At least the use of `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in the right places should solve a lot of errors.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:340,performance,Error,Error,340,"Dear @eguiraud,. I tried to play a bit with it and apparently one of the problem is that `CMAKE_SOURCE_DIR` and `CMAKE_BINARY_DIR` have to be changed to `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in some places. I'm able to enter in the configuration step but then it crashes because of `RootMacros.cmake` :. ```cmake. CMake Error at build/_deps/root-src/cmake/modules/RootMacros.cmake:442 (message):. Cannot find header ROOT/TErrorDefaultHandler.hxx to generate dictionary. G__Core for. Did you forget to set the INCLUDE_DIRECTORIES property for. the current directory? Call Stack (most recent call first):. build/_deps/root-src/core/CMakeLists.txt:237 (ROOT_GENERATE_DICTIONARY). ```. I tried to change them in `RootMacros.cmake` but it is a difficult part. . At least the use of `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in the right places should solve a lot of errors.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:897,performance,error,errors,897,"Dear @eguiraud,. I tried to play a bit with it and apparently one of the problem is that `CMAKE_SOURCE_DIR` and `CMAKE_BINARY_DIR` have to be changed to `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in some places. I'm able to enter in the configuration step but then it crashes because of `RootMacros.cmake` :. ```cmake. CMake Error at build/_deps/root-src/cmake/modules/RootMacros.cmake:442 (message):. Cannot find header ROOT/TErrorDefaultHandler.hxx to generate dictionary. G__Core for. Did you forget to set the INCLUDE_DIRECTORIES property for. the current directory? Call Stack (most recent call first):. build/_deps/root-src/core/CMakeLists.txt:237 (ROOT_GENERATE_DICTIONARY). ```. I tried to change them in `RootMacros.cmake` but it is a difficult part. . At least the use of `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in the right places should solve a lot of errors.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:340,safety,Error,Error,340,"Dear @eguiraud,. I tried to play a bit with it and apparently one of the problem is that `CMAKE_SOURCE_DIR` and `CMAKE_BINARY_DIR` have to be changed to `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in some places. I'm able to enter in the configuration step but then it crashes because of `RootMacros.cmake` :. ```cmake. CMake Error at build/_deps/root-src/cmake/modules/RootMacros.cmake:442 (message):. Cannot find header ROOT/TErrorDefaultHandler.hxx to generate dictionary. G__Core for. Did you forget to set the INCLUDE_DIRECTORIES property for. the current directory? Call Stack (most recent call first):. build/_deps/root-src/core/CMakeLists.txt:237 (ROOT_GENERATE_DICTIONARY). ```. I tried to change them in `RootMacros.cmake` but it is a difficult part. . At least the use of `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in the right places should solve a lot of errors.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:376,safety,modul,modules,376,"Dear @eguiraud,. I tried to play a bit with it and apparently one of the problem is that `CMAKE_SOURCE_DIR` and `CMAKE_BINARY_DIR` have to be changed to `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in some places. I'm able to enter in the configuration step but then it crashes because of `RootMacros.cmake` :. ```cmake. CMake Error at build/_deps/root-src/cmake/modules/RootMacros.cmake:442 (message):. Cannot find header ROOT/TErrorDefaultHandler.hxx to generate dictionary. G__Core for. Did you forget to set the INCLUDE_DIRECTORIES property for. the current directory? Call Stack (most recent call first):. build/_deps/root-src/core/CMakeLists.txt:237 (ROOT_GENERATE_DICTIONARY). ```. I tried to change them in `RootMacros.cmake` but it is a difficult part. . At least the use of `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in the right places should solve a lot of errors.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:897,safety,error,errors,897,"Dear @eguiraud,. I tried to play a bit with it and apparently one of the problem is that `CMAKE_SOURCE_DIR` and `CMAKE_BINARY_DIR` have to be changed to `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in some places. I'm able to enter in the configuration step but then it crashes because of `RootMacros.cmake` :. ```cmake. CMake Error at build/_deps/root-src/cmake/modules/RootMacros.cmake:442 (message):. Cannot find header ROOT/TErrorDefaultHandler.hxx to generate dictionary. G__Core for. Did you forget to set the INCLUDE_DIRECTORIES property for. the current directory? Call Stack (most recent call first):. build/_deps/root-src/core/CMakeLists.txt:237 (ROOT_GENERATE_DICTIONARY). ```. I tried to change them in `RootMacros.cmake` but it is a difficult part. . At least the use of `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in the right places should solve a lot of errors.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:252,security,configur,configuration,252,"Dear @eguiraud,. I tried to play a bit with it and apparently one of the problem is that `CMAKE_SOURCE_DIR` and `CMAKE_BINARY_DIR` have to be changed to `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in some places. I'm able to enter in the configuration step but then it crashes because of `RootMacros.cmake` :. ```cmake. CMake Error at build/_deps/root-src/cmake/modules/RootMacros.cmake:442 (message):. Cannot find header ROOT/TErrorDefaultHandler.hxx to generate dictionary. G__Core for. Did you forget to set the INCLUDE_DIRECTORIES property for. the current directory? Call Stack (most recent call first):. build/_deps/root-src/core/CMakeLists.txt:237 (ROOT_GENERATE_DICTIONARY). ```. I tried to change them in `RootMacros.cmake` but it is a difficult part. . At least the use of `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in the right places should solve a lot of errors.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:340,usability,Error,Error,340,"Dear @eguiraud,. I tried to play a bit with it and apparently one of the problem is that `CMAKE_SOURCE_DIR` and `CMAKE_BINARY_DIR` have to be changed to `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in some places. I'm able to enter in the configuration step but then it crashes because of `RootMacros.cmake` :. ```cmake. CMake Error at build/_deps/root-src/cmake/modules/RootMacros.cmake:442 (message):. Cannot find header ROOT/TErrorDefaultHandler.hxx to generate dictionary. G__Core for. Did you forget to set the INCLUDE_DIRECTORIES property for. the current directory? Call Stack (most recent call first):. build/_deps/root-src/core/CMakeLists.txt:237 (ROOT_GENERATE_DICTIONARY). ```. I tried to change them in `RootMacros.cmake` but it is a difficult part. . At least the use of `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in the right places should solve a lot of errors.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:897,usability,error,errors,897,"Dear @eguiraud,. I tried to play a bit with it and apparently one of the problem is that `CMAKE_SOURCE_DIR` and `CMAKE_BINARY_DIR` have to be changed to `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in some places. I'm able to enter in the configuration step but then it crashes because of `RootMacros.cmake` :. ```cmake. CMake Error at build/_deps/root-src/cmake/modules/RootMacros.cmake:442 (message):. Cannot find header ROOT/TErrorDefaultHandler.hxx to generate dictionary. G__Core for. Did you forget to set the INCLUDE_DIRECTORIES property for. the current directory? Call Stack (most recent call first):. build/_deps/root-src/core/CMakeLists.txt:237 (ROOT_GENERATE_DICTIONARY). ```. I tried to change them in `RootMacros.cmake` but it is a difficult part. . At least the use of `CMAKE_CURRENT_SOURCE_DIR` and `CMAKE_CURRENT_BINARY_DIR` in the right places should solve a lot of errors.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:79,integrability,sub,sub-package,79,"Hi,. I have made some changes and ROOT seems to compile as main package and as sub-package using FetchContent. Most changes are quite trivial but some parts may require checks from ROOT-expert. Can I pull request the proposed changes ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:64,modifiability,pac,package,64,"Hi,. I have made some changes and ROOT seems to compile as main package and as sub-package using FetchContent. Most changes are quite trivial but some parts may require checks from ROOT-expert. Can I pull request the proposed changes ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:83,modifiability,pac,package,83,"Hi,. I have made some changes and ROOT seems to compile as main package and as sub-package using FetchContent. Most changes are quite trivial but some parts may require checks from ROOT-expert. Can I pull request the proposed changes ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:68,deployability,patch,patch,68,"Hi @flagarde ,. nice! I would say yes to the PR, since you have the patch anyway. So we can see what's needed to make this work. Then it will be up to our build system expert @bellenot (coming back to work in a couple of weeks) to decide if we can merge or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:155,deployability,build,build,155,"Hi @flagarde ,. nice! I would say yes to the PR, since you have the patch anyway. So we can see what's needed to make this work. Then it will be up to our build system expert @bellenot (coming back to work in a couple of weeks) to decide if we can merge or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:211,integrability,coupl,couple,211,"Hi @flagarde ,. nice! I would say yes to the PR, since you have the patch anyway. So we can see what's needed to make this work. Then it will be up to our build system expert @bellenot (coming back to work in a couple of weeks) to decide if we can merge or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:211,modifiability,coupl,couple,211,"Hi @flagarde ,. nice! I would say yes to the PR, since you have the patch anyway. So we can see what's needed to make this work. Then it will be up to our build system expert @bellenot (coming back to work in a couple of weeks) to decide if we can merge or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:68,safety,patch,patch,68,"Hi @flagarde ,. nice! I would say yes to the PR, since you have the patch anyway. So we can see what's needed to make this work. Then it will be up to our build system expert @bellenot (coming back to work in a couple of weeks) to decide if we can merge or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:68,security,patch,patch,68,"Hi @flagarde ,. nice! I would say yes to the PR, since you have the patch anyway. So we can see what's needed to make this work. Then it will be up to our build system expert @bellenot (coming back to work in a couple of weeks) to decide if we can merge or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/issues/8923:211,testability,coupl,couple,211,"Hi @flagarde ,. nice! I would say yes to the PR, since you have the patch anyway. So we can see what's needed to make this work. Then it will be up to our build system expert @bellenot (coming back to work in a couple of weeks) to decide if we can merge or not :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8923
https://github.com/root-project/root/pull/8924:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8924
https://github.com/root-project/root/pull/8924:38,availability,outag,outage,38,(jenkins was stuck due to yesterday's outage),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8924
https://github.com/root-project/root/pull/8924:38,reliability,outag,outage,38,(jenkins was stuck due to yesterday's outage),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8924
https://github.com/root-project/root/pull/8925:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8925
https://github.com/root-project/root/pull/8925:0,availability,Failur,Failures,0,Failures are pre-existing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8925
https://github.com/root-project/root/pull/8925:0,deployability,Fail,Failures,0,Failures are pre-existing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8925
https://github.com/root-project/root/pull/8925:0,performance,Failur,Failures,0,Failures are pre-existing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8925
https://github.com/root-project/root/pull/8925:0,reliability,Fail,Failures,0,Failures are pre-existing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8925
https://github.com/root-project/root/pull/8927:64,deployability,patch,patches,64,"Hi @edfink234 ,. in this PR you are requesting to merge 6-24-00-patches into master, that was probably not the intention. Please open a new PR with your contribution.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8927
https://github.com/root-project/root/pull/8927:64,safety,patch,patches,64,"Hi @edfink234 ,. in this PR you are requesting to merge 6-24-00-patches into master, that was probably not the intention. Please open a new PR with your contribution.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8927
https://github.com/root-project/root/pull/8927:64,security,patch,patches,64,"Hi @edfink234 ,. in this PR you are requesting to merge 6-24-00-patches into master, that was probably not the intention. Please open a new PR with your contribution.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8927
https://github.com/root-project/root/pull/8929:11,deployability,build,build,11,@phsft-bot build just on mac11.0/cxx17,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8929
https://github.com/root-project/root/pull/8930:10,deployability,updat,updated,10,"The PR is updated with a better fix to the problem seen with the PCH, by removing some of the definitions in RModelParser_Keras.h in the implementation file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8930
https://github.com/root-project/root/pull/8930:10,safety,updat,updated,10,"The PR is updated with a better fix to the problem seen with the PCH, by removing some of the definitions in RModelParser_Keras.h in the implementation file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8930
https://github.com/root-project/root/pull/8930:10,security,updat,updated,10,"The PR is updated with a better fix to the problem seen with the PCH, by removing some of the definitions in RModelParser_Keras.h in the implementation file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8930
https://github.com/root-project/root/pull/8932:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8932
https://github.com/root-project/root/pull/8932:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8932
https://github.com/root-project/root/pull/8932:9,availability,failur,failure,9,The test failure are unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8932
https://github.com/root-project/root/pull/8932:9,deployability,fail,failure,9,The test failure are unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8932
https://github.com/root-project/root/pull/8932:9,performance,failur,failure,9,The test failure are unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8932
https://github.com/root-project/root/pull/8932:9,reliability,fail,failure,9,The test failure are unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8932
https://github.com/root-project/root/pull/8932:4,safety,test,test,4,The test failure are unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8932
https://github.com/root-project/root/pull/8932:4,testability,test,test,4,The test failure are unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8932
https://github.com/root-project/root/issues/8933:258,usability,prefer,preferred,258,"Yes, I agree that the commit you pointed out is the problem. We need to decide if we fix that to always use .so (not sure what happens to Windows then), or if we let ROOT use .dylib on Mac instead of .so. @Axel-Naumann, please let me know what should be the preferred fix, and I will make a pull request with it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8933
https://github.com/root-project/root/issues/8933:180,usability,confirm,confirmed,180,"Discussed with @amadio , probably the least disruptive way to solve this would be to use `.so` again instead of `${CMAKE_SHARED_LIBRARY_SUFFIX}` in cppyy's `CMakeList.txt`s. To be confirmed by @Axel-Naumann .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8933
https://github.com/root-project/root/pull/8934:83,deployability,log,logic,83,Following Philippe's suggestion for the test (thanks!) it's clear that the current logic is not enough.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8934
https://github.com/root-project/root/pull/8934:75,energy efficiency,current,current,75,Following Philippe's suggestion for the test (thanks!) it's clear that the current logic is not enough.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8934
https://github.com/root-project/root/pull/8934:40,safety,test,test,40,Following Philippe's suggestion for the test (thanks!) it's clear that the current logic is not enough.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8934
https://github.com/root-project/root/pull/8934:83,safety,log,logic,83,Following Philippe's suggestion for the test (thanks!) it's clear that the current logic is not enough.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8934
https://github.com/root-project/root/pull/8934:83,security,log,logic,83,Following Philippe's suggestion for the test (thanks!) it's clear that the current logic is not enough.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8934
https://github.com/root-project/root/pull/8934:40,testability,test,test,40,Following Philippe's suggestion for the test (thanks!) it's clear that the current logic is not enough.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8934
https://github.com/root-project/root/pull/8934:83,testability,log,logic,83,Following Philippe's suggestion for the test (thanks!) it's clear that the current logic is not enough.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8934
https://github.com/root-project/root/pull/8934:60,usability,clear,clear,60,Following Philippe's suggestion for the test (thanks!) it's clear that the current logic is not enough.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8934
https://github.com/root-project/root/pull/8934:0,deployability,Updat,Updated,0,"Updated docs, run clang-tidy on the modified file and squashed to one commit. If tests pass I will merge",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8934
https://github.com/root-project/root/pull/8934:0,safety,Updat,Updated,0,"Updated docs, run clang-tidy on the modified file and squashed to one commit. If tests pass I will merge",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8934
https://github.com/root-project/root/pull/8934:81,safety,test,tests,81,"Updated docs, run clang-tidy on the modified file and squashed to one commit. If tests pass I will merge",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8934
https://github.com/root-project/root/pull/8934:0,security,Updat,Updated,0,"Updated docs, run clang-tidy on the modified file and squashed to one commit. If tests pass I will merge",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8934
https://github.com/root-project/root/pull/8934:36,security,modif,modified,36,"Updated docs, run clang-tidy on the modified file and squashed to one commit. If tests pass I will merge",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8934
https://github.com/root-project/root/pull/8934:81,testability,test,tests,81,"Updated docs, run clang-tidy on the modified file and squashed to one commit. If tests pass I will merge",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8934
https://github.com/root-project/root/issues/8935:213,usability,help,helpful,213,"Hi @guitargeek , I didn't get notification regarding your reply to the issue which I posted on the ROOT forum. Sorry about the late reply. The suggested work around works fine for me. Thank you very much for your helpful reply!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8935
https://github.com/root-project/root/issues/8935:106,safety,compl,complicate,106,"Okay! If the solution suggested on the forum worked for you, I will close this issue. There is no need to complicate RooFit even more by adding new options if there is no immediate need.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8935
https://github.com/root-project/root/issues/8935:106,security,compl,complicate,106,"Okay! If the solution suggested on the forum worked for you, I will close this issue. There is no need to complicate RooFit even more by adding new options if there is no immediate need.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8935
https://github.com/root-project/root/issues/8935:68,usability,close,close,68,"Okay! If the solution suggested on the forum worked for you, I will close this issue. There is no need to complicate RooFit even more by adding new options if there is no immediate need.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8935
https://github.com/root-project/root/pull/8937:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu2004/default with flags -Dtmva-sofie=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8937
https://github.com/root-project/root/pull/8937:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu2004/default with flags -Dtmva-sofie=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8937
https://github.com/root-project/root/pull/8937:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu2004/default with flags -Dtmva-sofie=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8937
https://github.com/root-project/root/pull/8937:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu18.04/default with flags -Dtmva-sofie=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8937
https://github.com/root-project/root/pull/8937:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu18.04/default, ROOT-ubuntu2004/default, ROOT-ubuntu16/default with flags -Dtmva-sofie=On",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8937
https://github.com/root-project/root/pull/8937:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu18.04/default, ROOT-ubuntu2004/default with flags -Dtmva-sofie=On",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8937
https://github.com/root-project/root/pull/8937:11,deployability,build,build,11,"@phsft-bot build just on ROOT-ubuntu18.04/default, ROOT-ubuntu2004/default with flags -Dtmva-sofie=On",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8937
https://github.com/root-project/root/pull/8938:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu18.04/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8938
https://github.com/root-project/root/pull/8938:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu18.04/default,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8938
https://github.com/root-project/root/issues/8939:17,usability,document,documentation,17,That's more of a documentation issue. We don't actually support C++20 yet (clang too old). I hope https://github.com/root-project/web/pull/642 addresses this?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8939
https://github.com/root-project/root/issues/8939:56,usability,support,support,56,That's more of a documentation issue. We don't actually support C++20 yet (clang too old). I hope https://github.com/root-project/web/pull/642 addresses this?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8939
https://github.com/root-project/root/pull/8940:140,energy efficiency,model,models,140,"I think I made up the BranchingPDF test myself as a sort of stress test, also for benchmarking purposes, but not based on realistic physics models. Perhaps good to check whether it makes sense at all (conceptually, as a representative of a real kind of model) to keep it. If not, maybe just ditch it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8940
https://github.com/root-project/root/pull/8940:253,energy efficiency,model,model,253,"I think I made up the BranchingPDF test myself as a sort of stress test, also for benchmarking purposes, but not based on realistic physics models. Perhaps good to check whether it makes sense at all (conceptually, as a representative of a real kind of model) to keep it. If not, maybe just ditch it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8940
https://github.com/root-project/root/pull/8940:35,safety,test,test,35,"I think I made up the BranchingPDF test myself as a sort of stress test, also for benchmarking purposes, but not based on realistic physics models. Perhaps good to check whether it makes sense at all (conceptually, as a representative of a real kind of model) to keep it. If not, maybe just ditch it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8940
https://github.com/root-project/root/pull/8940:67,safety,test,test,67,"I think I made up the BranchingPDF test myself as a sort of stress test, also for benchmarking purposes, but not based on realistic physics models. Perhaps good to check whether it makes sense at all (conceptually, as a representative of a real kind of model) to keep it. If not, maybe just ditch it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8940
https://github.com/root-project/root/pull/8940:140,security,model,models,140,"I think I made up the BranchingPDF test myself as a sort of stress test, also for benchmarking purposes, but not based on realistic physics models. Perhaps good to check whether it makes sense at all (conceptually, as a representative of a real kind of model) to keep it. If not, maybe just ditch it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8940
https://github.com/root-project/root/pull/8940:253,security,model,model,253,"I think I made up the BranchingPDF test myself as a sort of stress test, also for benchmarking purposes, but not based on realistic physics models. Perhaps good to check whether it makes sense at all (conceptually, as a representative of a real kind of model) to keep it. If not, maybe just ditch it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8940
https://github.com/root-project/root/pull/8940:35,testability,test,test,35,"I think I made up the BranchingPDF test myself as a sort of stress test, also for benchmarking purposes, but not based on realistic physics models. Perhaps good to check whether it makes sense at all (conceptually, as a representative of a real kind of model) to keep it. If not, maybe just ditch it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8940
https://github.com/root-project/root/pull/8940:67,testability,test,test,67,"I think I made up the BranchingPDF test myself as a sort of stress test, also for benchmarking purposes, but not based on realistic physics models. Perhaps good to check whether it makes sense at all (conceptually, as a representative of a real kind of model) to keep it. If not, maybe just ditch it.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8940
https://github.com/root-project/root/pull/8941:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:183,availability,error,error,183,"@flagarde apologies for not making progress with this in a reasonable time. Would you be able to address the conflict by rebasing? We will then re-run the tests to see what the CMake error is. It might just be a CMake too old; we have bumped the required CMake version to 3.16 in the meantime, so that might have fixed itself.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:261,deployability,version,version,261,"@flagarde apologies for not making progress with this in a reasonable time. Would you be able to address the conflict by rebasing? We will then re-run the tests to see what the CMake error is. It might just be a CMake too old; we have bumped the required CMake version to 3.16 in the meantime, so that might have fixed itself.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:261,integrability,version,version,261,"@flagarde apologies for not making progress with this in a reasonable time. Would you be able to address the conflict by rebasing? We will then re-run the tests to see what the CMake error is. It might just be a CMake too old; we have bumped the required CMake version to 3.16 in the meantime, so that might have fixed itself.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:109,interoperability,conflict,conflict,109,"@flagarde apologies for not making progress with this in a reasonable time. Would you be able to address the conflict by rebasing? We will then re-run the tests to see what the CMake error is. It might just be a CMake too old; we have bumped the required CMake version to 3.16 in the meantime, so that might have fixed itself.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:261,modifiability,version,version,261,"@flagarde apologies for not making progress with this in a reasonable time. Would you be able to address the conflict by rebasing? We will then re-run the tests to see what the CMake error is. It might just be a CMake too old; we have bumped the required CMake version to 3.16 in the meantime, so that might have fixed itself.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:70,performance,time,time,70,"@flagarde apologies for not making progress with this in a reasonable time. Would you be able to address the conflict by rebasing? We will then re-run the tests to see what the CMake error is. It might just be a CMake too old; we have bumped the required CMake version to 3.16 in the meantime, so that might have fixed itself.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:183,performance,error,error,183,"@flagarde apologies for not making progress with this in a reasonable time. Would you be able to address the conflict by rebasing? We will then re-run the tests to see what the CMake error is. It might just be a CMake too old; we have bumped the required CMake version to 3.16 in the meantime, so that might have fixed itself.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:155,safety,test,tests,155,"@flagarde apologies for not making progress with this in a reasonable time. Would you be able to address the conflict by rebasing? We will then re-run the tests to see what the CMake error is. It might just be a CMake too old; we have bumped the required CMake version to 3.16 in the meantime, so that might have fixed itself.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:183,safety,error,error,183,"@flagarde apologies for not making progress with this in a reasonable time. Would you be able to address the conflict by rebasing? We will then re-run the tests to see what the CMake error is. It might just be a CMake too old; we have bumped the required CMake version to 3.16 in the meantime, so that might have fixed itself.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:155,testability,test,tests,155,"@flagarde apologies for not making progress with this in a reasonable time. Would you be able to address the conflict by rebasing? We will then re-run the tests to see what the CMake error is. It might just be a CMake too old; we have bumped the required CMake version to 3.16 in the meantime, so that might have fixed itself.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:35,usability,progress,progress,35,"@flagarde apologies for not making progress with this in a reasonable time. Would you be able to address the conflict by rebasing? We will then re-run the tests to see what the CMake error is. It might just be a CMake too old; we have bumped the required CMake version to 3.16 in the meantime, so that might have fixed itself.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:183,usability,error,error,183,"@flagarde apologies for not making progress with this in a reasonable time. Would you be able to address the conflict by rebasing? We will then re-run the tests to see what the CMake error is. It might just be a CMake too old; we have bumped the required CMake version to 3.16 in the meantime, so that might have fixed itself.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:564,deployability,instal,install,564,"@Axel-Naumann no problems. I'm working on it. I was using my branch on a personnal project. It seems to work but some hacking is needed to generate dictionnaries (STAGE1) :. ```cmake. root_generate_dictionary(G__Channel ""include/Channel.hpp"" LINKDEF ""include/ChannelLinkDef.hpp"" ${STAGE1}). add_library(Channel OBJECT ""src/Channel.cpp"" G__Channel.cxx). target_include_directories(Channel PUBLIC ""${YAODAQ_INCLUDE}"" PUBLIC ""include""). target_link_libraries(Channel PUBLIC ROOT::Core). set_target_properties(Channel PROPERTIES PUBLIC_HEADER ""include/Channel.hpp""). #install(FILES ${CMAKE_CURRENT_BINARY_DIR}/libChannel_rdict.pcm TYPE BIN). install(TARGETS Channel). ```. More changes are needed on the cmake/modules/RootMacros.cmake for an easier integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:638,deployability,instal,install,638,"@Axel-Naumann no problems. I'm working on it. I was using my branch on a personnal project. It seems to work but some hacking is needed to generate dictionnaries (STAGE1) :. ```cmake. root_generate_dictionary(G__Channel ""include/Channel.hpp"" LINKDEF ""include/ChannelLinkDef.hpp"" ${STAGE1}). add_library(Channel OBJECT ""src/Channel.cpp"" G__Channel.cxx). target_include_directories(Channel PUBLIC ""${YAODAQ_INCLUDE}"" PUBLIC ""include""). target_link_libraries(Channel PUBLIC ROOT::Core). set_target_properties(Channel PROPERTIES PUBLIC_HEADER ""include/Channel.hpp""). #install(FILES ${CMAKE_CURRENT_BINARY_DIR}/libChannel_rdict.pcm TYPE BIN). install(TARGETS Channel). ```. More changes are needed on the cmake/modules/RootMacros.cmake for an easier integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:706,deployability,modul,modules,706,"@Axel-Naumann no problems. I'm working on it. I was using my branch on a personnal project. It seems to work but some hacking is needed to generate dictionnaries (STAGE1) :. ```cmake. root_generate_dictionary(G__Channel ""include/Channel.hpp"" LINKDEF ""include/ChannelLinkDef.hpp"" ${STAGE1}). add_library(Channel OBJECT ""src/Channel.cpp"" G__Channel.cxx). target_include_directories(Channel PUBLIC ""${YAODAQ_INCLUDE}"" PUBLIC ""include""). target_link_libraries(Channel PUBLIC ROOT::Core). set_target_properties(Channel PROPERTIES PUBLIC_HEADER ""include/Channel.hpp""). #install(FILES ${CMAKE_CURRENT_BINARY_DIR}/libChannel_rdict.pcm TYPE BIN). install(TARGETS Channel). ```. More changes are needed on the cmake/modules/RootMacros.cmake for an easier integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:745,deployability,integr,integration,745,"@Axel-Naumann no problems. I'm working on it. I was using my branch on a personnal project. It seems to work but some hacking is needed to generate dictionnaries (STAGE1) :. ```cmake. root_generate_dictionary(G__Channel ""include/Channel.hpp"" LINKDEF ""include/ChannelLinkDef.hpp"" ${STAGE1}). add_library(Channel OBJECT ""src/Channel.cpp"" G__Channel.cxx). target_include_directories(Channel PUBLIC ""${YAODAQ_INCLUDE}"" PUBLIC ""include""). target_link_libraries(Channel PUBLIC ROOT::Core). set_target_properties(Channel PROPERTIES PUBLIC_HEADER ""include/Channel.hpp""). #install(FILES ${CMAKE_CURRENT_BINARY_DIR}/libChannel_rdict.pcm TYPE BIN). install(TARGETS Channel). ```. More changes are needed on the cmake/modules/RootMacros.cmake for an easier integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:477,energy efficiency,Core,Core,477,"@Axel-Naumann no problems. I'm working on it. I was using my branch on a personnal project. It seems to work but some hacking is needed to generate dictionnaries (STAGE1) :. ```cmake. root_generate_dictionary(G__Channel ""include/Channel.hpp"" LINKDEF ""include/ChannelLinkDef.hpp"" ${STAGE1}). add_library(Channel OBJECT ""src/Channel.cpp"" G__Channel.cxx). target_include_directories(Channel PUBLIC ""${YAODAQ_INCLUDE}"" PUBLIC ""include""). target_link_libraries(Channel PUBLIC ROOT::Core). set_target_properties(Channel PROPERTIES PUBLIC_HEADER ""include/Channel.hpp""). #install(FILES ${CMAKE_CURRENT_BINARY_DIR}/libChannel_rdict.pcm TYPE BIN). install(TARGETS Channel). ```. More changes are needed on the cmake/modules/RootMacros.cmake for an easier integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:388,integrability,PUB,PUBLIC,388,"@Axel-Naumann no problems. I'm working on it. I was using my branch on a personnal project. It seems to work but some hacking is needed to generate dictionnaries (STAGE1) :. ```cmake. root_generate_dictionary(G__Channel ""include/Channel.hpp"" LINKDEF ""include/ChannelLinkDef.hpp"" ${STAGE1}). add_library(Channel OBJECT ""src/Channel.cpp"" G__Channel.cxx). target_include_directories(Channel PUBLIC ""${YAODAQ_INCLUDE}"" PUBLIC ""include""). target_link_libraries(Channel PUBLIC ROOT::Core). set_target_properties(Channel PROPERTIES PUBLIC_HEADER ""include/Channel.hpp""). #install(FILES ${CMAKE_CURRENT_BINARY_DIR}/libChannel_rdict.pcm TYPE BIN). install(TARGETS Channel). ```. More changes are needed on the cmake/modules/RootMacros.cmake for an easier integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:415,integrability,PUB,PUBLIC,415,"@Axel-Naumann no problems. I'm working on it. I was using my branch on a personnal project. It seems to work but some hacking is needed to generate dictionnaries (STAGE1) :. ```cmake. root_generate_dictionary(G__Channel ""include/Channel.hpp"" LINKDEF ""include/ChannelLinkDef.hpp"" ${STAGE1}). add_library(Channel OBJECT ""src/Channel.cpp"" G__Channel.cxx). target_include_directories(Channel PUBLIC ""${YAODAQ_INCLUDE}"" PUBLIC ""include""). target_link_libraries(Channel PUBLIC ROOT::Core). set_target_properties(Channel PROPERTIES PUBLIC_HEADER ""include/Channel.hpp""). #install(FILES ${CMAKE_CURRENT_BINARY_DIR}/libChannel_rdict.pcm TYPE BIN). install(TARGETS Channel). ```. More changes are needed on the cmake/modules/RootMacros.cmake for an easier integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:464,integrability,PUB,PUBLIC,464,"@Axel-Naumann no problems. I'm working on it. I was using my branch on a personnal project. It seems to work but some hacking is needed to generate dictionnaries (STAGE1) :. ```cmake. root_generate_dictionary(G__Channel ""include/Channel.hpp"" LINKDEF ""include/ChannelLinkDef.hpp"" ${STAGE1}). add_library(Channel OBJECT ""src/Channel.cpp"" G__Channel.cxx). target_include_directories(Channel PUBLIC ""${YAODAQ_INCLUDE}"" PUBLIC ""include""). target_link_libraries(Channel PUBLIC ROOT::Core). set_target_properties(Channel PROPERTIES PUBLIC_HEADER ""include/Channel.hpp""). #install(FILES ${CMAKE_CURRENT_BINARY_DIR}/libChannel_rdict.pcm TYPE BIN). install(TARGETS Channel). ```. More changes are needed on the cmake/modules/RootMacros.cmake for an easier integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:745,integrability,integr,integration,745,"@Axel-Naumann no problems. I'm working on it. I was using my branch on a personnal project. It seems to work but some hacking is needed to generate dictionnaries (STAGE1) :. ```cmake. root_generate_dictionary(G__Channel ""include/Channel.hpp"" LINKDEF ""include/ChannelLinkDef.hpp"" ${STAGE1}). add_library(Channel OBJECT ""src/Channel.cpp"" G__Channel.cxx). target_include_directories(Channel PUBLIC ""${YAODAQ_INCLUDE}"" PUBLIC ""include""). target_link_libraries(Channel PUBLIC ROOT::Core). set_target_properties(Channel PROPERTIES PUBLIC_HEADER ""include/Channel.hpp""). #install(FILES ${CMAKE_CURRENT_BINARY_DIR}/libChannel_rdict.pcm TYPE BIN). install(TARGETS Channel). ```. More changes are needed on the cmake/modules/RootMacros.cmake for an easier integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:745,interoperability,integr,integration,745,"@Axel-Naumann no problems. I'm working on it. I was using my branch on a personnal project. It seems to work but some hacking is needed to generate dictionnaries (STAGE1) :. ```cmake. root_generate_dictionary(G__Channel ""include/Channel.hpp"" LINKDEF ""include/ChannelLinkDef.hpp"" ${STAGE1}). add_library(Channel OBJECT ""src/Channel.cpp"" G__Channel.cxx). target_include_directories(Channel PUBLIC ""${YAODAQ_INCLUDE}"" PUBLIC ""include""). target_link_libraries(Channel PUBLIC ROOT::Core). set_target_properties(Channel PROPERTIES PUBLIC_HEADER ""include/Channel.hpp""). #install(FILES ${CMAKE_CURRENT_BINARY_DIR}/libChannel_rdict.pcm TYPE BIN). install(TARGETS Channel). ```. More changes are needed on the cmake/modules/RootMacros.cmake for an easier integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:706,modifiability,modul,modules,706,"@Axel-Naumann no problems. I'm working on it. I was using my branch on a personnal project. It seems to work but some hacking is needed to generate dictionnaries (STAGE1) :. ```cmake. root_generate_dictionary(G__Channel ""include/Channel.hpp"" LINKDEF ""include/ChannelLinkDef.hpp"" ${STAGE1}). add_library(Channel OBJECT ""src/Channel.cpp"" G__Channel.cxx). target_include_directories(Channel PUBLIC ""${YAODAQ_INCLUDE}"" PUBLIC ""include""). target_link_libraries(Channel PUBLIC ROOT::Core). set_target_properties(Channel PROPERTIES PUBLIC_HEADER ""include/Channel.hpp""). #install(FILES ${CMAKE_CURRENT_BINARY_DIR}/libChannel_rdict.pcm TYPE BIN). install(TARGETS Channel). ```. More changes are needed on the cmake/modules/RootMacros.cmake for an easier integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:745,modifiability,integr,integration,745,"@Axel-Naumann no problems. I'm working on it. I was using my branch on a personnal project. It seems to work but some hacking is needed to generate dictionnaries (STAGE1) :. ```cmake. root_generate_dictionary(G__Channel ""include/Channel.hpp"" LINKDEF ""include/ChannelLinkDef.hpp"" ${STAGE1}). add_library(Channel OBJECT ""src/Channel.cpp"" G__Channel.cxx). target_include_directories(Channel PUBLIC ""${YAODAQ_INCLUDE}"" PUBLIC ""include""). target_link_libraries(Channel PUBLIC ROOT::Core). set_target_properties(Channel PROPERTIES PUBLIC_HEADER ""include/Channel.hpp""). #install(FILES ${CMAKE_CURRENT_BINARY_DIR}/libChannel_rdict.pcm TYPE BIN). install(TARGETS Channel). ```. More changes are needed on the cmake/modules/RootMacros.cmake for an easier integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:745,reliability,integr,integration,745,"@Axel-Naumann no problems. I'm working on it. I was using my branch on a personnal project. It seems to work but some hacking is needed to generate dictionnaries (STAGE1) :. ```cmake. root_generate_dictionary(G__Channel ""include/Channel.hpp"" LINKDEF ""include/ChannelLinkDef.hpp"" ${STAGE1}). add_library(Channel OBJECT ""src/Channel.cpp"" G__Channel.cxx). target_include_directories(Channel PUBLIC ""${YAODAQ_INCLUDE}"" PUBLIC ""include""). target_link_libraries(Channel PUBLIC ROOT::Core). set_target_properties(Channel PROPERTIES PUBLIC_HEADER ""include/Channel.hpp""). #install(FILES ${CMAKE_CURRENT_BINARY_DIR}/libChannel_rdict.pcm TYPE BIN). install(TARGETS Channel). ```. More changes are needed on the cmake/modules/RootMacros.cmake for an easier integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:706,safety,modul,modules,706,"@Axel-Naumann no problems. I'm working on it. I was using my branch on a personnal project. It seems to work but some hacking is needed to generate dictionnaries (STAGE1) :. ```cmake. root_generate_dictionary(G__Channel ""include/Channel.hpp"" LINKDEF ""include/ChannelLinkDef.hpp"" ${STAGE1}). add_library(Channel OBJECT ""src/Channel.cpp"" G__Channel.cxx). target_include_directories(Channel PUBLIC ""${YAODAQ_INCLUDE}"" PUBLIC ""include""). target_link_libraries(Channel PUBLIC ROOT::Core). set_target_properties(Channel PROPERTIES PUBLIC_HEADER ""include/Channel.hpp""). #install(FILES ${CMAKE_CURRENT_BINARY_DIR}/libChannel_rdict.pcm TYPE BIN). install(TARGETS Channel). ```. More changes are needed on the cmake/modules/RootMacros.cmake for an easier integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:118,security,hack,hacking,118,"@Axel-Naumann no problems. I'm working on it. I was using my branch on a personnal project. It seems to work but some hacking is needed to generate dictionnaries (STAGE1) :. ```cmake. root_generate_dictionary(G__Channel ""include/Channel.hpp"" LINKDEF ""include/ChannelLinkDef.hpp"" ${STAGE1}). add_library(Channel OBJECT ""src/Channel.cpp"" G__Channel.cxx). target_include_directories(Channel PUBLIC ""${YAODAQ_INCLUDE}"" PUBLIC ""include""). target_link_libraries(Channel PUBLIC ROOT::Core). set_target_properties(Channel PROPERTIES PUBLIC_HEADER ""include/Channel.hpp""). #install(FILES ${CMAKE_CURRENT_BINARY_DIR}/libChannel_rdict.pcm TYPE BIN). install(TARGETS Channel). ```. More changes are needed on the cmake/modules/RootMacros.cmake for an easier integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:745,security,integr,integration,745,"@Axel-Naumann no problems. I'm working on it. I was using my branch on a personnal project. It seems to work but some hacking is needed to generate dictionnaries (STAGE1) :. ```cmake. root_generate_dictionary(G__Channel ""include/Channel.hpp"" LINKDEF ""include/ChannelLinkDef.hpp"" ${STAGE1}). add_library(Channel OBJECT ""src/Channel.cpp"" G__Channel.cxx). target_include_directories(Channel PUBLIC ""${YAODAQ_INCLUDE}"" PUBLIC ""include""). target_link_libraries(Channel PUBLIC ROOT::Core). set_target_properties(Channel PROPERTIES PUBLIC_HEADER ""include/Channel.hpp""). #install(FILES ${CMAKE_CURRENT_BINARY_DIR}/libChannel_rdict.pcm TYPE BIN). install(TARGETS Channel). ```. More changes are needed on the cmake/modules/RootMacros.cmake for an easier integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:745,testability,integr,integration,745,"@Axel-Naumann no problems. I'm working on it. I was using my branch on a personnal project. It seems to work but some hacking is needed to generate dictionnaries (STAGE1) :. ```cmake. root_generate_dictionary(G__Channel ""include/Channel.hpp"" LINKDEF ""include/ChannelLinkDef.hpp"" ${STAGE1}). add_library(Channel OBJECT ""src/Channel.cpp"" G__Channel.cxx). target_include_directories(Channel PUBLIC ""${YAODAQ_INCLUDE}"" PUBLIC ""include""). target_link_libraries(Channel PUBLIC ROOT::Core). set_target_properties(Channel PROPERTIES PUBLIC_HEADER ""include/Channel.hpp""). #install(FILES ${CMAKE_CURRENT_BINARY_DIR}/libChannel_rdict.pcm TYPE BIN). install(TARGETS Channel). ```. More changes are needed on the cmake/modules/RootMacros.cmake for an easier integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:73,usability,person,personnal,73,"@Axel-Naumann no problems. I'm working on it. I was using my branch on a personnal project. It seems to work but some hacking is needed to generate dictionnaries (STAGE1) :. ```cmake. root_generate_dictionary(G__Channel ""include/Channel.hpp"" LINKDEF ""include/ChannelLinkDef.hpp"" ${STAGE1}). add_library(Channel OBJECT ""src/Channel.cpp"" G__Channel.cxx). target_include_directories(Channel PUBLIC ""${YAODAQ_INCLUDE}"" PUBLIC ""include""). target_link_libraries(Channel PUBLIC ROOT::Core). set_target_properties(Channel PROPERTIES PUBLIC_HEADER ""include/Channel.hpp""). #install(FILES ${CMAKE_CURRENT_BINARY_DIR}/libChannel_rdict.pcm TYPE BIN). install(TARGETS Channel). ```. More changes are needed on the cmake/modules/RootMacros.cmake for an easier integration.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:50,deployability,version,version,50,Thanks for this! Closing this in favor of the new version.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:50,integrability,version,version,50,Thanks for this! Closing this in favor of the new version.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/pull/8941:50,modifiability,version,version,50,Thanks for this! Closing this in favor of the new version.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8941
https://github.com/root-project/root/issues/8942:64,deployability,fail,fail,64,"@VanyaBelyaev I can't reproduce with latest dev3, does it still fail for you? I use this `CMakeLists.txt` on lxplus, after sourcing latest dev3:. ```. cmake_minimum_required(VERSION 3.16). project(TestProject). find_package(ROOT 6 CONFIG REQUIRED ). find_package(Python3 3.6.9 COMPONENTS Interpreter Development NumPy). ```. and the output I get for Python3 is:. ```. -- Found Python3: /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Tue/x86_64-centos7-gcc9-opt/bin/python3.9 (found suitable version ""3.9.6"", minimum required is ""3.6.9"") found components: Interpreter Development NumPy Development.Module Development.Embed . ```. There was maybe some temporary problem with the NumPy installation in dev3?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8942
https://github.com/root-project/root/issues/8942:174,deployability,VERSION,VERSION,174,"@VanyaBelyaev I can't reproduce with latest dev3, does it still fail for you? I use this `CMakeLists.txt` on lxplus, after sourcing latest dev3:. ```. cmake_minimum_required(VERSION 3.16). project(TestProject). find_package(ROOT 6 CONFIG REQUIRED ). find_package(Python3 3.6.9 COMPONENTS Interpreter Development NumPy). ```. and the output I get for Python3 is:. ```. -- Found Python3: /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Tue/x86_64-centos7-gcc9-opt/bin/python3.9 (found suitable version ""3.9.6"", minimum required is ""3.6.9"") found components: Interpreter Development NumPy Development.Module Development.Embed . ```. There was maybe some temporary problem with the NumPy installation in dev3?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8942
https://github.com/root-project/root/issues/8942:488,deployability,version,version,488,"@VanyaBelyaev I can't reproduce with latest dev3, does it still fail for you? I use this `CMakeLists.txt` on lxplus, after sourcing latest dev3:. ```. cmake_minimum_required(VERSION 3.16). project(TestProject). find_package(ROOT 6 CONFIG REQUIRED ). find_package(Python3 3.6.9 COMPONENTS Interpreter Development NumPy). ```. and the output I get for Python3 is:. ```. -- Found Python3: /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Tue/x86_64-centos7-gcc9-opt/bin/python3.9 (found suitable version ""3.9.6"", minimum required is ""3.6.9"") found components: Interpreter Development NumPy Development.Module Development.Embed . ```. There was maybe some temporary problem with the NumPy installation in dev3?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8942
https://github.com/root-project/root/issues/8942:594,deployability,Modul,Module,594,"@VanyaBelyaev I can't reproduce with latest dev3, does it still fail for you? I use this `CMakeLists.txt` on lxplus, after sourcing latest dev3:. ```. cmake_minimum_required(VERSION 3.16). project(TestProject). find_package(ROOT 6 CONFIG REQUIRED ). find_package(Python3 3.6.9 COMPONENTS Interpreter Development NumPy). ```. and the output I get for Python3 is:. ```. -- Found Python3: /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Tue/x86_64-centos7-gcc9-opt/bin/python3.9 (found suitable version ""3.9.6"", minimum required is ""3.6.9"") found components: Interpreter Development NumPy Development.Module Development.Embed . ```. There was maybe some temporary problem with the NumPy installation in dev3?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8942
https://github.com/root-project/root/issues/8942:680,deployability,instal,installation,680,"@VanyaBelyaev I can't reproduce with latest dev3, does it still fail for you? I use this `CMakeLists.txt` on lxplus, after sourcing latest dev3:. ```. cmake_minimum_required(VERSION 3.16). project(TestProject). find_package(ROOT 6 CONFIG REQUIRED ). find_package(Python3 3.6.9 COMPONENTS Interpreter Development NumPy). ```. and the output I get for Python3 is:. ```. -- Found Python3: /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Tue/x86_64-centos7-gcc9-opt/bin/python3.9 (found suitable version ""3.9.6"", minimum required is ""3.6.9"") found components: Interpreter Development NumPy Development.Module Development.Embed . ```. There was maybe some temporary problem with the NumPy installation in dev3?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8942
https://github.com/root-project/root/issues/8942:174,integrability,VERSION,VERSION,174,"@VanyaBelyaev I can't reproduce with latest dev3, does it still fail for you? I use this `CMakeLists.txt` on lxplus, after sourcing latest dev3:. ```. cmake_minimum_required(VERSION 3.16). project(TestProject). find_package(ROOT 6 CONFIG REQUIRED ). find_package(Python3 3.6.9 COMPONENTS Interpreter Development NumPy). ```. and the output I get for Python3 is:. ```. -- Found Python3: /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Tue/x86_64-centos7-gcc9-opt/bin/python3.9 (found suitable version ""3.9.6"", minimum required is ""3.6.9"") found components: Interpreter Development NumPy Development.Module Development.Embed . ```. There was maybe some temporary problem with the NumPy installation in dev3?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8942
https://github.com/root-project/root/issues/8942:277,integrability,COMPON,COMPONENTS,277,"@VanyaBelyaev I can't reproduce with latest dev3, does it still fail for you? I use this `CMakeLists.txt` on lxplus, after sourcing latest dev3:. ```. cmake_minimum_required(VERSION 3.16). project(TestProject). find_package(ROOT 6 CONFIG REQUIRED ). find_package(Python3 3.6.9 COMPONENTS Interpreter Development NumPy). ```. and the output I get for Python3 is:. ```. -- Found Python3: /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Tue/x86_64-centos7-gcc9-opt/bin/python3.9 (found suitable version ""3.9.6"", minimum required is ""3.6.9"") found components: Interpreter Development NumPy Development.Module Development.Embed . ```. There was maybe some temporary problem with the NumPy installation in dev3?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8942
https://github.com/root-project/root/issues/8942:488,integrability,version,version,488,"@VanyaBelyaev I can't reproduce with latest dev3, does it still fail for you? I use this `CMakeLists.txt` on lxplus, after sourcing latest dev3:. ```. cmake_minimum_required(VERSION 3.16). project(TestProject). find_package(ROOT 6 CONFIG REQUIRED ). find_package(Python3 3.6.9 COMPONENTS Interpreter Development NumPy). ```. and the output I get for Python3 is:. ```. -- Found Python3: /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Tue/x86_64-centos7-gcc9-opt/bin/python3.9 (found suitable version ""3.9.6"", minimum required is ""3.6.9"") found components: Interpreter Development NumPy Development.Module Development.Embed . ```. There was maybe some temporary problem with the NumPy installation in dev3?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8942
https://github.com/root-project/root/issues/8942:540,integrability,compon,components,540,"@VanyaBelyaev I can't reproduce with latest dev3, does it still fail for you? I use this `CMakeLists.txt` on lxplus, after sourcing latest dev3:. ```. cmake_minimum_required(VERSION 3.16). project(TestProject). find_package(ROOT 6 CONFIG REQUIRED ). find_package(Python3 3.6.9 COMPONENTS Interpreter Development NumPy). ```. and the output I get for Python3 is:. ```. -- Found Python3: /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Tue/x86_64-centos7-gcc9-opt/bin/python3.9 (found suitable version ""3.9.6"", minimum required is ""3.6.9"") found components: Interpreter Development NumPy Development.Module Development.Embed . ```. There was maybe some temporary problem with the NumPy installation in dev3?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8942
https://github.com/root-project/root/issues/8942:277,interoperability,COMPON,COMPONENTS,277,"@VanyaBelyaev I can't reproduce with latest dev3, does it still fail for you? I use this `CMakeLists.txt` on lxplus, after sourcing latest dev3:. ```. cmake_minimum_required(VERSION 3.16). project(TestProject). find_package(ROOT 6 CONFIG REQUIRED ). find_package(Python3 3.6.9 COMPONENTS Interpreter Development NumPy). ```. and the output I get for Python3 is:. ```. -- Found Python3: /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Tue/x86_64-centos7-gcc9-opt/bin/python3.9 (found suitable version ""3.9.6"", minimum required is ""3.6.9"") found components: Interpreter Development NumPy Development.Module Development.Embed . ```. There was maybe some temporary problem with the NumPy installation in dev3?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8942
https://github.com/root-project/root/issues/8942:540,interoperability,compon,components,540,"@VanyaBelyaev I can't reproduce with latest dev3, does it still fail for you? I use this `CMakeLists.txt` on lxplus, after sourcing latest dev3:. ```. cmake_minimum_required(VERSION 3.16). project(TestProject). find_package(ROOT 6 CONFIG REQUIRED ). find_package(Python3 3.6.9 COMPONENTS Interpreter Development NumPy). ```. and the output I get for Python3 is:. ```. -- Found Python3: /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Tue/x86_64-centos7-gcc9-opt/bin/python3.9 (found suitable version ""3.9.6"", minimum required is ""3.6.9"") found components: Interpreter Development NumPy Development.Module Development.Embed . ```. There was maybe some temporary problem with the NumPy installation in dev3?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8942
https://github.com/root-project/root/issues/8942:174,modifiability,VERSION,VERSION,174,"@VanyaBelyaev I can't reproduce with latest dev3, does it still fail for you? I use this `CMakeLists.txt` on lxplus, after sourcing latest dev3:. ```. cmake_minimum_required(VERSION 3.16). project(TestProject). find_package(ROOT 6 CONFIG REQUIRED ). find_package(Python3 3.6.9 COMPONENTS Interpreter Development NumPy). ```. and the output I get for Python3 is:. ```. -- Found Python3: /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Tue/x86_64-centos7-gcc9-opt/bin/python3.9 (found suitable version ""3.9.6"", minimum required is ""3.6.9"") found components: Interpreter Development NumPy Development.Module Development.Embed . ```. There was maybe some temporary problem with the NumPy installation in dev3?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8942
https://github.com/root-project/root/issues/8942:277,modifiability,COMPON,COMPONENTS,277,"@VanyaBelyaev I can't reproduce with latest dev3, does it still fail for you? I use this `CMakeLists.txt` on lxplus, after sourcing latest dev3:. ```. cmake_minimum_required(VERSION 3.16). project(TestProject). find_package(ROOT 6 CONFIG REQUIRED ). find_package(Python3 3.6.9 COMPONENTS Interpreter Development NumPy). ```. and the output I get for Python3 is:. ```. -- Found Python3: /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Tue/x86_64-centos7-gcc9-opt/bin/python3.9 (found suitable version ""3.9.6"", minimum required is ""3.6.9"") found components: Interpreter Development NumPy Development.Module Development.Embed . ```. There was maybe some temporary problem with the NumPy installation in dev3?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8942
https://github.com/root-project/root/issues/8942:488,modifiability,version,version,488,"@VanyaBelyaev I can't reproduce with latest dev3, does it still fail for you? I use this `CMakeLists.txt` on lxplus, after sourcing latest dev3:. ```. cmake_minimum_required(VERSION 3.16). project(TestProject). find_package(ROOT 6 CONFIG REQUIRED ). find_package(Python3 3.6.9 COMPONENTS Interpreter Development NumPy). ```. and the output I get for Python3 is:. ```. -- Found Python3: /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Tue/x86_64-centos7-gcc9-opt/bin/python3.9 (found suitable version ""3.9.6"", minimum required is ""3.6.9"") found components: Interpreter Development NumPy Development.Module Development.Embed . ```. There was maybe some temporary problem with the NumPy installation in dev3?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8942
https://github.com/root-project/root/issues/8942:540,modifiability,compon,components,540,"@VanyaBelyaev I can't reproduce with latest dev3, does it still fail for you? I use this `CMakeLists.txt` on lxplus, after sourcing latest dev3:. ```. cmake_minimum_required(VERSION 3.16). project(TestProject). find_package(ROOT 6 CONFIG REQUIRED ). find_package(Python3 3.6.9 COMPONENTS Interpreter Development NumPy). ```. and the output I get for Python3 is:. ```. -- Found Python3: /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Tue/x86_64-centos7-gcc9-opt/bin/python3.9 (found suitable version ""3.9.6"", minimum required is ""3.6.9"") found components: Interpreter Development NumPy Development.Module Development.Embed . ```. There was maybe some temporary problem with the NumPy installation in dev3?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8942
https://github.com/root-project/root/issues/8942:594,modifiability,Modul,Module,594,"@VanyaBelyaev I can't reproduce with latest dev3, does it still fail for you? I use this `CMakeLists.txt` on lxplus, after sourcing latest dev3:. ```. cmake_minimum_required(VERSION 3.16). project(TestProject). find_package(ROOT 6 CONFIG REQUIRED ). find_package(Python3 3.6.9 COMPONENTS Interpreter Development NumPy). ```. and the output I get for Python3 is:. ```. -- Found Python3: /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Tue/x86_64-centos7-gcc9-opt/bin/python3.9 (found suitable version ""3.9.6"", minimum required is ""3.6.9"") found components: Interpreter Development NumPy Development.Module Development.Embed . ```. There was maybe some temporary problem with the NumPy installation in dev3?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8942
https://github.com/root-project/root/issues/8942:50,reliability,doe,does,50,"@VanyaBelyaev I can't reproduce with latest dev3, does it still fail for you? I use this `CMakeLists.txt` on lxplus, after sourcing latest dev3:. ```. cmake_minimum_required(VERSION 3.16). project(TestProject). find_package(ROOT 6 CONFIG REQUIRED ). find_package(Python3 3.6.9 COMPONENTS Interpreter Development NumPy). ```. and the output I get for Python3 is:. ```. -- Found Python3: /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Tue/x86_64-centos7-gcc9-opt/bin/python3.9 (found suitable version ""3.9.6"", minimum required is ""3.6.9"") found components: Interpreter Development NumPy Development.Module Development.Embed . ```. There was maybe some temporary problem with the NumPy installation in dev3?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8942
https://github.com/root-project/root/issues/8942:64,reliability,fail,fail,64,"@VanyaBelyaev I can't reproduce with latest dev3, does it still fail for you? I use this `CMakeLists.txt` on lxplus, after sourcing latest dev3:. ```. cmake_minimum_required(VERSION 3.16). project(TestProject). find_package(ROOT 6 CONFIG REQUIRED ). find_package(Python3 3.6.9 COMPONENTS Interpreter Development NumPy). ```. and the output I get for Python3 is:. ```. -- Found Python3: /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Tue/x86_64-centos7-gcc9-opt/bin/python3.9 (found suitable version ""3.9.6"", minimum required is ""3.6.9"") found components: Interpreter Development NumPy Development.Module Development.Embed . ```. There was maybe some temporary problem with the NumPy installation in dev3?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8942
https://github.com/root-project/root/issues/8942:197,safety,Test,TestProject,197,"@VanyaBelyaev I can't reproduce with latest dev3, does it still fail for you? I use this `CMakeLists.txt` on lxplus, after sourcing latest dev3:. ```. cmake_minimum_required(VERSION 3.16). project(TestProject). find_package(ROOT 6 CONFIG REQUIRED ). find_package(Python3 3.6.9 COMPONENTS Interpreter Development NumPy). ```. and the output I get for Python3 is:. ```. -- Found Python3: /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Tue/x86_64-centos7-gcc9-opt/bin/python3.9 (found suitable version ""3.9.6"", minimum required is ""3.6.9"") found components: Interpreter Development NumPy Development.Module Development.Embed . ```. There was maybe some temporary problem with the NumPy installation in dev3?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8942
https://github.com/root-project/root/issues/8942:594,safety,Modul,Module,594,"@VanyaBelyaev I can't reproduce with latest dev3, does it still fail for you? I use this `CMakeLists.txt` on lxplus, after sourcing latest dev3:. ```. cmake_minimum_required(VERSION 3.16). project(TestProject). find_package(ROOT 6 CONFIG REQUIRED ). find_package(Python3 3.6.9 COMPONENTS Interpreter Development NumPy). ```. and the output I get for Python3 is:. ```. -- Found Python3: /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Tue/x86_64-centos7-gcc9-opt/bin/python3.9 (found suitable version ""3.9.6"", minimum required is ""3.6.9"") found components: Interpreter Development NumPy Development.Module Development.Embed . ```. There was maybe some temporary problem with the NumPy installation in dev3?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8942
https://github.com/root-project/root/issues/8942:197,testability,Test,TestProject,197,"@VanyaBelyaev I can't reproduce with latest dev3, does it still fail for you? I use this `CMakeLists.txt` on lxplus, after sourcing latest dev3:. ```. cmake_minimum_required(VERSION 3.16). project(TestProject). find_package(ROOT 6 CONFIG REQUIRED ). find_package(Python3 3.6.9 COMPONENTS Interpreter Development NumPy). ```. and the output I get for Python3 is:. ```. -- Found Python3: /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Tue/x86_64-centos7-gcc9-opt/bin/python3.9 (found suitable version ""3.9.6"", minimum required is ""3.6.9"") found components: Interpreter Development NumPy Development.Module Development.Embed . ```. There was maybe some temporary problem with the NumPy installation in dev3?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8942
https://github.com/root-project/root/issues/8942:505,usability,minim,minimum,505,"@VanyaBelyaev I can't reproduce with latest dev3, does it still fail for you? I use this `CMakeLists.txt` on lxplus, after sourcing latest dev3:. ```. cmake_minimum_required(VERSION 3.16). project(TestProject). find_package(ROOT 6 CONFIG REQUIRED ). find_package(Python3 3.6.9 COMPONENTS Interpreter Development NumPy). ```. and the output I get for Python3 is:. ```. -- Found Python3: /cvmfs/sft-nightlies.cern.ch/lcg/views/dev3/Tue/x86_64-centos7-gcc9-opt/bin/python3.9 (found suitable version ""3.9.6"", minimum required is ""3.6.9"") found components: Interpreter Development NumPy Development.Module Development.Embed . ```. There was maybe some temporary problem with the NumPy installation in dev3?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8942
https://github.com/root-project/root/issues/8942:130,availability,avail,available,130,I am closing the issue since @etejedor himself could not reproduce. Please do not hesitate to re-open if more information becomes available.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8942
https://github.com/root-project/root/issues/8942:130,reliability,availab,available,130,I am closing the issue since @etejedor himself could not reproduce. Please do not hesitate to re-open if more information becomes available.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8942
https://github.com/root-project/root/issues/8942:130,safety,avail,available,130,I am closing the issue since @etejedor himself could not reproduce. Please do not hesitate to re-open if more information becomes available.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8942
https://github.com/root-project/root/issues/8942:130,security,availab,available,130,I am closing the issue since @etejedor himself could not reproduce. Please do not hesitate to re-open if more information becomes available.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8942
https://github.com/root-project/root/pull/8944:2318,availability,servic,service,2318,"ofit/hs3/src/JSONFactories_HistFactory.cxx#L407"">JSONFactories_HistFactory.cxx:407</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FJSONFactories_HistFactory.cxx/cpp%2Fdc%2FContainerUpdatedButNeverQueried/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. <tr>. <td width=""77%"">Use empty instead of equals comparison of size to check for emptiness of std::string. Occurrences: <ul><li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L549"">RooJSONFactoryWSTool.cxx:549</a></li> <li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L607"">RooJSONFactoryWSTool.cxx:607</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FRooJSONFactoryWSTool.cxx/cpp%2Fdc%2FEmptyInsteadOfSize/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. </tbody>. </table>. #### 👉 View analysis in [**DeepCode’s Dashboard**](https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2F/code/?utm_source=gh_review&c=0&w=1&i=1&) | [_Configure the bot_](https://www.deepcode.ai/app/gh/?ownerconfig=root-project). #### 👉 The DeepCode service and API will be deprecated in August, 2021. [Here](https://www.deepcode.ai/blog/migrate-to-snyk-code) is the information how to migrate. Thank you for using DeepCode 🙏 ❤️ ! If you are using our plugins, you might be interested in their successors: [Snyk's JetBrains plugin](https://snyk.co/udpkq) and [Snyk's VS Code plugin](https://snyk.co/udpkr).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:483,deployability,Contain,Container,483,"## DeepCode's analysis on [#51516a](https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2F/code/?utm_source=gh_review&c=0&w=1&i=1&) found:. - :warning: **1** warning, :information_source: **1** minor issue. :point_down:. ## Top issues. <table>. <thead>. <tr>. <th align=""left"">Description</th>. <th align=""left"">Example fixes</th>. </tr>. </thead>. <tbody>. <tr>. <td width=""77%"">Container std::vector is only updated but does not seem to be ever queried. Occurrences: <ul><li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/JSONFactories_HistFactory.cxx#L407"">JSONFactories_HistFactory.cxx:407</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FJSONFactories_HistFactory.cxx/cpp%2Fdc%2FContainerUpdatedButNeverQueried/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. <tr>. <td width=""77%"">Use empty instead of equals comparison of size to check for emptiness of std::string. Occurrences: <ul><li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L549"">RooJSONFactoryWSTool.cxx:549</a></li> <li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L607"">RooJSONFactoryWSTool.cxx:607</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FRooJSONFactoryWSTool.cxx/cpp%2Fdc%2FEmptyInsteadOfSize/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. </tbody>. </table>. #### 👉 View analysis in [**DeepCode",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:513,deployability,updat,updated,513,"## DeepCode's analysis on [#51516a](https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2F/code/?utm_source=gh_review&c=0&w=1&i=1&) found:. - :warning: **1** warning, :information_source: **1** minor issue. :point_down:. ## Top issues. <table>. <thead>. <tr>. <th align=""left"">Description</th>. <th align=""left"">Example fixes</th>. </tr>. </thead>. <tbody>. <tr>. <td width=""77%"">Container std::vector is only updated but does not seem to be ever queried. Occurrences: <ul><li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/JSONFactories_HistFactory.cxx#L407"">JSONFactories_HistFactory.cxx:407</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FJSONFactories_HistFactory.cxx/cpp%2Fdc%2FContainerUpdatedButNeverQueried/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. <tr>. <td width=""77%"">Use empty instead of equals comparison of size to check for emptiness of std::string. Occurrences: <ul><li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L549"">RooJSONFactoryWSTool.cxx:549</a></li> <li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L607"">RooJSONFactoryWSTool.cxx:607</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FRooJSONFactoryWSTool.cxx/cpp%2Fdc%2FEmptyInsteadOfSize/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. </tbody>. </table>. #### 👉 View analysis in [**DeepCode",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:2318,deployability,servic,service,2318,"ofit/hs3/src/JSONFactories_HistFactory.cxx#L407"">JSONFactories_HistFactory.cxx:407</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FJSONFactories_HistFactory.cxx/cpp%2Fdc%2FContainerUpdatedButNeverQueried/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. <tr>. <td width=""77%"">Use empty instead of equals comparison of size to check for emptiness of std::string. Occurrences: <ul><li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L549"">RooJSONFactoryWSTool.cxx:549</a></li> <li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L607"">RooJSONFactoryWSTool.cxx:607</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FRooJSONFactoryWSTool.cxx/cpp%2Fdc%2FEmptyInsteadOfSize/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. </tbody>. </table>. #### 👉 View analysis in [**DeepCode’s Dashboard**](https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2F/code/?utm_source=gh_review&c=0&w=1&i=1&) | [_Configure the bot_](https://www.deepcode.ai/app/gh/?ownerconfig=root-project). #### 👉 The DeepCode service and API will be deprecated in August, 2021. [Here](https://www.deepcode.ai/blog/migrate-to-snyk-code) is the information how to migrate. Thank you for using DeepCode 🙏 ❤️ ! If you are using our plugins, you might be interested in their successors: [Snyk's JetBrains plugin](https://snyk.co/udpkq) and [Snyk's VS Code plugin](https://snyk.co/udpkr).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:2330,deployability,API,API,2330,"ofit/hs3/src/JSONFactories_HistFactory.cxx#L407"">JSONFactories_HistFactory.cxx:407</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FJSONFactories_HistFactory.cxx/cpp%2Fdc%2FContainerUpdatedButNeverQueried/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. <tr>. <td width=""77%"">Use empty instead of equals comparison of size to check for emptiness of std::string. Occurrences: <ul><li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L549"">RooJSONFactoryWSTool.cxx:549</a></li> <li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L607"">RooJSONFactoryWSTool.cxx:607</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FRooJSONFactoryWSTool.cxx/cpp%2Fdc%2FEmptyInsteadOfSize/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. </tbody>. </table>. #### 👉 View analysis in [**DeepCode’s Dashboard**](https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2F/code/?utm_source=gh_review&c=0&w=1&i=1&) | [_Configure the bot_](https://www.deepcode.ai/app/gh/?ownerconfig=root-project). #### 👉 The DeepCode service and API will be deprecated in August, 2021. [Here](https://www.deepcode.ai/blog/migrate-to-snyk-code) is the information how to migrate. Thank you for using DeepCode 🙏 ❤️ ! If you are using our plugins, you might be interested in their successors: [Snyk's JetBrains plugin](https://snyk.co/udpkq) and [Snyk's VS Code plugin](https://snyk.co/udpkr).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:2318,integrability,servic,service,2318,"ofit/hs3/src/JSONFactories_HistFactory.cxx#L407"">JSONFactories_HistFactory.cxx:407</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FJSONFactories_HistFactory.cxx/cpp%2Fdc%2FContainerUpdatedButNeverQueried/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. <tr>. <td width=""77%"">Use empty instead of equals comparison of size to check for emptiness of std::string. Occurrences: <ul><li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L549"">RooJSONFactoryWSTool.cxx:549</a></li> <li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L607"">RooJSONFactoryWSTool.cxx:607</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FRooJSONFactoryWSTool.cxx/cpp%2Fdc%2FEmptyInsteadOfSize/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. </tbody>. </table>. #### 👉 View analysis in [**DeepCode’s Dashboard**](https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2F/code/?utm_source=gh_review&c=0&w=1&i=1&) | [_Configure the bot_](https://www.deepcode.ai/app/gh/?ownerconfig=root-project). #### 👉 The DeepCode service and API will be deprecated in August, 2021. [Here](https://www.deepcode.ai/blog/migrate-to-snyk-code) is the information how to migrate. Thank you for using DeepCode 🙏 ❤️ ! If you are using our plugins, you might be interested in their successors: [Snyk's JetBrains plugin](https://snyk.co/udpkq) and [Snyk's VS Code plugin](https://snyk.co/udpkr).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:2330,integrability,API,API,2330,"ofit/hs3/src/JSONFactories_HistFactory.cxx#L407"">JSONFactories_HistFactory.cxx:407</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FJSONFactories_HistFactory.cxx/cpp%2Fdc%2FContainerUpdatedButNeverQueried/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. <tr>. <td width=""77%"">Use empty instead of equals comparison of size to check for emptiness of std::string. Occurrences: <ul><li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L549"">RooJSONFactoryWSTool.cxx:549</a></li> <li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L607"">RooJSONFactoryWSTool.cxx:607</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FRooJSONFactoryWSTool.cxx/cpp%2Fdc%2FEmptyInsteadOfSize/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. </tbody>. </table>. #### 👉 View analysis in [**DeepCode’s Dashboard**](https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2F/code/?utm_source=gh_review&c=0&w=1&i=1&) | [_Configure the bot_](https://www.deepcode.ai/app/gh/?ownerconfig=root-project). #### 👉 The DeepCode service and API will be deprecated in August, 2021. [Here](https://www.deepcode.ai/blog/migrate-to-snyk-code) is the information how to migrate. Thank you for using DeepCode 🙏 ❤️ ! If you are using our plugins, you might be interested in their successors: [Snyk's JetBrains plugin](https://snyk.co/udpkq) and [Snyk's VS Code plugin](https://snyk.co/udpkr).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:2330,interoperability,API,API,2330,"ofit/hs3/src/JSONFactories_HistFactory.cxx#L407"">JSONFactories_HistFactory.cxx:407</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FJSONFactories_HistFactory.cxx/cpp%2Fdc%2FContainerUpdatedButNeverQueried/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. <tr>. <td width=""77%"">Use empty instead of equals comparison of size to check for emptiness of std::string. Occurrences: <ul><li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L549"">RooJSONFactoryWSTool.cxx:549</a></li> <li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L607"">RooJSONFactoryWSTool.cxx:607</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FRooJSONFactoryWSTool.cxx/cpp%2Fdc%2FEmptyInsteadOfSize/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. </tbody>. </table>. #### 👉 View analysis in [**DeepCode’s Dashboard**](https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2F/code/?utm_source=gh_review&c=0&w=1&i=1&) | [_Configure the bot_](https://www.deepcode.ai/app/gh/?ownerconfig=root-project). #### 👉 The DeepCode service and API will be deprecated in August, 2021. [Here](https://www.deepcode.ai/blog/migrate-to-snyk-code) is the information how to migrate. Thank you for using DeepCode 🙏 ❤️ ! If you are using our plugins, you might be interested in their successors: [Snyk's JetBrains plugin](https://snyk.co/udpkq) and [Snyk's VS Code plugin](https://snyk.co/udpkr).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:2520,interoperability,plug,plugins,2520,"ofit/hs3/src/JSONFactories_HistFactory.cxx#L407"">JSONFactories_HistFactory.cxx:407</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FJSONFactories_HistFactory.cxx/cpp%2Fdc%2FContainerUpdatedButNeverQueried/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. <tr>. <td width=""77%"">Use empty instead of equals comparison of size to check for emptiness of std::string. Occurrences: <ul><li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L549"">RooJSONFactoryWSTool.cxx:549</a></li> <li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L607"">RooJSONFactoryWSTool.cxx:607</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FRooJSONFactoryWSTool.cxx/cpp%2Fdc%2FEmptyInsteadOfSize/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. </tbody>. </table>. #### 👉 View analysis in [**DeepCode’s Dashboard**](https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2F/code/?utm_source=gh_review&c=0&w=1&i=1&) | [_Configure the bot_](https://www.deepcode.ai/app/gh/?ownerconfig=root-project). #### 👉 The DeepCode service and API will be deprecated in August, 2021. [Here](https://www.deepcode.ai/blog/migrate-to-snyk-code) is the information how to migrate. Thank you for using DeepCode 🙏 ❤️ ! If you are using our plugins, you might be interested in their successors: [Snyk's JetBrains plugin](https://snyk.co/udpkq) and [Snyk's VS Code plugin](https://snyk.co/udpkr).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:2592,interoperability,plug,plugin,2592,"ofit/hs3/src/JSONFactories_HistFactory.cxx#L407"">JSONFactories_HistFactory.cxx:407</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FJSONFactories_HistFactory.cxx/cpp%2Fdc%2FContainerUpdatedButNeverQueried/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. <tr>. <td width=""77%"">Use empty instead of equals comparison of size to check for emptiness of std::string. Occurrences: <ul><li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L549"">RooJSONFactoryWSTool.cxx:549</a></li> <li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L607"">RooJSONFactoryWSTool.cxx:607</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FRooJSONFactoryWSTool.cxx/cpp%2Fdc%2FEmptyInsteadOfSize/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. </tbody>. </table>. #### 👉 View analysis in [**DeepCode’s Dashboard**](https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2F/code/?utm_source=gh_review&c=0&w=1&i=1&) | [_Configure the bot_](https://www.deepcode.ai/app/gh/?ownerconfig=root-project). #### 👉 The DeepCode service and API will be deprecated in August, 2021. [Here](https://www.deepcode.ai/blog/migrate-to-snyk-code) is the information how to migrate. Thank you for using DeepCode 🙏 ❤️ ! If you are using our plugins, you might be interested in their successors: [Snyk's JetBrains plugin](https://snyk.co/udpkq) and [Snyk's VS Code plugin](https://snyk.co/udpkr).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:2643,interoperability,plug,plugin,2643,"ofit/hs3/src/JSONFactories_HistFactory.cxx#L407"">JSONFactories_HistFactory.cxx:407</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FJSONFactories_HistFactory.cxx/cpp%2Fdc%2FContainerUpdatedButNeverQueried/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. <tr>. <td width=""77%"">Use empty instead of equals comparison of size to check for emptiness of std::string. Occurrences: <ul><li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L549"">RooJSONFactoryWSTool.cxx:549</a></li> <li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L607"">RooJSONFactoryWSTool.cxx:607</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FRooJSONFactoryWSTool.cxx/cpp%2Fdc%2FEmptyInsteadOfSize/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. </tbody>. </table>. #### 👉 View analysis in [**DeepCode’s Dashboard**](https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2F/code/?utm_source=gh_review&c=0&w=1&i=1&) | [_Configure the bot_](https://www.deepcode.ai/app/gh/?ownerconfig=root-project). #### 👉 The DeepCode service and API will be deprecated in August, 2021. [Here](https://www.deepcode.ai/blog/migrate-to-snyk-code) is the information how to migrate. Thank you for using DeepCode 🙏 ❤️ ! If you are using our plugins, you might be interested in their successors: [Snyk's JetBrains plugin](https://snyk.co/udpkq) and [Snyk's VS Code plugin](https://snyk.co/udpkr).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:2318,modifiability,servic,service,2318,"ofit/hs3/src/JSONFactories_HistFactory.cxx#L407"">JSONFactories_HistFactory.cxx:407</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FJSONFactories_HistFactory.cxx/cpp%2Fdc%2FContainerUpdatedButNeverQueried/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. <tr>. <td width=""77%"">Use empty instead of equals comparison of size to check for emptiness of std::string. Occurrences: <ul><li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L549"">RooJSONFactoryWSTool.cxx:549</a></li> <li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L607"">RooJSONFactoryWSTool.cxx:607</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FRooJSONFactoryWSTool.cxx/cpp%2Fdc%2FEmptyInsteadOfSize/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. </tbody>. </table>. #### 👉 View analysis in [**DeepCode’s Dashboard**](https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2F/code/?utm_source=gh_review&c=0&w=1&i=1&) | [_Configure the bot_](https://www.deepcode.ai/app/gh/?ownerconfig=root-project). #### 👉 The DeepCode service and API will be deprecated in August, 2021. [Here](https://www.deepcode.ai/blog/migrate-to-snyk-code) is the information how to migrate. Thank you for using DeepCode 🙏 ❤️ ! If you are using our plugins, you might be interested in their successors: [Snyk's JetBrains plugin](https://snyk.co/udpkq) and [Snyk's VS Code plugin](https://snyk.co/udpkr).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:525,reliability,doe,does,525,"## DeepCode's analysis on [#51516a](https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2F/code/?utm_source=gh_review&c=0&w=1&i=1&) found:. - :warning: **1** warning, :information_source: **1** minor issue. :point_down:. ## Top issues. <table>. <thead>. <tr>. <th align=""left"">Description</th>. <th align=""left"">Example fixes</th>. </tr>. </thead>. <tbody>. <tr>. <td width=""77%"">Container std::vector is only updated but does not seem to be ever queried. Occurrences: <ul><li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/JSONFactories_HistFactory.cxx#L407"">JSONFactories_HistFactory.cxx:407</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FJSONFactories_HistFactory.cxx/cpp%2Fdc%2FContainerUpdatedButNeverQueried/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. <tr>. <td width=""77%"">Use empty instead of equals comparison of size to check for emptiness of std::string. Occurrences: <ul><li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L549"">RooJSONFactoryWSTool.cxx:549</a></li> <li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L607"">RooJSONFactoryWSTool.cxx:607</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FRooJSONFactoryWSTool.cxx/cpp%2Fdc%2FEmptyInsteadOfSize/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. </tbody>. </table>. #### 👉 View analysis in [**DeepCode",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:513,safety,updat,updated,513,"## DeepCode's analysis on [#51516a](https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2F/code/?utm_source=gh_review&c=0&w=1&i=1&) found:. - :warning: **1** warning, :information_source: **1** minor issue. :point_down:. ## Top issues. <table>. <thead>. <tr>. <th align=""left"">Description</th>. <th align=""left"">Example fixes</th>. </tr>. </thead>. <tbody>. <tr>. <td width=""77%"">Container std::vector is only updated but does not seem to be ever queried. Occurrences: <ul><li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/JSONFactories_HistFactory.cxx#L407"">JSONFactories_HistFactory.cxx:407</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FJSONFactories_HistFactory.cxx/cpp%2Fdc%2FContainerUpdatedButNeverQueried/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. <tr>. <td width=""77%"">Use empty instead of equals comparison of size to check for emptiness of std::string. Occurrences: <ul><li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L549"">RooJSONFactoryWSTool.cxx:549</a></li> <li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L607"">RooJSONFactoryWSTool.cxx:607</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FRooJSONFactoryWSTool.cxx/cpp%2Fdc%2FEmptyInsteadOfSize/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. </tbody>. </table>. #### 👉 View analysis in [**DeepCode",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:513,security,updat,updated,513,"## DeepCode's analysis on [#51516a](https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2F/code/?utm_source=gh_review&c=0&w=1&i=1&) found:. - :warning: **1** warning, :information_source: **1** minor issue. :point_down:. ## Top issues. <table>. <thead>. <tr>. <th align=""left"">Description</th>. <th align=""left"">Example fixes</th>. </tr>. </thead>. <tbody>. <tr>. <td width=""77%"">Container std::vector is only updated but does not seem to be ever queried. Occurrences: <ul><li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/JSONFactories_HistFactory.cxx#L407"">JSONFactories_HistFactory.cxx:407</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FJSONFactories_HistFactory.cxx/cpp%2Fdc%2FContainerUpdatedButNeverQueried/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. <tr>. <td width=""77%"">Use empty instead of equals comparison of size to check for emptiness of std::string. Occurrences: <ul><li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L549"">RooJSONFactoryWSTool.cxx:549</a></li> <li><a href=""https://github.com/root-project/root/blob/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/roofit/hs3/src/RooJSONFactoryWSTool.cxx#L607"">RooJSONFactoryWSTool.cxx:607</a></li></ul></td>. <td width=""23%""><a href=""https://www.deepcode.ai/app/gh/root-project/root/24ea49d4702ba0aa9b1ea5521950520154ee151c/root-project/root/51516ae7e1ec80b8b4056ea39ffc08ce6e571266/pr/_/%2Froofit%2Fhs3%2Fsrc%2FRooJSONFactoryWSTool.cxx/cpp%2Fdc%2FEmptyInsteadOfSize/code/?utm_source=gh_review&"">:wrench: Example fixes</a></td>. </tr>. </tbody>. </table>. #### 👉 View analysis in [**DeepCode",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:34,availability,ping,ping,34,Hi everyone! this is just a quick ping on whether there is any progress in the review of this PR?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:79,safety,review,review,79,Hi everyone! this is just a quick ping on whether there is any progress in the review of this PR?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:79,testability,review,review,79,Hi everyone! this is just a quick ping on whether there is any progress in the review of this PR?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:63,usability,progress,progress,63,Hi everyone! this is just a quick ping on whether there is any progress in the review of this PR?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:259,deployability,updat,update,259,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1753,deployability,releas,release,1753,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1812,deployability,Releas,ReleaseNotes,1812,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1896,deployability,Releas,ReleaseNotes,1896,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:238,energy efficiency,current,current,238,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:322,energy efficiency,current,current,322,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1133,energy efficiency,model,model,1133,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1164,energy efficiency,model,model,1164,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1017,integrability,translat,translation,1017,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:536,interoperability,format,formatted,536,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:574,interoperability,format,format,574,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:644,interoperability,format,format,644,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:714,interoperability,format,format,714,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1017,interoperability,translat,translation,1017,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1562,interoperability,bind,bindings,1562,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:694,modifiability,pac,package,694,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1562,modifiability,bind,bindings,1562,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:259,safety,updat,update,259,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:433,safety,test,tests,433,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1082,safety,test,tests,1082,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1115,safety,test,test,1115,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1177,safety,test,tests,1177,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1208,safety,test,tests,1208,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1244,safety,test,test,1244,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1318,safety,test,test,1318,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1353,safety,test,tests,1353,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1407,safety,test,test,1407,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1506,safety,test,tests,1506,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1593,safety,test,test,1593,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1665,safety,test,tests,1665,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:259,security,updat,update,259,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1133,security,model,model,1133,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1164,security,model,model,1164,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:433,testability,test,tests,433,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1077,testability,unit,unit,1077,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1082,testability,test,tests,1082,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1115,testability,test,test,1115,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1177,testability,test,tests,1177,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1208,testability,test,tests,1208,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1244,testability,test,test,1244,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1318,testability,test,test,1318,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1353,testability,test,tests,1353,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1407,testability,test,test,1407,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1501,testability,unit,unit,1501,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1506,testability,test,tests,1506,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1593,testability,test,test,1593,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1665,testability,test,tests,1665,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:985,usability,prefer,prefer,985,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:1632,usability,help,help,1632,"Hi @cburgard, thanks for the reminder! There are a few things that need to be done here:. 1. We can't merge non-fast forward branches (like branches where you merged `master` in between). Please rebase all your developments on top of the current `master` and update this PR. If can be done in a single commit, because the current commit history of your developments is not so informative anyway :) Once this is done, the CI can also tests the PR (the CI also has problems with non fast-forward branches). 2. We try to have new C++ code formatted nicely with the [ROOT clang-format style](https://github.com/root-project/root/blob/master/.clang-format) can you please iron over new `roofit/hs3` package with `clang-format`, using the linked style file? 3. Please add a tutorial for the JSON/YML import/export (or more than one if you want) to the [tutorials/roofit](https://github.com/root-project/root/tree/master/tutorials/roofit) directory. It can be in either C++ or Python, as you prefer. We can take care of the translation later. 4. It would be good to have at least two unit tests: one export/import closure test for a binned model, and one for an unbinned model. These tests should be in `roofit/hs3/tests` (compare [`roofit/roofitcore/test`](https://github.com/root-project/root/tree/master/roofit/roofitcore/test) directory structure). If the tests are written in Python, you can add them to the `test/CmakeLists.txt` with the `ROOT_ADD_PYUNITTEST` macro (see for example the [pythonization unit tests](https://github.com/root-project/root/blob/master/bindings/pyroot/pythonizations/test/CMakeLists.txt)). If you need any help on how to write and run the tests don't hesitate to ask! 5. You should also advertise these new developments in the release notes (edit the RooFitLibraries section in [README/ReleaseNotes/v626/index.md](https://github.com/root-project/root/blob/master/README/ReleaseNotes/v626/index.md))",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:177,safety,test,testes,177,"Hi @cburgard, can you please fix the commit history in this PR by doing a fresh rebase of your commit onto master? LIke this, we can't merge the PR and I think it also can't be testes by the CI (I will try thought).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:177,testability,test,testes,177,"Hi @cburgard, can you please fix the commit history in this PR by doing a fresh rebase of your commit onto master? LIke this, we can't merge the PR and I think it also can't be testes by the CI (I will try thought).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/pull/8944:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8944
https://github.com/root-project/root/issues/8946:66,availability,error,error,66,"Hi, I have just tested this with 6.24.06 version and it seems the error has disappeared.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8946
https://github.com/root-project/root/issues/8946:41,deployability,version,version,41,"Hi, I have just tested this with 6.24.06 version and it seems the error has disappeared.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8946
https://github.com/root-project/root/issues/8946:41,integrability,version,version,41,"Hi, I have just tested this with 6.24.06 version and it seems the error has disappeared.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8946
https://github.com/root-project/root/issues/8946:41,modifiability,version,version,41,"Hi, I have just tested this with 6.24.06 version and it seems the error has disappeared.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8946
https://github.com/root-project/root/issues/8946:66,performance,error,error,66,"Hi, I have just tested this with 6.24.06 version and it seems the error has disappeared.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8946
https://github.com/root-project/root/issues/8946:16,safety,test,tested,16,"Hi, I have just tested this with 6.24.06 version and it seems the error has disappeared.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8946
https://github.com/root-project/root/issues/8946:66,safety,error,error,66,"Hi, I have just tested this with 6.24.06 version and it seems the error has disappeared.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8946
https://github.com/root-project/root/issues/8946:16,testability,test,tested,16,"Hi, I have just tested this with 6.24.06 version and it seems the error has disappeared.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8946
https://github.com/root-project/root/issues/8946:66,usability,error,error,66,"Hi, I have just tested this with 6.24.06 version and it seems the error has disappeared.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8946
https://github.com/root-project/root/issues/8947:339,availability,Error,Error,339,Side note: calling make clean does not clean the directory in case the build failed. I get:. ```. rm -r rootdoc filter htmlfooter.html dataset* ../../bindings/pyroot/pythonizations/python/ROOT/pythonization/*.pyzdoc. rm: cannot remove 'dataset*': No such file or directory. Makefile:56: recipe for target 'clean' failed. make: *** [clean] Error 1. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8947
https://github.com/root-project/root/issues/8947:71,deployability,build,build,71,Side note: calling make clean does not clean the directory in case the build failed. I get:. ```. rm -r rootdoc filter htmlfooter.html dataset* ../../bindings/pyroot/pythonizations/python/ROOT/pythonization/*.pyzdoc. rm: cannot remove 'dataset*': No such file or directory. Makefile:56: recipe for target 'clean' failed. make: *** [clean] Error 1. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8947
https://github.com/root-project/root/issues/8947:77,deployability,fail,failed,77,Side note: calling make clean does not clean the directory in case the build failed. I get:. ```. rm -r rootdoc filter htmlfooter.html dataset* ../../bindings/pyroot/pythonizations/python/ROOT/pythonization/*.pyzdoc. rm: cannot remove 'dataset*': No such file or directory. Makefile:56: recipe for target 'clean' failed. make: *** [clean] Error 1. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8947
https://github.com/root-project/root/issues/8947:313,deployability,fail,failed,313,Side note: calling make clean does not clean the directory in case the build failed. I get:. ```. rm -r rootdoc filter htmlfooter.html dataset* ../../bindings/pyroot/pythonizations/python/ROOT/pythonization/*.pyzdoc. rm: cannot remove 'dataset*': No such file or directory. Makefile:56: recipe for target 'clean' failed. make: *** [clean] Error 1. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8947
https://github.com/root-project/root/issues/8947:112,integrability,filter,filter,112,Side note: calling make clean does not clean the directory in case the build failed. I get:. ```. rm -r rootdoc filter htmlfooter.html dataset* ../../bindings/pyroot/pythonizations/python/ROOT/pythonization/*.pyzdoc. rm: cannot remove 'dataset*': No such file or directory. Makefile:56: recipe for target 'clean' failed. make: *** [clean] Error 1. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8947
https://github.com/root-project/root/issues/8947:150,interoperability,bind,bindings,150,Side note: calling make clean does not clean the directory in case the build failed. I get:. ```. rm -r rootdoc filter htmlfooter.html dataset* ../../bindings/pyroot/pythonizations/python/ROOT/pythonization/*.pyzdoc. rm: cannot remove 'dataset*': No such file or directory. Makefile:56: recipe for target 'clean' failed. make: *** [clean] Error 1. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8947
https://github.com/root-project/root/issues/8947:150,modifiability,bind,bindings,150,Side note: calling make clean does not clean the directory in case the build failed. I get:. ```. rm -r rootdoc filter htmlfooter.html dataset* ../../bindings/pyroot/pythonizations/python/ROOT/pythonization/*.pyzdoc. rm: cannot remove 'dataset*': No such file or directory. Makefile:56: recipe for target 'clean' failed. make: *** [clean] Error 1. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8947
https://github.com/root-project/root/issues/8947:339,performance,Error,Error,339,Side note: calling make clean does not clean the directory in case the build failed. I get:. ```. rm -r rootdoc filter htmlfooter.html dataset* ../../bindings/pyroot/pythonizations/python/ROOT/pythonization/*.pyzdoc. rm: cannot remove 'dataset*': No such file or directory. Makefile:56: recipe for target 'clean' failed. make: *** [clean] Error 1. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8947
https://github.com/root-project/root/issues/8947:30,reliability,doe,does,30,Side note: calling make clean does not clean the directory in case the build failed. I get:. ```. rm -r rootdoc filter htmlfooter.html dataset* ../../bindings/pyroot/pythonizations/python/ROOT/pythonization/*.pyzdoc. rm: cannot remove 'dataset*': No such file or directory. Makefile:56: recipe for target 'clean' failed. make: *** [clean] Error 1. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8947
https://github.com/root-project/root/issues/8947:77,reliability,fail,failed,77,Side note: calling make clean does not clean the directory in case the build failed. I get:. ```. rm -r rootdoc filter htmlfooter.html dataset* ../../bindings/pyroot/pythonizations/python/ROOT/pythonization/*.pyzdoc. rm: cannot remove 'dataset*': No such file or directory. Makefile:56: recipe for target 'clean' failed. make: *** [clean] Error 1. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8947
https://github.com/root-project/root/issues/8947:313,reliability,fail,failed,313,Side note: calling make clean does not clean the directory in case the build failed. I get:. ```. rm -r rootdoc filter htmlfooter.html dataset* ../../bindings/pyroot/pythonizations/python/ROOT/pythonization/*.pyzdoc. rm: cannot remove 'dataset*': No such file or directory. Makefile:56: recipe for target 'clean' failed. make: *** [clean] Error 1. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8947
https://github.com/root-project/root/issues/8947:339,safety,Error,Error,339,Side note: calling make clean does not clean the directory in case the build failed. I get:. ```. rm -r rootdoc filter htmlfooter.html dataset* ../../bindings/pyroot/pythonizations/python/ROOT/pythonization/*.pyzdoc. rm: cannot remove 'dataset*': No such file or directory. Makefile:56: recipe for target 'clean' failed. make: *** [clean] Error 1. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8947
https://github.com/root-project/root/issues/8947:339,usability,Error,Error,339,Side note: calling make clean does not clean the directory in case the build failed. I get:. ```. rm -r rootdoc filter htmlfooter.html dataset* ../../bindings/pyroot/pythonizations/python/ROOT/pythonization/*.pyzdoc. rm: cannot remove 'dataset*': No such file or directory. Makefile:56: recipe for target 'clean' failed. make: *** [clean] Error 1. ```,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8947
https://github.com/root-project/root/issues/8947:153,availability,Monitor,Monitoring,153,"Here a good example on how ALICE's experiment generates the documentation directly in the build directory, using CMake:. https://github.com/AliceO2Group/Monitoring/blob/dev/doc/CMakeLists.txt#L22",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8947
https://github.com/root-project/root/issues/8947:90,deployability,build,build,90,"Here a good example on how ALICE's experiment generates the documentation directly in the build directory, using CMake:. https://github.com/AliceO2Group/Monitoring/blob/dev/doc/CMakeLists.txt#L22",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8947
https://github.com/root-project/root/issues/8947:153,deployability,Monitor,Monitoring,153,"Here a good example on how ALICE's experiment generates the documentation directly in the build directory, using CMake:. https://github.com/AliceO2Group/Monitoring/blob/dev/doc/CMakeLists.txt#L22",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8947
https://github.com/root-project/root/issues/8947:153,energy efficiency,Monitor,Monitoring,153,"Here a good example on how ALICE's experiment generates the documentation directly in the build directory, using CMake:. https://github.com/AliceO2Group/Monitoring/blob/dev/doc/CMakeLists.txt#L22",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8947
https://github.com/root-project/root/issues/8947:153,reliability,Monitor,Monitoring,153,"Here a good example on how ALICE's experiment generates the documentation directly in the build directory, using CMake:. https://github.com/AliceO2Group/Monitoring/blob/dev/doc/CMakeLists.txt#L22",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8947
https://github.com/root-project/root/issues/8947:153,safety,Monitor,Monitoring,153,"Here a good example on how ALICE's experiment generates the documentation directly in the build directory, using CMake:. https://github.com/AliceO2Group/Monitoring/blob/dev/doc/CMakeLists.txt#L22",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8947
https://github.com/root-project/root/issues/8947:153,testability,Monitor,Monitoring,153,"Here a good example on how ALICE's experiment generates the documentation directly in the build directory, using CMake:. https://github.com/AliceO2Group/Monitoring/blob/dev/doc/CMakeLists.txt#L22",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8947
https://github.com/root-project/root/issues/8947:60,usability,document,documentation,60,"Here a good example on how ALICE's experiment generates the documentation directly in the build directory, using CMake:. https://github.com/AliceO2Group/Monitoring/blob/dev/doc/CMakeLists.txt#L22",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8947
https://github.com/root-project/root/issues/8950:77,security,team,team,77,@ferdymercury : that's a good point. That will have to be discussed with the team and in particular wit @bellenot who is responsible of came in root. It is quite a big change seems to me.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:56,deployability,build,build,56,Recent changes in the way the list of directories to be build might obsolete this issue. The documentation build is not part of the cmake procedure. It has its own Makefile. Now the list of directories is build via script. The page . https://root.cern/for_developers/doxygen/#how-to-generate-the-doxygen-documentation. has been. updated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:107,deployability,build,build,107,Recent changes in the way the list of directories to be build might obsolete this issue. The documentation build is not part of the cmake procedure. It has its own Makefile. Now the list of directories is build via script. The page . https://root.cern/for_developers/doxygen/#how-to-generate-the-doxygen-documentation. has been. updated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:205,deployability,build,build,205,Recent changes in the way the list of directories to be build might obsolete this issue. The documentation build is not part of the cmake procedure. It has its own Makefile. Now the list of directories is build via script. The page . https://root.cern/for_developers/doxygen/#how-to-generate-the-doxygen-documentation. has been. updated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:329,deployability,updat,updated,329,Recent changes in the way the list of directories to be build might obsolete this issue. The documentation build is not part of the cmake procedure. It has its own Makefile. Now the list of directories is build via script. The page . https://root.cern/for_developers/doxygen/#how-to-generate-the-doxygen-documentation. has been. updated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:329,safety,updat,updated,329,Recent changes in the way the list of directories to be build might obsolete this issue. The documentation build is not part of the cmake procedure. It has its own Makefile. Now the list of directories is build via script. The page . https://root.cern/for_developers/doxygen/#how-to-generate-the-doxygen-documentation. has been. updated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:329,security,updat,updated,329,Recent changes in the way the list of directories to be build might obsolete this issue. The documentation build is not part of the cmake procedure. It has its own Makefile. Now the list of directories is build via script. The page . https://root.cern/for_developers/doxygen/#how-to-generate-the-doxygen-documentation. has been. updated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:93,usability,document,documentation,93,Recent changes in the way the list of directories to be build might obsolete this issue. The documentation build is not part of the cmake procedure. It has its own Makefile. Now the list of directories is build via script. The page . https://root.cern/for_developers/doxygen/#how-to-generate-the-doxygen-documentation. has been. updated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:304,usability,document,documentation,304,Recent changes in the way the list of directories to be build might obsolete this issue. The documentation build is not part of the cmake procedure. It has its own Makefile. Now the list of directories is build via script. The page . https://root.cern/for_developers/doxygen/#how-to-generate-the-doxygen-documentation. has been. updated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:209,deployability,build,build,209,"Thanks for the feedback. Just as a suggestion, I think it would still be possible to migrate from that Makefile to a CMakeLists.txt. That way, one could configure via the command line what part of the docs to build, instead of having to modify the makeinput.sh script, which in turn modifies the git source directory, which brings us back to https://github.com/root-project/root/issues/8947",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:153,integrability,configur,configure,153,"Thanks for the feedback. Just as a suggestion, I think it would still be possible to migrate from that Makefile to a CMakeLists.txt. That way, one could configure via the command line what part of the docs to build, instead of having to modify the makeinput.sh script, which in turn modifies the git source directory, which brings us back to https://github.com/root-project/root/issues/8947",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:153,modifiability,configur,configure,153,"Thanks for the feedback. Just as a suggestion, I think it would still be possible to migrate from that Makefile to a CMakeLists.txt. That way, one could configure via the command line what part of the docs to build, instead of having to modify the makeinput.sh script, which in turn modifies the git source directory, which brings us back to https://github.com/root-project/root/issues/8947",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:153,security,configur,configure,153,"Thanks for the feedback. Just as a suggestion, I think it would still be possible to migrate from that Makefile to a CMakeLists.txt. That way, one could configure via the command line what part of the docs to build, instead of having to modify the makeinput.sh script, which in turn modifies the git source directory, which brings us back to https://github.com/root-project/root/issues/8947",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:237,security,modif,modify,237,"Thanks for the feedback. Just as a suggestion, I think it would still be possible to migrate from that Makefile to a CMakeLists.txt. That way, one could configure via the command line what part of the docs to build, instead of having to modify the makeinput.sh script, which in turn modifies the git source directory, which brings us back to https://github.com/root-project/root/issues/8947",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:283,security,modif,modifies,283,"Thanks for the feedback. Just as a suggestion, I think it would still be possible to migrate from that Makefile to a CMakeLists.txt. That way, one could configure via the command line what part of the docs to build, instead of having to modify the makeinput.sh script, which in turn modifies the git source directory, which brings us back to https://github.com/root-project/root/issues/8947",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:15,usability,feedback,feedback,15,"Thanks for the feedback. Just as a suggestion, I think it would still be possible to migrate from that Makefile to a CMakeLists.txt. That way, one could configure via the command line what part of the docs to build, instead of having to modify the makeinput.sh script, which in turn modifies the git source directory, which brings us back to https://github.com/root-project/root/issues/8947",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:171,usability,command,command,171,"Thanks for the feedback. Just as a suggestion, I think it would still be possible to migrate from that Makefile to a CMakeLists.txt. That way, one could configure via the command line what part of the docs to build, instead of having to modify the makeinput.sh script, which in turn modifies the git source directory, which brings us back to https://github.com/root-project/root/issues/8947",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:96,deployability,build,build,96,I am now looking at #8947. I am modifying the `Makefile` to left a clean source directory after build. `makeinput.sh` should be modified only temporarily by developers to make only part of the doc in order to speed the build when working on a specific part of the reference guide. This script is not only a static list. At the end is added the pieces of doc build by `xtract_docstrings.py`. and `print_roofit_pyz_doctrings.py`. But it is true that if one modifies (even temporarily) `makeinput.sh` then it will appears in `git status`. I am not should how a `cmake` approach will fix that.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:219,deployability,build,build,219,I am now looking at #8947. I am modifying the `Makefile` to left a clean source directory after build. `makeinput.sh` should be modified only temporarily by developers to make only part of the doc in order to speed the build when working on a specific part of the reference guide. This script is not only a static list. At the end is added the pieces of doc build by `xtract_docstrings.py`. and `print_roofit_pyz_doctrings.py`. But it is true that if one modifies (even temporarily) `makeinput.sh` then it will appears in `git status`. I am not should how a `cmake` approach will fix that.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:358,deployability,build,build,358,I am now looking at #8947. I am modifying the `Makefile` to left a clean source directory after build. `makeinput.sh` should be modified only temporarily by developers to make only part of the doc in order to speed the build when working on a specific part of the reference guide. This script is not only a static list. At the end is added the pieces of doc build by `xtract_docstrings.py`. and `print_roofit_pyz_doctrings.py`. But it is true that if one modifies (even temporarily) `makeinput.sh` then it will appears in `git status`. I am not should how a `cmake` approach will fix that.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:243,interoperability,specif,specific,243,I am now looking at #8947. I am modifying the `Makefile` to left a clean source directory after build. `makeinput.sh` should be modified only temporarily by developers to make only part of the doc in order to speed the build when working on a specific part of the reference guide. This script is not only a static list. At the end is added the pieces of doc build by `xtract_docstrings.py`. and `print_roofit_pyz_doctrings.py`. But it is true that if one modifies (even temporarily) `makeinput.sh` then it will appears in `git status`. I am not should how a `cmake` approach will fix that.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:32,security,modif,modifying,32,I am now looking at #8947. I am modifying the `Makefile` to left a clean source directory after build. `makeinput.sh` should be modified only temporarily by developers to make only part of the doc in order to speed the build when working on a specific part of the reference guide. This script is not only a static list. At the end is added the pieces of doc build by `xtract_docstrings.py`. and `print_roofit_pyz_doctrings.py`. But it is true that if one modifies (even temporarily) `makeinput.sh` then it will appears in `git status`. I am not should how a `cmake` approach will fix that.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:128,security,modif,modified,128,I am now looking at #8947. I am modifying the `Makefile` to left a clean source directory after build. `makeinput.sh` should be modified only temporarily by developers to make only part of the doc in order to speed the build when working on a specific part of the reference guide. This script is not only a static list. At the end is added the pieces of doc build by `xtract_docstrings.py`. and `print_roofit_pyz_doctrings.py`. But it is true that if one modifies (even temporarily) `makeinput.sh` then it will appears in `git status`. I am not should how a `cmake` approach will fix that.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:455,security,modif,modifies,455,I am now looking at #8947. I am modifying the `Makefile` to left a clean source directory after build. `makeinput.sh` should be modified only temporarily by developers to make only part of the doc in order to speed the build when working on a specific part of the reference guide. This script is not only a static list. At the end is added the pieces of doc build by `xtract_docstrings.py`. and `print_roofit_pyz_doctrings.py`. But it is true that if one modifies (even temporarily) `makeinput.sh` then it will appears in `git status`. I am not should how a `cmake` approach will fix that.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:274,usability,guid,guide,274,I am now looking at #8947. I am modifying the `Makefile` to left a clean source directory after build. `makeinput.sh` should be modified only temporarily by developers to make only part of the doc in order to speed the build when working on a specific part of the reference guide. This script is not only a static list. At the end is added the pieces of doc build by `xtract_docstrings.py`. and `print_roofit_pyz_doctrings.py`. But it is true that if one modifies (even temporarily) `makeinput.sh` then it will appears in `git status`. I am not should how a `cmake` approach will fix that.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:527,usability,statu,status,527,I am now looking at #8947. I am modifying the `Makefile` to left a clean source directory after build. `makeinput.sh` should be modified only temporarily by developers to make only part of the doc in order to speed the build when working on a specific part of the reference guide. This script is not only a static list. At the end is added the pieces of doc build by `xtract_docstrings.py`. and `print_roofit_pyz_doctrings.py`. But it is true that if one modifies (even temporarily) `makeinput.sh` then it will appears in `git status`. I am not should how a `cmake` approach will fix that.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:508,availability,Monitor,Monitoring,508,"Thanks. What I am suggesting is something like:. ```. ./configure --enable-th1 --enable-th2. make. ```. which lets you tune without modifying the source dir. EnableTH1 would activate the build of a specific dir behind the scenes. Or the alternative with cmake, which would be:. ```. cmake -DENABLE_TH1 -DENABLE_TH2. make. ```. With cmake it would be a bit cleaner, as there is the function doxygen_add_docs() which already does what makeinput.sh is doing manually. See Alice: https://github.com/AliceO2Group/Monitoring/blob/dev/doc/CMakeLists.txt#L22. But with ./configure it should probably be doable too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:187,deployability,build,build,187,"Thanks. What I am suggesting is something like:. ```. ./configure --enable-th1 --enable-th2. make. ```. which lets you tune without modifying the source dir. EnableTH1 would activate the build of a specific dir behind the scenes. Or the alternative with cmake, which would be:. ```. cmake -DENABLE_TH1 -DENABLE_TH2. make. ```. With cmake it would be a bit cleaner, as there is the function doxygen_add_docs() which already does what makeinput.sh is doing manually. See Alice: https://github.com/AliceO2Group/Monitoring/blob/dev/doc/CMakeLists.txt#L22. But with ./configure it should probably be doable too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:508,deployability,Monitor,Monitoring,508,"Thanks. What I am suggesting is something like:. ```. ./configure --enable-th1 --enable-th2. make. ```. which lets you tune without modifying the source dir. EnableTH1 would activate the build of a specific dir behind the scenes. Or the alternative with cmake, which would be:. ```. cmake -DENABLE_TH1 -DENABLE_TH2. make. ```. With cmake it would be a bit cleaner, as there is the function doxygen_add_docs() which already does what makeinput.sh is doing manually. See Alice: https://github.com/AliceO2Group/Monitoring/blob/dev/doc/CMakeLists.txt#L22. But with ./configure it should probably be doable too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:508,energy efficiency,Monitor,Monitoring,508,"Thanks. What I am suggesting is something like:. ```. ./configure --enable-th1 --enable-th2. make. ```. which lets you tune without modifying the source dir. EnableTH1 would activate the build of a specific dir behind the scenes. Or the alternative with cmake, which would be:. ```. cmake -DENABLE_TH1 -DENABLE_TH2. make. ```. With cmake it would be a bit cleaner, as there is the function doxygen_add_docs() which already does what makeinput.sh is doing manually. See Alice: https://github.com/AliceO2Group/Monitoring/blob/dev/doc/CMakeLists.txt#L22. But with ./configure it should probably be doable too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:56,integrability,configur,configure,56,"Thanks. What I am suggesting is something like:. ```. ./configure --enable-th1 --enable-th2. make. ```. which lets you tune without modifying the source dir. EnableTH1 would activate the build of a specific dir behind the scenes. Or the alternative with cmake, which would be:. ```. cmake -DENABLE_TH1 -DENABLE_TH2. make. ```. With cmake it would be a bit cleaner, as there is the function doxygen_add_docs() which already does what makeinput.sh is doing manually. See Alice: https://github.com/AliceO2Group/Monitoring/blob/dev/doc/CMakeLists.txt#L22. But with ./configure it should probably be doable too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:563,integrability,configur,configure,563,"Thanks. What I am suggesting is something like:. ```. ./configure --enable-th1 --enable-th2. make. ```. which lets you tune without modifying the source dir. EnableTH1 would activate the build of a specific dir behind the scenes. Or the alternative with cmake, which would be:. ```. cmake -DENABLE_TH1 -DENABLE_TH2. make. ```. With cmake it would be a bit cleaner, as there is the function doxygen_add_docs() which already does what makeinput.sh is doing manually. See Alice: https://github.com/AliceO2Group/Monitoring/blob/dev/doc/CMakeLists.txt#L22. But with ./configure it should probably be doable too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:198,interoperability,specif,specific,198,"Thanks. What I am suggesting is something like:. ```. ./configure --enable-th1 --enable-th2. make. ```. which lets you tune without modifying the source dir. EnableTH1 would activate the build of a specific dir behind the scenes. Or the alternative with cmake, which would be:. ```. cmake -DENABLE_TH1 -DENABLE_TH2. make. ```. With cmake it would be a bit cleaner, as there is the function doxygen_add_docs() which already does what makeinput.sh is doing manually. See Alice: https://github.com/AliceO2Group/Monitoring/blob/dev/doc/CMakeLists.txt#L22. But with ./configure it should probably be doable too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:56,modifiability,configur,configure,56,"Thanks. What I am suggesting is something like:. ```. ./configure --enable-th1 --enable-th2. make. ```. which lets you tune without modifying the source dir. EnableTH1 would activate the build of a specific dir behind the scenes. Or the alternative with cmake, which would be:. ```. cmake -DENABLE_TH1 -DENABLE_TH2. make. ```. With cmake it would be a bit cleaner, as there is the function doxygen_add_docs() which already does what makeinput.sh is doing manually. See Alice: https://github.com/AliceO2Group/Monitoring/blob/dev/doc/CMakeLists.txt#L22. But with ./configure it should probably be doable too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:563,modifiability,configur,configure,563,"Thanks. What I am suggesting is something like:. ```. ./configure --enable-th1 --enable-th2. make. ```. which lets you tune without modifying the source dir. EnableTH1 would activate the build of a specific dir behind the scenes. Or the alternative with cmake, which would be:. ```. cmake -DENABLE_TH1 -DENABLE_TH2. make. ```. With cmake it would be a bit cleaner, as there is the function doxygen_add_docs() which already does what makeinput.sh is doing manually. See Alice: https://github.com/AliceO2Group/Monitoring/blob/dev/doc/CMakeLists.txt#L22. But with ./configure it should probably be doable too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:119,performance,tune,tune,119,"Thanks. What I am suggesting is something like:. ```. ./configure --enable-th1 --enable-th2. make. ```. which lets you tune without modifying the source dir. EnableTH1 would activate the build of a specific dir behind the scenes. Or the alternative with cmake, which would be:. ```. cmake -DENABLE_TH1 -DENABLE_TH2. make. ```. With cmake it would be a bit cleaner, as there is the function doxygen_add_docs() which already does what makeinput.sh is doing manually. See Alice: https://github.com/AliceO2Group/Monitoring/blob/dev/doc/CMakeLists.txt#L22. But with ./configure it should probably be doable too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:423,reliability,doe,does,423,"Thanks. What I am suggesting is something like:. ```. ./configure --enable-th1 --enable-th2. make. ```. which lets you tune without modifying the source dir. EnableTH1 would activate the build of a specific dir behind the scenes. Or the alternative with cmake, which would be:. ```. cmake -DENABLE_TH1 -DENABLE_TH2. make. ```. With cmake it would be a bit cleaner, as there is the function doxygen_add_docs() which already does what makeinput.sh is doing manually. See Alice: https://github.com/AliceO2Group/Monitoring/blob/dev/doc/CMakeLists.txt#L22. But with ./configure it should probably be doable too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:508,reliability,Monitor,Monitoring,508,"Thanks. What I am suggesting is something like:. ```. ./configure --enable-th1 --enable-th2. make. ```. which lets you tune without modifying the source dir. EnableTH1 would activate the build of a specific dir behind the scenes. Or the alternative with cmake, which would be:. ```. cmake -DENABLE_TH1 -DENABLE_TH2. make. ```. With cmake it would be a bit cleaner, as there is the function doxygen_add_docs() which already does what makeinput.sh is doing manually. See Alice: https://github.com/AliceO2Group/Monitoring/blob/dev/doc/CMakeLists.txt#L22. But with ./configure it should probably be doable too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:508,safety,Monitor,Monitoring,508,"Thanks. What I am suggesting is something like:. ```. ./configure --enable-th1 --enable-th2. make. ```. which lets you tune without modifying the source dir. EnableTH1 would activate the build of a specific dir behind the scenes. Or the alternative with cmake, which would be:. ```. cmake -DENABLE_TH1 -DENABLE_TH2. make. ```. With cmake it would be a bit cleaner, as there is the function doxygen_add_docs() which already does what makeinput.sh is doing manually. See Alice: https://github.com/AliceO2Group/Monitoring/blob/dev/doc/CMakeLists.txt#L22. But with ./configure it should probably be doable too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:56,security,configur,configure,56,"Thanks. What I am suggesting is something like:. ```. ./configure --enable-th1 --enable-th2. make. ```. which lets you tune without modifying the source dir. EnableTH1 would activate the build of a specific dir behind the scenes. Or the alternative with cmake, which would be:. ```. cmake -DENABLE_TH1 -DENABLE_TH2. make. ```. With cmake it would be a bit cleaner, as there is the function doxygen_add_docs() which already does what makeinput.sh is doing manually. See Alice: https://github.com/AliceO2Group/Monitoring/blob/dev/doc/CMakeLists.txt#L22. But with ./configure it should probably be doable too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:132,security,modif,modifying,132,"Thanks. What I am suggesting is something like:. ```. ./configure --enable-th1 --enable-th2. make. ```. which lets you tune without modifying the source dir. EnableTH1 would activate the build of a specific dir behind the scenes. Or the alternative with cmake, which would be:. ```. cmake -DENABLE_TH1 -DENABLE_TH2. make. ```. With cmake it would be a bit cleaner, as there is the function doxygen_add_docs() which already does what makeinput.sh is doing manually. See Alice: https://github.com/AliceO2Group/Monitoring/blob/dev/doc/CMakeLists.txt#L22. But with ./configure it should probably be doable too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:563,security,configur,configure,563,"Thanks. What I am suggesting is something like:. ```. ./configure --enable-th1 --enable-th2. make. ```. which lets you tune without modifying the source dir. EnableTH1 would activate the build of a specific dir behind the scenes. Or the alternative with cmake, which would be:. ```. cmake -DENABLE_TH1 -DENABLE_TH2. make. ```. With cmake it would be a bit cleaner, as there is the function doxygen_add_docs() which already does what makeinput.sh is doing manually. See Alice: https://github.com/AliceO2Group/Monitoring/blob/dev/doc/CMakeLists.txt#L22. But with ./configure it should probably be doable too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:508,testability,Monitor,Monitoring,508,"Thanks. What I am suggesting is something like:. ```. ./configure --enable-th1 --enable-th2. make. ```. which lets you tune without modifying the source dir. EnableTH1 would activate the build of a specific dir behind the scenes. Or the alternative with cmake, which would be:. ```. cmake -DENABLE_TH1 -DENABLE_TH2. make. ```. With cmake it would be a bit cleaner, as there is the function doxygen_add_docs() which already does what makeinput.sh is doing manually. See Alice: https://github.com/AliceO2Group/Monitoring/blob/dev/doc/CMakeLists.txt#L22. But with ./configure it should probably be doable too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:185,integrability,sub,subfolders,185,Yes but the list of folders does not follow the classes naming .... You may need more something like `-DENABLE_HIST` .... but then is the `hist` folder we have `hist` and `histpainter` subfolders which might be enabled separately ... and this is a simple example there is much more complex structures for which we need a precise picking which is done by `makeinput.sh`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:28,reliability,doe,does,28,Yes but the list of folders does not follow the classes naming .... You may need more something like `-DENABLE_HIST` .... but then is the `hist` folder we have `hist` and `histpainter` subfolders which might be enabled separately ... and this is a simple example there is much more complex structures for which we need a precise picking which is done by `makeinput.sh`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:282,safety,compl,complex,282,Yes but the list of folders does not follow the classes naming .... You may need more something like `-DENABLE_HIST` .... but then is the `hist` folder we have `hist` and `histpainter` subfolders which might be enabled separately ... and this is a simple example there is much more complex structures for which we need a precise picking which is done by `makeinput.sh`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:282,security,compl,complex,282,Yes but the list of folders does not follow the classes naming .... You may need more something like `-DENABLE_HIST` .... but then is the `hist` folder we have `hist` and `histpainter` subfolders which might be enabled separately ... and this is a simple example there is much more complex structures for which we need a precise picking which is done by `makeinput.sh`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:248,testability,simpl,simple,248,Yes but the list of folders does not follow the classes naming .... You may need more something like `-DENABLE_HIST` .... but then is the `hist` folder we have `hist` and `histpainter` subfolders which might be enabled separately ... and this is a simple example there is much more complex structures for which we need a precise picking which is done by `makeinput.sh`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:248,usability,simpl,simple,248,Yes but the list of folders does not follow the classes naming .... You may need more something like `-DENABLE_HIST` .... but then is the `hist` folder we have `hist` and `histpainter` subfolders which might be enabled separately ... and this is a simple example there is much more complex structures for which we need a precise picking which is done by `makeinput.sh`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:56,security,hack,hacking,56,"True... But the cherry picking might be still doable by hacking the CMakeLists.txt (instead of hacking the makeinput.sh as right now). But yeah, we don't win much in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:95,security,hack,hacking,95,"True... But the cherry picking might be still doable by hacking the CMakeLists.txt (instead of hacking the makeinput.sh as right now). But yeah, we don't win much in that case.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:133,safety,avoid,avoid,133,Yes because `CMakeLists.txt` will appear as modified instead of `makeinput.sh`. Anyway there is some clean up to be done in order to avoid the sources polluting. I am looking at it..,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/issues/8950:44,security,modif,modified,44,Yes because `CMakeLists.txt` will appear as modified instead of `makeinput.sh`. Anyway there is some clean up to be done in order to avoid the sources polluting. I am looking at it..,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8950
https://github.com/root-project/root/pull/8955:110,testability,unit,units,110,"@MarkusFrankATcernch - please, see comments on cms-sw/cmsdist#7274 . With this PR merged DD4hep cannot change units to G4 ones that is a default for CMS.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8955
https://github.com/root-project/root/pull/8955:373,deployability,build,build,373,it gets in this condition:. https://github.com/AIDASoft/DD4hep/blob/9bbe12b080ce52615251facc6f6ff5dd58a60e69/DDCore/src/DetectorImp.cpp#L205-L208. which changes the value to . https://github.com/AIDASoft/DD4hep/blob/9bbe12b080ce52615251facc6f6ff5dd58a60e69/DDCore/src/DetectorImp.cpp#L207. DD4HEP_USE_GEANT4_UNITS if DD4Hep is built with DD4HEP_USE_GEANT4_UNITS. should we build DD4Hep with DD4HEP_USE_GEANT4_UNITS=OFF then ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8955
https://github.com/root-project/root/pull/8955:120,safety,Detect,DetectorImp,120,it gets in this condition:. https://github.com/AIDASoft/DD4hep/blob/9bbe12b080ce52615251facc6f6ff5dd58a60e69/DDCore/src/DetectorImp.cpp#L205-L208. which changes the value to . https://github.com/AIDASoft/DD4hep/blob/9bbe12b080ce52615251facc6f6ff5dd58a60e69/DDCore/src/DetectorImp.cpp#L207. DD4HEP_USE_GEANT4_UNITS if DD4Hep is built with DD4HEP_USE_GEANT4_UNITS. should we build DD4Hep with DD4HEP_USE_GEANT4_UNITS=OFF then ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8955
https://github.com/root-project/root/pull/8955:268,safety,Detect,DetectorImp,268,it gets in this condition:. https://github.com/AIDASoft/DD4hep/blob/9bbe12b080ce52615251facc6f6ff5dd58a60e69/DDCore/src/DetectorImp.cpp#L205-L208. which changes the value to . https://github.com/AIDASoft/DD4hep/blob/9bbe12b080ce52615251facc6f6ff5dd58a60e69/DDCore/src/DetectorImp.cpp#L207. DD4HEP_USE_GEANT4_UNITS if DD4Hep is built with DD4HEP_USE_GEANT4_UNITS. should we build DD4Hep with DD4HEP_USE_GEANT4_UNITS=OFF then ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8955
https://github.com/root-project/root/pull/8955:120,security,Detect,DetectorImp,120,it gets in this condition:. https://github.com/AIDASoft/DD4hep/blob/9bbe12b080ce52615251facc6f6ff5dd58a60e69/DDCore/src/DetectorImp.cpp#L205-L208. which changes the value to . https://github.com/AIDASoft/DD4hep/blob/9bbe12b080ce52615251facc6f6ff5dd58a60e69/DDCore/src/DetectorImp.cpp#L207. DD4HEP_USE_GEANT4_UNITS if DD4Hep is built with DD4HEP_USE_GEANT4_UNITS. should we build DD4Hep with DD4HEP_USE_GEANT4_UNITS=OFF then ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8955
https://github.com/root-project/root/pull/8955:268,security,Detect,DetectorImp,268,it gets in this condition:. https://github.com/AIDASoft/DD4hep/blob/9bbe12b080ce52615251facc6f6ff5dd58a60e69/DDCore/src/DetectorImp.cpp#L205-L208. which changes the value to . https://github.com/AIDASoft/DD4hep/blob/9bbe12b080ce52615251facc6f6ff5dd58a60e69/DDCore/src/DetectorImp.cpp#L207. DD4HEP_USE_GEANT4_UNITS if DD4Hep is built with DD4HEP_USE_GEANT4_UNITS. should we build DD4Hep with DD4HEP_USE_GEANT4_UNITS=OFF then ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8955
https://github.com/root-project/root/pull/8955:178,safety,Detect,DetectorImp,178,"@mrodozov . If you have compiled with DD4HEP_USE_GEANT4_UNITS=ON, then the condition. https://github.com/AIDASoft/DD4hep/blob/9bbe12b080ce52615251facc6f6ff5dd58a60e69/DDCore/src/DetectorImp.cpp#L205-L208. should be correct. Or do I miss here something? An explanation for the change can be found here:. https://github.com/root-project/root/commit/bcc8bb729c23873177b9cb3e250fa000a0b59035#commitcomment-56114745.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8955
https://github.com/root-project/root/pull/8955:178,security,Detect,DetectorImp,178,"@mrodozov . If you have compiled with DD4HEP_USE_GEANT4_UNITS=ON, then the condition. https://github.com/AIDASoft/DD4hep/blob/9bbe12b080ce52615251facc6f6ff5dd58a60e69/DDCore/src/DetectorImp.cpp#L205-L208. should be correct. Or do I miss here something? An explanation for the change can be found here:. https://github.com/root-project/root/commit/bcc8bb729c23873177b9cb3e250fa000a0b59035#commitcomment-56114745.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8955
https://github.com/root-project/root/pull/8955:95,deployability,integr,integrating,95,"@MarkusFrankATcernch . it's all clear now, nothing is missing. with the ROOT changes should be integrating fine. thank you :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8955
https://github.com/root-project/root/pull/8955:95,integrability,integr,integrating,95,"@MarkusFrankATcernch . it's all clear now, nothing is missing. with the ROOT changes should be integrating fine. thank you :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8955
https://github.com/root-project/root/pull/8955:95,interoperability,integr,integrating,95,"@MarkusFrankATcernch . it's all clear now, nothing is missing. with the ROOT changes should be integrating fine. thank you :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8955
https://github.com/root-project/root/pull/8955:95,modifiability,integr,integrating,95,"@MarkusFrankATcernch . it's all clear now, nothing is missing. with the ROOT changes should be integrating fine. thank you :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8955
https://github.com/root-project/root/pull/8955:95,reliability,integr,integrating,95,"@MarkusFrankATcernch . it's all clear now, nothing is missing. with the ROOT changes should be integrating fine. thank you :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8955
https://github.com/root-project/root/pull/8955:95,security,integr,integrating,95,"@MarkusFrankATcernch . it's all clear now, nothing is missing. with the ROOT changes should be integrating fine. thank you :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8955
https://github.com/root-project/root/pull/8955:95,testability,integr,integrating,95,"@MarkusFrankATcernch . it's all clear now, nothing is missing. with the ROOT changes should be integrating fine. thank you :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8955
https://github.com/root-project/root/pull/8955:32,usability,clear,clear,32,"@MarkusFrankATcernch . it's all clear now, nothing is missing. with the ROOT changes should be integrating fine. thank you :)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8955
https://github.com/root-project/root/pull/8956:11,deployability,build,build,11,@phsft-bot build on ROOT-performance-centos8-multicore/default with flags -DCTEST_TEST_EXCLUDE_NONE=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8956
https://github.com/root-project/root/pull/8956:25,performance,perform,performance-,25,@phsft-bot build on ROOT-performance-centos8-multicore/default with flags -DCTEST_TEST_EXCLUDE_NONE=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8956
https://github.com/root-project/root/pull/8956:25,usability,perform,performance-,25,@phsft-bot build on ROOT-performance-centos8-multicore/default with flags -DCTEST_TEST_EXCLUDE_NONE=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8956
https://github.com/root-project/root/pull/8956:22,deployability,build,build,22,"I have checked in the build above that the tutorials are now excluded, it should be ready to be merged.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8956
https://github.com/root-project/root/pull/8958:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu2004/default with flags -Dtmva-sofie=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8958
https://github.com/root-project/root/pull/8958:51,deployability,build,build,51,The merge conflict has been resolved. Please rerun build.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8958
https://github.com/root-project/root/pull/8958:10,interoperability,conflict,conflict,10,The merge conflict has been resolved. Please rerun build.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8958
https://github.com/root-project/root/pull/8958:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu2004/default with flags -Dtmva-sofie=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8958
https://github.com/root-project/root/pull/8958:14,deployability,updat,updating,14,"Thank you for updating the PR. I will check if it rebuilds and if it will be fine, I will merge it",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8958
https://github.com/root-project/root/pull/8958:14,safety,updat,updating,14,"Thank you for updating the PR. I will check if it rebuilds and if it will be fine, I will merge it",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8958
https://github.com/root-project/root/pull/8958:14,security,updat,updating,14,"Thank you for updating the PR. I will check if it rebuilds and if it will be fine, I will merge it",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8958
https://github.com/root-project/root/pull/8958:4,deployability,pipelin,pipeline,4,The pipeline failed because of a merged conflict. This time I tried rebase instead of merge. Could you try rebuild again?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8958
https://github.com/root-project/root/pull/8958:13,deployability,fail,failed,13,The pipeline failed because of a merged conflict. This time I tried rebase instead of merge. Could you try rebuild again?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8958
https://github.com/root-project/root/pull/8958:4,integrability,pipelin,pipeline,4,The pipeline failed because of a merged conflict. This time I tried rebase instead of merge. Could you try rebuild again?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8958
https://github.com/root-project/root/pull/8958:40,interoperability,conflict,conflict,40,The pipeline failed because of a merged conflict. This time I tried rebase instead of merge. Could you try rebuild again?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8958
https://github.com/root-project/root/pull/8958:55,performance,time,time,55,The pipeline failed because of a merged conflict. This time I tried rebase instead of merge. Could you try rebuild again?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8958
https://github.com/root-project/root/pull/8958:13,reliability,fail,failed,13,The pipeline failed because of a merged conflict. This time I tried rebase instead of merge. Could you try rebuild again?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8958
https://github.com/root-project/root/pull/8958:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu2004/default with flags -Dtmva-sofie=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8958
https://github.com/root-project/root/pull/8958:14,interoperability,conflict,conflict,14,Sorry a merge conflict was not handled properly. Now it should be fine.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8958
https://github.com/root-project/root/pull/8958:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu2004/default with flags -Dtmva-sofie=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8958
https://github.com/root-project/root/pull/8958:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu2004/default with flags -Dtmva-sofie=On.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8958
https://github.com/root-project/root/issues/8962:9,energy efficiency,current,current,9,"With the current benchmarking we have, turning it off does not seem to alter performance much, so I would say it's not critical to have it fixed by ""yesterday"". However it would be nice if a fix could make the 6.24.08 timeline. That said I reserve the right to bump the priority if further benchmarks show that `SetClusterPrefech(true)` gives a significant gain.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/issues/8962:77,performance,perform,performance,77,"With the current benchmarking we have, turning it off does not seem to alter performance much, so I would say it's not critical to have it fixed by ""yesterday"". However it would be nice if a fix could make the 6.24.08 timeline. That said I reserve the right to bump the priority if further benchmarks show that `SetClusterPrefech(true)` gives a significant gain.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/issues/8962:218,performance,time,timeline,218,"With the current benchmarking we have, turning it off does not seem to alter performance much, so I would say it's not critical to have it fixed by ""yesterday"". However it would be nice if a fix could make the 6.24.08 timeline. That said I reserve the right to bump the priority if further benchmarks show that `SetClusterPrefech(true)` gives a significant gain.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/issues/8962:54,reliability,doe,does,54,"With the current benchmarking we have, turning it off does not seem to alter performance much, so I would say it's not critical to have it fixed by ""yesterday"". However it would be nice if a fix could make the 6.24.08 timeline. That said I reserve the right to bump the priority if further benchmarks show that `SetClusterPrefech(true)` gives a significant gain.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/issues/8962:345,security,sign,significant,345,"With the current benchmarking we have, turning it off does not seem to alter performance much, so I would say it's not critical to have it fixed by ""yesterday"". However it would be nice if a fix could make the 6.24.08 timeline. That said I reserve the right to bump the priority if further benchmarks show that `SetClusterPrefech(true)` gives a significant gain.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/issues/8962:77,usability,perform,performance,77,"With the current benchmarking we have, turning it off does not seem to alter performance much, so I would say it's not critical to have it fixed by ""yesterday"". However it would be nice if a fix could make the 6.24.08 timeline. That said I reserve the right to bump the priority if further benchmarks show that `SetClusterPrefech(true)` gives a significant gain.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/issues/8962:83,availability,down,down,83,"This is actually still buggy and we now have a use case where not having it brings down the storage of some site, due to the excessive number of IOPS per server (50 IOPS, 720 concurrent accesses to 3 storage servers for a total of 0.2PB of data being read). Enabling this would allow us to reduce the IOPS by a factor ~5. The actual error that we get by enabling it is:. ```. [1923904:internal-dpl-aod-reader]: Fatal: fExtraBasket == nullptr && ""fExtraBasket should have been set to nullptr by GetFreshBasket"" violated at line 1679 of `/local/workspace/DailyBuilds/DailyO2Physics-slc9/daily-tags.nRQdop69vk/SOURCES/ROOT/v6-32-06-alice1/v6-32-06-alice1/tree/tree/src/TBranch.cxx'. [1923904:internal-dpl-aod-reader]: aborting. ```. I can provide some file which has the issue, if needed. This becomes rather urgent for us now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/issues/8962:333,availability,error,error,333,"This is actually still buggy and we now have a use case where not having it brings down the storage of some site, due to the excessive number of IOPS per server (50 IOPS, 720 concurrent accesses to 3 storage servers for a total of 0.2PB of data being read). Enabling this would allow us to reduce the IOPS by a factor ~5. The actual error that we get by enabling it is:. ```. [1923904:internal-dpl-aod-reader]: Fatal: fExtraBasket == nullptr && ""fExtraBasket should have been set to nullptr by GetFreshBasket"" violated at line 1679 of `/local/workspace/DailyBuilds/DailyO2Physics-slc9/daily-tags.nRQdop69vk/SOURCES/ROOT/v6-32-06-alice1/v6-32-06-alice1/tree/tree/src/TBranch.cxx'. [1923904:internal-dpl-aod-reader]: aborting. ```. I can provide some file which has the issue, if needed. This becomes rather urgent for us now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/issues/8962:290,energy efficiency,reduc,reduce,290,"This is actually still buggy and we now have a use case where not having it brings down the storage of some site, due to the excessive number of IOPS per server (50 IOPS, 720 concurrent accesses to 3 storage servers for a total of 0.2PB of data being read). Enabling this would allow us to reduce the IOPS by a factor ~5. The actual error that we get by enabling it is:. ```. [1923904:internal-dpl-aod-reader]: Fatal: fExtraBasket == nullptr && ""fExtraBasket should have been set to nullptr by GetFreshBasket"" violated at line 1679 of `/local/workspace/DailyBuilds/DailyO2Physics-slc9/daily-tags.nRQdop69vk/SOURCES/ROOT/v6-32-06-alice1/v6-32-06-alice1/tree/tree/src/TBranch.cxx'. [1923904:internal-dpl-aod-reader]: aborting. ```. I can provide some file which has the issue, if needed. This becomes rather urgent for us now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/issues/8962:145,performance,IOP,IOPS,145,"This is actually still buggy and we now have a use case where not having it brings down the storage of some site, due to the excessive number of IOPS per server (50 IOPS, 720 concurrent accesses to 3 storage servers for a total of 0.2PB of data being read). Enabling this would allow us to reduce the IOPS by a factor ~5. The actual error that we get by enabling it is:. ```. [1923904:internal-dpl-aod-reader]: Fatal: fExtraBasket == nullptr && ""fExtraBasket should have been set to nullptr by GetFreshBasket"" violated at line 1679 of `/local/workspace/DailyBuilds/DailyO2Physics-slc9/daily-tags.nRQdop69vk/SOURCES/ROOT/v6-32-06-alice1/v6-32-06-alice1/tree/tree/src/TBranch.cxx'. [1923904:internal-dpl-aod-reader]: aborting. ```. I can provide some file which has the issue, if needed. This becomes rather urgent for us now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/issues/8962:165,performance,IOP,IOPS,165,"This is actually still buggy and we now have a use case where not having it brings down the storage of some site, due to the excessive number of IOPS per server (50 IOPS, 720 concurrent accesses to 3 storage servers for a total of 0.2PB of data being read). Enabling this would allow us to reduce the IOPS by a factor ~5. The actual error that we get by enabling it is:. ```. [1923904:internal-dpl-aod-reader]: Fatal: fExtraBasket == nullptr && ""fExtraBasket should have been set to nullptr by GetFreshBasket"" violated at line 1679 of `/local/workspace/DailyBuilds/DailyO2Physics-slc9/daily-tags.nRQdop69vk/SOURCES/ROOT/v6-32-06-alice1/v6-32-06-alice1/tree/tree/src/TBranch.cxx'. [1923904:internal-dpl-aod-reader]: aborting. ```. I can provide some file which has the issue, if needed. This becomes rather urgent for us now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/issues/8962:175,performance,concurren,concurrent,175,"This is actually still buggy and we now have a use case where not having it brings down the storage of some site, due to the excessive number of IOPS per server (50 IOPS, 720 concurrent accesses to 3 storage servers for a total of 0.2PB of data being read). Enabling this would allow us to reduce the IOPS by a factor ~5. The actual error that we get by enabling it is:. ```. [1923904:internal-dpl-aod-reader]: Fatal: fExtraBasket == nullptr && ""fExtraBasket should have been set to nullptr by GetFreshBasket"" violated at line 1679 of `/local/workspace/DailyBuilds/DailyO2Physics-slc9/daily-tags.nRQdop69vk/SOURCES/ROOT/v6-32-06-alice1/v6-32-06-alice1/tree/tree/src/TBranch.cxx'. [1923904:internal-dpl-aod-reader]: aborting. ```. I can provide some file which has the issue, if needed. This becomes rather urgent for us now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/issues/8962:301,performance,IOP,IOPS,301,"This is actually still buggy and we now have a use case where not having it brings down the storage of some site, due to the excessive number of IOPS per server (50 IOPS, 720 concurrent accesses to 3 storage servers for a total of 0.2PB of data being read). Enabling this would allow us to reduce the IOPS by a factor ~5. The actual error that we get by enabling it is:. ```. [1923904:internal-dpl-aod-reader]: Fatal: fExtraBasket == nullptr && ""fExtraBasket should have been set to nullptr by GetFreshBasket"" violated at line 1679 of `/local/workspace/DailyBuilds/DailyO2Physics-slc9/daily-tags.nRQdop69vk/SOURCES/ROOT/v6-32-06-alice1/v6-32-06-alice1/tree/tree/src/TBranch.cxx'. [1923904:internal-dpl-aod-reader]: aborting. ```. I can provide some file which has the issue, if needed. This becomes rather urgent for us now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/issues/8962:333,performance,error,error,333,"This is actually still buggy and we now have a use case where not having it brings down the storage of some site, due to the excessive number of IOPS per server (50 IOPS, 720 concurrent accesses to 3 storage servers for a total of 0.2PB of data being read). Enabling this would allow us to reduce the IOPS by a factor ~5. The actual error that we get by enabling it is:. ```. [1923904:internal-dpl-aod-reader]: Fatal: fExtraBasket == nullptr && ""fExtraBasket should have been set to nullptr by GetFreshBasket"" violated at line 1679 of `/local/workspace/DailyBuilds/DailyO2Physics-slc9/daily-tags.nRQdop69vk/SOURCES/ROOT/v6-32-06-alice1/v6-32-06-alice1/tree/tree/src/TBranch.cxx'. [1923904:internal-dpl-aod-reader]: aborting. ```. I can provide some file which has the issue, if needed. This becomes rather urgent for us now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/issues/8962:333,safety,error,error,333,"This is actually still buggy and we now have a use case where not having it brings down the storage of some site, due to the excessive number of IOPS per server (50 IOPS, 720 concurrent accesses to 3 storage servers for a total of 0.2PB of data being read). Enabling this would allow us to reduce the IOPS by a factor ~5. The actual error that we get by enabling it is:. ```. [1923904:internal-dpl-aod-reader]: Fatal: fExtraBasket == nullptr && ""fExtraBasket should have been set to nullptr by GetFreshBasket"" violated at line 1679 of `/local/workspace/DailyBuilds/DailyO2Physics-slc9/daily-tags.nRQdop69vk/SOURCES/ROOT/v6-32-06-alice1/v6-32-06-alice1/tree/tree/src/TBranch.cxx'. [1923904:internal-dpl-aod-reader]: aborting. ```. I can provide some file which has the issue, if needed. This becomes rather urgent for us now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/issues/8962:186,security,access,accesses,186,"This is actually still buggy and we now have a use case where not having it brings down the storage of some site, due to the excessive number of IOPS per server (50 IOPS, 720 concurrent accesses to 3 storage servers for a total of 0.2PB of data being read). Enabling this would allow us to reduce the IOPS by a factor ~5. The actual error that we get by enabling it is:. ```. [1923904:internal-dpl-aod-reader]: Fatal: fExtraBasket == nullptr && ""fExtraBasket should have been set to nullptr by GetFreshBasket"" violated at line 1679 of `/local/workspace/DailyBuilds/DailyO2Physics-slc9/daily-tags.nRQdop69vk/SOURCES/ROOT/v6-32-06-alice1/v6-32-06-alice1/tree/tree/src/TBranch.cxx'. [1923904:internal-dpl-aod-reader]: aborting. ```. I can provide some file which has the issue, if needed. This becomes rather urgent for us now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/issues/8962:333,usability,error,error,333,"This is actually still buggy and we now have a use case where not having it brings down the storage of some site, due to the excessive number of IOPS per server (50 IOPS, 720 concurrent accesses to 3 storage servers for a total of 0.2PB of data being read). Enabling this would allow us to reduce the IOPS by a factor ~5. The actual error that we get by enabling it is:. ```. [1923904:internal-dpl-aod-reader]: Fatal: fExtraBasket == nullptr && ""fExtraBasket should have been set to nullptr by GetFreshBasket"" violated at line 1679 of `/local/workspace/DailyBuilds/DailyO2Physics-slc9/daily-tags.nRQdop69vk/SOURCES/ROOT/v6-32-06-alice1/v6-32-06-alice1/tree/tree/src/TBranch.cxx'. [1923904:internal-dpl-aod-reader]: aborting. ```. I can provide some file which has the issue, if needed. This becomes rather urgent for us now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/issues/8962:60,usability,behavi,behavior,60,"Yes, please point us to one of the file with the unexpected behavior.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/issues/8962:119,deployability,version,version,119,"The testcase in the description is actually wrong, it only reads starting from the first entry. A corrected / expanded version is:. ```C++. #include <TBufferFile.h>. #include <TFile.h>. #include <TTree.h>. #include <iostream>. #include <TKey.h>. void test() {. auto f = TFile::Open(""AO2D.root"");. for (auto&& keyAsObj : *f->GetListOfKeys()){. auto key = (TKey*) keyAsObj;. std::cout << key->GetName() << "" "" << key->GetClassName() << std::endl;. auto d = (TDirectoryFile*)f->Get(key->GetName());. if (key->GetName() == std::string(""metaData"")) {. continue;. }. std::cout << ""Reading DF "" << key->GetName() << std::endl;. char const *treeNames[] = {. ""O2trackextra_001"",. //""O2ambiguousfwdtr"",. //""O2ambiguousmfttr"",. //""O2ambiguoustrack"",. //""O2bc_001"",. //""O2calo"",. //""O2calotrigger"",. //""O2cascade_001"",. //""O2collision_001"",. //""O2cpvcluster"",. //""O2decay3body"",. //""O2fdd_001"",. //""O2ft0"",. //""O2fv0a"",. //""O2fwdtrack"",. //""O2fwdtrackcov"",. //""O2fwdtrkcl"",. //""O2hmpid_001"",. //""O2mccalolabel_001"",. //""O2mccollision"",. //""O2mccollisionlabel"",. //""O2mcfwdtracklabel"",. //""O2mcmfttracklabel"",. //""O2mcparticle_001"",. //""O2mctracklabel"",. //""O2mfttrack_001"",. //""O2origin"",. //""O2track_iu"",. //""O2trackcov_iu"",. //""O2tracked3body"",. //""O2trackedcascade"",. //""O2trackedv0"",. //""O2trackqa"",. //""O2v0_002"",. //""O2zdc_001"",. };. for (auto ti = 0; ti < sizeof(treeNames)/sizeof(void*); ti++) {. std::cout << ti << std::endl;. std::cout << "" "" << treeNames[ti] << std::endl;. auto t = (TTree*)d->Get(treeNames[ti]);. std::cout << t << std::endl;. if (t == nullptr) {. std::cout << ""Missing branch."" << treeNames[ti] << std::endl;. }. t->SetCacheSize(25000000);. t->SetClusterPrefetch(true);. auto branchList = t->GetListOfBranches();. for (size_t bi = 0; bi < branchList->GetSize(); bi++) {. t->AddBranchToCache((TBranch*)branchList->At(bi));. }. t->StopCacheLearningPhase();. static TBufferFile buf(TBuffer::EMode::kWrite, 4*1024*1024);. for (auto bi = 0; bi < branchList->GetEntries(); ++bi) {. auto b",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/issues/8962:547,deployability,continu,continue,547,"The testcase in the description is actually wrong, it only reads starting from the first entry. A corrected / expanded version is:. ```C++. #include <TBufferFile.h>. #include <TFile.h>. #include <TTree.h>. #include <iostream>. #include <TKey.h>. void test() {. auto f = TFile::Open(""AO2D.root"");. for (auto&& keyAsObj : *f->GetListOfKeys()){. auto key = (TKey*) keyAsObj;. std::cout << key->GetName() << "" "" << key->GetClassName() << std::endl;. auto d = (TDirectoryFile*)f->Get(key->GetName());. if (key->GetName() == std::string(""metaData"")) {. continue;. }. std::cout << ""Reading DF "" << key->GetName() << std::endl;. char const *treeNames[] = {. ""O2trackextra_001"",. //""O2ambiguousfwdtr"",. //""O2ambiguousmfttr"",. //""O2ambiguoustrack"",. //""O2bc_001"",. //""O2calo"",. //""O2calotrigger"",. //""O2cascade_001"",. //""O2collision_001"",. //""O2cpvcluster"",. //""O2decay3body"",. //""O2fdd_001"",. //""O2ft0"",. //""O2fv0a"",. //""O2fwdtrack"",. //""O2fwdtrackcov"",. //""O2fwdtrkcl"",. //""O2hmpid_001"",. //""O2mccalolabel_001"",. //""O2mccollision"",. //""O2mccollisionlabel"",. //""O2mcfwdtracklabel"",. //""O2mcmfttracklabel"",. //""O2mcparticle_001"",. //""O2mctracklabel"",. //""O2mfttrack_001"",. //""O2origin"",. //""O2track_iu"",. //""O2trackcov_iu"",. //""O2tracked3body"",. //""O2trackedcascade"",. //""O2trackedv0"",. //""O2trackqa"",. //""O2v0_002"",. //""O2zdc_001"",. };. for (auto ti = 0; ti < sizeof(treeNames)/sizeof(void*); ti++) {. std::cout << ti << std::endl;. std::cout << "" "" << treeNames[ti] << std::endl;. auto t = (TTree*)d->Get(treeNames[ti]);. std::cout << t << std::endl;. if (t == nullptr) {. std::cout << ""Missing branch."" << treeNames[ti] << std::endl;. }. t->SetCacheSize(25000000);. t->SetClusterPrefetch(true);. auto branchList = t->GetListOfBranches();. for (size_t bi = 0; bi < branchList->GetSize(); bi++) {. t->AddBranchToCache((TBranch*)branchList->At(bi));. }. t->StopCacheLearningPhase();. static TBufferFile buf(TBuffer::EMode::kWrite, 4*1024*1024);. for (auto bi = 0; bi < branchList->GetEntries(); ++bi) {. auto b",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/issues/8962:119,integrability,version,version,119,"The testcase in the description is actually wrong, it only reads starting from the first entry. A corrected / expanded version is:. ```C++. #include <TBufferFile.h>. #include <TFile.h>. #include <TTree.h>. #include <iostream>. #include <TKey.h>. void test() {. auto f = TFile::Open(""AO2D.root"");. for (auto&& keyAsObj : *f->GetListOfKeys()){. auto key = (TKey*) keyAsObj;. std::cout << key->GetName() << "" "" << key->GetClassName() << std::endl;. auto d = (TDirectoryFile*)f->Get(key->GetName());. if (key->GetName() == std::string(""metaData"")) {. continue;. }. std::cout << ""Reading DF "" << key->GetName() << std::endl;. char const *treeNames[] = {. ""O2trackextra_001"",. //""O2ambiguousfwdtr"",. //""O2ambiguousmfttr"",. //""O2ambiguoustrack"",. //""O2bc_001"",. //""O2calo"",. //""O2calotrigger"",. //""O2cascade_001"",. //""O2collision_001"",. //""O2cpvcluster"",. //""O2decay3body"",. //""O2fdd_001"",. //""O2ft0"",. //""O2fv0a"",. //""O2fwdtrack"",. //""O2fwdtrackcov"",. //""O2fwdtrkcl"",. //""O2hmpid_001"",. //""O2mccalolabel_001"",. //""O2mccollision"",. //""O2mccollisionlabel"",. //""O2mcfwdtracklabel"",. //""O2mcmfttracklabel"",. //""O2mcparticle_001"",. //""O2mctracklabel"",. //""O2mfttrack_001"",. //""O2origin"",. //""O2track_iu"",. //""O2trackcov_iu"",. //""O2tracked3body"",. //""O2trackedcascade"",. //""O2trackedv0"",. //""O2trackqa"",. //""O2v0_002"",. //""O2zdc_001"",. };. for (auto ti = 0; ti < sizeof(treeNames)/sizeof(void*); ti++) {. std::cout << ti << std::endl;. std::cout << "" "" << treeNames[ti] << std::endl;. auto t = (TTree*)d->Get(treeNames[ti]);. std::cout << t << std::endl;. if (t == nullptr) {. std::cout << ""Missing branch."" << treeNames[ti] << std::endl;. }. t->SetCacheSize(25000000);. t->SetClusterPrefetch(true);. auto branchList = t->GetListOfBranches();. for (size_t bi = 0; bi < branchList->GetSize(); bi++) {. t->AddBranchToCache((TBranch*)branchList->At(bi));. }. t->StopCacheLearningPhase();. static TBufferFile buf(TBuffer::EMode::kWrite, 4*1024*1024);. for (auto bi = 0; bi < branchList->GetEntries(); ++bi) {. auto b",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/issues/8962:119,modifiability,version,version,119,"The testcase in the description is actually wrong, it only reads starting from the first entry. A corrected / expanded version is:. ```C++. #include <TBufferFile.h>. #include <TFile.h>. #include <TTree.h>. #include <iostream>. #include <TKey.h>. void test() {. auto f = TFile::Open(""AO2D.root"");. for (auto&& keyAsObj : *f->GetListOfKeys()){. auto key = (TKey*) keyAsObj;. std::cout << key->GetName() << "" "" << key->GetClassName() << std::endl;. auto d = (TDirectoryFile*)f->Get(key->GetName());. if (key->GetName() == std::string(""metaData"")) {. continue;. }. std::cout << ""Reading DF "" << key->GetName() << std::endl;. char const *treeNames[] = {. ""O2trackextra_001"",. //""O2ambiguousfwdtr"",. //""O2ambiguousmfttr"",. //""O2ambiguoustrack"",. //""O2bc_001"",. //""O2calo"",. //""O2calotrigger"",. //""O2cascade_001"",. //""O2collision_001"",. //""O2cpvcluster"",. //""O2decay3body"",. //""O2fdd_001"",. //""O2ft0"",. //""O2fv0a"",. //""O2fwdtrack"",. //""O2fwdtrackcov"",. //""O2fwdtrkcl"",. //""O2hmpid_001"",. //""O2mccalolabel_001"",. //""O2mccollision"",. //""O2mccollisionlabel"",. //""O2mcfwdtracklabel"",. //""O2mcmfttracklabel"",. //""O2mcparticle_001"",. //""O2mctracklabel"",. //""O2mfttrack_001"",. //""O2origin"",. //""O2track_iu"",. //""O2trackcov_iu"",. //""O2tracked3body"",. //""O2trackedcascade"",. //""O2trackedv0"",. //""O2trackqa"",. //""O2v0_002"",. //""O2zdc_001"",. };. for (auto ti = 0; ti < sizeof(treeNames)/sizeof(void*); ti++) {. std::cout << ti << std::endl;. std::cout << "" "" << treeNames[ti] << std::endl;. auto t = (TTree*)d->Get(treeNames[ti]);. std::cout << t << std::endl;. if (t == nullptr) {. std::cout << ""Missing branch."" << treeNames[ti] << std::endl;. }. t->SetCacheSize(25000000);. t->SetClusterPrefetch(true);. auto branchList = t->GetListOfBranches();. for (size_t bi = 0; bi < branchList->GetSize(); bi++) {. t->AddBranchToCache((TBranch*)branchList->At(bi));. }. t->StopCacheLearningPhase();. static TBufferFile buf(TBuffer::EMode::kWrite, 4*1024*1024);. for (auto bi = 0; bi < branchList->GetEntries(); ++bi) {. auto b",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/issues/8962:4,safety,test,testcase,4,"The testcase in the description is actually wrong, it only reads starting from the first entry. A corrected / expanded version is:. ```C++. #include <TBufferFile.h>. #include <TFile.h>. #include <TTree.h>. #include <iostream>. #include <TKey.h>. void test() {. auto f = TFile::Open(""AO2D.root"");. for (auto&& keyAsObj : *f->GetListOfKeys()){. auto key = (TKey*) keyAsObj;. std::cout << key->GetName() << "" "" << key->GetClassName() << std::endl;. auto d = (TDirectoryFile*)f->Get(key->GetName());. if (key->GetName() == std::string(""metaData"")) {. continue;. }. std::cout << ""Reading DF "" << key->GetName() << std::endl;. char const *treeNames[] = {. ""O2trackextra_001"",. //""O2ambiguousfwdtr"",. //""O2ambiguousmfttr"",. //""O2ambiguoustrack"",. //""O2bc_001"",. //""O2calo"",. //""O2calotrigger"",. //""O2cascade_001"",. //""O2collision_001"",. //""O2cpvcluster"",. //""O2decay3body"",. //""O2fdd_001"",. //""O2ft0"",. //""O2fv0a"",. //""O2fwdtrack"",. //""O2fwdtrackcov"",. //""O2fwdtrkcl"",. //""O2hmpid_001"",. //""O2mccalolabel_001"",. //""O2mccollision"",. //""O2mccollisionlabel"",. //""O2mcfwdtracklabel"",. //""O2mcmfttracklabel"",. //""O2mcparticle_001"",. //""O2mctracklabel"",. //""O2mfttrack_001"",. //""O2origin"",. //""O2track_iu"",. //""O2trackcov_iu"",. //""O2tracked3body"",. //""O2trackedcascade"",. //""O2trackedv0"",. //""O2trackqa"",. //""O2v0_002"",. //""O2zdc_001"",. };. for (auto ti = 0; ti < sizeof(treeNames)/sizeof(void*); ti++) {. std::cout << ti << std::endl;. std::cout << "" "" << treeNames[ti] << std::endl;. auto t = (TTree*)d->Get(treeNames[ti]);. std::cout << t << std::endl;. if (t == nullptr) {. std::cout << ""Missing branch."" << treeNames[ti] << std::endl;. }. t->SetCacheSize(25000000);. t->SetClusterPrefetch(true);. auto branchList = t->GetListOfBranches();. for (size_t bi = 0; bi < branchList->GetSize(); bi++) {. t->AddBranchToCache((TBranch*)branchList->At(bi));. }. t->StopCacheLearningPhase();. static TBufferFile buf(TBuffer::EMode::kWrite, 4*1024*1024);. for (auto bi = 0; bi < branchList->GetEntries(); ++bi) {. auto b",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/issues/8962:251,safety,test,test,251,"The testcase in the description is actually wrong, it only reads starting from the first entry. A corrected / expanded version is:. ```C++. #include <TBufferFile.h>. #include <TFile.h>. #include <TTree.h>. #include <iostream>. #include <TKey.h>. void test() {. auto f = TFile::Open(""AO2D.root"");. for (auto&& keyAsObj : *f->GetListOfKeys()){. auto key = (TKey*) keyAsObj;. std::cout << key->GetName() << "" "" << key->GetClassName() << std::endl;. auto d = (TDirectoryFile*)f->Get(key->GetName());. if (key->GetName() == std::string(""metaData"")) {. continue;. }. std::cout << ""Reading DF "" << key->GetName() << std::endl;. char const *treeNames[] = {. ""O2trackextra_001"",. //""O2ambiguousfwdtr"",. //""O2ambiguousmfttr"",. //""O2ambiguoustrack"",. //""O2bc_001"",. //""O2calo"",. //""O2calotrigger"",. //""O2cascade_001"",. //""O2collision_001"",. //""O2cpvcluster"",. //""O2decay3body"",. //""O2fdd_001"",. //""O2ft0"",. //""O2fv0a"",. //""O2fwdtrack"",. //""O2fwdtrackcov"",. //""O2fwdtrkcl"",. //""O2hmpid_001"",. //""O2mccalolabel_001"",. //""O2mccollision"",. //""O2mccollisionlabel"",. //""O2mcfwdtracklabel"",. //""O2mcmfttracklabel"",. //""O2mcparticle_001"",. //""O2mctracklabel"",. //""O2mfttrack_001"",. //""O2origin"",. //""O2track_iu"",. //""O2trackcov_iu"",. //""O2tracked3body"",. //""O2trackedcascade"",. //""O2trackedv0"",. //""O2trackqa"",. //""O2v0_002"",. //""O2zdc_001"",. };. for (auto ti = 0; ti < sizeof(treeNames)/sizeof(void*); ti++) {. std::cout << ti << std::endl;. std::cout << "" "" << treeNames[ti] << std::endl;. auto t = (TTree*)d->Get(treeNames[ti]);. std::cout << t << std::endl;. if (t == nullptr) {. std::cout << ""Missing branch."" << treeNames[ti] << std::endl;. }. t->SetCacheSize(25000000);. t->SetClusterPrefetch(true);. auto branchList = t->GetListOfBranches();. for (size_t bi = 0; bi < branchList->GetSize(); bi++) {. t->AddBranchToCache((TBranch*)branchList->At(bi));. }. t->StopCacheLearningPhase();. static TBufferFile buf(TBuffer::EMode::kWrite, 4*1024*1024);. for (auto bi = 0; bi < branchList->GetEntries(); ++bi) {. auto b",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/issues/8962:4,testability,test,testcase,4,"The testcase in the description is actually wrong, it only reads starting from the first entry. A corrected / expanded version is:. ```C++. #include <TBufferFile.h>. #include <TFile.h>. #include <TTree.h>. #include <iostream>. #include <TKey.h>. void test() {. auto f = TFile::Open(""AO2D.root"");. for (auto&& keyAsObj : *f->GetListOfKeys()){. auto key = (TKey*) keyAsObj;. std::cout << key->GetName() << "" "" << key->GetClassName() << std::endl;. auto d = (TDirectoryFile*)f->Get(key->GetName());. if (key->GetName() == std::string(""metaData"")) {. continue;. }. std::cout << ""Reading DF "" << key->GetName() << std::endl;. char const *treeNames[] = {. ""O2trackextra_001"",. //""O2ambiguousfwdtr"",. //""O2ambiguousmfttr"",. //""O2ambiguoustrack"",. //""O2bc_001"",. //""O2calo"",. //""O2calotrigger"",. //""O2cascade_001"",. //""O2collision_001"",. //""O2cpvcluster"",. //""O2decay3body"",. //""O2fdd_001"",. //""O2ft0"",. //""O2fv0a"",. //""O2fwdtrack"",. //""O2fwdtrackcov"",. //""O2fwdtrkcl"",. //""O2hmpid_001"",. //""O2mccalolabel_001"",. //""O2mccollision"",. //""O2mccollisionlabel"",. //""O2mcfwdtracklabel"",. //""O2mcmfttracklabel"",. //""O2mcparticle_001"",. //""O2mctracklabel"",. //""O2mfttrack_001"",. //""O2origin"",. //""O2track_iu"",. //""O2trackcov_iu"",. //""O2tracked3body"",. //""O2trackedcascade"",. //""O2trackedv0"",. //""O2trackqa"",. //""O2v0_002"",. //""O2zdc_001"",. };. for (auto ti = 0; ti < sizeof(treeNames)/sizeof(void*); ti++) {. std::cout << ti << std::endl;. std::cout << "" "" << treeNames[ti] << std::endl;. auto t = (TTree*)d->Get(treeNames[ti]);. std::cout << t << std::endl;. if (t == nullptr) {. std::cout << ""Missing branch."" << treeNames[ti] << std::endl;. }. t->SetCacheSize(25000000);. t->SetClusterPrefetch(true);. auto branchList = t->GetListOfBranches();. for (size_t bi = 0; bi < branchList->GetSize(); bi++) {. t->AddBranchToCache((TBranch*)branchList->At(bi));. }. t->StopCacheLearningPhase();. static TBufferFile buf(TBuffer::EMode::kWrite, 4*1024*1024);. for (auto bi = 0; bi < branchList->GetEntries(); ++bi) {. auto b",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/issues/8962:251,testability,test,test,251,"The testcase in the description is actually wrong, it only reads starting from the first entry. A corrected / expanded version is:. ```C++. #include <TBufferFile.h>. #include <TFile.h>. #include <TTree.h>. #include <iostream>. #include <TKey.h>. void test() {. auto f = TFile::Open(""AO2D.root"");. for (auto&& keyAsObj : *f->GetListOfKeys()){. auto key = (TKey*) keyAsObj;. std::cout << key->GetName() << "" "" << key->GetClassName() << std::endl;. auto d = (TDirectoryFile*)f->Get(key->GetName());. if (key->GetName() == std::string(""metaData"")) {. continue;. }. std::cout << ""Reading DF "" << key->GetName() << std::endl;. char const *treeNames[] = {. ""O2trackextra_001"",. //""O2ambiguousfwdtr"",. //""O2ambiguousmfttr"",. //""O2ambiguoustrack"",. //""O2bc_001"",. //""O2calo"",. //""O2calotrigger"",. //""O2cascade_001"",. //""O2collision_001"",. //""O2cpvcluster"",. //""O2decay3body"",. //""O2fdd_001"",. //""O2ft0"",. //""O2fv0a"",. //""O2fwdtrack"",. //""O2fwdtrackcov"",. //""O2fwdtrkcl"",. //""O2hmpid_001"",. //""O2mccalolabel_001"",. //""O2mccollision"",. //""O2mccollisionlabel"",. //""O2mcfwdtracklabel"",. //""O2mcmfttracklabel"",. //""O2mcparticle_001"",. //""O2mctracklabel"",. //""O2mfttrack_001"",. //""O2origin"",. //""O2track_iu"",. //""O2trackcov_iu"",. //""O2tracked3body"",. //""O2trackedcascade"",. //""O2trackedv0"",. //""O2trackqa"",. //""O2v0_002"",. //""O2zdc_001"",. };. for (auto ti = 0; ti < sizeof(treeNames)/sizeof(void*); ti++) {. std::cout << ti << std::endl;. std::cout << "" "" << treeNames[ti] << std::endl;. auto t = (TTree*)d->Get(treeNames[ti]);. std::cout << t << std::endl;. if (t == nullptr) {. std::cout << ""Missing branch."" << treeNames[ti] << std::endl;. }. t->SetCacheSize(25000000);. t->SetClusterPrefetch(true);. auto branchList = t->GetListOfBranches();. for (size_t bi = 0; bi < branchList->GetSize(); bi++) {. t->AddBranchToCache((TBranch*)branchList->At(bi));. }. t->StopCacheLearningPhase();. static TBufferFile buf(TBuffer::EMode::kWrite, 4*1024*1024);. for (auto bi = 0; bi < branchList->GetEntries(); ++bi) {. auto b",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/issues/8962:2061,testability,assert,assert,2061,"d::string(""metaData"")) {. continue;. }. std::cout << ""Reading DF "" << key->GetName() << std::endl;. char const *treeNames[] = {. ""O2trackextra_001"",. //""O2ambiguousfwdtr"",. //""O2ambiguousmfttr"",. //""O2ambiguoustrack"",. //""O2bc_001"",. //""O2calo"",. //""O2calotrigger"",. //""O2cascade_001"",. //""O2collision_001"",. //""O2cpvcluster"",. //""O2decay3body"",. //""O2fdd_001"",. //""O2ft0"",. //""O2fv0a"",. //""O2fwdtrack"",. //""O2fwdtrackcov"",. //""O2fwdtrkcl"",. //""O2hmpid_001"",. //""O2mccalolabel_001"",. //""O2mccollision"",. //""O2mccollisionlabel"",. //""O2mcfwdtracklabel"",. //""O2mcmfttracklabel"",. //""O2mcparticle_001"",. //""O2mctracklabel"",. //""O2mfttrack_001"",. //""O2origin"",. //""O2track_iu"",. //""O2trackcov_iu"",. //""O2tracked3body"",. //""O2trackedcascade"",. //""O2trackedv0"",. //""O2trackqa"",. //""O2v0_002"",. //""O2zdc_001"",. };. for (auto ti = 0; ti < sizeof(treeNames)/sizeof(void*); ti++) {. std::cout << ti << std::endl;. std::cout << "" "" << treeNames[ti] << std::endl;. auto t = (TTree*)d->Get(treeNames[ti]);. std::cout << t << std::endl;. if (t == nullptr) {. std::cout << ""Missing branch."" << treeNames[ti] << std::endl;. }. t->SetCacheSize(25000000);. t->SetClusterPrefetch(true);. auto branchList = t->GetListOfBranches();. for (size_t bi = 0; bi < branchList->GetSize(); bi++) {. t->AddBranchToCache((TBranch*)branchList->At(bi));. }. t->StopCacheLearningPhase();. static TBufferFile buf(TBuffer::EMode::kWrite, 4*1024*1024);. for (auto bi = 0; bi < branchList->GetEntries(); ++bi) {. auto b = (TBranch*)branchList->At(bi);. auto e = t->GetEntries();. assert(b);. int pos = 0;. while (pos < e) {. //b->Print();. buf.Reset();. auto &r = b->GetBulkRead();. auto s = r.GetBulkEntries(pos, buf);. pos += s;. std::cout << "" "" << b->GetName() << "": "" << s << "" elements read."" << std::endl;. if (s == -1) {. break;. }. }. std::cout << "" "" << b->GetName() << "": "" << pos << "" total."" << std::endl;. b->SetStatus(false);. b->DropBaskets(""all"");. b->Reset();. b->GetTransientBuffer(0)->Expand(0);. }. }. break;. }. }. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/issues/8962:1847,usability,Stop,StopCacheLearningPhase,1847,"d::string(""metaData"")) {. continue;. }. std::cout << ""Reading DF "" << key->GetName() << std::endl;. char const *treeNames[] = {. ""O2trackextra_001"",. //""O2ambiguousfwdtr"",. //""O2ambiguousmfttr"",. //""O2ambiguoustrack"",. //""O2bc_001"",. //""O2calo"",. //""O2calotrigger"",. //""O2cascade_001"",. //""O2collision_001"",. //""O2cpvcluster"",. //""O2decay3body"",. //""O2fdd_001"",. //""O2ft0"",. //""O2fv0a"",. //""O2fwdtrack"",. //""O2fwdtrackcov"",. //""O2fwdtrkcl"",. //""O2hmpid_001"",. //""O2mccalolabel_001"",. //""O2mccollision"",. //""O2mccollisionlabel"",. //""O2mcfwdtracklabel"",. //""O2mcmfttracklabel"",. //""O2mcparticle_001"",. //""O2mctracklabel"",. //""O2mfttrack_001"",. //""O2origin"",. //""O2track_iu"",. //""O2trackcov_iu"",. //""O2tracked3body"",. //""O2trackedcascade"",. //""O2trackedv0"",. //""O2trackqa"",. //""O2v0_002"",. //""O2zdc_001"",. };. for (auto ti = 0; ti < sizeof(treeNames)/sizeof(void*); ti++) {. std::cout << ti << std::endl;. std::cout << "" "" << treeNames[ti] << std::endl;. auto t = (TTree*)d->Get(treeNames[ti]);. std::cout << t << std::endl;. if (t == nullptr) {. std::cout << ""Missing branch."" << treeNames[ti] << std::endl;. }. t->SetCacheSize(25000000);. t->SetClusterPrefetch(true);. auto branchList = t->GetListOfBranches();. for (size_t bi = 0; bi < branchList->GetSize(); bi++) {. t->AddBranchToCache((TBranch*)branchList->At(bi));. }. t->StopCacheLearningPhase();. static TBufferFile buf(TBuffer::EMode::kWrite, 4*1024*1024);. for (auto bi = 0; bi < branchList->GetEntries(); ++bi) {. auto b = (TBranch*)branchList->At(bi);. auto e = t->GetEntries();. assert(b);. int pos = 0;. while (pos < e) {. //b->Print();. buf.Reset();. auto &r = b->GetBulkRead();. auto s = r.GetBulkEntries(pos, buf);. pos += s;. std::cout << "" "" << b->GetName() << "": "" << s << "" elements read."" << std::endl;. if (s == -1) {. break;. }. }. std::cout << "" "" << b->GetName() << "": "" << pos << "" total."" << std::endl;. b->SetStatus(false);. b->DropBaskets(""all"");. b->Reset();. b->GetTransientBuffer(0)->Expand(0);. }. }. break;. }. }. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8962
https://github.com/root-project/root/pull/8963:53,deployability,depend,dependency,53,Closing since #7335 can handle better xrootd OpenSSL dependency (particularly OpenSSL builtin),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8963
https://github.com/root-project/root/pull/8963:53,integrability,depend,dependency,53,Closing since #7335 can handle better xrootd OpenSSL dependency (particularly OpenSSL builtin),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8963
https://github.com/root-project/root/pull/8963:53,modifiability,depend,dependency,53,Closing since #7335 can handle better xrootd OpenSSL dependency (particularly OpenSSL builtin),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8963
https://github.com/root-project/root/pull/8963:53,safety,depend,dependency,53,Closing since #7335 can handle better xrootd OpenSSL dependency (particularly OpenSSL builtin),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8963
https://github.com/root-project/root/pull/8963:53,testability,depend,dependency,53,Closing since #7335 can handle better xrootd OpenSSL dependency (particularly OpenSSL builtin),MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8963
https://github.com/root-project/root/pull/8965:156,deployability,automat,automatically,156,"Hello @edfink234,. welcome on the project. I *think* that the file that you worked with isn't used by anything. It's from a time when tutorials weren't run automatically. I invite you and @guitargeek to check that what I'm claiming here is correct. The real tutorials are in [`tutorials/roofit`](https://github.com/root-project/root/tree/master/tutorials/roofit). If those files indeed aren't used anywhere (I'm pretty sure they are not), I would suggest to delete them.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8965
https://github.com/root-project/root/pull/8965:124,performance,time,time,124,"Hello @edfink234,. welcome on the project. I *think* that the file that you worked with isn't used by anything. It's from a time when tutorials weren't run automatically. I invite you and @guitargeek to check that what I'm claiming here is correct. The real tutorials are in [`tutorials/roofit`](https://github.com/root-project/root/tree/master/tutorials/roofit). If those files indeed aren't used anywhere (I'm pretty sure they are not), I would suggest to delete them.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8965
https://github.com/root-project/root/pull/8965:156,testability,automat,automatically,156,"Hello @edfink234,. welcome on the project. I *think* that the file that you worked with isn't used by anything. It's from a time when tutorials weren't run automatically. I invite you and @guitargeek to check that what I'm claiming here is correct. The real tutorials are in [`tutorials/roofit`](https://github.com/root-project/root/tree/master/tutorials/roofit). If those files indeed aren't used anywhere (I'm pretty sure they are not), I would suggest to delete them.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8965
https://github.com/root-project/root/pull/8965:108,availability,redund,redundant,108,"Hi @edfink234, thanks for the PR and thanks to @hageboeck for reminding that these `test/rf*.cxx` files are redundant! The tutorials are already tested in unit tests in `stressRooFit`, so we don't need them again in `test`. These files are also badly out of sync, as the last non-trivial change to them was almost 10 years ago. I opened a follow-up PR with the deletion of these files:. https://github.com/root-project/root/pull/11361. This PR can hence be closed, and the translation of the tutorial will be followed up here: https://github.com/root-project/root/pull/9218",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8965
https://github.com/root-project/root/pull/8965:108,deployability,redundan,redundant,108,"Hi @edfink234, thanks for the PR and thanks to @hageboeck for reminding that these `test/rf*.cxx` files are redundant! The tutorials are already tested in unit tests in `stressRooFit`, so we don't need them again in `test`. These files are also badly out of sync, as the last non-trivial change to them was almost 10 years ago. I opened a follow-up PR with the deletion of these files:. https://github.com/root-project/root/pull/11361. This PR can hence be closed, and the translation of the tutorial will be followed up here: https://github.com/root-project/root/pull/9218",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8965
https://github.com/root-project/root/pull/8965:473,integrability,translat,translation,473,"Hi @edfink234, thanks for the PR and thanks to @hageboeck for reminding that these `test/rf*.cxx` files are redundant! The tutorials are already tested in unit tests in `stressRooFit`, so we don't need them again in `test`. These files are also badly out of sync, as the last non-trivial change to them was almost 10 years ago. I opened a follow-up PR with the deletion of these files:. https://github.com/root-project/root/pull/11361. This PR can hence be closed, and the translation of the tutorial will be followed up here: https://github.com/root-project/root/pull/9218",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8965
https://github.com/root-project/root/pull/8965:473,interoperability,translat,translation,473,"Hi @edfink234, thanks for the PR and thanks to @hageboeck for reminding that these `test/rf*.cxx` files are redundant! The tutorials are already tested in unit tests in `stressRooFit`, so we don't need them again in `test`. These files are also badly out of sync, as the last non-trivial change to them was almost 10 years ago. I opened a follow-up PR with the deletion of these files:. https://github.com/root-project/root/pull/11361. This PR can hence be closed, and the translation of the tutorial will be followed up here: https://github.com/root-project/root/pull/9218",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8965
https://github.com/root-project/root/pull/8965:108,reliability,redundan,redundant,108,"Hi @edfink234, thanks for the PR and thanks to @hageboeck for reminding that these `test/rf*.cxx` files are redundant! The tutorials are already tested in unit tests in `stressRooFit`, so we don't need them again in `test`. These files are also badly out of sync, as the last non-trivial change to them was almost 10 years ago. I opened a follow-up PR with the deletion of these files:. https://github.com/root-project/root/pull/11361. This PR can hence be closed, and the translation of the tutorial will be followed up here: https://github.com/root-project/root/pull/9218",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8965
https://github.com/root-project/root/pull/8965:84,safety,test,test,84,"Hi @edfink234, thanks for the PR and thanks to @hageboeck for reminding that these `test/rf*.cxx` files are redundant! The tutorials are already tested in unit tests in `stressRooFit`, so we don't need them again in `test`. These files are also badly out of sync, as the last non-trivial change to them was almost 10 years ago. I opened a follow-up PR with the deletion of these files:. https://github.com/root-project/root/pull/11361. This PR can hence be closed, and the translation of the tutorial will be followed up here: https://github.com/root-project/root/pull/9218",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8965
https://github.com/root-project/root/pull/8965:108,safety,redund,redundant,108,"Hi @edfink234, thanks for the PR and thanks to @hageboeck for reminding that these `test/rf*.cxx` files are redundant! The tutorials are already tested in unit tests in `stressRooFit`, so we don't need them again in `test`. These files are also badly out of sync, as the last non-trivial change to them was almost 10 years ago. I opened a follow-up PR with the deletion of these files:. https://github.com/root-project/root/pull/11361. This PR can hence be closed, and the translation of the tutorial will be followed up here: https://github.com/root-project/root/pull/9218",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8965
https://github.com/root-project/root/pull/8965:145,safety,test,tested,145,"Hi @edfink234, thanks for the PR and thanks to @hageboeck for reminding that these `test/rf*.cxx` files are redundant! The tutorials are already tested in unit tests in `stressRooFit`, so we don't need them again in `test`. These files are also badly out of sync, as the last non-trivial change to them was almost 10 years ago. I opened a follow-up PR with the deletion of these files:. https://github.com/root-project/root/pull/11361. This PR can hence be closed, and the translation of the tutorial will be followed up here: https://github.com/root-project/root/pull/9218",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8965
https://github.com/root-project/root/pull/8965:160,safety,test,tests,160,"Hi @edfink234, thanks for the PR and thanks to @hageboeck for reminding that these `test/rf*.cxx` files are redundant! The tutorials are already tested in unit tests in `stressRooFit`, so we don't need them again in `test`. These files are also badly out of sync, as the last non-trivial change to them was almost 10 years ago. I opened a follow-up PR with the deletion of these files:. https://github.com/root-project/root/pull/11361. This PR can hence be closed, and the translation of the tutorial will be followed up here: https://github.com/root-project/root/pull/9218",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8965
https://github.com/root-project/root/pull/8965:217,safety,test,test,217,"Hi @edfink234, thanks for the PR and thanks to @hageboeck for reminding that these `test/rf*.cxx` files are redundant! The tutorials are already tested in unit tests in `stressRooFit`, so we don't need them again in `test`. These files are also badly out of sync, as the last non-trivial change to them was almost 10 years ago. I opened a follow-up PR with the deletion of these files:. https://github.com/root-project/root/pull/11361. This PR can hence be closed, and the translation of the tutorial will be followed up here: https://github.com/root-project/root/pull/9218",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8965
https://github.com/root-project/root/pull/8965:84,testability,test,test,84,"Hi @edfink234, thanks for the PR and thanks to @hageboeck for reminding that these `test/rf*.cxx` files are redundant! The tutorials are already tested in unit tests in `stressRooFit`, so we don't need them again in `test`. These files are also badly out of sync, as the last non-trivial change to them was almost 10 years ago. I opened a follow-up PR with the deletion of these files:. https://github.com/root-project/root/pull/11361. This PR can hence be closed, and the translation of the tutorial will be followed up here: https://github.com/root-project/root/pull/9218",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8965
https://github.com/root-project/root/pull/8965:145,testability,test,tested,145,"Hi @edfink234, thanks for the PR and thanks to @hageboeck for reminding that these `test/rf*.cxx` files are redundant! The tutorials are already tested in unit tests in `stressRooFit`, so we don't need them again in `test`. These files are also badly out of sync, as the last non-trivial change to them was almost 10 years ago. I opened a follow-up PR with the deletion of these files:. https://github.com/root-project/root/pull/11361. This PR can hence be closed, and the translation of the tutorial will be followed up here: https://github.com/root-project/root/pull/9218",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8965
https://github.com/root-project/root/pull/8965:155,testability,unit,unit,155,"Hi @edfink234, thanks for the PR and thanks to @hageboeck for reminding that these `test/rf*.cxx` files are redundant! The tutorials are already tested in unit tests in `stressRooFit`, so we don't need them again in `test`. These files are also badly out of sync, as the last non-trivial change to them was almost 10 years ago. I opened a follow-up PR with the deletion of these files:. https://github.com/root-project/root/pull/11361. This PR can hence be closed, and the translation of the tutorial will be followed up here: https://github.com/root-project/root/pull/9218",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8965
https://github.com/root-project/root/pull/8965:160,testability,test,tests,160,"Hi @edfink234, thanks for the PR and thanks to @hageboeck for reminding that these `test/rf*.cxx` files are redundant! The tutorials are already tested in unit tests in `stressRooFit`, so we don't need them again in `test`. These files are also badly out of sync, as the last non-trivial change to them was almost 10 years ago. I opened a follow-up PR with the deletion of these files:. https://github.com/root-project/root/pull/11361. This PR can hence be closed, and the translation of the tutorial will be followed up here: https://github.com/root-project/root/pull/9218",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8965
https://github.com/root-project/root/pull/8965:217,testability,test,test,217,"Hi @edfink234, thanks for the PR and thanks to @hageboeck for reminding that these `test/rf*.cxx` files are redundant! The tutorials are already tested in unit tests in `stressRooFit`, so we don't need them again in `test`. These files are also badly out of sync, as the last non-trivial change to them was almost 10 years ago. I opened a follow-up PR with the deletion of these files:. https://github.com/root-project/root/pull/11361. This PR can hence be closed, and the translation of the tutorial will be followed up here: https://github.com/root-project/root/pull/9218",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8965
https://github.com/root-project/root/pull/8965:457,usability,close,closed,457,"Hi @edfink234, thanks for the PR and thanks to @hageboeck for reminding that these `test/rf*.cxx` files are redundant! The tutorials are already tested in unit tests in `stressRooFit`, so we don't need them again in `test`. These files are also badly out of sync, as the last non-trivial change to them was almost 10 years ago. I opened a follow-up PR with the deletion of these files:. https://github.com/root-project/root/pull/11361. This PR can hence be closed, and the translation of the tutorial will be followed up here: https://github.com/root-project/root/pull/9218",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8965
https://github.com/root-project/root/pull/8971:69,modifiability,paramet,parameters,69,"I made the changes required by Enric. Now the script takes two input parameters and generates the `.pyzdoc` files directly in the right place. No need to move them afterwards, Can you approve please ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8971
https://github.com/root-project/root/pull/8971:63,safety,input,input,63,"I made the changes required by Enric. Now the script takes two input parameters and generates the `.pyzdoc` files directly in the right place. No need to move them afterwards, Can you approve please ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8971
https://github.com/root-project/root/pull/8971:63,usability,input,input,63,"I made the changes required by Enric. Now the script takes two input parameters and generates the `.pyzdoc` files directly in the right place. No need to move them afterwards, Can you approve please ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8971
https://github.com/root-project/root/issues/8973:217,deployability,stack,stack,217,"The keyword arg functionality that you are trying to use has only been added recently (it's not in 6.22.08). @guitargeek can perhaps elaborate. If you run the tutorial you mentioned in SWAN and you select as software stack ""Bleeding Edge"" (which has ROOT master), you will see that it runs fine.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8973
https://github.com/root-project/root/issues/8973:144,availability,down,download,144,"Thanks @etejedor. Indeed, it works for the ""Bleeding Edge"" (root v6.25). I tried to update my root version in my desktop but I see I could only download up to 6.24.06. Is there a way for me to run the bleeding edge version locally or in a cluster? (Apart from using SWAN?) . I also see that the tutorial has been taken down. Perhaps someone is working on it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8973
https://github.com/root-project/root/issues/8973:239,availability,cluster,cluster,239,"Thanks @etejedor. Indeed, it works for the ""Bleeding Edge"" (root v6.25). I tried to update my root version in my desktop but I see I could only download up to 6.24.06. Is there a way for me to run the bleeding edge version locally or in a cluster? (Apart from using SWAN?) . I also see that the tutorial has been taken down. Perhaps someone is working on it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8973
https://github.com/root-project/root/issues/8973:319,availability,down,down,319,"Thanks @etejedor. Indeed, it works for the ""Bleeding Edge"" (root v6.25). I tried to update my root version in my desktop but I see I could only download up to 6.24.06. Is there a way for me to run the bleeding edge version locally or in a cluster? (Apart from using SWAN?) . I also see that the tutorial has been taken down. Perhaps someone is working on it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8973
https://github.com/root-project/root/issues/8973:84,deployability,updat,update,84,"Thanks @etejedor. Indeed, it works for the ""Bleeding Edge"" (root v6.25). I tried to update my root version in my desktop but I see I could only download up to 6.24.06. Is there a way for me to run the bleeding edge version locally or in a cluster? (Apart from using SWAN?) . I also see that the tutorial has been taken down. Perhaps someone is working on it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8973
https://github.com/root-project/root/issues/8973:99,deployability,version,version,99,"Thanks @etejedor. Indeed, it works for the ""Bleeding Edge"" (root v6.25). I tried to update my root version in my desktop but I see I could only download up to 6.24.06. Is there a way for me to run the bleeding edge version locally or in a cluster? (Apart from using SWAN?) . I also see that the tutorial has been taken down. Perhaps someone is working on it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8973
https://github.com/root-project/root/issues/8973:215,deployability,version,version,215,"Thanks @etejedor. Indeed, it works for the ""Bleeding Edge"" (root v6.25). I tried to update my root version in my desktop but I see I could only download up to 6.24.06. Is there a way for me to run the bleeding edge version locally or in a cluster? (Apart from using SWAN?) . I also see that the tutorial has been taken down. Perhaps someone is working on it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8973
https://github.com/root-project/root/issues/8973:239,deployability,cluster,cluster,239,"Thanks @etejedor. Indeed, it works for the ""Bleeding Edge"" (root v6.25). I tried to update my root version in my desktop but I see I could only download up to 6.24.06. Is there a way for me to run the bleeding edge version locally or in a cluster? (Apart from using SWAN?) . I also see that the tutorial has been taken down. Perhaps someone is working on it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8973
https://github.com/root-project/root/issues/8973:99,integrability,version,version,99,"Thanks @etejedor. Indeed, it works for the ""Bleeding Edge"" (root v6.25). I tried to update my root version in my desktop but I see I could only download up to 6.24.06. Is there a way for me to run the bleeding edge version locally or in a cluster? (Apart from using SWAN?) . I also see that the tutorial has been taken down. Perhaps someone is working on it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8973
https://github.com/root-project/root/issues/8973:215,integrability,version,version,215,"Thanks @etejedor. Indeed, it works for the ""Bleeding Edge"" (root v6.25). I tried to update my root version in my desktop but I see I could only download up to 6.24.06. Is there a way for me to run the bleeding edge version locally or in a cluster? (Apart from using SWAN?) . I also see that the tutorial has been taken down. Perhaps someone is working on it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8973
https://github.com/root-project/root/issues/8973:99,modifiability,version,version,99,"Thanks @etejedor. Indeed, it works for the ""Bleeding Edge"" (root v6.25). I tried to update my root version in my desktop but I see I could only download up to 6.24.06. Is there a way for me to run the bleeding edge version locally or in a cluster? (Apart from using SWAN?) . I also see that the tutorial has been taken down. Perhaps someone is working on it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8973
https://github.com/root-project/root/issues/8973:215,modifiability,version,version,215,"Thanks @etejedor. Indeed, it works for the ""Bleeding Edge"" (root v6.25). I tried to update my root version in my desktop but I see I could only download up to 6.24.06. Is there a way for me to run the bleeding edge version locally or in a cluster? (Apart from using SWAN?) . I also see that the tutorial has been taken down. Perhaps someone is working on it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8973
https://github.com/root-project/root/issues/8973:84,safety,updat,update,84,"Thanks @etejedor. Indeed, it works for the ""Bleeding Edge"" (root v6.25). I tried to update my root version in my desktop but I see I could only download up to 6.24.06. Is there a way for me to run the bleeding edge version locally or in a cluster? (Apart from using SWAN?) . I also see that the tutorial has been taken down. Perhaps someone is working on it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8973
https://github.com/root-project/root/issues/8973:84,security,updat,update,84,"Thanks @etejedor. Indeed, it works for the ""Bleeding Edge"" (root v6.25). I tried to update my root version in my desktop but I see I could only download up to 6.24.06. Is there a way for me to run the bleeding edge version locally or in a cluster? (Apart from using SWAN?) . I also see that the tutorial has been taken down. Perhaps someone is working on it?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8973
https://github.com/root-project/root/issues/8973:20,deployability,releas,released,20,"The feature will be released with 6.26, if you want to use it now in your local computer you can install ROOT master:. https://root.cern/install/nightlies/. The tutorial should be back now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8973
https://github.com/root-project/root/issues/8973:97,deployability,instal,install,97,"The feature will be released with 6.26, if you want to use it now in your local computer you can install ROOT master:. https://root.cern/install/nightlies/. The tutorial should be back now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8973
https://github.com/root-project/root/issues/8973:137,deployability,instal,install,137,"The feature will be released with 6.26, if you want to use it now in your local computer you can install ROOT master:. https://root.cern/install/nightlies/. The tutorial should be back now.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8973
https://github.com/root-project/root/issues/8973:64,usability,close,close,64,Thanks to @etejedor for explaining what's going on here! We can close this issue then.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8973
https://github.com/root-project/root/pull/8974:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu2004/default with flags -Dtmva-sofie=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8974
https://github.com/root-project/root/pull/8974:34,usability,support,support,34,"Closing this, as we already added support in PR #9666 and PR #9119",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8974
https://github.com/root-project/root/pull/8975:23,reliability,doe,doesn,23,I wonder though why it doesn't appear in our CI and how we could have made it appear,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8975
https://github.com/root-project/root/pull/8975:120,availability,error,error,120,"> why it doesn't appear in our CI. i don't know, but this is undefined behavior so it's fairly hard to say -- i see the error on my laptop",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8975
https://github.com/root-project/root/pull/8975:120,performance,error,error,120,"> why it doesn't appear in our CI. i don't know, but this is undefined behavior so it's fairly hard to say -- i see the error on my laptop",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8975
https://github.com/root-project/root/pull/8975:9,reliability,doe,doesn,9,"> why it doesn't appear in our CI. i don't know, but this is undefined behavior so it's fairly hard to say -- i see the error on my laptop",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8975
https://github.com/root-project/root/pull/8975:120,safety,error,error,120,"> why it doesn't appear in our CI. i don't know, but this is undefined behavior so it's fairly hard to say -- i see the error on my laptop",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8975
https://github.com/root-project/root/pull/8975:71,usability,behavi,behavior,71,"> why it doesn't appear in our CI. i don't know, but this is undefined behavior so it's fairly hard to say -- i see the error on my laptop",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8975
https://github.com/root-project/root/pull/8975:120,usability,error,error,120,"> why it doesn't appear in our CI. i don't know, but this is undefined behavior so it's fairly hard to say -- i see the error on my laptop",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8975
https://github.com/root-project/root/issues/8976:51,integrability,interfac,interface,51,"You are right! I was not taking care about the new interface being backwards compatible, because these constructors are considered as RooFit internal. But of course it doesn't hurt to make them backwards compatible either :). I opened a PR to do that: https://github.com/root-project/root/pull/8986",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8976
https://github.com/root-project/root/issues/8976:51,interoperability,interfac,interface,51,"You are right! I was not taking care about the new interface being backwards compatible, because these constructors are considered as RooFit internal. But of course it doesn't hurt to make them backwards compatible either :). I opened a PR to do that: https://github.com/root-project/root/pull/8986",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8976
https://github.com/root-project/root/issues/8976:77,interoperability,compatib,compatible,77,"You are right! I was not taking care about the new interface being backwards compatible, because these constructors are considered as RooFit internal. But of course it doesn't hurt to make them backwards compatible either :). I opened a PR to do that: https://github.com/root-project/root/pull/8986",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8976
https://github.com/root-project/root/issues/8976:204,interoperability,compatib,compatible,204,"You are right! I was not taking care about the new interface being backwards compatible, because these constructors are considered as RooFit internal. But of course it doesn't hurt to make them backwards compatible either :). I opened a PR to do that: https://github.com/root-project/root/pull/8986",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8976
https://github.com/root-project/root/issues/8976:51,modifiability,interfac,interface,51,"You are right! I was not taking care about the new interface being backwards compatible, because these constructors are considered as RooFit internal. But of course it doesn't hurt to make them backwards compatible either :). I opened a PR to do that: https://github.com/root-project/root/pull/8986",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8976
https://github.com/root-project/root/issues/8976:168,reliability,doe,doesn,168,"You are right! I was not taking care about the new interface being backwards compatible, because these constructors are considered as RooFit internal. But of course it doesn't hurt to make them backwards compatible either :). I opened a PR to do that: https://github.com/root-project/root/pull/8986",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8976
https://github.com/root-project/root/issues/8981:255,deployability,Build,Build,255,I am confused ... how can the `this` pointer be null in a virtual function? Why does it complains only about this line (and not all the other lines above and below)? Is there some context missing (and the problem is really a caller of the `TStreamerInfo::Build` function)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8981
https://github.com/root-project/root/issues/8981:80,reliability,doe,does,80,I am confused ... how can the `this` pointer be null in a virtual function? Why does it complains only about this line (and not all the other lines above and below)? Is there some context missing (and the problem is really a caller of the `TStreamerInfo::Build` function)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8981
https://github.com/root-project/root/issues/8981:88,safety,compl,complains,88,I am confused ... how can the `this` pointer be null in a virtual function? Why does it complains only about this line (and not all the other lines above and below)? Is there some context missing (and the problem is really a caller of the `TStreamerInfo::Build` function)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8981
https://github.com/root-project/root/issues/8981:88,security,compl,complains,88,I am confused ... how can the `this` pointer be null in a virtual function? Why does it complains only about this line (and not all the other lines above and below)? Is there some context missing (and the problem is really a caller of the `TStreamerInfo::Build` function)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8981
https://github.com/root-project/root/issues/8981:180,testability,context,context,180,I am confused ... how can the `this` pointer be null in a virtual function? Why does it complains only about this line (and not all the other lines above and below)? Is there some context missing (and the problem is really a caller of the `TStreamerInfo::Build` function)?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8981
https://github.com/root-project/root/issues/8984:42,performance,time,time,42,Thank you. Good luck to Jonas if he finds time for the investigation.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:140,deployability,version,version,140,"Hi, I'm glad you asked! I tried to reproduce this issue myself a few weeks ago actually, but I couldn't see the memory increase. Which ROOT version are you using? If this is still a problem for you with the current ROOT version, I will continue the investigation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:220,deployability,version,version,220,"Hi, I'm glad you asked! I tried to reproduce this issue myself a few weeks ago actually, but I couldn't see the memory increase. Which ROOT version are you using? If this is still a problem for you with the current ROOT version, I will continue the investigation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:236,deployability,continu,continue,236,"Hi, I'm glad you asked! I tried to reproduce this issue myself a few weeks ago actually, but I couldn't see the memory increase. Which ROOT version are you using? If this is still a problem for you with the current ROOT version, I will continue the investigation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:207,energy efficiency,current,current,207,"Hi, I'm glad you asked! I tried to reproduce this issue myself a few weeks ago actually, but I couldn't see the memory increase. Which ROOT version are you using? If this is still a problem for you with the current ROOT version, I will continue the investigation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:140,integrability,version,version,140,"Hi, I'm glad you asked! I tried to reproduce this issue myself a few weeks ago actually, but I couldn't see the memory increase. Which ROOT version are you using? If this is still a problem for you with the current ROOT version, I will continue the investigation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:220,integrability,version,version,220,"Hi, I'm glad you asked! I tried to reproduce this issue myself a few weeks ago actually, but I couldn't see the memory increase. Which ROOT version are you using? If this is still a problem for you with the current ROOT version, I will continue the investigation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:140,modifiability,version,version,140,"Hi, I'm glad you asked! I tried to reproduce this issue myself a few weeks ago actually, but I couldn't see the memory increase. Which ROOT version are you using? If this is still a problem for you with the current ROOT version, I will continue the investigation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:220,modifiability,version,version,220,"Hi, I'm glad you asked! I tried to reproduce this issue myself a few weeks ago actually, but I couldn't see the memory increase. Which ROOT version are you using? If this is still a problem for you with the current ROOT version, I will continue the investigation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:112,performance,memor,memory,112,"Hi, I'm glad you asked! I tried to reproduce this issue myself a few weeks ago actually, but I couldn't see the memory increase. Which ROOT version are you using? If this is still a problem for you with the current ROOT version, I will continue the investigation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:112,usability,memor,memory,112,"Hi, I'm glad you asked! I tried to reproduce this issue myself a few weeks ago actually, but I couldn't see the memory increase. Which ROOT version are you using? If this is still a problem for you with the current ROOT version, I will continue the investigation.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:668,availability,cluster,cluster,668,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:45,deployability,version,version,45,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:668,deployability,cluster,cluster,668,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:322,energy efficiency,reduc,reduce,322,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:45,integrability,version,version,45,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:45,modifiability,version,version,45,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:179,performance,memor,memory,179,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:333,performance,memor,memory,333,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:430,performance,memor,memory,430,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:464,performance,memor,memory,464,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:519,performance,memor,memory,519,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:591,performance,memor,memory,591,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:625,performance,memor,memory,625,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:799,performance,memor,memory,799,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:833,performance,memor,memory,833,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:888,performance,memor,memory,888,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:960,performance,memor,memory,960,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:994,performance,memor,memory,994,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:313,reliability,doe,does,313,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:526,reliability,doe,does,526,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:895,reliability,doe,does,895,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:179,usability,memor,memory,179,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:333,usability,memor,memory,333,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:430,usability,memor,memory,430,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:464,usability,memor,memory,464,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:519,usability,memor,memory,519,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:591,usability,memor,memory,591,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:625,usability,memor,memory,625,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:799,usability,memor,memory,799,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:833,usability,memor,memory,833,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:888,usability,memor,memory,888,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:960,usability,memor,memory,960,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:994,usability,memor,memory,994,"Thank you. I was using root 6.18.00. . Which version of root do you use without having the problem ? Could you check that in ""EXAMPLE Of PROBLEM"", you really have a *decrease* of memory consumption ? I tried again (same problem). -on lxplus, with root 6.20.02 : same problem. proof : the deletion of a RooDataSet does not reduce the memory consuption :. just after creation of dataset toy that uses previous toy per category. res memory=243.1718750000 Mbytes. vir memory=568.2500000000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=243.3007812500 Mbytes. vir memory=568.2500000000 Mbytes. -on a french cluster of computer, with root 6.26.04 : same problem. just after creation of dataset toy that uses previous toy per category. res memory=315.2851562500 Mbytes. vir memory=711.7109375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=315.3359375000 Mbytes. vir memory=711.7109375000 Mbytes.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:156,energy efficiency,alloc,allocated,156,"To summarize : the problem is not a memory increase, but the fact that when we delete the RooDataSet,. so there is an intrinsic memory leak of roofit : the allocated memory is not given back to the system when we delete the RooDataset.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:36,performance,memor,memory,36,"To summarize : the problem is not a memory increase, but the fact that when we delete the RooDataSet,. so there is an intrinsic memory leak of roofit : the allocated memory is not given back to the system when we delete the RooDataset.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:128,performance,memor,memory,128,"To summarize : the problem is not a memory increase, but the fact that when we delete the RooDataSet,. so there is an intrinsic memory leak of roofit : the allocated memory is not given back to the system when we delete the RooDataset.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:166,performance,memor,memory,166,"To summarize : the problem is not a memory increase, but the fact that when we delete the RooDataSet,. so there is an intrinsic memory leak of roofit : the allocated memory is not given back to the system when we delete the RooDataset.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:36,usability,memor,memory,36,"To summarize : the problem is not a memory increase, but the fact that when we delete the RooDataSet,. so there is an intrinsic memory leak of roofit : the allocated memory is not given back to the system when we delete the RooDataset.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:128,usability,memor,memory,128,"To summarize : the problem is not a memory increase, but the fact that when we delete the RooDataSet,. so there is an intrinsic memory leak of roofit : the allocated memory is not given back to the system when we delete the RooDataset.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:166,usability,memor,memory,166,"To summarize : the problem is not a memory increase, but the fact that when we delete the RooDataSet,. so there is an intrinsic memory leak of roofit : the allocated memory is not given back to the system when we delete the RooDataset.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:226,deployability,build,build,226,"Okay! Then it's very likely related to the memory pool, which will be disabled in ROOT 6.28 as of this PR:. https://github.com/root-project/root/pull/8324. Can you please try if you still see you problem with the ROOT nighlty build? https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:251,deployability,instal,install,251,"Okay! Then it's very likely related to the memory pool, which will be disabled in ROOT 6.28 as of this PR:. https://github.com/root-project/root/pull/8324. Can you please try if you still see you problem with the ROOT nighlty build? https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:43,performance,memor,memory,43,"Okay! Then it's very likely related to the memory pool, which will be disabled in ROOT 6.28 as of this PR:. https://github.com/root-project/root/pull/8324. Can you please try if you still see you problem with the ROOT nighlty build? https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:43,usability,memor,memory,43,"Okay! Then it's very likely related to the memory pool, which will be disabled in ROOT 6.28 as of this PR:. https://github.com/root-project/root/pull/8324. Can you please try if you still see you problem with the ROOT nighlty build? https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:273,availability,escal,escalier,273,"I tried to setup a nightly version of root, following your suggestion :. source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos7-gcc8-opt/setup.sh. but this gives :. root --version. ROOT Version: 6.24/08. and then the program does not work. ```. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"". ------------------------------------------------------------------. | Welcome to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:900,availability,escal,escalier,900,"I tried to setup a nightly version of root, following your suggestion :. source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos7-gcc8-opt/setup.sh. but this gives :. root --version. ROOT Version: 6.24/08. and then the program does not work. ```. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"". ------------------------------------------------------------------. | Welcome to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1445,availability,escal,escalier,1445,"ern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1762,availability,escal,escalier,1762,"-------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In fu",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1945,availability,escal,escalier,1945,"_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2413,availability,escal,escalier,2413,"anford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RooDataSet*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, RooDataSet*> > > const&)'. collect2: error: ld returned 1 exit status. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2697,availability,escal,escalier,2697,"anford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RooDataSet*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, RooDataSet*> > > const&)'. collect2: error: ld returned 1 exit status. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2807,availability,escal,escalier,2807,"anford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RooDataSet*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, RooDataSet*> > > const&)'. collect2: error: ld returned 1 exit status. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3248,availability,error,error,3248,"anford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RooDataSet*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, RooDataSet*> > > const&)'. collect2: error: ld returned 1 exit status. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:27,deployability,version,version,27,"I tried to setup a nightly version of root, following your suggestion :. source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos7-gcc8-opt/setup.sh. but this gives :. root --version. ROOT Version: 6.24/08. and then the program does not work. ```. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"". ------------------------------------------------------------------. | Welcome to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:180,deployability,version,version,180,"I tried to setup a nightly version of root, following your suggestion :. source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos7-gcc8-opt/setup.sh. but this gives :. root --version. ROOT Version: 6.24/08. and then the program does not work. ```. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"". ------------------------------------------------------------------. | Welcome to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:194,deployability,Version,Version,194,"I tried to setup a nightly version of root, following your suggestion :. source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos7-gcc8-opt/setup.sh. but this gives :. root --version. ROOT Version: 6.24/08. and then the program does not work. ```. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"". ------------------------------------------------------------------. | Welcome to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1136,deployability,version,version,1136,"-opt/setup.sh. but this gives :. root --version. ROOT Version: 6.24/08. and then the program does not work. ```. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"". ------------------------------------------------------------------. | Welcome to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1410,energy efficiency,load,loadLibrary,1410,"me to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/esc",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2223,energy efficiency,alloc,allocator,2223,"right (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RooDataSet*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, RooDataSet*> > > ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2253,energy efficiency,alloc,allocator,2253,"iversity of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RooDataSet*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, RooDataSet*> > > const&)'. collect2: error: ld ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2335,energy efficiency,alloc,allocator,2335,"anford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RooDataSet*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, RooDataSet*> > > const&)'. collect2: error: ld returned 1 exit status. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2649,energy efficiency,alloc,allocator,2649,"anford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RooDataSet*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, RooDataSet*> > > const&)'. collect2: error: ld returned 1 exit status. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2974,energy efficiency,alloc,allocator,2974,"anford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RooDataSet*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, RooDataSet*> > > const&)'. collect2: error: ld returned 1 exit status. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3078,energy efficiency,alloc,allocator,3078,"anford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RooDataSet*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, RooDataSet*> > > const&)'. collect2: error: ld returned 1 exit status. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3104,energy efficiency,alloc,allocator,3104,"anford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RooDataSet*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, RooDataSet*> > > const&)'. collect2: error: ld returned 1 exit status. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3186,energy efficiency,alloc,allocator,3186,"anford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RooDataSet*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, RooDataSet*> > > const&)'. collect2: error: ld returned 1 exit status. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:27,integrability,version,version,27,"I tried to setup a nightly version of root, following your suggestion :. source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos7-gcc8-opt/setup.sh. but this gives :. root --version. ROOT Version: 6.24/08. and then the program does not work. ```. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"". ------------------------------------------------------------------. | Welcome to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:180,integrability,version,version,180,"I tried to setup a nightly version of root, following your suggestion :. source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos7-gcc8-opt/setup.sh. but this gives :. root --version. ROOT Version: 6.24/08. and then the program does not work. ```. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"". ------------------------------------------------------------------. | Welcome to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:194,integrability,Version,Version,194,"I tried to setup a nightly version of root, following your suggestion :. source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos7-gcc8-opt/setup.sh. but this gives :. root --version. ROOT Version: 6.24/08. and then the program does not work. ```. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"". ------------------------------------------------------------------. | Welcome to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:282,integrability,pub,public,282,"I tried to setup a nightly version of root, following your suggestion :. source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos7-gcc8-opt/setup.sh. but this gives :. root --version. ROOT Version: 6.24/08. and then the program does not work. ```. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"". ------------------------------------------------------------------. | Welcome to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:909,integrability,pub,public,909,"I tried to setup a nightly version of root, following your suggestion :. source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos7-gcc8-opt/setup.sh. but this gives :. root --version. ROOT Version: 6.24/08. and then the program does not work. ```. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"". ------------------------------------------------------------------. | Welcome to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1136,integrability,version,version,1136,"-opt/setup.sh. but this gives :. root --version. ROOT Version: 6.24/08. and then the program does not work. ```. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"". ------------------------------------------------------------------. | Welcome to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1454,integrability,pub,public,1454," (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Mini",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1771,integrability,pub,public,1771,"-----------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1954,integrability,pub,public,1954,"arning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std::char_tr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2422,integrability,pub,public,2422,"anford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RooDataSet*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, RooDataSet*> > > const&)'. collect2: error: ld returned 1 exit status. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2706,integrability,pub,public,2706,"anford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RooDataSet*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, RooDataSet*> > > const&)'. collect2: error: ld returned 1 exit status. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2816,integrability,pub,public,2816,"anford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RooDataSet*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, RooDataSet*> > > const&)'. collect2: error: ld returned 1 exit status. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:865,interoperability,share,shared,865,"I tried to setup a nightly version of root, following your suggestion :. source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos7-gcc8-opt/setup.sh. but this gives :. root --version. ROOT Version: 6.24/08. and then the program does not work. ```. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"". ------------------------------------------------------------------. | Welcome to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1032,interoperability,standard,standard,1032,"f root, following your suggestion :. source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos7-gcc8-opt/setup.sh. but this gives :. root --version. ROOT Version: 6.24/08. and then the program does not work. ```. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"". ------------------------------------------------------------------. | Welcome to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1049,interoperability,mismatch,mismatch,1049," your suggestion :. source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos7-gcc8-opt/setup.sh. but this gives :. root --version. ROOT Version: 6.24/08. and then the program does not work. ```. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"". ------------------------------------------------------------------. | Welcome to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::Register",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1119,interoperability,standard,standard,1119,"6_64-centos7-gcc8-opt/setup.sh. but this gives :. root --version. ROOT Version: 6.24/08. and then the program does not work. ```. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"". ------------------------------------------------------------------. | Welcome to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char cons",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:27,modifiability,version,version,27,"I tried to setup a nightly version of root, following your suggestion :. source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos7-gcc8-opt/setup.sh. but this gives :. root --version. ROOT Version: 6.24/08. and then the program does not work. ```. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"". ------------------------------------------------------------------. | Welcome to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:180,modifiability,version,version,180,"I tried to setup a nightly version of root, following your suggestion :. source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos7-gcc8-opt/setup.sh. but this gives :. root --version. ROOT Version: 6.24/08. and then the program does not work. ```. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"". ------------------------------------------------------------------. | Welcome to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:194,modifiability,Version,Version,194,"I tried to setup a nightly version of root, following your suggestion :. source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos7-gcc8-opt/setup.sh. but this gives :. root --version. ROOT Version: 6.24/08. and then the program does not work. ```. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"". ------------------------------------------------------------------. | Welcome to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1136,modifiability,version,version,1136,"-opt/setup.sh. but this gives :. root --version. ROOT Version: 6.24/08. and then the program does not work. ```. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"". ------------------------------------------------------------------. | Welcome to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), s",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1410,performance,load,loadLibrary,1410,"me to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/esc",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3248,performance,error,error,3248,"anford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RooDataSet*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, RooDataSet*> > > const&)'. collect2: error: ld returned 1 exit status. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:233,reliability,doe,does,233,"I tried to setup a nightly version of root, following your suggestion :. source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos7-gcc8-opt/setup.sh. but this gives :. root --version. ROOT Version: 6.24/08. and then the program does not work. ```. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"". ------------------------------------------------------------------. | Welcome to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3248,safety,error,error,3248,"anford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RooDataSet*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, RooDataSet*> > > const&)'. collect2: error: ld returned 1 exit status. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:273,security,escal,escalier,273,"I tried to setup a nightly version of root, following your suggestion :. source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos7-gcc8-opt/setup.sh. but this gives :. root --version. ROOT Version: 6.24/08. and then the program does not work. ```. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"". ------------------------------------------------------------------. | Welcome to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:482,security,Team,Team,482,"I tried to setup a nightly version of root, following your suggestion :. source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos7-gcc8-opt/setup.sh. but this gives :. root --version. ROOT Version: 6.24/08. and then the program does not work. ```. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"". ------------------------------------------------------------------. | Welcome to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:900,security,escal,escalier,900,"I tried to setup a nightly version of root, following your suggestion :. source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos7-gcc8-opt/setup.sh. but this gives :. root --version. ROOT Version: 6.24/08. and then the program does not work. ```. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"". ------------------------------------------------------------------. | Welcome to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1445,security,escal,escalier,1445,"ern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1762,security,escal,escalier,1762,"-------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In fu",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1945,security,escal,escalier,1945,"_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std:",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2413,security,escal,escalier,2413,"anford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RooDataSet*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, RooDataSet*> > > const&)'. collect2: error: ld returned 1 exit status. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2697,security,escal,escalier,2697,"anford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RooDataSet*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, RooDataSet*> > > const&)'. collect2: error: ld returned 1 exit status. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2807,security,escal,escalier,2807,"anford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RooDataSet*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, RooDataSet*> > > const&)'. collect2: error: ld returned 1 exit status. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:326,usability,Minim,Minimum,326,"I tried to setup a nightly version of root, following your suggestion :. source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos7-gcc8-opt/setup.sh. but this gives :. root --version. ROOT Version: 6.24/08. and then the program does not work. ```. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"". ------------------------------------------------------------------. | Welcome to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:675,usability,help,help,675,"I tried to setup a nightly version of root, following your suggestion :. source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos7-gcc8-opt/setup.sh. but this gives :. root --version. ROOT Version: 6.24/08. and then the program does not work. ```. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"". ------------------------------------------------------------------. | Welcome to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:810,usability,Minim,Minimum,810,"I tried to setup a nightly version of root, following your suggestion :. source /cvmfs/sft.cern.ch/lcg/views/dev3/latest/x86_64-centos7-gcc8-opt/setup.sh. but this gives :. root --version. ROOT Version: 6.24/08. and then the program does not work. ```. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"". ------------------------------------------------------------------. | Welcome to ROOT 6.24/08 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 29 2022, 13:04:57 |. | From tags/v6-24-08@v6-24-08 |. | With c++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44) |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Warning in cling::IncrementalParser::CheckABICompatibility():. Possible C++ standard library mismatch, compiled with __GLIBCXX__ '20150623'. Extraction of runtime standard library version was: '20190222'. RooFit v3.60 -- Developed by Wouter Verkerke and David Kirkby. Copyright (C) 2000-2013 NIKHEF, University of California & Stanford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2490,usability,Minim,Minimum,2490,"anford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RooDataSet*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, RooDataSet*> > > const&)'. collect2: error: ld returned 1 exit status. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2774,usability,Minim,Minimum,2774,"anford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RooDataSet*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, RooDataSet*> > > const&)'. collect2: error: ld returned 1 exit status. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2849,usability,Minim,Minimum,2849,"anford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RooDataSet*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, RooDataSet*> > > const&)'. collect2: error: ld returned 1 exit status. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3248,usability,error,error,3248,"anford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RooDataSet*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, RooDataSet*> > > const&)'. collect2: error: ld returned 1 exit status. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3274,usability,statu,status,3274,"anford University. All rights reserved, please read http://roofit.sourceforge.net/license.txt. cling::DynamicLibraryManager::loadLibrary(): /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C.so: undefined symbol: _ZN5TROOT14RegisterModuleEPKcPS1_S2_S1_S1_PFvvERKSt6vectorISt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiESaISD_EES2_b. /lib/../lib64/crt1.o: In function `_start':. (.text+0x20): undefined reference to `main'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `(anonymous namespace)::TriggerDictionaryInitialization_Minimum_C_ACLiC_dict_Impl()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.cxx:94: undefined reference to `TROOT::RegisterModule(char const*, char const**, char const**, char const*, char const*, void (*)(), std::vector<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> > > const&, char const**, bool)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /usr/include/root/RooCategory.h:60: undefined reference to `RooCategory::defineType(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)'. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/Minimum_C_ACLiC_dict.o: In function `Minimum()':. /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum.C:307: undefined reference to `RooFit::Import(std::map<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, RooDataSet*, std::less<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const, RooDataSet*> > > const&)'. collect2: error: ld returned 1 exit status. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1437,energy efficiency,current,current,1437,".demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2497,energy efficiency,current,current,2497,". vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3558,energy efficiency,current,current,3558,". vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4619,energy efficiency,current,current,4619,". vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5680,energy efficiency,current,current,5680,". vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:598,performance,Memor,Memory,598,"Oh well, I don't know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:632,performance,memor,memory,632,"Oh well, I don't know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:659,performance,memor,memory,659,"Oh well, I don't know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:689,performance,Memor,Memory,689,"Oh well, I don't know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:718,performance,memor,memory,718,"Oh well, I don't know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:745,performance,memor,memory,745,"Oh well, I don't know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:775,performance,Memor,Memory,775,"Oh well, I don't know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:814,performance,memor,memory,814,"Oh well, I don't know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:840,performance,memor,memory,840,"Oh well, I don't know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:914,performance,Memor,Memory,914,"Oh well, I don't know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:956,performance,memor,memory,956,"Oh well, I don't know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:982,performance,memor,memory,982,"Oh well, I don't know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1012,performance,Memor,Memory,1012,"t know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1050,performance,memor,memory,1050,"onment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1076,performance,memor,memory,1076,"s? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1299,performance,Memor,Memory,1299,"linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1311,performance,memor,memory,1311,"c on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1337,performance,memor,memory,1337," |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. in",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1481,performance,memor,memory,1481,"' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e914",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1507,performance,memor,memory,1507,"---------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current categ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1555,performance,memor,memory,1555,"oot [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mb",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1582,performance,memor,memory,1582,".C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mb",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1997,performance,memor,memory,1997,"tes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creatio",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2031,performance,memor,memory,2031,"utput file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previou",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2086,performance,memor,memory,2086,"8 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. v",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2158,performance,memor,memory,2158,"H,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does no",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2192,performance,memor,memory,2192,"BFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2274,performance,memor,memory,2274,". index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mb",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2308,performance,memor,memory,2308,"memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after d",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2358,performance,Memor,Memory,2358,"tart randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbyt",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2370,performance,memor,memory,2370,"zation. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2397,performance,memor,memory,2397,"ant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. i",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2541,performance,memor,memory,2541,"erate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2568,performance,memor,memory,2568,"bytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current categ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2616,performance,memor,memory,2616,">GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mb",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2643,performance,memor,memory,2643,"5. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mb",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3058,performance,memor,memory,3058,"EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creatio",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3092,performance,memor,memory,3092,"es not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previou",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3147,performance,memor,memory,3147,"ry. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. v",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3219,performance,memor,memory,3219,"delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does no",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3253,performance,memor,memory,3253,"n of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3335,performance,memor,memory,3335,"index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mb",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3369,performance,memor,memory,3369,"mory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after d",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3419,performance,Memor,Memory,3419,"art randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbyt",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3431,performance,memor,memory,3431,"ation. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3458,performance,memor,memory,3458,"nt. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. i",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3602,performance,memor,memory,3602,"erate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3629,performance,memor,memory,3629,"bytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current categ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3677,performance,memor,memory,3677,">GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mb",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3704,performance,memor,memory,3704,"8. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mb",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4119,performance,memor,memory,4119,"EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creatio",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4153,performance,memor,memory,4153,"es not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previou",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4208,performance,memor,memory,4208,"ry. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. v",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4280,performance,memor,memory,4280,"delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does no",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4314,performance,memor,memory,4314,"n of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4396,performance,memor,memory,4396,"index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mb",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4430,performance,memor,memory,4430,"mory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after d",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4480,performance,Memor,Memory,4480,"art randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbyt",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4492,performance,memor,memory,4492,"ation. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4519,performance,memor,memory,4519,"nt. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. i",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4663,performance,memor,memory,4663,"erate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4690,performance,memor,memory,4690,"bytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current categ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4738,performance,memor,memory,4738,">GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mb",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4765,performance,memor,memory,4765,"3. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mb",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5180,performance,memor,memory,5180,"EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creatio",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5214,performance,memor,memory,5214,"es not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previou",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5269,performance,memor,memory,5269,"ry. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. v",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5341,performance,memor,memory,5341,"delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does no",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5375,performance,memor,memory,5375,"n of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5457,performance,memor,memory,5457,"index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mb",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5491,performance,memor,memory,5491,"mory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after d",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5541,performance,Memor,Memory,5541,"art randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbyt",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5553,performance,memor,memory,5553,"ation. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5580,performance,memor,memory,5580,"nt. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. S",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5724,performance,memor,memory,5724,"erate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5751,performance,memor,memory,5751,"bytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5799,performance,memor,memory,5799,">GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By the way, the `RooArgSet` you create in line 303 o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5826,performance,memor,memory,5826,"7. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By the way, the `RooArgSet` you create in line 303 of your reproducer is leakin",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:6241,performance,memor,memory,6241,"enerate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By the way, the `RooArgSet` you create in line 303 of your reproducer is leaking:. ```. RooArgSet* args = new RooArgSet(); // never deleted! ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:6275,performance,memor,memory,6275,"enerate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By the way, the `RooArgSet` you create in line 303 of your reproducer is leaking:. ```. RooArgSet* args = new RooArgSet(); // never deleted! ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:6330,performance,memor,memory,6330,"enerate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By the way, the `RooArgSet` you create in line 303 of your reproducer is leaking:. ```. RooArgSet* args = new RooArgSet(); // never deleted! ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:6402,performance,memor,memory,6402,"enerate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By the way, the `RooArgSet` you create in line 303 of your reproducer is leaking:. ```. RooArgSet* args = new RooArgSet(); // never deleted! ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:6436,performance,memor,memory,6436,"enerate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By the way, the `RooArgSet` you create in line 303 of your reproducer is leaking:. ```. RooArgSet* args = new RooArgSet(); // never deleted! ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:6518,performance,memor,memory,6518,"enerate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By the way, the `RooArgSet` you create in line 303 of your reproducer is leaking:. ```. RooArgSet* args = new RooArgSet(); // never deleted! ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:6552,performance,memor,memory,6552,"enerate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By the way, the `RooArgSet` you create in line 303 of your reproducer is leaking:. ```. RooArgSet* args = new RooArgSet(); // never deleted! ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:6629,performance,memor,memory,6629,"enerate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By the way, the `RooArgSet` you create in line 303 of your reproducer is leaking:. ```. RooArgSet* args = new RooArgSet(); // never deleted! ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:6663,performance,memor,memory,6663,"enerate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By the way, the `RooArgSet` you create in line 303 of your reproducer is leaking:. ```. RooArgSet* args = new RooArgSet(); // never deleted! ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:6727,performance,memor,memory,6727,"enerate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By the way, the `RooArgSet` you create in line 303 of your reproducer is leaking:. ```. RooArgSet* args = new RooArgSet(); // never deleted! ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2093,reliability,doe,does,2093,"es. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3154,reliability,doe,does,3154,"s memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4215,reliability,doe,does,4215,"s memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5276,reliability,doe,does,5276,"s memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:6337,reliability,doe,does,6337,"enerate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By the way, the `RooArgSet` you create in line 303 of your reproducer is leaking:. ```. RooArgSet* args = new RooArgSet(); // never deleted! ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:246,security,Team,Team,246,"Oh well, I don't know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:428,usability,help,help,428,"Oh well, I don't know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:578,usability,Minim,Minimum,578,"Oh well, I don't know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:598,usability,Memor,Memory,598,"Oh well, I don't know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:632,usability,memor,memory,632,"Oh well, I don't know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:659,usability,memor,memory,659,"Oh well, I don't know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:689,usability,Memor,Memory,689,"Oh well, I don't know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:718,usability,memor,memory,718,"Oh well, I don't know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:745,usability,memor,memory,745,"Oh well, I don't know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:775,usability,Memor,Memory,775,"Oh well, I don't know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:814,usability,memor,memory,814,"Oh well, I don't know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:840,usability,memor,memory,840,"Oh well, I don't know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:914,usability,Memor,Memory,914,"Oh well, I don't know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:956,usability,memor,memory,956,"Oh well, I don't know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:982,usability,memor,memory,982,"Oh well, I don't know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res mem",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1012,usability,Memor,Memory,1012,"t know what's messed up with the environment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1050,usability,memor,memory,1050,"onment. You tried on lxplus? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1076,usability,memor,memory,1076,"s? For me it works:. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1299,usability,Memor,Memory,1299,"linuxx8664gcc on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1311,usability,memor,memory,1311,"c on Jan 18 2023, 10:59:00 |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1337,usability,memor,memory,1337," |. | From heads/master@v6-29-01-232-gbdd7e89922e |. | With c++ (GCC) 12.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. in",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1481,usability,memor,memory,1481,"' |. ------------------------------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e914",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1507,usability,memor,memory,1507,"---------------------------------------------. root [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current categ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1555,usability,memor,memory,1555,"oot [0]. Processing Minimum.C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mb",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1582,usability,memor,memory,1582,".C... Survey Memory, beginning of program. res memory=287.363 Mbytes. vir memory=343.223 Mbytes. Survey Memory, after open file. res memory=301.309 Mbytes. vir memory=390.062 Mbytes. Survey Memory, after read workspace file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooRealVar::XS_HH_res = 1 C L(-INF - +INF). Survey Memory, after read dataset workspace. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mb",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1997,usability,memor,memory,1997,"tes. Survey Memory, after create output file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creatio",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2031,usability,memor,memory,2031,"utput file. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previou",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2086,usability,memor,memory,2086,"8 Mbytes. RooArgSet:: = (XS_HH_res,mu,mu_HH,mu_ZH,mu_ttH,mu_ggH,mu_VBF_HH,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. v",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2158,usability,memor,memory,2158,"H,mu_WH,mu_tWH,mu_tHjb,mu_bbH,mu_VBFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does no",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2192,usability,memor,memory,2192,"BFH). start of toys. phase 1. RooRealVar::xi = -0.0190762 +/- 0.0234282 L(-10 - 0). index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2274,usability,memor,memory,2274,". index_toy=1. Survey Memory. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mb",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2308,usability,memor,memory,2308,"memory=314.93 Mbytes. vir memory=402.078 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after d",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2358,usability,Memor,Memory,2358,"tart randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbyt",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2370,usability,memor,memory,2370,"zation. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2397,usability,memor,memory,2397,"ant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. i",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2541,usability,memor,memory,2541,"erate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2568,usability,memor,memory,2568,"bytes. vir memory=423.648 Mbytes. toyDataMap[tt->GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current categ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2616,usability,memor,memory,2616,">GetName()]->numEntries()=45. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mb",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2643,usability,memor,memory,2643,"5. toyDataMap[tt->GetName()]->sumEntries()=45. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 3.03502e-17. printed the pdf. toy numEntries=45, toyData->numEntries()=45.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mb",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3058,usability,memor,memory,3058,"EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creatio",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3092,usability,memor,memory,3092,"es not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previou",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3147,usability,memor,memory,3147,"ry. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. v",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3219,usability,memor,memory,3219,"delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does no",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3253,usability,memor,memory,3253,"n of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3335,usability,memor,memory,3335,"index_toy=2. Survey Memory. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mb",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3369,usability,memor,memory,3369,"mory=334.656 Mbytes. vir memory=423.648 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after d",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3419,usability,Memor,Memory,3419,"art randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbyt",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3431,usability,memor,memory,3431,"ation. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3458,usability,memor,memory,3458,"nt. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. i",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3602,usability,memor,memory,3602,"erate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3629,usability,memor,memory,3629,"bytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current categ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3677,usability,memor,memory,3677,">GetName()]->numEntries()=48. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mb",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:3704,usability,memor,memory,3704,"8. toyDataMap[tt->GetName()]->sumEntries()=48. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.93479e-22. printed the pdf. toy numEntries=48, toyData->numEntries()=48.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mb",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4119,usability,memor,memory,4119,"EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creatio",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4153,usability,memor,memory,4153,"es not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previou",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4208,usability,memor,memory,4208,"ry. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. v",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4280,usability,memor,memory,4280,"delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does no",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4314,usability,memor,memory,4314,"n of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4396,usability,memor,memory,4396,"index_toy=3. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mb",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4430,usability,memor,memory,4430,"mory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after d",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4480,usability,Memor,Memory,4480,"art randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbyt",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4492,usability,memor,memory,4492,"ation. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4519,usability,memor,memory,4519,"nt. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. i",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4663,usability,memor,memory,4663,"erate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4690,usability,memor,memory,4690,"bytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current categ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4738,usability,memor,memory,4738,">GetName()]->numEntries()=43. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mb",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:4765,usability,memor,memory,4765,"3. toyDataMap[tt->GetName()]->sumEntries()=43. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.85588e-20. printed the pdf. toy numEntries=43, toyData->numEntries()=43.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mb",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5180,usability,memor,memory,5180,"EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creatio",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5214,usability,memor,memory,5214,"es not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previou",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5269,usability,memor,memory,5269,"ry. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. v",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5341,usability,memor,memory,5341,"delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does no",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5375,usability,memor,memory,5375,"n of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5457,usability,memor,memory,5457,"index_toy=4. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mb",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5491,usability,memor,memory,5491,"mory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after d",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5541,usability,Memor,Memory,5541,"art randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbyt",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5553,usability,memor,memory,5553,"ation. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5580,usability,memor,memory,5580,"nt. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. S",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5724,usability,memor,memory,5724,"erate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5751,usability,memor,memory,5751,"bytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5799,usability,memor,memory,5799,">GetName()]->numEntries()=57. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By the way, the `RooArgSet` you create in line 303 o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:5826,usability,memor,memory,5826,"7. toyDataMap[tt->GetName()]->sumEntries()=57. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By the way, the `RooArgSet` you create in line 303 of your reproducer is leakin",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:6241,usability,memor,memory,6241,"enerate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By the way, the `RooArgSet` you create in line 303 of your reproducer is leaking:. ```. RooArgSet* args = new RooArgSet(); // never deleted! ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:6275,usability,memor,memory,6275,"enerate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By the way, the `RooArgSet` you create in line 303 of your reproducer is leaking:. ```. RooArgSet* args = new RooArgSet(); // never deleted! ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:6330,usability,memor,memory,6330,"enerate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By the way, the `RooArgSet` you create in line 303 of your reproducer is leaking:. ```. RooArgSet* args = new RooArgSet(); // never deleted! ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:6402,usability,memor,memory,6402,"enerate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By the way, the `RooArgSet` you create in line 303 of your reproducer is leaking:. ```. RooArgSet* args = new RooArgSet(); // never deleted! ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:6436,usability,memor,memory,6436,"enerate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By the way, the `RooArgSet` you create in line 303 of your reproducer is leaking:. ```. RooArgSet* args = new RooArgSet(); // never deleted! ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:6518,usability,memor,memory,6518,"enerate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By the way, the `RooArgSet` you create in line 303 of your reproducer is leaking:. ```. RooArgSet* args = new RooArgSet(); // never deleted! ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:6552,usability,memor,memory,6552,"enerate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By the way, the `RooArgSet` you create in line 303 of your reproducer is leaking:. ```. RooArgSet* args = new RooArgSet(); // never deleted! ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:6582,usability,STOP,STOP,6582,"enerate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By the way, the `RooArgSet` you create in line 303 of your reproducer is leaking:. ```. RooArgSet* args = new RooArgSet(); // never deleted! ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:6608,usability,stop,stop,6608,"enerate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By the way, the `RooArgSet` you create in line 303 of your reproducer is leaking:. ```. RooArgSet* args = new RooArgSet(); // never deleted! ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:6629,usability,memor,memory,6629,"enerate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By the way, the `RooArgSet` you create in line 303 of your reproducer is leaking:. ```. RooArgSet* args = new RooArgSet(); // never deleted! ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:6663,usability,memor,memory,6663,"enerate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By the way, the `RooArgSet` you create in line 303 of your reproducer is leaking:. ```. RooArgSet* args = new RooArgSet(); // never deleted! ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:6727,usability,memor,memory,6727,"enerate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 2.17115e-14. printed the pdf. toy numEntries=57, toyData->numEntries()=57.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. index_toy=5. Survey Memory. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. start randomization. tt->GetName()=resonant. pdftmp=0x55b9e4e91430. generate current category. just before generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. just after generate. res memory=335.289 Mbytes. vir memory=424.035 Mbytes. toyDataMap[tt->GetName()]->numEntries()=40. toyDataMap[tt->GetName()]->sumEntries()=40. immediatly after generate. print the pdf. pdf=0x55b9e4e07720. RooSimultaneous::CombinedPdf[ indexCat=channellist resonant=_model_resonant ] = 1.52722e-20. printed the pdf. toy numEntries=40, toyData->numEntries()=40.0000000000. just after creation of dataset toy that uses previous toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. delete toyData. just after deletion of toyData. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. STOP PROGRAM. just before stop of program. res memory=335.2890625000 Mbytes. vir memory=424.0351562500 Mbytes. ```. And in fact, the increase in memory is gone, right? By the way, the `RooArgSet` you create in line 303 of your reproducer is leaking:. ```. RooArgSet* args = new RooArgSet(); // never deleted! ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:165,performance,memor,memory,165,"ok : I don't know why root does not work for me (yes, I use lxplus). As I said, the problem is not that there is not an increase : the problem is that when I delete memory of the RooDataSet, the memory has not decreased. See this in your example :. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? (thank you for the information about the RooArgSet * deletion)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:195,performance,memor,memory,195,"ok : I don't know why root does not work for me (yes, I use lxplus). As I said, the problem is not that there is not an increase : the problem is that when I delete memory of the RooDataSet, the memory has not decreased. See this in your example :. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? (thank you for the information about the RooArgSet * deletion)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:325,performance,memor,memory,325,"ok : I don't know why root does not work for me (yes, I use lxplus). As I said, the problem is not that there is not an increase : the problem is that when I delete memory of the RooDataSet, the memory has not decreased. See this in your example :. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? (thank you for the information about the RooArgSet * deletion)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:359,performance,memor,memory,359,"ok : I don't know why root does not work for me (yes, I use lxplus). As I said, the problem is not that there is not an increase : the problem is that when I delete memory of the RooDataSet, the memory has not decreased. See this in your example :. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? (thank you for the information about the RooArgSet * deletion)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:414,performance,memor,memory,414,"ok : I don't know why root does not work for me (yes, I use lxplus). As I said, the problem is not that there is not an increase : the problem is that when I delete memory of the RooDataSet, the memory has not decreased. See this in your example :. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? (thank you for the information about the RooArgSet * deletion)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:486,performance,memor,memory,486,"ok : I don't know why root does not work for me (yes, I use lxplus). As I said, the problem is not that there is not an increase : the problem is that when I delete memory of the RooDataSet, the memory has not decreased. See this in your example :. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? (thank you for the information about the RooArgSet * deletion)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:520,performance,memor,memory,520,"ok : I don't know why root does not work for me (yes, I use lxplus). As I said, the problem is not that there is not an increase : the problem is that when I delete memory of the RooDataSet, the memory has not decreased. See this in your example :. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? (thank you for the information about the RooArgSet * deletion)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:602,performance,memor,memory,602,"ok : I don't know why root does not work for me (yes, I use lxplus). As I said, the problem is not that there is not an increase : the problem is that when I delete memory of the RooDataSet, the memory has not decreased. See this in your example :. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? (thank you for the information about the RooArgSet * deletion)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:636,performance,memor,memory,636,"ok : I don't know why root does not work for me (yes, I use lxplus). As I said, the problem is not that there is not an increase : the problem is that when I delete memory of the RooDataSet, the memory has not decreased. See this in your example :. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? (thank you for the information about the RooArgSet * deletion)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:729,performance,memor,memory,729,"ok : I don't know why root does not work for me (yes, I use lxplus). As I said, the problem is not that there is not an increase : the problem is that when I delete memory of the RooDataSet, the memory has not decreased. See this in your example :. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? (thank you for the information about the RooArgSet * deletion)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:27,reliability,doe,does,27,"ok : I don't know why root does not work for me (yes, I use lxplus). As I said, the problem is not that there is not an increase : the problem is that when I delete memory of the RooDataSet, the memory has not decreased. See this in your example :. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? (thank you for the information about the RooArgSet * deletion)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:421,reliability,doe,does,421,"ok : I don't know why root does not work for me (yes, I use lxplus). As I said, the problem is not that there is not an increase : the problem is that when I delete memory of the RooDataSet, the memory has not decreased. See this in your example :. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? (thank you for the information about the RooArgSet * deletion)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:165,usability,memor,memory,165,"ok : I don't know why root does not work for me (yes, I use lxplus). As I said, the problem is not that there is not an increase : the problem is that when I delete memory of the RooDataSet, the memory has not decreased. See this in your example :. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? (thank you for the information about the RooArgSet * deletion)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:195,usability,memor,memory,195,"ok : I don't know why root does not work for me (yes, I use lxplus). As I said, the problem is not that there is not an increase : the problem is that when I delete memory of the RooDataSet, the memory has not decreased. See this in your example :. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? (thank you for the information about the RooArgSet * deletion)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:325,usability,memor,memory,325,"ok : I don't know why root does not work for me (yes, I use lxplus). As I said, the problem is not that there is not an increase : the problem is that when I delete memory of the RooDataSet, the memory has not decreased. See this in your example :. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? (thank you for the information about the RooArgSet * deletion)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:359,usability,memor,memory,359,"ok : I don't know why root does not work for me (yes, I use lxplus). As I said, the problem is not that there is not an increase : the problem is that when I delete memory of the RooDataSet, the memory has not decreased. See this in your example :. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? (thank you for the information about the RooArgSet * deletion)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:414,usability,memor,memory,414,"ok : I don't know why root does not work for me (yes, I use lxplus). As I said, the problem is not that there is not an increase : the problem is that when I delete memory of the RooDataSet, the memory has not decreased. See this in your example :. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? (thank you for the information about the RooArgSet * deletion)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:486,usability,memor,memory,486,"ok : I don't know why root does not work for me (yes, I use lxplus). As I said, the problem is not that there is not an increase : the problem is that when I delete memory of the RooDataSet, the memory has not decreased. See this in your example :. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? (thank you for the information about the RooArgSet * deletion)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:520,usability,memor,memory,520,"ok : I don't know why root does not work for me (yes, I use lxplus). As I said, the problem is not that there is not an increase : the problem is that when I delete memory of the RooDataSet, the memory has not decreased. See this in your example :. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? (thank you for the information about the RooArgSet * deletion)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:602,usability,memor,memory,602,"ok : I don't know why root does not work for me (yes, I use lxplus). As I said, the problem is not that there is not an increase : the problem is that when I delete memory of the RooDataSet, the memory has not decreased. See this in your example :. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? (thank you for the information about the RooArgSet * deletion)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:636,usability,memor,memory,636,"ok : I don't know why root does not work for me (yes, I use lxplus). As I said, the problem is not that there is not an increase : the problem is that when I delete memory of the RooDataSet, the memory has not decreased. See this in your example :. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? (thank you for the information about the RooArgSet * deletion)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:729,usability,memor,memory,729,"ok : I don't know why root does not work for me (yes, I use lxplus). As I said, the problem is not that there is not an increase : the problem is that when I delete memory of the RooDataSet, the memory has not decreased. See this in your example :. just after creation of dataset toy that uses previous toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. EXAMPLE OF PROBLEM : the memory does not decrease ! just after deletion of toy per category. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. delete toyData. just after deletion of toyData. res memory=334.6562500000 Mbytes. vir memory=423.6484375000 Mbytes. You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? (thank you for the information about the RooArgSet * deletion)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:592,availability,stead,steady,592,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:519,deployability,manag,managed,519,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:580,deployability,observ,observing,580,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:655,deployability,version,version,655,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1159,deployability,Observ,Observables,1159," this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. }. }. ```. The output is now:. ```. 10: 346.156 441.535. 20: 346.156 441.715. 30: 346.156 441.71",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1573,deployability,Observ,Observables,1573," observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. }. }. ```. The output is now:. ```. 10: 346.156 441.535. 20: 346.156 441.715. 30: 346.156 441.715. 40: 346.473 441.91. 50: 346.473 441.91. 60: 346.473 441.91. 70: 346.73 442.301. 80: 346.73 442.301. 90: 346.73 442.301. 100: 346.746 442.301. 110: 346.746 442.301. 120: 346.746 442.301. 130: 346.746 442.301. 140: 347.512 443.082. 150: 347.512 443.082. 160: 347.512 443.082. 170: 347.512 443.082. 180: 347.512 443.082. 190: 347.512 443.082. 200: 347.512 443.082. 210: 347.512 443.082. 220: 347.512 443.082. 230: ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1812,deployability,Observ,Observables,1812,". std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. }. }. ```. The output is now:. ```. 10: 346.156 441.535. 20: 346.156 441.715. 30: 346.156 441.715. 40: 346.473 441.91. 50: 346.473 441.91. 60: 346.473 441.91. 70: 346.73 442.301. 80: 346.73 442.301. 90: 346.73 442.301. 100: 346.746 442.301. 110: 346.746 442.301. 120: 346.746 442.301. 130: 346.746 442.301. 140: 347.512 443.082. 150: 347.512 443.082. 160: 347.512 443.082. 170: 347.512 443.082. 180: 347.512 443.082. 190: 347.512 443.082. 200: 347.512 443.082. 210: 347.512 443.082. 220: 347.512 443.082. 230: 347.512 443.082. 240: 347.512 443.082. 250: 347.512 443.082. 260: 347.512 443.082. 270: 347.512 443.082. 280: 349.082 444.645. 290: 349.082 444.645. 300: 349.082 444.645. 310: 349.082 444.645. 320: 349.082 444.645. 330: 349.082 444.645. 34",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2898,deployability,continu,continue,2898,"combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. }. }. ```. The output is now:. ```. 10: 346.156 441.535. 20: 346.156 441.715. 30: 346.156 441.715. 40: 346.473 441.91. 50: 346.473 441.91. 60: 346.473 441.91. 70: 346.73 442.301. 80: 346.73 442.301. 90: 346.73 442.301. 100: 346.746 442.301. 110: 346.746 442.301. 120: 346.746 442.301. 130: 346.746 442.301. 140: 347.512 443.082. 150: 347.512 443.082. 160: 347.512 443.082. 170: 347.512 443.082. 180: 347.512 443.082. 190: 347.512 443.082. 200: 347.512 443.082. 210: 347.512 443.082. 220: 347.512 443.082. 230: 347.512 443.082. 240: 347.512 443.082. 250: 347.512 443.082. 260: 347.512 443.082. 270: 347.512 443.082. 280: 349.082 444.645. 290: 349.082 444.645. 300: 349.082 444.645. 310: 349.082 444.645. 320: 349.082 444.645. 330: 349.082 444.645. 340: 349.082 444.645. 350: 349.082 444.645. 360: 349.082 444.645. ... ```. I will continue debugging this, starting from there.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:519,energy efficiency,manag,managed,519,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:977,energy efficiency,Model,ModelConfig,977,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1001,energy efficiency,Model,ModelConfig,1001,"ee that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:655,integrability,version,version,655,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:655,modifiability,version,version,655,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1669,modifiability,Exten,Extended,1669,"producer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. }. }. ```. The output is now:. ```. 10: 346.156 441.535. 20: 346.156 441.715. 30: 346.156 441.715. 40: 346.473 441.91. 50: 346.473 441.91. 60: 346.473 441.91. 70: 346.73 442.301. 80: 346.73 442.301. 90: 346.73 442.301. 100: 346.746 442.301. 110: 346.746 442.301. 120: 346.746 442.301. 130: 346.746 442.301. 140: 347.512 443.082. 150: 347.512 443.082. 160: 347.512 443.082. 170: 347.512 443.082. 180: 347.512 443.082. 190: 347.512 443.082. 200: 347.512 443.082. 210: 347.512 443.082. 220: 347.512 443.082. 230: 347.512 443.082. 240: 347.512 443.082. 250: 347.512 443.082. 260: 347.512 443.082. 270: 347.51",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:65,performance,memor,memory,65,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:259,performance,memor,memory,259,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:482,performance,memor,memory,482,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:599,performance,memor,memory,599,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:620,performance,time,time,620,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:266,reliability,doe,doesn,266,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:324,reliability,doe,doesn,324,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:191,safety,compl,completely,191,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:519,safety,manag,managed,519,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:191,security,compl,completely,191,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:977,security,Model,ModelConfig,977,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1001,security,Model,ModelConfig,1001,"ee that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:202,testability,understand,understand,202,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:580,testability,observ,observing,580,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:644,testability,simpl,simplified,644,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1159,testability,Observ,Observables,1159," this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. }. }. ```. The output is now:. ```. 10: 346.156 441.535. 20: 346.156 441.715. 30: 346.156 441.71",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1573,testability,Observ,Observables,1573," observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. }. }. ```. The output is now:. ```. 10: 346.156 441.535. 20: 346.156 441.715. 30: 346.156 441.715. 40: 346.473 441.91. 50: 346.473 441.91. 60: 346.473 441.91. 70: 346.73 442.301. 80: 346.73 442.301. 90: 346.73 442.301. 100: 346.746 442.301. 110: 346.746 442.301. 120: 346.746 442.301. 130: 346.746 442.301. 140: 347.512 443.082. 150: 347.512 443.082. 160: 347.512 443.082. 170: 347.512 443.082. 180: 347.512 443.082. 190: 347.512 443.082. 200: 347.512 443.082. 210: 347.512 443.082. 220: 347.512 443.082. 230: ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1812,testability,Observ,Observables,1812,". std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. }. }. ```. The output is now:. ```. 10: 346.156 441.535. 20: 346.156 441.715. 30: 346.156 441.715. 40: 346.473 441.91. 50: 346.473 441.91. 60: 346.473 441.91. 70: 346.73 442.301. 80: 346.73 442.301. 90: 346.73 442.301. 100: 346.746 442.301. 110: 346.746 442.301. 120: 346.746 442.301. 130: 346.746 442.301. 140: 347.512 443.082. 150: 347.512 443.082. 160: 347.512 443.082. 170: 347.512 443.082. 180: 347.512 443.082. 190: 347.512 443.082. 200: 347.512 443.082. 210: 347.512 443.082. 220: 347.512 443.082. 230: 347.512 443.082. 240: 347.512 443.082. 250: 347.512 443.082. 260: 347.512 443.082. 270: 347.512 443.082. 280: 349.082 444.645. 290: 349.082 444.645. 300: 349.082 444.645. 310: 349.082 444.645. 320: 349.082 444.645. 330: 349.082 444.645. 34",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:65,usability,memor,memory,65,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:259,usability,memor,memory,259,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:482,usability,memor,memory,482,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:599,usability,memor,memory,599,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:644,usability,simpl,simplified,644,"> You see that after deleting the dataset gives exactly the same memory as after having created the dataset, so there is a problem, isn't it ?!? I'm not convinced by this yet because I don't completely understand the output at this point. Yes, you are right, memory doesn't decrease, but starting from the third toy it also doesn't *increase* when `generate()` is called, right? So these numbers don't make sense to me to begin with, and I would rather not conclude that there is a memory leak based on . But anyway, I managed to convince myself by generating many more toys, and observing a steady memory increase over time. I did this with a simplified version of your reproducer:. ```C++. void Minimum2(). {. using namespace RooFit;. using namespace RooStats;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. std::unique_ptr<TFile> f_ws{TFile::Open(""WS-YY-resonant_500_For_Comb.root"", ""READ"")};. auto *ws = f_ws->Get<RooWorkspace>(""combWS"");. auto *mc = static_cast<ModelConfig *>(ws->obj(""ModelConfig""));. auto *pdf = static_cast<RooSimultaneous *>(mc->GetPdf());. for (std::size_t index_toy = 1; index_toy < 500; index_toy++) {. const RooArgSet *Observables = (RooArgSet *)mc->GetObservables();. std::vector<std::unique_ptr<RooDataSet>> toyDatas;. std::map<string, RooDataSet *> toyDataMap;. RooCategory channellist{""channellist"", ""channellist""};. // generate each category. for (auto const &item : pdf->indexCat()) {. channellist.defineType(item.first.c_str());. RooAbsPdf *pdftmp = pdf->getPdf(item.first.c_str());. RooArgSet obstmp;. pdftmp->getObservables(Observables, obstmp);. toyDatas.emplace_back(static_cast<RooDataSet *>(pdftmp->generate(obstmp, Extended())));. toyDataMap[item.first.c_str()] = toyDatas.back().get();. }. RooRealVar wt(""wt"", ""wt"", 1);. RooDataSet toyData{""toyData"", """", {*Observables, wt}, Index(channellist), Import(toyDataMap), WeightVar(wt)};. if (index_toy % 10 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResi",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:46,deployability,log,log,46,"Thank you Jonas. . In my feeling this part of log proves somehow that memory is not freed at least for the first toy (index toy = 1) :. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. We see that after generate, the memory has increased (which is normal), but afterwards, even when deleting the generated dataset, we no more get back to the level of memory memory that was before the generate, even though we delete the generated dataset.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:70,performance,memor,memory,70,"Thank you Jonas. . In my feeling this part of log proves somehow that memory is not freed at least for the first toy (index toy = 1) :. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. We see that after generate, the memory has increased (which is normal), but afterwards, even when deleting the generated dataset, we no more get back to the level of memory memory that was before the generate, even though we delete the generated dataset.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:162,performance,memor,memory,162,"Thank you Jonas. . In my feeling this part of log proves somehow that memory is not freed at least for the first toy (index toy = 1) :. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. We see that after generate, the memory has increased (which is normal), but afterwards, even when deleting the generated dataset, we no more get back to the level of memory memory that was before the generate, even though we delete the generated dataset.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:188,performance,memor,memory,188,"Thank you Jonas. . In my feeling this part of log proves somehow that memory is not freed at least for the first toy (index toy = 1) :. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. We see that after generate, the memory has increased (which is normal), but afterwards, even when deleting the generated dataset, we no more get back to the level of memory memory that was before the generate, even though we delete the generated dataset.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:236,performance,memor,memory,236,"Thank you Jonas. . In my feeling this part of log proves somehow that memory is not freed at least for the first toy (index toy = 1) :. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. We see that after generate, the memory has increased (which is normal), but afterwards, even when deleting the generated dataset, we no more get back to the level of memory memory that was before the generate, even though we delete the generated dataset.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:263,performance,memor,memory,263,"Thank you Jonas. . In my feeling this part of log proves somehow that memory is not freed at least for the first toy (index toy = 1) :. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. We see that after generate, the memory has increased (which is normal), but afterwards, even when deleting the generated dataset, we no more get back to the level of memory memory that was before the generate, even though we delete the generated dataset.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:318,performance,memor,memory,318,"Thank you Jonas. . In my feeling this part of log proves somehow that memory is not freed at least for the first toy (index toy = 1) :. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. We see that after generate, the memory has increased (which is normal), but afterwards, even when deleting the generated dataset, we no more get back to the level of memory memory that was before the generate, even though we delete the generated dataset.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:452,performance,memor,memory,452,"Thank you Jonas. . In my feeling this part of log proves somehow that memory is not freed at least for the first toy (index toy = 1) :. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. We see that after generate, the memory has increased (which is normal), but afterwards, even when deleting the generated dataset, we no more get back to the level of memory memory that was before the generate, even though we delete the generated dataset.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:459,performance,memor,memory,459,"Thank you Jonas. . In my feeling this part of log proves somehow that memory is not freed at least for the first toy (index toy = 1) :. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. We see that after generate, the memory has increased (which is normal), but afterwards, even when deleting the generated dataset, we no more get back to the level of memory memory that was before the generate, even though we delete the generated dataset.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:46,safety,log,log,46,"Thank you Jonas. . In my feeling this part of log proves somehow that memory is not freed at least for the first toy (index toy = 1) :. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. We see that after generate, the memory has increased (which is normal), but afterwards, even when deleting the generated dataset, we no more get back to the level of memory memory that was before the generate, even though we delete the generated dataset.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:46,security,log,log,46,"Thank you Jonas. . In my feeling this part of log proves somehow that memory is not freed at least for the first toy (index toy = 1) :. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. We see that after generate, the memory has increased (which is normal), but afterwards, even when deleting the generated dataset, we no more get back to the level of memory memory that was before the generate, even though we delete the generated dataset.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:46,testability,log,log,46,"Thank you Jonas. . In my feeling this part of log proves somehow that memory is not freed at least for the first toy (index toy = 1) :. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. We see that after generate, the memory has increased (which is normal), but afterwards, even when deleting the generated dataset, we no more get back to the level of memory memory that was before the generate, even though we delete the generated dataset.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:70,usability,memor,memory,70,"Thank you Jonas. . In my feeling this part of log proves somehow that memory is not freed at least for the first toy (index toy = 1) :. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. We see that after generate, the memory has increased (which is normal), but afterwards, even when deleting the generated dataset, we no more get back to the level of memory memory that was before the generate, even though we delete the generated dataset.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:162,usability,memor,memory,162,"Thank you Jonas. . In my feeling this part of log proves somehow that memory is not freed at least for the first toy (index toy = 1) :. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. We see that after generate, the memory has increased (which is normal), but afterwards, even when deleting the generated dataset, we no more get back to the level of memory memory that was before the generate, even though we delete the generated dataset.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:188,usability,memor,memory,188,"Thank you Jonas. . In my feeling this part of log proves somehow that memory is not freed at least for the first toy (index toy = 1) :. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. We see that after generate, the memory has increased (which is normal), but afterwards, even when deleting the generated dataset, we no more get back to the level of memory memory that was before the generate, even though we delete the generated dataset.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:236,usability,memor,memory,236,"Thank you Jonas. . In my feeling this part of log proves somehow that memory is not freed at least for the first toy (index toy = 1) :. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. We see that after generate, the memory has increased (which is normal), but afterwards, even when deleting the generated dataset, we no more get back to the level of memory memory that was before the generate, even though we delete the generated dataset.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:263,usability,memor,memory,263,"Thank you Jonas. . In my feeling this part of log proves somehow that memory is not freed at least for the first toy (index toy = 1) :. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. We see that after generate, the memory has increased (which is normal), but afterwards, even when deleting the generated dataset, we no more get back to the level of memory memory that was before the generate, even though we delete the generated dataset.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:318,usability,memor,memory,318,"Thank you Jonas. . In my feeling this part of log proves somehow that memory is not freed at least for the first toy (index toy = 1) :. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. We see that after generate, the memory has increased (which is normal), but afterwards, even when deleting the generated dataset, we no more get back to the level of memory memory that was before the generate, even though we delete the generated dataset.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:452,usability,memor,memory,452,"Thank you Jonas. . In my feeling this part of log proves somehow that memory is not freed at least for the first toy (index toy = 1) :. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. We see that after generate, the memory has increased (which is normal), but afterwards, even when deleting the generated dataset, we no more get back to the level of memory memory that was before the generate, even though we delete the generated dataset.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:459,usability,memor,memory,459,"Thank you Jonas. . In my feeling this part of log proves somehow that memory is not freed at least for the first toy (index toy = 1) :. just before generate. res memory=314.93 Mbytes. vir memory=402.078 Mbytes. just after generate. res memory=334.656 Mbytes. vir memory=423.648 Mbytes. We see that after generate, the memory has increased (which is normal), but afterwards, even when deleting the generated dataset, we no more get back to the level of memory memory that was before the generate, even though we delete the generated dataset.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:224,deployability,depend,depend,224,"Yes yes I see the point for the first toy, but for the others I just didn't understand it. Anyhow I'm convinced that there is a problem, and just to record my progress for today, here is a standalone reproducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1583,deployability,observ,observable,1583,"roducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- RooGenContext::ctor() accept/reject sampling function is expo_AccRej. [#3] DEBUG:Generation -- RooGenContext::ctor() creating MC sampling generator RooFoamGenerator from function for observables (x). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1649,deployability,observ,observables,1649,"roducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- RooGenContext::ctor() accept/reject sampling function is expo_AccRej. [#3] DEBUG:Generation -- RooGenContext::ctor() creating MC sampling generator RooFoamGenerator from function for observables (x). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1817,deployability,observ,observables,1817,"roducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- RooGenContext::ctor() accept/reject sampling function is expo_AccRej. [#3] DEBUG:Generation -- RooGenContext::ctor() creating MC sampling generator RooFoamGenerator from function for observables (x). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1837,deployability,configurat,configuration,1837,"roducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- RooGenContext::ctor() accept/reject sampling function is expo_AccRej. [#3] DEBUG:Generation -- RooGenContext::ctor() creating MC sampling generator RooFoamGenerator from function for observables (x). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2183,deployability,observ,observables,2183,"roducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- RooGenContext::ctor() accept/reject sampling function is expo_AccRej. [#3] DEBUG:Generation -- RooGenContext::ctor() creating MC sampling generator RooFoamGenerator from function for observables (x). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1769,energy efficiency,Model,Model,1769,"roducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- RooGenContext::ctor() accept/reject sampling function is expo_AccRej. [#3] DEBUG:Generation -- RooGenContext::ctor() creating MC sampling generator RooFoamGenerator from function for observables (x). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:224,integrability,depend,depend,224,"Yes yes I see the point for the first toy, but for the others I just didn't understand it. Anyhow I'm convinced that there is a problem, and just to record my progress for today, here is a standalone reproducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1163,integrability,Topic,Topic,1163,"s for today, here is a standalone reproducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- RooGenContext::ctor() accept/reject sampling function is expo_AccRej. [#3] DEBUG:Generation -- RooGenContext::ctor() creating MC sampling generator RooFoamGenerator f",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1525,integrability,event,event,1525,"roducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- RooGenContext::ctor() accept/reject sampling function is expo_AccRej. [#3] DEBUG:Generation -- RooGenContext::ctor() creating MC sampling generator RooFoamGenerator from function for observables (x). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1837,integrability,configur,configuration,1837,"roducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- RooGenContext::ctor() accept/reject sampling function is expo_AccRej. [#3] DEBUG:Generation -- RooGenContext::ctor() creating MC sampling generator RooFoamGenerator from function for observables (x). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:718,interoperability,distribut,distribution,718,"Yes yes I see the point for the first toy, but for the others I just didn't understand it. Anyhow I'm convinced that there is a problem, and just to record my progress for today, here is a standalone reproducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:224,modifiability,depend,depend,224,"Yes yes I see the point for the first toy, but for the others I just didn't understand it. Anyhow I'm convinced that there is a problem, and just to record my progress for today, here is a standalone reproducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1837,modifiability,configur,configuration,1837,"roducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- RooGenContext::ctor() accept/reject sampling function is expo_AccRej. [#3] DEBUG:Generation -- RooGenContext::ctor() creating MC sampling generator RooFoamGenerator from function for observables (x). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1933,modifiability,variab,variables,1933,"roducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- RooGenContext::ctor() accept/reject sampling function is expo_AccRej. [#3] DEBUG:Generation -- RooGenContext::ctor() creating MC sampling generator RooFoamGenerator from function for observables (x). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:216,reliability,doe,doesn,216,"Yes yes I see the point for the first toy, but for the others I just didn't understand it. Anyhow I'm convinced that there is a problem, and just to record my progress for today, here is a standalone reproducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:224,safety,depend,depend,224,"Yes yes I see the point for the first toy, but for the others I just didn't understand it. Anyhow I'm convinced that there is a problem, and just to record my progress for today, here is a standalone reproducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1669,safety,safe,safe,1669,"roducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- RooGenContext::ctor() accept/reject sampling function is expo_AccRej. [#3] DEBUG:Generation -- RooGenContext::ctor() creating MC sampling generator RooFoamGenerator from function for observables (x). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1769,security,Model,Model,1769,"roducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- RooGenContext::ctor() accept/reject sampling function is expo_AccRej. [#3] DEBUG:Generation -- RooGenContext::ctor() creating MC sampling generator RooFoamGenerator from function for observables (x). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1837,security,configur,configuration,1837,"roducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- RooGenContext::ctor() accept/reject sampling function is expo_AccRej. [#3] DEBUG:Generation -- RooGenContext::ctor() creating MC sampling generator RooFoamGenerator from function for observables (x). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1851,security,ident,identifier,1851,"roducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- RooGenContext::ctor() accept/reject sampling function is expo_AccRej. [#3] DEBUG:Generation -- RooGenContext::ctor() creating MC sampling generator RooFoamGenerator from function for observables (x). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:76,testability,understand,understand,76,"Yes yes I see the point for the first toy, but for the others I just didn't understand it. Anyhow I'm convinced that there is a problem, and just to record my progress for today, here is a standalone reproducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:224,testability,depend,depend,224,"Yes yes I see the point for the first toy, but for the others I just didn't understand it. Anyhow I'm convinced that there is a problem, and just to record my progress for today, here is a standalone reproducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1541,testability,context,context,1541,"roducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- RooGenContext::ctor() accept/reject sampling function is expo_AccRej. [#3] DEBUG:Generation -- RooGenContext::ctor() creating MC sampling generator RooFoamGenerator from function for observables (x). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1583,testability,observ,observable,1583,"roducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- RooGenContext::ctor() accept/reject sampling function is expo_AccRej. [#3] DEBUG:Generation -- RooGenContext::ctor() creating MC sampling generator RooFoamGenerator from function for observables (x). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1649,testability,observ,observables,1649,"roducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- RooGenContext::ctor() accept/reject sampling function is expo_AccRej. [#3] DEBUG:Generation -- RooGenContext::ctor() creating MC sampling generator RooFoamGenerator from function for observables (x). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1817,testability,observ,observables,1817,"roducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- RooGenContext::ctor() accept/reject sampling function is expo_AccRej. [#3] DEBUG:Generation -- RooGenContext::ctor() creating MC sampling generator RooFoamGenerator from function for observables (x). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1911,testability,Context,Context,1911,"roducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- RooGenContext::ctor() accept/reject sampling function is expo_AccRej. [#3] DEBUG:Generation -- RooGenContext::ctor() creating MC sampling generator RooFoamGenerator from function for observables (x). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2183,testability,observ,observables,2183,"roducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- RooGenContext::ctor() accept/reject sampling function is expo_AccRej. [#3] DEBUG:Generation -- RooGenContext::ctor() creating MC sampling generator RooFoamGenerator from function for observables (x). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:159,usability,progress,progress,159,"Yes yes I see the point for the first toy, but for the others I just didn't understand it. Anyhow I'm convinced that there is a problem, and just to record my progress for today, here is a standalone reproducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1701,usability,support,supported,1701,"roducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- RooGenContext::ctor() accept/reject sampling function is expo_AccRej. [#3] DEBUG:Generation -- RooGenContext::ctor() creating MC sampling generator RooFoamGenerator from function for observables (x). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1775,usability,indicat,indicates,1775,"roducer that doesn't depend on Marcs workspace:. ```c++. #include <RooGenContext.h>. #include <RooRealVar.h>. #include <RooExponential.h>. #include <RooUniform.h>. #include <RooMsgService.h>. #include <TFile.h>. #include <TSystem.h>. #include <iostream>. void repro(). {. using namespace RooFit;. ProcInfo_t procinfo;. const float toMB = 1.f / 1024.f;. RooRealVar x{""x"", ""x"", 0.1, 5.1};. RooRealVar c{""c"", ""c"", -1.8, -5, 5};. RooExponential expo{""expo"", ""expo"", x, c};. RooAbsPdf *pdf = &expo;. // With the uniform distribution, there is no leak! // RooUniform uni{""uni"", ""uni"", x};. // RooAbsPdf * pdf = &uni;. std::size_t nToys = 5000;. for (std::size_t index_toy = 1; index_toy <= nToys; index_toy++) {. if (index_toy % 500 == 0) {. gSystem->GetProcInfo(&procinfo);. std::cout << index_toy << "": "" << procinfo.fMemResident * toMB << "" "" << procinfo.fMemVirtual * toMB. << std::endl;. }. if (index_toy == nToys) {. RooMsgService::instance().addStream(DEBUG, Topic(Generation));. }. RooGenContext{*pdf, x};. }. }. ```. The output:. ```. 500: 209.504 345.379. 1000: 209.762 345.77. 1500: 209.762 345.77. 2000: 210.535 346.551. 2500: 210.535 346.551. 3000: 210.535 346.551. 3500: 210.535 346.551. 4000: 212.082 348.117. 4500: 212.082 348.117. 5000: 212.082 348.117. [#3] INFO:Generation -- RooGenContext::ctor() setting up event generator context for p.d.f. expo for generation of observable(s) (x). [#3] DEBUG:Generation -- RooGenContext::ctor() observables (x) are safe for internal generator (if supported by p.d.f). [#3] DEBUG:Generation -- RooGenContext::ctor() Model indicates that it can internally generate observables () with configuration identifier 0. [#3] INFO:Generation -- RooGenContext::ctor() Context will generate variables (x) with accept/reject sampling. [#3] INFO:Generation -- RooGenContext::ctor() accept/reject sampling function is expo_AccRej. [#3] DEBUG:Generation -- RooGenContext::ctor() creating MC sampling generator RooFoamGenerator from function for observables (x). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:75,availability,operat,operation,75,"I also increased the priority, because having a leak in such a fundamental operation with RooFit is not so great...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:53,deployability,version,version,53,Thank you @guitargeek . Would you know in which root version I can check that it works ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:53,integrability,version,version,53,Thank you @guitargeek . Would you know in which root version I can check that it works ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:53,modifiability,version,version,53,Thank you @guitargeek . Would you know in which root version I can check that it works ?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:15,deployability,releas,release,15,"In the 6.28.00 release that will be released in a week or so. Sorry I didn't mean to close the issue, GitHub did that automatically! I'll leave this open until you confirm that the leak is gone. If you manage to source them correctly, you can also try it out with the ROOT nightly builds:. https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:36,deployability,releas,released,36,"In the 6.28.00 release that will be released in a week or so. Sorry I didn't mean to close the issue, GitHub did that automatically! I'll leave this open until you confirm that the leak is gone. If you manage to source them correctly, you can also try it out with the ROOT nightly builds:. https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:118,deployability,automat,automatically,118,"In the 6.28.00 release that will be released in a week or so. Sorry I didn't mean to close the issue, GitHub did that automatically! I'll leave this open until you confirm that the leak is gone. If you manage to source them correctly, you can also try it out with the ROOT nightly builds:. https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:202,deployability,manag,manage,202,"In the 6.28.00 release that will be released in a week or so. Sorry I didn't mean to close the issue, GitHub did that automatically! I'll leave this open until you confirm that the leak is gone. If you manage to source them correctly, you can also try it out with the ROOT nightly builds:. https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:281,deployability,build,builds,281,"In the 6.28.00 release that will be released in a week or so. Sorry I didn't mean to close the issue, GitHub did that automatically! I'll leave this open until you confirm that the leak is gone. If you manage to source them correctly, you can also try it out with the ROOT nightly builds:. https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:308,deployability,instal,install,308,"In the 6.28.00 release that will be released in a week or so. Sorry I didn't mean to close the issue, GitHub did that automatically! I'll leave this open until you confirm that the leak is gone. If you manage to source them correctly, you can also try it out with the ROOT nightly builds:. https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:202,energy efficiency,manag,manage,202,"In the 6.28.00 release that will be released in a week or so. Sorry I didn't mean to close the issue, GitHub did that automatically! I'll leave this open until you confirm that the leak is gone. If you manage to source them correctly, you can also try it out with the ROOT nightly builds:. https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:202,safety,manag,manage,202,"In the 6.28.00 release that will be released in a week or so. Sorry I didn't mean to close the issue, GitHub did that automatically! I'll leave this open until you confirm that the leak is gone. If you manage to source them correctly, you can also try it out with the ROOT nightly builds:. https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:118,testability,automat,automatically,118,"In the 6.28.00 release that will be released in a week or so. Sorry I didn't mean to close the issue, GitHub did that automatically! I'll leave this open until you confirm that the leak is gone. If you manage to source them correctly, you can also try it out with the ROOT nightly builds:. https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:85,usability,close,close,85,"In the 6.28.00 release that will be released in a week or so. Sorry I didn't mean to close the issue, GitHub did that automatically! I'll leave this open until you confirm that the leak is gone. If you manage to source them correctly, you can also try it out with the ROOT nightly builds:. https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:164,usability,confirm,confirm,164,"In the 6.28.00 release that will be released in a week or so. Sorry I didn't mean to close the issue, GitHub did that automatically! I'll leave this open until you confirm that the leak is gone. If you manage to source them correctly, you can also try it out with the ROOT nightly builds:. https://root.cern/install/nightlies/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:118,safety,valid,validation,118,Removing the 6.28 milestone because it should be already fixed in ROOT 6.28. This issue is only left open because the validation of the fix is still pending,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:118,security,validat,validation,118,Removing the 6.28 milestone because it should be already fixed in ROOT 6.28. This issue is only left open because the validation of the fix is still pending,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:15,safety,test,test,15,Thanks. I will test it in a few days. Apologizes for the delay.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:15,testability,test,test,15,Thanks. I will test it in a few days. Apologizes for the delay.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:319,availability,avail,available,319,"So unfortunately, I have no way to check with the nightly (apart if I would change/redevelop a new program). The reason is that the workspace used in my example includes RooTwoSidedCBShape, which is unknown to root, so one needs to switch on first a tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:477,availability,escal,escalier,477,"So unfortunately, I have no way to check with the nightly (apart if I would change/redevelop a new program). The reason is that the workspace used in my example includes RooTwoSidedCBShape, which is unknown to root, so one needs to switch on first a tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:516,availability,escal,escalier,516,"So unfortunately, I have no way to check with the nightly (apart if I would change/redevelop a new program). The reason is that the workspace used in my example includes RooTwoSidedCBShape, which is unknown to root, so one needs to switch on first a tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1150,availability,escal,escalier,1150,"xample includes RooTwoSidedCBShape, which is unknown to root, so one needs to switch on first a tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedC",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1369,availability,avail,available,1369,"at it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: tr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1412,availability,Error,Error,1412," you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSid",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1544,availability,Error,Error,1544,"emMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSid",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1676,availability,Error,Error,1676,"to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSid",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1808,availability,Error,Error,1808," on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSid",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1940,availability,Error,Error,1940,"license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2072,availability,Error,Error,2072,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2204,availability,Error,Error,2204,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2336,availability,Error,Error,2336,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2468,availability,Error,Error,2468,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2600,availability,Error,Error,2600,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2732,availability,Error,Error,2732,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2868,availability,Error,Error,2868,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:346,deployability,version,versions,346,"So unfortunately, I have no way to check with the nightly (apart if I would change/redevelop a new program). The reason is that the workspace used in my example includes RooTwoSidedCBShape, which is unknown to root, so one needs to switch on first a tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:346,integrability,version,versions,346,"So unfortunately, I have no way to check with the nightly (apart if I would change/redevelop a new program). The reason is that the workspace used in my example includes RooTwoSidedCBShape, which is unknown to root, so one needs to switch on first a tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:525,integrability,pub,public,525,"So unfortunately, I have no way to check with the nightly (apart if I would change/redevelop a new program). The reason is that the workspace used in my example includes RooTwoSidedCBShape, which is unknown to root, so one needs to switch on first a tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1159,integrability,pub,public,1159,"ncludes RooTwoSidedCBShape, which is unknown to root, so one needs to switch on first a tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1115,interoperability,share,shared,1115,"n is that the workspace used in my example includes RooTwoSidedCBShape, which is unknown to root, so one needs to switch on first a tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:346,modifiability,version,versions,346,"So unfortunately, I have no way to check with the nightly (apart if I would change/redevelop a new program). The reason is that the workspace used in my example includes RooTwoSidedCBShape, which is unknown to root, so one needs to switch on first a tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1213,performance,Memor,Memory,1213,"so one needs to switch on first a tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TB",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1247,performance,memor,memory,1247,"tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1274,performance,memor,memory,1274,"to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (Roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1387,performance,Memor,Memory,1387,"can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1412,performance,Error,Error,1412," you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSid",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1544,performance,Error,Error,1544,"emMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSid",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1676,performance,Error,Error,1676,"to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSid",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1808,performance,Error,Error,1808," on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSid",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1940,performance,Error,Error,1940,"license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2072,performance,Error,Error,2072,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2204,performance,Error,Error,2204,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2336,performance,Error,Error,2336,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2468,performance,Error,Error,2468,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2600,performance,Error,Error,2600,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2732,performance,Error,Error,2732,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2868,performance,Error,Error,2868,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:319,reliability,availab,available,319,"So unfortunately, I have no way to check with the nightly (apart if I would change/redevelop a new program). The reason is that the workspace used in my example includes RooTwoSidedCBShape, which is unknown to root, so one needs to switch on first a tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1369,reliability,availab,available,1369,"at it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: tr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:319,safety,avail,available,319,"So unfortunately, I have no way to check with the nightly (apart if I would change/redevelop a new program). The reason is that the workspace used in my example includes RooTwoSidedCBShape, which is unknown to root, so one needs to switch on first a tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1369,safety,avail,available,1369,"at it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: tr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1412,safety,Error,Error,1412," you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSid",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1544,safety,Error,Error,1544,"emMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSid",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1676,safety,Error,Error,1676,"to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSid",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1808,safety,Error,Error,1808," on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSid",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1940,safety,Error,Error,1940,"license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2072,safety,Error,Error,2072,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2204,safety,Error,Error,2204,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2336,safety,Error,Error,2336,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2468,safety,Error,Error,2468,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2600,safety,Error,Error,2600,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2732,safety,Error,Error,2732,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2868,safety,Error,Error,2868,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:270,security,access,access,270,"So unfortunately, I have no way to check with the nightly (apart if I would change/redevelop a new program). The reason is that the workspace used in my example includes RooTwoSidedCBShape, which is unknown to root, so one needs to switch on first a tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:319,security,availab,available,319,"So unfortunately, I have no way to check with the nightly (apart if I would change/redevelop a new program). The reason is that the workspace used in my example includes RooTwoSidedCBShape, which is unknown to root, so one needs to switch on first a tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:366,security,trust,trust,366,"So unfortunately, I have no way to check with the nightly (apart if I would change/redevelop a new program). The reason is that the workspace used in my example includes RooTwoSidedCBShape, which is unknown to root, so one needs to switch on first a tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:477,security,escal,escalier,477,"So unfortunately, I have no way to check with the nightly (apart if I would change/redevelop a new program). The reason is that the workspace used in my example includes RooTwoSidedCBShape, which is unknown to root, so one needs to switch on first a tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:516,security,escal,escalier,516,"So unfortunately, I have no way to check with the nightly (apart if I would change/redevelop a new program). The reason is that the workspace used in my example includes RooTwoSidedCBShape, which is unknown to root, so one needs to switch on first a tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:742,security,Team,Team,742,"So unfortunately, I have no way to check with the nightly (apart if I would change/redevelop a new program). The reason is that the workspace used in my example includes RooTwoSidedCBShape, which is unknown to root, so one needs to switch on first a tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1150,security,escal,escalier,1150,"xample includes RooTwoSidedCBShape, which is unknown to root, so one needs to switch on first a tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedC",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1369,security,availab,available,1369,"at it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: tr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1466,testability,emul,emulated,1466,"es :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Er",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1598,testability,emul,emulated,1598,"-----------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Er",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1730,testability,emul,emulated,1730,"he ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Er",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1862,testability,emul,emulated,1862,"01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). **",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1994,testability,emul,emulated,1994,"-------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid po",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2126,testability,emul,emulated,2126,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2258,testability,emul,emulated,2258,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2390,testability,emul,emulated,2390,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2522,testability,emul,emulated,2522,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2654,testability,emul,emulated,2654,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2786,testability,emul,emulated,2786,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:250,usability,tool,tool,250,"So unfortunately, I have no way to check with the nightly (apart if I would change/redevelop a new program). The reason is that the workspace used in my example includes RooTwoSidedCBShape, which is unknown to root, so one needs to switch on first a tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:305,usability,tool,tools,305,"So unfortunately, I have no way to check with the nightly (apart if I would change/redevelop a new program). The reason is that the workspace used in my example includes RooTwoSidedCBShape, which is unknown to root, so one needs to switch on first a tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:569,usability,Minim,Minimum,569,"So unfortunately, I have no way to check with the nightly (apart if I would change/redevelop a new program). The reason is that the workspace used in my example includes RooTwoSidedCBShape, which is unknown to root, so one needs to switch on first a tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:920,usability,help,help,920,"So unfortunately, I have no way to check with the nightly (apart if I would change/redevelop a new program). The reason is that the workspace used in my example includes RooTwoSidedCBShape, which is unknown to root, so one needs to switch on first a tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1060,usability,Minim,Minimum,1060," if I would change/redevelop a new program). The reason is that the workspace used in my example includes RooTwoSidedCBShape, which is unknown to root, so one needs to switch on first a tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TO",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1213,usability,Memor,Memory,1213,"so one needs to switch on first a tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TB",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1247,usability,memor,memory,1247,"tool that allows to access to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1274,usability,memor,memory,1274,"to RooTwoSidedCBShape. Such tools are not available with recent root versions. So I just trust that it works but can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (Roo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1387,usability,Memor,Memory,1387,"can't check. If so, maybe you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1412,usability,Error,Error,1412," you may put as ""resolved"". With root 6.29.01, this gives :. [escalier@lxplus745 /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSid",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1544,usability,Error,Error,1544,"emMemory] root -b -q ""Minimum.C+()"" |tee log_6.29.01. ------------------------------------------------------------------. | Welcome to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSid",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1676,usability,Error,Error,1676,"to ROOT 6.29/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSid",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1808,usability,Error,Error,1808," on Jan 27 2023, 00:37:00 |. | From heads/master@v6-29-01-357-g4ef94f4 |. | With g++ (GCC) 11.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSid",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:1940,usability,Error,Error,1940,"license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. Processing Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2072,usability,Error,Error,2072,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2204,usability,Error,Error,2204,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2336,usability,Error,Error,2336,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2468,usability,Error,Error,2468,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2600,usability,Error,Error,2600,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2732,usability,Error,Error,2732,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:2868,usability,Error,Error,2868,"g Minimum.C+()... Info in <TUnixSystem::ACLiC>: creating shared library /afs/cern.ch/work/e/escalier/public/ForOthers/ProblemMemory/./Minimum_C.so. Survey Memory, beginning of program. res memory=481.965 Mbytes. vir memory=760.32 Mbytes. Warning in <TClass::Init>: no dictionary for class RooTwoSidedCBShape is available. Survey Memory, after open file. Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). Error in <TBufferFile::ReadObject>: trying to read an emulated class (RooTwoSidedCBShape) to store in a compiled pointer (TObject). *** Error in `/cvmfs/sft-nightlies.cern.ch/lcg/nightlies/dev3/Fri/ROOT/HEAD/x86_64-centos7-gcc11-opt/bin/root.exe': free(): invalid pointer: 0x00007f1e9976b218 ***. ======= Backtrace: =========.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8984:13,usability,close,close,13,"Okay, then I close this issue now! Feel free to open a new one if you see problems again.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8984
https://github.com/root-project/root/issues/8985:7,integrability,translat,translating,7,"Ok for translating the tutorial to DistRDF 👍 . About the local multi-process execution: this implies we'd need to create a local backend that spawns local Python processes. Is that something we want, since we can just fall back to regular MT RDF for local runs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8985
https://github.com/root-project/root/issues/8985:7,interoperability,translat,translating,7,"Ok for translating the tutorial to DistRDF 👍 . About the local multi-process execution: this implies we'd need to create a local backend that spawns local Python processes. Is that something we want, since we can just fall back to regular MT RDF for local runs?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8985
https://github.com/root-project/root/issues/8985:66,safety,test,testing,66,Having local multiprocess distRDF might be really useful also for testing?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8985
https://github.com/root-project/root/issues/8985:66,testability,test,testing,66,Having local multiprocess distRDF might be really useful also for testing?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8985
https://github.com/root-project/root/issues/8985:147,energy efficiency,schedul,scheduler,147,"Yes, perhaps just for testing? It would allow to test the creation of ranges and the task processing in separate worker processes with no external scheduler (now we can do the same local runs with Spark and Dask but we need the corresponding libraries). Performance-wise still MT RDF should be the best.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8985
https://github.com/root-project/root/issues/8985:147,performance,schedul,scheduler,147,"Yes, perhaps just for testing? It would allow to test the creation of ranges and the task processing in separate worker processes with no external scheduler (now we can do the same local runs with Spark and Dask but we need the corresponding libraries). Performance-wise still MT RDF should be the best.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8985
https://github.com/root-project/root/issues/8985:254,performance,Perform,Performance-wise,254,"Yes, perhaps just for testing? It would allow to test the creation of ranges and the task processing in separate worker processes with no external scheduler (now we can do the same local runs with Spark and Dask but we need the corresponding libraries). Performance-wise still MT RDF should be the best.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8985
https://github.com/root-project/root/issues/8985:22,safety,test,testing,22,"Yes, perhaps just for testing? It would allow to test the creation of ranges and the task processing in separate worker processes with no external scheduler (now we can do the same local runs with Spark and Dask but we need the corresponding libraries). Performance-wise still MT RDF should be the best.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8985
https://github.com/root-project/root/issues/8985:49,safety,test,test,49,"Yes, perhaps just for testing? It would allow to test the creation of ranges and the task processing in separate worker processes with no external scheduler (now we can do the same local runs with Spark and Dask but we need the corresponding libraries). Performance-wise still MT RDF should be the best.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8985
https://github.com/root-project/root/issues/8985:22,testability,test,testing,22,"Yes, perhaps just for testing? It would allow to test the creation of ranges and the task processing in separate worker processes with no external scheduler (now we can do the same local runs with Spark and Dask but we need the corresponding libraries). Performance-wise still MT RDF should be the best.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8985
https://github.com/root-project/root/issues/8985:49,testability,test,test,49,"Yes, perhaps just for testing? It would allow to test the creation of ranges and the task processing in separate worker processes with no external scheduler (now we can do the same local runs with Spark and Dask but we need the corresponding libraries). Performance-wise still MT RDF should be the best.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8985
https://github.com/root-project/root/issues/8985:254,usability,Perform,Performance-wise,254,"Yes, perhaps just for testing? It would allow to test the creation of ranges and the task processing in separate worker processes with no external scheduler (now we can do the same local runs with Spark and Dask but we need the corresponding libraries). Performance-wise still MT RDF should be the best.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8985
https://github.com/root-project/root/issues/8985:278,deployability,releas,releases-,278,"After a careful consideration, we decided to close this item in particular - i.e. we will not proceed with the H1 Analysis translation to distRDF. Instead, we will focus on providing a distRDF tutorial with the recently published CMS OpenData (https://opendata.cern.ch/docs/cms-releases-2016data-2024) as we believe such a tutorial will serve the community best.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8985
https://github.com/root-project/root/issues/8985:123,integrability,translat,translation,123,"After a careful consideration, we decided to close this item in particular - i.e. we will not proceed with the H1 Analysis translation to distRDF. Instead, we will focus on providing a distRDF tutorial with the recently published CMS OpenData (https://opendata.cern.ch/docs/cms-releases-2016data-2024) as we believe such a tutorial will serve the community best.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8985
https://github.com/root-project/root/issues/8985:220,integrability,pub,published,220,"After a careful consideration, we decided to close this item in particular - i.e. we will not proceed with the H1 Analysis translation to distRDF. Instead, we will focus on providing a distRDF tutorial with the recently published CMS OpenData (https://opendata.cern.ch/docs/cms-releases-2016data-2024) as we believe such a tutorial will serve the community best.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8985
https://github.com/root-project/root/issues/8985:123,interoperability,translat,translation,123,"After a careful consideration, we decided to close this item in particular - i.e. we will not proceed with the H1 Analysis translation to distRDF. Instead, we will focus on providing a distRDF tutorial with the recently published CMS OpenData (https://opendata.cern.ch/docs/cms-releases-2016data-2024) as we believe such a tutorial will serve the community best.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8985
https://github.com/root-project/root/issues/8985:45,usability,close,close,45,"After a careful consideration, we decided to close this item in particular - i.e. we will not proceed with the H1 Analysis translation to distRDF. Instead, we will focus on providing a distRDF tutorial with the recently published CMS OpenData (https://opendata.cern.ch/docs/cms-releases-2016data-2024) as we believe such a tutorial will serve the community best.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8985
https://github.com/root-project/root/issues/8989:62,deployability,releas,releases,62,"Hello @philippe554 ,. Indeed, we changed this behaviour a few releases ago, IIRC the reason was that the progressive output implementation had some problems, so we opted for capturing the output and releasing it only at the end, even at the expense of not covering cases such a progress bar.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8989
https://github.com/root-project/root/issues/8989:199,deployability,releas,releasing,199,"Hello @philippe554 ,. Indeed, we changed this behaviour a few releases ago, IIRC the reason was that the progressive output implementation had some problems, so we opted for capturing the output and releasing it only at the end, even at the expense of not covering cases such a progress bar.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8989
https://github.com/root-project/root/issues/8989:46,usability,behavi,behaviour,46,"Hello @philippe554 ,. Indeed, we changed this behaviour a few releases ago, IIRC the reason was that the progressive output implementation had some problems, so we opted for capturing the output and releasing it only at the end, even at the expense of not covering cases such a progress bar.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8989
https://github.com/root-project/root/issues/8989:105,usability,progress,progressive,105,"Hello @philippe554 ,. Indeed, we changed this behaviour a few releases ago, IIRC the reason was that the progressive output implementation had some problems, so we opted for capturing the output and releasing it only at the end, even at the expense of not covering cases such a progress bar.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8989
https://github.com/root-project/root/issues/8989:278,usability,progress,progress,278,"Hello @philippe554 ,. Indeed, we changed this behaviour a few releases ago, IIRC the reason was that the progressive output implementation had some problems, so we opted for capturing the output and releasing it only at the end, even at the expense of not covering cases such a progress bar.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8989
https://github.com/root-project/root/issues/8989:29,deployability,updat,update,29,Thank you @etejedor for this update.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8989
https://github.com/root-project/root/issues/8989:29,safety,updat,update,29,Thank you @etejedor for this update.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8989
https://github.com/root-project/root/issues/8989:29,security,updat,update,29,Thank you @etejedor for this update.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/8989
https://github.com/root-project/root/pull/8993:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu2004/default with flags -Dtmva-sofie=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8993
https://github.com/root-project/root/pull/8994:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8994
https://github.com/root-project/root/pull/8995:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8995
https://github.com/root-project/root/pull/8995:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8995
https://github.com/root-project/root/pull/8995:4,availability,failur,failures,4,The failures are unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8995
https://github.com/root-project/root/pull/8995:4,deployability,fail,failures,4,The failures are unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8995
https://github.com/root-project/root/pull/8995:4,performance,failur,failures,4,The failures are unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8995
https://github.com/root-project/root/pull/8995:4,reliability,fail,failures,4,The failures are unrelated,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/8995
https://github.com/root-project/root/pull/9000:11,deployability,build,build,11,@phsft-bot build just on ROOT-ubuntu2004/default with flags -Dtmva-sofie=On,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9000
https://github.com/root-project/root/issues/9001:43,interoperability,platform,platform,43,Does the reading work properly on the same platform (both no warning and the correct value)? What is the array value for the example provided?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9001
https://github.com/root-project/root/issues/9001:0,reliability,Doe,Does,0,Does the reading work properly on the same platform (both no warning and the correct value)? What is the array value for the example provided?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9001
https://github.com/root-project/root/issues/9001:32,performance,time,timestamp,32,The actual value should be some timestamp around 1630659771715.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9001
https://github.com/root-project/root/pull/9004:74,availability,error,errors,74,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:180,availability,error,error,180,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:319,availability,error,error,319,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:449,availability,error,error,449,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:579,availability,error,error,579,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:5,deployability,build,building,5,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:20,energy efficiency,GPU,GPU,20,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:139,integrability,batch,batchcompute,139,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:218,integrability,transform,transform,218,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:284,integrability,batch,batchcompute,284,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:414,integrability,batch,batchcompute,414,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:544,integrability,batch,batchcompute,544,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:218,interoperability,transform,transform,218,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:339,modifiability,variab,variable,339,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:469,modifiability,variab,variable,469,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:599,modifiability,variab,variable,599,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:20,performance,GPU,GPU,20,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:74,performance,error,errors,74,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:139,performance,batch,batchcompute,139,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:180,performance,error,error,180,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:284,performance,batch,batchcompute,284,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:319,performance,error,error,319,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:414,performance,batch,batchcompute,414,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:449,performance,error,error,449,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:544,performance,batch,batchcompute,544,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:579,performance,error,error,579,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:74,safety,error,errors,74,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:180,safety,error,error,180,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:319,safety,error,error,319,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:449,safety,error,error,449,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:579,safety,error,error,579,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:74,usability,error,errors,74,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:180,usability,error,error,180,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:319,usability,error,error,319,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:449,usability,error,error,449,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9004:579,usability,error,error,579,"When building on my GPU machine , using -Dcuda=On, I am getting this cuda errors in compiling:. ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooBatchCompute.cu(43): error: namespace ""std"" has no member ""transform"". ```. and . ```. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(284): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(294): error: A __device__ variable cannot be marked constexpr. /home/moneta/rootgit/root_dev4/roofit/batchcompute/src/RooMath.cxx(304): error: A __device__ variable cannot be marked constexpr. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9004
https://github.com/root-project/root/pull/9005:90,usability,undo,undoes,90,@Linev The first(2cf3535) and the last commit(3262d53) should be deleted. The last commit undoes the first. I could make an new PR if you think it is necessary.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9005
https://github.com/root-project/root/pull/9005:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9005
https://github.com/root-project/root/pull/9005:18,usability,undo,undoes,18,"> The last commit undoes the first. I could make an new PR if you think it is necessary. Yes, please create new PR, removing these commits",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9005
https://github.com/root-project/root/pull/9005:28,availability,error,error,28,@alja Please check compiler error on Mac,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9005
https://github.com/root-project/root/pull/9005:28,performance,error,error,28,@alja Please check compiler error on Mac,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9005
https://github.com/root-project/root/pull/9005:28,safety,error,error,28,@alja Please check compiler error on Mac,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9005
https://github.com/root-project/root/pull/9005:28,usability,error,error,28,@alja Please check compiler error on Mac,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9005
https://github.com/root-project/root/pull/9008:29,safety,test,tested,29,"Thanks for the suggestion. I tested it and it works as well. Since in the names the c++ typenames were used instead of the ROOT typedefs, I assumed the class would always expext the c++ typename which is the same for Float_t and Float16_t as well as Double_t and Double32_t. I will also add a small test using the TTreeReader soon.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:299,safety,test,test,299,"Thanks for the suggestion. I tested it and it works as well. Since in the names the c++ typenames were used instead of the ROOT typedefs, I assumed the class would always expext the c++ typename which is the same for Float_t and Float16_t as well as Double_t and Double32_t. I will also add a small test using the TTreeReader soon.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:29,testability,test,tested,29,"Thanks for the suggestion. I tested it and it works as well. Since in the names the c++ typenames were used instead of the ROOT typedefs, I assumed the class would always expext the c++ typename which is the same for Float_t and Float16_t as well as Double_t and Double32_t. I will also add a small test using the TTreeReader soon.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:299,testability,test,test,299,"Thanks for the suggestion. I tested it and it works as well. Since in the names the c++ typenames were used instead of the ROOT typedefs, I assumed the class would always expext the c++ typename which is the same for Float_t and Float16_t as well as Double_t and Double32_t. I will also add a small test using the TTreeReader soon.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:418,deployability,automat,automatically,418,"> See command and If you could also add a test for this features (eg. a TTreeReader usage) that would be great. I realized there was already a test for using TTreeReader with the truncated datatypes, however it was not properly working and thereby unable to detect the problem since it stored the Float16_t / Double32_t data as regular Float_t / Double_t. The reason is that the used TTree::Branch method is unable to automatically detect the Float16_t / Double32_t datatype since like Float_t / Double_t they are typedefs of float / double which results in typeid(Float_t) = typeid(Float16_t) = typeid(float), same for the double types. For these reasons, the truncated datatypes always need to be specified via the leaflist. I changed the test accordingly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:699,interoperability,specif,specified,699,"> See command and If you could also add a test for this features (eg. a TTreeReader usage) that would be great. I realized there was already a test for using TTreeReader with the truncated datatypes, however it was not properly working and thereby unable to detect the problem since it stored the Float16_t / Double32_t data as regular Float_t / Double_t. The reason is that the used TTree::Branch method is unable to automatically detect the Float16_t / Double32_t datatype since like Float_t / Double_t they are typedefs of float / double which results in typeid(Float_t) = typeid(Float16_t) = typeid(float), same for the double types. For these reasons, the truncated datatypes always need to be specified via the leaflist. I changed the test accordingly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:42,safety,test,test,42,"> See command and If you could also add a test for this features (eg. a TTreeReader usage) that would be great. I realized there was already a test for using TTreeReader with the truncated datatypes, however it was not properly working and thereby unable to detect the problem since it stored the Float16_t / Double32_t data as regular Float_t / Double_t. The reason is that the used TTree::Branch method is unable to automatically detect the Float16_t / Double32_t datatype since like Float_t / Double_t they are typedefs of float / double which results in typeid(Float_t) = typeid(Float16_t) = typeid(float), same for the double types. For these reasons, the truncated datatypes always need to be specified via the leaflist. I changed the test accordingly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:143,safety,test,test,143,"> See command and If you could also add a test for this features (eg. a TTreeReader usage) that would be great. I realized there was already a test for using TTreeReader with the truncated datatypes, however it was not properly working and thereby unable to detect the problem since it stored the Float16_t / Double32_t data as regular Float_t / Double_t. The reason is that the used TTree::Branch method is unable to automatically detect the Float16_t / Double32_t datatype since like Float_t / Double_t they are typedefs of float / double which results in typeid(Float_t) = typeid(Float16_t) = typeid(float), same for the double types. For these reasons, the truncated datatypes always need to be specified via the leaflist. I changed the test accordingly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:258,safety,detect,detect,258,"> See command and If you could also add a test for this features (eg. a TTreeReader usage) that would be great. I realized there was already a test for using TTreeReader with the truncated datatypes, however it was not properly working and thereby unable to detect the problem since it stored the Float16_t / Double32_t data as regular Float_t / Double_t. The reason is that the used TTree::Branch method is unable to automatically detect the Float16_t / Double32_t datatype since like Float_t / Double_t they are typedefs of float / double which results in typeid(Float_t) = typeid(Float16_t) = typeid(float), same for the double types. For these reasons, the truncated datatypes always need to be specified via the leaflist. I changed the test accordingly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:432,safety,detect,detect,432,"> See command and If you could also add a test for this features (eg. a TTreeReader usage) that would be great. I realized there was already a test for using TTreeReader with the truncated datatypes, however it was not properly working and thereby unable to detect the problem since it stored the Float16_t / Double32_t data as regular Float_t / Double_t. The reason is that the used TTree::Branch method is unable to automatically detect the Float16_t / Double32_t datatype since like Float_t / Double_t they are typedefs of float / double which results in typeid(Float_t) = typeid(Float16_t) = typeid(float), same for the double types. For these reasons, the truncated datatypes always need to be specified via the leaflist. I changed the test accordingly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:741,safety,test,test,741,"> See command and If you could also add a test for this features (eg. a TTreeReader usage) that would be great. I realized there was already a test for using TTreeReader with the truncated datatypes, however it was not properly working and thereby unable to detect the problem since it stored the Float16_t / Double32_t data as regular Float_t / Double_t. The reason is that the used TTree::Branch method is unable to automatically detect the Float16_t / Double32_t datatype since like Float_t / Double_t they are typedefs of float / double which results in typeid(Float_t) = typeid(Float16_t) = typeid(float), same for the double types. For these reasons, the truncated datatypes always need to be specified via the leaflist. I changed the test accordingly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:258,security,detect,detect,258,"> See command and If you could also add a test for this features (eg. a TTreeReader usage) that would be great. I realized there was already a test for using TTreeReader with the truncated datatypes, however it was not properly working and thereby unable to detect the problem since it stored the Float16_t / Double32_t data as regular Float_t / Double_t. The reason is that the used TTree::Branch method is unable to automatically detect the Float16_t / Double32_t datatype since like Float_t / Double_t they are typedefs of float / double which results in typeid(Float_t) = typeid(Float16_t) = typeid(float), same for the double types. For these reasons, the truncated datatypes always need to be specified via the leaflist. I changed the test accordingly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:432,security,detect,detect,432,"> See command and If you could also add a test for this features (eg. a TTreeReader usage) that would be great. I realized there was already a test for using TTreeReader with the truncated datatypes, however it was not properly working and thereby unable to detect the problem since it stored the Float16_t / Double32_t data as regular Float_t / Double_t. The reason is that the used TTree::Branch method is unable to automatically detect the Float16_t / Double32_t datatype since like Float_t / Double_t they are typedefs of float / double which results in typeid(Float_t) = typeid(Float16_t) = typeid(float), same for the double types. For these reasons, the truncated datatypes always need to be specified via the leaflist. I changed the test accordingly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:42,testability,test,test,42,"> See command and If you could also add a test for this features (eg. a TTreeReader usage) that would be great. I realized there was already a test for using TTreeReader with the truncated datatypes, however it was not properly working and thereby unable to detect the problem since it stored the Float16_t / Double32_t data as regular Float_t / Double_t. The reason is that the used TTree::Branch method is unable to automatically detect the Float16_t / Double32_t datatype since like Float_t / Double_t they are typedefs of float / double which results in typeid(Float_t) = typeid(Float16_t) = typeid(float), same for the double types. For these reasons, the truncated datatypes always need to be specified via the leaflist. I changed the test accordingly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:143,testability,test,test,143,"> See command and If you could also add a test for this features (eg. a TTreeReader usage) that would be great. I realized there was already a test for using TTreeReader with the truncated datatypes, however it was not properly working and thereby unable to detect the problem since it stored the Float16_t / Double32_t data as regular Float_t / Double_t. The reason is that the used TTree::Branch method is unable to automatically detect the Float16_t / Double32_t datatype since like Float_t / Double_t they are typedefs of float / double which results in typeid(Float_t) = typeid(Float16_t) = typeid(float), same for the double types. For these reasons, the truncated datatypes always need to be specified via the leaflist. I changed the test accordingly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:418,testability,automat,automatically,418,"> See command and If you could also add a test for this features (eg. a TTreeReader usage) that would be great. I realized there was already a test for using TTreeReader with the truncated datatypes, however it was not properly working and thereby unable to detect the problem since it stored the Float16_t / Double32_t data as regular Float_t / Double_t. The reason is that the used TTree::Branch method is unable to automatically detect the Float16_t / Double32_t datatype since like Float_t / Double_t they are typedefs of float / double which results in typeid(Float_t) = typeid(Float16_t) = typeid(float), same for the double types. For these reasons, the truncated datatypes always need to be specified via the leaflist. I changed the test accordingly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:741,testability,test,test,741,"> See command and If you could also add a test for this features (eg. a TTreeReader usage) that would be great. I realized there was already a test for using TTreeReader with the truncated datatypes, however it was not properly working and thereby unable to detect the problem since it stored the Float16_t / Double32_t data as regular Float_t / Double_t. The reason is that the used TTree::Branch method is unable to automatically detect the Float16_t / Double32_t datatype since like Float_t / Double_t they are typedefs of float / double which results in typeid(Float_t) = typeid(Float16_t) = typeid(float), same for the double types. For these reasons, the truncated datatypes always need to be specified via the leaflist. I changed the test accordingly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:6,usability,command,command,6,"> See command and If you could also add a test for this features (eg. a TTreeReader usage) that would be great. I realized there was already a test for using TTreeReader with the truncated datatypes, however it was not properly working and thereby unable to detect the problem since it stored the Float16_t / Double32_t data as regular Float_t / Double_t. The reason is that the used TTree::Branch method is unable to automatically detect the Float16_t / Double32_t datatype since like Float_t / Double_t they are typedefs of float / double which results in typeid(Float_t) = typeid(Float16_t) = typeid(float), same for the double types. For these reasons, the truncated datatypes always need to be specified via the leaflist. I changed the test accordingly.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:98,deployability,fail,fails,98,"It seems to me that the test projectroot.roottest.root.io.double32.roottest_root_io_double32_make fails just because its reference file needs to be updated now. At least I don't see any critical problem with that test. The test projectroot.roottest.root.tree.cache.roottest_root_tree_cache_TooSmall failed once too, but on my local machine it is working. Unfortunately I can no longer access the build logs with my CERN account. Most probably because it was converted to a ""Lightweight Account"" so I am unable to investigate this further.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:148,deployability,updat,updated,148,"It seems to me that the test projectroot.roottest.root.io.double32.roottest_root_io_double32_make fails just because its reference file needs to be updated now. At least I don't see any critical problem with that test. The test projectroot.roottest.root.tree.cache.roottest_root_tree_cache_TooSmall failed once too, but on my local machine it is working. Unfortunately I can no longer access the build logs with my CERN account. Most probably because it was converted to a ""Lightweight Account"" so I am unable to investigate this further.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:299,deployability,fail,failed,299,"It seems to me that the test projectroot.roottest.root.io.double32.roottest_root_io_double32_make fails just because its reference file needs to be updated now. At least I don't see any critical problem with that test. The test projectroot.roottest.root.tree.cache.roottest_root_tree_cache_TooSmall failed once too, but on my local machine it is working. Unfortunately I can no longer access the build logs with my CERN account. Most probably because it was converted to a ""Lightweight Account"" so I am unable to investigate this further.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:396,deployability,build,build,396,"It seems to me that the test projectroot.roottest.root.io.double32.roottest_root_io_double32_make fails just because its reference file needs to be updated now. At least I don't see any critical problem with that test. The test projectroot.roottest.root.tree.cache.roottest_root_tree_cache_TooSmall failed once too, but on my local machine it is working. Unfortunately I can no longer access the build logs with my CERN account. Most probably because it was converted to a ""Lightweight Account"" so I am unable to investigate this further.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:402,deployability,log,logs,402,"It seems to me that the test projectroot.roottest.root.io.double32.roottest_root_io_double32_make fails just because its reference file needs to be updated now. At least I don't see any critical problem with that test. The test projectroot.roottest.root.tree.cache.roottest_root_tree_cache_TooSmall failed once too, but on my local machine it is working. Unfortunately I can no longer access the build logs with my CERN account. Most probably because it was converted to a ""Lightweight Account"" so I am unable to investigate this further.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:259,performance,cach,cache,259,"It seems to me that the test projectroot.roottest.root.io.double32.roottest_root_io_double32_make fails just because its reference file needs to be updated now. At least I don't see any critical problem with that test. The test projectroot.roottest.root.tree.cache.roottest_root_tree_cache_TooSmall failed once too, but on my local machine it is working. Unfortunately I can no longer access the build logs with my CERN account. Most probably because it was converted to a ""Lightweight Account"" so I am unable to investigate this further.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:98,reliability,fail,fails,98,"It seems to me that the test projectroot.roottest.root.io.double32.roottest_root_io_double32_make fails just because its reference file needs to be updated now. At least I don't see any critical problem with that test. The test projectroot.roottest.root.tree.cache.roottest_root_tree_cache_TooSmall failed once too, but on my local machine it is working. Unfortunately I can no longer access the build logs with my CERN account. Most probably because it was converted to a ""Lightweight Account"" so I am unable to investigate this further.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:299,reliability,fail,failed,299,"It seems to me that the test projectroot.roottest.root.io.double32.roottest_root_io_double32_make fails just because its reference file needs to be updated now. At least I don't see any critical problem with that test. The test projectroot.roottest.root.tree.cache.roottest_root_tree_cache_TooSmall failed once too, but on my local machine it is working. Unfortunately I can no longer access the build logs with my CERN account. Most probably because it was converted to a ""Lightweight Account"" so I am unable to investigate this further.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:24,safety,test,test,24,"It seems to me that the test projectroot.roottest.root.io.double32.roottest_root_io_double32_make fails just because its reference file needs to be updated now. At least I don't see any critical problem with that test. The test projectroot.roottest.root.tree.cache.roottest_root_tree_cache_TooSmall failed once too, but on my local machine it is working. Unfortunately I can no longer access the build logs with my CERN account. Most probably because it was converted to a ""Lightweight Account"" so I am unable to investigate this further.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:148,safety,updat,updated,148,"It seems to me that the test projectroot.roottest.root.io.double32.roottest_root_io_double32_make fails just because its reference file needs to be updated now. At least I don't see any critical problem with that test. The test projectroot.roottest.root.tree.cache.roottest_root_tree_cache_TooSmall failed once too, but on my local machine it is working. Unfortunately I can no longer access the build logs with my CERN account. Most probably because it was converted to a ""Lightweight Account"" so I am unable to investigate this further.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:213,safety,test,test,213,"It seems to me that the test projectroot.roottest.root.io.double32.roottest_root_io_double32_make fails just because its reference file needs to be updated now. At least I don't see any critical problem with that test. The test projectroot.roottest.root.tree.cache.roottest_root_tree_cache_TooSmall failed once too, but on my local machine it is working. Unfortunately I can no longer access the build logs with my CERN account. Most probably because it was converted to a ""Lightweight Account"" so I am unable to investigate this further.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:223,safety,test,test,223,"It seems to me that the test projectroot.roottest.root.io.double32.roottest_root_io_double32_make fails just because its reference file needs to be updated now. At least I don't see any critical problem with that test. The test projectroot.roottest.root.tree.cache.roottest_root_tree_cache_TooSmall failed once too, but on my local machine it is working. Unfortunately I can no longer access the build logs with my CERN account. Most probably because it was converted to a ""Lightweight Account"" so I am unable to investigate this further.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:402,safety,log,logs,402,"It seems to me that the test projectroot.roottest.root.io.double32.roottest_root_io_double32_make fails just because its reference file needs to be updated now. At least I don't see any critical problem with that test. The test projectroot.roottest.root.tree.cache.roottest_root_tree_cache_TooSmall failed once too, but on my local machine it is working. Unfortunately I can no longer access the build logs with my CERN account. Most probably because it was converted to a ""Lightweight Account"" so I am unable to investigate this further.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:148,security,updat,updated,148,"It seems to me that the test projectroot.roottest.root.io.double32.roottest_root_io_double32_make fails just because its reference file needs to be updated now. At least I don't see any critical problem with that test. The test projectroot.roottest.root.tree.cache.roottest_root_tree_cache_TooSmall failed once too, but on my local machine it is working. Unfortunately I can no longer access the build logs with my CERN account. Most probably because it was converted to a ""Lightweight Account"" so I am unable to investigate this further.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:385,security,access,access,385,"It seems to me that the test projectroot.roottest.root.io.double32.roottest_root_io_double32_make fails just because its reference file needs to be updated now. At least I don't see any critical problem with that test. The test projectroot.roottest.root.tree.cache.roottest_root_tree_cache_TooSmall failed once too, but on my local machine it is working. Unfortunately I can no longer access the build logs with my CERN account. Most probably because it was converted to a ""Lightweight Account"" so I am unable to investigate this further.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:402,security,log,logs,402,"It seems to me that the test projectroot.roottest.root.io.double32.roottest_root_io_double32_make fails just because its reference file needs to be updated now. At least I don't see any critical problem with that test. The test projectroot.roottest.root.tree.cache.roottest_root_tree_cache_TooSmall failed once too, but on my local machine it is working. Unfortunately I can no longer access the build logs with my CERN account. Most probably because it was converted to a ""Lightweight Account"" so I am unable to investigate this further.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:24,testability,test,test,24,"It seems to me that the test projectroot.roottest.root.io.double32.roottest_root_io_double32_make fails just because its reference file needs to be updated now. At least I don't see any critical problem with that test. The test projectroot.roottest.root.tree.cache.roottest_root_tree_cache_TooSmall failed once too, but on my local machine it is working. Unfortunately I can no longer access the build logs with my CERN account. Most probably because it was converted to a ""Lightweight Account"" so I am unable to investigate this further.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:213,testability,test,test,213,"It seems to me that the test projectroot.roottest.root.io.double32.roottest_root_io_double32_make fails just because its reference file needs to be updated now. At least I don't see any critical problem with that test. The test projectroot.roottest.root.tree.cache.roottest_root_tree_cache_TooSmall failed once too, but on my local machine it is working. Unfortunately I can no longer access the build logs with my CERN account. Most probably because it was converted to a ""Lightweight Account"" so I am unable to investigate this further.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:223,testability,test,test,223,"It seems to me that the test projectroot.roottest.root.io.double32.roottest_root_io_double32_make fails just because its reference file needs to be updated now. At least I don't see any critical problem with that test. The test projectroot.roottest.root.tree.cache.roottest_root_tree_cache_TooSmall failed once too, but on my local machine it is working. Unfortunately I can no longer access the build logs with my CERN account. Most probably because it was converted to a ""Lightweight Account"" so I am unable to investigate this further.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:402,testability,log,logs,402,"It seems to me that the test projectroot.roottest.root.io.double32.roottest_root_io_double32_make fails just because its reference file needs to be updated now. At least I don't see any critical problem with that test. The test projectroot.roottest.root.tree.cache.roottest_root_tree_cache_TooSmall failed once too, but on my local machine it is working. Unfortunately I can no longer access the build logs with my CERN account. Most probably because it was converted to a ""Lightweight Account"" so I am unable to investigate this further.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:87,availability,failur,failure,87,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:87,deployability,fail,failure,87,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:128,deployability,fail,fails,128,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:313,deployability,log,log,313,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:348,deployability,log,log,348,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:410,deployability,log,log,410,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:445,deployability,log,log,445,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:495,deployability,log,log,495,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:530,deployability,log,log,530,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:579,deployability,log,log,579,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:614,deployability,log,log,614,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:664,deployability,log,log,664,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:699,deployability,log,log,699,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:354,energy efficiency,optim,optimized,354,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:87,performance,failur,failure,87,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:354,performance,optimiz,optimized,354,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:87,reliability,fail,failure,87,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:128,reliability,fail,fails,128,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:313,safety,log,log,313,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:348,safety,log,log,348,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:410,safety,log,log,410,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:445,safety,log,log,445,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:495,safety,log,log,495,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:530,safety,log,log,530,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:579,safety,log,log,579,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:614,safety,log,log,614,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:664,safety,log,log,664,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:699,safety,log,log,699,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:313,security,log,log,313,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:348,security,log,log,348,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:410,security,log,log,410,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:445,security,log,log,445,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:495,security,log,log,495,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:530,security,log,log,530,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:579,security,log,log,579,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:614,security,log,log,614,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:664,security,log,log,664,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:699,security,log,log,699,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:313,testability,log,log,313,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:348,testability,log,log,348,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:410,testability,log,log,410,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:445,testability,log,log,445,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:495,testability,log,log,495,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:530,testability,log,log,530,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:579,testability,log,log,579,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:614,testability,log,log,614,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:664,testability,log,log,664,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:699,testability,log,log,699,"Unfortunately the projectroot.roottest.root.io.double32.roottest_root_io_double32_make failure is a real issue. It, surpringly, fails to merge some consecutive `Double32_t` data member that it was able to before (so the issue appear in `TStreamerInfo::Compile`):. ```. - i= 3, ff2 type= 29, offset= [deleted from log], len=4, method= [deleted from log] [optimized]. - i= 4, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. + i= 3, ff2 type= 29, offset= [deleted from log], len=3, method= [deleted from log]. + i= 4, ff3 type= 9, offset= [deleted from log], len=1, method= [deleted from log]. + i= 5, ff4 type= 49, offset= [deleted from log], len=1, method= [deleted from log]. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:23,deployability,version,version,23,Note that the complete version of this PR is at https://github.com/root-project/root/pull/11261 for the main branch and https://github.com/root-project/root/pull/11292 for the v6.24 patch branch.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:182,deployability,patch,patch,182,Note that the complete version of this PR is at https://github.com/root-project/root/pull/11261 for the main branch and https://github.com/root-project/root/pull/11292 for the v6.24 patch branch.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:23,integrability,version,version,23,Note that the complete version of this PR is at https://github.com/root-project/root/pull/11261 for the main branch and https://github.com/root-project/root/pull/11292 for the v6.24 patch branch.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:23,modifiability,version,version,23,Note that the complete version of this PR is at https://github.com/root-project/root/pull/11261 for the main branch and https://github.com/root-project/root/pull/11292 for the v6.24 patch branch.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:14,safety,compl,complete,14,Note that the complete version of this PR is at https://github.com/root-project/root/pull/11261 for the main branch and https://github.com/root-project/root/pull/11292 for the v6.24 patch branch.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:182,safety,patch,patch,182,Note that the complete version of this PR is at https://github.com/root-project/root/pull/11261 for the main branch and https://github.com/root-project/root/pull/11292 for the v6.24 patch branch.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:14,security,compl,complete,14,Note that the complete version of this PR is at https://github.com/root-project/root/pull/11261 for the main branch and https://github.com/root-project/root/pull/11292 for the v6.24 patch branch.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9008:182,security,patch,patch,182,Note that the complete version of this PR is at https://github.com/root-project/root/pull/11261 for the main branch and https://github.com/root-project/root/pull/11292 for the v6.24 patch branch.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9008
https://github.com/root-project/root/pull/9009:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9009
https://github.com/root-project/root/pull/9010:17,performance,cach,cache,17,How does the new cache handle the typical cache of a file being edited and then reloaded?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:42,performance,cach,cache,42,How does the new cache handle the typical cache of a file being edited and then reloaded?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:4,reliability,doe,does,4,How does the new cache handle the typical cache of a file being edited and then reloaded?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:193,deployability,log,logic,193,"> How does the new cache handle the typical cache of a file being edited and then reloaded? While being loaded by the same path and when being matched against itself, it should hit the strncmp logic and exit the function. The race condition causing false positives or false negatives can only be triggered by accessing via different paths to what was or should now be the same file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:104,energy efficiency,load,loaded,104,"> How does the new cache handle the typical cache of a file being edited and then reloaded? While being loaded by the same path and when being matched against itself, it should hit the strncmp logic and exit the function. The race condition causing false positives or false negatives can only be triggered by accessing via different paths to what was or should now be the same file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:19,performance,cach,cache,19,"> How does the new cache handle the typical cache of a file being edited and then reloaded? While being loaded by the same path and when being matched against itself, it should hit the strncmp logic and exit the function. The race condition causing false positives or false negatives can only be triggered by accessing via different paths to what was or should now be the same file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:44,performance,cach,cache,44,"> How does the new cache handle the typical cache of a file being edited and then reloaded? While being loaded by the same path and when being matched against itself, it should hit the strncmp logic and exit the function. The race condition causing false positives or false negatives can only be triggered by accessing via different paths to what was or should now be the same file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:104,performance,load,loaded,104,"> How does the new cache handle the typical cache of a file being edited and then reloaded? While being loaded by the same path and when being matched against itself, it should hit the strncmp logic and exit the function. The race condition causing false positives or false negatives can only be triggered by accessing via different paths to what was or should now be the same file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:6,reliability,doe,does,6,"> How does the new cache handle the typical cache of a file being edited and then reloaded? While being loaded by the same path and when being matched against itself, it should hit the strncmp logic and exit the function. The race condition causing false positives or false negatives can only be triggered by accessing via different paths to what was or should now be the same file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:193,safety,log,logic,193,"> How does the new cache handle the typical cache of a file being edited and then reloaded? While being loaded by the same path and when being matched against itself, it should hit the strncmp logic and exit the function. The race condition causing false positives or false negatives can only be triggered by accessing via different paths to what was or should now be the same file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:193,security,log,logic,193,"> How does the new cache handle the typical cache of a file being edited and then reloaded? While being loaded by the same path and when being matched against itself, it should hit the strncmp logic and exit the function. The race condition causing false positives or false negatives can only be triggered by accessing via different paths to what was or should now be the same file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:309,security,access,accessing,309,"> How does the new cache handle the typical cache of a file being edited and then reloaded? While being loaded by the same path and when being matched against itself, it should hit the strncmp logic and exit the function. The race condition causing false positives or false negatives can only be triggered by accessing via different paths to what was or should now be the same file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:193,testability,log,logic,193,"> How does the new cache handle the typical cache of a file being edited and then reloaded? While being loaded by the same path and when being matched against itself, it should hit the strncmp logic and exit the function. The race condition causing false positives or false negatives can only be triggered by accessing via different paths to what was or should now be the same file.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:92,deployability,releas,release,92,@pcanal Thank you for reviewing. This raises a question if there is a possibility to make a release with this fix?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:22,safety,review,reviewing,22,@pcanal Thank you for reviewing. This raises a question if there is a possibility to make a release with this fix?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:22,testability,review,reviewing,22,@pcanal Thank you for reviewing. This raises a question if there is a possibility to make a release with this fix?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:152,safety,test,test,152,I doubt so (but maybe @Axel-Naumann can add) as we are no longer really supporting v5 and as you see from the CI result we no longer have a functioning test stand ...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:152,testability,test,test,152,I doubt so (but maybe @Axel-Naumann can add) as we are no longer really supporting v5 and as you see from the CI result we no longer have a functioning test stand ...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:72,usability,support,supporting,72,I doubt so (but maybe @Axel-Naumann can add) as we are no longer really supporting v5 and as you see from the CI result we no longer have a functioning test stand ...,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:43,deployability,releas,releases,43,We can create a git tag but we cannot make releases anymore; not sure how useful vs confusing this would be.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:153,availability,down,download,153,What we really need is just a tarball with the source. There is no need to build anything on your side. I believe Spack uses this URL `https://root.cern/download/root_v6.16.00.source.tar.gz` as a template to download other versions of the source from the same location. https://github.com/star-bnl/star-spack/blob/main/packages/root/package.py#L16. Maybe there is trick to tell Spack to download the archive from GitHub instead but I am not very familiar with how to achieve that with minimal changes to the current package config. A human friendly tag would still help to pick up these accepted changes. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:208,availability,down,download,208,What we really need is just a tarball with the source. There is no need to build anything on your side. I believe Spack uses this URL `https://root.cern/download/root_v6.16.00.source.tar.gz` as a template to download other versions of the source from the same location. https://github.com/star-bnl/star-spack/blob/main/packages/root/package.py#L16. Maybe there is trick to tell Spack to download the archive from GitHub instead but I am not very familiar with how to achieve that with minimal changes to the current package config. A human friendly tag would still help to pick up these accepted changes. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:387,availability,down,download,387,What we really need is just a tarball with the source. There is no need to build anything on your side. I believe Spack uses this URL `https://root.cern/download/root_v6.16.00.source.tar.gz` as a template to download other versions of the source from the same location. https://github.com/star-bnl/star-spack/blob/main/packages/root/package.py#L16. Maybe there is trick to tell Spack to download the archive from GitHub instead but I am not very familiar with how to achieve that with minimal changes to the current package config. A human friendly tag would still help to pick up these accepted changes. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:75,deployability,build,build,75,What we really need is just a tarball with the source. There is no need to build anything on your side. I believe Spack uses this URL `https://root.cern/download/root_v6.16.00.source.tar.gz` as a template to download other versions of the source from the same location. https://github.com/star-bnl/star-spack/blob/main/packages/root/package.py#L16. Maybe there is trick to tell Spack to download the archive from GitHub instead but I am not very familiar with how to achieve that with minimal changes to the current package config. A human friendly tag would still help to pick up these accepted changes. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:223,deployability,version,versions,223,What we really need is just a tarball with the source. There is no need to build anything on your side. I believe Spack uses this URL `https://root.cern/download/root_v6.16.00.source.tar.gz` as a template to download other versions of the source from the same location. https://github.com/star-bnl/star-spack/blob/main/packages/root/package.py#L16. Maybe there is trick to tell Spack to download the archive from GitHub instead but I am not very familiar with how to achieve that with minimal changes to the current package config. A human friendly tag would still help to pick up these accepted changes. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:508,energy efficiency,current,current,508,What we really need is just a tarball with the source. There is no need to build anything on your side. I believe Spack uses this URL `https://root.cern/download/root_v6.16.00.source.tar.gz` as a template to download other versions of the source from the same location. https://github.com/star-bnl/star-spack/blob/main/packages/root/package.py#L16. Maybe there is trick to tell Spack to download the archive from GitHub instead but I am not very familiar with how to achieve that with minimal changes to the current package config. A human friendly tag would still help to pick up these accepted changes. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:223,integrability,version,versions,223,What we really need is just a tarball with the source. There is no need to build anything on your side. I believe Spack uses this URL `https://root.cern/download/root_v6.16.00.source.tar.gz` as a template to download other versions of the source from the same location. https://github.com/star-bnl/star-spack/blob/main/packages/root/package.py#L16. Maybe there is trick to tell Spack to download the archive from GitHub instead but I am not very familiar with how to achieve that with minimal changes to the current package config. A human friendly tag would still help to pick up these accepted changes. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:223,modifiability,version,versions,223,What we really need is just a tarball with the source. There is no need to build anything on your side. I believe Spack uses this URL `https://root.cern/download/root_v6.16.00.source.tar.gz` as a template to download other versions of the source from the same location. https://github.com/star-bnl/star-spack/blob/main/packages/root/package.py#L16. Maybe there is trick to tell Spack to download the archive from GitHub instead but I am not very familiar with how to achieve that with minimal changes to the current package config. A human friendly tag would still help to pick up these accepted changes. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:319,modifiability,pac,packages,319,What we really need is just a tarball with the source. There is no need to build anything on your side. I believe Spack uses this URL `https://root.cern/download/root_v6.16.00.source.tar.gz` as a template to download other versions of the source from the same location. https://github.com/star-bnl/star-spack/blob/main/packages/root/package.py#L16. Maybe there is trick to tell Spack to download the archive from GitHub instead but I am not very familiar with how to achieve that with minimal changes to the current package config. A human friendly tag would still help to pick up these accepted changes. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:333,modifiability,pac,package,333,What we really need is just a tarball with the source. There is no need to build anything on your side. I believe Spack uses this URL `https://root.cern/download/root_v6.16.00.source.tar.gz` as a template to download other versions of the source from the same location. https://github.com/star-bnl/star-spack/blob/main/packages/root/package.py#L16. Maybe there is trick to tell Spack to download the archive from GitHub instead but I am not very familiar with how to achieve that with minimal changes to the current package config. A human friendly tag would still help to pick up these accepted changes. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:516,modifiability,pac,package,516,What we really need is just a tarball with the source. There is no need to build anything on your side. I believe Spack uses this URL `https://root.cern/download/root_v6.16.00.source.tar.gz` as a template to download other versions of the source from the same location. https://github.com/star-bnl/star-spack/blob/main/packages/root/package.py#L16. Maybe there is trick to tell Spack to download the archive from GitHub instead but I am not very familiar with how to achieve that with minimal changes to the current package config. A human friendly tag would still help to pick up these accepted changes. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:485,usability,minim,minimal,485,What we really need is just a tarball with the source. There is no need to build anything on your side. I believe Spack uses this URL `https://root.cern/download/root_v6.16.00.source.tar.gz` as a template to download other versions of the source from the same location. https://github.com/star-bnl/star-spack/blob/main/packages/root/package.py#L16. Maybe there is trick to tell Spack to download the archive from GitHub instead but I am not very familiar with how to achieve that with minimal changes to the current package config. A human friendly tag would still help to pick up these accepted changes. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/pull/9010:565,usability,help,help,565,What we really need is just a tarball with the source. There is no need to build anything on your side. I believe Spack uses this URL `https://root.cern/download/root_v6.16.00.source.tar.gz` as a template to download other versions of the source from the same location. https://github.com/star-bnl/star-spack/blob/main/packages/root/package.py#L16. Maybe there is trick to tell Spack to download the archive from GitHub instead but I am not very familiar with how to achieve that with minimal changes to the current package config. A human friendly tag would still help to pick up these accepted changes. .,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9010
https://github.com/root-project/root/issues/9011:14,deployability,patch,patch,14,"Removing this patch will produce a problem with this macro:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. // comment or uncomment the following line to get diffrent plot. // mg->GetXaxis()->CenterTitle(true);. mg->Draw(""AL"");. }. ```. Without this patch you get a different X range depending if you center the X title or not. I guess we should keep the patch and understand why in log scale it crashes (it should be protected).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:694,deployability,patch,patch,694,"Removing this patch will produce a problem with this macro:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. // comment or uncomment the following line to get diffrent plot. // mg->GetXaxis()->CenterTitle(true);. mg->Draw(""AL"");. }. ```. Without this patch you get a different X range depending if you center the X title or not. I guess we should keep the patch and understand why in log scale it crashes (it should be protected).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:728,deployability,depend,depending,728,"Removing this patch will produce a problem with this macro:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. // comment or uncomment the following line to get diffrent plot. // mg->GetXaxis()->CenterTitle(true);. mg->Draw(""AL"");. }. ```. Without this patch you get a different X range depending if you center the X title or not. I guess we should keep the patch and understand why in log scale it crashes (it should be protected).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:799,deployability,patch,patch,799,"Removing this patch will produce a problem with this macro:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. // comment or uncomment the following line to get diffrent plot. // mg->GetXaxis()->CenterTitle(true);. mg->Draw(""AL"");. }. ```. Without this patch you get a different X range depending if you center the X title or not. I guess we should keep the patch and understand why in log scale it crashes (it should be protected).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:827,deployability,log,log,827,"Removing this patch will produce a problem with this macro:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. // comment or uncomment the following line to get diffrent plot. // mg->GetXaxis()->CenterTitle(true);. mg->Draw(""AL"");. }. ```. Without this patch you get a different X range depending if you center the X title or not. I guess we should keep the patch and understand why in log scale it crashes (it should be protected).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:831,deployability,scale,scale,831,"Removing this patch will produce a problem with this macro:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. // comment or uncomment the following line to get diffrent plot. // mg->GetXaxis()->CenterTitle(true);. mg->Draw(""AL"");. }. ```. Without this patch you get a different X range depending if you center the X title or not. I guess we should keep the patch and understand why in log scale it crashes (it should be protected).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:660,energy efficiency,Draw,Draw,660,"Removing this patch will produce a problem with this macro:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. // comment or uncomment the following line to get diffrent plot. // mg->GetXaxis()->CenterTitle(true);. mg->Draw(""AL"");. }. ```. Without this patch you get a different X range depending if you center the X title or not. I guess we should keep the patch and understand why in log scale it crashes (it should be protected).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:831,energy efficiency,scale,scale,831,"Removing this patch will produce a problem with this macro:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. // comment or uncomment the following line to get diffrent plot. // mg->GetXaxis()->CenterTitle(true);. mg->Draw(""AL"");. }. ```. Without this patch you get a different X range depending if you center the X title or not. I guess we should keep the patch and understand why in log scale it crashes (it should be protected).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:728,integrability,depend,depending,728,"Removing this patch will produce a problem with this macro:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. // comment or uncomment the following line to get diffrent plot. // mg->GetXaxis()->CenterTitle(true);. mg->Draw(""AL"");. }. ```. Without this patch you get a different X range depending if you center the X title or not. I guess we should keep the patch and understand why in log scale it crashes (it should be protected).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:728,modifiability,depend,depending,728,"Removing this patch will produce a problem with this macro:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. // comment or uncomment the following line to get diffrent plot. // mg->GetXaxis()->CenterTitle(true);. mg->Draw(""AL"");. }. ```. Without this patch you get a different X range depending if you center the X title or not. I guess we should keep the patch and understand why in log scale it crashes (it should be protected).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:831,modifiability,scal,scale,831,"Removing this patch will produce a problem with this macro:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. // comment or uncomment the following line to get diffrent plot. // mg->GetXaxis()->CenterTitle(true);. mg->Draw(""AL"");. }. ```. Without this patch you get a different X range depending if you center the X title or not. I guess we should keep the patch and understand why in log scale it crashes (it should be protected).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:831,performance,scale,scale,831,"Removing this patch will produce a problem with this macro:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. // comment or uncomment the following line to get diffrent plot. // mg->GetXaxis()->CenterTitle(true);. mg->Draw(""AL"");. }. ```. Without this patch you get a different X range depending if you center the X title or not. I guess we should keep the patch and understand why in log scale it crashes (it should be protected).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:14,safety,patch,patch,14,"Removing this patch will produce a problem with this macro:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. // comment or uncomment the following line to get diffrent plot. // mg->GetXaxis()->CenterTitle(true);. mg->Draw(""AL"");. }. ```. Without this patch you get a different X range depending if you center the X title or not. I guess we should keep the patch and understand why in log scale it crashes (it should be protected).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:694,safety,patch,patch,694,"Removing this patch will produce a problem with this macro:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. // comment or uncomment the following line to get diffrent plot. // mg->GetXaxis()->CenterTitle(true);. mg->Draw(""AL"");. }. ```. Without this patch you get a different X range depending if you center the X title or not. I guess we should keep the patch and understand why in log scale it crashes (it should be protected).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:728,safety,depend,depending,728,"Removing this patch will produce a problem with this macro:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. // comment or uncomment the following line to get diffrent plot. // mg->GetXaxis()->CenterTitle(true);. mg->Draw(""AL"");. }. ```. Without this patch you get a different X range depending if you center the X title or not. I guess we should keep the patch and understand why in log scale it crashes (it should be protected).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:799,safety,patch,patch,799,"Removing this patch will produce a problem with this macro:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. // comment or uncomment the following line to get diffrent plot. // mg->GetXaxis()->CenterTitle(true);. mg->Draw(""AL"");. }. ```. Without this patch you get a different X range depending if you center the X title or not. I guess we should keep the patch and understand why in log scale it crashes (it should be protected).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:827,safety,log,log,827,"Removing this patch will produce a problem with this macro:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. // comment or uncomment the following line to get diffrent plot. // mg->GetXaxis()->CenterTitle(true);. mg->Draw(""AL"");. }. ```. Without this patch you get a different X range depending if you center the X title or not. I guess we should keep the patch and understand why in log scale it crashes (it should be protected).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:14,security,patch,patch,14,"Removing this patch will produce a problem with this macro:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. // comment or uncomment the following line to get diffrent plot. // mg->GetXaxis()->CenterTitle(true);. mg->Draw(""AL"");. }. ```. Without this patch you get a different X range depending if you center the X title or not. I guess we should keep the patch and understand why in log scale it crashes (it should be protected).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:694,security,patch,patch,694,"Removing this patch will produce a problem with this macro:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. // comment or uncomment the following line to get diffrent plot. // mg->GetXaxis()->CenterTitle(true);. mg->Draw(""AL"");. }. ```. Without this patch you get a different X range depending if you center the X title or not. I guess we should keep the patch and understand why in log scale it crashes (it should be protected).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:799,security,patch,patch,799,"Removing this patch will produce a problem with this macro:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. // comment or uncomment the following line to get diffrent plot. // mg->GetXaxis()->CenterTitle(true);. mg->Draw(""AL"");. }. ```. Without this patch you get a different X range depending if you center the X title or not. I guess we should keep the patch and understand why in log scale it crashes (it should be protected).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:827,security,log,log,827,"Removing this patch will produce a problem with this macro:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. // comment or uncomment the following line to get diffrent plot. // mg->GetXaxis()->CenterTitle(true);. mg->Draw(""AL"");. }. ```. Without this patch you get a different X range depending if you center the X title or not. I guess we should keep the patch and understand why in log scale it crashes (it should be protected).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:728,testability,depend,depending,728,"Removing this patch will produce a problem with this macro:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. // comment or uncomment the following line to get diffrent plot. // mg->GetXaxis()->CenterTitle(true);. mg->Draw(""AL"");. }. ```. Without this patch you get a different X range depending if you center the X title or not. I guess we should keep the patch and understand why in log scale it crashes (it should be protected).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:809,testability,understand,understand,809,"Removing this patch will produce a problem with this macro:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. // comment or uncomment the following line to get diffrent plot. // mg->GetXaxis()->CenterTitle(true);. mg->Draw(""AL"");. }. ```. Without this patch you get a different X range depending if you center the X title or not. I guess we should keep the patch and understand why in log scale it crashes (it should be protected).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:827,testability,log,log,827,"Removing this patch will produce a problem with this macro:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. // comment or uncomment the following line to get diffrent plot. // mg->GetXaxis()->CenterTitle(true);. mg->Draw(""AL"");. }. ```. Without this patch you get a different X range depending if you center the X title or not. I guess we should keep the patch and understand why in log scale it crashes (it should be protected).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:121,deployability,log,log,121,"Actually it worked for you because you centred the X title. In the previous macro, remove the X title centring and go to log scale in Y and you will get the problem you discovered. So that's not a regression. The bug fix simply revealed a problem (?) which was hidden by the bug generated by the X title centring. To make it short, with a ROOT version without the patch, try:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. mg->Draw(""AL"");. gPad->Update();. c1->SetLogy();. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:125,deployability,scale,scale,125,"Actually it worked for you because you centred the X title. In the previous macro, remove the X title centring and go to log scale in Y and you will get the problem you discovered. So that's not a regression. The bug fix simply revealed a problem (?) which was hidden by the bug generated by the X title centring. To make it short, with a ROOT version without the patch, try:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. mg->Draw(""AL"");. gPad->Update();. c1->SetLogy();. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:344,deployability,version,version,344,"Actually it worked for you because you centred the X title. In the previous macro, remove the X title centring and go to log scale in Y and you will get the problem you discovered. So that's not a regression. The bug fix simply revealed a problem (?) which was hidden by the bug generated by the X title centring. To make it short, with a ROOT version without the patch, try:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. mg->Draw(""AL"");. gPad->Update();. c1->SetLogy();. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:364,deployability,patch,patch,364,"Actually it worked for you because you centred the X title. In the previous macro, remove the X title centring and go to log scale in Y and you will get the problem you discovered. So that's not a regression. The bug fix simply revealed a problem (?) which was hidden by the bug generated by the X title centring. To make it short, with a ROOT version without the patch, try:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. mg->Draw(""AL"");. gPad->Update();. c1->SetLogy();. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:891,deployability,Updat,Update,891,"Actually it worked for you because you centred the X title. In the previous macro, remove the X title centring and go to log scale in Y and you will get the problem you discovered. So that's not a regression. The bug fix simply revealed a problem (?) which was hidden by the bug generated by the X title centring. To make it short, with a ROOT version without the patch, try:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. mg->Draw(""AL"");. gPad->Update();. c1->SetLogy();. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:125,energy efficiency,scale,scale,125,"Actually it worked for you because you centred the X title. In the previous macro, remove the X title centring and go to log scale in Y and you will get the problem you discovered. So that's not a regression. The bug fix simply revealed a problem (?) which was hidden by the bug generated by the X title centring. To make it short, with a ROOT version without the patch, try:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. mg->Draw(""AL"");. gPad->Update();. c1->SetLogy();. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:872,energy efficiency,Draw,Draw,872,"Actually it worked for you because you centred the X title. In the previous macro, remove the X title centring and go to log scale in Y and you will get the problem you discovered. So that's not a regression. The bug fix simply revealed a problem (?) which was hidden by the bug generated by the X title centring. To make it short, with a ROOT version without the patch, try:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. mg->Draw(""AL"");. gPad->Update();. c1->SetLogy();. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:169,integrability,discover,discovered,169,"Actually it worked for you because you centred the X title. In the previous macro, remove the X title centring and go to log scale in Y and you will get the problem you discovered. So that's not a regression. The bug fix simply revealed a problem (?) which was hidden by the bug generated by the X title centring. To make it short, with a ROOT version without the patch, try:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. mg->Draw(""AL"");. gPad->Update();. c1->SetLogy();. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:344,integrability,version,version,344,"Actually it worked for you because you centred the X title. In the previous macro, remove the X title centring and go to log scale in Y and you will get the problem you discovered. So that's not a regression. The bug fix simply revealed a problem (?) which was hidden by the bug generated by the X title centring. To make it short, with a ROOT version without the patch, try:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. mg->Draw(""AL"");. gPad->Update();. c1->SetLogy();. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:169,interoperability,discover,discovered,169,"Actually it worked for you because you centred the X title. In the previous macro, remove the X title centring and go to log scale in Y and you will get the problem you discovered. So that's not a regression. The bug fix simply revealed a problem (?) which was hidden by the bug generated by the X title centring. To make it short, with a ROOT version without the patch, try:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. mg->Draw(""AL"");. gPad->Update();. c1->SetLogy();. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:125,modifiability,scal,scale,125,"Actually it worked for you because you centred the X title. In the previous macro, remove the X title centring and go to log scale in Y and you will get the problem you discovered. So that's not a regression. The bug fix simply revealed a problem (?) which was hidden by the bug generated by the X title centring. To make it short, with a ROOT version without the patch, try:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. mg->Draw(""AL"");. gPad->Update();. c1->SetLogy();. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:344,modifiability,version,version,344,"Actually it worked for you because you centred the X title. In the previous macro, remove the X title centring and go to log scale in Y and you will get the problem you discovered. So that's not a regression. The bug fix simply revealed a problem (?) which was hidden by the bug generated by the X title centring. To make it short, with a ROOT version without the patch, try:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. mg->Draw(""AL"");. gPad->Update();. c1->SetLogy();. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:125,performance,scale,scale,125,"Actually it worked for you because you centred the X title. In the previous macro, remove the X title centring and go to log scale in Y and you will get the problem you discovered. So that's not a regression. The bug fix simply revealed a problem (?) which was hidden by the bug generated by the X title centring. To make it short, with a ROOT version without the patch, try:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. mg->Draw(""AL"");. gPad->Update();. c1->SetLogy();. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:121,safety,log,log,121,"Actually it worked for you because you centred the X title. In the previous macro, remove the X title centring and go to log scale in Y and you will get the problem you discovered. So that's not a regression. The bug fix simply revealed a problem (?) which was hidden by the bug generated by the X title centring. To make it short, with a ROOT version without the patch, try:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. mg->Draw(""AL"");. gPad->Update();. c1->SetLogy();. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:364,safety,patch,patch,364,"Actually it worked for you because you centred the X title. In the previous macro, remove the X title centring and go to log scale in Y and you will get the problem you discovered. So that's not a regression. The bug fix simply revealed a problem (?) which was hidden by the bug generated by the X title centring. To make it short, with a ROOT version without the patch, try:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. mg->Draw(""AL"");. gPad->Update();. c1->SetLogy();. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:891,safety,Updat,Update,891,"Actually it worked for you because you centred the X title. In the previous macro, remove the X title centring and go to log scale in Y and you will get the problem you discovered. So that's not a regression. The bug fix simply revealed a problem (?) which was hidden by the bug generated by the X title centring. To make it short, with a ROOT version without the patch, try:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. mg->Draw(""AL"");. gPad->Update();. c1->SetLogy();. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:121,security,log,log,121,"Actually it worked for you because you centred the X title. In the previous macro, remove the X title centring and go to log scale in Y and you will get the problem you discovered. So that's not a regression. The bug fix simply revealed a problem (?) which was hidden by the bug generated by the X title centring. To make it short, with a ROOT version without the patch, try:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. mg->Draw(""AL"");. gPad->Update();. c1->SetLogy();. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:364,security,patch,patch,364,"Actually it worked for you because you centred the X title. In the previous macro, remove the X title centring and go to log scale in Y and you will get the problem you discovered. So that's not a regression. The bug fix simply revealed a problem (?) which was hidden by the bug generated by the X title centring. To make it short, with a ROOT version without the patch, try:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. mg->Draw(""AL"");. gPad->Update();. c1->SetLogy();. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:891,security,Updat,Update,891,"Actually it worked for you because you centred the X title. In the previous macro, remove the X title centring and go to log scale in Y and you will get the problem you discovered. So that's not a regression. The bug fix simply revealed a problem (?) which was hidden by the bug generated by the X title centring. To make it short, with a ROOT version without the patch, try:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. mg->Draw(""AL"");. gPad->Update();. c1->SetLogy();. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:121,testability,log,log,121,"Actually it worked for you because you centred the X title. In the previous macro, remove the X title centring and go to log scale in Y and you will get the problem you discovered. So that's not a regression. The bug fix simply revealed a problem (?) which was hidden by the bug generated by the X title centring. To make it short, with a ROOT version without the patch, try:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. mg->Draw(""AL"");. gPad->Update();. c1->SetLogy();. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:197,testability,regress,regression,197,"Actually it worked for you because you centred the X title. In the previous macro, remove the X title centring and go to log scale in Y and you will get the problem you discovered. So that's not a regression. The bug fix simply revealed a problem (?) which was hidden by the bug generated by the X title centring. To make it short, with a ROOT version without the patch, try:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. mg->Draw(""AL"");. gPad->Update();. c1->SetLogy();. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:221,testability,simpl,simply,221,"Actually it worked for you because you centred the X title. In the previous macro, remove the X title centring and go to log scale in Y and you will get the problem you discovered. So that's not a regression. The bug fix simply revealed a problem (?) which was hidden by the bug generated by the X title centring. To make it short, with a ROOT version without the patch, try:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. mg->Draw(""AL"");. gPad->Update();. c1->SetLogy();. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:169,usability,discov,discovered,169,"Actually it worked for you because you centred the X title. In the previous macro, remove the X title centring and go to log scale in Y and you will get the problem you discovered. So that's not a regression. The bug fix simply revealed a problem (?) which was hidden by the bug generated by the X title centring. To make it short, with a ROOT version without the patch, try:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. mg->Draw(""AL"");. gPad->Update();. c1->SetLogy();. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/issues/9011:221,usability,simpl,simply,221,"Actually it worked for you because you centred the X title. In the previous macro, remove the X title centring and go to log scale in Y and you will get the problem you discovered. So that's not a regression. The bug fix simply revealed a problem (?) which was hidden by the bug generated by the X title centring. To make it short, with a ROOT version without the patch, try:. ```. {. auto c1 = new TCanvas(""c1"",""multigraph"",700,500);. c1->SetGrid();. auto *mg = new TMultiGraph();. std::vector<double> x1;. std::vector<double> sig1;. std::vector<double> sig2;. for (double E=1e-4;E<2e7;E*=1.1) {. x1.push_back(E);. sig1.push_back(10*pow(E,-0.1));. sig2.push_back(15*pow(E,-0.15));. }. auto g1 = new TGraph(x1.size(), x1.data(), sig1.data());. mg->Add(g1);. auto g2 = new TGraph(x1.size(), x1.data(), sig2.data());. mg->Add(g2);. mg->SetTitle(""; E (eV);#sigma (b)"");. mg->Draw(""AL"");. gPad->Update();. c1->SetLogy();. }. ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9011
https://github.com/root-project/root/pull/9012:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:185,availability,avail,available,185,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:203,availability,servic,service,203,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:830,availability,servic,service,830,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:203,deployability,servic,service,203,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:830,deployability,servic,service,830,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:599,energy efficiency,current,currently,599,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:176,integrability,pub,publicly,176,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:203,integrability,servic,service,203,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:545,integrability,protocol,protocols,545,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:739,integrability,protocol,protocols,739,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:830,integrability,servic,service,830,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:493,interoperability,plug,plugin,493,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:545,interoperability,protocol,protocols,545,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:739,interoperability,protocol,protocols,739,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:203,modifiability,servic,service,203,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:830,modifiability,servic,service,830,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:185,reliability,availab,available,185,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:139,safety,test,test,139,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:185,safety,avail,available,185,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:216,safety,test,test,216,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:261,safety,test,test,261,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:589,safety,test,tests,589,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:689,safety,test,tests,689,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:822,safety,test,testing,822,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:185,security,availab,available,185,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:312,security,access,access,312,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:134,testability,unit,unit,134,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:139,testability,test,test,139,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:216,testability,test,test,216,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:256,testability,unit,unit,256,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:261,testability,test,test,261,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:366,testability,simpl,simple,366,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:570,testability,simpl,simply,570,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:589,testability,test,tests,589,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:689,testability,test,tests,689,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:822,testability,test,testing,822,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:366,usability,simpl,simple,366,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:570,usability,simpl,simply,570,"@jblomer : thanks a lot for your comments, I will address them shortly! . >One thing I'd like to discuss before merging is how we can unit test the code. If there is a stable, publicly available XRootD >service with test data, we can use the RRawFileDavix unit test as a blueprint. Otherwise, given that we have access to the xrootd >library, perhaps we can spawn a simple ad-hoc server in another thread. Well, I think one nice thing that we could do is to have an XRootD server with an HTTP plugin exporting same files with both root and HTTP protocols. Then we could simply run all the tests you currently have for the `RRawFileDavix` also for `RRawFileNetXNG`. If you have some stress tests we could even use them to benchmark the two protocols. Could we use `root.cern.ch` to do this? Otherwise, I can create a small testing service, I would need to see what machine I can get.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:25,safety,test,testing,25,"We can use eospublic for testing xrootd. We have existing tutorials / tests that use it, see e.g. [test/stressIOPlugins.cxx](https://github.com/root-project/root/blob/de7bcdff077be4ec08892c1d8349d9f8e62dd420/test/stressIOPlugins.cxx#L160)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:70,safety,test,tests,70,"We can use eospublic for testing xrootd. We have existing tutorials / tests that use it, see e.g. [test/stressIOPlugins.cxx](https://github.com/root-project/root/blob/de7bcdff077be4ec08892c1d8349d9f8e62dd420/test/stressIOPlugins.cxx#L160)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:99,safety,test,test,99,"We can use eospublic for testing xrootd. We have existing tutorials / tests that use it, see e.g. [test/stressIOPlugins.cxx](https://github.com/root-project/root/blob/de7bcdff077be4ec08892c1d8349d9f8e62dd420/test/stressIOPlugins.cxx#L160)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:208,safety,test,test,208,"We can use eospublic for testing xrootd. We have existing tutorials / tests that use it, see e.g. [test/stressIOPlugins.cxx](https://github.com/root-project/root/blob/de7bcdff077be4ec08892c1d8349d9f8e62dd420/test/stressIOPlugins.cxx#L160)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:25,testability,test,testing,25,"We can use eospublic for testing xrootd. We have existing tutorials / tests that use it, see e.g. [test/stressIOPlugins.cxx](https://github.com/root-project/root/blob/de7bcdff077be4ec08892c1d8349d9f8e62dd420/test/stressIOPlugins.cxx#L160)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:70,testability,test,tests,70,"We can use eospublic for testing xrootd. We have existing tutorials / tests that use it, see e.g. [test/stressIOPlugins.cxx](https://github.com/root-project/root/blob/de7bcdff077be4ec08892c1d8349d9f8e62dd420/test/stressIOPlugins.cxx#L160)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:99,testability,test,test,99,"We can use eospublic for testing xrootd. We have existing tutorials / tests that use it, see e.g. [test/stressIOPlugins.cxx](https://github.com/root-project/root/blob/de7bcdff077be4ec08892c1d8349d9f8e62dd420/test/stressIOPlugins.cxx#L160)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:208,testability,test,test,208,"We can use eospublic for testing xrootd. We have existing tutorials / tests that use it, see e.g. [test/stressIOPlugins.cxx](https://github.com/root-project/root/blob/de7bcdff077be4ec08892c1d8349d9f8e62dd420/test/stressIOPlugins.cxx#L160)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:91,integrability,endpoint,endpoint,91,"@simonmichal Great, thanks! We are still working on getting that test file up on an XRootD endpoint. Will let you know.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:65,safety,test,test,65,"@simonmichal Great, thanks! We are still working on getting that test file up on an XRootD endpoint. Will let you know.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:65,testability,test,test,65,"@simonmichal Great, thanks! We are still working on getting that test file up on an XRootD endpoint. Will let you know.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:73,safety,test,test,73,@simonmichal There is now `root://eospublic.cern.ch//eos/root-eos/xrootd.test`. You can use it to implement unit tests along the line of the `RRawFileDavix` implementation.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:113,safety,test,tests,113,@simonmichal There is now `root://eospublic.cern.ch//eos/root-eos/xrootd.test`. You can use it to implement unit tests along the line of the `RRawFileDavix` implementation.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:73,testability,test,test,73,@simonmichal There is now `root://eospublic.cern.ch//eos/root-eos/xrootd.test`. You can use it to implement unit tests along the line of the `RRawFileDavix` implementation.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:108,testability,unit,unit,108,@simonmichal There is now `root://eospublic.cern.ch//eos/root-eos/xrootd.test`. You can use it to implement unit tests along the line of the `RRawFileDavix` implementation.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:113,testability,test,tests,113,@simonmichal There is now `root://eospublic.cern.ch//eos/root-eos/xrootd.test`. You can use it to implement unit tests along the line of the `RRawFileDavix` implementation.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:614,availability,failur,failures,614,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:308,deployability,build,buildtmp,308,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:614,deployability,fail,failures,614,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:657,deployability,fail,failed,657,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:949,deployability,FAIL,FAILED,949,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:983,deployability,depend,dependency-versions,983,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1004,deployability,Fail,Failed,1004,"r : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1053,deployability,Fail,Failed,1053,"ts (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Ag",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1088,deployability,Fail,Failed,1088,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1147,deployability,Fail,Failed,1147,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1183,deployability,Fail,Failed,1183,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1242,deployability,Fail,Failed,1242,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1277,deployability,Fail,Failed,1277,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1341,deployability,Fail,Failed,1341,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1401,deployability,Fail,Failed,1401,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1458,deployability,Fail,Failed,1458,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1521,deployability,Fail,Failed,1521,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1588,deployability,Fail,Failed,1588,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1653,deployability,Fail,Failed,1653,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1717,deployability,Fail,Failed,1717,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1777,deployability,Fail,Failed,1777,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1844,deployability,Fail,Failed,1844,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1894,deployability,Fail,Failed,1894,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1952,deployability,Fail,Failed,1952,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:983,integrability,depend,dependency-versions,983,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:983,modifiability,depend,dependency-versions,983,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:614,performance,failur,failures,614,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:683,performance,Time,Time,683,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:902,performance,time,time,902,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:614,reliability,fail,failures,614,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:657,reliability,fail,failed,657,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:949,reliability,FAIL,FAILED,949,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1004,reliability,Fail,Failed,1004,"r : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1053,reliability,Fail,Failed,1053,"ts (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Ag",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1088,reliability,Fail,Failed,1088,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1147,reliability,Fail,Failed,1147,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1183,reliability,Fail,Failed,1183,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1242,reliability,Fail,Failed,1242,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1277,reliability,Fail,Failed,1277,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1341,reliability,Fail,Failed,1341,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1401,reliability,Fail,Failed,1401,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1458,reliability,Fail,Failed,1458,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1521,reliability,Fail,Failed,1521,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1588,reliability,Fail,Failed,1588,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1653,reliability,Fail,Failed,1653,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1717,reliability,Fail,Failed,1717,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1777,reliability,Fail,Failed,1777,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1844,reliability,Fail,Failed,1844,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1894,reliability,Fail,Failed,1894,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1952,reliability,Fail,Failed,1952,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:23,safety,test,tests,23,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:53,safety,test,tests,53,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:179,safety,test,test,179,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:240,safety,test,test,240,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:270,safety,Test,Test,270,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:345,safety,test,test-RRawFileDavix,345,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:369,safety,Test,Test,369,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:396,safety,test,test-RRawFileDavix,396,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:466,safety,test,test-RRawFileNetXNG,466,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:491,safety,Test,Test,491,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:519,safety,test,test-RRawFileNetXNG,519,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:590,safety,test,test,590,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:634,safety,test,tests,634,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:651,safety,test,tests,651,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:897,safety,Test,Test,897,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:943,safety,test,tests,943,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:983,safety,depend,dependency-versions,983,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1069,safety,test,test-import-numba,1069," creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the del",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1163,safety,test,test-import-pandas,1163,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1258,safety,test,test-import-numba,1258,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:2020,safety,safe,safe,2020,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:123,security,modif,modified,123,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:23,testability,test,tests,23,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:53,testability,test,tests,53,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:179,testability,test,test,179,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:240,testability,test,test,240,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:270,testability,Test,Test,270,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:345,testability,test,test-RRawFileDavix,345,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:369,testability,Test,Test,369,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:396,testability,test,test-RRawFileDavix,396,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:466,testability,test,test-RRawFileNetXNG,466,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:491,testability,Test,Test,491,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:519,testability,test,test-RRawFileNetXNG,519,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:590,testability,test,test,590,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:634,testability,test,tests,634,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:651,testability,test,tests,651,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:821,testability,regress,regression,821,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:897,testability,Test,Test,897,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:943,testability,test,tests,943,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:983,testability,depend,dependency-versions,983,"@jblomer : I added few tests equivalent to the Davix tests (sorry for the lack creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1069,testability,test,test-import-numba,1069," creativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the del",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1163,testability,test,test-import-pandas,1163,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:1258,testability,test,test-import-numba,1258,"eativity) and I also took the liberty and modified `root://eospublic.cern.ch//eos/root-eos/xrootd.test` so it is in line with `http://root.cern.ch/files/davix.test`. ```. ctest -I 164,165. Test project /home/simonm/git/root-my/buildtmp. Start 164: gtest-net-davix-test-RRawFileDavix. 1/2 Test #164: gtest-net-davix-test-RRawFileDavix ..... Passed 0.20 sec. Start 165: gtest-net-netxng-test-RRawFileNetXNG. 2/2 Test #165: gtest-net-netxng-test-RRawFileNetXNG ... Passed 0.05 sec. ```. However running the full test suite yielded some failures:. ```. 99% tests passed, 18 tests failed out of 2101. Label Time Summary:. cling = 69.10 sec. longtest = 1541.18 sec. matrix = 0.22 sec. multithreaded = 206.29 sec. python_runtime_deps = 27.45 sec. regression = 68.69 sec. roottest = 69.32 sec. tutorial = 1559.92 sec. Total Test time (real) = 5594.32 sec. The following tests FAILED:. 	 3 - pyunittests-pyroot-dependency-versions (Failed). 	 56 - pyunittests-pyroot-numbadeclare (Failed). 	 57 - test-import-numba (Failed). 	918 - tutorial-dataframe-df026_AsNumpyArrays-py (Failed). 	920 - test-import-pandas (Failed). 	961 - tutorial-pyroot-pyroot004_NumbaDeclare-py (Failed). 	962 - test-import-numba (Failed). 	1219 - roottest-python-JupyROOT-cppcompleter_doctest (Failed). 	1220 - roottest-python-JupyROOT-handlers_doctest (Failed). 	1221 - roottest-python-JupyROOT-utils_doctest (Failed). 	1222 - roottest-python-JupyROOT-importROOT_notebook (Failed). 	1223 - roottest-python-JupyROOT-simpleCppMagic_notebook (Failed). 	1224 - roottest-python-JupyROOT-thread_local_notebook (Failed). 	1225 - roottest-python-JupyROOT-ROOT_kernel_notebook (Failed). 	1226 - roottest-python-JupyROOT-tpython_notebook (Failed). 	1227 - roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook (Failed). 	1444 - roottest-root-html-runMakeIndex (Failed). 	1627 - roottest-root-meta-execTypedefList-auto (Failed). ```. I don't think it's related to the PR but to be on the safe side I'm reporting it. P. S. Again, sorry for the delay!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9012:0,energy efficiency,Cool,Cool,0,"Cool, thanks for merging :-)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9012
https://github.com/root-project/root/pull/9013:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9013
https://github.com/root-project/root/pull/9013:19,availability,error,errors,19,@linev I saw osx11 errors from the previous PR. std::timespec is not defined there. An option is to use defines for Big Sur.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9013
https://github.com/root-project/root/pull/9013:19,performance,error,errors,19,@linev I saw osx11 errors from the previous PR. std::timespec is not defined there. An option is to use defines for Big Sur.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9013
https://github.com/root-project/root/pull/9013:53,performance,time,timespec,53,@linev I saw osx11 errors from the previous PR. std::timespec is not defined there. An option is to use defines for Big Sur.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9013
https://github.com/root-project/root/pull/9013:19,safety,error,errors,19,@linev I saw osx11 errors from the previous PR. std::timespec is not defined there. An option is to use defines for Big Sur.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9013
https://github.com/root-project/root/pull/9013:19,usability,error,errors,19,@linev I saw osx11 errors from the previous PR. std::timespec is not defined there. An option is to use defines for Big Sur.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9013
https://github.com/root-project/root/pull/9013:41,performance,time,timespec,41,@linev Required includes are there. std::timespec is part of C++17. It should work on osx11. For the moment I used std::time for non linux systems.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9013
https://github.com/root-project/root/pull/9013:120,performance,time,time,120,@linev Required includes are there. std::timespec is part of C++17. It should work on osx11. For the moment I used std::time for non linux systems.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9013
https://github.com/root-project/root/pull/9013:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9013
https://github.com/root-project/root/pull/9013:25,availability,error,errors,25,@linev I think the build errors are not related to this change.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9013
https://github.com/root-project/root/pull/9013:19,deployability,build,build,19,@linev I think the build errors are not related to this change.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9013
https://github.com/root-project/root/pull/9013:25,performance,error,errors,25,@linev I think the build errors are not related to this change.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9013
https://github.com/root-project/root/pull/9013:25,safety,error,errors,25,@linev I think the build errors are not related to this change.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9013
https://github.com/root-project/root/pull/9013:25,usability,error,errors,25,@linev I think the build errors are not related to this change.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9013
https://github.com/root-project/root/pull/9015:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9015
https://github.com/root-project/root/pull/9015:26,interoperability,specif,specific,26,"I just realized that this specific functionality is entirely missing in THistPainter::PaintErrors(). Instead just the symbolsize x 8 (Equal to 100% symbolwidth in pixel) is taken, so every symbol is treated as if it had full width and full height. Is this somehow intended or is it just something that was never changed, because if so it might be a good idea to add the more specific offsets there too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9015
https://github.com/root-project/root/pull/9015:375,interoperability,specif,specific,375,"I just realized that this specific functionality is entirely missing in THistPainter::PaintErrors(). Instead just the symbolsize x 8 (Equal to 100% symbolwidth in pixel) is taken, so every symbol is treated as if it had full width and full height. Is this somehow intended or is it just something that was never changed, because if so it might be a good idea to add the more specific offsets there too.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9015
https://github.com/root-project/root/pull/9015:11,deployability,build,build,11,@phsft-bot build.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9015
https://github.com/root-project/root/pull/9015:73,testability,simpl,simply,73,- It looks good. Thanks. - I think for THistPainter::PaintErrors() it is simply missing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9015
https://github.com/root-project/root/pull/9015:73,usability,simpl,simply,73,- It looks good. Thanks. - I think for THistPainter::PaintErrors() it is simply missing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9015
https://github.com/root-project/root/pull/9015:214,deployability,instal,installation,214,"Sorry, I just realized I screwed up the offsets for marker style 49. They should be 1/1 and not 0.5/0.5. I will just add the changes to THistPainter::PaintErrors() too, because I already did it for my private ROOT installation. XD",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9015
https://github.com/root-project/root/pull/9015:77,testability,simpl,simply,77,> * It looks good. Thanks. > * I think for THistPainter::PaintErrors() it is simply missing. Now the offsets are also implemented for THistPainter::PaintErrors().,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9015
https://github.com/root-project/root/pull/9015:77,usability,simpl,simply,77,> * It looks good. Thanks. > * I think for THistPainter::PaintErrors() it is simply missing. Now the offsets are also implemented for THistPainter::PaintErrors().,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9015
https://github.com/root-project/root/pull/9015:334,availability,error,errorbars,334,"For histograms with the diamond marker as example:. ```. gStyle->SetOptStat(0);. TH1D* h = new TH1D(""h"", """", 3, 0., 3.);. h->SetMarkerSize(20);. h->SetMarkerStyle(110);. h->SetLineWidth(5);. h->SetBinContent(2, 0.5);. h->SetBinError(2, 0.25);. h->Draw();. ```. Produces before and after the changes the following plots (Observe the x-errorbars):. ![tempBefore](https://user-images.githubusercontent.com/5320187/134165950-ef3c02a9-c0bd-44e4-9b18-c67d7da2d1ba.png). ![tempAfter](https://user-images.githubusercontent.com/5320187/134166363-a60380ba-15a0-4b5d-8424-7e8b69449df1.png)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9015
https://github.com/root-project/root/pull/9015:320,deployability,Observ,Observe,320,"For histograms with the diamond marker as example:. ```. gStyle->SetOptStat(0);. TH1D* h = new TH1D(""h"", """", 3, 0., 3.);. h->SetMarkerSize(20);. h->SetMarkerStyle(110);. h->SetLineWidth(5);. h->SetBinContent(2, 0.5);. h->SetBinError(2, 0.25);. h->Draw();. ```. Produces before and after the changes the following plots (Observe the x-errorbars):. ![tempBefore](https://user-images.githubusercontent.com/5320187/134165950-ef3c02a9-c0bd-44e4-9b18-c67d7da2d1ba.png). ![tempAfter](https://user-images.githubusercontent.com/5320187/134166363-a60380ba-15a0-4b5d-8424-7e8b69449df1.png)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9015
https://github.com/root-project/root/pull/9015:247,energy efficiency,Draw,Draw,247,"For histograms with the diamond marker as example:. ```. gStyle->SetOptStat(0);. TH1D* h = new TH1D(""h"", """", 3, 0., 3.);. h->SetMarkerSize(20);. h->SetMarkerStyle(110);. h->SetLineWidth(5);. h->SetBinContent(2, 0.5);. h->SetBinError(2, 0.25);. h->Draw();. ```. Produces before and after the changes the following plots (Observe the x-errorbars):. ![tempBefore](https://user-images.githubusercontent.com/5320187/134165950-ef3c02a9-c0bd-44e4-9b18-c67d7da2d1ba.png). ![tempAfter](https://user-images.githubusercontent.com/5320187/134166363-a60380ba-15a0-4b5d-8424-7e8b69449df1.png)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9015
https://github.com/root-project/root/pull/9015:334,performance,error,errorbars,334,"For histograms with the diamond marker as example:. ```. gStyle->SetOptStat(0);. TH1D* h = new TH1D(""h"", """", 3, 0., 3.);. h->SetMarkerSize(20);. h->SetMarkerStyle(110);. h->SetLineWidth(5);. h->SetBinContent(2, 0.5);. h->SetBinError(2, 0.25);. h->Draw();. ```. Produces before and after the changes the following plots (Observe the x-errorbars):. ![tempBefore](https://user-images.githubusercontent.com/5320187/134165950-ef3c02a9-c0bd-44e4-9b18-c67d7da2d1ba.png). ![tempAfter](https://user-images.githubusercontent.com/5320187/134166363-a60380ba-15a0-4b5d-8424-7e8b69449df1.png)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9015
https://github.com/root-project/root/pull/9015:334,safety,error,errorbars,334,"For histograms with the diamond marker as example:. ```. gStyle->SetOptStat(0);. TH1D* h = new TH1D(""h"", """", 3, 0., 3.);. h->SetMarkerSize(20);. h->SetMarkerStyle(110);. h->SetLineWidth(5);. h->SetBinContent(2, 0.5);. h->SetBinError(2, 0.25);. h->Draw();. ```. Produces before and after the changes the following plots (Observe the x-errorbars):. ![tempBefore](https://user-images.githubusercontent.com/5320187/134165950-ef3c02a9-c0bd-44e4-9b18-c67d7da2d1ba.png). ![tempAfter](https://user-images.githubusercontent.com/5320187/134166363-a60380ba-15a0-4b5d-8424-7e8b69449df1.png)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9015
https://github.com/root-project/root/pull/9015:320,testability,Observ,Observe,320,"For histograms with the diamond marker as example:. ```. gStyle->SetOptStat(0);. TH1D* h = new TH1D(""h"", """", 3, 0., 3.);. h->SetMarkerSize(20);. h->SetMarkerStyle(110);. h->SetLineWidth(5);. h->SetBinContent(2, 0.5);. h->SetBinError(2, 0.25);. h->Draw();. ```. Produces before and after the changes the following plots (Observe the x-errorbars):. ![tempBefore](https://user-images.githubusercontent.com/5320187/134165950-ef3c02a9-c0bd-44e4-9b18-c67d7da2d1ba.png). ![tempAfter](https://user-images.githubusercontent.com/5320187/134166363-a60380ba-15a0-4b5d-8424-7e8b69449df1.png)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9015
https://github.com/root-project/root/pull/9015:334,usability,error,errorbars,334,"For histograms with the diamond marker as example:. ```. gStyle->SetOptStat(0);. TH1D* h = new TH1D(""h"", """", 3, 0., 3.);. h->SetMarkerSize(20);. h->SetMarkerStyle(110);. h->SetLineWidth(5);. h->SetBinContent(2, 0.5);. h->SetBinError(2, 0.25);. h->Draw();. ```. Produces before and after the changes the following plots (Observe the x-errorbars):. ![tempBefore](https://user-images.githubusercontent.com/5320187/134165950-ef3c02a9-c0bd-44e4-9b18-c67d7da2d1ba.png). ![tempAfter](https://user-images.githubusercontent.com/5320187/134166363-a60380ba-15a0-4b5d-8424-7e8b69449df1.png)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9015
https://github.com/root-project/root/pull/9015:369,usability,user,user-images,369,"For histograms with the diamond marker as example:. ```. gStyle->SetOptStat(0);. TH1D* h = new TH1D(""h"", """", 3, 0., 3.);. h->SetMarkerSize(20);. h->SetMarkerStyle(110);. h->SetLineWidth(5);. h->SetBinContent(2, 0.5);. h->SetBinError(2, 0.25);. h->Draw();. ```. Produces before and after the changes the following plots (Observe the x-errorbars):. ![tempBefore](https://user-images.githubusercontent.com/5320187/134165950-ef3c02a9-c0bd-44e4-9b18-c67d7da2d1ba.png). ![tempAfter](https://user-images.githubusercontent.com/5320187/134166363-a60380ba-15a0-4b5d-8424-7e8b69449df1.png)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9015
https://github.com/root-project/root/pull/9015:485,usability,user,user-images,485,"For histograms with the diamond marker as example:. ```. gStyle->SetOptStat(0);. TH1D* h = new TH1D(""h"", """", 3, 0., 3.);. h->SetMarkerSize(20);. h->SetMarkerStyle(110);. h->SetLineWidth(5);. h->SetBinContent(2, 0.5);. h->SetBinError(2, 0.25);. h->Draw();. ```. Produces before and after the changes the following plots (Observe the x-errorbars):. ![tempBefore](https://user-images.githubusercontent.com/5320187/134165950-ef3c02a9-c0bd-44e4-9b18-c67d7da2d1ba.png). ![tempAfter](https://user-images.githubusercontent.com/5320187/134166363-a60380ba-15a0-4b5d-8424-7e8b69449df1.png)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9015
https://github.com/root-project/root/pull/9018:11,deployability,build,build,11,@phsft-bot build!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9018
https://github.com/root-project/root/pull/9018:46,availability,failur,failures,46,"@lmoneta, it seems this PR is good to go, the failures are unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9018
https://github.com/root-project/root/pull/9018:46,deployability,fail,failures,46,"@lmoneta, it seems this PR is good to go, the failures are unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9018
https://github.com/root-project/root/pull/9018:46,performance,failur,failures,46,"@lmoneta, it seems this PR is good to go, the failures are unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9018
https://github.com/root-project/root/pull/9018:46,reliability,fail,failures,46,"@lmoneta, it seems this PR is good to go, the failures are unrelated.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9018
https://github.com/root-project/root/pull/9018:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9018
https://github.com/root-project/root/issues/9020:48,energy efficiency,core,core,48,Needs `-isystem` (cmake's `SYSTEM`) of tbb for `core/imt`,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9020
https://github.com/root-project/root/pull/9021:4,availability,failur,failure,4,The failure in roottest_root_tree_branches_make is real and was due to the `fDirectory` member being reset too early. Turns out that the `TBranch` destructor still need it to have a valid value. A new version correcting this has been uploaded.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9021
https://github.com/root-project/root/pull/9021:4,deployability,fail,failure,4,The failure in roottest_root_tree_branches_make is real and was due to the `fDirectory` member being reset too early. Turns out that the `TBranch` destructor still need it to have a valid value. A new version correcting this has been uploaded.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9021
https://github.com/root-project/root/pull/9021:201,deployability,version,version,201,The failure in roottest_root_tree_branches_make is real and was due to the `fDirectory` member being reset too early. Turns out that the `TBranch` destructor still need it to have a valid value. A new version correcting this has been uploaded.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9021
https://github.com/root-project/root/pull/9021:201,integrability,version,version,201,The failure in roottest_root_tree_branches_make is real and was due to the `fDirectory` member being reset too early. Turns out that the `TBranch` destructor still need it to have a valid value. A new version correcting this has been uploaded.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9021
https://github.com/root-project/root/pull/9021:201,modifiability,version,version,201,The failure in roottest_root_tree_branches_make is real and was due to the `fDirectory` member being reset too early. Turns out that the `TBranch` destructor still need it to have a valid value. A new version correcting this has been uploaded.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9021
https://github.com/root-project/root/pull/9021:4,performance,failur,failure,4,The failure in roottest_root_tree_branches_make is real and was due to the `fDirectory` member being reset too early. Turns out that the `TBranch` destructor still need it to have a valid value. A new version correcting this has been uploaded.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9021
https://github.com/root-project/root/pull/9021:4,reliability,fail,failure,4,The failure in roottest_root_tree_branches_make is real and was due to the `fDirectory` member being reset too early. Turns out that the `TBranch` destructor still need it to have a valid value. A new version correcting this has been uploaded.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9021
https://github.com/root-project/root/pull/9021:182,safety,valid,valid,182,The failure in roottest_root_tree_branches_make is real and was due to the `fDirectory` member being reset too early. Turns out that the `TBranch` destructor still need it to have a valid value. A new version correcting this has been uploaded.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9021
https://github.com/root-project/root/pull/9021:112,deployability,patch,patch,112,"@pcanal does it make sense to also add a test in `roottest` against issue #9017? If not, I trust you (that this patch fixes the issue) ;-)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9021
https://github.com/root-project/root/pull/9021:8,reliability,doe,does,8,"@pcanal does it make sense to also add a test in `roottest` against issue #9017? If not, I trust you (that this patch fixes the issue) ;-)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9021
https://github.com/root-project/root/pull/9021:41,safety,test,test,41,"@pcanal does it make sense to also add a test in `roottest` against issue #9017? If not, I trust you (that this patch fixes the issue) ;-)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9021
https://github.com/root-project/root/pull/9021:112,safety,patch,patch,112,"@pcanal does it make sense to also add a test in `roottest` against issue #9017? If not, I trust you (that this patch fixes the issue) ;-)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9021
https://github.com/root-project/root/pull/9021:91,security,trust,trust,91,"@pcanal does it make sense to also add a test in `roottest` against issue #9017? If not, I trust you (that this patch fixes the issue) ;-)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9021
https://github.com/root-project/root/pull/9021:112,security,patch,patch,112,"@pcanal does it make sense to also add a test in `roottest` against issue #9017? If not, I trust you (that this patch fixes the issue) ;-)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9021
https://github.com/root-project/root/pull/9021:41,testability,test,test,41,"@pcanal does it make sense to also add a test in `roottest` against issue #9017? If not, I trust you (that this patch fixes the issue) ;-)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9021
https://github.com/root-project/root/pull/9021:4,availability,failur,failures,4,The failures (multicore tutorials) are unrelated/pre-existing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9021
https://github.com/root-project/root/pull/9021:4,deployability,fail,failures,4,The failures (multicore tutorials) are unrelated/pre-existing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9021
https://github.com/root-project/root/pull/9021:4,performance,failur,failures,4,The failures (multicore tutorials) are unrelated/pre-existing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9021
https://github.com/root-project/root/pull/9021:4,reliability,fail,failures,4,The failures (multicore tutorials) are unrelated/pre-existing.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9021
https://github.com/root-project/root/issues/9022:11,deployability,observ,observation,11,Additional observation: `-n1` is different from `-n 1`. I can reproduce the problem with `-n 1` on master.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9022
https://github.com/root-project/root/issues/9022:11,testability,observ,observation,11,Additional observation: `-n1` is different from `-n 1`. I can reproduce the problem with `-n 1` on master.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9022
https://github.com/root-project/root/issues/9022:205,safety,test,tests,205,"Option parsing in `hadd` demands a space between `-n` and the value. The value is passed on to `TFileMerger::SetMaxOpenedFiles()` which in turn sets it to a minimum value of `fMaxOpenedFiles = 2`. From my tests, it appears that `TFileMerger` merges the first `fMaxOpenedFiles - 1` input files, which is probably not the desired behavior.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9022
https://github.com/root-project/root/issues/9022:281,safety,input,input,281,"Option parsing in `hadd` demands a space between `-n` and the value. The value is passed on to `TFileMerger::SetMaxOpenedFiles()` which in turn sets it to a minimum value of `fMaxOpenedFiles = 2`. From my tests, it appears that `TFileMerger` merges the first `fMaxOpenedFiles - 1` input files, which is probably not the desired behavior.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9022
https://github.com/root-project/root/issues/9022:205,testability,test,tests,205,"Option parsing in `hadd` demands a space between `-n` and the value. The value is passed on to `TFileMerger::SetMaxOpenedFiles()` which in turn sets it to a minimum value of `fMaxOpenedFiles = 2`. From my tests, it appears that `TFileMerger` merges the first `fMaxOpenedFiles - 1` input files, which is probably not the desired behavior.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9022
https://github.com/root-project/root/issues/9022:157,usability,minim,minimum,157,"Option parsing in `hadd` demands a space between `-n` and the value. The value is passed on to `TFileMerger::SetMaxOpenedFiles()` which in turn sets it to a minimum value of `fMaxOpenedFiles = 2`. From my tests, it appears that `TFileMerger` merges the first `fMaxOpenedFiles - 1` input files, which is probably not the desired behavior.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9022
https://github.com/root-project/root/issues/9022:281,usability,input,input,281,"Option parsing in `hadd` demands a space between `-n` and the value. The value is passed on to `TFileMerger::SetMaxOpenedFiles()` which in turn sets it to a minimum value of `fMaxOpenedFiles = 2`. From my tests, it appears that `TFileMerger` merges the first `fMaxOpenedFiles - 1` input files, which is probably not the desired behavior.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9022
https://github.com/root-project/root/issues/9022:328,usability,behavi,behavior,328,"Option parsing in `hadd` demands a space between `-n` and the value. The value is passed on to `TFileMerger::SetMaxOpenedFiles()` which in turn sets it to a minimum value of `fMaxOpenedFiles = 2`. From my tests, it appears that `TFileMerger` merges the first `fMaxOpenedFiles - 1` input files, which is probably not the desired behavior.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9022
https://github.com/root-project/root/issues/9022:46,availability,down,down,46,"I'm reassigning to Philippe. I think it boils down to this: when processing the excess files, `TFileMerger` switches to the incremental mode. In this mode, `TFileMerger::MergeOne` sets `canBeFound = true`, which in turn at the end of `MergeOne` skips the if block commented with `// Don't write the partial result for TTree and TH1`. Perhaps `canBeFound` should not be true for a histogram that is not (yet) found in the target file?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9022
https://github.com/root-project/root/issues/9023:73,interoperability,prox,proxy,73,The `Histo1D` case comes from a pythonization that replaces the original proxy method by a Python function. Perhaps the same pythonization could take care of forwarding to the original method when possible. What is not clear is why `Count` and `Report` do not print docs.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9023
https://github.com/root-project/root/issues/9023:219,usability,clear,clear,219,The `Histo1D` case comes from a pythonization that replaces the original proxy method by a Python function. Perhaps the same pythonization could take care of forwarding to the original method when possible. What is not clear is why `Count` and `Report` do not print docs.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9023
https://github.com/root-project/root/issues/9023:151,security,access,access,151,"Making the issue more concrete, what would certainly be nice would be to:. - have a nice string representation for RDF nodes and results. - be able to access method docs from the Python prompt. Having nice printouts for the types of RDF _methods_ in PyROOT seems low priority.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9023
https://github.com/root-project/root/pull/9024:11,deployability,build,build,11,@phsft-bot build just on windows10/cxx14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9024
https://github.com/root-project/root/pull/9025:11,deployability,build,build,11,@phsft-bot build just on windows10/cxx14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9025
https://github.com/root-project/root/pull/9028:325,deployability,automat,automatic,325,"Yes adding a tutorial is a good idea. I will add one to this PR. . I decided to use this technique (w>h) to flip from vertical to horizontal because it makes really no sense to draw the palette vertically when w>h and vice versa. Just try to resize the palette interactively and you will understand. Usually I am against the automatic stuff, but for that It is easier and more natural to make it fully automatic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9028
https://github.com/root-project/root/pull/9028:402,deployability,automat,automatic,402,"Yes adding a tutorial is a good idea. I will add one to this PR. . I decided to use this technique (w>h) to flip from vertical to horizontal because it makes really no sense to draw the palette vertically when w>h and vice versa. Just try to resize the palette interactively and you will understand. Usually I am against the automatic stuff, but for that It is easier and more natural to make it fully automatic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9028
https://github.com/root-project/root/pull/9028:177,energy efficiency,draw,draw,177,"Yes adding a tutorial is a good idea. I will add one to this PR. . I decided to use this technique (w>h) to flip from vertical to horizontal because it makes really no sense to draw the palette vertically when w>h and vice versa. Just try to resize the palette interactively and you will understand. Usually I am against the automatic stuff, but for that It is easier and more natural to make it fully automatic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9028
https://github.com/root-project/root/pull/9028:288,testability,understand,understand,288,"Yes adding a tutorial is a good idea. I will add one to this PR. . I decided to use this technique (w>h) to flip from vertical to horizontal because it makes really no sense to draw the palette vertically when w>h and vice versa. Just try to resize the palette interactively and you will understand. Usually I am against the automatic stuff, but for that It is easier and more natural to make it fully automatic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9028
https://github.com/root-project/root/pull/9028:325,testability,automat,automatic,325,"Yes adding a tutorial is a good idea. I will add one to this PR. . I decided to use this technique (w>h) to flip from vertical to horizontal because it makes really no sense to draw the palette vertically when w>h and vice versa. Just try to resize the palette interactively and you will understand. Usually I am against the automatic stuff, but for that It is easier and more natural to make it fully automatic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9028
https://github.com/root-project/root/pull/9028:402,testability,automat,automatic,402,"Yes adding a tutorial is a good idea. I will add one to this PR. . I decided to use this technique (w>h) to flip from vertical to horizontal because it makes really no sense to draw the palette vertically when w>h and vice versa. Just try to resize the palette interactively and you will understand. Usually I am against the automatic stuff, but for that It is easier and more natural to make it fully automatic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9028
https://github.com/root-project/root/pull/9028:261,usability,interact,interactively,261,"Yes adding a tutorial is a good idea. I will add one to this PR. . I decided to use this technique (w>h) to flip from vertical to horizontal because it makes really no sense to draw the palette vertically when w>h and vice versa. Just try to resize the palette interactively and you will understand. Usually I am against the automatic stuff, but for that It is easier and more natural to make it fully automatic.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9028
https://github.com/root-project/root/issues/9029:85,energy efficiency,alloc,allocates,85,"At a quick glance it looks like `TClass::GetClass` calls the interpreter and jitting allocates a little bit every time, notoriously never giving that memory back until the end of the application. I can't tell whether `TClass::GetClass` could avoid any and all jitting on subsequent calls, but it seems reasonable to think so. @Axel-Naumann @pcanal ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:271,integrability,sub,subsequent,271,"At a quick glance it looks like `TClass::GetClass` calls the interpreter and jitting allocates a little bit every time, notoriously never giving that memory back until the end of the application. I can't tell whether `TClass::GetClass` could avoid any and all jitting on subsequent calls, but it seems reasonable to think so. @Axel-Naumann @pcanal ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:114,performance,time,time,114,"At a quick glance it looks like `TClass::GetClass` calls the interpreter and jitting allocates a little bit every time, notoriously never giving that memory back until the end of the application. I can't tell whether `TClass::GetClass` could avoid any and all jitting on subsequent calls, but it seems reasonable to think so. @Axel-Naumann @pcanal ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:150,performance,memor,memory,150,"At a quick glance it looks like `TClass::GetClass` calls the interpreter and jitting allocates a little bit every time, notoriously never giving that memory back until the end of the application. I can't tell whether `TClass::GetClass` could avoid any and all jitting on subsequent calls, but it seems reasonable to think so. @Axel-Naumann @pcanal ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:242,safety,avoid,avoid,242,"At a quick glance it looks like `TClass::GetClass` calls the interpreter and jitting allocates a little bit every time, notoriously never giving that memory back until the end of the application. I can't tell whether `TClass::GetClass` could avoid any and all jitting on subsequent calls, but it seems reasonable to think so. @Axel-Naumann @pcanal ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:150,usability,memor,memory,150,"At a quick glance it looks like `TClass::GetClass` calls the interpreter and jitting allocates a little bit every time, notoriously never giving that memory back until the end of the application. I can't tell whether `TClass::GetClass` could avoid any and all jitting on subsequent calls, but it seems reasonable to think so. @Axel-Naumann @pcanal ?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:11,usability,help,helps,11,"In case it helps here's the output of massif for the first of the two reproducers: https://cernbox.cern.ch/index.php/s/aACGp2JdPzAQUfW (it should be readable with `ms_print`, the most relevant frame is the very last one)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:36,deployability,scale,scale,36,I was wondering if there was a time scale for this issue being fixed as it impacts one of the calibration workflows in ATLAS?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:36,energy efficiency,scale,scale,36,I was wondering if there was a time scale for this issue being fixed as it impacts one of the calibration workflows in ATLAS?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:36,modifiability,scal,scale,36,I was wondering if there was a time scale for this issue being fixed as it impacts one of the calibration workflows in ATLAS?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:31,performance,time,time,31,I was wondering if there was a time scale for this issue being fixed as it impacts one of the calibration workflows in ATLAS?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:36,performance,scale,scale,36,I was wondering if there was a time scale for this issue being fixed as it impacts one of the calibration workflows in ATLAS?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:106,usability,workflow,workflows,106,I was wondering if there was a time scale for this issue being fixed as it impacts one of the calibration workflows in ATLAS?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:144,availability,avail,available,144,"Just FYI, `std::vector<int>::value_size` doesn't exist, which is why `TClass::GetClass()` tries again and again to see whether it has been made available in between the calls. This would not be an issue for an existing type, such as `std::vector<int>::value_type`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:41,reliability,doe,doesn,41,"Just FYI, `std::vector<int>::value_size` doesn't exist, which is why `TClass::GetClass()` tries again and again to see whether it has been made available in between the calls. This would not be an issue for an existing type, such as `std::vector<int>::value_type`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:144,reliability,availab,available,144,"Just FYI, `std::vector<int>::value_size` doesn't exist, which is why `TClass::GetClass()` tries again and again to see whether it has been made available in between the calls. This would not be an issue for an existing type, such as `std::vector<int>::value_type`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:144,safety,avail,available,144,"Just FYI, `std::vector<int>::value_size` doesn't exist, which is why `TClass::GetClass()` tries again and again to see whether it has been made available in between the calls. This would not be an issue for an existing type, such as `std::vector<int>::value_type`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:144,security,availab,available,144,"Just FYI, `std::vector<int>::value_size` doesn't exist, which is why `TClass::GetClass()` tries again and again to see whether it has been made available in between the calls. This would not be an issue for an existing type, such as `std::vector<int>::value_type`",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:483,availability,reliab,reliable,483,"Thanks @Axel-Naumann. I'm afraid I still see the issue even if I ask for an existing type, e.g. `std::vector<int>::value_type`. I just tested the following snippet:. ```. import ROOT. while True:. ROOT.TClass.GetClass(""std::vector<int>::value_type""). ```. on:. ```. $ root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on Sep 02 2021, 14:20:23. From tags/v6-24-06@v6-24-06. ```. Admittedly, we were also making some non-optimal calls to `TClass::GetClass()` and the most reliable way to avoid the issue is to avoid these calls altogether. However, finding the offending calls is a bit of a challenge at the moment. Is there a more targeted way to warn about auto-parsing apart from setting `ROOTDEBUG=1`, which of course prints a lot more.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:275,deployability,version,version,275,"Thanks @Axel-Naumann. I'm afraid I still see the issue even if I ask for an existing type, e.g. `std::vector<int>::value_type`. I just tested the following snippet:. ```. import ROOT. while True:. ROOT.TClass.GetClass(""std::vector<int>::value_type""). ```. on:. ```. $ root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on Sep 02 2021, 14:20:23. From tags/v6-24-06@v6-24-06. ```. Admittedly, we were also making some non-optimal calls to `TClass::GetClass()` and the most reliable way to avoid the issue is to avoid these calls altogether. However, finding the offending calls is a bit of a challenge at the moment. Is there a more targeted way to warn about auto-parsing apart from setting `ROOTDEBUG=1`, which of course prints a lot more.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:289,deployability,Version,Version,289,"Thanks @Axel-Naumann. I'm afraid I still see the issue even if I ask for an existing type, e.g. `std::vector<int>::value_type`. I just tested the following snippet:. ```. import ROOT. while True:. ROOT.TClass.GetClass(""std::vector<int>::value_type""). ```. on:. ```. $ root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on Sep 02 2021, 14:20:23. From tags/v6-24-06@v6-24-06. ```. Admittedly, we were also making some non-optimal calls to `TClass::GetClass()` and the most reliable way to avoid the issue is to avoid these calls altogether. However, finding the offending calls is a bit of a challenge at the moment. Is there a more targeted way to warn about auto-parsing apart from setting `ROOTDEBUG=1`, which of course prints a lot more.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:432,energy efficiency,optim,optimal,432,"Thanks @Axel-Naumann. I'm afraid I still see the issue even if I ask for an existing type, e.g. `std::vector<int>::value_type`. I just tested the following snippet:. ```. import ROOT. while True:. ROOT.TClass.GetClass(""std::vector<int>::value_type""). ```. on:. ```. $ root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on Sep 02 2021, 14:20:23. From tags/v6-24-06@v6-24-06. ```. Admittedly, we were also making some non-optimal calls to `TClass::GetClass()` and the most reliable way to avoid the issue is to avoid these calls altogether. However, finding the offending calls is a bit of a challenge at the moment. Is there a more targeted way to warn about auto-parsing apart from setting `ROOTDEBUG=1`, which of course prints a lot more.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:275,integrability,version,version,275,"Thanks @Axel-Naumann. I'm afraid I still see the issue even if I ask for an existing type, e.g. `std::vector<int>::value_type`. I just tested the following snippet:. ```. import ROOT. while True:. ROOT.TClass.GetClass(""std::vector<int>::value_type""). ```. on:. ```. $ root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on Sep 02 2021, 14:20:23. From tags/v6-24-06@v6-24-06. ```. Admittedly, we were also making some non-optimal calls to `TClass::GetClass()` and the most reliable way to avoid the issue is to avoid these calls altogether. However, finding the offending calls is a bit of a challenge at the moment. Is there a more targeted way to warn about auto-parsing apart from setting `ROOTDEBUG=1`, which of course prints a lot more.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:289,integrability,Version,Version,289,"Thanks @Axel-Naumann. I'm afraid I still see the issue even if I ask for an existing type, e.g. `std::vector<int>::value_type`. I just tested the following snippet:. ```. import ROOT. while True:. ROOT.TClass.GetClass(""std::vector<int>::value_type""). ```. on:. ```. $ root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on Sep 02 2021, 14:20:23. From tags/v6-24-06@v6-24-06. ```. Admittedly, we were also making some non-optimal calls to `TClass::GetClass()` and the most reliable way to avoid the issue is to avoid these calls altogether. However, finding the offending calls is a bit of a challenge at the moment. Is there a more targeted way to warn about auto-parsing apart from setting `ROOTDEBUG=1`, which of course prints a lot more.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:275,modifiability,version,version,275,"Thanks @Axel-Naumann. I'm afraid I still see the issue even if I ask for an existing type, e.g. `std::vector<int>::value_type`. I just tested the following snippet:. ```. import ROOT. while True:. ROOT.TClass.GetClass(""std::vector<int>::value_type""). ```. on:. ```. $ root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on Sep 02 2021, 14:20:23. From tags/v6-24-06@v6-24-06. ```. Admittedly, we were also making some non-optimal calls to `TClass::GetClass()` and the most reliable way to avoid the issue is to avoid these calls altogether. However, finding the offending calls is a bit of a challenge at the moment. Is there a more targeted way to warn about auto-parsing apart from setting `ROOTDEBUG=1`, which of course prints a lot more.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:289,modifiability,Version,Version,289,"Thanks @Axel-Naumann. I'm afraid I still see the issue even if I ask for an existing type, e.g. `std::vector<int>::value_type`. I just tested the following snippet:. ```. import ROOT. while True:. ROOT.TClass.GetClass(""std::vector<int>::value_type""). ```. on:. ```. $ root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on Sep 02 2021, 14:20:23. From tags/v6-24-06@v6-24-06. ```. Admittedly, we were also making some non-optimal calls to `TClass::GetClass()` and the most reliable way to avoid the issue is to avoid these calls altogether. However, finding the offending calls is a bit of a challenge at the moment. Is there a more targeted way to warn about auto-parsing apart from setting `ROOTDEBUG=1`, which of course prints a lot more.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:483,reliability,reliab,reliable,483,"Thanks @Axel-Naumann. I'm afraid I still see the issue even if I ask for an existing type, e.g. `std::vector<int>::value_type`. I just tested the following snippet:. ```. import ROOT. while True:. ROOT.TClass.GetClass(""std::vector<int>::value_type""). ```. on:. ```. $ root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on Sep 02 2021, 14:20:23. From tags/v6-24-06@v6-24-06. ```. Admittedly, we were also making some non-optimal calls to `TClass::GetClass()` and the most reliable way to avoid the issue is to avoid these calls altogether. However, finding the offending calls is a bit of a challenge at the moment. Is there a more targeted way to warn about auto-parsing apart from setting `ROOTDEBUG=1`, which of course prints a lot more.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:135,safety,test,tested,135,"Thanks @Axel-Naumann. I'm afraid I still see the issue even if I ask for an existing type, e.g. `std::vector<int>::value_type`. I just tested the following snippet:. ```. import ROOT. while True:. ROOT.TClass.GetClass(""std::vector<int>::value_type""). ```. on:. ```. $ root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on Sep 02 2021, 14:20:23. From tags/v6-24-06@v6-24-06. ```. Admittedly, we were also making some non-optimal calls to `TClass::GetClass()` and the most reliable way to avoid the issue is to avoid these calls altogether. However, finding the offending calls is a bit of a challenge at the moment. Is there a more targeted way to warn about auto-parsing apart from setting `ROOTDEBUG=1`, which of course prints a lot more.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:499,safety,avoid,avoid,499,"Thanks @Axel-Naumann. I'm afraid I still see the issue even if I ask for an existing type, e.g. `std::vector<int>::value_type`. I just tested the following snippet:. ```. import ROOT. while True:. ROOT.TClass.GetClass(""std::vector<int>::value_type""). ```. on:. ```. $ root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on Sep 02 2021, 14:20:23. From tags/v6-24-06@v6-24-06. ```. Admittedly, we were also making some non-optimal calls to `TClass::GetClass()` and the most reliable way to avoid the issue is to avoid these calls altogether. However, finding the offending calls is a bit of a challenge at the moment. Is there a more targeted way to warn about auto-parsing apart from setting `ROOTDEBUG=1`, which of course prints a lot more.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:521,safety,avoid,avoid,521,"Thanks @Axel-Naumann. I'm afraid I still see the issue even if I ask for an existing type, e.g. `std::vector<int>::value_type`. I just tested the following snippet:. ```. import ROOT. while True:. ROOT.TClass.GetClass(""std::vector<int>::value_type""). ```. on:. ```. $ root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on Sep 02 2021, 14:20:23. From tags/v6-24-06@v6-24-06. ```. Admittedly, we were also making some non-optimal calls to `TClass::GetClass()` and the most reliable way to avoid the issue is to avoid these calls altogether. However, finding the offending calls is a bit of a challenge at the moment. Is there a more targeted way to warn about auto-parsing apart from setting `ROOTDEBUG=1`, which of course prints a lot more.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9029:135,testability,test,tested,135,"Thanks @Axel-Naumann. I'm afraid I still see the issue even if I ask for an existing type, e.g. `std::vector<int>::value_type`. I just tested the following snippet:. ```. import ROOT. while True:. ROOT.TClass.GetClass(""std::vector<int>::value_type""). ```. on:. ```. $ root --version. ROOT Version: 6.24/06. Built for linuxx8664gcc on Sep 02 2021, 14:20:23. From tags/v6-24-06@v6-24-06. ```. Admittedly, we were also making some non-optimal calls to `TClass::GetClass()` and the most reliable way to avoid the issue is to avoid these calls altogether. However, finding the offending calls is a bit of a challenge at the moment. Is there a more targeted way to warn about auto-parsing apart from setting `ROOTDEBUG=1`, which of course prints a lot more.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9029
https://github.com/root-project/root/issues/9030:1154,deployability,contain,contained,1154,"DataFrame objects are meant to be treated like trees. I am curious about this first sentence. I have never got this impression, neither reading docs / toying with tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. > there should be a function that allows us to merge them. If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_1.Merge(df_2). # Opening a new file and save the merged dataset into the new file. df_3.Snapshot('tree', 'file.root'). ```. I admit that I might not be able to",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2233,deployability,log,logical,2233,"` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_1.Merge(df_2). # Opening a new file and save the merged dataset into the new file. df_3.Snapshot('tree', 'file.root'). ```. I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. ## Current possible approaches. If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFriend`). This has the big advantage that you don't need to merge any of the files/trees together and thus you also don't need to save them again before creating the RDF object. At the same time, once you do create the RDF object with this concatenated dat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1279,energy efficiency,load,loading,1279,"on, neither reading docs / toying with tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. > there should be a function that allows us to merge them. If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_1.Merge(df_2). # Opening a new file and save the merged dataset into the new file. df_3.Snapshot('tree', 'file.root'). ```. I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I al",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1364,energy efficiency,load,loading,1364,"RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. > there should be a function that allows us to merge them. If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_1.Merge(df_2). # Opening a new file and save the merged dataset into the new file. df_3.Snapshot('tree', 'file.root'). ```. I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. ## Current possible approaches. If you nee",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1727,energy efficiency,load,loading,1727,". Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. > there should be a function that allows us to merge them. If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_1.Merge(df_2). # Opening a new file and save the merged dataset into the new file. df_3.Snapshot('tree', 'file.root'). ```. I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. ## Current possible approaches. If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append val",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2178,energy efficiency,optim,optimizations,2178,". Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_1.Merge(df_2). # Opening a new file and save the merged dataset into the new file. df_3.Snapshot('tree', 'file.root'). ```. I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. ## Current possible approaches. If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFriend`). This has the big advantage that you don't need to merge any of the files/trees together and thus you also don't need to save them again before creating the RDF object. At the same time, once you",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2329,energy efficiency,Current,Current,2329,"you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_1.Merge(df_2). # Opening a new file and save the merged dataset into the new file. df_3.Snapshot('tree', 'file.root'). ```. I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. ## Current possible approaches. If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFriend`). This has the big advantage that you don't need to merge any of the files/trees together and thus you also don't need to save them again before creating the RDF object. At the same time, once you do create the RDF object with this concatenated dataset, you will still be able to call `Snapshot` and get practically a ""merged"" dataset in your o",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2441,energy efficiency,current,current,2441,"e loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_1.Merge(df_2). # Opening a new file and save the merged dataset into the new file. df_3.Snapshot('tree', 'file.root'). ```. I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. ## Current possible approaches. If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFriend`). This has the big advantage that you don't need to merge any of the files/trees together and thus you also don't need to save them again before creating the RDF object. At the same time, once you do create the RDF object with this concatenated dataset, you will still be able to call `Snapshot` and get practically a ""merged"" dataset in your output file. Cheers,. Vincenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:509,integrability,interfac,interface,509,"Dear @acampove,. Thanks contacting us. We should probably wait for @eguiraud for a final answer, but I'd like to give my two cents about this. > Instances of RDataFrame objects are meant to be treated like trees. I am curious about this first sentence. I have never got this impression, neither reading docs / toying with tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. > there should be a function that allows us to merge them. If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1084,integrability,interfac,interface,1084,"answer, but I'd like to give my two cents about this. > Instances of RDataFrame objects are meant to be treated like trees. I am curious about this first sentence. I have never got this impression, neither reading docs / toying with tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. > there should be a function that allows us to merge them. If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_1.Merge(df_2). # Opening a new file and save the merged dataset into the new file. df_3.S",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2682,integrability,schema,schema,2682,"e loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_1.Merge(df_2). # Opening a new file and save the merged dataset into the new file. df_3.Snapshot('tree', 'file.root'). ```. I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. ## Current possible approaches. If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFriend`). This has the big advantage that you don't need to merge any of the files/trees together and thus you also don't need to save them again before creating the RDF object. At the same time, once you do create the RDF object with this concatenated dataset, you will still be able to call `Snapshot` and get practically a ""merged"" dataset in your output file. Cheers,. Vincenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2903,integrability,schema,schema,2903,"e loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_1.Merge(df_2). # Opening a new file and save the merged dataset into the new file. df_3.Snapshot('tree', 'file.root'). ```. I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. ## Current possible approaches. If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFriend`). This has the big advantage that you don't need to merge any of the files/trees together and thus you also don't need to save them again before creating the RDF object. At the same time, once you do create the RDF object with this concatenated dataset, you will still be able to call `Snapshot` and get practically a ""merged"" dataset in your output file. Cheers,. Vincenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:509,interoperability,interfac,interface,509,"Dear @acampove,. Thanks contacting us. We should probably wait for @eguiraud for a final answer, but I'd like to give my two cents about this. > Instances of RDataFrame objects are meant to be treated like trees. I am curious about this first sentence. I have never got this impression, neither reading docs / toying with tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. > there should be a function that allows us to merge them. If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:578,interoperability,format,formats,578,"Dear @acampove,. Thanks contacting us. We should probably wait for @eguiraud for a final answer, but I'd like to give my two cents about this. > Instances of RDataFrame objects are meant to be treated like trees. I am curious about this first sentence. I have never got this impression, neither reading docs / toying with tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. > there should be a function that allows us to merge them. If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:641,interoperability,format,formats,641,"Dear @acampove,. Thanks contacting us. We should probably wait for @eguiraud for a final answer, but I'd like to give my two cents about this. > Instances of RDataFrame objects are meant to be treated like trees. I am curious about this first sentence. I have never got this impression, neither reading docs / toying with tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. > there should be a function that allows us to merge them. If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1084,interoperability,interfac,interface,1084,"answer, but I'd like to give my two cents about this. > Instances of RDataFrame objects are meant to be treated like trees. I am curious about this first sentence. I have never got this impression, neither reading docs / toying with tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. > there should be a function that allows us to merge them. If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_1.Merge(df_2). # Opening a new file and save the merged dataset into the new file. df_3.S",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:509,modifiability,interfac,interface,509,"Dear @acampove,. Thanks contacting us. We should probably wait for @eguiraud for a final answer, but I'd like to give my two cents about this. > Instances of RDataFrame objects are meant to be treated like trees. I am curious about this first sentence. I have never got this impression, neither reading docs / toying with tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. > there should be a function that allows us to merge them. If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1084,modifiability,interfac,interface,1084,"answer, but I'd like to give my two cents about this. > Instances of RDataFrame objects are meant to be treated like trees. I am curious about this first sentence. I have never got this impression, neither reading docs / toying with tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. > there should be a function that allows us to merge them. If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_1.Merge(df_2). # Opening a new file and save the merged dataset into the new file. df_3.S",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1279,performance,load,loading,1279,"on, neither reading docs / toying with tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. > there should be a function that allows us to merge them. If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_1.Merge(df_2). # Opening a new file and save the merged dataset into the new file. df_3.Snapshot('tree', 'file.root'). ```. I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I al",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1364,performance,load,loading,1364,"RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. > there should be a function that allows us to merge them. If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_1.Merge(df_2). # Opening a new file and save the merged dataset into the new file. df_3.Snapshot('tree', 'file.root'). ```. I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. ## Current possible approaches. If you nee",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1727,performance,load,loading,1727,". Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. > there should be a function that allows us to merge them. If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_1.Merge(df_2). # Opening a new file and save the merged dataset into the new file. df_3.Snapshot('tree', 'file.root'). ```. I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. ## Current possible approaches. If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append val",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1982,performance,memor,memory,1982,"an the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_1.Merge(df_2). # Opening a new file and save the merged dataset into the new file. df_3.Snapshot('tree', 'file.root'). ```. I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. ## Current possible approaches. If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFrie",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2178,performance,optimiz,optimizations,2178,". Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_1.Merge(df_2). # Opening a new file and save the merged dataset into the new file. df_3.Snapshot('tree', 'file.root'). ```. I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. ## Current possible approaches. If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFriend`). This has the big advantage that you don't need to merge any of the files/trees together and thus you also don't need to save them again before creating the RDF object. At the same time, once you",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:3171,performance,time,time,3171,"e loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_1.Merge(df_2). # Opening a new file and save the merged dataset into the new file. df_3.Snapshot('tree', 'file.root'). ```. I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. ## Current possible approaches. If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFriend`). This has the big advantage that you don't need to merge any of the files/trees together and thus you also don't need to save them again before creating the RDF object. At the same time, once you do create the RDF object with this concatenated dataset, you will still be able to call `Snapshot` and get practically a ""merged"" dataset in your output file. Cheers,. Vincenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:3293,reliability,pra,practically,3293,"e loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_1.Merge(df_2). # Opening a new file and save the merged dataset into the new file. df_3.Snapshot('tree', 'file.root'). ```. I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. ## Current possible approaches. If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFriend`). This has the big advantage that you don't need to merge any of the files/trees together and thus you also don't need to save them again before creating the RDF object. At the same time, once you do create the RDF object with this concatenated dataset, you will still be able to call `Snapshot` and get practically a ""merged"" dataset in your output file. Cheers,. Vincenzo",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:346,safety,compl,complex,346,"Dear @acampove,. Thanks contacting us. We should probably wait for @eguiraud for a final answer, but I'd like to give my two cents about this. > Instances of RDataFrame objects are meant to be treated like trees. I am curious about this first sentence. I have never got this impression, neither reading docs / toying with tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. > there should be a function that allows us to merge them. If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2233,safety,log,logical,2233,"` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_1.Merge(df_2). # Opening a new file and save the merged dataset into the new file. df_3.Snapshot('tree', 'file.root'). ```. I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. ## Current possible approaches. If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFriend`). This has the big advantage that you don't need to merge any of the files/trees together and thus you also don't need to save them again before creating the RDF object. At the same time, once you do create the RDF object with this concatenated dat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:346,security,compl,complex,346,"Dear @acampove,. Thanks contacting us. We should probably wait for @eguiraud for a final answer, but I'd like to give my two cents about this. > Instances of RDataFrame objects are meant to be treated like trees. I am curious about this first sentence. I have never got this impression, neither reading docs / toying with tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. > there should be a function that allows us to merge them. If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1902,security,ident,identity,1902," to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_1.Merge(df_2). # Opening a new file and save the merged dataset into the new file. df_3.Snapshot('tree', 'file.root'). ```. I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. ## Current possible approaches. If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different sch",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1938,security,ident,identity,1938,"opose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_1.Merge(df_2). # Opening a new file and save the merged dataset into the new file. df_3.Snapshot('tree', 'file.root'). ```. I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. ## Current possible approaches. If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2233,security,log,logical,2233,"` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_1.Merge(df_2). # Opening a new file and save the merged dataset into the new file. df_3.Snapshot('tree', 'file.root'). ```. I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. ## Current possible approaches. If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFriend`). This has the big advantage that you don't need to merge any of the files/trees together and thus you also don't need to save them again before creating the RDF object. At the same time, once you do create the RDF object with this concatenated dat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2233,testability,log,logical,2233,"` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_1.Merge(df_2). # Opening a new file and save the merged dataset into the new file. df_3.Snapshot('tree', 'file.root'). ```. I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. ## Current possible approaches. If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFriend`). This has the big advantage that you don't need to merge any of the files/trees together and thus you also don't need to save them again before creating the RDF object. At the same time, once you do create the RDF object with this concatenated dat",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1982,usability,memor,memory,1982,"an the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. ```python. # Opening files and loading pre-existing datasets. df_1=ROOT.RDataFrame('tree', file_path_1). df_2=ROOT.RDataFrame('tree', file_path_2). # creating new columns in the datasets. df_1=df_1.Define('identity', '+1'). df_2=df_2.Define('identity', '+2'). # Merging the datasets in memory. df_3 = df_1.Merge(df_2). # Opening a new file and save the merged dataset into the new file. df_3.Snapshot('tree', 'file.root'). ```. I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. ## Current possible approaches. If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFrie",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2816,availability,slo,slower,2816,"so just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python. > # Opening files and loading pre-existing datasets. > df_1=ROOT.RDataFrame('tree', file_path_1). > df_2=ROOT.RDataFrame('tree', file_path_2). > . > # creating new columns in the datasets. > df_1=df_1.Define('identity', '+1'). > df_2=df_2.Define('identity', '+2'). > . > # Merging the datasets in memory. > df_3 = df_1.Merge(df_2). > # Opening a new file and save the merged dataset into the new file. > df_3.Snapshot('tree', 'file.root'). > ```. > . > I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. No, the approaches are different. In the approach without `RDataFrame::Merge` I save twice the modified trees with the new column added, so the whole thing is slower than the second approach where the looping and saving can be done only once. . > . > ## Current possible approaches. > If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFriend`). This has the big advantage that you don't need to merge any of the files/trees together and thus you also don't need to save them again before creating the RDF object. At the same time, once you do create the RDF object with this. concatenated ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1443,deployability,contain,contained,1443," the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. I did not refer to the documentation but to how people would actually use this class. 99% of people do not read CSV files with ROOT and `RDataFrame` will be mostly used to interact in a simple and quick way with trees. > . > > there should be a function that allows us to merge them. > . > If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python. > # Opening files and loading pre-existing datasets. > df_1=ROOT.RDataFrame('tree', file_path_1). > df_2=ROOT.RDataFrame('tree', file_path_2). > . > # creating new columns in the datasets. > df_1=df_1.Define('identity', '+1'). > df_2=df_2.Define('identity', '+2'). > . > # Merging the datasets in memory. > df_3 = df_1.Merge(df_2). > # Opening a new file and save the merged dataset into the new file. > df_3.Snapshot('tree', 'file.root'). > ```.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2564,deployability,log,logical,2564,"loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python. > # Opening files and loading pre-existing datasets. > df_1=ROOT.RDataFrame('tree', file_path_1). > df_2=ROOT.RDataFrame('tree', file_path_2). > . > # creating new columns in the datasets. > df_1=df_1.Define('identity', '+1'). > df_2=df_2.Define('identity', '+2'). > . > # Merging the datasets in memory. > df_3 = df_1.Merge(df_2). > # Opening a new file and save the merged dataset into the new file. > df_3.Snapshot('tree', 'file.root'). > ```. > . > I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. No, the approaches are different. In the approach without `RDataFrame::Merge` I save twice the modified trees with the new column added, so the whole thing is slower than the second approach where the looping and saving can be done only once. . > . > ## Current possible approaches. > If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFri",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:4141,deployability,version,version,4141,"ging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. No, the approaches are different. In the approach without `RDataFrame::Merge` I save twice the modified trees with the new column added, so the whole thing is slower than the second approach where the looping and saving can be done only once. . > . > ## Current possible approaches. > If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFriend`). This has the big advantage that you don't need to merge any of the files/trees together and thus you also don't need to save them again before creating the RDF object. At the same time, once you do create the RDF object with this. concatenated dataset, you will still be able to call `Snapshot` and get practically a ""merged"" dataset in your output file. OK, I agree with this and this is a third approach what you propose. The trees can be added as a chain to the `RDataFrame`, the chain can get branches added with `Define` and then `Snapshot` would make a merged version. This would probably mean looping and saving only once and it is efficient. However what if we have 3 trees in the brach and we need a branch `index` whose value is `1` for the first tree `2` for the second and `3` for the third. How would we do that with `Define`? Stuff like:. ```python. df = df.Define('index', 'GetTreeNumber() + 1'). ```. would not work, right? Cheers. > . > Cheers,. > Vincenzo .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1568,energy efficiency,load,loading,1568,"face for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. I did not refer to the documentation but to how people would actually use this class. 99% of people do not read CSV files with ROOT and `RDataFrame` will be mostly used to interact in a simple and quick way with trees. > . > > there should be a function that allows us to merge them. > . > If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python. > # Opening files and loading pre-existing datasets. > df_1=ROOT.RDataFrame('tree', file_path_1). > df_2=ROOT.RDataFrame('tree', file_path_2). > . > # creating new columns in the datasets. > df_1=df_1.Define('identity', '+1'). > df_2=df_2.Define('identity', '+2'). > . > # Merging the datasets in memory. > df_3 = df_1.Merge(df_2). > # Opening a new file and save the merged dataset into the new file. > df_3.Snapshot('tree', 'file.root'). > ```. > . > I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1653,energy efficiency,load,loading,1653,"he fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. I did not refer to the documentation but to how people would actually use this class. 99% of people do not read CSV files with ROOT and `RDataFrame` will be mostly used to interact in a simple and quick way with trees. > . > > there should be a function that allows us to merge them. > . > If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python. > # Opening files and loading pre-existing datasets. > df_1=ROOT.RDataFrame('tree', file_path_1). > df_2=ROOT.RDataFrame('tree', file_path_2). > . > # creating new columns in the datasets. > df_1=df_1.Define('identity', '+1'). > df_2=df_2.Define('identity', '+2'). > . > # Merging the datasets in memory. > df_3 = df_1.Merge(df_2). > # Opening a new file and save the merged dataset into the new file. > df_3.Snapshot('tree', 'file.root'). > ```. > . > I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2024,energy efficiency,load,loading,2024,"and `RDataFrame` will be mostly used to interact in a simple and quick way with trees. > . > > there should be a function that allows us to merge them. > . > If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python. > # Opening files and loading pre-existing datasets. > df_1=ROOT.RDataFrame('tree', file_path_1). > df_2=ROOT.RDataFrame('tree', file_path_2). > . > # creating new columns in the datasets. > df_1=df_1.Define('identity', '+1'). > df_2=df_2.Define('identity', '+2'). > . > # Merging the datasets in memory. > df_3 = df_1.Merge(df_2). > # Opening a new file and save the merged dataset into the new file. > df_3.Snapshot('tree', 'file.root'). > ```. > . > I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. No, the approaches are different. In the approach without `RDataFrame::Merge` I save twice the modified trees with the new column added, so the whole thing is slower than the second approach where the looping and saving can be done only once. . > . > ## Current possible approaches. > If you need to process a dataset with RDF and need to concatenate parts of it, the cur",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2509,energy efficiency,optim,optimizations,2509,"l involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python. > # Opening files and loading pre-existing datasets. > df_1=ROOT.RDataFrame('tree', file_path_1). > df_2=ROOT.RDataFrame('tree', file_path_2). > . > # creating new columns in the datasets. > df_1=df_1.Define('identity', '+1'). > df_2=df_2.Define('identity', '+2'). > . > # Merging the datasets in memory. > df_3 = df_1.Merge(df_2). > # Opening a new file and save the merged dataset into the new file. > df_3.Snapshot('tree', 'file.root'). > ```. > . > I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. No, the approaches are different. In the approach without `RDataFrame::Merge` I save twice the modified trees with the new column added, so the whole thing is slower than the second approach where the looping and saving can be done only once. . > . > ## Current possible approaches. > If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of ent",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2911,energy efficiency,Current,Current,2911,"rging. In fact the solution you provide follows exactly these steps:. > . > ```python. > # Opening files and loading pre-existing datasets. > df_1=ROOT.RDataFrame('tree', file_path_1). > df_2=ROOT.RDataFrame('tree', file_path_2). > . > # creating new columns in the datasets. > df_1=df_1.Define('identity', '+1'). > df_2=df_2.Define('identity', '+2'). > . > # Merging the datasets in memory. > df_3 = df_1.Merge(df_2). > # Opening a new file and save the merged dataset into the new file. > df_3.Snapshot('tree', 'file.root'). > ```. > . > I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. No, the approaches are different. In the approach without `RDataFrame::Merge` I save twice the modified trees with the new column added, so the whole thing is slower than the second approach where the looping and saving can be done only once. . > . > ## Current possible approaches. > If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFriend`). This has the big advantage that you don't need to merge any of the files/trees together and thus you also don't need to save them again before creating the RDF object. At the same time, once you do create the RDF object with this. concatenated dataset, you will still be able to call `Snapshot` and get practically a ""merged"" dataset in you",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:3025,energy efficiency,current,current,3025,"ng pre-existing datasets. > df_1=ROOT.RDataFrame('tree', file_path_1). > df_2=ROOT.RDataFrame('tree', file_path_2). > . > # creating new columns in the datasets. > df_1=df_1.Define('identity', '+1'). > df_2=df_2.Define('identity', '+2'). > . > # Merging the datasets in memory. > df_3 = df_1.Merge(df_2). > # Opening a new file and save the merged dataset into the new file. > df_3.Snapshot('tree', 'file.root'). > ```. > . > I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. No, the approaches are different. In the approach without `RDataFrame::Merge` I save twice the modified trees with the new column added, so the whole thing is slower than the second approach where the looping and saving can be done only once. . > . > ## Current possible approaches. > If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFriend`). This has the big advantage that you don't need to merge any of the files/trees together and thus you also don't need to save them again before creating the RDF object. At the same time, once you do create the RDF object with this. concatenated dataset, you will still be able to call `Snapshot` and get practically a ""merged"" dataset in your output file. OK, I agree with this and this is a third approach what you propose. The trees can be added as a ch",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:567,integrability,interfac,interface,567,"Dear @vepadulano . Thanks for your reply. > Dear @acampove,. > Thanks contacting us. We should probably wait for @eguiraud for a final answer, but I'd like to give my two cents about this. > . > > Instances of RDataFrame objects are meant to be treated like trees. > . > I am curious about this first sentence. I have never got this impression, neither reading docs / toying with tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. I did not refer to the documentation but to how people would actually use this class. 99% of people do not read CSV files with ROOT and `RDataFrame` will be mostly used to interact in a simple and quick way with trees. > . > > there should be a function that allows us to merge them. > . > If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1373,integrability,interfac,interface,1373,"h tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. I did not refer to the documentation but to how people would actually use this class. 99% of people do not read CSV files with ROOT and `RDataFrame` will be mostly used to interact in a simple and quick way with trees. > . > > there should be a function that allows us to merge them. > . > If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python. > # Opening files and loading pre-existing datasets. > df_1=ROOT.RDataFrame('tree', file_path_1). > df_2=ROOT.RDataFrame('tree', file_path_2). > . > # creating new columns in the datasets. > df_1=df_1.Define('identity', '+1'). > df_2=df_2.Define('identity', '+2'). > . > # Merging the datasets in memory. > df_3 = df_1.Merge(df_2). > # Opening a new file and save the merged d",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:3266,integrability,schema,schema,3266,". > # Merging the datasets in memory. > df_3 = df_1.Merge(df_2). > # Opening a new file and save the merged dataset into the new file. > df_3.Snapshot('tree', 'file.root'). > ```. > . > I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. No, the approaches are different. In the approach without `RDataFrame::Merge` I save twice the modified trees with the new column added, so the whole thing is slower than the second approach where the looping and saving can be done only once. . > . > ## Current possible approaches. > If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFriend`). This has the big advantage that you don't need to merge any of the files/trees together and thus you also don't need to save them again before creating the RDF object. At the same time, once you do create the RDF object with this. concatenated dataset, you will still be able to call `Snapshot` and get practically a ""merged"" dataset in your output file. OK, I agree with this and this is a third approach what you propose. The trees can be added as a chain to the `RDataFrame`, the chain can get branches added with `Define` and then `Snapshot` would make a merged version. This would probably mean looping and saving only once and it is efficient. However what if we have 3 trees in the brach",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:3487,integrability,schema,schema,3487," see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. No, the approaches are different. In the approach without `RDataFrame::Merge` I save twice the modified trees with the new column added, so the whole thing is slower than the second approach where the looping and saving can be done only once. . > . > ## Current possible approaches. > If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFriend`). This has the big advantage that you don't need to merge any of the files/trees together and thus you also don't need to save them again before creating the RDF object. At the same time, once you do create the RDF object with this. concatenated dataset, you will still be able to call `Snapshot` and get practically a ""merged"" dataset in your output file. OK, I agree with this and this is a third approach what you propose. The trees can be added as a chain to the `RDataFrame`, the chain can get branches added with `Define` and then `Snapshot` would make a merged version. This would probably mean looping and saving only once and it is efficient. However what if we have 3 trees in the brach and we need a branch `index` whose value is `1` for the first tree `2` for the second and `3` for the third. How would we do that with `Define`? Stuff like:. ```python. df = df.Define('index', 'GetTreeNumber() + 1'). ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:4141,integrability,version,version,4141,"ging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. No, the approaches are different. In the approach without `RDataFrame::Merge` I save twice the modified trees with the new column added, so the whole thing is slower than the second approach where the looping and saving can be done only once. . > . > ## Current possible approaches. > If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFriend`). This has the big advantage that you don't need to merge any of the files/trees together and thus you also don't need to save them again before creating the RDF object. At the same time, once you do create the RDF object with this. concatenated dataset, you will still be able to call `Snapshot` and get practically a ""merged"" dataset in your output file. OK, I agree with this and this is a third approach what you propose. The trees can be added as a chain to the `RDataFrame`, the chain can get branches added with `Define` and then `Snapshot` would make a merged version. This would probably mean looping and saving only once and it is efficient. However what if we have 3 trees in the brach and we need a branch `index` whose value is `1` for the first tree `2` for the second and `3` for the third. How would we do that with `Define`? Stuff like:. ```python. df = df.Define('index', 'GetTreeNumber() + 1'). ```. would not work, right? Cheers. > . > Cheers,. > Vincenzo .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:567,interoperability,interfac,interface,567,"Dear @vepadulano . Thanks for your reply. > Dear @acampove,. > Thanks contacting us. We should probably wait for @eguiraud for a final answer, but I'd like to give my two cents about this. > . > > Instances of RDataFrame objects are meant to be treated like trees. > . > I am curious about this first sentence. I have never got this impression, neither reading docs / toying with tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. I did not refer to the documentation but to how people would actually use this class. 99% of people do not read CSV files with ROOT and `RDataFrame` will be mostly used to interact in a simple and quick way with trees. > . > > there should be a function that allows us to merge them. > . > If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:636,interoperability,format,formats,636,"Dear @vepadulano . Thanks for your reply. > Dear @acampove,. > Thanks contacting us. We should probably wait for @eguiraud for a final answer, but I'd like to give my two cents about this. > . > > Instances of RDataFrame objects are meant to be treated like trees. > . > I am curious about this first sentence. I have never got this impression, neither reading docs / toying with tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. I did not refer to the documentation but to how people would actually use this class. 99% of people do not read CSV files with ROOT and `RDataFrame` will be mostly used to interact in a simple and quick way with trees. > . > > there should be a function that allows us to merge them. > . > If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:699,interoperability,format,formats,699,"Dear @vepadulano . Thanks for your reply. > Dear @acampove,. > Thanks contacting us. We should probably wait for @eguiraud for a final answer, but I'd like to give my two cents about this. > . > > Instances of RDataFrame objects are meant to be treated like trees. > . > I am curious about this first sentence. I have never got this impression, neither reading docs / toying with tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. I did not refer to the documentation but to how people would actually use this class. 99% of people do not read CSV files with ROOT and `RDataFrame` will be mostly used to interact in a simple and quick way with trees. > . > > there should be a function that allows us to merge them. > . > If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1373,interoperability,interfac,interface,1373,"h tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. I did not refer to the documentation but to how people would actually use this class. 99% of people do not read CSV files with ROOT and `RDataFrame` will be mostly used to interact in a simple and quick way with trees. > . > > there should be a function that allows us to merge them. > . > If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python. > # Opening files and loading pre-existing datasets. > df_1=ROOT.RDataFrame('tree', file_path_1). > df_2=ROOT.RDataFrame('tree', file_path_2). > . > # creating new columns in the datasets. > df_1=df_1.Define('identity', '+1'). > df_2=df_2.Define('identity', '+2'). > . > # Merging the datasets in memory. > df_3 = df_1.Merge(df_2). > # Opening a new file and save the merged d",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:567,modifiability,interfac,interface,567,"Dear @vepadulano . Thanks for your reply. > Dear @acampove,. > Thanks contacting us. We should probably wait for @eguiraud for a final answer, but I'd like to give my two cents about this. > . > > Instances of RDataFrame objects are meant to be treated like trees. > . > I am curious about this first sentence. I have never got this impression, neither reading docs / toying with tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. I did not refer to the documentation but to how people would actually use this class. 99% of people do not read CSV files with ROOT and `RDataFrame` will be mostly used to interact in a simple and quick way with trees. > . > > there should be a function that allows us to merge them. > . > If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1373,modifiability,interfac,interface,1373,"h tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. I did not refer to the documentation but to how people would actually use this class. 99% of people do not read CSV files with ROOT and `RDataFrame` will be mostly used to interact in a simple and quick way with trees. > . > > there should be a function that allows us to merge them. > . > If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python. > # Opening files and loading pre-existing datasets. > df_1=ROOT.RDataFrame('tree', file_path_1). > df_2=ROOT.RDataFrame('tree', file_path_2). > . > # creating new columns in the datasets. > df_1=df_1.Define('identity', '+1'). > df_2=df_2.Define('identity', '+2'). > . > # Merging the datasets in memory. > df_3 = df_1.Merge(df_2). > # Opening a new file and save the merged d",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:4141,modifiability,version,version,4141,"ging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. No, the approaches are different. In the approach without `RDataFrame::Merge` I save twice the modified trees with the new column added, so the whole thing is slower than the second approach where the looping and saving can be done only once. . > . > ## Current possible approaches. > If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFriend`). This has the big advantage that you don't need to merge any of the files/trees together and thus you also don't need to save them again before creating the RDF object. At the same time, once you do create the RDF object with this. concatenated dataset, you will still be able to call `Snapshot` and get practically a ""merged"" dataset in your output file. OK, I agree with this and this is a third approach what you propose. The trees can be added as a chain to the `RDataFrame`, the chain can get branches added with `Define` and then `Snapshot` would make a merged version. This would probably mean looping and saving only once and it is efficient. However what if we have 3 trees in the brach and we need a branch `index` whose value is `1` for the first tree `2` for the second and `3` for the third. How would we do that with `Define`? Stuff like:. ```python. df = df.Define('index', 'GetTreeNumber() + 1'). ```. would not work, right? Cheers. > . > Cheers,. > Vincenzo .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1568,performance,load,loading,1568,"face for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. I did not refer to the documentation but to how people would actually use this class. 99% of people do not read CSV files with ROOT and `RDataFrame` will be mostly used to interact in a simple and quick way with trees. > . > > there should be a function that allows us to merge them. > . > If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python. > # Opening files and loading pre-existing datasets. > df_1=ROOT.RDataFrame('tree', file_path_1). > df_2=ROOT.RDataFrame('tree', file_path_2). > . > # creating new columns in the datasets. > df_1=df_1.Define('identity', '+1'). > df_2=df_2.Define('identity', '+2'). > . > # Merging the datasets in memory. > df_3 = df_1.Merge(df_2). > # Opening a new file and save the merged dataset into the new file. > df_3.Snapshot('tree', 'file.root'). > ```. > . > I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1653,performance,load,loading,1653,"he fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. I did not refer to the documentation but to how people would actually use this class. 99% of people do not read CSV files with ROOT and `RDataFrame` will be mostly used to interact in a simple and quick way with trees. > . > > there should be a function that allows us to merge them. > . > If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python. > # Opening files and loading pre-existing datasets. > df_1=ROOT.RDataFrame('tree', file_path_1). > df_2=ROOT.RDataFrame('tree', file_path_2). > . > # creating new columns in the datasets. > df_1=df_1.Define('identity', '+1'). > df_2=df_2.Define('identity', '+2'). > . > # Merging the datasets in memory. > df_3 = df_1.Merge(df_2). > # Opening a new file and save the merged dataset into the new file. > df_3.Snapshot('tree', 'file.root'). > ```. > . > I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2024,performance,load,loading,2024,"and `RDataFrame` will be mostly used to interact in a simple and quick way with trees. > . > > there should be a function that allows us to merge them. > . > If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python. > # Opening files and loading pre-existing datasets. > df_1=ROOT.RDataFrame('tree', file_path_1). > df_2=ROOT.RDataFrame('tree', file_path_2). > . > # creating new columns in the datasets. > df_1=df_1.Define('identity', '+1'). > df_2=df_2.Define('identity', '+2'). > . > # Merging the datasets in memory. > df_3 = df_1.Merge(df_2). > # Opening a new file and save the merged dataset into the new file. > df_3.Snapshot('tree', 'file.root'). > ```. > . > I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. No, the approaches are different. In the approach without `RDataFrame::Merge` I save twice the modified trees with the new column added, so the whole thing is slower than the second approach where the looping and saving can be done only once. . > . > ## Current possible approaches. > If you need to process a dataset with RDF and need to concatenate parts of it, the cur",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2299,performance,memor,memory,2299,"ave above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python. > # Opening files and loading pre-existing datasets. > df_1=ROOT.RDataFrame('tree', file_path_1). > df_2=ROOT.RDataFrame('tree', file_path_2). > . > # creating new columns in the datasets. > df_1=df_1.Define('identity', '+1'). > df_2=df_2.Define('identity', '+2'). > . > # Merging the datasets in memory. > df_3 = df_1.Merge(df_2). > # Opening a new file and save the merged dataset into the new file. > df_3.Snapshot('tree', 'file.root'). > ```. > . > I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. No, the approaches are different. In the approach without `RDataFrame::Merge` I save twice the modified trees with the new column added, so the whole thing is slower than the second approach where the looping and saving can be done only once. . > . > ## Current possible approaches. > If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2509,performance,optimiz,optimizations,2509,"l involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python. > # Opening files and loading pre-existing datasets. > df_1=ROOT.RDataFrame('tree', file_path_1). > df_2=ROOT.RDataFrame('tree', file_path_2). > . > # creating new columns in the datasets. > df_1=df_1.Define('identity', '+1'). > df_2=df_2.Define('identity', '+2'). > . > # Merging the datasets in memory. > df_3 = df_1.Merge(df_2). > # Opening a new file and save the merged dataset into the new file. > df_3.Snapshot('tree', 'file.root'). > ```. > . > I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. No, the approaches are different. In the approach without `RDataFrame::Merge` I save twice the modified trees with the new column added, so the whole thing is slower than the second approach where the looping and saving can be done only once. . > . > ## Current possible approaches. > If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of ent",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:3755,performance,time,time,3755,"ging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. No, the approaches are different. In the approach without `RDataFrame::Merge` I save twice the modified trees with the new column added, so the whole thing is slower than the second approach where the looping and saving can be done only once. . > . > ## Current possible approaches. > If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFriend`). This has the big advantage that you don't need to merge any of the files/trees together and thus you also don't need to save them again before creating the RDF object. At the same time, once you do create the RDF object with this. concatenated dataset, you will still be able to call `Snapshot` and get practically a ""merged"" dataset in your output file. OK, I agree with this and this is a third approach what you propose. The trees can be added as a chain to the `RDataFrame`, the chain can get branches added with `Define` and then `Snapshot` would make a merged version. This would probably mean looping and saving only once and it is efficient. However what if we have 3 trees in the brach and we need a branch `index` whose value is `1` for the first tree `2` for the second and `3` for the third. How would we do that with `Define`? Stuff like:. ```python. df = df.Define('index', 'GetTreeNumber() + 1'). ```. would not work, right? Cheers. > . > Cheers,. > Vincenzo .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2816,reliability,slo,slower,2816,"so just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python. > # Opening files and loading pre-existing datasets. > df_1=ROOT.RDataFrame('tree', file_path_1). > df_2=ROOT.RDataFrame('tree', file_path_2). > . > # creating new columns in the datasets. > df_1=df_1.Define('identity', '+1'). > df_2=df_2.Define('identity', '+2'). > . > # Merging the datasets in memory. > df_3 = df_1.Merge(df_2). > # Opening a new file and save the merged dataset into the new file. > df_3.Snapshot('tree', 'file.root'). > ```. > . > I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. No, the approaches are different. In the approach without `RDataFrame::Merge` I save twice the modified trees with the new column added, so the whole thing is slower than the second approach where the looping and saving can be done only once. . > . > ## Current possible approaches. > If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFriend`). This has the big advantage that you don't need to merge any of the files/trees together and thus you also don't need to save them again before creating the RDF object. At the same time, once you do create the RDF object with this. concatenated ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:3878,reliability,pra,practically,3878,"ging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. No, the approaches are different. In the approach without `RDataFrame::Merge` I save twice the modified trees with the new column added, so the whole thing is slower than the second approach where the looping and saving can be done only once. . > . > ## Current possible approaches. > If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFriend`). This has the big advantage that you don't need to merge any of the files/trees together and thus you also don't need to save them again before creating the RDF object. At the same time, once you do create the RDF object with this. concatenated dataset, you will still be able to call `Snapshot` and get practically a ""merged"" dataset in your output file. OK, I agree with this and this is a third approach what you propose. The trees can be added as a chain to the `RDataFrame`, the chain can get branches added with `Define` and then `Snapshot` would make a merged version. This would probably mean looping and saving only once and it is efficient. However what if we have 3 trees in the brach and we need a branch `index` whose value is `1` for the first tree `2` for the second and `3` for the third. How would we do that with `Define`? Stuff like:. ```python. df = df.Define('index', 'GetTreeNumber() + 1'). ```. would not work, right? Cheers. > . > Cheers,. > Vincenzo .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:404,safety,compl,complex,404,"Dear @vepadulano . Thanks for your reply. > Dear @acampove,. > Thanks contacting us. We should probably wait for @eguiraud for a final answer, but I'd like to give my two cents about this. > . > > Instances of RDataFrame objects are meant to be treated like trees. > . > I am curious about this first sentence. I have never got this impression, neither reading docs / toying with tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. I did not refer to the documentation but to how people would actually use this class. 99% of people do not read CSV files with ROOT and `RDataFrame` will be mostly used to interact in a simple and quick way with trees. > . > > there should be a function that allows us to merge them. > . > If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2564,safety,log,logical,2564,"loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python. > # Opening files and loading pre-existing datasets. > df_1=ROOT.RDataFrame('tree', file_path_1). > df_2=ROOT.RDataFrame('tree', file_path_2). > . > # creating new columns in the datasets. > df_1=df_1.Define('identity', '+1'). > df_2=df_2.Define('identity', '+2'). > . > # Merging the datasets in memory. > df_3 = df_1.Merge(df_2). > # Opening a new file and save the merged dataset into the new file. > df_3.Snapshot('tree', 'file.root'). > ```. > . > I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. No, the approaches are different. In the approach without `RDataFrame::Merge` I save twice the modified trees with the new column added, so the whole thing is slower than the second approach where the looping and saving can be done only once. . > . > ## Current possible approaches. > If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFri",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:404,security,compl,complex,404,"Dear @vepadulano . Thanks for your reply. > Dear @acampove,. > Thanks contacting us. We should probably wait for @eguiraud for a final answer, but I'd like to give my two cents about this. > . > > Instances of RDataFrame objects are meant to be treated like trees. > . > I am curious about this first sentence. I have never got this impression, neither reading docs / toying with tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. I did not refer to the documentation but to how people would actually use this class. 99% of people do not read CSV files with ROOT and `RDataFrame` will be mostly used to interact in a simple and quick way with trees. > . > > there should be a function that allows us to merge them. > . > If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2211,security,ident,identity,2211," function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python. > # Opening files and loading pre-existing datasets. > df_1=ROOT.RDataFrame('tree', file_path_1). > df_2=ROOT.RDataFrame('tree', file_path_2). > . > # creating new columns in the datasets. > df_1=df_1.Define('identity', '+1'). > df_2=df_2.Define('identity', '+2'). > . > # Merging the datasets in memory. > df_3 = df_1.Merge(df_2). > # Opening a new file and save the merged dataset into the new file. > df_3.Snapshot('tree', 'file.root'). > ```. > . > I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. No, the approaches are different. In the approach without `RDataFrame::Merge` I save twice the modified trees with the new column added, so the whole thing is slower than the second approach where the looping and saving can be done only once. . > . > ## Current possible approaches. > If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vert",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2249,security,ident,identity,2249,"going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python. > # Opening files and loading pre-existing datasets. > df_1=ROOT.RDataFrame('tree', file_path_1). > df_2=ROOT.RDataFrame('tree', file_path_2). > . > # creating new columns in the datasets. > df_1=df_1.Define('identity', '+1'). > df_2=df_2.Define('identity', '+2'). > . > # Merging the datasets in memory. > df_3 = df_1.Merge(df_2). > # Opening a new file and save the merged dataset into the new file. > df_3.Snapshot('tree', 'file.root'). > ```. > . > I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. No, the approaches are different. In the approach without `RDataFrame::Merge` I save twice the modified trees with the new column added, so the whole thing is slower than the second approach where the looping and saving can be done only once. . > . > ## Current possible approaches. > If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all h",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2564,security,log,logical,2564,"loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python. > # Opening files and loading pre-existing datasets. > df_1=ROOT.RDataFrame('tree', file_path_1). > df_2=ROOT.RDataFrame('tree', file_path_2). > . > # creating new columns in the datasets. > df_1=df_1.Define('identity', '+1'). > df_2=df_2.Define('identity', '+2'). > . > # Merging the datasets in memory. > df_3 = df_1.Merge(df_2). > # Opening a new file and save the merged dataset into the new file. > df_3.Snapshot('tree', 'file.root'). > ```. > . > I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. No, the approaches are different. In the approach without `RDataFrame::Merge` I save twice the modified trees with the new column added, so the whole thing is slower than the second approach where the looping and saving can be done only once. . > . > ## Current possible approaches. > If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFri",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2752,security,modif,modified,2752,"wo files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python. > # Opening files and loading pre-existing datasets. > df_1=ROOT.RDataFrame('tree', file_path_1). > df_2=ROOT.RDataFrame('tree', file_path_2). > . > # creating new columns in the datasets. > df_1=df_1.Define('identity', '+1'). > df_2=df_2.Define('identity', '+2'). > . > # Merging the datasets in memory. > df_3 = df_1.Merge(df_2). > # Opening a new file and save the merged dataset into the new file. > df_3.Snapshot('tree', 'file.root'). > ```. > . > I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. No, the approaches are different. In the approach without `RDataFrame::Merge` I save twice the modified trees with the new column added, so the whole thing is slower than the second approach where the looping and saving can be done only once. . > . > ## Current possible approaches. > If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFriend`). This has the big advantage that you don't need to merge any of the files/trees together and thus you also don't need to save them again before creating the RDF object. At the same t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1082,testability,simpl,simple,1082,"We should probably wait for @eguiraud for a final answer, but I'd like to give my two cents about this. > . > > Instances of RDataFrame objects are meant to be treated like trees. > . > I am curious about this first sentence. I have never got this impression, neither reading docs / toying with tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. I did not refer to the documentation but to how people would actually use this class. 99% of people do not read CSV files with ROOT and `RDataFrame` will be mostly used to interact in a simple and quick way with trees. > . > > there should be a function that allows us to merge them. > . > If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python. > # Opening files and loading pre-existing datasets. > df_1=ROOT.RDataFrame('tree',",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2564,testability,log,logical,2564,"loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python. > # Opening files and loading pre-existing datasets. > df_1=ROOT.RDataFrame('tree', file_path_1). > df_2=ROOT.RDataFrame('tree', file_path_2). > . > # creating new columns in the datasets. > df_1=df_1.Define('identity', '+1'). > df_2=df_2.Define('identity', '+2'). > . > # Merging the datasets in memory. > df_3 = df_1.Merge(df_2). > # Opening a new file and save the merged dataset into the new file. > df_3.Snapshot('tree', 'file.root'). > ```. > . > I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. No, the approaches are different. In the approach without `RDataFrame::Merge` I save twice the modified trees with the new column added, so the whole thing is slower than the second approach where the looping and saving can be done only once. . > . > ## Current possible approaches. > If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFri",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:919,usability,document,documentation,919,"Dear @vepadulano . Thanks for your reply. > Dear @acampove,. > Thanks contacting us. We should probably wait for @eguiraud for a final answer, but I'd like to give my two cents about this. > . > > Instances of RDataFrame objects are meant to be treated like trees. > . > I am curious about this first sentence. I have never got this impression, neither reading docs / toying with tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. I did not refer to the documentation but to how people would actually use this class. 99% of people do not read CSV files with ROOT and `RDataFrame` will be mostly used to interact in a simple and quick way with trees. > . > > there should be a function that allows us to merge them. > . > If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1068,usability,interact,interact,1068,"ntacting us. We should probably wait for @eguiraud for a final answer, but I'd like to give my two cents about this. > . > > Instances of RDataFrame objects are meant to be treated like trees. > . > I am curious about this first sentence. I have never got this impression, neither reading docs / toying with tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. I did not refer to the documentation but to how people would actually use this class. 99% of people do not read CSV files with ROOT and `RDataFrame` will be mostly used to interact in a simple and quick way with trees. > . > > there should be a function that allows us to merge them. > . > If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python. > # Opening files and loading pre-existing datasets. > df_1=ROOT.RData",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1082,usability,simpl,simple,1082,"We should probably wait for @eguiraud for a final answer, but I'd like to give my two cents about this. > . > > Instances of RDataFrame objects are meant to be treated like trees. > . > I am curious about this first sentence. I have never got this impression, neither reading docs / toying with tutorials or doing more complex analyses with RDF. the first line of the [RDF docs](https://root.cern/doc/master/classROOT_1_1RDataFrame.html) says `ROOT's RDataFrame offers a high level interface for analyses of data stored in TTree, CSV's and other data formats. `. Just by the fact that I can read and process other formats than TTree I would say that in general RDF is not meant to be treated like a TTree. Otherwise I would also have to say that RDF is meant to be treated like a CSV file or something similar. I did not refer to the documentation but to how people would actually use this class. 99% of people do not read CSV files with ROOT and `RDataFrame` will be mostly used to interact in a simple and quick way with trees. > . > > there should be a function that allows us to merge them. > . > If I have to think about this function you propose, I don't see it going much further than the example you already have above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python. > # Opening files and loading pre-existing datasets. > df_1=ROOT.RDataFrame('tree',",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2299,usability,memor,memory,2299,"ave above. Since RDataFrame **is not** the dataset itself, but just an interface to it, it still needs to open the file where the dataset is contained and read data from it. Thus, merging two RDF objects would still involve ` opening each file and saving them. Then loading them again and merging, then saving again` as you say above. Or at least the loading, merging and saving again part, if we consider that the part of your example where you create two files from scratch and save data into them with RDF could also just have been opening already existing files written by some other application before the merging. In fact the solution you provide follows exactly these steps:. > . > ```python. > # Opening files and loading pre-existing datasets. > df_1=ROOT.RDataFrame('tree', file_path_1). > df_2=ROOT.RDataFrame('tree', file_path_2). > . > # creating new columns in the datasets. > df_1=df_1.Define('identity', '+1'). > df_2=df_2.Define('identity', '+2'). > . > # Merging the datasets in memory. > df_3 = df_1.Merge(df_2). > # Opening a new file and save the merged dataset into the new file. > df_3.Snapshot('tree', 'file.root'). > ```. > . > I admit that I might not be able to see some internal optimizations that RDF might do while merging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. No, the approaches are different. In the approach without `RDataFrame::Merge` I save twice the modified trees with the new column added, so the whole thing is slower than the second approach where the looping and saving can be done only once. . > . > ## Current possible approaches. > If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:4214,usability,efficien,efficient,4214,"ging, but the logical steps seem to be equivalent to me. Or I also might be misinterpreting your proposal. No, the approaches are different. In the approach without `RDataFrame::Merge` I save twice the modified trees with the new column added, so the whole thing is slower than the second approach where the looping and saving can be done only once. . > . > ## Current possible approaches. > If you need to process a dataset with RDF and need to concatenate parts of it, the current best approach is to use the `RDataFrame(TTree &tree)` constructor after having created the correct tree with all the information you need. If for example you need to concatenate vertically 2 or more TTrees (i.e. if all have the same schema with column `a` and you want to append values of the same column into a single entity), than you can create a TChain and add all the trees to it. If you need horizontal concatenation (i.e. the trees have different schema but same number of entries) you can use friends pattern (e.g. `tree.AddFriend`). This has the big advantage that you don't need to merge any of the files/trees together and thus you also don't need to save them again before creating the RDF object. At the same time, once you do create the RDF object with this. concatenated dataset, you will still be able to call `Snapshot` and get practically a ""merged"" dataset in your output file. OK, I agree with this and this is a third approach what you propose. The trees can be added as a chain to the `RDataFrame`, the chain can get branches added with `Define` and then `Snapshot` would make a merged version. This would probably mean looping and saving only once and it is efficient. However what if we have 3 trees in the brach and we need a branch `index` whose value is `1` for the first tree `2` for the second and `3` for the third. How would we do that with `Define`? Stuff like:. ```python. df = df.Define('index', 'GetTreeNumber() + 1'). ```. would not work, right? Cheers. > . > Cheers,. > Vincenzo .",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:927,deployability,build,build,927,"Hi,. assuming that simply producing a single tree to begin with is impossible, I would also recommend to go with a TChain for post-processing. > what if we have 3 trees in the brach and we need a branch index whose value is 1 for the first tree 2 for the second and 3 for the third. How would we do that with Define? Is it not possible to store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. - calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. - store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. - do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1175,deployability,Build,BuildIndex,1175,"h and we need a branch index whose value is 1 for the first tree 2 for the second and 3 for the third. How would we do that with Define? Is it not possible to store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. - calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. - store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. - do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. ```cpp. df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.A",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1290,deployability,Build,BuildIndex,1290," do that with Define? Is it not possible to store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. - calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. - store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. - do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. ```cpp. df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). ```. where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1363,deployability,depend,depending,1363,"o store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. - calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. - store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. - do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. ```cpp. df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). ```. where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge this feature in master today or tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:404,energy efficiency,current,currently,404,"Hi,. assuming that simply producing a single tree to begin with is impossible, I would also recommend to go with a TChain for post-processing. > what if we have 3 trees in the brach and we need a branch index whose value is 1 for the first tree 2 for the second and 3 for the third. How would we do that with Define? Is it not possible to store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. - calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. - store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. - do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:789,integrability,event,event,789,"Hi,. assuming that simply producing a single tree to begin with is impossible, I would also recommend to go with a TChain for post-processing. > what if we have 3 trees in the brach and we need a branch index whose value is 1 for the first tree 2 for the second and 3 for the third. How would we do that with Define? Is it not possible to store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. - calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. - store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. - do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1357,integrability,event,event,1357,"o store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. - calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. - store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. - do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. ```cpp. df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). ```. where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge this feature in master today or tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1363,integrability,depend,depending,1363,"o store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. - calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. - store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. - do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. ```cpp. df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). ```. where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge this feature in master today or tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1363,modifiability,depend,depending,1363,"o store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. - calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. - store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. - do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. ```cpp. df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). ```. where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge this feature in master today or tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:674,performance,time,timestamp,674,"Hi,. assuming that simply producing a single tree to begin with is impossible, I would also recommend to go with a TChain for post-processing. > what if we have 3 trees in the brach and we need a branch index whose value is 1 for the first tree 2 for the second and 3 for the third. How would we do that with Define? Is it not possible to store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. - calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. - store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. - do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:875,performance,disk,disk,875,"Hi,. assuming that simply producing a single tree to begin with is impossible, I would also recommend to go with a TChain for post-processing. > what if we have 3 trees in the brach and we need a branch index whose value is 1 for the first tree 2 for the second and 3 for the third. How would we do that with Define? Is it not possible to store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. - calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. - store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. - do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1363,safety,depend,depending,1363,"o store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. - calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. - store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. - do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. ```cpp. df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). ```. where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge this feature in master today or tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1498,safety,input,input,1498,"o store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. - calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. - store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. - do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. ```cpp. df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). ```. where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge this feature in master today or tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:623,security,ident,identifier,623,"Hi,. assuming that simply producing a single tree to begin with is impossible, I would also recommend to go with a TChain for post-processing. > what if we have 3 trees in the brach and we need a branch index whose value is 1 for the first tree 2 for the second and 3 for the third. How would we do that with Define? Is it not possible to store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. - calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. - store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. - do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:899,security,ident,identifier,899,"Hi,. assuming that simply producing a single tree to begin with is impossible, I would also recommend to go with a TChain for post-processing. > what if we have 3 trees in the brach and we need a branch index whose value is 1 for the first tree 2 for the second and 3 for the third. How would we do that with Define? Is it not possible to store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. - calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. - store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. - do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:19,testability,simpl,simply,19,"Hi,. assuming that simply producing a single tree to begin with is impossible, I would also recommend to go with a TChain for post-processing. > what if we have 3 trees in the brach and we need a branch index whose value is 1 for the first tree 2 for the second and 3 for the third. How would we do that with Define? Is it not possible to store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. - calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. - store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. - do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1363,testability,depend,depending,1363,"o store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. - calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. - store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. - do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. ```cpp. df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). ```. where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge this feature in master today or tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1837,testability,simpl,simplest,1837,"o store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. - calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. - store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. - do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. ```cpp. df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). ```. where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge this feature in master today or tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:19,usability,simpl,simply,19,"Hi,. assuming that simply producing a single tree to begin with is impossible, I would also recommend to go with a TChain for post-processing. > what if we have 3 trees in the brach and we need a branch index whose value is 1 for the first tree 2 for the second and 3 for the third. How would we do that with Define? Is it not possible to store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. - calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. - store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. - do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1498,usability,input,input,1498,"o store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. - calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. - store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. - do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. ```cpp. df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). ```. where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge this feature in master today or tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1757,usability,effectiv,effectively,1757,"o store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. - calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. - store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. - do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. ```cpp. df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). ```. where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge this feature in master today or tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1837,usability,simpl,simplest,1837,"o store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. - calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. - store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. - do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. ```cpp. df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). ```. where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge this feature in master today or tomorrow.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:798,availability,sli,slip,798,"Hi,. > Hi, assuming that simply producing a single tree to begin with is impossible, I would also recommend to go with a TChain for post-processing. These trees are produced from jobs in the grid, it is not possible to produce a single file. > . > > what if we have 3 trees in the brach and we need a branch index whose value is 1 for the first tree 2 for the second and 3 for the third. How would we do that with Define? > . > Is it not possible to store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. It is possible to do that. However those trees do not have those indexes and in order to add them we would need to rerun hundreds of jobs in the grid. We do need to postprocess these ntuples anyway, so the idea is to slip in a small function to add this index. . > . > * calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. It is dangerous and requires adding too many lines of code. > * store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. Howeve",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2588,availability,sli,slightly,2588,"Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. However the name of the file identifies it, so we deduce the index with the filename. The rest of the solution is close to what I did below. . > * do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). OK, that is closer to what we need, I managed to get the code below to add these indexes in a slightly different way from what you said (or maybe the same if I misunderstood you), i.e. using chains and friend trees:. ```python. import ROOT. import numpy. #------------------------------------------. def make_data(val):. val = str(val). filepath = '/tmp/file_{}.root'.format(val). df=ROOT.RDataFrame(2). df=df.Define('a', val). df.Snapshot('tree', filepath). return filepath. #------------------------------------------. def get_df(l_tp_file, treename, id_column='index'):. l_index = []. for index, filepath in l_tp_file:. df=ROOT.RDataFrame(treename, filepath). nentries = df.Count().GetValue(). l_index += nentries * [index]. arr_id = numpy.array(l_index). idfilepath = '/tmp/file_id.root'. df_id = ROOT.RDF.MakeNumpyDataFrame({id_column: arr_id}). df_id.Snapshot(treename, idfilepath). ch_data = ROOT.TChain(treename, '') . for _, filepath in l_tp_file:. ch_data.Add(filepath). size_ch = ch_data.GetEntries(). size_id = arr_id.size. if size_ch != size_id:. print('Different id and chain sizes: {",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:5505,availability,avail,available,5505," ch_data.AddFriend(treename, idfilepath). df = ROOT.RDataFrame(ch_data). return (df, ch_data). #------------------------------------------. def test():. #----------------------. #Make input. #----------------------. index = 0 . l_tp_file = [] . for val in range(0, 100, 10):. filepath = make_data(val). l_tp_file.append((index, filepath)). index+=1. #----------------------. #Merge. #----------------------. df, _ = get_df(l_tp_file, 'tree', id_column='id'). df.Display(['a', 'id'], -1).Print(). #df.Snapshot('tree', 'file.root'). #------------------------------------------. test(). ```. I will add `get_df` to my personal library. The approach seems safe and clean enough, however the return value needs to include the chain (i.e. _) because otherwise I get a crash. Which seems to indicate that the chain's reference is not kept inside the dataframe. So once the function returns, the chain is removed by the garbage collector and the dataframe does not have anything to save (the script above is self contained and you can try it yourself). That should not be right, if I tell the dataframe to use the chain, the chain should be kept alive by the dataframe. > . > The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. > . > ```c++. > df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). > ```. > . > where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge this feature in master today or tomorrow. So we would have to create a `GetIndex` function to extract from the ""filename/treename"" the index? Yes, that would make my code far simpler. However it might take months until that is available through CVMFS. In any case, the simpler our code gets, the better, fewer places for bugs to hide. Cheers and thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1369,deployability,build,build,1369," for the third. How would we do that with Define? > . > Is it not possible to store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. It is possible to do that. However those trees do not have those indexes and in order to add them we would need to rerun hundreds of jobs in the grid. We do need to postprocess these ntuples anyway, so the idea is to slip in a small function to add this index. . > . > * calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. It is dangerous and requires adding too many lines of code. > * store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. However the name of the file identifies it, so we deduce the index with the filename. The rest of the solution is close to what I did below. . > * do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then a",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1617,deployability,Build,BuildIndex,1617,"trees do not have those indexes and in order to add them we would need to rerun hundreds of jobs in the grid. We do need to postprocess these ntuples anyway, so the idea is to slip in a small function to add this index. . > . > * calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. It is dangerous and requires adding too many lines of code. > * store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. However the name of the file identifies it, so we deduce the index with the filename. The rest of the solution is close to what I did below. . > * do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). OK, that is closer to what we need, I managed to get the code below to add these indexes in a slightly different way from what y",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1732,deployability,Build,BuildIndex,1732," need to postprocess these ntuples anyway, so the idea is to slip in a small function to add this index. . > . > * calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. It is dangerous and requires adding too many lines of code. > * store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. However the name of the file identifies it, so we deduce the index with the filename. The rest of the solution is close to what I did below. . > * do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). OK, that is closer to what we need, I managed to get the code below to add these indexes in a slightly different way from what you said (or maybe the same if I misunderstood you), i.e. using chains and friend trees:. ```python. import ROOT. im",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1805,deployability,depend,depending,1805,"all function to add this index. . > . > * calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. It is dangerous and requires adding too many lines of code. > * store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. However the name of the file identifies it, so we deduce the index with the filename. The rest of the solution is close to what I did below. . > * do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). OK, that is closer to what we need, I managed to get the code below to add these indexes in a slightly different way from what you said (or maybe the same if I misunderstood you), i.e. using chains and friend trees:. ```python. import ROOT. import numpy. #------------------------------------------. def make_data(va",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2532,deployability,manag,managed,2532," tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. However the name of the file identifies it, so we deduce the index with the filename. The rest of the solution is close to what I did below. . > * do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). OK, that is closer to what we need, I managed to get the code below to add these indexes in a slightly different way from what you said (or maybe the same if I misunderstood you), i.e. using chains and friend trees:. ```python. import ROOT. import numpy. #------------------------------------------. def make_data(val):. val = str(val). filepath = '/tmp/file_{}.root'.format(val). df=ROOT.RDataFrame(2). df=df.Define('a', val). df.Snapshot('tree', filepath). return filepath. #------------------------------------------. def get_df(l_tp_file, treename, id_column='index'):. l_index = []. for index, filepath in l_tp_file:. df=ROOT.RDataFrame(treename, filepath). nentries = df.Count().GetValue(). l_index += nentries * [index]. arr_id = numpy.array(l_index). idfilepath = '/tmp/file_id.root'. df_id = ROOT.RDF.MakeNumpyDataFrame({id_column: arr_id}). df_id.Snapshot(treename, idfilepath). ch_data = ROOT.TChain(treename, '') . for _, filepath in l_tp_file:. ch_data.Add(filepath). size_ch = ch_data.GetEntries(). size_id = arr_id.size. if siz",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:4636,deployability,contain,contained,4636," ch_data.AddFriend(treename, idfilepath). df = ROOT.RDataFrame(ch_data). return (df, ch_data). #------------------------------------------. def test():. #----------------------. #Make input. #----------------------. index = 0 . l_tp_file = [] . for val in range(0, 100, 10):. filepath = make_data(val). l_tp_file.append((index, filepath)). index+=1. #----------------------. #Merge. #----------------------. df, _ = get_df(l_tp_file, 'tree', id_column='id'). df.Display(['a', 'id'], -1).Print(). #df.Snapshot('tree', 'file.root'). #------------------------------------------. test(). ```. I will add `get_df` to my personal library. The approach seems safe and clean enough, however the return value needs to include the chain (i.e. _) because otherwise I get a crash. Which seems to indicate that the chain's reference is not kept inside the dataframe. So once the function returns, the chain is removed by the garbage collector and the dataframe does not have anything to save (the script above is self contained and you can try it yourself). That should not be right, if I tell the dataframe to use the chain, the chain should be kept alive by the dataframe. > . > The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. > . > ```c++. > df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). > ```. > . > where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge this feature in master today or tomorrow. So we would have to create a `GetIndex` function to extract from the ""filename/treename"" the index? Yes, that would make my code far simpler. However it might take months until that is available through CVMFS. In any case, the simpler our code gets, the better, fewer places for bugs to hide. Cheers and thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:515,energy efficiency,current,currently,515,"Hi,. > Hi, assuming that simply producing a single tree to begin with is impossible, I would also recommend to go with a TChain for post-processing. These trees are produced from jobs in the grid, it is not possible to produce a single file. > . > > what if we have 3 trees in the brach and we need a branch index whose value is 1 for the first tree 2 for the second and 3 for the third. How would we do that with Define? > . > Is it not possible to store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. It is possible to do that. However those trees do not have those indexes and in order to add them we would need to rerun hundreds of jobs in the grid. We do need to postprocess these ntuples anyway, so the idea is to slip in a small function to add this index. . > . > * calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. It is dangerous and requires adding too many lines of code. > * store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. Howeve",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2532,energy efficiency,manag,managed,2532," tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. However the name of the file identifies it, so we deduce the index with the filename. The rest of the solution is close to what I did below. . > * do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). OK, that is closer to what we need, I managed to get the code below to add these indexes in a slightly different way from what you said (or maybe the same if I misunderstood you), i.e. using chains and friend trees:. ```python. import ROOT. import numpy. #------------------------------------------. def make_data(val):. val = str(val). filepath = '/tmp/file_{}.root'.format(val). df=ROOT.RDataFrame(2). df=df.Define('a', val). df.Snapshot('tree', filepath). return filepath. #------------------------------------------. def get_df(l_tp_file, treename, id_column='index'):. l_index = []. for index, filepath in l_tp_file:. df=ROOT.RDataFrame(treename, filepath). nentries = df.Count().GetValue(). l_index += nentries * [index]. arr_id = numpy.array(l_index). idfilepath = '/tmp/file_id.root'. df_id = ROOT.RDF.MakeNumpyDataFrame({id_column: arr_id}). df_id.Snapshot(treename, idfilepath). ch_data = ROOT.TChain(treename, '') . for _, filepath in l_tp_file:. ch_data.Add(filepath). size_ch = ch_data.GetEntries(). size_id = arr_id.size. if siz",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1231,integrability,event,event,1231,"e file. > . > > what if we have 3 trees in the brach and we need a branch index whose value is 1 for the first tree 2 for the second and 3 for the third. How would we do that with Define? > . > Is it not possible to store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. It is possible to do that. However those trees do not have those indexes and in order to add them we would need to rerun hundreds of jobs in the grid. We do need to postprocess these ntuples anyway, so the idea is to slip in a small function to add this index. . > . > * calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. It is dangerous and requires adding too many lines of code. > * store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. However the name of the file identifies it, so we deduce the index with the filename. The rest of the solution is close to what I did below. . > * do a pass on each input tree to calculate whatever other quantities you need to calculate (le",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1799,integrability,event,event,1799," in a small function to add this index. . > . > * calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. It is dangerous and requires adding too many lines of code. > * store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. However the name of the file identifies it, so we deduce the index with the filename. The rest of the solution is close to what I did below. . > * do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). OK, that is closer to what we need, I managed to get the code below to add these indexes in a slightly different way from what you said (or maybe the same if I misunderstood you), i.e. using chains and friend trees:. ```python. import ROOT. import numpy. #------------------------------------------. def make",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1805,integrability,depend,depending,1805,"all function to add this index. . > . > * calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. It is dangerous and requires adding too many lines of code. > * store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. However the name of the file identifies it, so we deduce the index with the filename. The rest of the solution is close to what I did below. . > * do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). OK, that is closer to what we need, I managed to get the code below to add these indexes in a slightly different way from what you said (or maybe the same if I misunderstood you), i.e. using chains and friend trees:. ```python. import ROOT. import numpy. #------------------------------------------. def make_data(va",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2862,interoperability,format,format,2862,"nfo at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. However the name of the file identifies it, so we deduce the index with the filename. The rest of the solution is close to what I did below. . > * do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). OK, that is closer to what we need, I managed to get the code below to add these indexes in a slightly different way from what you said (or maybe the same if I misunderstood you), i.e. using chains and friend trees:. ```python. import ROOT. import numpy. #------------------------------------------. def make_data(val):. val = str(val). filepath = '/tmp/file_{}.root'.format(val). df=ROOT.RDataFrame(2). df=df.Define('a', val). df.Snapshot('tree', filepath). return filepath. #------------------------------------------. def get_df(l_tp_file, treename, id_column='index'):. l_index = []. for index, filepath in l_tp_file:. df=ROOT.RDataFrame(treename, filepath). nentries = df.Count().GetValue(). l_index += nentries * [index]. arr_id = numpy.array(l_index). idfilepath = '/tmp/file_id.root'. df_id = ROOT.RDF.MakeNumpyDataFrame({id_column: arr_id}). df_id.Snapshot(treename, idfilepath). ch_data = ROOT.TChain(treename, '') . for _, filepath in l_tp_file:. ch_data.Add(filepath). size_ch = ch_data.GetEntries(). size_id = arr_id.size. if size_ch != size_id:. print('Different id and chain sizes: {}/{}'.format(size_id, size_ch)). raise. ch_data.AddFriend(treename, idfilepath). df = ROOT.RDataFrame(ch_data). return (df, ch_data). #------------------------------------------. def test():. #----------------------. #Make input. #----------------------. index = 0 . l_tp_f",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:3598,interoperability,format,format,3598,"erent way from what you said (or maybe the same if I misunderstood you), i.e. using chains and friend trees:. ```python. import ROOT. import numpy. #------------------------------------------. def make_data(val):. val = str(val). filepath = '/tmp/file_{}.root'.format(val). df=ROOT.RDataFrame(2). df=df.Define('a', val). df.Snapshot('tree', filepath). return filepath. #------------------------------------------. def get_df(l_tp_file, treename, id_column='index'):. l_index = []. for index, filepath in l_tp_file:. df=ROOT.RDataFrame(treename, filepath). nentries = df.Count().GetValue(). l_index += nentries * [index]. arr_id = numpy.array(l_index). idfilepath = '/tmp/file_id.root'. df_id = ROOT.RDF.MakeNumpyDataFrame({id_column: arr_id}). df_id.Snapshot(treename, idfilepath). ch_data = ROOT.TChain(treename, '') . for _, filepath in l_tp_file:. ch_data.Add(filepath). size_ch = ch_data.GetEntries(). size_id = arr_id.size. if size_ch != size_id:. print('Different id and chain sizes: {}/{}'.format(size_id, size_ch)). raise. ch_data.AddFriend(treename, idfilepath). df = ROOT.RDataFrame(ch_data). return (df, ch_data). #------------------------------------------. def test():. #----------------------. #Make input. #----------------------. index = 0 . l_tp_file = [] . for val in range(0, 100, 10):. filepath = make_data(val). l_tp_file.append((index, filepath)). index+=1. #----------------------. #Merge. #----------------------. df, _ = get_df(l_tp_file, 'tree', id_column='id'). df.Display(['a', 'id'], -1).Print(). #df.Snapshot('tree', 'file.root'). #------------------------------------------. test(). ```. I will add `get_df` to my personal library. The approach seems safe and clean enough, however the return value needs to include the chain (i.e. _) because otherwise I get a crash. Which seems to indicate that the chain's reference is not kept inside the dataframe. So once the function returns, the chain is removed by the garbage collector and the dataframe does not have anything",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1805,modifiability,depend,depending,1805,"all function to add this index. . > . > * calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. It is dangerous and requires adding too many lines of code. > * store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. However the name of the file identifies it, so we deduce the index with the filename. The rest of the solution is close to what I did below. . > * do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). OK, that is closer to what we need, I managed to get the code below to add these indexes in a slightly different way from what you said (or maybe the same if I misunderstood you), i.e. using chains and friend trees:. ```python. import ROOT. import numpy. #------------------------------------------. def make_data(va",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1116,performance,time,timestamp,1116,"TChain for post-processing. These trees are produced from jobs in the grid, it is not possible to produce a single file. > . > > what if we have 3 trees in the brach and we need a branch index whose value is 1 for the first tree 2 for the second and 3 for the third. How would we do that with Define? > . > Is it not possible to store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. It is possible to do that. However those trees do not have those indexes and in order to add them we would need to rerun hundreds of jobs in the grid. We do need to postprocess these ntuples anyway, so the idea is to slip in a small function to add this index. . > . > * calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. It is dangerous and requires adding too many lines of code. > * store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. However the name of the file identifies it, so we deduce the index with the filename. The rest of the solution is close to what",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1317,performance,disk,disk,1317," value is 1 for the first tree 2 for the second and 3 for the third. How would we do that with Define? > . > Is it not possible to store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. It is possible to do that. However those trees do not have those indexes and in order to add them we would need to rerun hundreds of jobs in the grid. We do need to postprocess these ntuples anyway, so the idea is to slip in a small function to add this index. . > . > * calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. It is dangerous and requires adding too many lines of code. > * store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. However the name of the file identifies it, so we deduce the index with the filename. The rest of the solution is close to what I did below. . > * do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original tre",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:798,reliability,sli,slip,798,"Hi,. > Hi, assuming that simply producing a single tree to begin with is impossible, I would also recommend to go with a TChain for post-processing. These trees are produced from jobs in the grid, it is not possible to produce a single file. > . > > what if we have 3 trees in the brach and we need a branch index whose value is 1 for the first tree 2 for the second and 3 for the third. How would we do that with Define? > . > Is it not possible to store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. It is possible to do that. However those trees do not have those indexes and in order to add them we would need to rerun hundreds of jobs in the grid. We do need to postprocess these ntuples anyway, so the idea is to slip in a small function to add this index. . > . > * calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. It is dangerous and requires adding too many lines of code. > * store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. Howeve",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2588,reliability,sli,slightly,2588,"Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. However the name of the file identifies it, so we deduce the index with the filename. The rest of the solution is close to what I did below. . > * do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). OK, that is closer to what we need, I managed to get the code below to add these indexes in a slightly different way from what you said (or maybe the same if I misunderstood you), i.e. using chains and friend trees:. ```python. import ROOT. import numpy. #------------------------------------------. def make_data(val):. val = str(val). filepath = '/tmp/file_{}.root'.format(val). df=ROOT.RDataFrame(2). df=df.Define('a', val). df.Snapshot('tree', filepath). return filepath. #------------------------------------------. def get_df(l_tp_file, treename, id_column='index'):. l_index = []. for index, filepath in l_tp_file:. df=ROOT.RDataFrame(treename, filepath). nentries = df.Count().GetValue(). l_index += nentries * [index]. arr_id = numpy.array(l_index). idfilepath = '/tmp/file_id.root'. df_id = ROOT.RDF.MakeNumpyDataFrame({id_column: arr_id}). df_id.Snapshot(treename, idfilepath). ch_data = ROOT.TChain(treename, '') . for _, filepath in l_tp_file:. ch_data.Add(filepath). size_ch = ch_data.GetEntries(). size_id = arr_id.size. if size_ch != size_id:. print('Different id and chain sizes: {",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:4579,reliability,doe,does,4579,"in sizes: {}/{}'.format(size_id, size_ch)). raise. ch_data.AddFriend(treename, idfilepath). df = ROOT.RDataFrame(ch_data). return (df, ch_data). #------------------------------------------. def test():. #----------------------. #Make input. #----------------------. index = 0 . l_tp_file = [] . for val in range(0, 100, 10):. filepath = make_data(val). l_tp_file.append((index, filepath)). index+=1. #----------------------. #Merge. #----------------------. df, _ = get_df(l_tp_file, 'tree', id_column='id'). df.Display(['a', 'id'], -1).Print(). #df.Snapshot('tree', 'file.root'). #------------------------------------------. test(). ```. I will add `get_df` to my personal library. The approach seems safe and clean enough, however the return value needs to include the chain (i.e. _) because otherwise I get a crash. Which seems to indicate that the chain's reference is not kept inside the dataframe. So once the function returns, the chain is removed by the garbage collector and the dataframe does not have anything to save (the script above is self contained and you can try it yourself). That should not be right, if I tell the dataframe to use the chain, the chain should be kept alive by the dataframe. > . > The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. > . > ```c++. > df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). > ```. > . > where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge this feature in master today or tomorrow. So we would have to create a `GetIndex` function to extract from the ""filename/treename"" the index? Yes, that would make my code far simpler. However it might take months until that is available through CVMFS. In any case, the simpler our code gets, the better,",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:5505,reliability,availab,available,5505," ch_data.AddFriend(treename, idfilepath). df = ROOT.RDataFrame(ch_data). return (df, ch_data). #------------------------------------------. def test():. #----------------------. #Make input. #----------------------. index = 0 . l_tp_file = [] . for val in range(0, 100, 10):. filepath = make_data(val). l_tp_file.append((index, filepath)). index+=1. #----------------------. #Merge. #----------------------. df, _ = get_df(l_tp_file, 'tree', id_column='id'). df.Display(['a', 'id'], -1).Print(). #df.Snapshot('tree', 'file.root'). #------------------------------------------. test(). ```. I will add `get_df` to my personal library. The approach seems safe and clean enough, however the return value needs to include the chain (i.e. _) because otherwise I get a crash. Which seems to indicate that the chain's reference is not kept inside the dataframe. So once the function returns, the chain is removed by the garbage collector and the dataframe does not have anything to save (the script above is self contained and you can try it yourself). That should not be right, if I tell the dataframe to use the chain, the chain should be kept alive by the dataframe. > . > The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. > . > ```c++. > df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). > ```. > . > where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge this feature in master today or tomorrow. So we would have to create a `GetIndex` function to extract from the ""filename/treename"" the index? Yes, that would make my code far simpler. However it might take months until that is available through CVMFS. In any case, the simpler our code gets, the better, fewer places for bugs to hide. Cheers and thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1805,safety,depend,depending,1805,"all function to add this index. . > . > * calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. It is dangerous and requires adding too many lines of code. > * store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. However the name of the file identifies it, so we deduce the index with the filename. The rest of the solution is close to what I did below. . > * do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). OK, that is closer to what we need, I managed to get the code below to add these indexes in a slightly different way from what you said (or maybe the same if I misunderstood you), i.e. using chains and friend trees:. ```python. import ROOT. import numpy. #------------------------------------------. def make_data(va",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2159,safety,input,input,2159," you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. However the name of the file identifies it, so we deduce the index with the filename. The rest of the solution is close to what I did below. . > * do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). OK, that is closer to what we need, I managed to get the code below to add these indexes in a slightly different way from what you said (or maybe the same if I misunderstood you), i.e. using chains and friend trees:. ```python. import ROOT. import numpy. #------------------------------------------. def make_data(val):. val = str(val). filepath = '/tmp/file_{}.root'.format(val). df=ROOT.RDataFrame(2). df=df.Define('a', val). df.Snapshot('tree', filepath). return filepath. #------------------------------------------. def get_df(l_tp_file, treename, id_column='index'):. l_index = []. for index, filepath in l_tp_file:. df=ROOT.RDataFrame(treename, filepath). nentr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2532,safety,manag,managed,2532," tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. However the name of the file identifies it, so we deduce the index with the filename. The rest of the solution is close to what I did below. . > * do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). OK, that is closer to what we need, I managed to get the code below to add these indexes in a slightly different way from what you said (or maybe the same if I misunderstood you), i.e. using chains and friend trees:. ```python. import ROOT. import numpy. #------------------------------------------. def make_data(val):. val = str(val). filepath = '/tmp/file_{}.root'.format(val). df=ROOT.RDataFrame(2). df=df.Define('a', val). df.Snapshot('tree', filepath). return filepath. #------------------------------------------. def get_df(l_tp_file, treename, id_column='index'):. l_index = []. for index, filepath in l_tp_file:. df=ROOT.RDataFrame(treename, filepath). nentries = df.Count().GetValue(). l_index += nentries * [index]. arr_id = numpy.array(l_index). idfilepath = '/tmp/file_id.root'. df_id = ROOT.RDF.MakeNumpyDataFrame({id_column: arr_id}). df_id.Snapshot(treename, idfilepath). ch_data = ROOT.TChain(treename, '') . for _, filepath in l_tp_file:. ch_data.Add(filepath). size_ch = ch_data.GetEntries(). size_id = arr_id.size. if siz",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:3775,safety,test,test,3775,"---------------. def make_data(val):. val = str(val). filepath = '/tmp/file_{}.root'.format(val). df=ROOT.RDataFrame(2). df=df.Define('a', val). df.Snapshot('tree', filepath). return filepath. #------------------------------------------. def get_df(l_tp_file, treename, id_column='index'):. l_index = []. for index, filepath in l_tp_file:. df=ROOT.RDataFrame(treename, filepath). nentries = df.Count().GetValue(). l_index += nentries * [index]. arr_id = numpy.array(l_index). idfilepath = '/tmp/file_id.root'. df_id = ROOT.RDF.MakeNumpyDataFrame({id_column: arr_id}). df_id.Snapshot(treename, idfilepath). ch_data = ROOT.TChain(treename, '') . for _, filepath in l_tp_file:. ch_data.Add(filepath). size_ch = ch_data.GetEntries(). size_id = arr_id.size. if size_ch != size_id:. print('Different id and chain sizes: {}/{}'.format(size_id, size_ch)). raise. ch_data.AddFriend(treename, idfilepath). df = ROOT.RDataFrame(ch_data). return (df, ch_data). #------------------------------------------. def test():. #----------------------. #Make input. #----------------------. index = 0 . l_tp_file = [] . for val in range(0, 100, 10):. filepath = make_data(val). l_tp_file.append((index, filepath)). index+=1. #----------------------. #Merge. #----------------------. df, _ = get_df(l_tp_file, 'tree', id_column='id'). df.Display(['a', 'id'], -1).Print(). #df.Snapshot('tree', 'file.root'). #------------------------------------------. test(). ```. I will add `get_df` to my personal library. The approach seems safe and clean enough, however the return value needs to include the chain (i.e. _) because otherwise I get a crash. Which seems to indicate that the chain's reference is not kept inside the dataframe. So once the function returns, the chain is removed by the garbage collector and the dataframe does not have anything to save (the script above is self contained and you can try it yourself). That should not be right, if I tell the dataframe to use the chain, the chain should be kept alive by",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:3815,safety,input,input,3815," = str(val). filepath = '/tmp/file_{}.root'.format(val). df=ROOT.RDataFrame(2). df=df.Define('a', val). df.Snapshot('tree', filepath). return filepath. #------------------------------------------. def get_df(l_tp_file, treename, id_column='index'):. l_index = []. for index, filepath in l_tp_file:. df=ROOT.RDataFrame(treename, filepath). nentries = df.Count().GetValue(). l_index += nentries * [index]. arr_id = numpy.array(l_index). idfilepath = '/tmp/file_id.root'. df_id = ROOT.RDF.MakeNumpyDataFrame({id_column: arr_id}). df_id.Snapshot(treename, idfilepath). ch_data = ROOT.TChain(treename, '') . for _, filepath in l_tp_file:. ch_data.Add(filepath). size_ch = ch_data.GetEntries(). size_id = arr_id.size. if size_ch != size_id:. print('Different id and chain sizes: {}/{}'.format(size_id, size_ch)). raise. ch_data.AddFriend(treename, idfilepath). df = ROOT.RDataFrame(ch_data). return (df, ch_data). #------------------------------------------. def test():. #----------------------. #Make input. #----------------------. index = 0 . l_tp_file = [] . for val in range(0, 100, 10):. filepath = make_data(val). l_tp_file.append((index, filepath)). index+=1. #----------------------. #Merge. #----------------------. df, _ = get_df(l_tp_file, 'tree', id_column='id'). df.Display(['a', 'id'], -1).Print(). #df.Snapshot('tree', 'file.root'). #------------------------------------------. test(). ```. I will add `get_df` to my personal library. The approach seems safe and clean enough, however the return value needs to include the chain (i.e. _) because otherwise I get a crash. Which seems to indicate that the chain's reference is not kept inside the dataframe. So once the function returns, the chain is removed by the garbage collector and the dataframe does not have anything to save (the script above is self contained and you can try it yourself). That should not be right, if I tell the dataframe to use the chain, the chain should be kept alive by the dataframe. > . > The simplest soluti",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:4207,safety,test,test,4207,"s * [index]. arr_id = numpy.array(l_index). idfilepath = '/tmp/file_id.root'. df_id = ROOT.RDF.MakeNumpyDataFrame({id_column: arr_id}). df_id.Snapshot(treename, idfilepath). ch_data = ROOT.TChain(treename, '') . for _, filepath in l_tp_file:. ch_data.Add(filepath). size_ch = ch_data.GetEntries(). size_id = arr_id.size. if size_ch != size_id:. print('Different id and chain sizes: {}/{}'.format(size_id, size_ch)). raise. ch_data.AddFriend(treename, idfilepath). df = ROOT.RDataFrame(ch_data). return (df, ch_data). #------------------------------------------. def test():. #----------------------. #Make input. #----------------------. index = 0 . l_tp_file = [] . for val in range(0, 100, 10):. filepath = make_data(val). l_tp_file.append((index, filepath)). index+=1. #----------------------. #Merge. #----------------------. df, _ = get_df(l_tp_file, 'tree', id_column='id'). df.Display(['a', 'id'], -1).Print(). #df.Snapshot('tree', 'file.root'). #------------------------------------------. test(). ```. I will add `get_df` to my personal library. The approach seems safe and clean enough, however the return value needs to include the chain (i.e. _) because otherwise I get a crash. Which seems to indicate that the chain's reference is not kept inside the dataframe. So once the function returns, the chain is removed by the garbage collector and the dataframe does not have anything to save (the script above is self contained and you can try it yourself). That should not be right, if I tell the dataframe to use the chain, the chain should be kept alive by the dataframe. > . > The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. > . > ```c++. > df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). > ```. > . > where `rdfsampleinfo_.AsStri",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:4283,safety,safe,safe,4283,". df_id = ROOT.RDF.MakeNumpyDataFrame({id_column: arr_id}). df_id.Snapshot(treename, idfilepath). ch_data = ROOT.TChain(treename, '') . for _, filepath in l_tp_file:. ch_data.Add(filepath). size_ch = ch_data.GetEntries(). size_id = arr_id.size. if size_ch != size_id:. print('Different id and chain sizes: {}/{}'.format(size_id, size_ch)). raise. ch_data.AddFriend(treename, idfilepath). df = ROOT.RDataFrame(ch_data). return (df, ch_data). #------------------------------------------. def test():. #----------------------. #Make input. #----------------------. index = 0 . l_tp_file = [] . for val in range(0, 100, 10):. filepath = make_data(val). l_tp_file.append((index, filepath)). index+=1. #----------------------. #Merge. #----------------------. df, _ = get_df(l_tp_file, 'tree', id_column='id'). df.Display(['a', 'id'], -1).Print(). #df.Snapshot('tree', 'file.root'). #------------------------------------------. test(). ```. I will add `get_df` to my personal library. The approach seems safe and clean enough, however the return value needs to include the chain (i.e. _) because otherwise I get a crash. Which seems to indicate that the chain's reference is not kept inside the dataframe. So once the function returns, the chain is removed by the garbage collector and the dataframe does not have anything to save (the script above is self contained and you can try it yourself). That should not be right, if I tell the dataframe to use the chain, the chain should be kept alive by the dataframe. > . > The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. > . > ```c++. > df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). > ```. > . > where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge this fe",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:5505,safety,avail,available,5505," ch_data.AddFriend(treename, idfilepath). df = ROOT.RDataFrame(ch_data). return (df, ch_data). #------------------------------------------. def test():. #----------------------. #Make input. #----------------------. index = 0 . l_tp_file = [] . for val in range(0, 100, 10):. filepath = make_data(val). l_tp_file.append((index, filepath)). index+=1. #----------------------. #Merge. #----------------------. df, _ = get_df(l_tp_file, 'tree', id_column='id'). df.Display(['a', 'id'], -1).Print(). #df.Snapshot('tree', 'file.root'). #------------------------------------------. test(). ```. I will add `get_df` to my personal library. The approach seems safe and clean enough, however the return value needs to include the chain (i.e. _) because otherwise I get a crash. Which seems to indicate that the chain's reference is not kept inside the dataframe. So once the function returns, the chain is removed by the garbage collector and the dataframe does not have anything to save (the script above is self contained and you can try it yourself). That should not be right, if I tell the dataframe to use the chain, the chain should be kept alive by the dataframe. > . > The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. > . > ```c++. > df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). > ```. > . > where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge this feature in master today or tomorrow. So we would have to create a `GetIndex` function to extract from the ""filename/treename"" the index? Yes, that would make my code far simpler. However it might take months until that is available through CVMFS. In any case, the simpler our code gets, the better, fewer places for bugs to hide. Cheers and thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1065,security,ident,identifier,1065,"is impossible, I would also recommend to go with a TChain for post-processing. These trees are produced from jobs in the grid, it is not possible to produce a single file. > . > > what if we have 3 trees in the brach and we need a branch index whose value is 1 for the first tree 2 for the second and 3 for the third. How would we do that with Define? > . > Is it not possible to store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. It is possible to do that. However those trees do not have those indexes and in order to add them we would need to rerun hundreds of jobs in the grid. We do need to postprocess these ntuples anyway, so the idea is to slip in a small function to add this index. . > . > * calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. It is dangerous and requires adding too many lines of code. > * store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. However the name of the file identifies it, so we deduce the index with the ",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1341,security,ident,identifier,1341,"ree 2 for the second and 3 for the third. How would we do that with Define? > . > Is it not possible to store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. It is possible to do that. However those trees do not have those indexes and in order to add them we would need to rerun hundreds of jobs in the grid. We do need to postprocess these ntuples anyway, so the idea is to slip in a small function to add this index. . > . > * calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. It is dangerous and requires adding too many lines of code. > * store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. However the name of the file identifies it, so we deduce the index with the filename. The rest of the solution is close to what I did below. . > * do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of t",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2023,security,ident,identifies,2023,"lines of code. > * store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. However the name of the file identifies it, so we deduce the index with the filename. The rest of the solution is close to what I did below. . > * do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). OK, that is closer to what we need, I managed to get the code below to add these indexes in a slightly different way from what you said (or maybe the same if I misunderstood you), i.e. using chains and friend trees:. ```python. import ROOT. import numpy. #------------------------------------------. def make_data(val):. val = str(val). filepath = '/tmp/file_{}.root'.format(val). df=ROOT.RDataFrame(2). df=df.Define('a', val). df.Snapshot('tree', filepath). return filepath. #------------------------------------------. def get_df(l_",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:5505,security,availab,available,5505," ch_data.AddFriend(treename, idfilepath). df = ROOT.RDataFrame(ch_data). return (df, ch_data). #------------------------------------------. def test():. #----------------------. #Make input. #----------------------. index = 0 . l_tp_file = [] . for val in range(0, 100, 10):. filepath = make_data(val). l_tp_file.append((index, filepath)). index+=1. #----------------------. #Merge. #----------------------. df, _ = get_df(l_tp_file, 'tree', id_column='id'). df.Display(['a', 'id'], -1).Print(). #df.Snapshot('tree', 'file.root'). #------------------------------------------. test(). ```. I will add `get_df` to my personal library. The approach seems safe and clean enough, however the return value needs to include the chain (i.e. _) because otherwise I get a crash. Which seems to indicate that the chain's reference is not kept inside the dataframe. So once the function returns, the chain is removed by the garbage collector and the dataframe does not have anything to save (the script above is self contained and you can try it yourself). That should not be right, if I tell the dataframe to use the chain, the chain should be kept alive by the dataframe. > . > The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. > . > ```c++. > df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). > ```. > . > where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge this feature in master today or tomorrow. So we would have to create a `GetIndex` function to extract from the ""filename/treename"" the index? Yes, that would make my code far simpler. However it might take months until that is available through CVMFS. In any case, the simpler our code gets, the better, fewer places for bugs to hide. Cheers and thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:25,testability,simpl,simply,25,"Hi,. > Hi, assuming that simply producing a single tree to begin with is impossible, I would also recommend to go with a TChain for post-processing. These trees are produced from jobs in the grid, it is not possible to produce a single file. > . > > what if we have 3 trees in the brach and we need a branch index whose value is 1 for the first tree 2 for the second and 3 for the third. How would we do that with Define? > . > Is it not possible to store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. It is possible to do that. However those trees do not have those indexes and in order to add them we would need to rerun hundreds of jobs in the grid. We do need to postprocess these ntuples anyway, so the idea is to slip in a small function to add this index. . > . > * calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. It is dangerous and requires adding too many lines of code. > * store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. Howeve",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:1805,testability,depend,depending,1805,"all function to add this index. . > . > * calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. It is dangerous and requires adding too many lines of code. > * store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. However the name of the file identifies it, so we deduce the index with the filename. The rest of the solution is close to what I did below. . > * do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). OK, that is closer to what we need, I managed to get the code below to add these indexes in a slightly different way from what you said (or maybe the same if I misunderstood you), i.e. using chains and friend trees:. ```python. import ROOT. import numpy. #------------------------------------------. def make_data(va",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:3775,testability,test,test,3775,"---------------. def make_data(val):. val = str(val). filepath = '/tmp/file_{}.root'.format(val). df=ROOT.RDataFrame(2). df=df.Define('a', val). df.Snapshot('tree', filepath). return filepath. #------------------------------------------. def get_df(l_tp_file, treename, id_column='index'):. l_index = []. for index, filepath in l_tp_file:. df=ROOT.RDataFrame(treename, filepath). nentries = df.Count().GetValue(). l_index += nentries * [index]. arr_id = numpy.array(l_index). idfilepath = '/tmp/file_id.root'. df_id = ROOT.RDF.MakeNumpyDataFrame({id_column: arr_id}). df_id.Snapshot(treename, idfilepath). ch_data = ROOT.TChain(treename, '') . for _, filepath in l_tp_file:. ch_data.Add(filepath). size_ch = ch_data.GetEntries(). size_id = arr_id.size. if size_ch != size_id:. print('Different id and chain sizes: {}/{}'.format(size_id, size_ch)). raise. ch_data.AddFriend(treename, idfilepath). df = ROOT.RDataFrame(ch_data). return (df, ch_data). #------------------------------------------. def test():. #----------------------. #Make input. #----------------------. index = 0 . l_tp_file = [] . for val in range(0, 100, 10):. filepath = make_data(val). l_tp_file.append((index, filepath)). index+=1. #----------------------. #Merge. #----------------------. df, _ = get_df(l_tp_file, 'tree', id_column='id'). df.Display(['a', 'id'], -1).Print(). #df.Snapshot('tree', 'file.root'). #------------------------------------------. test(). ```. I will add `get_df` to my personal library. The approach seems safe and clean enough, however the return value needs to include the chain (i.e. _) because otherwise I get a crash. Which seems to indicate that the chain's reference is not kept inside the dataframe. So once the function returns, the chain is removed by the garbage collector and the dataframe does not have anything to save (the script above is self contained and you can try it yourself). That should not be right, if I tell the dataframe to use the chain, the chain should be kept alive by",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:4207,testability,test,test,4207,"s * [index]. arr_id = numpy.array(l_index). idfilepath = '/tmp/file_id.root'. df_id = ROOT.RDF.MakeNumpyDataFrame({id_column: arr_id}). df_id.Snapshot(treename, idfilepath). ch_data = ROOT.TChain(treename, '') . for _, filepath in l_tp_file:. ch_data.Add(filepath). size_ch = ch_data.GetEntries(). size_id = arr_id.size. if size_ch != size_id:. print('Different id and chain sizes: {}/{}'.format(size_id, size_ch)). raise. ch_data.AddFriend(treename, idfilepath). df = ROOT.RDataFrame(ch_data). return (df, ch_data). #------------------------------------------. def test():. #----------------------. #Make input. #----------------------. index = 0 . l_tp_file = [] . for val in range(0, 100, 10):. filepath = make_data(val). l_tp_file.append((index, filepath)). index+=1. #----------------------. #Merge. #----------------------. df, _ = get_df(l_tp_file, 'tree', id_column='id'). df.Display(['a', 'id'], -1).Print(). #df.Snapshot('tree', 'file.root'). #------------------------------------------. test(). ```. I will add `get_df` to my personal library. The approach seems safe and clean enough, however the return value needs to include the chain (i.e. _) because otherwise I get a crash. Which seems to indicate that the chain's reference is not kept inside the dataframe. So once the function returns, the chain is removed by the garbage collector and the dataframe does not have anything to save (the script above is self contained and you can try it yourself). That should not be right, if I tell the dataframe to use the chain, the chain should be kept alive by the dataframe. > . > The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. > . > ```c++. > df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). > ```. > . > where `rdfsampleinfo_.AsStri",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:4803,testability,simpl,simplest,4803," ch_data.AddFriend(treename, idfilepath). df = ROOT.RDataFrame(ch_data). return (df, ch_data). #------------------------------------------. def test():. #----------------------. #Make input. #----------------------. index = 0 . l_tp_file = [] . for val in range(0, 100, 10):. filepath = make_data(val). l_tp_file.append((index, filepath)). index+=1. #----------------------. #Merge. #----------------------. df, _ = get_df(l_tp_file, 'tree', id_column='id'). df.Display(['a', 'id'], -1).Print(). #df.Snapshot('tree', 'file.root'). #------------------------------------------. test(). ```. I will add `get_df` to my personal library. The approach seems safe and clean enough, however the return value needs to include the chain (i.e. _) because otherwise I get a crash. Which seems to indicate that the chain's reference is not kept inside the dataframe. So once the function returns, the chain is removed by the garbage collector and the dataframe does not have anything to save (the script above is self contained and you can try it yourself). That should not be right, if I tell the dataframe to use the chain, the chain should be kept alive by the dataframe. > . > The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. > . > ```c++. > df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). > ```. > . > where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge this feature in master today or tomorrow. So we would have to create a `GetIndex` function to extract from the ""filename/treename"" the index? Yes, that would make my code far simpler. However it might take months until that is available through CVMFS. In any case, the simpler our code gets, the better, fewer places for bugs to hide. Cheers and thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:5453,testability,simpl,simpler,5453," ch_data.AddFriend(treename, idfilepath). df = ROOT.RDataFrame(ch_data). return (df, ch_data). #------------------------------------------. def test():. #----------------------. #Make input. #----------------------. index = 0 . l_tp_file = [] . for val in range(0, 100, 10):. filepath = make_data(val). l_tp_file.append((index, filepath)). index+=1. #----------------------. #Merge. #----------------------. df, _ = get_df(l_tp_file, 'tree', id_column='id'). df.Display(['a', 'id'], -1).Print(). #df.Snapshot('tree', 'file.root'). #------------------------------------------. test(). ```. I will add `get_df` to my personal library. The approach seems safe and clean enough, however the return value needs to include the chain (i.e. _) because otherwise I get a crash. Which seems to indicate that the chain's reference is not kept inside the dataframe. So once the function returns, the chain is removed by the garbage collector and the dataframe does not have anything to save (the script above is self contained and you can try it yourself). That should not be right, if I tell the dataframe to use the chain, the chain should be kept alive by the dataframe. > . > The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. > . > ```c++. > df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). > ```. > . > where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge this feature in master today or tomorrow. So we would have to create a `GetIndex` function to extract from the ""filename/treename"" the index? Yes, that would make my code far simpler. However it might take months until that is available through CVMFS. In any case, the simpler our code gets, the better, fewer places for bugs to hide. Cheers and thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:5547,testability,simpl,simpler,5547," ch_data.AddFriend(treename, idfilepath). df = ROOT.RDataFrame(ch_data). return (df, ch_data). #------------------------------------------. def test():. #----------------------. #Make input. #----------------------. index = 0 . l_tp_file = [] . for val in range(0, 100, 10):. filepath = make_data(val). l_tp_file.append((index, filepath)). index+=1. #----------------------. #Merge. #----------------------. df, _ = get_df(l_tp_file, 'tree', id_column='id'). df.Display(['a', 'id'], -1).Print(). #df.Snapshot('tree', 'file.root'). #------------------------------------------. test(). ```. I will add `get_df` to my personal library. The approach seems safe and clean enough, however the return value needs to include the chain (i.e. _) because otherwise I get a crash. Which seems to indicate that the chain's reference is not kept inside the dataframe. So once the function returns, the chain is removed by the garbage collector and the dataframe does not have anything to save (the script above is self contained and you can try it yourself). That should not be right, if I tell the dataframe to use the chain, the chain should be kept alive by the dataframe. > . > The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. > . > ```c++. > df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). > ```. > . > where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge this feature in master today or tomorrow. So we would have to create a `GetIndex` function to extract from the ""filename/treename"" the index? Yes, that would make my code far simpler. However it might take months until that is available through CVMFS. In any case, the simpler our code gets, the better, fewer places for bugs to hide. Cheers and thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:25,usability,simpl,simply,25,"Hi,. > Hi, assuming that simply producing a single tree to begin with is impossible, I would also recommend to go with a TChain for post-processing. These trees are produced from jobs in the grid, it is not possible to produce a single file. > . > > what if we have 3 trees in the brach and we need a branch index whose value is 1 for the first tree 2 for the second and 3 for the third. How would we do that with Define? > . > Is it not possible to store these indexes in the trees when they are produced? If not, currently you have three possible solutions that I can think of:. It is possible to do that. However those trees do not have those indexes and in order to add them we would need to rerun hundreds of jobs in the grid. We do need to postprocess these ntuples anyway, so the idea is to slip in a small function to add this index. . > . > * calculate the index from the value of `rdfentry_`, knowing how many entries are in each tree and their ordering inside the TChain. It is dangerous and requires adding too many lines of code. > * store some unique identifier in each tree when it's produced (even a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. Howeve",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2108,usability,close,close,2108,"en a timestamp works, and although it's not elegant you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. However the name of the file identifies it, so we deduce the index with the filename. The rest of the solution is close to what I did below. . > * do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). OK, that is closer to what we need, I managed to get the code below to add these indexes in a slightly different way from what you said (or maybe the same if I misunderstood you), i.e. using chains and friend trees:. ```python. import ROOT. import numpy. #------------------------------------------. def make_data(val):. val = str(val). filepath = '/tmp/file_{}.root'.format(val). df=ROOT.RDataFrame(2). df=df.Define('a', val). df.Snapshot('tree', filepath). return filepath. #------------------------------------------. def get_df(l_tp_file, treename, id_column='index'):. l_index = []. for index, filepath in l_tp_f",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2159,usability,input,input,2159," you don't have to worry about having that same value stored in each event because it will compress almost perfectly, occupying very little extra space on disk). With that unique identifier per tree you can build another tree that serves as a lookup table between id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. However the name of the file identifies it, so we deduce the index with the filename. The rest of the solution is close to what I did below. . > * do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). OK, that is closer to what we need, I managed to get the code below to add these indexes in a slightly different way from what you said (or maybe the same if I misunderstood you), i.e. using chains and friend trees:. ```python. import ROOT. import numpy. #------------------------------------------. def make_data(val):. val = str(val). filepath = '/tmp/file_{}.root'.format(val). df=ROOT.RDataFrame(2). df=df.Define('a', val). df.Snapshot('tree', filepath). return filepath. #------------------------------------------. def get_df(l_tp_file, treename, id_column='index'):. l_index = []. for index, filepath in l_tp_file:. df=ROOT.RDataFrame(treename, filepath). nentr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2418,usability,effectiv,effectively,2418,"n id and index. It will have two branches, `id` and `index`, with the first taking the values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. However the name of the file identifies it, so we deduce the index with the filename. The rest of the solution is close to what I did below. . > * do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). OK, that is closer to what we need, I managed to get the code below to add these indexes in a slightly different way from what you said (or maybe the same if I misunderstood you), i.e. using chains and friend trees:. ```python. import ROOT. import numpy. #------------------------------------------. def make_data(val):. val = str(val). filepath = '/tmp/file_{}.root'.format(val). df=ROOT.RDataFrame(2). df=df.Define('a', val). df.Snapshot('tree', filepath). return filepath. #------------------------------------------. def get_df(l_tp_file, treename, id_column='index'):. l_index = []. for index, filepath in l_tp_file:. df=ROOT.RDataFrame(treename, filepath). nentries = df.Count().GetValue(). l_index += nentries * [index]. arr_id = numpy.array(l_index). idfilepath = '/tmp/file_id.root'. df_id = ROOT.RDF.MakeNumpyDataFrame({id_column: arr_id}). df_id.Snapshot(treename, idfilepath). ch_data = ROOT.TChain(treename, '') . for",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:2506,usability,close,closer,2506,"e values of the ids of each tree and the second being an index from 0 to nTrees-1. Then you can use `TTree::BuildIndex` and `TChain::AddFriend` to add that lookup table tree as a friend of the original chain and thanks to `BuildIndex` the correct value of `index` will be returned for each event depending on the value of `id` in the original chain. More info at https://root.cern/manual/trees/#indexing-trees. We would have to run again all the jobs in the grid to store a unique ID. However the name of the file identifies it, so we deduce the index with the filename. The rest of the solution is close to what I did below. . > * do a pass on each input tree to calculate whatever other quantities you need to calculate (let's call these trees `aux1`, `aux2` etc.), then make a TChain out of the original trees, another TChain out of the `aux` trees, and then add the second chain as a friend of the first (effectively creating a single large ""virtual"" TTree with everything in it). OK, that is closer to what we need, I managed to get the code below to add these indexes in a slightly different way from what you said (or maybe the same if I misunderstood you), i.e. using chains and friend trees:. ```python. import ROOT. import numpy. #------------------------------------------. def make_data(val):. val = str(val). filepath = '/tmp/file_{}.root'.format(val). df=ROOT.RDataFrame(2). df=df.Define('a', val). df.Snapshot('tree', filepath). return filepath. #------------------------------------------. def get_df(l_tp_file, treename, id_column='index'):. l_index = []. for index, filepath in l_tp_file:. df=ROOT.RDataFrame(treename, filepath). nentries = df.Count().GetValue(). l_index += nentries * [index]. arr_id = numpy.array(l_index). idfilepath = '/tmp/file_id.root'. df_id = ROOT.RDF.MakeNumpyDataFrame({id_column: arr_id}). df_id.Snapshot(treename, idfilepath). ch_data = ROOT.TChain(treename, '') . for _, filepath in l_tp_file:. ch_data.Add(filepath). size_ch = ch_data.GetEntries(). si",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:3815,usability,input,input,3815," = str(val). filepath = '/tmp/file_{}.root'.format(val). df=ROOT.RDataFrame(2). df=df.Define('a', val). df.Snapshot('tree', filepath). return filepath. #------------------------------------------. def get_df(l_tp_file, treename, id_column='index'):. l_index = []. for index, filepath in l_tp_file:. df=ROOT.RDataFrame(treename, filepath). nentries = df.Count().GetValue(). l_index += nentries * [index]. arr_id = numpy.array(l_index). idfilepath = '/tmp/file_id.root'. df_id = ROOT.RDF.MakeNumpyDataFrame({id_column: arr_id}). df_id.Snapshot(treename, idfilepath). ch_data = ROOT.TChain(treename, '') . for _, filepath in l_tp_file:. ch_data.Add(filepath). size_ch = ch_data.GetEntries(). size_id = arr_id.size. if size_ch != size_id:. print('Different id and chain sizes: {}/{}'.format(size_id, size_ch)). raise. ch_data.AddFriend(treename, idfilepath). df = ROOT.RDataFrame(ch_data). return (df, ch_data). #------------------------------------------. def test():. #----------------------. #Make input. #----------------------. index = 0 . l_tp_file = [] . for val in range(0, 100, 10):. filepath = make_data(val). l_tp_file.append((index, filepath)). index+=1. #----------------------. #Merge. #----------------------. df, _ = get_df(l_tp_file, 'tree', id_column='id'). df.Display(['a', 'id'], -1).Print(). #df.Snapshot('tree', 'file.root'). #------------------------------------------. test(). ```. I will add `get_df` to my personal library. The approach seems safe and clean enough, however the return value needs to include the chain (i.e. _) because otherwise I get a crash. Which seems to indicate that the chain's reference is not kept inside the dataframe. So once the function returns, the chain is removed by the garbage collector and the dataframe does not have anything to save (the script above is self contained and you can try it yourself). That should not be right, if I tell the dataframe to use the chain, the chain should be kept alive by the dataframe. > . > The simplest soluti",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:4246,usability,person,personal,4246,"). idfilepath = '/tmp/file_id.root'. df_id = ROOT.RDF.MakeNumpyDataFrame({id_column: arr_id}). df_id.Snapshot(treename, idfilepath). ch_data = ROOT.TChain(treename, '') . for _, filepath in l_tp_file:. ch_data.Add(filepath). size_ch = ch_data.GetEntries(). size_id = arr_id.size. if size_ch != size_id:. print('Different id and chain sizes: {}/{}'.format(size_id, size_ch)). raise. ch_data.AddFriend(treename, idfilepath). df = ROOT.RDataFrame(ch_data). return (df, ch_data). #------------------------------------------. def test():. #----------------------. #Make input. #----------------------. index = 0 . l_tp_file = [] . for val in range(0, 100, 10):. filepath = make_data(val). l_tp_file.append((index, filepath)). index+=1. #----------------------. #Merge. #----------------------. df, _ = get_df(l_tp_file, 'tree', id_column='id'). df.Display(['a', 'id'], -1).Print(). #df.Snapshot('tree', 'file.root'). #------------------------------------------. test(). ```. I will add `get_df` to my personal library. The approach seems safe and clean enough, however the return value needs to include the chain (i.e. _) because otherwise I get a crash. Which seems to indicate that the chain's reference is not kept inside the dataframe. So once the function returns, the chain is removed by the garbage collector and the dataframe does not have anything to save (the script above is self contained and you can try it yourself). That should not be right, if I tell the dataframe to use the chain, the chain should be kept alive by the dataframe. > . > The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. > . > ```c++. > df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). > ```. > . > where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<tr",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:4415,usability,indicat,indicate,4415,". for _, filepath in l_tp_file:. ch_data.Add(filepath). size_ch = ch_data.GetEntries(). size_id = arr_id.size. if size_ch != size_id:. print('Different id and chain sizes: {}/{}'.format(size_id, size_ch)). raise. ch_data.AddFriend(treename, idfilepath). df = ROOT.RDataFrame(ch_data). return (df, ch_data). #------------------------------------------. def test():. #----------------------. #Make input. #----------------------. index = 0 . l_tp_file = [] . for val in range(0, 100, 10):. filepath = make_data(val). l_tp_file.append((index, filepath)). index+=1. #----------------------. #Merge. #----------------------. df, _ = get_df(l_tp_file, 'tree', id_column='id'). df.Display(['a', 'id'], -1).Print(). #df.Snapshot('tree', 'file.root'). #------------------------------------------. test(). ```. I will add `get_df` to my personal library. The approach seems safe and clean enough, however the return value needs to include the chain (i.e. _) because otherwise I get a crash. Which seems to indicate that the chain's reference is not kept inside the dataframe. So once the function returns, the chain is removed by the garbage collector and the dataframe does not have anything to save (the script above is self contained and you can try it yourself). That should not be right, if I tell the dataframe to use the chain, the chain should be kept alive by the dataframe. > . > The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. > . > ```c++. > df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). > ```. > . > where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge this feature in master today or tomorrow. So we would have to create a `GetIndex` function to extract from the ""filename/treename"" the index?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:4803,usability,simpl,simplest,4803," ch_data.AddFriend(treename, idfilepath). df = ROOT.RDataFrame(ch_data). return (df, ch_data). #------------------------------------------. def test():. #----------------------. #Make input. #----------------------. index = 0 . l_tp_file = [] . for val in range(0, 100, 10):. filepath = make_data(val). l_tp_file.append((index, filepath)). index+=1. #----------------------. #Merge. #----------------------. df, _ = get_df(l_tp_file, 'tree', id_column='id'). df.Display(['a', 'id'], -1).Print(). #df.Snapshot('tree', 'file.root'). #------------------------------------------. test(). ```. I will add `get_df` to my personal library. The approach seems safe and clean enough, however the return value needs to include the chain (i.e. _) because otherwise I get a crash. Which seems to indicate that the chain's reference is not kept inside the dataframe. So once the function returns, the chain is removed by the garbage collector and the dataframe does not have anything to save (the script above is self contained and you can try it yourself). That should not be right, if I tell the dataframe to use the chain, the chain should be kept alive by the dataframe. > . > The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. > . > ```c++. > df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). > ```. > . > where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge this feature in master today or tomorrow. So we would have to create a `GetIndex` function to extract from the ""filename/treename"" the index? Yes, that would make my code far simpler. However it might take months until that is available through CVMFS. In any case, the simpler our code gets, the better, fewer places for bugs to hide. Cheers and thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:5453,usability,simpl,simpler,5453," ch_data.AddFriend(treename, idfilepath). df = ROOT.RDataFrame(ch_data). return (df, ch_data). #------------------------------------------. def test():. #----------------------. #Make input. #----------------------. index = 0 . l_tp_file = [] . for val in range(0, 100, 10):. filepath = make_data(val). l_tp_file.append((index, filepath)). index+=1. #----------------------. #Merge. #----------------------. df, _ = get_df(l_tp_file, 'tree', id_column='id'). df.Display(['a', 'id'], -1).Print(). #df.Snapshot('tree', 'file.root'). #------------------------------------------. test(). ```. I will add `get_df` to my personal library. The approach seems safe and clean enough, however the return value needs to include the chain (i.e. _) because otherwise I get a crash. Which seems to indicate that the chain's reference is not kept inside the dataframe. So once the function returns, the chain is removed by the garbage collector and the dataframe does not have anything to save (the script above is self contained and you can try it yourself). That should not be right, if I tell the dataframe to use the chain, the chain should be kept alive by the dataframe. > . > The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. > . > ```c++. > df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). > ```. > . > where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge this feature in master today or tomorrow. So we would have to create a `GetIndex` function to extract from the ""filename/treename"" the index? Yes, that would make my code far simpler. However it might take months until that is available through CVMFS. In any case, the simpler our code gets, the better, fewer places for bugs to hide. Cheers and thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:5547,usability,simpl,simpler,5547," ch_data.AddFriend(treename, idfilepath). df = ROOT.RDataFrame(ch_data). return (df, ch_data). #------------------------------------------. def test():. #----------------------. #Make input. #----------------------. index = 0 . l_tp_file = [] . for val in range(0, 100, 10):. filepath = make_data(val). l_tp_file.append((index, filepath)). index+=1. #----------------------. #Merge. #----------------------. df, _ = get_df(l_tp_file, 'tree', id_column='id'). df.Display(['a', 'id'], -1).Print(). #df.Snapshot('tree', 'file.root'). #------------------------------------------. test(). ```. I will add `get_df` to my personal library. The approach seems safe and clean enough, however the return value needs to include the chain (i.e. _) because otherwise I get a crash. Which seems to indicate that the chain's reference is not kept inside the dataframe. So once the function returns, the chain is removed by the garbage collector and the dataframe does not have anything to save (the script above is self contained and you can try it yourself). That should not be right, if I tell the dataframe to use the chain, the chain should be kept alive by the dataframe. > . > The simplest solution: with the upcoming `DefinePerSample` method you can solve this more easily, but the feature will only be merged in ROOT master in a few days ([PR here](https://github.com/root-project/root/pull/8841)). With `DefinePerSample` you could write something like this:. > . > ```c++. > df.DefinePerSample(""index"", ""GetIndex(rdfsampleinfo_.AsString())""). > ```. > . > where `rdfsampleinfo_.AsString()` will be of the form `<filename>/<treename>`. I expect to merge this feature in master today or tomorrow. So we would have to create a `GetIndex` function to extract from the ""filename/treename"" the index? Yes, that would make my code far simpler. However it might take months until that is available through CVMFS. In any case, the simpler our code gets, the better, fewer places for bugs to hide. Cheers and thanks.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:128,availability,avail,available,128,"> So we would have to create a GetIndex function to extract from the ""filename/treename"" the index? Exactly! The feature is now available in master and CVMFS has nightly ROOT builds: https://root.cern/install/nightlies . Unless there are further questions I'm going to close this as solved as you have a not-so-nice workaround with current ROOT versions and a better solution in master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:175,deployability,build,builds,175,"> So we would have to create a GetIndex function to extract from the ""filename/treename"" the index? Exactly! The feature is now available in master and CVMFS has nightly ROOT builds: https://root.cern/install/nightlies . Unless there are further questions I'm going to close this as solved as you have a not-so-nice workaround with current ROOT versions and a better solution in master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:201,deployability,instal,install,201,"> So we would have to create a GetIndex function to extract from the ""filename/treename"" the index? Exactly! The feature is now available in master and CVMFS has nightly ROOT builds: https://root.cern/install/nightlies . Unless there are further questions I'm going to close this as solved as you have a not-so-nice workaround with current ROOT versions and a better solution in master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:345,deployability,version,versions,345,"> So we would have to create a GetIndex function to extract from the ""filename/treename"" the index? Exactly! The feature is now available in master and CVMFS has nightly ROOT builds: https://root.cern/install/nightlies . Unless there are further questions I'm going to close this as solved as you have a not-so-nice workaround with current ROOT versions and a better solution in master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:332,energy efficiency,current,current,332,"> So we would have to create a GetIndex function to extract from the ""filename/treename"" the index? Exactly! The feature is now available in master and CVMFS has nightly ROOT builds: https://root.cern/install/nightlies . Unless there are further questions I'm going to close this as solved as you have a not-so-nice workaround with current ROOT versions and a better solution in master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:345,integrability,version,versions,345,"> So we would have to create a GetIndex function to extract from the ""filename/treename"" the index? Exactly! The feature is now available in master and CVMFS has nightly ROOT builds: https://root.cern/install/nightlies . Unless there are further questions I'm going to close this as solved as you have a not-so-nice workaround with current ROOT versions and a better solution in master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:345,modifiability,version,versions,345,"> So we would have to create a GetIndex function to extract from the ""filename/treename"" the index? Exactly! The feature is now available in master and CVMFS has nightly ROOT builds: https://root.cern/install/nightlies . Unless there are further questions I'm going to close this as solved as you have a not-so-nice workaround with current ROOT versions and a better solution in master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:128,reliability,availab,available,128,"> So we would have to create a GetIndex function to extract from the ""filename/treename"" the index? Exactly! The feature is now available in master and CVMFS has nightly ROOT builds: https://root.cern/install/nightlies . Unless there are further questions I'm going to close this as solved as you have a not-so-nice workaround with current ROOT versions and a better solution in master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:128,safety,avail,available,128,"> So we would have to create a GetIndex function to extract from the ""filename/treename"" the index? Exactly! The feature is now available in master and CVMFS has nightly ROOT builds: https://root.cern/install/nightlies . Unless there are further questions I'm going to close this as solved as you have a not-so-nice workaround with current ROOT versions and a better solution in master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:128,security,availab,available,128,"> So we would have to create a GetIndex function to extract from the ""filename/treename"" the index? Exactly! The feature is now available in master and CVMFS has nightly ROOT builds: https://root.cern/install/nightlies . Unless there are further questions I'm going to close this as solved as you have a not-so-nice workaround with current ROOT versions and a better solution in master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:269,usability,close,close,269,"> So we would have to create a GetIndex function to extract from the ""filename/treename"" the index? Exactly! The feature is now available in master and CVMFS has nightly ROOT builds: https://root.cern/install/nightlies . Unless there are further questions I'm going to close this as solved as you have a not-so-nice workaround with current ROOT versions and a better solution in master.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:56,reliability,doe,does,56,"Hi @eguiraud ,. OK, thanks for your help, that function does give us more flexibility. I closed the issue already. Cheers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:36,usability,help,help,36,"Hi @eguiraud ,. OK, thanks for your help, that function does give us more flexibility. I closed the issue already. Cheers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9030:89,usability,close,closed,89,"Hi @eguiraud ,. OK, thanks for your help, that function does give us more flexibility. I closed the issue already. Cheers.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9030
https://github.com/root-project/root/issues/9031:20,deployability,build,build,20,"Hi, I think you can build with `-Dmemstat=OFF`. Those classes have been completely removed in ROOT master. EDIT: `memstat` is also `OFF` by default, but maybe something like `-Dall=ON` turns it back on for you..?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9031
https://github.com/root-project/root/issues/9031:72,safety,compl,completely,72,"Hi, I think you can build with `-Dmemstat=OFF`. Those classes have been completely removed in ROOT master. EDIT: `memstat` is also `OFF` by default, but maybe something like `-Dall=ON` turns it back on for you..?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9031
https://github.com/root-project/root/issues/9031:72,security,compl,completely,72,"Hi, I think you can build with `-Dmemstat=OFF`. Those classes have been completely removed in ROOT master. EDIT: `memstat` is also `OFF` by default, but maybe something like `-Dall=ON` turns it back on for you..?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9031
https://github.com/root-project/root/pull/9033:82,availability,servic,services,82,> * [projectroot.runtutorials.tutorial_multicore_mp001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mp001_fillHistos/). > . > * [projectroot.runtutorials.tutorial_multicore_mtbb001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mtbb001_fillHistos/). These failures are totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9033
https://github.com/root-project/root/pull/9033:310,availability,servic,services,310,> * [projectroot.runtutorials.tutorial_multicore_mp001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mp001_fillHistos/). > . > * [projectroot.runtutorials.tutorial_multicore_mtbb001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mtbb001_fillHistos/). These failures are totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9033
https://github.com/root-project/root/pull/9033:458,availability,failur,failures,458,> * [projectroot.runtutorials.tutorial_multicore_mp001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mp001_fillHistos/). > . > * [projectroot.runtutorials.tutorial_multicore_mtbb001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mtbb001_fillHistos/). These failures are totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9033
https://github.com/root-project/root/pull/9033:82,deployability,servic,services,82,> * [projectroot.runtutorials.tutorial_multicore_mp001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mp001_fillHistos/). > . > * [projectroot.runtutorials.tutorial_multicore_mtbb001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mtbb001_fillHistos/). These failures are totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9033
https://github.com/root-project/root/pull/9033:134,deployability,build,build,134,> * [projectroot.runtutorials.tutorial_multicore_mp001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mp001_fillHistos/). > . > * [projectroot.runtutorials.tutorial_multicore_mtbb001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mtbb001_fillHistos/). These failures are totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9033
https://github.com/root-project/root/pull/9033:310,deployability,servic,services,310,> * [projectroot.runtutorials.tutorial_multicore_mp001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mp001_fillHistos/). > . > * [projectroot.runtutorials.tutorial_multicore_mtbb001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mtbb001_fillHistos/). These failures are totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9033
https://github.com/root-project/root/pull/9033:362,deployability,build,build,362,> * [projectroot.runtutorials.tutorial_multicore_mp001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mp001_fillHistos/). > . > * [projectroot.runtutorials.tutorial_multicore_mtbb001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mtbb001_fillHistos/). These failures are totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9033
https://github.com/root-project/root/pull/9033:458,deployability,fail,failures,458,> * [projectroot.runtutorials.tutorial_multicore_mp001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mp001_fillHistos/). > . > * [projectroot.runtutorials.tutorial_multicore_mtbb001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mtbb001_fillHistos/). These failures are totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9033
https://github.com/root-project/root/pull/9033:82,integrability,servic,services,82,> * [projectroot.runtutorials.tutorial_multicore_mp001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mp001_fillHistos/). > . > * [projectroot.runtutorials.tutorial_multicore_mtbb001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mtbb001_fillHistos/). These failures are totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9033
https://github.com/root-project/root/pull/9033:310,integrability,servic,services,310,> * [projectroot.runtutorials.tutorial_multicore_mp001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mp001_fillHistos/). > . > * [projectroot.runtutorials.tutorial_multicore_mtbb001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mtbb001_fillHistos/). These failures are totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9033
https://github.com/root-project/root/pull/9033:82,modifiability,servic,services,82,> * [projectroot.runtutorials.tutorial_multicore_mp001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mp001_fillHistos/). > . > * [projectroot.runtutorials.tutorial_multicore_mtbb001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mtbb001_fillHistos/). These failures are totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9033
https://github.com/root-project/root/pull/9033:310,modifiability,servic,services,310,> * [projectroot.runtutorials.tutorial_multicore_mp001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mp001_fillHistos/). > . > * [projectroot.runtutorials.tutorial_multicore_mtbb001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mtbb001_fillHistos/). These failures are totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9033
https://github.com/root-project/root/pull/9033:458,performance,failur,failures,458,> * [projectroot.runtutorials.tutorial_multicore_mp001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mp001_fillHistos/). > . > * [projectroot.runtutorials.tutorial_multicore_mtbb001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mtbb001_fillHistos/). These failures are totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9033
https://github.com/root-project/root/pull/9033:458,reliability,fail,failures,458,> * [projectroot.runtutorials.tutorial_multicore_mp001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mp001_fillHistos/). > . > * [projectroot.runtutorials.tutorial_multicore_mtbb001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mtbb001_fillHistos/). These failures are totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9033
https://github.com/root-project/root/pull/9033:147,safety,test,testReport,147,> * [projectroot.runtutorials.tutorial_multicore_mp001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mp001_fillHistos/). > . > * [projectroot.runtutorials.tutorial_multicore_mtbb001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mtbb001_fillHistos/). These failures are totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9033
https://github.com/root-project/root/pull/9033:375,safety,test,testReport,375,> * [projectroot.runtutorials.tutorial_multicore_mp001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mp001_fillHistos/). > . > * [projectroot.runtutorials.tutorial_multicore_mtbb001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mtbb001_fillHistos/). These failures are totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9033
https://github.com/root-project/root/pull/9033:147,testability,test,testReport,147,> * [projectroot.runtutorials.tutorial_multicore_mp001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mp001_fillHistos/). > . > * [projectroot.runtutorials.tutorial_multicore_mtbb001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mtbb001_fillHistos/). These failures are totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9033
https://github.com/root-project/root/pull/9033:375,testability,test,testReport,375,> * [projectroot.runtutorials.tutorial_multicore_mp001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mp001_fillHistos/). > . > * [projectroot.runtutorials.tutorial_multicore_mtbb001_fillHistos](https://lcgapp-services.cern.ch/root-jenkins/job/root-pullrequests-build/126450/testReport/projectroot/runtutorials/tutorial_multicore_mtbb001_fillHistos/). These failures are totally unrelated.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9033
https://github.com/root-project/root/pull/9035:4,availability,error,error,4,"The error on Windows is actually not an error, it picks up the errors in the commit log...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9035
https://github.com/root-project/root/pull/9035:40,availability,error,error,40,"The error on Windows is actually not an error, it picks up the errors in the commit log...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9035
https://github.com/root-project/root/pull/9035:63,availability,error,errors,63,"The error on Windows is actually not an error, it picks up the errors in the commit log...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9035
https://github.com/root-project/root/pull/9035:84,deployability,log,log,84,"The error on Windows is actually not an error, it picks up the errors in the commit log...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9035
https://github.com/root-project/root/pull/9035:4,performance,error,error,4,"The error on Windows is actually not an error, it picks up the errors in the commit log...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9035
https://github.com/root-project/root/pull/9035:40,performance,error,error,40,"The error on Windows is actually not an error, it picks up the errors in the commit log...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9035
https://github.com/root-project/root/pull/9035:63,performance,error,errors,63,"The error on Windows is actually not an error, it picks up the errors in the commit log...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9035
https://github.com/root-project/root/pull/9035:4,safety,error,error,4,"The error on Windows is actually not an error, it picks up the errors in the commit log...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9035
https://github.com/root-project/root/pull/9035:40,safety,error,error,40,"The error on Windows is actually not an error, it picks up the errors in the commit log...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9035
https://github.com/root-project/root/pull/9035:63,safety,error,errors,63,"The error on Windows is actually not an error, it picks up the errors in the commit log...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9035
https://github.com/root-project/root/pull/9035:84,safety,log,log,84,"The error on Windows is actually not an error, it picks up the errors in the commit log...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9035
https://github.com/root-project/root/pull/9035:84,security,log,log,84,"The error on Windows is actually not an error, it picks up the errors in the commit log...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9035
https://github.com/root-project/root/pull/9035:84,testability,log,log,84,"The error on Windows is actually not an error, it picks up the errors in the commit log...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9035
https://github.com/root-project/root/pull/9035:4,usability,error,error,4,"The error on Windows is actually not an error, it picks up the errors in the commit log...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9035
https://github.com/root-project/root/pull/9035:40,usability,error,error,40,"The error on Windows is actually not an error, it picks up the errors in the commit log...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9035
https://github.com/root-project/root/pull/9035:63,usability,error,errors,63,"The error on Windows is actually not an error, it picks up the errors in the commit log...",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9035
https://github.com/root-project/root/issues/9036:10,deployability,build,build,10,Can nvc++ build llvm?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:11,usability,experien,experience,11,We have no experience with nvc++. Is that just an experiment or is there something we can help with? What's the motivation for using nvc++?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:90,usability,help,help,90,We have no experience with nvc++. Is that just an experiment or is there something we can help with? What's the motivation for using nvc++?,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:21,deployability,build,building,21,"I have not yet tried building llvm. Will try later this week. nvc++ has an implementation for std::par which allows seamless execution of both CPUs and NVIDIA GPUs (depending on a compile time flag). This could be a huge win for GPU portability (once other manufactures create the AMD/Intel backends), and allows much simpler user access to GPUs without having to learn CUDA (or hip, dpc++, etc). I was trying to compile some parts of a project with gcc and the bits that use std::par with nvc++, but immediately got some runtime segfaults at startup, so tried to compile the whole thing (including ROOT) with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:165,deployability,depend,depending,165,"I have not yet tried building llvm. Will try later this week. nvc++ has an implementation for std::par which allows seamless execution of both CPUs and NVIDIA GPUs (depending on a compile time flag). This could be a huge win for GPU portability (once other manufactures create the AMD/Intel backends), and allows much simpler user access to GPUs without having to learn CUDA (or hip, dpc++, etc). I was trying to compile some parts of a project with gcc and the bits that use std::par with nvc++, but immediately got some runtime segfaults at startup, so tried to compile the whole thing (including ROOT) with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:143,energy efficiency,CPU,CPUs,143,"I have not yet tried building llvm. Will try later this week. nvc++ has an implementation for std::par which allows seamless execution of both CPUs and NVIDIA GPUs (depending on a compile time flag). This could be a huge win for GPU portability (once other manufactures create the AMD/Intel backends), and allows much simpler user access to GPUs without having to learn CUDA (or hip, dpc++, etc). I was trying to compile some parts of a project with gcc and the bits that use std::par with nvc++, but immediately got some runtime segfaults at startup, so tried to compile the whole thing (including ROOT) with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:159,energy efficiency,GPU,GPUs,159,"I have not yet tried building llvm. Will try later this week. nvc++ has an implementation for std::par which allows seamless execution of both CPUs and NVIDIA GPUs (depending on a compile time flag). This could be a huge win for GPU portability (once other manufactures create the AMD/Intel backends), and allows much simpler user access to GPUs without having to learn CUDA (or hip, dpc++, etc). I was trying to compile some parts of a project with gcc and the bits that use std::par with nvc++, but immediately got some runtime segfaults at startup, so tried to compile the whole thing (including ROOT) with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:229,energy efficiency,GPU,GPU,229,"I have not yet tried building llvm. Will try later this week. nvc++ has an implementation for std::par which allows seamless execution of both CPUs and NVIDIA GPUs (depending on a compile time flag). This could be a huge win for GPU portability (once other manufactures create the AMD/Intel backends), and allows much simpler user access to GPUs without having to learn CUDA (or hip, dpc++, etc). I was trying to compile some parts of a project with gcc and the bits that use std::par with nvc++, but immediately got some runtime segfaults at startup, so tried to compile the whole thing (including ROOT) with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:341,energy efficiency,GPU,GPUs,341,"I have not yet tried building llvm. Will try later this week. nvc++ has an implementation for std::par which allows seamless execution of both CPUs and NVIDIA GPUs (depending on a compile time flag). This could be a huge win for GPU portability (once other manufactures create the AMD/Intel backends), and allows much simpler user access to GPUs without having to learn CUDA (or hip, dpc++, etc). I was trying to compile some parts of a project with gcc and the bits that use std::par with nvc++, but immediately got some runtime segfaults at startup, so tried to compile the whole thing (including ROOT) with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:165,integrability,depend,depending,165,"I have not yet tried building llvm. Will try later this week. nvc++ has an implementation for std::par which allows seamless execution of both CPUs and NVIDIA GPUs (depending on a compile time flag). This could be a huge win for GPU portability (once other manufactures create the AMD/Intel backends), and allows much simpler user access to GPUs without having to learn CUDA (or hip, dpc++, etc). I was trying to compile some parts of a project with gcc and the bits that use std::par with nvc++, but immediately got some runtime segfaults at startup, so tried to compile the whole thing (including ROOT) with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:165,modifiability,depend,depending,165,"I have not yet tried building llvm. Will try later this week. nvc++ has an implementation for std::par which allows seamless execution of both CPUs and NVIDIA GPUs (depending on a compile time flag). This could be a huge win for GPU portability (once other manufactures create the AMD/Intel backends), and allows much simpler user access to GPUs without having to learn CUDA (or hip, dpc++, etc). I was trying to compile some parts of a project with gcc and the bits that use std::par with nvc++, but immediately got some runtime segfaults at startup, so tried to compile the whole thing (including ROOT) with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:233,modifiability,portab,portability,233,"I have not yet tried building llvm. Will try later this week. nvc++ has an implementation for std::par which allows seamless execution of both CPUs and NVIDIA GPUs (depending on a compile time flag). This could be a huge win for GPU portability (once other manufactures create the AMD/Intel backends), and allows much simpler user access to GPUs without having to learn CUDA (or hip, dpc++, etc). I was trying to compile some parts of a project with gcc and the bits that use std::par with nvc++, but immediately got some runtime segfaults at startup, so tried to compile the whole thing (including ROOT) with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:143,performance,CPU,CPUs,143,"I have not yet tried building llvm. Will try later this week. nvc++ has an implementation for std::par which allows seamless execution of both CPUs and NVIDIA GPUs (depending on a compile time flag). This could be a huge win for GPU portability (once other manufactures create the AMD/Intel backends), and allows much simpler user access to GPUs without having to learn CUDA (or hip, dpc++, etc). I was trying to compile some parts of a project with gcc and the bits that use std::par with nvc++, but immediately got some runtime segfaults at startup, so tried to compile the whole thing (including ROOT) with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:159,performance,GPU,GPUs,159,"I have not yet tried building llvm. Will try later this week. nvc++ has an implementation for std::par which allows seamless execution of both CPUs and NVIDIA GPUs (depending on a compile time flag). This could be a huge win for GPU portability (once other manufactures create the AMD/Intel backends), and allows much simpler user access to GPUs without having to learn CUDA (or hip, dpc++, etc). I was trying to compile some parts of a project with gcc and the bits that use std::par with nvc++, but immediately got some runtime segfaults at startup, so tried to compile the whole thing (including ROOT) with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:188,performance,time,time,188,"I have not yet tried building llvm. Will try later this week. nvc++ has an implementation for std::par which allows seamless execution of both CPUs and NVIDIA GPUs (depending on a compile time flag). This could be a huge win for GPU portability (once other manufactures create the AMD/Intel backends), and allows much simpler user access to GPUs without having to learn CUDA (or hip, dpc++, etc). I was trying to compile some parts of a project with gcc and the bits that use std::par with nvc++, but immediately got some runtime segfaults at startup, so tried to compile the whole thing (including ROOT) with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:229,performance,GPU,GPU,229,"I have not yet tried building llvm. Will try later this week. nvc++ has an implementation for std::par which allows seamless execution of both CPUs and NVIDIA GPUs (depending on a compile time flag). This could be a huge win for GPU portability (once other manufactures create the AMD/Intel backends), and allows much simpler user access to GPUs without having to learn CUDA (or hip, dpc++, etc). I was trying to compile some parts of a project with gcc and the bits that use std::par with nvc++, but immediately got some runtime segfaults at startup, so tried to compile the whole thing (including ROOT) with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:341,performance,GPU,GPUs,341,"I have not yet tried building llvm. Will try later this week. nvc++ has an implementation for std::par which allows seamless execution of both CPUs and NVIDIA GPUs (depending on a compile time flag). This could be a huge win for GPU portability (once other manufactures create the AMD/Intel backends), and allows much simpler user access to GPUs without having to learn CUDA (or hip, dpc++, etc). I was trying to compile some parts of a project with gcc and the bits that use std::par with nvc++, but immediately got some runtime segfaults at startup, so tried to compile the whole thing (including ROOT) with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:165,safety,depend,depending,165,"I have not yet tried building llvm. Will try later this week. nvc++ has an implementation for std::par which allows seamless execution of both CPUs and NVIDIA GPUs (depending on a compile time flag). This could be a huge win for GPU portability (once other manufactures create the AMD/Intel backends), and allows much simpler user access to GPUs without having to learn CUDA (or hip, dpc++, etc). I was trying to compile some parts of a project with gcc and the bits that use std::par with nvc++, but immediately got some runtime segfaults at startup, so tried to compile the whole thing (including ROOT) with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:331,security,access,access,331,"I have not yet tried building llvm. Will try later this week. nvc++ has an implementation for std::par which allows seamless execution of both CPUs and NVIDIA GPUs (depending on a compile time flag). This could be a huge win for GPU portability (once other manufactures create the AMD/Intel backends), and allows much simpler user access to GPUs without having to learn CUDA (or hip, dpc++, etc). I was trying to compile some parts of a project with gcc and the bits that use std::par with nvc++, but immediately got some runtime segfaults at startup, so tried to compile the whole thing (including ROOT) with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:165,testability,depend,depending,165,"I have not yet tried building llvm. Will try later this week. nvc++ has an implementation for std::par which allows seamless execution of both CPUs and NVIDIA GPUs (depending on a compile time flag). This could be a huge win for GPU portability (once other manufactures create the AMD/Intel backends), and allows much simpler user access to GPUs without having to learn CUDA (or hip, dpc++, etc). I was trying to compile some parts of a project with gcc and the bits that use std::par with nvc++, but immediately got some runtime segfaults at startup, so tried to compile the whole thing (including ROOT) with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:318,testability,simpl,simpler,318,"I have not yet tried building llvm. Will try later this week. nvc++ has an implementation for std::par which allows seamless execution of both CPUs and NVIDIA GPUs (depending on a compile time flag). This could be a huge win for GPU portability (once other manufactures create the AMD/Intel backends), and allows much simpler user access to GPUs without having to learn CUDA (or hip, dpc++, etc). I was trying to compile some parts of a project with gcc and the bits that use std::par with nvc++, but immediately got some runtime segfaults at startup, so tried to compile the whole thing (including ROOT) with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:318,usability,simpl,simpler,318,"I have not yet tried building llvm. Will try later this week. nvc++ has an implementation for std::par which allows seamless execution of both CPUs and NVIDIA GPUs (depending on a compile time flag). This could be a huge win for GPU portability (once other manufactures create the AMD/Intel backends), and allows much simpler user access to GPUs without having to learn CUDA (or hip, dpc++, etc). I was trying to compile some parts of a project with gcc and the bits that use std::par with nvc++, but immediately got some runtime segfaults at startup, so tried to compile the whole thing (including ROOT) with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:326,usability,user,user,326,"I have not yet tried building llvm. Will try later this week. nvc++ has an implementation for std::par which allows seamless execution of both CPUs and NVIDIA GPUs (depending on a compile time flag). This could be a huge win for GPU portability (once other manufactures create the AMD/Intel backends), and allows much simpler user access to GPUs without having to learn CUDA (or hip, dpc++, etc). I was trying to compile some parts of a project with gcc and the bits that use std::par with nvc++, but immediately got some runtime segfaults at startup, so tried to compile the whole thing (including ROOT) with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:364,usability,learn,learn,364,"I have not yet tried building llvm. Will try later this week. nvc++ has an implementation for std::par which allows seamless execution of both CPUs and NVIDIA GPUs (depending on a compile time flag). This could be a huge win for GPU portability (once other manufactures create the AMD/Intel backends), and allows much simpler user access to GPUs without having to learn CUDA (or hip, dpc++, etc). I was trying to compile some parts of a project with gcc and the bits that use std::par with nvc++, but immediately got some runtime segfaults at startup, so tried to compile the whole thing (including ROOT) with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:20,deployability,build,build,20,"looks like it can't build llvm (12.0.1):. ```. [ 4%] Building IntrinsicImpl.inc... cd /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR && ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. llvm-tblgen: /home/leggett/install/llvm/llvm-project/llvm/utils/TableGen/IntrinsicEmitter.cpp:353: void EncodeFixedType(llvm::Record *, std::vector<unsigned char, std::allocator<unsigned char>> &, unsigned int &, std::vector<unsigned char, std::allocator<unsigned char>> &, llvm::ArrayRef<unsigned char>): Assertion `NextArgCode < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:53,deployability,Build,Building,53,"looks like it can't build llvm (12.0.1):. ```. [ 4%] Building IntrinsicImpl.inc... cd /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR && ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. llvm-tblgen: /home/leggett/install/llvm/llvm-project/llvm/utils/TableGen/IntrinsicEmitter.cpp:353: void EncodeFixedType(llvm::Record *, std::vector<unsigned char, std::allocator<unsigned char>> &, unsigned int &, std::vector<unsigned char, std::allocator<unsigned char>> &, llvm::ArrayRef<unsigned char>): Assertion `NextArgCode < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:100,deployability,instal,install,100,"looks like it can't build llvm (12.0.1):. ```. [ 4%] Building IntrinsicImpl.inc... cd /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR && ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. llvm-tblgen: /home/leggett/install/llvm/llvm-project/llvm/utils/TableGen/IntrinsicEmitter.cpp:353: void EncodeFixedType(llvm::Record *, std::vector<unsigned char, std::allocator<unsigned char>> &, unsigned int &, std::vector<unsigned char, std::allocator<unsigned char>> &, llvm::ArrayRef<unsigned char>): Assertion `NextArgCode < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:216,deployability,instal,install,216,"looks like it can't build llvm (12.0.1):. ```. [ 4%] Building IntrinsicImpl.inc... cd /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR && ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. llvm-tblgen: /home/leggett/install/llvm/llvm-project/llvm/utils/TableGen/IntrinsicEmitter.cpp:353: void EncodeFixedType(llvm::Record *, std::vector<unsigned char, std::allocator<unsigned char>> &, unsigned int &, std::vector<unsigned char, std::allocator<unsigned char>> &, llvm::ArrayRef<unsigned char>): Assertion `NextArgCode < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:279,deployability,instal,install,279,"looks like it can't build llvm (12.0.1):. ```. [ 4%] Building IntrinsicImpl.inc... cd /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR && ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. llvm-tblgen: /home/leggett/install/llvm/llvm-project/llvm/utils/TableGen/IntrinsicEmitter.cpp:353: void EncodeFixedType(llvm::Record *, std::vector<unsigned char, std::allocator<unsigned char>> &, unsigned int &, std::vector<unsigned char, std::allocator<unsigned char>> &, llvm::ArrayRef<unsigned char>): Assertion `NextArgCode < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:338,deployability,instal,install,338,"looks like it can't build llvm (12.0.1):. ```. [ 4%] Building IntrinsicImpl.inc... cd /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR && ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. llvm-tblgen: /home/leggett/install/llvm/llvm-project/llvm/utils/TableGen/IntrinsicEmitter.cpp:353: void EncodeFixedType(llvm::Record *, std::vector<unsigned char, std::allocator<unsigned char>> &, unsigned int &, std::vector<unsigned char, std::allocator<unsigned char>> &, llvm::ArrayRef<unsigned char>): Assertion `NextArgCode < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:391,deployability,instal,install,391,"looks like it can't build llvm (12.0.1):. ```. [ 4%] Building IntrinsicImpl.inc... cd /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR && ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. llvm-tblgen: /home/leggett/install/llvm/llvm-project/llvm/utils/TableGen/IntrinsicEmitter.cpp:353: void EncodeFixedType(llvm::Record *, std::vector<unsigned char, std::allocator<unsigned char>> &, unsigned int &, std::vector<unsigned char, std::allocator<unsigned char>> &, llvm::ArrayRef<unsigned char>): Assertion `NextArgCode < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:488,deployability,instal,install,488,"looks like it can't build llvm (12.0.1):. ```. [ 4%] Building IntrinsicImpl.inc... cd /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR && ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. llvm-tblgen: /home/leggett/install/llvm/llvm-project/llvm/utils/TableGen/IntrinsicEmitter.cpp:353: void EncodeFixedType(llvm::Record *, std::vector<unsigned char, std::allocator<unsigned char>> &, unsigned int &, std::vector<unsigned char, std::allocator<unsigned char>> &, llvm::ArrayRef<unsigned char>): Assertion `NextArgCode < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:585,deployability,instal,install,585,"looks like it can't build llvm (12.0.1):. ```. [ 4%] Building IntrinsicImpl.inc... cd /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR && ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. llvm-tblgen: /home/leggett/install/llvm/llvm-project/llvm/utils/TableGen/IntrinsicEmitter.cpp:353: void EncodeFixedType(llvm::Record *, std::vector<unsigned char, std::allocator<unsigned char>> &, unsigned int &, std::vector<unsigned char, std::allocator<unsigned char>> &, llvm::ArrayRef<unsigned char>): Assertion `NextArgCode < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:996,deployability,fail,failed,996,"looks like it can't build llvm (12.0.1):. ```. [ 4%] Building IntrinsicImpl.inc... cd /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR && ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. llvm-tblgen: /home/leggett/install/llvm/llvm-project/llvm/utils/TableGen/IntrinsicEmitter.cpp:353: void EncodeFixedType(llvm::Record *, std::vector<unsigned char, std::allocator<unsigned char>> &, unsigned int &, std::vector<unsigned char, std::allocator<unsigned char>> &, llvm::ArrayRef<unsigned char>): Assertion `NextArgCode < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:1090,deployability,Stack,Stack,1090,"eggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR && ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. llvm-tblgen: /home/leggett/install/llvm/llvm-project/llvm/utils/TableGen/IntrinsicEmitter.cpp:353: void EncodeFixedType(llvm::Record *, std::vector<unsigned char, std::allocator<unsigned char>> &, unsigned int &, std::vector<unsigned char, std::allocator<unsigned char>> &, llvm::ArrayRef<unsigned char>): Assertion `NextArgCode < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61b1a6]. /lib64/libc.so.6(+0x2f252)[0x7f551c61b252]. ../../../bin/llvm-tblgen[0x8d488b]. ../../",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:1187,deployability,instal,install,1187,"ic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. llvm-tblgen: /home/leggett/install/llvm/llvm-project/llvm/utils/TableGen/IntrinsicEmitter.cpp:353: void EncodeFixedType(llvm::Record *, std::vector<unsigned char, std::allocator<unsigned char>> &, unsigned int &, std::vector<unsigned char, std::allocator<unsigned char>> &, llvm::ArrayRef<unsigned char>): Assertion `NextArgCode < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61b1a6]. /lib64/libc.so.6(+0x2f252)[0x7f551c61b252]. ../../../bin/llvm-tblgen[0x8d488b]. ../../../bin/llvm-tblgen[0x8d5236]. ../../../bin/llvm-tblgen[0x8eb3aa]. ../../../bin/llvm-tblgen[0x8ea77",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:1250,deployability,instal,install,1250,"/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. llvm-tblgen: /home/leggett/install/llvm/llvm-project/llvm/utils/TableGen/IntrinsicEmitter.cpp:353: void EncodeFixedType(llvm::Record *, std::vector<unsigned char, std::allocator<unsigned char>> &, unsigned int &, std::vector<unsigned char, std::allocator<unsigned char>> &, llvm::ArrayRef<unsigned char>): Assertion `NextArgCode < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61b1a6]. /lib64/libc.so.6(+0x2f252)[0x7f551c61b252]. ../../../bin/llvm-tblgen[0x8d488b]. ../../../bin/llvm-tblgen[0x8d5236]. ../../../bin/llvm-tblgen[0x8eb3aa]. ../../../bin/llvm-tblgen[0x8ea772]. ../../../bin/llvm-tblgen[0x8e9ad3]. ../../../bin/llvm-tblge",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:1309,deployability,instal,install,1309,"/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. llvm-tblgen: /home/leggett/install/llvm/llvm-project/llvm/utils/TableGen/IntrinsicEmitter.cpp:353: void EncodeFixedType(llvm::Record *, std::vector<unsigned char, std::allocator<unsigned char>> &, unsigned int &, std::vector<unsigned char, std::allocator<unsigned char>> &, llvm::ArrayRef<unsigned char>): Assertion `NextArgCode < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61b1a6]. /lib64/libc.so.6(+0x2f252)[0x7f551c61b252]. ../../../bin/llvm-tblgen[0x8d488b]. ../../../bin/llvm-tblgen[0x8d5236]. ../../../bin/llvm-tblgen[0x8eb3aa]. ../../../bin/llvm-tblgen[0x8ea772]. ../../../bin/llvm-tblgen[0x8e9ad3]. ../../../bin/llvm-tblgen[0x9fafb0]. ../../../bin/llvm-tblgen[0xc35bfb]. ../../../b",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:1362,deployability,instal,install,1362,"vm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. llvm-tblgen: /home/leggett/install/llvm/llvm-project/llvm/utils/TableGen/IntrinsicEmitter.cpp:353: void EncodeFixedType(llvm::Record *, std::vector<unsigned char, std::allocator<unsigned char>> &, unsigned int &, std::vector<unsigned char, std::allocator<unsigned char>> &, llvm::ArrayRef<unsigned char>): Assertion `NextArgCode < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61b1a6]. /lib64/libc.so.6(+0x2f252)[0x7f551c61b252]. ../../../bin/llvm-tblgen[0x8d488b]. ../../../bin/llvm-tblgen[0x8d5236]. ../../../bin/llvm-tblgen[0x8eb3aa]. ../../../bin/llvm-tblgen[0x8ea772]. ../../../bin/llvm-tblgen[0x8e9ad3]. ../../../bin/llvm-tblgen[0x9fafb0]. ../../../bin/llvm-tblgen[0xc35bfb]. ../../../bin/llvm-tblgen[0x9f1848]. /lib64/libc.so.6(__libc_sta",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:1459,deployability,instal,install,1459,"changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. llvm-tblgen: /home/leggett/install/llvm/llvm-project/llvm/utils/TableGen/IntrinsicEmitter.cpp:353: void EncodeFixedType(llvm::Record *, std::vector<unsigned char, std::allocator<unsigned char>> &, unsigned int &, std::vector<unsigned char, std::allocator<unsigned char>> &, llvm::ArrayRef<unsigned char>): Assertion `NextArgCode < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61b1a6]. /lib64/libc.so.6(+0x2f252)[0x7f551c61b252]. ../../../bin/llvm-tblgen[0x8d488b]. ../../../bin/llvm-tblgen[0x8d5236]. ../../../bin/llvm-tblgen[0x8eb3aa]. ../../../bin/llvm-tblgen[0x8ea772]. ../../../bin/llvm-tblgen[0x8e9ad3]. ../../../bin/llvm-tblgen[0x9fafb0]. ../../../bin/llvm-tblgen[0xc35bfb]. ../../../bin/llvm-tblgen[0x9f1848]. /lib64/libc.so.6(__libc_start_main+0xf5)[0x7f551c60e555]. ../../../bin/llvm-tblgen[0x40f919]. /bin/sh: line 1: 212409 Aborte",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:1529,deployability,Stack,Stack,1529,"lvm/IR/IntrinsicImpl.inc. llvm-tblgen: /home/leggett/install/llvm/llvm-project/llvm/utils/TableGen/IntrinsicEmitter.cpp:353: void EncodeFixedType(llvm::Record *, std::vector<unsigned char, std::allocator<unsigned char>> &, unsigned int &, std::vector<unsigned char, std::allocator<unsigned char>> &, llvm::ArrayRef<unsigned char>): Assertion `NextArgCode < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61b1a6]. /lib64/libc.so.6(+0x2f252)[0x7f551c61b252]. ../../../bin/llvm-tblgen[0x8d488b]. ../../../bin/llvm-tblgen[0x8d5236]. ../../../bin/llvm-tblgen[0x8eb3aa]. ../../../bin/llvm-tblgen[0x8ea772]. ../../../bin/llvm-tblgen[0x8e9ad3]. ../../../bin/llvm-tblgen[0x9fafb0]. ../../../bin/llvm-tblgen[0xc35bfb]. ../../../bin/llvm-tblgen[0x9f1848]. /lib64/libc.so.6(__libc_start_main+0xf5)[0x7f551c60e555]. ../../../bin/llvm-tblgen[0x40f919]. /bin/sh: line 1: 212409 Aborted (core dumped) ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:2541,deployability,instal,install,2541," < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61b1a6]. /lib64/libc.so.6(+0x2f252)[0x7f551c61b252]. ../../../bin/llvm-tblgen[0x8d488b]. ../../../bin/llvm-tblgen[0x8d5236]. ../../../bin/llvm-tblgen[0x8eb3aa]. ../../../bin/llvm-tblgen[0x8ea772]. ../../../bin/llvm-tblgen[0x8e9ad3]. ../../../bin/llvm-tblgen[0x9fafb0]. ../../../bin/llvm-tblgen[0xc35bfb]. ../../../bin/llvm-tblgen[0x9f1848]. /lib64/libc.so.6(__libc_start_main+0xf5)[0x7f551c60e555]. ../../../bin/llvm-tblgen[0x40f919]. /bin/sh: line 1: 212409 Aborted (core dumped) ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:2604,deployability,instal,install,2604," < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61b1a6]. /lib64/libc.so.6(+0x2f252)[0x7f551c61b252]. ../../../bin/llvm-tblgen[0x8d488b]. ../../../bin/llvm-tblgen[0x8d5236]. ../../../bin/llvm-tblgen[0x8eb3aa]. ../../../bin/llvm-tblgen[0x8ea772]. ../../../bin/llvm-tblgen[0x8e9ad3]. ../../../bin/llvm-tblgen[0x9fafb0]. ../../../bin/llvm-tblgen[0xc35bfb]. ../../../bin/llvm-tblgen[0x9f1848]. /lib64/libc.so.6(__libc_start_main+0xf5)[0x7f551c60e555]. ../../../bin/llvm-tblgen[0x40f919]. /bin/sh: line 1: 212409 Aborted (core dumped) ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:2663,deployability,instal,install,2663," < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61b1a6]. /lib64/libc.so.6(+0x2f252)[0x7f551c61b252]. ../../../bin/llvm-tblgen[0x8d488b]. ../../../bin/llvm-tblgen[0x8d5236]. ../../../bin/llvm-tblgen[0x8eb3aa]. ../../../bin/llvm-tblgen[0x8ea772]. ../../../bin/llvm-tblgen[0x8e9ad3]. ../../../bin/llvm-tblgen[0x9fafb0]. ../../../bin/llvm-tblgen[0xc35bfb]. ../../../bin/llvm-tblgen[0x9f1848]. /lib64/libc.so.6(__libc_start_main+0xf5)[0x7f551c60e555]. ../../../bin/llvm-tblgen[0x40f919]. /bin/sh: line 1: 212409 Aborted (core dumped) ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:2716,deployability,instal,install,2716," < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61b1a6]. /lib64/libc.so.6(+0x2f252)[0x7f551c61b252]. ../../../bin/llvm-tblgen[0x8d488b]. ../../../bin/llvm-tblgen[0x8d5236]. ../../../bin/llvm-tblgen[0x8eb3aa]. ../../../bin/llvm-tblgen[0x8ea772]. ../../../bin/llvm-tblgen[0x8e9ad3]. ../../../bin/llvm-tblgen[0x9fafb0]. ../../../bin/llvm-tblgen[0xc35bfb]. ../../../bin/llvm-tblgen[0x9f1848]. /lib64/libc.so.6(__libc_start_main+0xf5)[0x7f551c60e555]. ../../../bin/llvm-tblgen[0x40f919]. /bin/sh: line 1: 212409 Aborted (core dumped) ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:2813,deployability,instal,install,2813," < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61b1a6]. /lib64/libc.so.6(+0x2f252)[0x7f551c61b252]. ../../../bin/llvm-tblgen[0x8d488b]. ../../../bin/llvm-tblgen[0x8d5236]. ../../../bin/llvm-tblgen[0x8eb3aa]. ../../../bin/llvm-tblgen[0x8ea772]. ../../../bin/llvm-tblgen[0x8e9ad3]. ../../../bin/llvm-tblgen[0x9fafb0]. ../../../bin/llvm-tblgen[0xc35bfb]. ../../../bin/llvm-tblgen[0x9f1848]. /lib64/libc.so.6(__libc_start_main+0xf5)[0x7f551c60e555]. ../../../bin/llvm-tblgen[0x40f919]. /bin/sh: line 1: 212409 Aborted (core dumped) ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:726,energy efficiency,alloc,allocator,726,"looks like it can't build llvm (12.0.1):. ```. [ 4%] Building IntrinsicImpl.inc... cd /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR && ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. llvm-tblgen: /home/leggett/install/llvm/llvm-project/llvm/utils/TableGen/IntrinsicEmitter.cpp:353: void EncodeFixedType(llvm::Record *, std::vector<unsigned char, std::allocator<unsigned char>> &, unsigned int &, std::vector<unsigned char, std::allocator<unsigned char>> &, llvm::ArrayRef<unsigned char>): Assertion `NextArgCode < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:803,energy efficiency,alloc,allocator,803,"looks like it can't build llvm (12.0.1):. ```. [ 4%] Building IntrinsicImpl.inc... cd /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR && ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. llvm-tblgen: /home/leggett/install/llvm/llvm-project/llvm/utils/TableGen/IntrinsicEmitter.cpp:353: void EncodeFixedType(llvm::Record *, std::vector<unsigned char, std::allocator<unsigned char>> &, unsigned int &, std::vector<unsigned char, std::allocator<unsigned char>> &, llvm::ArrayRef<unsigned char>): Assertion `NextArgCode < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:2466,energy efficiency,core,core,2466," < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61b1a6]. /lib64/libc.so.6(+0x2f252)[0x7f551c61b252]. ../../../bin/llvm-tblgen[0x8d488b]. ../../../bin/llvm-tblgen[0x8d5236]. ../../../bin/llvm-tblgen[0x8eb3aa]. ../../../bin/llvm-tblgen[0x8ea772]. ../../../bin/llvm-tblgen[0x8e9ad3]. ../../../bin/llvm-tblgen[0x9fafb0]. ../../../bin/llvm-tblgen[0xc35bfb]. ../../../bin/llvm-tblgen[0x9f1848]. /lib64/libc.so.6(__libc_start_main+0xf5)[0x7f551c60e555]. ../../../bin/llvm-tblgen[0x40f919]. /bin/sh: line 1: 212409 Aborted (core dumped) ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:1011,integrability,sub,submit,1011,"can't build llvm (12.0.1):. ```. [ 4%] Building IntrinsicImpl.inc... cd /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR && ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. llvm-tblgen: /home/leggett/install/llvm/llvm-project/llvm/utils/TableGen/IntrinsicEmitter.cpp:353: void EncodeFixedType(llvm::Record *, std::vector<unsigned char, std::allocator<unsigned char>> &, unsigned int &, std::vector<unsigned char, std::allocator<unsigned char>> &, llvm::ArrayRef<unsigned char>): Assertion `NextArgCode < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61b1a6]. /lib64/",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:996,reliability,fail,failed,996,"looks like it can't build llvm (12.0.1):. ```. [ 4%] Building IntrinsicImpl.inc... cd /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR && ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. llvm-tblgen: /home/leggett/install/llvm/llvm-project/llvm/utils/TableGen/IntrinsicEmitter.cpp:353: void EncodeFixedType(llvm::Record *, std::vector<unsigned char, std::allocator<unsigned char>> &, unsigned int &, std::vector<unsigned char, std::allocator<unsigned char>> &, llvm::ArrayRef<unsigned char>): Assertion `NextArgCode < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:864,testability,Assert,Assertion,864,"looks like it can't build llvm (12.0.1):. ```. [ 4%] Building IntrinsicImpl.inc... cd /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR && ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. llvm-tblgen: /home/leggett/install/llvm/llvm-project/llvm/utils/TableGen/IntrinsicEmitter.cpp:353: void EncodeFixedType(llvm::Record *, std::vector<unsigned char, std::allocator<unsigned char>> &, unsigned int &, std::vector<unsigned char, std::allocator<unsigned char>> &, llvm::ArrayRef<unsigned char>): Assertion `NextArgCode < ArgCodes.size() && ArgCodes[NextArgCode] == Tmp && ""Invalid or no ArgCode associated with overloaded VT!""' failed. PLEASE submit a bug report to https://bugs.llvm.org/ and include the crash backtrace. Stack dump:. 0.	Program arguments: ../../../bin/llvm-tblgen -gen-intrinsic-impl -I /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR -I/home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include -I/home/leggett/install/llvm/llvm-project/llvm/include /home/leggett/install/llvm/llvm-project/llvm/include/llvm/IR/Intrinsics.td --write-if-changed -o /home/leggett/install/llvm/bld-12.0.1-nvc++-21.9/include/llvm/IR/IntrinsicImpl.inc. Stack dump without symbol names (ensure you have llvm-symbolizer in your PATH or set the environment var `LLVM_SYMBOLIZER_PATH` to point to it):. ../../../bin/llvm-tblgen[0xbd77e0]. ../../../bin/llvm-tblgen[0xbcda5b]. ../../../bin/llvm-tblgen[0xbd7478]. ../../../bin/llvm-tblgen[0xbcd731]. /lib64/libpthread.so.0(+0xf630)[0x7f551d056630]. /lib64/libc.so.6(gsignal+0x37)[0x7f551c6223d7]. /lib64/libc.so.6(abort+0x148)[0x7f551c623ac8]. /lib64/libc.so.6(+0x2f1a6)[0x7f551c61",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:156,deployability,build,building,156,"@Axel-Naumann, since I just revisited compiling root with nvc++, the issue still persists. With a couple of fixes (PR: #14139), `clang-tblgen` crashes when building ROOT's LLVM. The same crash happens when building upstream LLVM 17.0.6. So the blocker may be a bug in nvc++'s code generation or a bug in `clang-tblgen` that only manifests with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:206,deployability,build,building,206,"@Axel-Naumann, since I just revisited compiling root with nvc++, the issue still persists. With a couple of fixes (PR: #14139), `clang-tblgen` crashes when building ROOT's LLVM. The same crash happens when building upstream LLVM 17.0.6. So the blocker may be a bug in nvc++'s code generation or a bug in `clang-tblgen` that only manifests with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:98,integrability,coupl,couple,98,"@Axel-Naumann, since I just revisited compiling root with nvc++, the issue still persists. With a couple of fixes (PR: #14139), `clang-tblgen` crashes when building ROOT's LLVM. The same crash happens when building upstream LLVM 17.0.6. So the blocker may be a bug in nvc++'s code generation or a bug in `clang-tblgen` that only manifests with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:98,modifiability,coupl,couple,98,"@Axel-Naumann, since I just revisited compiling root with nvc++, the issue still persists. With a couple of fixes (PR: #14139), `clang-tblgen` crashes when building ROOT's LLVM. The same crash happens when building upstream LLVM 17.0.6. So the blocker may be a bug in nvc++'s code generation or a bug in `clang-tblgen` that only manifests with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:98,testability,coupl,couple,98,"@Axel-Naumann, since I just revisited compiling root with nvc++, the issue still persists. With a couple of fixes (PR: #14139), `clang-tblgen` crashes when building ROOT's LLVM. The same crash happens when building upstream LLVM 17.0.6. So the blocker may be a bug in nvc++'s code generation or a bug in `clang-tblgen` that only manifests with nvc++.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:35,deployability,build,build,35,"The crash does not happen, when we build LLVM in Debug (`-DLLVM_BUILD_TYPE=Debug -DCMAKE_BUILD_TYPE=Debug`). However, then `rootcling_stage1` will crash later with:. ```. <FlagClass Prefixes:[""/"", ""-""] Name:""/?"" Group:<GroupClass Name:""<clang-cl options>"">. Alias:<FlagClass Prefixes:[""-"", ""--""] Name:""-help"">. >. <JoinedClass Prefixes:[""-""] Name:""-A-"" Group:<GroupClass Name:""<gfortran group>"">. >. Options are not in order! UNREACHABLE executed at /home/bgruber/dev/root/interpreter/llvm-project/llvm/lib/Option/OptTable.cpp:134! ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:10,reliability,doe,does,10,"The crash does not happen, when we build LLVM in Debug (`-DLLVM_BUILD_TYPE=Debug -DCMAKE_BUILD_TYPE=Debug`). However, then `rootcling_stage1` will crash later with:. ```. <FlagClass Prefixes:[""/"", ""-""] Name:""/?"" Group:<GroupClass Name:""<clang-cl options>"">. Alias:<FlagClass Prefixes:[""-"", ""--""] Name:""-help"">. >. <JoinedClass Prefixes:[""-""] Name:""-A-"" Group:<GroupClass Name:""<gfortran group>"">. >. Options are not in order! UNREACHABLE executed at /home/bgruber/dev/root/interpreter/llvm-project/llvm/lib/Option/OptTable.cpp:134! ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/issues/9036:303,usability,help,help,303,"The crash does not happen, when we build LLVM in Debug (`-DLLVM_BUILD_TYPE=Debug -DCMAKE_BUILD_TYPE=Debug`). However, then `rootcling_stage1` will crash later with:. ```. <FlagClass Prefixes:[""/"", ""-""] Name:""/?"" Group:<GroupClass Name:""<clang-cl options>"">. Alias:<FlagClass Prefixes:[""-"", ""--""] Name:""-help"">. >. <JoinedClass Prefixes:[""-""] Name:""-A-"" Group:<GroupClass Name:""<gfortran group>"">. >. Options are not in order! UNREACHABLE executed at /home/bgruber/dev/root/interpreter/llvm-project/llvm/lib/Option/OptTable.cpp:134! ```",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9036
https://github.com/root-project/root/pull/9037:11,deployability,build,build,11,@phsft-bot build with flags -DCMAKE_CXX_STANDARD=17 -Droot7=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9037
https://github.com/root-project/root/pull/9037:36,interoperability,platform,platforms,36,@osschar Note it is broken on other platforms!,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9037
https://github.com/root-project/root/pull/9040:27,reliability,doe,does,27,for whatever reason github does not let me re-request a review from @bernhardmgruber (clicking the button does nothing) :man_shrugging:,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9040
https://github.com/root-project/root/pull/9040:106,reliability,doe,does,106,for whatever reason github does not let me re-request a review from @bernhardmgruber (clicking the button does nothing) :man_shrugging:,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9040
https://github.com/root-project/root/pull/9040:56,safety,review,review,56,for whatever reason github does not let me re-request a review from @bernhardmgruber (clicking the button does nothing) :man_shrugging:,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9040
https://github.com/root-project/root/pull/9040:56,testability,review,review,56,for whatever reason github does not let me re-request a review from @bernhardmgruber (clicking the button does nothing) :man_shrugging:,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9040
https://github.com/root-project/root/pull/9045:4,availability,failur,failures,4,The failures are unrelated (caused by me merging https://github.com/root-project/root/pull/9041 prematurely) and are fixed by https://github.com/root-project/root/pull/9046,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9045
https://github.com/root-project/root/pull/9045:4,deployability,fail,failures,4,The failures are unrelated (caused by me merging https://github.com/root-project/root/pull/9041 prematurely) and are fixed by https://github.com/root-project/root/pull/9046,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9045
https://github.com/root-project/root/pull/9045:4,performance,failur,failures,4,The failures are unrelated (caused by me merging https://github.com/root-project/root/pull/9041 prematurely) and are fixed by https://github.com/root-project/root/pull/9046,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9045
https://github.com/root-project/root/pull/9045:4,reliability,fail,failures,4,The failures are unrelated (caused by me merging https://github.com/root-project/root/pull/9041 prematurely) and are fixed by https://github.com/root-project/root/pull/9046,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9045
https://github.com/root-project/root/pull/9046:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9046
https://github.com/root-project/root/pull/9046:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9046
https://github.com/root-project/root/pull/9048:11,deployability,build,build,11,@phsft-bot build with flags -DCMAKE_CXX_STANDARD=17 -Droot7=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9048
https://github.com/root-project/root/pull/9048:18,availability,error,error,18,"@alja here is the error:. ```. REveManager.cxx(1115,48): error C2440: '<function-style-cast>': cannot convert from 'nullptr' to 'time_t' . ```. see also https://godbolt.org/z/8crcWjYdh.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9048
https://github.com/root-project/root/pull/9048:57,availability,error,error,57,"@alja here is the error:. ```. REveManager.cxx(1115,48): error C2440: '<function-style-cast>': cannot convert from 'nullptr' to 'time_t' . ```. see also https://godbolt.org/z/8crcWjYdh.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9048
https://github.com/root-project/root/pull/9048:18,performance,error,error,18,"@alja here is the error:. ```. REveManager.cxx(1115,48): error C2440: '<function-style-cast>': cannot convert from 'nullptr' to 'time_t' . ```. see also https://godbolt.org/z/8crcWjYdh.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9048
https://github.com/root-project/root/pull/9048:57,performance,error,error,57,"@alja here is the error:. ```. REveManager.cxx(1115,48): error C2440: '<function-style-cast>': cannot convert from 'nullptr' to 'time_t' . ```. see also https://godbolt.org/z/8crcWjYdh.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9048
https://github.com/root-project/root/pull/9048:18,safety,error,error,18,"@alja here is the error:. ```. REveManager.cxx(1115,48): error C2440: '<function-style-cast>': cannot convert from 'nullptr' to 'time_t' . ```. see also https://godbolt.org/z/8crcWjYdh.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9048
https://github.com/root-project/root/pull/9048:57,safety,error,error,57,"@alja here is the error:. ```. REveManager.cxx(1115,48): error C2440: '<function-style-cast>': cannot convert from 'nullptr' to 'time_t' . ```. see also https://godbolt.org/z/8crcWjYdh.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9048
https://github.com/root-project/root/pull/9048:18,usability,error,error,18,"@alja here is the error:. ```. REveManager.cxx(1115,48): error C2440: '<function-style-cast>': cannot convert from 'nullptr' to 'time_t' . ```. see also https://godbolt.org/z/8crcWjYdh.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9048
https://github.com/root-project/root/pull/9048:57,usability,error,error,57,"@alja here is the error:. ```. REveManager.cxx(1115,48): error C2440: '<function-style-cast>': cannot convert from 'nullptr' to 'time_t' . ```. see also https://godbolt.org/z/8crcWjYdh.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9048
https://github.com/root-project/root/pull/9048:11,deployability,build,build,11,@phsft-bot build with flags -DCMAKE_CXX_STANDARD=17 -Droot7=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9048
https://github.com/root-project/root/pull/9048:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9048
https://github.com/root-project/root/pull/9049:11,deployability,build,build,11,@phsft-bot build,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9049
https://github.com/root-project/root/pull/9050:11,deployability,build,build,11,@phsft-bot build please,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9050
https://github.com/root-project/root/pull/9056:38,deployability,patch,patches,38,"Let's get this in (including v6-26-00-patches, please)!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9056
https://github.com/root-project/root/pull/9056:38,safety,patch,patches,38,"Let's get this in (including v6-26-00-patches, please)!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9056
https://github.com/root-project/root/pull/9056:38,security,patch,patches,38,"Let's get this in (including v6-26-00-patches, please)!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9056
https://github.com/root-project/root/pull/9065:11,deployability,build,build,11,@phsft-bot build also on ROOT-fedora34/default with flags -Dbuiltin_tbb=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9065
https://github.com/root-project/root/pull/9065:11,deployability,build,build,11,@phsft-bot build also on ROOT-fedora34/default with flags -Dbuiltin_tbb=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9065
https://github.com/root-project/root/pull/9065:11,deployability,build,build,11,@phsft-bot build also on ROOT-fedora34/default with flags -Dbuiltin_tbb=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9065
https://github.com/root-project/root/pull/9065:4,availability,failur,failures,4,"The failures on Fedora 34 don't seem to be related, but this commit actually fixes the warning seen in the linked PR https://github.com/root-project/root/pull/9066#issuecomment-933646782",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9065
https://github.com/root-project/root/pull/9065:4,deployability,fail,failures,4,"The failures on Fedora 34 don't seem to be related, but this commit actually fixes the warning seen in the linked PR https://github.com/root-project/root/pull/9066#issuecomment-933646782",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9065
https://github.com/root-project/root/pull/9065:4,performance,failur,failures,4,"The failures on Fedora 34 don't seem to be related, but this commit actually fixes the warning seen in the linked PR https://github.com/root-project/root/pull/9066#issuecomment-933646782",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9065
https://github.com/root-project/root/pull/9065:4,reliability,fail,failures,4,"The failures on Fedora 34 don't seem to be related, but this commit actually fixes the warning seen in the linked PR https://github.com/root-project/root/pull/9066#issuecomment-933646782",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9065
https://github.com/root-project/root/pull/9066:11,deployability,build,build,11,@phsft-bot build just on ROOT-fedora34/default with flags -Dbuiltin_tbb=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9066
https://github.com/root-project/root/pull/9067:163,energy efficiency,current,currently,163,"> We just have to watch out that `${TBB_INCLUDE_DIRS}` is never `$ROOTSYS/include` else we will not see any warning from any of ROOT's headers... But IIUC this is currently external or if builtin in `ginclude/`, so all good. Thanks for the review and for the comment. So should I add a test or not?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9067
https://github.com/root-project/root/pull/9067:240,safety,review,review,240,"> We just have to watch out that `${TBB_INCLUDE_DIRS}` is never `$ROOTSYS/include` else we will not see any warning from any of ROOT's headers... But IIUC this is currently external or if builtin in `ginclude/`, so all good. Thanks for the review and for the comment. So should I add a test or not?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9067
https://github.com/root-project/root/pull/9067:286,safety,test,test,286,"> We just have to watch out that `${TBB_INCLUDE_DIRS}` is never `$ROOTSYS/include` else we will not see any warning from any of ROOT's headers... But IIUC this is currently external or if builtin in `ginclude/`, so all good. Thanks for the review and for the comment. So should I add a test or not?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9067
https://github.com/root-project/root/pull/9067:240,testability,review,review,240,"> We just have to watch out that `${TBB_INCLUDE_DIRS}` is never `$ROOTSYS/include` else we will not see any warning from any of ROOT's headers... But IIUC this is currently external or if builtin in `ginclude/`, so all good. Thanks for the review and for the comment. So should I add a test or not?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9067
https://github.com/root-project/root/pull/9067:286,testability,test,test,286,"> We just have to watch out that `${TBB_INCLUDE_DIRS}` is never `$ROOTSYS/include` else we will not see any warning from any of ROOT's headers... But IIUC this is currently external or if builtin in `ginclude/`, so all good. Thanks for the review and for the comment. So should I add a test or not?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9067
https://github.com/root-project/root/pull/9068:0,availability,Error,Errors,0,Errors are unrelated. Merging.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9068
https://github.com/root-project/root/pull/9068:0,performance,Error,Errors,0,Errors are unrelated. Merging.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9068
https://github.com/root-project/root/pull/9068:0,safety,Error,Errors,0,Errors are unrelated. Merging.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9068
https://github.com/root-project/root/pull/9068:0,usability,Error,Errors,0,Errors are unrelated. Merging.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9068
https://github.com/root-project/root/issues/9069:0,safety,Reme,Remember,0,Remember to fix-up the `rfield_vector.cxx` unit test once this has been addressed.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9069
https://github.com/root-project/root/issues/9069:48,safety,test,test,48,Remember to fix-up the `rfield_vector.cxx` unit test once this has been addressed.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9069
https://github.com/root-project/root/issues/9069:43,testability,unit,unit,43,Remember to fix-up the `rfield_vector.cxx` unit test once this has been addressed.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9069
https://github.com/root-project/root/issues/9069:48,testability,test,test,48,Remember to fix-up the `rfield_vector.cxx` unit test once this has been addressed.,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9069
https://github.com/root-project/root/issues/9070:102,energy efficiency,measur,measurement,102,"Hi all,. My name is Alberto Prades Ibañez and I am an ATLAS PhD student who is doing a top quark mass measurement. For my analysis I have implemented a Likelihood Unfolding approach where I have a set of nuisance parameters for the uncertainties (with their gaussian priors) and a Nuisance Parameter for the Top MC mass (with a uniform/flat prior). While talking with the experts (Tomas Dado and @alexander-held ) I was told that the uniform prior had a bug. The bug is explained in this issue but it seems it was never been solved. I would to encourage the HistFactory/Root team to solve it because it is a really important feature for our analysis (and I am sure that also for many more analysis that will come in the future). Cheers,. Alberto Prades",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9070
https://github.com/root-project/root/issues/9070:213,modifiability,paramet,parameters,213,"Hi all,. My name is Alberto Prades Ibañez and I am an ATLAS PhD student who is doing a top quark mass measurement. For my analysis I have implemented a Likelihood Unfolding approach where I have a set of nuisance parameters for the uncertainties (with their gaussian priors) and a Nuisance Parameter for the Top MC mass (with a uniform/flat prior). While talking with the experts (Tomas Dado and @alexander-held ) I was told that the uniform prior had a bug. The bug is explained in this issue but it seems it was never been solved. I would to encourage the HistFactory/Root team to solve it because it is a really important feature for our analysis (and I am sure that also for many more analysis that will come in the future). Cheers,. Alberto Prades",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9070
https://github.com/root-project/root/issues/9070:290,modifiability,Paramet,Parameter,290,"Hi all,. My name is Alberto Prades Ibañez and I am an ATLAS PhD student who is doing a top quark mass measurement. For my analysis I have implemented a Likelihood Unfolding approach where I have a set of nuisance parameters for the uncertainties (with their gaussian priors) and a Nuisance Parameter for the Top MC mass (with a uniform/flat prior). While talking with the experts (Tomas Dado and @alexander-held ) I was told that the uniform prior had a bug. The bug is explained in this issue but it seems it was never been solved. I would to encourage the HistFactory/Root team to solve it because it is a really important feature for our analysis (and I am sure that also for many more analysis that will come in the future). Cheers,. Alberto Prades",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9070
https://github.com/root-project/root/issues/9070:28,reliability,Pra,Prades,28,"Hi all,. My name is Alberto Prades Ibañez and I am an ATLAS PhD student who is doing a top quark mass measurement. For my analysis I have implemented a Likelihood Unfolding approach where I have a set of nuisance parameters for the uncertainties (with their gaussian priors) and a Nuisance Parameter for the Top MC mass (with a uniform/flat prior). While talking with the experts (Tomas Dado and @alexander-held ) I was told that the uniform prior had a bug. The bug is explained in this issue but it seems it was never been solved. I would to encourage the HistFactory/Root team to solve it because it is a really important feature for our analysis (and I am sure that also for many more analysis that will come in the future). Cheers,. Alberto Prades",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9070
https://github.com/root-project/root/issues/9070:746,reliability,Pra,Prades,746,"Hi all,. My name is Alberto Prades Ibañez and I am an ATLAS PhD student who is doing a top quark mass measurement. For my analysis I have implemented a Likelihood Unfolding approach where I have a set of nuisance parameters for the uncertainties (with their gaussian priors) and a Nuisance Parameter for the Top MC mass (with a uniform/flat prior). While talking with the experts (Tomas Dado and @alexander-held ) I was told that the uniform prior had a bug. The bug is explained in this issue but it seems it was never been solved. I would to encourage the HistFactory/Root team to solve it because it is a really important feature for our analysis (and I am sure that also for many more analysis that will come in the future). Cheers,. Alberto Prades",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9070
https://github.com/root-project/root/issues/9070:575,security,team,team,575,"Hi all,. My name is Alberto Prades Ibañez and I am an ATLAS PhD student who is doing a top quark mass measurement. For my analysis I have implemented a Likelihood Unfolding approach where I have a set of nuisance parameters for the uncertainties (with their gaussian priors) and a Nuisance Parameter for the Top MC mass (with a uniform/flat prior). While talking with the experts (Tomas Dado and @alexander-held ) I was told that the uniform prior had a bug. The bug is explained in this issue but it seems it was never been solved. I would to encourage the HistFactory/Root team to solve it because it is a really important feature for our analysis (and I am sure that also for many more analysis that will come in the future). Cheers,. Alberto Prades",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9070
https://github.com/root-project/root/issues/9070:135,modifiability,paramet,parameter,135,"Hi all,. I am also interested in this. Is there perhaps a workaround that would enable us to have an unconstrained shape-only nuisance parameter? Best,. Miha",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9070
https://github.com/root-project/root/issues/9070:280,availability,consist,consistent,280,"Hi! Thanks for reminding me of this issue. I missed it last year, as it didn't get `RooFit/RooStats` label, sorry! I have opened a PR to fix the inconsistency:. https://github.com/root-project/root/pull/10525. And you are right, the label for constant nuisance parameters are not consistent on the XML and C++ side. As you noticed, in XML it's `NoConstraint` and in C++ `Measurement` class the label `NoSyst` is used, however, I would not change this in HistFactory because changing this longstanding naming might surprise users. Let me know if this is good for you and feel free to open new issues in case you have any other problems!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9070
https://github.com/root-project/root/issues/9070:371,energy efficiency,Measur,Measurement,371,"Hi! Thanks for reminding me of this issue. I missed it last year, as it didn't get `RooFit/RooStats` label, sorry! I have opened a PR to fix the inconsistency:. https://github.com/root-project/root/pull/10525. And you are right, the label for constant nuisance parameters are not consistent on the XML and C++ side. As you noticed, in XML it's `NoConstraint` and in C++ `Measurement` class the label `NoSyst` is used, however, I would not change this in HistFactory because changing this longstanding naming might surprise users. Let me know if this is good for you and feel free to open new issues in case you have any other problems!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9070
https://github.com/root-project/root/issues/9070:298,interoperability,XML,XML,298,"Hi! Thanks for reminding me of this issue. I missed it last year, as it didn't get `RooFit/RooStats` label, sorry! I have opened a PR to fix the inconsistency:. https://github.com/root-project/root/pull/10525. And you are right, the label for constant nuisance parameters are not consistent on the XML and C++ side. As you noticed, in XML it's `NoConstraint` and in C++ `Measurement` class the label `NoSyst` is used, however, I would not change this in HistFactory because changing this longstanding naming might surprise users. Let me know if this is good for you and feel free to open new issues in case you have any other problems!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9070
https://github.com/root-project/root/issues/9070:335,interoperability,XML,XML,335,"Hi! Thanks for reminding me of this issue. I missed it last year, as it didn't get `RooFit/RooStats` label, sorry! I have opened a PR to fix the inconsistency:. https://github.com/root-project/root/pull/10525. And you are right, the label for constant nuisance parameters are not consistent on the XML and C++ side. As you noticed, in XML it's `NoConstraint` and in C++ `Measurement` class the label `NoSyst` is used, however, I would not change this in HistFactory because changing this longstanding naming might surprise users. Let me know if this is good for you and feel free to open new issues in case you have any other problems!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9070
https://github.com/root-project/root/issues/9070:261,modifiability,paramet,parameters,261,"Hi! Thanks for reminding me of this issue. I missed it last year, as it didn't get `RooFit/RooStats` label, sorry! I have opened a PR to fix the inconsistency:. https://github.com/root-project/root/pull/10525. And you are right, the label for constant nuisance parameters are not consistent on the XML and C++ side. As you noticed, in XML it's `NoConstraint` and in C++ `Measurement` class the label `NoSyst` is used, however, I would not change this in HistFactory because changing this longstanding naming might surprise users. Let me know if this is good for you and feel free to open new issues in case you have any other problems!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9070
https://github.com/root-project/root/issues/9070:280,usability,consist,consistent,280,"Hi! Thanks for reminding me of this issue. I missed it last year, as it didn't get `RooFit/RooStats` label, sorry! I have opened a PR to fix the inconsistency:. https://github.com/root-project/root/pull/10525. And you are right, the label for constant nuisance parameters are not consistent on the XML and C++ side. As you noticed, in XML it's `NoConstraint` and in C++ `Measurement` class the label `NoSyst` is used, however, I would not change this in HistFactory because changing this longstanding naming might surprise users. Let me know if this is good for you and feel free to open new issues in case you have any other problems!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9070
https://github.com/root-project/root/issues/9070:523,usability,user,users,523,"Hi! Thanks for reminding me of this issue. I missed it last year, as it didn't get `RooFit/RooStats` label, sorry! I have opened a PR to fix the inconsistency:. https://github.com/root-project/root/pull/10525. And you are right, the label for constant nuisance parameters are not consistent on the XML and C++ side. As you noticed, in XML it's `NoConstraint` and in C++ `Measurement` class the label `NoSyst` is used, however, I would not change this in HistFactory because changing this longstanding naming might surprise users. Let me know if this is good for you and feel free to open new issues in case you have any other problems!",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9070
https://github.com/root-project/root/issues/9070:98,availability,consist,consistent,98,"Thanks a lot @guitargeek! > And you are right, the label for constant nuisance parameters are not consistent on the XML and C++ side. As you noticed, in XML it's NoConstraint and in C++ Measurement class the label NoSyst is used, however, I would not change this in HistFactory because changing this longstanding naming might surprise users. Sticking with the existing names sounds good to me, I wouldn't want to break existing code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9070
https://github.com/root-project/root/issues/9070:186,energy efficiency,Measur,Measurement,186,"Thanks a lot @guitargeek! > And you are right, the label for constant nuisance parameters are not consistent on the XML and C++ side. As you noticed, in XML it's NoConstraint and in C++ Measurement class the label NoSyst is used, however, I would not change this in HistFactory because changing this longstanding naming might surprise users. Sticking with the existing names sounds good to me, I wouldn't want to break existing code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9070
https://github.com/root-project/root/issues/9070:116,interoperability,XML,XML,116,"Thanks a lot @guitargeek! > And you are right, the label for constant nuisance parameters are not consistent on the XML and C++ side. As you noticed, in XML it's NoConstraint and in C++ Measurement class the label NoSyst is used, however, I would not change this in HistFactory because changing this longstanding naming might surprise users. Sticking with the existing names sounds good to me, I wouldn't want to break existing code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9070
https://github.com/root-project/root/issues/9070:153,interoperability,XML,XML,153,"Thanks a lot @guitargeek! > And you are right, the label for constant nuisance parameters are not consistent on the XML and C++ side. As you noticed, in XML it's NoConstraint and in C++ Measurement class the label NoSyst is used, however, I would not change this in HistFactory because changing this longstanding naming might surprise users. Sticking with the existing names sounds good to me, I wouldn't want to break existing code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9070
https://github.com/root-project/root/issues/9070:79,modifiability,paramet,parameters,79,"Thanks a lot @guitargeek! > And you are right, the label for constant nuisance parameters are not consistent on the XML and C++ side. As you noticed, in XML it's NoConstraint and in C++ Measurement class the label NoSyst is used, however, I would not change this in HistFactory because changing this longstanding naming might surprise users. Sticking with the existing names sounds good to me, I wouldn't want to break existing code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9070
https://github.com/root-project/root/issues/9070:98,usability,consist,consistent,98,"Thanks a lot @guitargeek! > And you are right, the label for constant nuisance parameters are not consistent on the XML and C++ side. As you noticed, in XML it's NoConstraint and in C++ Measurement class the label NoSyst is used, however, I would not change this in HistFactory because changing this longstanding naming might surprise users. Sticking with the existing names sounds good to me, I wouldn't want to break existing code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9070
https://github.com/root-project/root/issues/9070:335,usability,user,users,335,"Thanks a lot @guitargeek! > And you are right, the label for constant nuisance parameters are not consistent on the XML and C++ side. As you noticed, in XML it's NoConstraint and in C++ Measurement class the label NoSyst is used, however, I would not change this in HistFactory because changing this longstanding naming might surprise users. Sticking with the existing names sounds good to me, I wouldn't want to break existing code.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9070
https://github.com/root-project/root/issues/9072:178,modifiability,concern,concerns,178,"Hello,. I had a look at this and `davix` does not support any escaping for the userinfo segment. Adding support to this in `davix` is possible, but I have to raise the following concerns:. - Davix uses the `neon` library for the HTTP requests. - The `libneon` URI parsing has been duplicated from neon to davix. - I can extend the duplicated, now-in-Davix URI parsing and this should be good enough. - Problems might show up if we have places where `libneon` attempts to parse the URI again, using the `neon` URI parsing (instead of the Davix URI parsing). I've pushed the changes for this to the following branch: [davix/userinfo_escape_chars](https://github.com/cern-fts/davix/tree/userinfo_escape_chars). @Axel-Naumann Can we have a go with this branch?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9072
https://github.com/root-project/root/issues/9072:320,modifiability,exten,extend,320,"Hello,. I had a look at this and `davix` does not support any escaping for the userinfo segment. Adding support to this in `davix` is possible, but I have to raise the following concerns:. - Davix uses the `neon` library for the HTTP requests. - The `libneon` URI parsing has been duplicated from neon to davix. - I can extend the duplicated, now-in-Davix URI parsing and this should be good enough. - Problems might show up if we have places where `libneon` attempts to parse the URI again, using the `neon` URI parsing (instead of the Davix URI parsing). I've pushed the changes for this to the following branch: [davix/userinfo_escape_chars](https://github.com/cern-fts/davix/tree/userinfo_escape_chars). @Axel-Naumann Can we have a go with this branch?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9072
https://github.com/root-project/root/issues/9072:41,reliability,doe,does,41,"Hello,. I had a look at this and `davix` does not support any escaping for the userinfo segment. Adding support to this in `davix` is possible, but I have to raise the following concerns:. - Davix uses the `neon` library for the HTTP requests. - The `libneon` URI parsing has been duplicated from neon to davix. - I can extend the duplicated, now-in-Davix URI parsing and this should be good enough. - Problems might show up if we have places where `libneon` attempts to parse the URI again, using the `neon` URI parsing (instead of the Davix URI parsing). I've pushed the changes for this to the following branch: [davix/userinfo_escape_chars](https://github.com/cern-fts/davix/tree/userinfo_escape_chars). @Axel-Naumann Can we have a go with this branch?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9072
https://github.com/root-project/root/issues/9072:178,testability,concern,concerns,178,"Hello,. I had a look at this and `davix` does not support any escaping for the userinfo segment. Adding support to this in `davix` is possible, but I have to raise the following concerns:. - Davix uses the `neon` library for the HTTP requests. - The `libneon` URI parsing has been duplicated from neon to davix. - I can extend the duplicated, now-in-Davix URI parsing and this should be good enough. - Problems might show up if we have places where `libneon` attempts to parse the URI again, using the `neon` URI parsing (instead of the Davix URI parsing). I've pushed the changes for this to the following branch: [davix/userinfo_escape_chars](https://github.com/cern-fts/davix/tree/userinfo_escape_chars). @Axel-Naumann Can we have a go with this branch?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9072
https://github.com/root-project/root/issues/9072:50,usability,support,support,50,"Hello,. I had a look at this and `davix` does not support any escaping for the userinfo segment. Adding support to this in `davix` is possible, but I have to raise the following concerns:. - Davix uses the `neon` library for the HTTP requests. - The `libneon` URI parsing has been duplicated from neon to davix. - I can extend the duplicated, now-in-Davix URI parsing and this should be good enough. - Problems might show up if we have places where `libneon` attempts to parse the URI again, using the `neon` URI parsing (instead of the Davix URI parsing). I've pushed the changes for this to the following branch: [davix/userinfo_escape_chars](https://github.com/cern-fts/davix/tree/userinfo_escape_chars). @Axel-Naumann Can we have a go with this branch?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9072
https://github.com/root-project/root/issues/9072:79,usability,user,userinfo,79,"Hello,. I had a look at this and `davix` does not support any escaping for the userinfo segment. Adding support to this in `davix` is possible, but I have to raise the following concerns:. - Davix uses the `neon` library for the HTTP requests. - The `libneon` URI parsing has been duplicated from neon to davix. - I can extend the duplicated, now-in-Davix URI parsing and this should be good enough. - Problems might show up if we have places where `libneon` attempts to parse the URI again, using the `neon` URI parsing (instead of the Davix URI parsing). I've pushed the changes for this to the following branch: [davix/userinfo_escape_chars](https://github.com/cern-fts/davix/tree/userinfo_escape_chars). @Axel-Naumann Can we have a go with this branch?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9072
https://github.com/root-project/root/issues/9072:104,usability,support,support,104,"Hello,. I had a look at this and `davix` does not support any escaping for the userinfo segment. Adding support to this in `davix` is possible, but I have to raise the following concerns:. - Davix uses the `neon` library for the HTTP requests. - The `libneon` URI parsing has been duplicated from neon to davix. - I can extend the duplicated, now-in-Davix URI parsing and this should be good enough. - Problems might show up if we have places where `libneon` attempts to parse the URI again, using the `neon` URI parsing (instead of the Davix URI parsing). I've pushed the changes for this to the following branch: [davix/userinfo_escape_chars](https://github.com/cern-fts/davix/tree/userinfo_escape_chars). @Axel-Naumann Can we have a go with this branch?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9072
https://github.com/root-project/root/issues/9072:46,safety,test,tests,46,"Yes looks good, @mpatrascoiu ! I see you have tests - I don't think we can add much here :-)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9072
https://github.com/root-project/root/issues/9072:46,testability,test,tests,46,"Yes looks good, @mpatrascoiu ! I see you have tests - I don't think we can add much here :-)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/9072
https://github.com/root-project/root/pull/9074:33,availability,servic,services,33,"Tests pass [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9691/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/) and [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9690/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/), merging this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9074
https://github.com/root-project/root/pull/9074:226,availability,servic,services,226,"Tests pass [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9691/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/) and [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9690/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/), merging this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9074
https://github.com/root-project/root/pull/9074:33,deployability,servic,services,33,"Tests pass [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9691/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/) and [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9690/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/), merging this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9074
https://github.com/root-project/root/pull/9074:89,deployability,build,build,89,"Tests pass [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9691/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/) and [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9690/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/), merging this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9074
https://github.com/root-project/root/pull/9074:226,deployability,servic,services,226,"Tests pass [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9691/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/) and [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9690/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/), merging this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9074
https://github.com/root-project/root/pull/9074:282,deployability,build,build,282,"Tests pass [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9691/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/) and [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9690/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/), merging this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9074
https://github.com/root-project/root/pull/9074:33,integrability,servic,services,33,"Tests pass [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9691/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/) and [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9690/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/), merging this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9074
https://github.com/root-project/root/pull/9074:226,integrability,servic,services,226,"Tests pass [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9691/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/) and [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9690/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/), merging this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9074
https://github.com/root-project/root/pull/9074:33,modifiability,servic,services,33,"Tests pass [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9691/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/) and [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9690/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/), merging this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9074
https://github.com/root-project/root/pull/9074:226,modifiability,servic,services,226,"Tests pass [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9691/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/) and [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9690/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/), merging this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9074
https://github.com/root-project/root/pull/9074:0,safety,Test,Tests,0,"Tests pass [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9691/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/) and [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9690/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/), merging this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9074
https://github.com/root-project/root/pull/9074:100,safety,test,testReport,100,"Tests pass [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9691/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/) and [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9690/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/), merging this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9074
https://github.com/root-project/root/pull/9074:293,safety,test,testReport,293,"Tests pass [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9691/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/) and [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9690/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/), merging this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9074
https://github.com/root-project/root/pull/9074:0,testability,Test,Tests,0,"Tests pass [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9691/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/) and [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9690/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/), merging this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9074
https://github.com/root-project/root/pull/9074:100,testability,test,testReport,100,"Tests pass [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9691/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/) and [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9690/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/), merging this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9074
https://github.com/root-project/root/pull/9074:293,testability,test,testReport,293,"Tests pass [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9691/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/) and [here](https://lcgapp-services.cern.ch/root-jenkins/job/roottest-pullrequests-build/9690/testReport/projectroot.roottest.python/distrdf/roottest_python_distrdf_spark_test_definepersample/), merging this",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9074
https://github.com/root-project/root/pull/9078:15,deployability,build,build,15,"Thanks for the build system review @amadio, very useful comments. Indeed, I will rebase stuff into probably just two commits, one for RooFitZMQ and one for MultiProcess. Maybe one more for the builtins, but probably not, because they don't make sense without RooFitZMQ.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:28,safety,review,review,28,"Thanks for the build system review @amadio, very useful comments. Indeed, I will rebase stuff into probably just two commits, one for RooFitZMQ and one for MultiProcess. Maybe one more for the builtins, but probably not, because they don't make sense without RooFitZMQ.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:28,testability,review,review,28,"Thanks for the build system review @amadio, very useful comments. Indeed, I will rebase stuff into probably just two commits, one for RooFitZMQ and one for MultiProcess. Maybe one more for the builtins, but probably not, because they don't make sense without RooFitZMQ.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:150,deployability,build,build,150,"@lmoneta indeed, it looks like `-Droofit_multiprocess=OFF`, `-Dbuiltin_zeromq=OFF` and `-Dbuiltin_cppzmq=OFF` are used, at least on the mac11.0/cxx17 build log. Is there somewhere we can change this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:156,deployability,log,log,156,"@lmoneta indeed, it looks like `-Droofit_multiprocess=OFF`, `-Dbuiltin_zeromq=OFF` and `-Dbuiltin_cppzmq=OFF` are used, at least on the mac11.0/cxx17 build log. Is there somewhere we can change this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:156,safety,log,log,156,"@lmoneta indeed, it looks like `-Droofit_multiprocess=OFF`, `-Dbuiltin_zeromq=OFF` and `-Dbuiltin_cppzmq=OFF` are used, at least on the mac11.0/cxx17 build log. Is there somewhere we can change this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:156,security,log,log,156,"@lmoneta indeed, it looks like `-Droofit_multiprocess=OFF`, `-Dbuiltin_zeromq=OFF` and `-Dbuiltin_cppzmq=OFF` are used, at least on the mac11.0/cxx17 build log. Is there somewhere we can change this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:156,testability,log,log,156,"@lmoneta indeed, it looks like `-Droofit_multiprocess=OFF`, `-Dbuiltin_zeromq=OFF` and `-Dbuiltin_cppzmq=OFF` are used, at least on the mac11.0/cxx17 build log. Is there somewhere we can change this?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:61,availability,failur,failures,61,"@egpbos Please try again with the builtin enabled, the build failures are due to ZeroMQ not being found, since we have fail-on-missing=ON in our CI builds.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:55,deployability,build,build,55,"@egpbos Please try again with the builtin enabled, the build failures are due to ZeroMQ not being found, since we have fail-on-missing=ON in our CI builds.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:61,deployability,fail,failures,61,"@egpbos Please try again with the builtin enabled, the build failures are due to ZeroMQ not being found, since we have fail-on-missing=ON in our CI builds.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:119,deployability,fail,fail-on-missing,119,"@egpbos Please try again with the builtin enabled, the build failures are due to ZeroMQ not being found, since we have fail-on-missing=ON in our CI builds.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:148,deployability,build,builds,148,"@egpbos Please try again with the builtin enabled, the build failures are due to ZeroMQ not being found, since we have fail-on-missing=ON in our CI builds.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:61,performance,failur,failures,61,"@egpbos Please try again with the builtin enabled, the build failures are due to ZeroMQ not being found, since we have fail-on-missing=ON in our CI builds.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:61,reliability,fail,failures,61,"@egpbos Please try again with the builtin enabled, the build failures are due to ZeroMQ not being found, since we have fail-on-missing=ON in our CI builds.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:119,reliability,fail,fail-on-missing,119,"@egpbos Please try again with the builtin enabled, the build failures are due to ZeroMQ not being found, since we have fail-on-missing=ON in our CI builds.",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dbuiltin_zeromq=OFF -Dbuiltin_cppzmq=OFF,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build on windows10/cxx14,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build on ROOT-ubuntu16/nortcxxmod with flags -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build on ROOT-ubuntu16/nortcxxmod with flags -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build on ROOT-ubuntu2004/soversion with flags -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build on ROOT-ubuntu2004/soversion with flags -Droofit_multiprocess=ON -Dbuiltin_zeromq=ON -Dbuiltin_cppzmq=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:544,availability,error,error,544,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:563,availability,Error,Error,563,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1338,availability,error,errors,1338,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:33,deployability,updat,updates,33,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:102,deployability,build,build,102,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:299,deployability,instal,installed,299,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:505,deployability,configurat,configuration,505,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:519,deployability,fail,fails,519,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:578,deployability,modul,modules,578,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:742,deployability,configurat,configuration,742,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:837,deployability,configurat,configuration,837,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:961,deployability,instal,installation,961,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1050,deployability,contain,containing,1050,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1167,deployability,instal,installed,1167,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1183,deployability,Stack,Stack,1183,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1222,deployability,modul,modules,1222,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1593,deployability,build,build,1593,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1599,deployability,configurat,configuration,1599,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1737,deployability,configurat,configuration,1737,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1787,deployability,version,version,1787,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1839,deployability,automat,automatically,1839,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:505,integrability,configur,configuration,505,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:742,integrability,configur,configuration,742,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:837,integrability,configur,configuration,837,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1314,integrability,Configur,Configuring,1314,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1554,integrability,sub,subtleties,1554,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1599,integrability,configur,configuration,1599,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1737,integrability,configur,configuration,1737,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1787,integrability,version,version,1787,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1545,interoperability,specif,specific,1545,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:505,modifiability,configur,configuration,505,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:578,modifiability,modul,modules,578,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:734,modifiability,pac,package,734,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:742,modifiability,configur,configuration,742,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:829,modifiability,pac,package,829,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:837,modifiability,configur,configuration,837,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1130,modifiability,pac,package,1130,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1222,modifiability,modul,modules,1222,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1314,modifiability,Configur,Configuring,1314,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1599,modifiability,configur,configuration,1599,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1737,modifiability,configur,configuration,1737,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1787,modifiability,version,version,1787,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:544,performance,error,error,544,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:563,performance,Error,Error,563,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1338,performance,error,errors,1338,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:443,reliability,doe,doesn,443,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:519,reliability,fail,fails,519,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:33,safety,updat,updates,33,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:544,safety,error,error,544,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:563,safety,Error,Error,563,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:578,safety,modul,modules,578,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1222,safety,modul,modules,1222,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1338,safety,error,errors,1338,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:33,security,updat,updates,33,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:505,security,configur,configuration,505,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:742,security,configur,configuration,742,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:837,security,configur,configuration,837,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1314,security,Configur,Configuring,1314,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1599,security,configur,configuration,1599,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1737,security,configur,configuration,1737,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1839,testability,automat,automatically,1839,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:544,usability,error,error,544,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:563,usability,Error,Error,563,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:1338,usability,error,errors,1338,"Hi @egpbos, thanks a lot for the updates and great that everything now passes with the CI! I can also build ROOT on my system successfully with the new `zeromq` and `cppzmq` builtins that you introduced. However, I still have problems builting without the builtins, taking zeromq from the system. I installed zeromq from the GitHub master on my system, to make sure I have `zmq_ppoll`. One problem is that the check for the `zmq_ppoll` symbol doesn't seem to work (see inline comment above), and then the configuration fails with the following error:. ```. CMake Error at cmake/modules/SearchInstalledSoftware.cmake:17 (_find_package):. By not providing ""Findcppzmq.cmake"" in CMAKE_MODULE_PATH this project has. asked CMake to find a package configuration file provided by ""cppzmq"", but. CMake did not find one. Could not find a package configuration file provided by ""cppzmq"" with any. of the following names:. cppzmqConfig.cmake. cppzmq-config.cmake. Add the installation prefix of ""cppzmq"" to CMAKE_PREFIX_PATH or set. ""cppzmq_DIR"" to a directory containing one of the above files. If ""cppzmq"". provides a separate development package or SDK, be sure it has been. installed. Call Stack (most recent call first):. cmake/modules/SearchInstalledSoftware.cmake:1927 (find_package). CMakeLists.txt:245 (include). -- Configuring incomplete, errors occurred! ```. Is it really reasonable to expect a `cppzmqConfig.cmake` on the system, just for this `zmq.hxx` header that is most likely in the same directory as `zmq.h` anyway? Maybe there are some specific subtleties on my system that cause the build configuration not to work. Let's see with the CI when we disable builtins but enable roofit_multiprocess. What I would expect is that the configuration realized that an appropriate zeromq version is missing, and it switches to the builtins automatically right?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:48,deployability,build,build,48,"@guitargeek That would/should work if CI didn't build with fail-on-missing. Let's try turning that off then (I realize this completely changes the build setup, hopefully it doesn't break other things, but just to try out what @guitargeek is suggesting).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:59,deployability,fail,fail-on-missing,59,"@guitargeek That would/should work if CI didn't build with fail-on-missing. Let's try turning that off then (I realize this completely changes the build setup, hopefully it doesn't break other things, but just to try out what @guitargeek is suggesting).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:147,deployability,build,build,147,"@guitargeek That would/should work if CI didn't build with fail-on-missing. Let's try turning that off then (I realize this completely changes the build setup, hopefully it doesn't break other things, but just to try out what @guitargeek is suggesting).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:59,reliability,fail,fail-on-missing,59,"@guitargeek That would/should work if CI didn't build with fail-on-missing. Let's try turning that off then (I realize this completely changes the build setup, hopefully it doesn't break other things, but just to try out what @guitargeek is suggesting).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:173,reliability,doe,doesn,173,"@guitargeek That would/should work if CI didn't build with fail-on-missing. Let's try turning that off then (I realize this completely changes the build setup, hopefully it doesn't break other things, but just to try out what @guitargeek is suggesting).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:124,safety,compl,completely,124,"@guitargeek That would/should work if CI didn't build with fail-on-missing. Let's try turning that off then (I realize this completely changes the build setup, hopefully it doesn't break other things, but just to try out what @guitargeek is suggesting).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:124,security,compl,completely,124,"@guitargeek That would/should work if CI didn't build with fail-on-missing. Let's try turning that off then (I realize this completely changes the build setup, hopefully it doesn't break other things, but just to try out what @guitargeek is suggesting).",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dfail-on-missing=OFF,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dfail-on-missing=OFF,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dfail-on-missing=OFF,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dfail-on-missing=OFF,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dfail-on-missing=OFF,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:198,deployability,modul,module,198,"> Is it really reasonable to expect a cppzmqConfig.cmake on the system, just for this zmq.hxx header that is most likely in the same directory as zmq.h anyway? @guitargeek I have added a Findcppzmq module that should find the header. Could you check if it works for you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:198,modifiability,modul,module,198,"> Is it really reasonable to expect a cppzmqConfig.cmake on the system, just for this zmq.hxx header that is most likely in the same directory as zmq.h anyway? @guitargeek I have added a Findcppzmq module that should find the header. Could you check if it works for you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:198,safety,modul,module,198,"> Is it really reasonable to expect a cppzmqConfig.cmake on the system, just for this zmq.hxx header that is most likely in the same directory as zmq.h anyway? @guitargeek I have added a Findcppzmq module that should find the header. Could you check if it works for you?",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:11,deployability,build,build,11,@phsft-bot build with flags -Droofit_multiprocess=ON -Dfail-on-missing=OFF,MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:206,deployability,modul,module,206,"> > Is it really reasonable to expect a cppzmqConfig.cmake on the system, just for this zmq.hxx header that is most likely in the same directory as zmq.h anyway? > . > @guitargeek I have added a Findcppzmq module that should find the header. Could you check if it works for you? Thanks for the update! Yes, I confirm that things work for me now in all scenarios:. * switching builtins ON. * switching builtins OFF and having new zeromq with ppoll on the system. * switching builtins OFF, fail on missing OFF and having old zeromq on the system (it automatically switches builtins on then)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:294,deployability,updat,update,294,"> > Is it really reasonable to expect a cppzmqConfig.cmake on the system, just for this zmq.hxx header that is most likely in the same directory as zmq.h anyway? > . > @guitargeek I have added a Findcppzmq module that should find the header. Could you check if it works for you? Thanks for the update! Yes, I confirm that things work for me now in all scenarios:. * switching builtins ON. * switching builtins OFF and having new zeromq with ppoll on the system. * switching builtins OFF, fail on missing OFF and having old zeromq on the system (it automatically switches builtins on then)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
https://github.com/root-project/root/pull/9078:488,deployability,fail,fail,488,"> > Is it really reasonable to expect a cppzmqConfig.cmake on the system, just for this zmq.hxx header that is most likely in the same directory as zmq.h anyway? > . > @guitargeek I have added a Findcppzmq module that should find the header. Could you check if it works for you? Thanks for the update! Yes, I confirm that things work for me now in all scenarios:. * switching builtins ON. * switching builtins OFF and having new zeromq with ppoll on the system. * switching builtins OFF, fail on missing OFF and having old zeromq on the system (it automatically switches builtins on then)",MatchSource.ISSUE_COMMENT,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/9078
