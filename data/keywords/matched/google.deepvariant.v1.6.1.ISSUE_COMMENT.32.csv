id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/google/deepvariant/issues/849:24,usability,clear,clearing,24,"Hi @pichuan, thanks for clearing this up! When you get the chance, please let me know what to look for in the call_variants -output. Also, I'm not sure I understand the format, using zcat I get many very short lines. I see AD, DP and VAF but not sure how to read variant positions / probabilities. . Many thanks! . -Karoliina",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:514,deployability,fail,fails,514,"One thing I noticed is that you have multiple outputs: one generated with `--cpus=16` and one with `--cpus=19`. If you set cpus to 19 then the expected input to postprocesss should be `call_variants_output-[00000-00018]-of-00019.tfrecord.gz`. But in your [comment](https://github.com/google/deepvariant/issues/849#issuecomment-2222290171) you have `call_variants_output-[00000-00015]-of-00016.tfrecord.gz`. So, it looks like you had multiple runs with different cpus settings. This could be the reason postprocess fails. I suggest to clean the call_variants output or rerun it pointing to the different directory and then run postprocess with the **same number of CPUs**.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:77,energy efficiency,cpu,cpus,77,"One thing I noticed is that you have multiple outputs: one generated with `--cpus=16` and one with `--cpus=19`. If you set cpus to 19 then the expected input to postprocesss should be `call_variants_output-[00000-00018]-of-00019.tfrecord.gz`. But in your [comment](https://github.com/google/deepvariant/issues/849#issuecomment-2222290171) you have `call_variants_output-[00000-00015]-of-00016.tfrecord.gz`. So, it looks like you had multiple runs with different cpus settings. This could be the reason postprocess fails. I suggest to clean the call_variants output or rerun it pointing to the different directory and then run postprocess with the **same number of CPUs**.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:102,energy efficiency,cpu,cpus,102,"One thing I noticed is that you have multiple outputs: one generated with `--cpus=16` and one with `--cpus=19`. If you set cpus to 19 then the expected input to postprocesss should be `call_variants_output-[00000-00018]-of-00019.tfrecord.gz`. But in your [comment](https://github.com/google/deepvariant/issues/849#issuecomment-2222290171) you have `call_variants_output-[00000-00015]-of-00016.tfrecord.gz`. So, it looks like you had multiple runs with different cpus settings. This could be the reason postprocess fails. I suggest to clean the call_variants output or rerun it pointing to the different directory and then run postprocess with the **same number of CPUs**.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:123,energy efficiency,cpu,cpus,123,"One thing I noticed is that you have multiple outputs: one generated with `--cpus=16` and one with `--cpus=19`. If you set cpus to 19 then the expected input to postprocesss should be `call_variants_output-[00000-00018]-of-00019.tfrecord.gz`. But in your [comment](https://github.com/google/deepvariant/issues/849#issuecomment-2222290171) you have `call_variants_output-[00000-00015]-of-00016.tfrecord.gz`. So, it looks like you had multiple runs with different cpus settings. This could be the reason postprocess fails. I suggest to clean the call_variants output or rerun it pointing to the different directory and then run postprocess with the **same number of CPUs**.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:462,energy efficiency,cpu,cpus,462,"One thing I noticed is that you have multiple outputs: one generated with `--cpus=16` and one with `--cpus=19`. If you set cpus to 19 then the expected input to postprocesss should be `call_variants_output-[00000-00018]-of-00019.tfrecord.gz`. But in your [comment](https://github.com/google/deepvariant/issues/849#issuecomment-2222290171) you have `call_variants_output-[00000-00015]-of-00016.tfrecord.gz`. So, it looks like you had multiple runs with different cpus settings. This could be the reason postprocess fails. I suggest to clean the call_variants output or rerun it pointing to the different directory and then run postprocess with the **same number of CPUs**.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:664,energy efficiency,CPU,CPUs,664,"One thing I noticed is that you have multiple outputs: one generated with `--cpus=16` and one with `--cpus=19`. If you set cpus to 19 then the expected input to postprocesss should be `call_variants_output-[00000-00018]-of-00019.tfrecord.gz`. But in your [comment](https://github.com/google/deepvariant/issues/849#issuecomment-2222290171) you have `call_variants_output-[00000-00015]-of-00016.tfrecord.gz`. So, it looks like you had multiple runs with different cpus settings. This could be the reason postprocess fails. I suggest to clean the call_variants output or rerun it pointing to the different directory and then run postprocess with the **same number of CPUs**.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:77,performance,cpu,cpus,77,"One thing I noticed is that you have multiple outputs: one generated with `--cpus=16` and one with `--cpus=19`. If you set cpus to 19 then the expected input to postprocesss should be `call_variants_output-[00000-00018]-of-00019.tfrecord.gz`. But in your [comment](https://github.com/google/deepvariant/issues/849#issuecomment-2222290171) you have `call_variants_output-[00000-00015]-of-00016.tfrecord.gz`. So, it looks like you had multiple runs with different cpus settings. This could be the reason postprocess fails. I suggest to clean the call_variants output or rerun it pointing to the different directory and then run postprocess with the **same number of CPUs**.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:102,performance,cpu,cpus,102,"One thing I noticed is that you have multiple outputs: one generated with `--cpus=16` and one with `--cpus=19`. If you set cpus to 19 then the expected input to postprocesss should be `call_variants_output-[00000-00018]-of-00019.tfrecord.gz`. But in your [comment](https://github.com/google/deepvariant/issues/849#issuecomment-2222290171) you have `call_variants_output-[00000-00015]-of-00016.tfrecord.gz`. So, it looks like you had multiple runs with different cpus settings. This could be the reason postprocess fails. I suggest to clean the call_variants output or rerun it pointing to the different directory and then run postprocess with the **same number of CPUs**.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:123,performance,cpu,cpus,123,"One thing I noticed is that you have multiple outputs: one generated with `--cpus=16` and one with `--cpus=19`. If you set cpus to 19 then the expected input to postprocesss should be `call_variants_output-[00000-00018]-of-00019.tfrecord.gz`. But in your [comment](https://github.com/google/deepvariant/issues/849#issuecomment-2222290171) you have `call_variants_output-[00000-00015]-of-00016.tfrecord.gz`. So, it looks like you had multiple runs with different cpus settings. This could be the reason postprocess fails. I suggest to clean the call_variants output or rerun it pointing to the different directory and then run postprocess with the **same number of CPUs**.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:462,performance,cpu,cpus,462,"One thing I noticed is that you have multiple outputs: one generated with `--cpus=16` and one with `--cpus=19`. If you set cpus to 19 then the expected input to postprocesss should be `call_variants_output-[00000-00018]-of-00019.tfrecord.gz`. But in your [comment](https://github.com/google/deepvariant/issues/849#issuecomment-2222290171) you have `call_variants_output-[00000-00015]-of-00016.tfrecord.gz`. So, it looks like you had multiple runs with different cpus settings. This could be the reason postprocess fails. I suggest to clean the call_variants output or rerun it pointing to the different directory and then run postprocess with the **same number of CPUs**.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:664,performance,CPU,CPUs,664,"One thing I noticed is that you have multiple outputs: one generated with `--cpus=16` and one with `--cpus=19`. If you set cpus to 19 then the expected input to postprocesss should be `call_variants_output-[00000-00018]-of-00019.tfrecord.gz`. But in your [comment](https://github.com/google/deepvariant/issues/849#issuecomment-2222290171) you have `call_variants_output-[00000-00015]-of-00016.tfrecord.gz`. So, it looks like you had multiple runs with different cpus settings. This could be the reason postprocess fails. I suggest to clean the call_variants output or rerun it pointing to the different directory and then run postprocess with the **same number of CPUs**.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:514,reliability,fail,fails,514,"One thing I noticed is that you have multiple outputs: one generated with `--cpus=16` and one with `--cpus=19`. If you set cpus to 19 then the expected input to postprocesss should be `call_variants_output-[00000-00018]-of-00019.tfrecord.gz`. But in your [comment](https://github.com/google/deepvariant/issues/849#issuecomment-2222290171) you have `call_variants_output-[00000-00015]-of-00016.tfrecord.gz`. So, it looks like you had multiple runs with different cpus settings. This could be the reason postprocess fails. I suggest to clean the call_variants output or rerun it pointing to the different directory and then run postprocess with the **same number of CPUs**.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:152,safety,input,input,152,"One thing I noticed is that you have multiple outputs: one generated with `--cpus=16` and one with `--cpus=19`. If you set cpus to 19 then the expected input to postprocesss should be `call_variants_output-[00000-00018]-of-00019.tfrecord.gz`. But in your [comment](https://github.com/google/deepvariant/issues/849#issuecomment-2222290171) you have `call_variants_output-[00000-00015]-of-00016.tfrecord.gz`. So, it looks like you had multiple runs with different cpus settings. This could be the reason postprocess fails. I suggest to clean the call_variants output or rerun it pointing to the different directory and then run postprocess with the **same number of CPUs**.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:152,usability,input,input,152,"One thing I noticed is that you have multiple outputs: one generated with `--cpus=16` and one with `--cpus=19`. If you set cpus to 19 then the expected input to postprocesss should be `call_variants_output-[00000-00018]-of-00019.tfrecord.gz`. But in your [comment](https://github.com/google/deepvariant/issues/849#issuecomment-2222290171) you have `call_variants_output-[00000-00015]-of-00016.tfrecord.gz`. So, it looks like you had multiple runs with different cpus settings. This could be the reason postprocess fails. I suggest to clean the call_variants output or rerun it pointing to the different directory and then run postprocess with the **same number of CPUs**.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:398,deployability,instal,install,398,"Nice catch! Thank you! It does seem that there are different number of outputs, though I've (to my knowledge) only used the commands from the full run with 19 cpus and --dry_run=true. I've cleared the output directories and am running the full command from the beginning. Which nvidia-driver - cuda combination do you run deepvariant with? I'm looking into the gpu -problem, I'm thinking I need to install an older nvidia-driver and cuda. Currently the driver is 555.42.02, but looking at this https://docs.nvidia.com/deploy/cuda-compatibility/#id1 , it's not compatible with cuda 11.3.1 that the deepvariant:1.6.1-gpu is using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:518,deployability,deploy,deploy,518,"Nice catch! Thank you! It does seem that there are different number of outputs, though I've (to my knowledge) only used the commands from the full run with 19 cpus and --dry_run=true. I've cleared the output directories and am running the full command from the beginning. Which nvidia-driver - cuda combination do you run deepvariant with? I'm looking into the gpu -problem, I'm thinking I need to install an older nvidia-driver and cuda. Currently the driver is 555.42.02, but looking at this https://docs.nvidia.com/deploy/cuda-compatibility/#id1 , it's not compatible with cuda 11.3.1 that the deepvariant:1.6.1-gpu is using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:159,energy efficiency,cpu,cpus,159,"Nice catch! Thank you! It does seem that there are different number of outputs, though I've (to my knowledge) only used the commands from the full run with 19 cpus and --dry_run=true. I've cleared the output directories and am running the full command from the beginning. Which nvidia-driver - cuda combination do you run deepvariant with? I'm looking into the gpu -problem, I'm thinking I need to install an older nvidia-driver and cuda. Currently the driver is 555.42.02, but looking at this https://docs.nvidia.com/deploy/cuda-compatibility/#id1 , it's not compatible with cuda 11.3.1 that the deepvariant:1.6.1-gpu is using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:361,energy efficiency,gpu,gpu,361,"Nice catch! Thank you! It does seem that there are different number of outputs, though I've (to my knowledge) only used the commands from the full run with 19 cpus and --dry_run=true. I've cleared the output directories and am running the full command from the beginning. Which nvidia-driver - cuda combination do you run deepvariant with? I'm looking into the gpu -problem, I'm thinking I need to install an older nvidia-driver and cuda. Currently the driver is 555.42.02, but looking at this https://docs.nvidia.com/deploy/cuda-compatibility/#id1 , it's not compatible with cuda 11.3.1 that the deepvariant:1.6.1-gpu is using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:439,energy efficiency,Current,Currently,439,"Nice catch! Thank you! It does seem that there are different number of outputs, though I've (to my knowledge) only used the commands from the full run with 19 cpus and --dry_run=true. I've cleared the output directories and am running the full command from the beginning. Which nvidia-driver - cuda combination do you run deepvariant with? I'm looking into the gpu -problem, I'm thinking I need to install an older nvidia-driver and cuda. Currently the driver is 555.42.02, but looking at this https://docs.nvidia.com/deploy/cuda-compatibility/#id1 , it's not compatible with cuda 11.3.1 that the deepvariant:1.6.1-gpu is using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:615,energy efficiency,gpu,gpu,615,"Nice catch! Thank you! It does seem that there are different number of outputs, though I've (to my knowledge) only used the commands from the full run with 19 cpus and --dry_run=true. I've cleared the output directories and am running the full command from the beginning. Which nvidia-driver - cuda combination do you run deepvariant with? I'm looking into the gpu -problem, I'm thinking I need to install an older nvidia-driver and cuda. Currently the driver is 555.42.02, but looking at this https://docs.nvidia.com/deploy/cuda-compatibility/#id1 , it's not compatible with cuda 11.3.1 that the deepvariant:1.6.1-gpu is using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:530,interoperability,compatib,compatibility,530,"Nice catch! Thank you! It does seem that there are different number of outputs, though I've (to my knowledge) only used the commands from the full run with 19 cpus and --dry_run=true. I've cleared the output directories and am running the full command from the beginning. Which nvidia-driver - cuda combination do you run deepvariant with? I'm looking into the gpu -problem, I'm thinking I need to install an older nvidia-driver and cuda. Currently the driver is 555.42.02, but looking at this https://docs.nvidia.com/deploy/cuda-compatibility/#id1 , it's not compatible with cuda 11.3.1 that the deepvariant:1.6.1-gpu is using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:560,interoperability,compatib,compatible,560,"Nice catch! Thank you! It does seem that there are different number of outputs, though I've (to my knowledge) only used the commands from the full run with 19 cpus and --dry_run=true. I've cleared the output directories and am running the full command from the beginning. Which nvidia-driver - cuda combination do you run deepvariant with? I'm looking into the gpu -problem, I'm thinking I need to install an older nvidia-driver and cuda. Currently the driver is 555.42.02, but looking at this https://docs.nvidia.com/deploy/cuda-compatibility/#id1 , it's not compatible with cuda 11.3.1 that the deepvariant:1.6.1-gpu is using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:159,performance,cpu,cpus,159,"Nice catch! Thank you! It does seem that there are different number of outputs, though I've (to my knowledge) only used the commands from the full run with 19 cpus and --dry_run=true. I've cleared the output directories and am running the full command from the beginning. Which nvidia-driver - cuda combination do you run deepvariant with? I'm looking into the gpu -problem, I'm thinking I need to install an older nvidia-driver and cuda. Currently the driver is 555.42.02, but looking at this https://docs.nvidia.com/deploy/cuda-compatibility/#id1 , it's not compatible with cuda 11.3.1 that the deepvariant:1.6.1-gpu is using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:361,performance,gpu,gpu,361,"Nice catch! Thank you! It does seem that there are different number of outputs, though I've (to my knowledge) only used the commands from the full run with 19 cpus and --dry_run=true. I've cleared the output directories and am running the full command from the beginning. Which nvidia-driver - cuda combination do you run deepvariant with? I'm looking into the gpu -problem, I'm thinking I need to install an older nvidia-driver and cuda. Currently the driver is 555.42.02, but looking at this https://docs.nvidia.com/deploy/cuda-compatibility/#id1 , it's not compatible with cuda 11.3.1 that the deepvariant:1.6.1-gpu is using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:615,performance,gpu,gpu,615,"Nice catch! Thank you! It does seem that there are different number of outputs, though I've (to my knowledge) only used the commands from the full run with 19 cpus and --dry_run=true. I've cleared the output directories and am running the full command from the beginning. Which nvidia-driver - cuda combination do you run deepvariant with? I'm looking into the gpu -problem, I'm thinking I need to install an older nvidia-driver and cuda. Currently the driver is 555.42.02, but looking at this https://docs.nvidia.com/deploy/cuda-compatibility/#id1 , it's not compatible with cuda 11.3.1 that the deepvariant:1.6.1-gpu is using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:26,reliability,doe,does,26,"Nice catch! Thank you! It does seem that there are different number of outputs, though I've (to my knowledge) only used the commands from the full run with 19 cpus and --dry_run=true. I've cleared the output directories and am running the full command from the beginning. Which nvidia-driver - cuda combination do you run deepvariant with? I'm looking into the gpu -problem, I'm thinking I need to install an older nvidia-driver and cuda. Currently the driver is 555.42.02, but looking at this https://docs.nvidia.com/deploy/cuda-compatibility/#id1 , it's not compatible with cuda 11.3.1 that the deepvariant:1.6.1-gpu is using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:124,usability,command,commands,124,"Nice catch! Thank you! It does seem that there are different number of outputs, though I've (to my knowledge) only used the commands from the full run with 19 cpus and --dry_run=true. I've cleared the output directories and am running the full command from the beginning. Which nvidia-driver - cuda combination do you run deepvariant with? I'm looking into the gpu -problem, I'm thinking I need to install an older nvidia-driver and cuda. Currently the driver is 555.42.02, but looking at this https://docs.nvidia.com/deploy/cuda-compatibility/#id1 , it's not compatible with cuda 11.3.1 that the deepvariant:1.6.1-gpu is using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:189,usability,clear,cleared,189,"Nice catch! Thank you! It does seem that there are different number of outputs, though I've (to my knowledge) only used the commands from the full run with 19 cpus and --dry_run=true. I've cleared the output directories and am running the full command from the beginning. Which nvidia-driver - cuda combination do you run deepvariant with? I'm looking into the gpu -problem, I'm thinking I need to install an older nvidia-driver and cuda. Currently the driver is 555.42.02, but looking at this https://docs.nvidia.com/deploy/cuda-compatibility/#id1 , it's not compatible with cuda 11.3.1 that the deepvariant:1.6.1-gpu is using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:244,usability,command,command,244,"Nice catch! Thank you! It does seem that there are different number of outputs, though I've (to my knowledge) only used the commands from the full run with 19 cpus and --dry_run=true. I've cleared the output directories and am running the full command from the beginning. Which nvidia-driver - cuda combination do you run deepvariant with? I'm looking into the gpu -problem, I'm thinking I need to install an older nvidia-driver and cuda. Currently the driver is 555.42.02, but looking at this https://docs.nvidia.com/deploy/cuda-compatibility/#id1 , it's not compatible with cuda 11.3.1 that the deepvariant:1.6.1-gpu is using.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1210,availability,error,error,1210,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1271,availability,error,error,1271,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1457,availability,error,error,1457,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1631,availability,error,error,1631,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:43,deployability,pipelin,pipeline,43,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:508,deployability,contain,containers,508,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1150,deployability,log,logs,1150,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1637,deployability,log,log,1637,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:534,energy efficiency,gpu,gpus,534,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:576,energy efficiency,gpu,gpu,576,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:609,energy efficiency,gpu,gpu,609,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1496,energy efficiency,gpu,gpu,1496,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:43,integrability,pipelin,pipeline,43,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1216,integrability,messag,messages,1216,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1654,integrability,messag,message,1654,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:502,interoperability,share,share,502,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1216,interoperability,messag,messages,1216,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1654,interoperability,messag,message,1654,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:165,modifiability,interm,intermediate,165,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:432,modifiability,pac,packages,432,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1100,modifiability,interm,intermediate,1100,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:534,performance,gpu,gpus,534,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:576,performance,gpu,gpu,576,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:609,performance,gpu,gpu,609,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1210,performance,error,error,1210,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1271,performance,error,error,1271,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1457,performance,error,error,1457,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1496,performance,gpu,gpu,1496,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1631,performance,error,error,1631,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1150,safety,log,logs,1150,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1210,safety,error,error,1210,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1271,safety,error,error,1271,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1457,safety,error,error,1457,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1631,safety,error,error,1631,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1637,safety,log,log,1637,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:458,security,secur,security-opt,458,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1150,security,log,logs,1150,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1637,security,log,log,1637,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:487,testability,hook,hooks-dir,487,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:523,testability,hook,hooks,523,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1150,testability,log,logs,1150,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1637,testability,log,log,1637,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:256,usability,command,command,256,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1210,usability,error,error,1210,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1271,usability,error,error,1271,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1457,usability,error,error,1457,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:1631,usability,error,error,1631,"Hello @pichuan, I ran the full deepvariant pipeline after deleting all output directories from the previous run. It seems call_variants outputs only 16 files to the intermediate dir, whereas make_examples outputs 19 (with --num_shards 19). Here's the full command:. `podman run -it --rm -e LD_LIBRARY_PATH=/usr/bin:/usr/lib/nvidia:/usr/local/nvidia/:/usr/local/cuda-12.3/lib64:/usr/local/cuda-12.3/bin:/usr/local/lib/python3.8/dist-packages/tensorrt_libs/ --security-opt=label=disable --hooks-dir=/usr/share/containers/oci/hooks.d/ --gpus 1 -v /data:/data --device nvidia.com/gpu=all google/deepvariant:1.6.1-gpu /opt/deepvariant/bin/run_deepvariant --model_type=WGS --regions 'chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 chrX chrY chrM' --num_shards 19 --ref=/data/references/GCA_000001405.15_GRCh38_no_alt_analysis_set.fna.gz --reads=/data/bamfiles/sample1.E250013.L1.hg38.rg.bam --output_vcf=/data/variants/sample1.vcf.gz --output_gvcf=/data/variants/sample1.g.vcf.gz --intermediate_results_dir=/data/variants/sample1.intermediate --logging_dir=/data/variants/sample1.logs`. Adding the ld_library_path -argument gets rid of the error messages about libvinfer, however I still get the cuda error:. `2024-07-16 14:14:08.323907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:1278] could not retrieve CUDA device count: CUDA_ERROR_NOT_INITIALIZED: initialization error`. Although call_variants did use gpu and ran in about half an hour. Then postprocess_variants halts with:. `ValueError: ptrue must be between zero and one: nan`. (Full error log in the first message) I'll try to play around with --num_shards next.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:661,availability,error,error,661,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:135,deployability,version,version,135,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:337,deployability,version,version,337,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:398,deployability,updat,update,398,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:454,deployability,version,version,454,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:58,energy efficiency,predict,prediction,58,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:131,energy efficiency,GPU,GPU,131,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:214,energy efficiency,GPU,GPU,214,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:326,energy efficiency,GPU,GPU,326,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:615,energy efficiency,CPU,CPU,615,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:135,integrability,version,version,135,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:337,integrability,version,version,337,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:454,integrability,version,version,454,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:315,interoperability,compatib,compatible,315,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:499,interoperability,compatib,compatible,499,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:135,modifiability,version,version,135,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:337,modifiability,version,version,337,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:454,modifiability,version,version,454,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:131,performance,GPU,GPU,131,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:214,performance,GPU,GPU,214,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:326,performance,GPU,GPU,326,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:615,performance,CPU,CPU,615,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:661,performance,error,error,661,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:58,safety,predict,prediction,58,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:398,safety,updat,update,398,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:487,safety,test,test,487,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:661,safety,error,error,661,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:765,safety,input,input,765,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:398,security,updat,update,398,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:686,security,ident,identify,686,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:349,testability,understand,understand,349,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:487,testability,test,test,487,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:557,usability,confirm,confirm,557,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:661,usability,error,error,661,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:678,usability,help,help,678,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:765,usability,input,input,765,"Hi @karoliinas,. Given that you're having weird numerical prediction values from call_variants output, and that you mentioned your GPU version is newer that what we used in DeepVariant 1.6, I strongly suspect your GPU+DeepVariant setting is producing unexpected output. Would it be possible for you to:. 1. Use the compatible GPU driver version? (I understand this is annoying. We've made the CUDA update internally already, and it'll be out in the next version. But if it's possible to test with a compatible one, that might be easier for you). 2. Just to confirm whether it's the hardware issue: Can you run with CPU and see if it still crashes with the same error? That will help us identify whether it's the hardware, or actually something unexpected with your input file.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:177,availability,error,error,177,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:280,availability,avail,available,280,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:362,availability,avail,available,362,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:416,availability,down,download,416,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:634,availability,avail,available,634,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:213,deployability,version,versions,213,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:527,deployability,version,version,527,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:486,energy efficiency,estimat,estimate,486,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:670,energy efficiency,cpu,cpu,670,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:213,integrability,version,versions,213,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:527,integrability,version,version,527,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:213,modifiability,version,versions,213,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:527,modifiability,version,version,527,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:177,performance,error,error,177,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:670,performance,cpu,cpu,670,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:280,reliability,availab,available,280,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:362,reliability,availab,available,362,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:634,reliability,availab,available,634,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:177,safety,error,error,177,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:280,safety,avail,available,280,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:362,safety,avail,available,362,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:634,safety,avail,available,634,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:280,security,availab,available,280,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:362,security,availab,available,362,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:634,security,availab,available,634,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:177,usability,error,error,177,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:226,usability,support,supported,226,"Hi @pichuan, thanks for looking into this! And you're right, though changing the --num_shards to 16 did result in the same number of files from make_examples call_variants, the error remains. Which driver / cuda -versions are supported? The server I have is RHEL9, and the oldest available driver begins with 515 and cuda with 11.7. Would they do? I checked the available drivers from nvidia repo: https://developer.download.nvidia.com/compute/cuda/repos/rhel9/x86_64/. Do you have any estimate as to when the new deepvariant -version will be out, since it might be easier to wait than set up a new server (I'm not sure we have RHEL8 available). I'll try to run it with cpu for now, and will let you know how it goes. The funny thing is, I already processed 19 samples with this set up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:26,deployability,version,version,26,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:128,deployability,updat,update,128,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:228,deployability,version,version,228,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:472,deployability,upgrad,upgrade,472,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:524,deployability,continu,continue,524,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:555,deployability,version,version,555,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:21,energy efficiency,cpu,cpu,21,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:146,energy efficiency,gpu,gpu,146,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:183,energy efficiency,model,model,183,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:291,energy efficiency,current,current,291,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:502,energy efficiency,gpu,gpu,502,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:515,energy efficiency,cpu,cpu,515,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:542,energy efficiency,current,current,542,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:550,energy efficiency,cpu,cpu,550,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:26,integrability,version,version,26,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:228,integrability,version,version,228,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:370,integrability,coupl,couple,370,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:555,integrability,version,version,555,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:244,interoperability,compatib,compatible,244,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:26,modifiability,version,version,26,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:228,modifiability,version,version,228,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:370,modifiability,coupl,couple,370,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:472,modifiability,upgrad,upgrade,472,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:555,modifiability,version,version,555,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:21,performance,cpu,cpu,21,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:146,performance,gpu,gpu,146,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:502,performance,gpu,gpu,502,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:515,performance,cpu,cpu,515,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:550,performance,cpu,cpu,550,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:128,safety,updat,update,128,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:128,security,updat,update,128,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:183,security,model,model,183,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:370,testability,coupl,couple,370,"Hi again, indeed the cpu -version works. Boy am I glad there's no problem with the data! We'll have to wait for the deepvariant update to get the gpu going. Will it be using the same model, so that the samples processed the new version will be compatible with the samples processed with the current one? I'm getting new samples in every week, and we will have ~150 in a couple of months, so I'm interested as to not end up running them twice. The other option would be to upgrade the vm to one without gpu and more cpu:s to continue with the current cpu -version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:62,deployability,version,version,62,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:118,deployability,updat,updates,118,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:216,deployability,updat,update,216,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:231,deployability,version,version,231,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:251,deployability,version,version,251,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:362,deployability,build,building,362,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:384,deployability,version,version,384,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:403,deployability,releas,release,403,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:58,energy efficiency,CPU,CPU,58,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:114,energy efficiency,GPU,GPU,114,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:227,energy efficiency,GPU,GPU,227,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:62,integrability,version,version,62,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:231,integrability,version,version,231,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:251,integrability,version,version,251,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:384,integrability,version,version,384,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:62,modifiability,version,version,62,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:231,modifiability,version,version,231,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:251,modifiability,version,version,251,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:384,modifiability,version,version,384,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:58,performance,CPU,CPU,58,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:114,performance,GPU,GPU,114,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:227,performance,GPU,GPU,227,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:21,reliability,stabil,stability,21,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:118,safety,updat,updates,118,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:216,safety,updat,update,216,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:118,security,updat,updates,118,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:216,security,updat,update,216,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/849:417,usability,close,close,417,"Hi @karoliinas , for stability and reproducibility, using CPU version is likely the better way to go. In terms of GPU updates, in our developmental branch (https://github.com/google/deepvariant/tree/dev) we actually update the GPU version (and Ubuntu version). For example you can see: https://github.com/google/deepvariant/blob/dev/Dockerfile. But, we won't be building a new Docker version until next release. I'll close this now. Please let us know if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/849
https://github.com/google/deepvariant/issues/851:998,energy efficiency,Current,Currently,998,"@pioneer-pi,. Citing from [this source](https://www.ebi.ac.uk/training/online/courses/human-genetic-variation-introduction/variant-identification-and-analysis/). **What is variant calling?**. Variant calling is the process by which we identify variants from sequence data (Figure 11). * Step 1: Carry out whole genome or whole exome sequencing to create **FASTQ** files. * Step 2: Align the sequences to a reference genome, creating **BAM** or **CRAM** files. * Step 3: Identify where the aligned reads differ from the reference genome and write to a **VCF** file. For your issue:. DeepVariant is the software you use in step 3: "" Identify where the aligned reads differ from the reference genome and write to a VCF file."". So, if you want to use HG19 reference genome, you have to go back to step 2 and align your fastq file to HG19 reference genome to get a bam where the reads are aligned to HG19 reference. Then if you supply that bam of reads aligned to HG19 and HG19 reference, it will work. Currently, DeepVariant is saying that you have supplied it with a BAM where reads are **not** aligned to the reference you supplied. So it seems your bam is where reads are aligned to GRCh38 and you supplied HG19 as a reference, so it's not finding the contigs correctly. So, please align the reads to HG19 and provide the correct files and DeepVariant should work.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/851
https://github.com/google/deepvariant/issues/851:131,security,ident,identification-and-analysis,131,"@pioneer-pi,. Citing from [this source](https://www.ebi.ac.uk/training/online/courses/human-genetic-variation-introduction/variant-identification-and-analysis/). **What is variant calling?**. Variant calling is the process by which we identify variants from sequence data (Figure 11). * Step 1: Carry out whole genome or whole exome sequencing to create **FASTQ** files. * Step 2: Align the sequences to a reference genome, creating **BAM** or **CRAM** files. * Step 3: Identify where the aligned reads differ from the reference genome and write to a **VCF** file. For your issue:. DeepVariant is the software you use in step 3: "" Identify where the aligned reads differ from the reference genome and write to a VCF file."". So, if you want to use HG19 reference genome, you have to go back to step 2 and align your fastq file to HG19 reference genome to get a bam where the reads are aligned to HG19 reference. Then if you supply that bam of reads aligned to HG19 and HG19 reference, it will work. Currently, DeepVariant is saying that you have supplied it with a BAM where reads are **not** aligned to the reference you supplied. So it seems your bam is where reads are aligned to GRCh38 and you supplied HG19 as a reference, so it's not finding the contigs correctly. So, please align the reads to HG19 and provide the correct files and DeepVariant should work.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/851
https://github.com/google/deepvariant/issues/851:235,security,ident,identify,235,"@pioneer-pi,. Citing from [this source](https://www.ebi.ac.uk/training/online/courses/human-genetic-variation-introduction/variant-identification-and-analysis/). **What is variant calling?**. Variant calling is the process by which we identify variants from sequence data (Figure 11). * Step 1: Carry out whole genome or whole exome sequencing to create **FASTQ** files. * Step 2: Align the sequences to a reference genome, creating **BAM** or **CRAM** files. * Step 3: Identify where the aligned reads differ from the reference genome and write to a **VCF** file. For your issue:. DeepVariant is the software you use in step 3: "" Identify where the aligned reads differ from the reference genome and write to a VCF file."". So, if you want to use HG19 reference genome, you have to go back to step 2 and align your fastq file to HG19 reference genome to get a bam where the reads are aligned to HG19 reference. Then if you supply that bam of reads aligned to HG19 and HG19 reference, it will work. Currently, DeepVariant is saying that you have supplied it with a BAM where reads are **not** aligned to the reference you supplied. So it seems your bam is where reads are aligned to GRCh38 and you supplied HG19 as a reference, so it's not finding the contigs correctly. So, please align the reads to HG19 and provide the correct files and DeepVariant should work.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/851
https://github.com/google/deepvariant/issues/851:470,security,Ident,Identify,470,"@pioneer-pi,. Citing from [this source](https://www.ebi.ac.uk/training/online/courses/human-genetic-variation-introduction/variant-identification-and-analysis/). **What is variant calling?**. Variant calling is the process by which we identify variants from sequence data (Figure 11). * Step 1: Carry out whole genome or whole exome sequencing to create **FASTQ** files. * Step 2: Align the sequences to a reference genome, creating **BAM** or **CRAM** files. * Step 3: Identify where the aligned reads differ from the reference genome and write to a **VCF** file. For your issue:. DeepVariant is the software you use in step 3: "" Identify where the aligned reads differ from the reference genome and write to a VCF file."". So, if you want to use HG19 reference genome, you have to go back to step 2 and align your fastq file to HG19 reference genome to get a bam where the reads are aligned to HG19 reference. Then if you supply that bam of reads aligned to HG19 and HG19 reference, it will work. Currently, DeepVariant is saying that you have supplied it with a BAM where reads are **not** aligned to the reference you supplied. So it seems your bam is where reads are aligned to GRCh38 and you supplied HG19 as a reference, so it's not finding the contigs correctly. So, please align the reads to HG19 and provide the correct files and DeepVariant should work.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/851
https://github.com/google/deepvariant/issues/851:631,security,Ident,Identify,631,"@pioneer-pi,. Citing from [this source](https://www.ebi.ac.uk/training/online/courses/human-genetic-variation-introduction/variant-identification-and-analysis/). **What is variant calling?**. Variant calling is the process by which we identify variants from sequence data (Figure 11). * Step 1: Carry out whole genome or whole exome sequencing to create **FASTQ** files. * Step 2: Align the sequences to a reference genome, creating **BAM** or **CRAM** files. * Step 3: Identify where the aligned reads differ from the reference genome and write to a **VCF** file. For your issue:. DeepVariant is the software you use in step 3: "" Identify where the aligned reads differ from the reference genome and write to a VCF file."". So, if you want to use HG19 reference genome, you have to go back to step 2 and align your fastq file to HG19 reference genome to get a bam where the reads are aligned to HG19 reference. Then if you supply that bam of reads aligned to HG19 and HG19 reference, it will work. Currently, DeepVariant is saying that you have supplied it with a BAM where reads are **not** aligned to the reference you supplied. So it seems your bam is where reads are aligned to GRCh38 and you supplied HG19 as a reference, so it's not finding the contigs correctly. So, please align the reads to HG19 and provide the correct files and DeepVariant should work.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/851
https://github.com/google/deepvariant/issues/852:101,deployability,resourc,resources,101,"Hi @pioneer-pi,. You may find Platinum Genomes at [here](https://cloud.google.com/life-sciences/docs/resources/public-datasets/illumina-platinum-genomes).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:65,energy efficiency,cloud,cloud,65,"Hi @pioneer-pi,. You may find Platinum Genomes at [here](https://cloud.google.com/life-sciences/docs/resources/public-datasets/illumina-platinum-genomes).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:101,energy efficiency,resourc,resources,101,"Hi @pioneer-pi,. You may find Platinum Genomes at [here](https://cloud.google.com/life-sciences/docs/resources/public-datasets/illumina-platinum-genomes).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:111,integrability,pub,public-datasets,111,"Hi @pioneer-pi,. You may find Platinum Genomes at [here](https://cloud.google.com/life-sciences/docs/resources/public-datasets/illumina-platinum-genomes).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:101,performance,resourc,resources,101,"Hi @pioneer-pi,. You may find Platinum Genomes at [here](https://cloud.google.com/life-sciences/docs/resources/public-datasets/illumina-platinum-genomes).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:101,safety,resourc,resources,101,"Hi @pioneer-pi,. You may find Platinum Genomes at [here](https://cloud.google.com/life-sciences/docs/resources/public-datasets/illumina-platinum-genomes).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:101,testability,resourc,resources,101,"Hi @pioneer-pi,. You may find Platinum Genomes at [here](https://cloud.google.com/life-sciences/docs/resources/public-datasets/illumina-platinum-genomes).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:45,deployability,version,version,45,"@akolesnikov Sorry, I don't find the special version of reference, fastq, vcf in your essay in Platinume Genome Project NA12878. In the given link, I find different version of data. Can you support me the special version of data. Thank you very much!!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:165,deployability,version,version,165,"@akolesnikov Sorry, I don't find the special version of reference, fastq, vcf in your essay in Platinume Genome Project NA12878. In the given link, I find different version of data. Can you support me the special version of data. Thank you very much!!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:213,deployability,version,version,213,"@akolesnikov Sorry, I don't find the special version of reference, fastq, vcf in your essay in Platinume Genome Project NA12878. In the given link, I find different version of data. Can you support me the special version of data. Thank you very much!!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:45,integrability,version,version,45,"@akolesnikov Sorry, I don't find the special version of reference, fastq, vcf in your essay in Platinume Genome Project NA12878. In the given link, I find different version of data. Can you support me the special version of data. Thank you very much!!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:165,integrability,version,version,165,"@akolesnikov Sorry, I don't find the special version of reference, fastq, vcf in your essay in Platinume Genome Project NA12878. In the given link, I find different version of data. Can you support me the special version of data. Thank you very much!!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:213,integrability,version,version,213,"@akolesnikov Sorry, I don't find the special version of reference, fastq, vcf in your essay in Platinume Genome Project NA12878. In the given link, I find different version of data. Can you support me the special version of data. Thank you very much!!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:45,modifiability,version,version,45,"@akolesnikov Sorry, I don't find the special version of reference, fastq, vcf in your essay in Platinume Genome Project NA12878. In the given link, I find different version of data. Can you support me the special version of data. Thank you very much!!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:165,modifiability,version,version,165,"@akolesnikov Sorry, I don't find the special version of reference, fastq, vcf in your essay in Platinume Genome Project NA12878. In the given link, I find different version of data. Can you support me the special version of data. Thank you very much!!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:213,modifiability,version,version,213,"@akolesnikov Sorry, I don't find the special version of reference, fastq, vcf in your essay in Platinume Genome Project NA12878. In the given link, I find different version of data. Can you support me the special version of data. Thank you very much!!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:190,usability,support,support,190,"@akolesnikov Sorry, I don't find the special version of reference, fastq, vcf in your essay in Platinume Genome Project NA12878. In the given link, I find different version of data. Can you support me the special version of data. Thank you very much!!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:127,deployability,updat,updated,127,"@pioneer-pi , the deepvariant manuscript from six years ago. Since then, the benchmarking methods, tools and data all has been updated. The latest version of bechmarking is GIAB v4.2.1 for HG002 that you can find [here](https://ftp.ncbi.nlm.nih.gov/ReferenceSamples/giab/release/AshkenazimTrio/HG002_NA24385_son/NISTv4.2.1/). I would suggest reading the following manuscripts if you are interested to learn about these benchmarks:. 1) https://cell.com/cell-genomics/fulltext/S2666-979X(22)00058-1. 2) https://www.cell.com/cell-genomics/fulltext/S2666-979X-2200057-X. 3) https://www.biorxiv.org/content/10.1101/2020.12.11.422022v1.abstract. The latest data can be found in: . https://storage.googleapis.com/brain-genomics-public/research/sequencing/fastq/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch37/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch38/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:147,deployability,version,version,147,"@pioneer-pi , the deepvariant manuscript from six years ago. Since then, the benchmarking methods, tools and data all has been updated. The latest version of bechmarking is GIAB v4.2.1 for HG002 that you can find [here](https://ftp.ncbi.nlm.nih.gov/ReferenceSamples/giab/release/AshkenazimTrio/HG002_NA24385_son/NISTv4.2.1/). I would suggest reading the following manuscripts if you are interested to learn about these benchmarks:. 1) https://cell.com/cell-genomics/fulltext/S2666-979X(22)00058-1. 2) https://www.cell.com/cell-genomics/fulltext/S2666-979X-2200057-X. 3) https://www.biorxiv.org/content/10.1101/2020.12.11.422022v1.abstract. The latest data can be found in: . https://storage.googleapis.com/brain-genomics-public/research/sequencing/fastq/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch37/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch38/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:271,deployability,releas,release,271,"@pioneer-pi , the deepvariant manuscript from six years ago. Since then, the benchmarking methods, tools and data all has been updated. The latest version of bechmarking is GIAB v4.2.1 for HG002 that you can find [here](https://ftp.ncbi.nlm.nih.gov/ReferenceSamples/giab/release/AshkenazimTrio/HG002_NA24385_son/NISTv4.2.1/). I would suggest reading the following manuscripts if you are interested to learn about these benchmarks:. 1) https://cell.com/cell-genomics/fulltext/S2666-979X(22)00058-1. 2) https://www.cell.com/cell-genomics/fulltext/S2666-979X-2200057-X. 3) https://www.biorxiv.org/content/10.1101/2020.12.11.422022v1.abstract. The latest data can be found in: . https://storage.googleapis.com/brain-genomics-public/research/sequencing/fastq/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch37/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch38/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:147,integrability,version,version,147,"@pioneer-pi , the deepvariant manuscript from six years ago. Since then, the benchmarking methods, tools and data all has been updated. The latest version of bechmarking is GIAB v4.2.1 for HG002 that you can find [here](https://ftp.ncbi.nlm.nih.gov/ReferenceSamples/giab/release/AshkenazimTrio/HG002_NA24385_son/NISTv4.2.1/). I would suggest reading the following manuscripts if you are interested to learn about these benchmarks:. 1) https://cell.com/cell-genomics/fulltext/S2666-979X(22)00058-1. 2) https://www.cell.com/cell-genomics/fulltext/S2666-979X-2200057-X. 3) https://www.biorxiv.org/content/10.1101/2020.12.11.422022v1.abstract. The latest data can be found in: . https://storage.googleapis.com/brain-genomics-public/research/sequencing/fastq/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch37/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch38/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:630,integrability,abstract,abstract,630,"@pioneer-pi , the deepvariant manuscript from six years ago. Since then, the benchmarking methods, tools and data all has been updated. The latest version of bechmarking is GIAB v4.2.1 for HG002 that you can find [here](https://ftp.ncbi.nlm.nih.gov/ReferenceSamples/giab/release/AshkenazimTrio/HG002_NA24385_son/NISTv4.2.1/). I would suggest reading the following manuscripts if you are interested to learn about these benchmarks:. 1) https://cell.com/cell-genomics/fulltext/S2666-979X(22)00058-1. 2) https://www.cell.com/cell-genomics/fulltext/S2666-979X-2200057-X. 3) https://www.biorxiv.org/content/10.1101/2020.12.11.422022v1.abstract. The latest data can be found in: . https://storage.googleapis.com/brain-genomics-public/research/sequencing/fastq/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch37/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch38/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:721,integrability,pub,public,721,"@pioneer-pi , the deepvariant manuscript from six years ago. Since then, the benchmarking methods, tools and data all has been updated. The latest version of bechmarking is GIAB v4.2.1 for HG002 that you can find [here](https://ftp.ncbi.nlm.nih.gov/ReferenceSamples/giab/release/AshkenazimTrio/HG002_NA24385_son/NISTv4.2.1/). I would suggest reading the following manuscripts if you are interested to learn about these benchmarks:. 1) https://cell.com/cell-genomics/fulltext/S2666-979X(22)00058-1. 2) https://www.cell.com/cell-genomics/fulltext/S2666-979X-2200057-X. 3) https://www.biorxiv.org/content/10.1101/2020.12.11.422022v1.abstract. The latest data can be found in: . https://storage.googleapis.com/brain-genomics-public/research/sequencing/fastq/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch37/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch38/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:802,integrability,pub,public,802,"@pioneer-pi , the deepvariant manuscript from six years ago. Since then, the benchmarking methods, tools and data all has been updated. The latest version of bechmarking is GIAB v4.2.1 for HG002 that you can find [here](https://ftp.ncbi.nlm.nih.gov/ReferenceSamples/giab/release/AshkenazimTrio/HG002_NA24385_son/NISTv4.2.1/). I would suggest reading the following manuscripts if you are interested to learn about these benchmarks:. 1) https://cell.com/cell-genomics/fulltext/S2666-979X(22)00058-1. 2) https://www.cell.com/cell-genomics/fulltext/S2666-979X-2200057-X. 3) https://www.biorxiv.org/content/10.1101/2020.12.11.422022v1.abstract. The latest data can be found in: . https://storage.googleapis.com/brain-genomics-public/research/sequencing/fastq/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch37/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch38/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:884,integrability,pub,public,884,"@pioneer-pi , the deepvariant manuscript from six years ago. Since then, the benchmarking methods, tools and data all has been updated. The latest version of bechmarking is GIAB v4.2.1 for HG002 that you can find [here](https://ftp.ncbi.nlm.nih.gov/ReferenceSamples/giab/release/AshkenazimTrio/HG002_NA24385_son/NISTv4.2.1/). I would suggest reading the following manuscripts if you are interested to learn about these benchmarks:. 1) https://cell.com/cell-genomics/fulltext/S2666-979X(22)00058-1. 2) https://www.cell.com/cell-genomics/fulltext/S2666-979X-2200057-X. 3) https://www.biorxiv.org/content/10.1101/2020.12.11.422022v1.abstract. The latest data can be found in: . https://storage.googleapis.com/brain-genomics-public/research/sequencing/fastq/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch37/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch38/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:147,modifiability,version,version,147,"@pioneer-pi , the deepvariant manuscript from six years ago. Since then, the benchmarking methods, tools and data all has been updated. The latest version of bechmarking is GIAB v4.2.1 for HG002 that you can find [here](https://ftp.ncbi.nlm.nih.gov/ReferenceSamples/giab/release/AshkenazimTrio/HG002_NA24385_son/NISTv4.2.1/). I would suggest reading the following manuscripts if you are interested to learn about these benchmarks:. 1) https://cell.com/cell-genomics/fulltext/S2666-979X(22)00058-1. 2) https://www.cell.com/cell-genomics/fulltext/S2666-979X-2200057-X. 3) https://www.biorxiv.org/content/10.1101/2020.12.11.422022v1.abstract. The latest data can be found in: . https://storage.googleapis.com/brain-genomics-public/research/sequencing/fastq/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch37/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch38/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:630,modifiability,abstract,abstract,630,"@pioneer-pi , the deepvariant manuscript from six years ago. Since then, the benchmarking methods, tools and data all has been updated. The latest version of bechmarking is GIAB v4.2.1 for HG002 that you can find [here](https://ftp.ncbi.nlm.nih.gov/ReferenceSamples/giab/release/AshkenazimTrio/HG002_NA24385_son/NISTv4.2.1/). I would suggest reading the following manuscripts if you are interested to learn about these benchmarks:. 1) https://cell.com/cell-genomics/fulltext/S2666-979X(22)00058-1. 2) https://www.cell.com/cell-genomics/fulltext/S2666-979X-2200057-X. 3) https://www.biorxiv.org/content/10.1101/2020.12.11.422022v1.abstract. The latest data can be found in: . https://storage.googleapis.com/brain-genomics-public/research/sequencing/fastq/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch37/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch38/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:594,performance,content,content,594,"@pioneer-pi , the deepvariant manuscript from six years ago. Since then, the benchmarking methods, tools and data all has been updated. The latest version of bechmarking is GIAB v4.2.1 for HG002 that you can find [here](https://ftp.ncbi.nlm.nih.gov/ReferenceSamples/giab/release/AshkenazimTrio/HG002_NA24385_son/NISTv4.2.1/). I would suggest reading the following manuscripts if you are interested to learn about these benchmarks:. 1) https://cell.com/cell-genomics/fulltext/S2666-979X(22)00058-1. 2) https://www.cell.com/cell-genomics/fulltext/S2666-979X-2200057-X. 3) https://www.biorxiv.org/content/10.1101/2020.12.11.422022v1.abstract. The latest data can be found in: . https://storage.googleapis.com/brain-genomics-public/research/sequencing/fastq/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch37/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch38/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:127,safety,updat,updated,127,"@pioneer-pi , the deepvariant manuscript from six years ago. Since then, the benchmarking methods, tools and data all has been updated. The latest version of bechmarking is GIAB v4.2.1 for HG002 that you can find [here](https://ftp.ncbi.nlm.nih.gov/ReferenceSamples/giab/release/AshkenazimTrio/HG002_NA24385_son/NISTv4.2.1/). I would suggest reading the following manuscripts if you are interested to learn about these benchmarks:. 1) https://cell.com/cell-genomics/fulltext/S2666-979X(22)00058-1. 2) https://www.cell.com/cell-genomics/fulltext/S2666-979X-2200057-X. 3) https://www.biorxiv.org/content/10.1101/2020.12.11.422022v1.abstract. The latest data can be found in: . https://storage.googleapis.com/brain-genomics-public/research/sequencing/fastq/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch37/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch38/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:127,security,updat,updated,127,"@pioneer-pi , the deepvariant manuscript from six years ago. Since then, the benchmarking methods, tools and data all has been updated. The latest version of bechmarking is GIAB v4.2.1 for HG002 that you can find [here](https://ftp.ncbi.nlm.nih.gov/ReferenceSamples/giab/release/AshkenazimTrio/HG002_NA24385_son/NISTv4.2.1/). I would suggest reading the following manuscripts if you are interested to learn about these benchmarks:. 1) https://cell.com/cell-genomics/fulltext/S2666-979X(22)00058-1. 2) https://www.cell.com/cell-genomics/fulltext/S2666-979X-2200057-X. 3) https://www.biorxiv.org/content/10.1101/2020.12.11.422022v1.abstract. The latest data can be found in: . https://storage.googleapis.com/brain-genomics-public/research/sequencing/fastq/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch37/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch38/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:99,usability,tool,tools,99,"@pioneer-pi , the deepvariant manuscript from six years ago. Since then, the benchmarking methods, tools and data all has been updated. The latest version of bechmarking is GIAB v4.2.1 for HG002 that you can find [here](https://ftp.ncbi.nlm.nih.gov/ReferenceSamples/giab/release/AshkenazimTrio/HG002_NA24385_son/NISTv4.2.1/). I would suggest reading the following manuscripts if you are interested to learn about these benchmarks:. 1) https://cell.com/cell-genomics/fulltext/S2666-979X(22)00058-1. 2) https://www.cell.com/cell-genomics/fulltext/S2666-979X-2200057-X. 3) https://www.biorxiv.org/content/10.1101/2020.12.11.422022v1.abstract. The latest data can be found in: . https://storage.googleapis.com/brain-genomics-public/research/sequencing/fastq/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch37/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch38/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:401,usability,learn,learn,401,"@pioneer-pi , the deepvariant manuscript from six years ago. Since then, the benchmarking methods, tools and data all has been updated. The latest version of bechmarking is GIAB v4.2.1 for HG002 that you can find [here](https://ftp.ncbi.nlm.nih.gov/ReferenceSamples/giab/release/AshkenazimTrio/HG002_NA24385_son/NISTv4.2.1/). I would suggest reading the following manuscripts if you are interested to learn about these benchmarks:. 1) https://cell.com/cell-genomics/fulltext/S2666-979X(22)00058-1. 2) https://www.cell.com/cell-genomics/fulltext/S2666-979X-2200057-X. 3) https://www.biorxiv.org/content/10.1101/2020.12.11.422022v1.abstract. The latest data can be found in: . https://storage.googleapis.com/brain-genomics-public/research/sequencing/fastq/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch37/. https://storage.googleapis.com/brain-genomics-public/research/sequencing/grch38/.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/852:21,usability,close,close,21,"@pioneer-pi , I will close this issue. Please feel free to reopen if you have further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/852
https://github.com/google/deepvariant/issues/853:55,availability,down,downloaded,55,"@poddarharsh15, can you please check if the files were downloaded correctly and if their sizes look good. The case studies are designed in a way that you can simply copy-paste the commands and it should work. I just tested the case study and it worked on my end.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:216,safety,test,tested,216,"@poddarharsh15, can you please check if the files were downloaded correctly and if their sizes look good. The case studies are designed in a way that you can simply copy-paste the commands and it should work. I just tested the case study and it worked on my end.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:158,testability,simpl,simply,158,"@poddarharsh15, can you please check if the files were downloaded correctly and if their sizes look good. The case studies are designed in a way that you can simply copy-paste the commands and it should work. I just tested the case study and it worked on my end.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:216,testability,test,tested,216,"@poddarharsh15, can you please check if the files were downloaded correctly and if their sizes look good. The case studies are designed in a way that you can simply copy-paste the commands and it should work. I just tested the case study and it worked on my end.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:158,usability,simpl,simply,158,"@poddarharsh15, can you please check if the files were downloaded correctly and if their sizes look good. The case studies are designed in a way that you can simply copy-paste the commands and it should work. I just tested the case study and it worked on my end.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:180,usability,command,commands,180,"@poddarharsh15, can you please check if the files were downloaded correctly and if their sizes look good. The case studies are designed in a way that you can simply copy-paste the commands and it should work. I just tested the case study and it worked on my end.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:25,usability,help,help,25,It worked thanks for the help :)),MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:74,deployability,modul,module,74,"Hi @kishwarshafin,. I am trying to add --haploid_contigs=""chrX,chrY"" in a module from nf-core that I am using. However, when running the command line, I am only detecting chrX variants from the test data. When I try to run the command using a BED file with only chrY, I get an empty VCF file with headers as the result. I also tried using --regions as a parameter, but without success. Could you please suggest some ideas on how to resolve this issue? Thank you for your assistance. ```. /opt/deepvariant/bin/run_deepvariant \. --ref=GRCh38_no_alt_analysis_set.fasta \. --reads=sample1-lane_1.converted.cram \. --output_vcf=sample1-lane_1.deepvariant.vcf.gz \. --output_gvcf=sample1-lane_1.deepvariant.g.vcf.gz \. --haploid_contigs=""chrX,chrY"" \ . --regions=""chrX chrY"" \ . --model_type PACBIO \. --regions=chrX_10001-44821.bed \. --intermediate_results_dir=tmp \. --num_shards=12. ```. [chrY.vcf.gz](https://github.com/user-attachments/files/16334591/chrY.vcf.gz). [sample1-lane_1.deepvariant.vcf.gz](https://github.com/user-attachments/files/16334613/sample1-lane_1.deepvariant.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:89,energy efficiency,core,core,89,"Hi @kishwarshafin,. I am trying to add --haploid_contigs=""chrX,chrY"" in a module from nf-core that I am using. However, when running the command line, I am only detecting chrX variants from the test data. When I try to run the command using a BED file with only chrY, I get an empty VCF file with headers as the result. I also tried using --regions as a parameter, but without success. Could you please suggest some ideas on how to resolve this issue? Thank you for your assistance. ```. /opt/deepvariant/bin/run_deepvariant \. --ref=GRCh38_no_alt_analysis_set.fasta \. --reads=sample1-lane_1.converted.cram \. --output_vcf=sample1-lane_1.deepvariant.vcf.gz \. --output_gvcf=sample1-lane_1.deepvariant.g.vcf.gz \. --haploid_contigs=""chrX,chrY"" \ . --regions=""chrX chrY"" \ . --model_type PACBIO \. --regions=chrX_10001-44821.bed \. --intermediate_results_dir=tmp \. --num_shards=12. ```. [chrY.vcf.gz](https://github.com/user-attachments/files/16334591/chrY.vcf.gz). [sample1-lane_1.deepvariant.vcf.gz](https://github.com/user-attachments/files/16334613/sample1-lane_1.deepvariant.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:74,modifiability,modul,module,74,"Hi @kishwarshafin,. I am trying to add --haploid_contigs=""chrX,chrY"" in a module from nf-core that I am using. However, when running the command line, I am only detecting chrX variants from the test data. When I try to run the command using a BED file with only chrY, I get an empty VCF file with headers as the result. I also tried using --regions as a parameter, but without success. Could you please suggest some ideas on how to resolve this issue? Thank you for your assistance. ```. /opt/deepvariant/bin/run_deepvariant \. --ref=GRCh38_no_alt_analysis_set.fasta \. --reads=sample1-lane_1.converted.cram \. --output_vcf=sample1-lane_1.deepvariant.vcf.gz \. --output_gvcf=sample1-lane_1.deepvariant.g.vcf.gz \. --haploid_contigs=""chrX,chrY"" \ . --regions=""chrX chrY"" \ . --model_type PACBIO \. --regions=chrX_10001-44821.bed \. --intermediate_results_dir=tmp \. --num_shards=12. ```. [chrY.vcf.gz](https://github.com/user-attachments/files/16334591/chrY.vcf.gz). [sample1-lane_1.deepvariant.vcf.gz](https://github.com/user-attachments/files/16334613/sample1-lane_1.deepvariant.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:354,modifiability,paramet,parameter,354,"Hi @kishwarshafin,. I am trying to add --haploid_contigs=""chrX,chrY"" in a module from nf-core that I am using. However, when running the command line, I am only detecting chrX variants from the test data. When I try to run the command using a BED file with only chrY, I get an empty VCF file with headers as the result. I also tried using --regions as a parameter, but without success. Could you please suggest some ideas on how to resolve this issue? Thank you for your assistance. ```. /opt/deepvariant/bin/run_deepvariant \. --ref=GRCh38_no_alt_analysis_set.fasta \. --reads=sample1-lane_1.converted.cram \. --output_vcf=sample1-lane_1.deepvariant.vcf.gz \. --output_gvcf=sample1-lane_1.deepvariant.g.vcf.gz \. --haploid_contigs=""chrX,chrY"" \ . --regions=""chrX chrY"" \ . --model_type PACBIO \. --regions=chrX_10001-44821.bed \. --intermediate_results_dir=tmp \. --num_shards=12. ```. [chrY.vcf.gz](https://github.com/user-attachments/files/16334591/chrY.vcf.gz). [sample1-lane_1.deepvariant.vcf.gz](https://github.com/user-attachments/files/16334613/sample1-lane_1.deepvariant.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:787,modifiability,PAC,PACBIO,787,"Hi @kishwarshafin,. I am trying to add --haploid_contigs=""chrX,chrY"" in a module from nf-core that I am using. However, when running the command line, I am only detecting chrX variants from the test data. When I try to run the command using a BED file with only chrY, I get an empty VCF file with headers as the result. I also tried using --regions as a parameter, but without success. Could you please suggest some ideas on how to resolve this issue? Thank you for your assistance. ```. /opt/deepvariant/bin/run_deepvariant \. --ref=GRCh38_no_alt_analysis_set.fasta \. --reads=sample1-lane_1.converted.cram \. --output_vcf=sample1-lane_1.deepvariant.vcf.gz \. --output_gvcf=sample1-lane_1.deepvariant.g.vcf.gz \. --haploid_contigs=""chrX,chrY"" \ . --regions=""chrX chrY"" \ . --model_type PACBIO \. --regions=chrX_10001-44821.bed \. --intermediate_results_dir=tmp \. --num_shards=12. ```. [chrY.vcf.gz](https://github.com/user-attachments/files/16334591/chrY.vcf.gz). [sample1-lane_1.deepvariant.vcf.gz](https://github.com/user-attachments/files/16334613/sample1-lane_1.deepvariant.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:74,safety,modul,module,74,"Hi @kishwarshafin,. I am trying to add --haploid_contigs=""chrX,chrY"" in a module from nf-core that I am using. However, when running the command line, I am only detecting chrX variants from the test data. When I try to run the command using a BED file with only chrY, I get an empty VCF file with headers as the result. I also tried using --regions as a parameter, but without success. Could you please suggest some ideas on how to resolve this issue? Thank you for your assistance. ```. /opt/deepvariant/bin/run_deepvariant \. --ref=GRCh38_no_alt_analysis_set.fasta \. --reads=sample1-lane_1.converted.cram \. --output_vcf=sample1-lane_1.deepvariant.vcf.gz \. --output_gvcf=sample1-lane_1.deepvariant.g.vcf.gz \. --haploid_contigs=""chrX,chrY"" \ . --regions=""chrX chrY"" \ . --model_type PACBIO \. --regions=chrX_10001-44821.bed \. --intermediate_results_dir=tmp \. --num_shards=12. ```. [chrY.vcf.gz](https://github.com/user-attachments/files/16334591/chrY.vcf.gz). [sample1-lane_1.deepvariant.vcf.gz](https://github.com/user-attachments/files/16334613/sample1-lane_1.deepvariant.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:161,safety,detect,detecting,161,"Hi @kishwarshafin,. I am trying to add --haploid_contigs=""chrX,chrY"" in a module from nf-core that I am using. However, when running the command line, I am only detecting chrX variants from the test data. When I try to run the command using a BED file with only chrY, I get an empty VCF file with headers as the result. I also tried using --regions as a parameter, but without success. Could you please suggest some ideas on how to resolve this issue? Thank you for your assistance. ```. /opt/deepvariant/bin/run_deepvariant \. --ref=GRCh38_no_alt_analysis_set.fasta \. --reads=sample1-lane_1.converted.cram \. --output_vcf=sample1-lane_1.deepvariant.vcf.gz \. --output_gvcf=sample1-lane_1.deepvariant.g.vcf.gz \. --haploid_contigs=""chrX,chrY"" \ . --regions=""chrX chrY"" \ . --model_type PACBIO \. --regions=chrX_10001-44821.bed \. --intermediate_results_dir=tmp \. --num_shards=12. ```. [chrY.vcf.gz](https://github.com/user-attachments/files/16334591/chrY.vcf.gz). [sample1-lane_1.deepvariant.vcf.gz](https://github.com/user-attachments/files/16334613/sample1-lane_1.deepvariant.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:194,safety,test,test,194,"Hi @kishwarshafin,. I am trying to add --haploid_contigs=""chrX,chrY"" in a module from nf-core that I am using. However, when running the command line, I am only detecting chrX variants from the test data. When I try to run the command using a BED file with only chrY, I get an empty VCF file with headers as the result. I also tried using --regions as a parameter, but without success. Could you please suggest some ideas on how to resolve this issue? Thank you for your assistance. ```. /opt/deepvariant/bin/run_deepvariant \. --ref=GRCh38_no_alt_analysis_set.fasta \. --reads=sample1-lane_1.converted.cram \. --output_vcf=sample1-lane_1.deepvariant.vcf.gz \. --output_gvcf=sample1-lane_1.deepvariant.g.vcf.gz \. --haploid_contigs=""chrX,chrY"" \ . --regions=""chrX chrY"" \ . --model_type PACBIO \. --regions=chrX_10001-44821.bed \. --intermediate_results_dir=tmp \. --num_shards=12. ```. [chrY.vcf.gz](https://github.com/user-attachments/files/16334591/chrY.vcf.gz). [sample1-lane_1.deepvariant.vcf.gz](https://github.com/user-attachments/files/16334613/sample1-lane_1.deepvariant.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:161,security,detect,detecting,161,"Hi @kishwarshafin,. I am trying to add --haploid_contigs=""chrX,chrY"" in a module from nf-core that I am using. However, when running the command line, I am only detecting chrX variants from the test data. When I try to run the command using a BED file with only chrY, I get an empty VCF file with headers as the result. I also tried using --regions as a parameter, but without success. Could you please suggest some ideas on how to resolve this issue? Thank you for your assistance. ```. /opt/deepvariant/bin/run_deepvariant \. --ref=GRCh38_no_alt_analysis_set.fasta \. --reads=sample1-lane_1.converted.cram \. --output_vcf=sample1-lane_1.deepvariant.vcf.gz \. --output_gvcf=sample1-lane_1.deepvariant.g.vcf.gz \. --haploid_contigs=""chrX,chrY"" \ . --regions=""chrX chrY"" \ . --model_type PACBIO \. --regions=chrX_10001-44821.bed \. --intermediate_results_dir=tmp \. --num_shards=12. ```. [chrY.vcf.gz](https://github.com/user-attachments/files/16334591/chrY.vcf.gz). [sample1-lane_1.deepvariant.vcf.gz](https://github.com/user-attachments/files/16334613/sample1-lane_1.deepvariant.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:194,testability,test,test,194,"Hi @kishwarshafin,. I am trying to add --haploid_contigs=""chrX,chrY"" in a module from nf-core that I am using. However, when running the command line, I am only detecting chrX variants from the test data. When I try to run the command using a BED file with only chrY, I get an empty VCF file with headers as the result. I also tried using --regions as a parameter, but without success. Could you please suggest some ideas on how to resolve this issue? Thank you for your assistance. ```. /opt/deepvariant/bin/run_deepvariant \. --ref=GRCh38_no_alt_analysis_set.fasta \. --reads=sample1-lane_1.converted.cram \. --output_vcf=sample1-lane_1.deepvariant.vcf.gz \. --output_gvcf=sample1-lane_1.deepvariant.g.vcf.gz \. --haploid_contigs=""chrX,chrY"" \ . --regions=""chrX chrY"" \ . --model_type PACBIO \. --regions=chrX_10001-44821.bed \. --intermediate_results_dir=tmp \. --num_shards=12. ```. [chrY.vcf.gz](https://github.com/user-attachments/files/16334591/chrY.vcf.gz). [sample1-lane_1.deepvariant.vcf.gz](https://github.com/user-attachments/files/16334613/sample1-lane_1.deepvariant.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:137,usability,command,command,137,"Hi @kishwarshafin,. I am trying to add --haploid_contigs=""chrX,chrY"" in a module from nf-core that I am using. However, when running the command line, I am only detecting chrX variants from the test data. When I try to run the command using a BED file with only chrY, I get an empty VCF file with headers as the result. I also tried using --regions as a parameter, but without success. Could you please suggest some ideas on how to resolve this issue? Thank you for your assistance. ```. /opt/deepvariant/bin/run_deepvariant \. --ref=GRCh38_no_alt_analysis_set.fasta \. --reads=sample1-lane_1.converted.cram \. --output_vcf=sample1-lane_1.deepvariant.vcf.gz \. --output_gvcf=sample1-lane_1.deepvariant.g.vcf.gz \. --haploid_contigs=""chrX,chrY"" \ . --regions=""chrX chrY"" \ . --model_type PACBIO \. --regions=chrX_10001-44821.bed \. --intermediate_results_dir=tmp \. --num_shards=12. ```. [chrY.vcf.gz](https://github.com/user-attachments/files/16334591/chrY.vcf.gz). [sample1-lane_1.deepvariant.vcf.gz](https://github.com/user-attachments/files/16334613/sample1-lane_1.deepvariant.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:227,usability,command,command,227,"Hi @kishwarshafin,. I am trying to add --haploid_contigs=""chrX,chrY"" in a module from nf-core that I am using. However, when running the command line, I am only detecting chrX variants from the test data. When I try to run the command using a BED file with only chrY, I get an empty VCF file with headers as the result. I also tried using --regions as a parameter, but without success. Could you please suggest some ideas on how to resolve this issue? Thank you for your assistance. ```. /opt/deepvariant/bin/run_deepvariant \. --ref=GRCh38_no_alt_analysis_set.fasta \. --reads=sample1-lane_1.converted.cram \. --output_vcf=sample1-lane_1.deepvariant.vcf.gz \. --output_gvcf=sample1-lane_1.deepvariant.g.vcf.gz \. --haploid_contigs=""chrX,chrY"" \ . --regions=""chrX chrY"" \ . --model_type PACBIO \. --regions=chrX_10001-44821.bed \. --intermediate_results_dir=tmp \. --num_shards=12. ```. [chrY.vcf.gz](https://github.com/user-attachments/files/16334591/chrY.vcf.gz). [sample1-lane_1.deepvariant.vcf.gz](https://github.com/user-attachments/files/16334613/sample1-lane_1.deepvariant.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:920,usability,user,user-attachments,920,"Hi @kishwarshafin,. I am trying to add --haploid_contigs=""chrX,chrY"" in a module from nf-core that I am using. However, when running the command line, I am only detecting chrX variants from the test data. When I try to run the command using a BED file with only chrY, I get an empty VCF file with headers as the result. I also tried using --regions as a parameter, but without success. Could you please suggest some ideas on how to resolve this issue? Thank you for your assistance. ```. /opt/deepvariant/bin/run_deepvariant \. --ref=GRCh38_no_alt_analysis_set.fasta \. --reads=sample1-lane_1.converted.cram \. --output_vcf=sample1-lane_1.deepvariant.vcf.gz \. --output_gvcf=sample1-lane_1.deepvariant.g.vcf.gz \. --haploid_contigs=""chrX,chrY"" \ . --regions=""chrX chrY"" \ . --model_type PACBIO \. --regions=chrX_10001-44821.bed \. --intermediate_results_dir=tmp \. --num_shards=12. ```. [chrY.vcf.gz](https://github.com/user-attachments/files/16334591/chrY.vcf.gz). [sample1-lane_1.deepvariant.vcf.gz](https://github.com/user-attachments/files/16334613/sample1-lane_1.deepvariant.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/853:1021,usability,user,user-attachments,1021,"Hi @kishwarshafin,. I am trying to add --haploid_contigs=""chrX,chrY"" in a module from nf-core that I am using. However, when running the command line, I am only detecting chrX variants from the test data. When I try to run the command using a BED file with only chrY, I get an empty VCF file with headers as the result. I also tried using --regions as a parameter, but without success. Could you please suggest some ideas on how to resolve this issue? Thank you for your assistance. ```. /opt/deepvariant/bin/run_deepvariant \. --ref=GRCh38_no_alt_analysis_set.fasta \. --reads=sample1-lane_1.converted.cram \. --output_vcf=sample1-lane_1.deepvariant.vcf.gz \. --output_gvcf=sample1-lane_1.deepvariant.g.vcf.gz \. --haploid_contigs=""chrX,chrY"" \ . --regions=""chrX chrY"" \ . --model_type PACBIO \. --regions=chrX_10001-44821.bed \. --intermediate_results_dir=tmp \. --num_shards=12. ```. [chrY.vcf.gz](https://github.com/user-attachments/files/16334591/chrY.vcf.gz). [sample1-lane_1.deepvariant.vcf.gz](https://github.com/user-attachments/files/16334613/sample1-lane_1.deepvariant.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/853
https://github.com/google/deepvariant/issues/854:99,availability,operat,operating,99,"@DineshRavindraRaju ,. It looks like it's not a memory issue rather it's a compilation issue. What operating system are you working on? Looks like it's throwing an error for typecasting `bytes`. Can you please run https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md to see if it runs to completion? You should be able to run it just by copy pasting the commands.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:164,availability,error,error,164,"@DineshRavindraRaju ,. It looks like it's not a memory issue rather it's a compilation issue. What operating system are you working on? Looks like it's throwing an error for typecasting `bytes`. Can you please run https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md to see if it runs to completion? You should be able to run it just by copy pasting the commands.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:48,performance,memor,memory,48,"@DineshRavindraRaju ,. It looks like it's not a memory issue rather it's a compilation issue. What operating system are you working on? Looks like it's throwing an error for typecasting `bytes`. Can you please run https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md to see if it runs to completion? You should be able to run it just by copy pasting the commands.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:164,performance,error,error,164,"@DineshRavindraRaju ,. It looks like it's not a memory issue rather it's a compilation issue. What operating system are you working on? Looks like it's throwing an error for typecasting `bytes`. Can you please run https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md to see if it runs to completion? You should be able to run it just by copy pasting the commands.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:164,safety,error,error,164,"@DineshRavindraRaju ,. It looks like it's not a memory issue rather it's a compilation issue. What operating system are you working on? Looks like it's throwing an error for typecasting `bytes`. Can you please run https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md to see if it runs to completion? You should be able to run it just by copy pasting the commands.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:317,safety,compl,completion,317,"@DineshRavindraRaju ,. It looks like it's not a memory issue rather it's a compilation issue. What operating system are you working on? Looks like it's throwing an error for typecasting `bytes`. Can you please run https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md to see if it runs to completion? You should be able to run it just by copy pasting the commands.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:317,security,compl,completion,317,"@DineshRavindraRaju ,. It looks like it's not a memory issue rather it's a compilation issue. What operating system are you working on? Looks like it's throwing an error for typecasting `bytes`. Can you please run https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md to see if it runs to completion? You should be able to run it just by copy pasting the commands.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:48,usability,memor,memory,48,"@DineshRavindraRaju ,. It looks like it's not a memory issue rather it's a compilation issue. What operating system are you working on? Looks like it's throwing an error for typecasting `bytes`. Can you please run https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md to see if it runs to completion? You should be able to run it just by copy pasting the commands.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:164,usability,error,error,164,"@DineshRavindraRaju ,. It looks like it's not a memory issue rather it's a compilation issue. What operating system are you working on? Looks like it's throwing an error for typecasting `bytes`. Can you please run https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md to see if it runs to completion? You should be able to run it just by copy pasting the commands.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:383,usability,command,commands,383,"@DineshRavindraRaju ,. It looks like it's not a memory issue rather it's a compilation issue. What operating system are you working on? Looks like it's throwing an error for typecasting `bytes`. Can you please run https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md to see if it runs to completion? You should be able to run it just by copy pasting the commands.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:23,availability,operat,operating,23,"@kishwarshafin ,. What operating system are you working on? Linux in TACC cluster (ls6). In the previous run, I was executing four separate runs on a single node, distributing them evenly across 32 threads. I did run the test data, it did finish and have generated the output files without error. Have attached the log file. [Deepvarint.txt](https://github.com/user-attachments/files/16364399/Deepvarint.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:74,availability,cluster,cluster,74,"@kishwarshafin ,. What operating system are you working on? Linux in TACC cluster (ls6). In the previous run, I was executing four separate runs on a single node, distributing them evenly across 32 threads. I did run the test data, it did finish and have generated the output files without error. Have attached the log file. [Deepvarint.txt](https://github.com/user-attachments/files/16364399/Deepvarint.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:290,availability,error,error,290,"@kishwarshafin ,. What operating system are you working on? Linux in TACC cluster (ls6). In the previous run, I was executing four separate runs on a single node, distributing them evenly across 32 threads. I did run the test data, it did finish and have generated the output files without error. Have attached the log file. [Deepvarint.txt](https://github.com/user-attachments/files/16364399/Deepvarint.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:74,deployability,cluster,cluster,74,"@kishwarshafin ,. What operating system are you working on? Linux in TACC cluster (ls6). In the previous run, I was executing four separate runs on a single node, distributing them evenly across 32 threads. I did run the test data, it did finish and have generated the output files without error. Have attached the log file. [Deepvarint.txt](https://github.com/user-attachments/files/16364399/Deepvarint.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:315,deployability,log,log,315,"@kishwarshafin ,. What operating system are you working on? Linux in TACC cluster (ls6). In the previous run, I was executing four separate runs on a single node, distributing them evenly across 32 threads. I did run the test data, it did finish and have generated the output files without error. Have attached the log file. [Deepvarint.txt](https://github.com/user-attachments/files/16364399/Deepvarint.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:163,interoperability,distribut,distributing,163,"@kishwarshafin ,. What operating system are you working on? Linux in TACC cluster (ls6). In the previous run, I was executing four separate runs on a single node, distributing them evenly across 32 threads. I did run the test data, it did finish and have generated the output files without error. Have attached the log file. [Deepvarint.txt](https://github.com/user-attachments/files/16364399/Deepvarint.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:290,performance,error,error,290,"@kishwarshafin ,. What operating system are you working on? Linux in TACC cluster (ls6). In the previous run, I was executing four separate runs on a single node, distributing them evenly across 32 threads. I did run the test data, it did finish and have generated the output files without error. Have attached the log file. [Deepvarint.txt](https://github.com/user-attachments/files/16364399/Deepvarint.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:221,safety,test,test,221,"@kishwarshafin ,. What operating system are you working on? Linux in TACC cluster (ls6). In the previous run, I was executing four separate runs on a single node, distributing them evenly across 32 threads. I did run the test data, it did finish and have generated the output files without error. Have attached the log file. [Deepvarint.txt](https://github.com/user-attachments/files/16364399/Deepvarint.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:290,safety,error,error,290,"@kishwarshafin ,. What operating system are you working on? Linux in TACC cluster (ls6). In the previous run, I was executing four separate runs on a single node, distributing them evenly across 32 threads. I did run the test data, it did finish and have generated the output files without error. Have attached the log file. [Deepvarint.txt](https://github.com/user-attachments/files/16364399/Deepvarint.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:315,safety,log,log,315,"@kishwarshafin ,. What operating system are you working on? Linux in TACC cluster (ls6). In the previous run, I was executing four separate runs on a single node, distributing them evenly across 32 threads. I did run the test data, it did finish and have generated the output files without error. Have attached the log file. [Deepvarint.txt](https://github.com/user-attachments/files/16364399/Deepvarint.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:315,security,log,log,315,"@kishwarshafin ,. What operating system are you working on? Linux in TACC cluster (ls6). In the previous run, I was executing four separate runs on a single node, distributing them evenly across 32 threads. I did run the test data, it did finish and have generated the output files without error. Have attached the log file. [Deepvarint.txt](https://github.com/user-attachments/files/16364399/Deepvarint.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:221,testability,test,test,221,"@kishwarshafin ,. What operating system are you working on? Linux in TACC cluster (ls6). In the previous run, I was executing four separate runs on a single node, distributing them evenly across 32 threads. I did run the test data, it did finish and have generated the output files without error. Have attached the log file. [Deepvarint.txt](https://github.com/user-attachments/files/16364399/Deepvarint.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:315,testability,log,log,315,"@kishwarshafin ,. What operating system are you working on? Linux in TACC cluster (ls6). In the previous run, I was executing four separate runs on a single node, distributing them evenly across 32 threads. I did run the test data, it did finish and have generated the output files without error. Have attached the log file. [Deepvarint.txt](https://github.com/user-attachments/files/16364399/Deepvarint.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:290,usability,error,error,290,"@kishwarshafin ,. What operating system are you working on? Linux in TACC cluster (ls6). In the previous run, I was executing four separate runs on a single node, distributing them evenly across 32 threads. I did run the test data, it did finish and have generated the output files without error. Have attached the log file. [Deepvarint.txt](https://github.com/user-attachments/files/16364399/Deepvarint.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:361,usability,user,user-attachments,361,"@kishwarshafin ,. What operating system are you working on? Linux in TACC cluster (ls6). In the previous run, I was executing four separate runs on a single node, distributing them evenly across 32 threads. I did run the test data, it did finish and have generated the output files without error. Have attached the log file. [Deepvarint.txt](https://github.com/user-attachments/files/16364399/Deepvarint.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:26,interoperability,share,share,26,Is it possible for you to share the bam so I can take a closer look?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:56,usability,close,closer,56,Is it possible for you to share the bam so I can take a closer look?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:78,availability,down,down,78,"@kishwarshafin ,. Sure, how do I share it ,bam file is around 125gb. Should I down sample it to 10,000k reads?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:33,interoperability,share,share,33,"@kishwarshafin ,. Sure, how do I share it ,bam file is around 125gb. Should I down sample it to 10,000k reads?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:163,availability,down,download,163,"@DineshRavindraRaju , . Would be great if I can get the entire file to see if memory usage is the issue. If you can put it temporarily to somewhere public until I download, that would be very helpful. Please send an email to shafin@google.com",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:148,integrability,pub,public,148,"@DineshRavindraRaju , . Would be great if I can get the entire file to see if memory usage is the issue. If you can put it temporarily to somewhere public until I download, that would be very helpful. Please send an email to shafin@google.com",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:78,performance,memor,memory,78,"@DineshRavindraRaju , . Would be great if I can get the entire file to see if memory usage is the issue. If you can put it temporarily to somewhere public until I download, that would be very helpful. Please send an email to shafin@google.com",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:78,usability,memor,memory,78,"@DineshRavindraRaju , . Would be great if I can get the entire file to see if memory usage is the issue. If you can put it temporarily to somewhere public until I download, that would be very helpful. Please send an email to shafin@google.com",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:192,usability,help,helpful,192,"@DineshRavindraRaju , . Would be great if I can get the entire file to see if memory usage is the issue. If you can put it temporarily to somewhere public until I download, that would be very helpful. Please send an email to shafin@google.com",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:154,availability,down,download,154,"@kishwarshafin . Sorry to let you know, but the researcher is not okay to share the BAM file due to confidentiality concerns. Quick question: where can I download the complete datasets (aligned BAM files) for HG002 and HG003 datasets for R10 ONT chemistry used for benchmarking in the study ""Local read haplotagging enables accurate long-read small variant calling""? Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:74,interoperability,share,share,74,"@kishwarshafin . Sorry to let you know, but the researcher is not okay to share the BAM file due to confidentiality concerns. Quick question: where can I download the complete datasets (aligned BAM files) for HG002 and HG003 datasets for R10 ONT chemistry used for benchmarking in the study ""Local read haplotagging enables accurate long-read small variant calling""? Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:116,modifiability,concern,concerns,116,"@kishwarshafin . Sorry to let you know, but the researcher is not okay to share the BAM file due to confidentiality concerns. Quick question: where can I download the complete datasets (aligned BAM files) for HG002 and HG003 datasets for R10 ONT chemistry used for benchmarking in the study ""Local read haplotagging enables accurate long-read small variant calling""? Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:167,safety,compl,complete,167,"@kishwarshafin . Sorry to let you know, but the researcher is not okay to share the BAM file due to confidentiality concerns. Quick question: where can I download the complete datasets (aligned BAM files) for HG002 and HG003 datasets for R10 ONT chemistry used for benchmarking in the study ""Local read haplotagging enables accurate long-read small variant calling""? Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:100,security,confidential,confidentiality,100,"@kishwarshafin . Sorry to let you know, but the researcher is not okay to share the BAM file due to confidentiality concerns. Quick question: where can I download the complete datasets (aligned BAM files) for HG002 and HG003 datasets for R10 ONT chemistry used for benchmarking in the study ""Local read haplotagging enables accurate long-read small variant calling""? Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:167,security,compl,complete,167,"@kishwarshafin . Sorry to let you know, but the researcher is not okay to share the BAM file due to confidentiality concerns. Quick question: where can I download the complete datasets (aligned BAM files) for HG002 and HG003 datasets for R10 ONT chemistry used for benchmarking in the study ""Local read haplotagging enables accurate long-read small variant calling""? Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:116,testability,concern,concerns,116,"@kishwarshafin . Sorry to let you know, but the researcher is not okay to share the BAM file due to confidentiality concerns. Quick question: where can I download the complete datasets (aligned BAM files) for HG002 and HG003 datasets for R10 ONT chemistry used for benchmarking in the study ""Local read haplotagging enables accurate long-read small variant calling""? Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:94,integrability,pub,public,94,"@DineshRavindraRaju , no worries, the files are here:. ```bash. gsutil ls gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotag",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:101,integrability,pub,publications,101,"@DineshRavindraRaju , no worries, the files are here:. ```bash. gsutil ls gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotag",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:207,integrability,pub,public,207,"@DineshRavindraRaju , no worries, the files are here:. ```bash. gsutil ls gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotag",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:214,integrability,pub,publications,214,"@DineshRavindraRaju , no worries, the files are here:. ```bash. gsutil ls gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotag",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:364,integrability,pub,public,364,"@DineshRavindraRaju , no worries, the files are here:. ```bash. gsutil ls gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotag",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:371,integrability,pub,publications,371,"@DineshRavindraRaju , no worries, the files are here:. ```bash. gsutil ls gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotag",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:525,integrability,pub,public,525,"@DineshRavindraRaju , no worries, the files are here:. ```bash. gsutil ls gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotag",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:532,integrability,pub,publications,532,"@DineshRavindraRaju , no worries, the files are here:. ```bash. gsutil ls gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotag",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:682,integrability,pub,public,682,"@DineshRavindraRaju , no worries, the files are here:. ```bash. gsutil ls gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotag",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:689,integrability,pub,publications,689,"@DineshRavindraRaju , no worries, the files are here:. ```bash. gsutil ls gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotag",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:843,integrability,pub,public,843,"@DineshRavindraRaju , no worries, the files are here:. ```bash. gsutil ls gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotag",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:850,integrability,pub,publications,850,"@DineshRavindraRaju , no worries, the files are here:. ```bash. gsutil ls gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotag",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1000,integrability,pub,public,1000,"neshRavindraRaju , no worries, the files are here:. ```bash. gsutil ls gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotaggin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1007,integrability,pub,publications,1007,"raRaju , no worries, the files are here:. ```bash. gsutil ls gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluati",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1161,integrability,pub,public,1161,lex/downsampled_bams/. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotaggin,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1168,integrability,pub,publications,1168,mpled_bams/. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluati,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1318,integrability,pub,public,1318,2_GRCh38.pass.10x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotaggin,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1325,integrability,pub,publications,1325,ass.10x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.10x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluati,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1479,integrability,pub,public,1479,Ch38.pass.10x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotaggin,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1486,integrability,pub,publications,1486,10x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluati,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1636,integrability,pub,public,1636,2_GRCh38.pass.15x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotaggin,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1643,integrability,pub,publications,1643,ass.15x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.15x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluati,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1797,integrability,pub,public,1797,Ch38.pass.15x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotaggin,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1804,integrability,pub,publications,1804,15x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluati,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1954,integrability,pub,public,1954,2_GRCh38.pass.20x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotaggin,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:1961,integrability,pub,publications,1961,ass.20x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluati,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2115,integrability,pub,public,2115,Ch38.pass.20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotaggin,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2122,integrability,pub,publications,2122,20x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluati,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2272,integrability,pub,public,2272,2_GRCh38.pass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotaggin,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2279,integrability,pub,publications,2279,ass.25x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluati,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2433,integrability,pub,public,2433,Ch38.pass.25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotaggin,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2440,integrability,pub,publications,2440,25x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluati,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2590,integrability,pub,public,2590,2_GRCh38.pass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotaggin,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2597,integrability,pub,publications,2597,ass.30x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluati,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2751,integrability,pub,public,2751,Ch38.pass.30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotaggin,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2758,integrability,pub,publications,2758,30x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluati,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2908,integrability,pub,public,2908,2_GRCh38.pass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.65x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotaggin,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:2915,integrability,pub,publications,2915,ass.35x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.65x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluati,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3069,integrability,pub,public,3069,valuation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.65x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.65x.bam.bai. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3076,integrability,pub,publications,3076,valuation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.65x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.65x.bam.bai. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3226,integrability,pub,public,3226,valuation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.65x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.65x.bam.bai. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3233,integrability,pub,publications,3233,valuation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.65x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.65x.bam.bai. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3387,integrability,pub,public,3387,valuation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.65x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.65x.bam.bai. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3394,integrability,pub,publications,3394,valuation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.65x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.65x.bam.bai. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3544,integrability,pub,public,3544,valuation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.65x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.65x.bam.bai. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3551,integrability,pub,publications,3551,valuation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.65x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.65x.bam.bai. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3705,integrability,pub,public,3705,valuation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.65x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.65x.bam.bai. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3712,integrability,pub,publications,3712,valuation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.65x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.65x.bam.bai. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3862,integrability,pub,public,3862,valuation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.65x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.65x.bam.bai. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/854:3869,integrability,pub,publications,3869,valuation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.35x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.40x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.45x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.50x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.55x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.60x.bam.bai. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.65x.bam. gs://brain-genomics-public/publications/kolesnikov2023_dv_haplotagging/evaluation/ont_simplex/downsampled_bams/HG003_R1041_Guppy6_sup_2_GRCh38.pass.65x.bam.bai. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/854
https://github.com/google/deepvariant/issues/855:328,deployability,continu,continue,328,"> @liukeweiaway are these human samples? Looks like the program is running fine, it's just not finding any variants. Can you please explain a bit more to what exactly is your data? It is a human sample, and the generated data is the same as the reference genome. When no mutation is detected, the program will not stop and will continue to run. You need to stop the program manually. [chr6_CYP21A2.bwa.read1.fastq.gz](https://github.com/user-attachments/files/16420817/chr6_CYP21A2.bwa.read1.fastq.gz). [chr6_CYP21A2.bwa.read2.fastq.gz](https://github.com/user-attachments/files/16420818/chr6_CYP21A2.bwa.read2.fastq.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:283,safety,detect,detected,283,"> @liukeweiaway are these human samples? Looks like the program is running fine, it's just not finding any variants. Can you please explain a bit more to what exactly is your data? It is a human sample, and the generated data is the same as the reference genome. When no mutation is detected, the program will not stop and will continue to run. You need to stop the program manually. [chr6_CYP21A2.bwa.read1.fastq.gz](https://github.com/user-attachments/files/16420817/chr6_CYP21A2.bwa.read1.fastq.gz). [chr6_CYP21A2.bwa.read2.fastq.gz](https://github.com/user-attachments/files/16420818/chr6_CYP21A2.bwa.read2.fastq.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:283,security,detect,detected,283,"> @liukeweiaway are these human samples? Looks like the program is running fine, it's just not finding any variants. Can you please explain a bit more to what exactly is your data? It is a human sample, and the generated data is the same as the reference genome. When no mutation is detected, the program will not stop and will continue to run. You need to stop the program manually. [chr6_CYP21A2.bwa.read1.fastq.gz](https://github.com/user-attachments/files/16420817/chr6_CYP21A2.bwa.read1.fastq.gz). [chr6_CYP21A2.bwa.read2.fastq.gz](https://github.com/user-attachments/files/16420818/chr6_CYP21A2.bwa.read2.fastq.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:314,usability,stop,stop,314,"> @liukeweiaway are these human samples? Looks like the program is running fine, it's just not finding any variants. Can you please explain a bit more to what exactly is your data? It is a human sample, and the generated data is the same as the reference genome. When no mutation is detected, the program will not stop and will continue to run. You need to stop the program manually. [chr6_CYP21A2.bwa.read1.fastq.gz](https://github.com/user-attachments/files/16420817/chr6_CYP21A2.bwa.read1.fastq.gz). [chr6_CYP21A2.bwa.read2.fastq.gz](https://github.com/user-attachments/files/16420818/chr6_CYP21A2.bwa.read2.fastq.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:357,usability,stop,stop,357,"> @liukeweiaway are these human samples? Looks like the program is running fine, it's just not finding any variants. Can you please explain a bit more to what exactly is your data? It is a human sample, and the generated data is the same as the reference genome. When no mutation is detected, the program will not stop and will continue to run. You need to stop the program manually. [chr6_CYP21A2.bwa.read1.fastq.gz](https://github.com/user-attachments/files/16420817/chr6_CYP21A2.bwa.read1.fastq.gz). [chr6_CYP21A2.bwa.read2.fastq.gz](https://github.com/user-attachments/files/16420818/chr6_CYP21A2.bwa.read2.fastq.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:437,usability,user,user-attachments,437,"> @liukeweiaway are these human samples? Looks like the program is running fine, it's just not finding any variants. Can you please explain a bit more to what exactly is your data? It is a human sample, and the generated data is the same as the reference genome. When no mutation is detected, the program will not stop and will continue to run. You need to stop the program manually. [chr6_CYP21A2.bwa.read1.fastq.gz](https://github.com/user-attachments/files/16420817/chr6_CYP21A2.bwa.read1.fastq.gz). [chr6_CYP21A2.bwa.read2.fastq.gz](https://github.com/user-attachments/files/16420818/chr6_CYP21A2.bwa.read2.fastq.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:556,usability,user,user-attachments,556,"> @liukeweiaway are these human samples? Looks like the program is running fine, it's just not finding any variants. Can you please explain a bit more to what exactly is your data? It is a human sample, and the generated data is the same as the reference genome. When no mutation is detected, the program will not stop and will continue to run. You need to stop the program manually. [chr6_CYP21A2.bwa.read1.fastq.gz](https://github.com/user-attachments/files/16420817/chr6_CYP21A2.bwa.read1.fastq.gz). [chr6_CYP21A2.bwa.read2.fastq.gz](https://github.com/user-attachments/files/16420818/chr6_CYP21A2.bwa.read2.fastq.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:39,deployability,updat,update,39,"@liukeweiaway ,. I see, can you please update to 1.6.1? I think you are getting stuck in the bug of 1.6.0 that we fixed in 1.6.1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:39,safety,updat,update,39,"@liukeweiaway ,. I see, can you please update to 1.6.1? I think you are getting stuck in the bug of 1.6.0 that we fixed in 1.6.1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/855:39,security,updat,update,39,"@liukeweiaway ,. I see, can you please update to 1.6.1? I think you are getting stuck in the bug of 1.6.0 that we fixed in 1.6.1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/855
https://github.com/google/deepvariant/issues/856:101,energy efficiency,model,models,101,"@DineshRavindraRaju , you are using R9 data which is lot more noisier than R10.4 data we trained our models on. For R9, we recommend using PEPPER-DeepVariant, you can see the mention on our github landing page. The current model is for R10.4 chemistry only.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:215,energy efficiency,current,current,215,"@DineshRavindraRaju , you are using R9 data which is lot more noisier than R10.4 data we trained our models on. For R9, we recommend using PEPPER-DeepVariant, you can see the mention on our github landing page. The current model is for R10.4 chemistry only.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:223,energy efficiency,model,model,223,"@DineshRavindraRaju , you are using R9 data which is lot more noisier than R10.4 data we trained our models on. For R9, we recommend using PEPPER-DeepVariant, you can see the mention on our github landing page. The current model is for R10.4 chemistry only.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:101,security,model,models,101,"@DineshRavindraRaju , you are using R9 data which is lot more noisier than R10.4 data we trained our models on. For R9, we recommend using PEPPER-DeepVariant, you can see the mention on our github landing page. The current model is for R10.4 chemistry only.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/856:223,security,model,model,223,"@DineshRavindraRaju , you are using R9 data which is lot more noisier than R10.4 data we trained our models on. For R9, we recommend using PEPPER-DeepVariant, you can see the mention on our github landing page. The current model is for R10.4 chemistry only.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/856
https://github.com/google/deepvariant/issues/857:37,energy efficiency,model,model,37,"@xianyu0623 ,. Looks like the custom model file you are loading is not valid. Can you give a little more information on how you generated the custom model?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:56,energy efficiency,load,loading,56,"@xianyu0623 ,. Looks like the custom model file you are loading is not valid. Can you give a little more information on how you generated the custom model?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:149,energy efficiency,model,model,149,"@xianyu0623 ,. Looks like the custom model file you are loading is not valid. Can you give a little more information on how you generated the custom model?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:56,performance,load,loading,56,"@xianyu0623 ,. Looks like the custom model file you are loading is not valid. Can you give a little more information on how you generated the custom model?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:71,safety,valid,valid,71,"@xianyu0623 ,. Looks like the custom model file you are loading is not valid. Can you give a little more information on how you generated the custom model?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:37,security,model,model,37,"@xianyu0623 ,. Looks like the custom model file you are loading is not valid. Can you give a little more information on how you generated the custom model?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:149,security,model,model,149,"@xianyu0623 ,. Looks like the custom model file you are loading is not valid. Can you give a little more information on how you generated the custom model?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:30,usability,custom,custom,30,"@xianyu0623 ,. Looks like the custom model file you are loading is not valid. Can you give a little more information on how you generated the custom model?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:142,usability,custom,custom,142,"@xianyu0623 ,. Looks like the custom model file you are loading is not valid. Can you give a little more information on how you generated the custom model?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:62,availability,down,downloaded,62,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:53,energy efficiency,model,model,53,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:145,energy efficiency,model,models,145,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:222,energy efficiency,model,model,222,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:255,energy efficiency,model,model,255,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:261,energy efficiency,model,model,261,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:341,energy efficiency,model,models,341,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:418,energy efficiency,model,model,418,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:449,energy efficiency,model,model,449,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:455,energy efficiency,model,model,455,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:533,energy efficiency,model,models,533,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:610,energy efficiency,model,model,610,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:629,energy efficiency,model,model,629,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:635,energy efficiency,model,model,635,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:701,energy efficiency,model,models,701,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:778,energy efficiency,model,model,778,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:796,energy efficiency,model,model,796,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:802,energy efficiency,model,model,802,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:53,security,model,model,53,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:145,security,model,models,145,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:222,security,model,model,222,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:255,security,model,model,255,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:261,security,model,model,261,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:341,security,model,models,341,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:418,security,model,model,418,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:449,security,model,model,449,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:455,security,model,model,455,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:533,security,model,models,533,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:610,security,model,model,610,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:629,security,model,model,629,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:635,security,model,model,635,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:701,security,model,models,701,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:778,security,model,model,778,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:796,security,model,model,796,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:802,security,model,model,802,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:46,usability,custom,custom,46,@kishwarshafin Hi! Thanks for your reply. The custom model is downloaded from these links:. ```. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.data-00000-of-00001 > model/model.ckpt.data-00000-of-00001. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.example_info.json > model/model.ckpt.example_info.json. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.index > model/model.ckpt.index. curl https://storage.googleapis.com/deepvariant/models/DeepVariant/1.4.0/DeepVariant-inception_v3-1.4.0+data-rnaseq_standard/model.ckpt.meta > model/model.ckpt.meta. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:151,availability,sli,slim,151,"@xianyu0623 ,. You are trying to run V1.6.0 with 1.4 models which is the issue. Please use the 1.4.0 docker to run it successfully. We have moved from slim to keras between these versions so the models are not compatible.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:179,deployability,version,versions,179,"@xianyu0623 ,. You are trying to run V1.6.0 with 1.4 models which is the issue. Please use the 1.4.0 docker to run it successfully. We have moved from slim to keras between these versions so the models are not compatible.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:53,energy efficiency,model,models,53,"@xianyu0623 ,. You are trying to run V1.6.0 with 1.4 models which is the issue. Please use the 1.4.0 docker to run it successfully. We have moved from slim to keras between these versions so the models are not compatible.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:195,energy efficiency,model,models,195,"@xianyu0623 ,. You are trying to run V1.6.0 with 1.4 models which is the issue. Please use the 1.4.0 docker to run it successfully. We have moved from slim to keras between these versions so the models are not compatible.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:179,integrability,version,versions,179,"@xianyu0623 ,. You are trying to run V1.6.0 with 1.4 models which is the issue. Please use the 1.4.0 docker to run it successfully. We have moved from slim to keras between these versions so the models are not compatible.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:210,interoperability,compatib,compatible,210,"@xianyu0623 ,. You are trying to run V1.6.0 with 1.4 models which is the issue. Please use the 1.4.0 docker to run it successfully. We have moved from slim to keras between these versions so the models are not compatible.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:179,modifiability,version,versions,179,"@xianyu0623 ,. You are trying to run V1.6.0 with 1.4 models which is the issue. Please use the 1.4.0 docker to run it successfully. We have moved from slim to keras between these versions so the models are not compatible.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:151,reliability,sli,slim,151,"@xianyu0623 ,. You are trying to run V1.6.0 with 1.4 models which is the issue. Please use the 1.4.0 docker to run it successfully. We have moved from slim to keras between these versions so the models are not compatible.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:53,security,model,models,53,"@xianyu0623 ,. You are trying to run V1.6.0 with 1.4 models which is the issue. Please use the 1.4.0 docker to run it successfully. We have moved from slim to keras between these versions so the models are not compatible.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:195,security,model,models,195,"@xianyu0623 ,. You are trying to run V1.6.0 with 1.4 models which is the issue. Please use the 1.4.0 docker to run it successfully. We have moved from slim to keras between these versions so the models are not compatible.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/857:37,usability,help,help,37,@kishwarshafin Thanks a lot for your help! This works!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/857
https://github.com/google/deepvariant/issues/858:788,availability,checkpoint,checkpoint,788,"Hi @pioneer-pi . DeepVariant trains on all of chr1-chr19 and shuffles all together, as opposed to progressively going across chr1, chr2, etc... Because of some aspects of how training works, it's better to have the training batches be as uniformly sampled as possible. That corresponds to number 2 in your list. By ""clean"" DeepVariant, I assume that you mean to initialize from an InceptionV3 model that has been trained on ImageNet (that is only general images). This is possible, but you will need a large number of training examples, likely at least a few full whole genomes of examples, maybe something like 30 million created training examples, to get good performance. For most training experiments or setups, you will get better results training from an existing DeepVariant model checkpoint.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/858
https://github.com/google/deepvariant/issues/858:393,energy efficiency,model,model,393,"Hi @pioneer-pi . DeepVariant trains on all of chr1-chr19 and shuffles all together, as opposed to progressively going across chr1, chr2, etc... Because of some aspects of how training works, it's better to have the training batches be as uniformly sampled as possible. That corresponds to number 2 in your list. By ""clean"" DeepVariant, I assume that you mean to initialize from an InceptionV3 model that has been trained on ImageNet (that is only general images). This is possible, but you will need a large number of training examples, likely at least a few full whole genomes of examples, maybe something like 30 million created training examples, to get good performance. For most training experiments or setups, you will get better results training from an existing DeepVariant model checkpoint.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/858
https://github.com/google/deepvariant/issues/858:782,energy efficiency,model,model,782,"Hi @pioneer-pi . DeepVariant trains on all of chr1-chr19 and shuffles all together, as opposed to progressively going across chr1, chr2, etc... Because of some aspects of how training works, it's better to have the training batches be as uniformly sampled as possible. That corresponds to number 2 in your list. By ""clean"" DeepVariant, I assume that you mean to initialize from an InceptionV3 model that has been trained on ImageNet (that is only general images). This is possible, but you will need a large number of training examples, likely at least a few full whole genomes of examples, maybe something like 30 million created training examples, to get good performance. For most training experiments or setups, you will get better results training from an existing DeepVariant model checkpoint.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/858
https://github.com/google/deepvariant/issues/858:224,integrability,batch,batches,224,"Hi @pioneer-pi . DeepVariant trains on all of chr1-chr19 and shuffles all together, as opposed to progressively going across chr1, chr2, etc... Because of some aspects of how training works, it's better to have the training batches be as uniformly sampled as possible. That corresponds to number 2 in your list. By ""clean"" DeepVariant, I assume that you mean to initialize from an InceptionV3 model that has been trained on ImageNet (that is only general images). This is possible, but you will need a large number of training examples, likely at least a few full whole genomes of examples, maybe something like 30 million created training examples, to get good performance. For most training experiments or setups, you will get better results training from an existing DeepVariant model checkpoint.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/858
https://github.com/google/deepvariant/issues/858:224,performance,batch,batches,224,"Hi @pioneer-pi . DeepVariant trains on all of chr1-chr19 and shuffles all together, as opposed to progressively going across chr1, chr2, etc... Because of some aspects of how training works, it's better to have the training batches be as uniformly sampled as possible. That corresponds to number 2 in your list. By ""clean"" DeepVariant, I assume that you mean to initialize from an InceptionV3 model that has been trained on ImageNet (that is only general images). This is possible, but you will need a large number of training examples, likely at least a few full whole genomes of examples, maybe something like 30 million created training examples, to get good performance. For most training experiments or setups, you will get better results training from an existing DeepVariant model checkpoint.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/858
https://github.com/google/deepvariant/issues/858:662,performance,perform,performance,662,"Hi @pioneer-pi . DeepVariant trains on all of chr1-chr19 and shuffles all together, as opposed to progressively going across chr1, chr2, etc... Because of some aspects of how training works, it's better to have the training batches be as uniformly sampled as possible. That corresponds to number 2 in your list. By ""clean"" DeepVariant, I assume that you mean to initialize from an InceptionV3 model that has been trained on ImageNet (that is only general images). This is possible, but you will need a large number of training examples, likely at least a few full whole genomes of examples, maybe something like 30 million created training examples, to get good performance. For most training experiments or setups, you will get better results training from an existing DeepVariant model checkpoint.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/858
https://github.com/google/deepvariant/issues/858:788,reliability,checkpoint,checkpoint,788,"Hi @pioneer-pi . DeepVariant trains on all of chr1-chr19 and shuffles all together, as opposed to progressively going across chr1, chr2, etc... Because of some aspects of how training works, it's better to have the training batches be as uniformly sampled as possible. That corresponds to number 2 in your list. By ""clean"" DeepVariant, I assume that you mean to initialize from an InceptionV3 model that has been trained on ImageNet (that is only general images). This is possible, but you will need a large number of training examples, likely at least a few full whole genomes of examples, maybe something like 30 million created training examples, to get good performance. For most training experiments or setups, you will get better results training from an existing DeepVariant model checkpoint.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/858
https://github.com/google/deepvariant/issues/858:393,security,model,model,393,"Hi @pioneer-pi . DeepVariant trains on all of chr1-chr19 and shuffles all together, as opposed to progressively going across chr1, chr2, etc... Because of some aspects of how training works, it's better to have the training batches be as uniformly sampled as possible. That corresponds to number 2 in your list. By ""clean"" DeepVariant, I assume that you mean to initialize from an InceptionV3 model that has been trained on ImageNet (that is only general images). This is possible, but you will need a large number of training examples, likely at least a few full whole genomes of examples, maybe something like 30 million created training examples, to get good performance. For most training experiments or setups, you will get better results training from an existing DeepVariant model checkpoint.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/858
https://github.com/google/deepvariant/issues/858:782,security,model,model,782,"Hi @pioneer-pi . DeepVariant trains on all of chr1-chr19 and shuffles all together, as opposed to progressively going across chr1, chr2, etc... Because of some aspects of how training works, it's better to have the training batches be as uniformly sampled as possible. That corresponds to number 2 in your list. By ""clean"" DeepVariant, I assume that you mean to initialize from an InceptionV3 model that has been trained on ImageNet (that is only general images). This is possible, but you will need a large number of training examples, likely at least a few full whole genomes of examples, maybe something like 30 million created training examples, to get good performance. For most training experiments or setups, you will get better results training from an existing DeepVariant model checkpoint.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/858
https://github.com/google/deepvariant/issues/858:98,usability,progress,progressively,98,"Hi @pioneer-pi . DeepVariant trains on all of chr1-chr19 and shuffles all together, as opposed to progressively going across chr1, chr2, etc... Because of some aspects of how training works, it's better to have the training batches be as uniformly sampled as possible. That corresponds to number 2 in your list. By ""clean"" DeepVariant, I assume that you mean to initialize from an InceptionV3 model that has been trained on ImageNet (that is only general images). This is possible, but you will need a large number of training examples, likely at least a few full whole genomes of examples, maybe something like 30 million created training examples, to get good performance. For most training experiments or setups, you will get better results training from an existing DeepVariant model checkpoint.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/858
https://github.com/google/deepvariant/issues/858:662,usability,perform,performance,662,"Hi @pioneer-pi . DeepVariant trains on all of chr1-chr19 and shuffles all together, as opposed to progressively going across chr1, chr2, etc... Because of some aspects of how training works, it's better to have the training batches be as uniformly sampled as possible. That corresponds to number 2 in your list. By ""clean"" DeepVariant, I assume that you mean to initialize from an InceptionV3 model that has been trained on ImageNet (that is only general images). This is possible, but you will need a large number of training examples, likely at least a few full whole genomes of examples, maybe something like 30 million created training examples, to get good performance. For most training experiments or setups, you will get better results training from an existing DeepVariant model checkpoint.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/858
https://github.com/google/deepvariant/issues/858:60,usability,close,close,60,"Hi @pioneer-pi ,. Hopefully your question is answered. I'll close this issue now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/858
https://github.com/google/deepvariant/issues/859:1163,availability,error,error,1163,"g: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 195 | new_data = PyDataMem_RENEW(PyArray_DATA(ret), i * npyarr->elsize);. | ^~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c: In function Object_npyArrayAddItem:. pandas/_libs/src/ujson/python/JSONtoObj.c:260:31: error: PyArray_Descr {aka struct _PyArray_Descr} has no member named elsize. 260 | npyarr->elsize = dtype->elsize;. | ^~. pandas/_libs/src/ujson/python/JSONtoObj.c:305:59: warning: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 305 | new_data = PyDataMem_RENEW(PyArray_DATA(npyarr->ret),. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6571,availability,error,error,6571,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6656,availability,error,error,6656,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6730,availability,ERROR,ERROR,6730,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6771,availability,ERROR,ERROR,6771,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:423,deployability,build,build-env-,423,"use pandas 2.2.2 numpy 1.24.3 . pandas/_libs/src/ujson/python/JSONtoObj.c: In function Object_npyEndArray:. pandas/_libs/src/ujson/python/JSONtoObj.c:195:49: warning: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 195 | new_data = PyDataMem_RENEW(PyArray_DATA(ret), i * npyarr->elsize);. | ^~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c: In function Object_npyArrayAddItem:. pandas/_libs/src/ujson/python/JSONtoObj.c:260:31: error: PyArray_Descr {aka struct _PyArray_Descr} has no member named elsize. 260 | npyarr->elsize = dtype->elsize;. | ^~. pandas/_libs/src/ujson/python/JSONtoObj.c:305:59: warning: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 305 | new_data = PyDataMem_RENEW(PyArray_DATA(npyarr->ret),. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:540,deployability,build,build-env-,540,"use pandas 2.2.2 numpy 1.24.3 . pandas/_libs/src/ujson/python/JSONtoObj.c: In function Object_npyEndArray:. pandas/_libs/src/ujson/python/JSONtoObj.c:195:49: warning: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 195 | new_data = PyDataMem_RENEW(PyArray_DATA(ret), i * npyarr->elsize);. | ^~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c: In function Object_npyArrayAddItem:. pandas/_libs/src/ujson/python/JSONtoObj.c:260:31: error: PyArray_Descr {aka struct _PyArray_Descr} has no member named elsize. 260 | npyarr->elsize = dtype->elsize;. | ^~. pandas/_libs/src/ujson/python/JSONtoObj.c:305:59: warning: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 305 | new_data = PyDataMem_RENEW(PyArray_DATA(npyarr->ret),. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:701,deployability,build,build-env-,701,"use pandas 2.2.2 numpy 1.24.3 . pandas/_libs/src/ujson/python/JSONtoObj.c: In function Object_npyEndArray:. pandas/_libs/src/ujson/python/JSONtoObj.c:195:49: warning: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 195 | new_data = PyDataMem_RENEW(PyArray_DATA(ret), i * npyarr->elsize);. | ^~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c: In function Object_npyArrayAddItem:. pandas/_libs/src/ujson/python/JSONtoObj.c:260:31: error: PyArray_Descr {aka struct _PyArray_Descr} has no member named elsize. 260 | npyarr->elsize = dtype->elsize;. | ^~. pandas/_libs/src/ujson/python/JSONtoObj.c:305:59: warning: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 305 | new_data = PyDataMem_RENEW(PyArray_DATA(npyarr->ret),. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1599,deployability,build,build-env-,1599,"ore/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c: In function Object_npyArrayAddItem:. pandas/_libs/src/ujson/python/JSONtoObj.c:260:31: error: PyArray_Descr {aka struct _PyArray_Descr} has no member named elsize. 260 | npyarr->elsize = dtype->elsize;. | ^~. pandas/_libs/src/ujson/python/JSONtoObj.c:305:59: warning: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 305 | new_data = PyDataMem_RENEW(PyArray_DATA(npyarr->ret),. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:316:24: warning: passing argument 1 of PyArray_DIMS from incompatible pointer type [-Wincompatible-pointer-types]. 316 | PyArray_DIMS(npyarr->ret)[0] = i + 1;. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. fr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1716,deployability,build,build-env-,1716,"verlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c: In function Object_npyArrayAddItem:. pandas/_libs/src/ujson/python/JSONtoObj.c:260:31: error: PyArray_Descr {aka struct _PyArray_Descr} has no member named elsize. 260 | npyarr->elsize = dtype->elsize;. | ^~. pandas/_libs/src/ujson/python/JSONtoObj.c:305:59: warning: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 305 | new_data = PyDataMem_RENEW(PyArray_DATA(npyarr->ret),. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:316:24: warning: passing argument 1 of PyArray_DIMS from incompatible pointer type [-Wincompatible-pointer-types]. 316 | PyArray_DIMS(npyarr->ret)[0] = i + 1;. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1877,deployability,build,build-env-,1877,"fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c: In function Object_npyArrayAddItem:. pandas/_libs/src/ujson/python/JSONtoObj.c:260:31: error: PyArray_Descr {aka struct _PyArray_Descr} has no member named elsize. 260 | npyarr->elsize = dtype->elsize;. | ^~. pandas/_libs/src/ujson/python/JSONtoObj.c:305:59: warning: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 305 | new_data = PyDataMem_RENEW(PyArray_DATA(npyarr->ret),. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:316:24: warning: passing argument 1 of PyArray_DIMS from incompatible pointer type [-Wincompatible-pointer-types]. 316 | PyArray_DIMS(npyarr->ret)[0] = i + 1;. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1520:35:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2499,deployability,build,build-env-,2499,"ret),. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:316:24: warning: passing argument 1 of PyArray_DIMS from incompatible pointer type [-Wincompatible-pointer-types]. 316 | PyArray_DIMS(npyarr->ret)[0] = i + 1;. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1520:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1520 | PyArray_DIMS(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_BYTES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2616,deployability,build,build-env-,2616,"rlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:316:24: warning: passing argument 1 of PyArray_DIMS from incompatible pointer type [-Wincompatible-pointer-types]. 316 | PyArray_DIMS(npyarr->ret)[0] = i + 1;. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1520:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1520 | PyArray_DIMS(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_BYTES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2777,deployability,build,build-env-,2777,"e/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:316:24: warning: passing argument 1 of PyArray_DIMS from incompatible pointer type [-Wincompatible-pointer-types]. 316 | PyArray_DIMS(npyarr->ret)[0] = i + 1;. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1520:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1520 | PyArray_DIMS(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_BYTES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:138:57: note: in definition of macro PyArray_GETPTR1. 138 | #define PyArray_GETPTR1(obj, i) ((void *)(P",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3138,deployability,build,build-env-,3138,"ray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:316:24: warning: passing argument 1 of PyArray_DIMS from incompatible pointer type [-Wincompatible-pointer-types]. 316 | PyArray_DIMS(npyarr->ret)[0] = i + 1;. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1520:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1520 | PyArray_DIMS(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_BYTES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:138:57: note: in definition of macro PyArray_GETPTR1. 138 | #define PyArray_GETPTR1(obj, i) ((void *)(PyArray_BYTES(obj) + \. | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/ove",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3579,deployability,build,build-env-,3579,"rrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1520:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1520 | PyArray_DIMS(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_BYTES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:138:57: note: in definition of macro PyArray_GETPTR1. 138 | #define PyArray_GETPTR1(obj, i) ((void *)(PyArray_BYTES(obj) + \. | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1514:36: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1514 | PyArray_BYTES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. f",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3843,deployability,build,build-env-,3843,"lude/numpy/ndarraytypes.h:1520:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1520 | PyArray_DIMS(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_BYTES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:138:57: note: in definition of macro PyArray_GETPTR1. 138 | #define PyArray_GETPTR1(obj, i) ((void *)(PyArray_BYTES(obj) + \. | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1514:36: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1514 | PyArray_BYTES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_STRIDES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3960,deployability,build,build-env-,3960,"*} but argument is of type PyObject * {aka struct _object *}. 1520 | PyArray_DIMS(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_BYTES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:138:57: note: in definition of macro PyArray_GETPTR1. 138 | #define PyArray_GETPTR1(obj, i) ((void *)(PyArray_BYTES(obj) + \. | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1514:36: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1514 | PyArray_BYTES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_STRIDES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4121,deployability,build,build-env-,4121,"om /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_BYTES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:138:57: note: in definition of macro PyArray_GETPTR1. 138 | #define PyArray_GETPTR1(obj, i) ((void *)(PyArray_BYTES(obj) + \. | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1514:36: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1514 | PyArray_BYTES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_STRIDES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4483,deployability,build,build-env-,4483,"rr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:138:57: note: in definition of macro PyArray_GETPTR1. 138 | #define PyArray_GETPTR1(obj, i) ((void *)(PyArray_BYTES(obj) + \. | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1514:36: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1514 | PyArray_BYTES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_STRIDES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4926,deployability,build,build-env-,4926,"yobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1514:36: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1514 | PyArray_BYTES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_STRIDES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5155,deployability,build,build-env-,5155,"10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1514:36: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1514 | PyArray_BYTES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_STRIDES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arra",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5272,deployability,build,build-env-,5272," struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1514 | PyArray_BYTES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_STRIDES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5433,deployability,build,build-env-,5433,"~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_STRIDES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6074,deployability,build,build-env-,6074,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6235,deployability,build,build-env-,6235,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6601,deployability,fail,failed,6601,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6737,deployability,Fail,Failed,6737,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6744,deployability,build,building,6744,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6788,deployability,build,build,6788,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6834,deployability,instal,install,6834,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6680,integrability,sub,subprocess,6680,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:211,interoperability,incompatib,incompatible,211,"use pandas 2.2.2 numpy 1.24.3 . pandas/_libs/src/ujson/python/JSONtoObj.c: In function Object_npyEndArray:. pandas/_libs/src/ujson/python/JSONtoObj.c:195:49: warning: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 195 | new_data = PyDataMem_RENEW(PyArray_DATA(ret), i * npyarr->elsize);. | ^~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c: In function Object_npyArrayAddItem:. pandas/_libs/src/ujson/python/JSONtoObj.c:260:31: error: PyArray_Descr {aka struct _PyArray_Descr} has no member named elsize. 260 | npyarr->elsize = dtype->elsize;. | ^~. pandas/_libs/src/ujson/python/JSONtoObj.c:305:59: warning: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 305 | new_data = PyDataMem_RENEW(PyArray_DATA(npyarr->ret),. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1392,interoperability,incompatib,incompatible,1392,"e included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c: In function Object_npyArrayAddItem:. pandas/_libs/src/ujson/python/JSONtoObj.c:260:31: error: PyArray_Descr {aka struct _PyArray_Descr} has no member named elsize. 260 | npyarr->elsize = dtype->elsize;. | ^~. pandas/_libs/src/ujson/python/JSONtoObj.c:305:59: warning: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 305 | new_data = PyDataMem_RENEW(PyArray_DATA(npyarr->ret),. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:316:24: warning: passing argument 1 of PyArray_DIMS from incompatible pointer type [-Wincompatible-pointer-types]. 316 | PyArray_DIMS(npyarr->ret)[",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2308,interoperability,incompatib,incompatible,2308,"python/JSONtoObj.c:305:59: warning: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 305 | new_data = PyDataMem_RENEW(PyArray_DATA(npyarr->ret),. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:316:24: warning: passing argument 1 of PyArray_DIMS from incompatible pointer type [-Wincompatible-pointer-types]. 316 | PyArray_DIMS(npyarr->ret)[0] = i + 1;. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1520:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1520 | PyArray_DIMS(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3392,interoperability,incompatib,incompatible,3392,"0] = i + 1;. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1520:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1520 | PyArray_DIMS(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_BYTES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:138:57: note: in definition of macro PyArray_GETPTR1. 138 | #define PyArray_GETPTR1(obj, i) ((void *)(PyArray_BYTES(obj) + \. | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1514:36: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1514 | PyArray_BYTES(c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4739,interoperability,incompatib,incompatible,4739,"e PyArray_GETPTR1(obj, i) ((void *)(PyArray_BYTES(obj) + \. | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1514:36: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1514 | PyArray_BYTES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_STRIDES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5870,interoperability,incompatib,incompatible,5870,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:470,modifiability,pac,packages,470,"use pandas 2.2.2 numpy 1.24.3 . pandas/_libs/src/ujson/python/JSONtoObj.c: In function Object_npyEndArray:. pandas/_libs/src/ujson/python/JSONtoObj.c:195:49: warning: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 195 | new_data = PyDataMem_RENEW(PyArray_DATA(ret), i * npyarr->elsize);. | ^~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c: In function Object_npyArrayAddItem:. pandas/_libs/src/ujson/python/JSONtoObj.c:260:31: error: PyArray_Descr {aka struct _PyArray_Descr} has no member named elsize. 260 | npyarr->elsize = dtype->elsize;. | ^~. pandas/_libs/src/ujson/python/JSONtoObj.c:305:59: warning: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 305 | new_data = PyDataMem_RENEW(PyArray_DATA(npyarr->ret),. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:587,modifiability,pac,packages,587,"use pandas 2.2.2 numpy 1.24.3 . pandas/_libs/src/ujson/python/JSONtoObj.c: In function Object_npyEndArray:. pandas/_libs/src/ujson/python/JSONtoObj.c:195:49: warning: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 195 | new_data = PyDataMem_RENEW(PyArray_DATA(ret), i * npyarr->elsize);. | ^~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c: In function Object_npyArrayAddItem:. pandas/_libs/src/ujson/python/JSONtoObj.c:260:31: error: PyArray_Descr {aka struct _PyArray_Descr} has no member named elsize. 260 | npyarr->elsize = dtype->elsize;. | ^~. pandas/_libs/src/ujson/python/JSONtoObj.c:305:59: warning: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 305 | new_data = PyDataMem_RENEW(PyArray_DATA(npyarr->ret),. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:748,modifiability,pac,packages,748,"use pandas 2.2.2 numpy 1.24.3 . pandas/_libs/src/ujson/python/JSONtoObj.c: In function Object_npyEndArray:. pandas/_libs/src/ujson/python/JSONtoObj.c:195:49: warning: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 195 | new_data = PyDataMem_RENEW(PyArray_DATA(ret), i * npyarr->elsize);. | ^~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c: In function Object_npyArrayAddItem:. pandas/_libs/src/ujson/python/JSONtoObj.c:260:31: error: PyArray_Descr {aka struct _PyArray_Descr} has no member named elsize. 260 | npyarr->elsize = dtype->elsize;. | ^~. pandas/_libs/src/ujson/python/JSONtoObj.c:305:59: warning: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 305 | new_data = PyDataMem_RENEW(PyArray_DATA(npyarr->ret),. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1646,modifiability,pac,packages,1646,"s/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c: In function Object_npyArrayAddItem:. pandas/_libs/src/ujson/python/JSONtoObj.c:260:31: error: PyArray_Descr {aka struct _PyArray_Descr} has no member named elsize. 260 | npyarr->elsize = dtype->elsize;. | ^~. pandas/_libs/src/ujson/python/JSONtoObj.c:305:59: warning: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 305 | new_data = PyDataMem_RENEW(PyArray_DATA(npyarr->ret),. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:316:24: warning: passing argument 1 of PyArray_DIMS from incompatible pointer type [-Wincompatible-pointer-types]. 316 | PyArray_DIMS(npyarr->ret)[0] = i + 1;. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/pyt",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1763,modifiability,pac,packages,1763,"e/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c: In function Object_npyArrayAddItem:. pandas/_libs/src/ujson/python/JSONtoObj.c:260:31: error: PyArray_Descr {aka struct _PyArray_Descr} has no member named elsize. 260 | npyarr->elsize = dtype->elsize;. | ^~. pandas/_libs/src/ujson/python/JSONtoObj.c:305:59: warning: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 305 | new_data = PyDataMem_RENEW(PyArray_DATA(npyarr->ret),. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:316:24: warning: passing argument 1 of PyArray_DIMS from incompatible pointer type [-Wincompatible-pointer-types]. 316 | PyArray_DIMS(npyarr->ret)[0] = i + 1;. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1924,modifiability,pac,packages,1924," {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c: In function Object_npyArrayAddItem:. pandas/_libs/src/ujson/python/JSONtoObj.c:260:31: error: PyArray_Descr {aka struct _PyArray_Descr} has no member named elsize. 260 | npyarr->elsize = dtype->elsize;. | ^~. pandas/_libs/src/ujson/python/JSONtoObj.c:305:59: warning: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 305 | new_data = PyDataMem_RENEW(PyArray_DATA(npyarr->ret),. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:316:24: warning: passing argument 1 of PyArray_DIMS from incompatible pointer type [-Wincompatible-pointer-types]. 316 | PyArray_DIMS(npyarr->ret)[0] = i + 1;. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1520:35: note: expected const PyArrayObject * {aka ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2546,modifiability,pac,packages,2546,"truct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:316:24: warning: passing argument 1 of PyArray_DIMS from incompatible pointer type [-Wincompatible-pointer-types]. 316 | PyArray_DIMS(npyarr->ret)[0] = i + 1;. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1520:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1520 | PyArray_DIMS(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_BYTES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2663,modifiability,pac,packages,2663,"include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:316:24: warning: passing argument 1 of PyArray_DIMS from incompatible pointer type [-Wincompatible-pointer-types]. 316 | PyArray_DIMS(npyarr->ret)[0] = i + 1;. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1520:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1520 | PyArray_DIMS(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_BYTES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarra",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:2824,modifiability,pac,packages,2824,"_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:316:24: warning: passing argument 1 of PyArray_DIMS from incompatible pointer type [-Wincompatible-pointer-types]. 316 | PyArray_DIMS(npyarr->ret)[0] = i + 1;. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1520:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1520 | PyArray_DIMS(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_BYTES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:138:57: note: in definition of macro PyArray_GETPTR1. 138 | #define PyArray_GETPTR1(obj, i) ((void *)(PyArray_BYTES(obj) + \. | ^~~. In file included",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3185,modifiability,pac,packages,3185,"~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:316:24: warning: passing argument 1 of PyArray_DIMS from incompatible pointer type [-Wincompatible-pointer-types]. 316 | PyArray_DIMS(npyarr->ret)[0] = i + 1;. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1520:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1520 | PyArray_DIMS(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_BYTES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:138:57: note: in definition of macro PyArray_GETPTR1. 138 | #define PyArray_GETPTR1(obj, i) ((void *)(PyArray_BYTES(obj) + \. | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3626,modifiability,pac,packages,3626,"nwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1520:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1520 | PyArray_DIMS(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_BYTES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:138:57: note: in definition of macro PyArray_GETPTR1. 138 | #define PyArray_GETPTR1(obj, i) ((void *)(PyArray_BYTES(obj) + \. | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1514:36: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1514 | PyArray_BYTES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:3890,modifiability,pac,packages,3890,"ted const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1520 | PyArray_DIMS(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_BYTES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:138:57: note: in definition of macro PyArray_GETPTR1. 138 | #define PyArray_GETPTR1(obj, i) ((void *)(PyArray_BYTES(obj) + \. | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1514:36: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1514 | PyArray_BYTES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_STRIDES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4007,modifiability,pac,packages,4007,"struct _object *}. 1520 | PyArray_DIMS(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_BYTES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:138:57: note: in definition of macro PyArray_GETPTR1. 138 | #define PyArray_GETPTR1(obj, i) ((void *)(PyArray_BYTES(obj) + \. | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1514:36: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1514 | PyArray_BYTES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_STRIDES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/nda",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4168,modifiability,pac,packages,4168,"hon3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_BYTES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:138:57: note: in definition of macro PyArray_GETPTR1. 138 | #define PyArray_GETPTR1(obj, i) ((void *)(PyArray_BYTES(obj) + \. | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1514:36: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1514 | PyArray_BYTES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_STRIDES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4530,modifiability,pac,packages,4530," PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:138:57: note: in definition of macro PyArray_GETPTR1. 138 | #define PyArray_GETPTR1(obj, i) ((void *)(PyArray_BYTES(obj) + \. | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1514:36: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1514 | PyArray_BYTES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_STRIDES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:4973,modifiability,pac,packages,4973,"z/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1514:36: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1514 | PyArray_BYTES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_STRIDES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) =",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5202,modifiability,pac,packages,5202,"rraytypes.h:1514:36: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1514 | PyArray_BYTES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_STRIDES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/pyth",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5319,modifiability,pac,packages,5319,"nt is of type PyObject * {aka struct _object *}. 1514 | PyArray_BYTES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_STRIDES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarra",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:5480,modifiability,pac,packages,5480,"uild-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. pandas/_libs/src/ujson/python/JSONtoObj.c:318:39: warning: passing argument 1 of PyArray_STRIDES from incompatible pointer type [-Wincompatible-pointer-types]. 318 | if ((item = PyArray_GETPTR1(npyarr->ret, i)) == NULL ||. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6121,modifiability,pac,packages,6121,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6282,modifiability,pac,packages,6282,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1163,performance,error,error,1163,"g: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 195 | new_data = PyDataMem_RENEW(PyArray_DATA(ret), i * npyarr->elsize);. | ^~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c: In function Object_npyArrayAddItem:. pandas/_libs/src/ujson/python/JSONtoObj.c:260:31: error: PyArray_Descr {aka struct _PyArray_Descr} has no member named elsize. 260 | npyarr->elsize = dtype->elsize;. | ^~. pandas/_libs/src/ujson/python/JSONtoObj.c:305:59: warning: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 305 | new_data = PyDataMem_RENEW(PyArray_DATA(npyarr->ret),. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6571,performance,error,error,6571,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6656,performance,error,error,6656,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6730,performance,ERROR,ERROR,6730,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6771,performance,ERROR,ERROR,6771,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6601,reliability,fail,failed,6601,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6737,reliability,Fail,Failed,6737,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1163,safety,error,error,1163,"g: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 195 | new_data = PyDataMem_RENEW(PyArray_DATA(ret), i * npyarr->elsize);. | ^~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c: In function Object_npyArrayAddItem:. pandas/_libs/src/ujson/python/JSONtoObj.c:260:31: error: PyArray_Descr {aka struct _PyArray_Descr} has no member named elsize. 260 | npyarr->elsize = dtype->elsize;. | ^~. pandas/_libs/src/ujson/python/JSONtoObj.c:305:59: warning: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 305 | new_data = PyDataMem_RENEW(PyArray_DATA(npyarr->ret),. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6571,safety,error,error,6571,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6656,safety,error,error,6656,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6730,safety,ERROR,ERROR,6730,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6771,safety,ERROR,ERROR,6771,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:1163,usability,error,error,1163,"g: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 195 | new_data = PyDataMem_RENEW(PyArray_DATA(ret), i * npyarr->elsize);. | ^~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c: In function Object_npyArrayAddItem:. pandas/_libs/src/ujson/python/JSONtoObj.c:260:31: error: PyArray_Descr {aka struct _PyArray_Descr} has no member named elsize. 260 | npyarr->elsize = dtype->elsize;. | ^~. pandas/_libs/src/ujson/python/JSONtoObj.c:305:59: warning: passing argument 1 of PyArray_DATA from incompatible pointer type [-Wincompatible-pointer-types]. 305 | new_data = PyDataMem_RENEW(PyArray_DATA(npyarr->ret),. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1508:35: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1508 | PyArray_DATA(const PyArrayO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6571,usability,error,error,6571,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6578,usability,command,command,6578,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6656,usability,error,error,6656,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6730,usability,ERROR,ERROR,6730,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:6771,usability,ERROR,ERROR,6771,"~~. | |. | PyObject * {aka struct _object *}. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:139:62: note: in definition of macro PyArray_GETPTR1. 139 | (i)*PyArray_STRIDES(obj)[0])). | ^~~. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:12,. from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarraytypes.h:1526:38: note: expected const PyArrayObject * {aka const struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 1526 | PyArray_STRIDES(const PyArrayObject *arr). | ~~~~~~~~~~~~~~~~~~~~~^~~. pandas/_libs/src/ujson/python/JSONtoObj.c:319:31: warning: passing argument 1 of PyArray_SETITEM from incompatible pointer type [-Wincompatible-pointer-types]. 319 | PyArray_SETITEM(npyarr->ret, item, value) == -1) {. | ~~~~~~^~~~~. | |. | PyObject * {aka struct _object *}. In file included from /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/arrayobject.h:5,. from pandas/_libs/src/ujson/python/JSONtoObj.c:42:. /tmp/pip-build-env-ga9pnwrz/overlay/lib/python3.10/site-packages/numpy/_core/include/numpy/ndarrayobject.h:292:32: note: expected PyArrayObject * {aka struct tagPyArrayObject_fields *} but argument is of type PyObject * {aka struct _object *}. 292 | PyArray_SETITEM(PyArrayObject *arr, char *itemptr, PyObject *v). | ~~~~~~~~~~~~~~~^~~. error: command '/usr/bin/gcc' failed with exit code 1. [end of output]. . note: This error originates from a subprocess, and is likely not a problem with pip. ERROR: Failed building wheel for pandas. ERROR: Could not build wheels for pandas, which is required to install pyproject.toml-based projects",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:66,availability,error,errors,66,"@zhl201226 , what OS are you building this on? Also, a lot of the errors can be due to permission error, are you running this as root?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:98,availability,error,error,98,"@zhl201226 , what OS are you building this on? Also, a lot of the errors can be due to permission error, are you running this as root?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:29,deployability,build,building,29,"@zhl201226 , what OS are you building this on? Also, a lot of the errors can be due to permission error, are you running this as root?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:66,performance,error,errors,66,"@zhl201226 , what OS are you building this on? Also, a lot of the errors can be due to permission error, are you running this as root?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:98,performance,error,error,98,"@zhl201226 , what OS are you building this on? Also, a lot of the errors can be due to permission error, are you running this as root?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:66,safety,error,errors,66,"@zhl201226 , what OS are you building this on? Also, a lot of the errors can be due to permission error, are you running this as root?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:87,safety,permiss,permission,87,"@zhl201226 , what OS are you building this on? Also, a lot of the errors can be due to permission error, are you running this as root?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:98,safety,error,error,98,"@zhl201226 , what OS are you building this on? Also, a lot of the errors can be due to permission error, are you running this as root?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:66,usability,error,errors,66,"@zhl201226 , what OS are you building this on? Also, a lot of the errors can be due to permission error, are you running this as root?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:98,usability,error,error,98,"@zhl201226 , what OS are you building this on? Also, a lot of the errors can be due to permission error, are you running this as root?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:68,availability,error,errors,68,"> @zhl201226 , what OS are you building this on? Also, a lot of the errors can be due to permission error, are you running this as root? OS:Ubuntu 20.04 , I also running with root",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:100,availability,error,error,100,"> @zhl201226 , what OS are you building this on? Also, a lot of the errors can be due to permission error, are you running this as root? OS:Ubuntu 20.04 , I also running with root",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:31,deployability,build,building,31,"> @zhl201226 , what OS are you building this on? Also, a lot of the errors can be due to permission error, are you running this as root? OS:Ubuntu 20.04 , I also running with root",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:68,performance,error,errors,68,"> @zhl201226 , what OS are you building this on? Also, a lot of the errors can be due to permission error, are you running this as root? OS:Ubuntu 20.04 , I also running with root",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:100,performance,error,error,100,"> @zhl201226 , what OS are you building this on? Also, a lot of the errors can be due to permission error, are you running this as root? OS:Ubuntu 20.04 , I also running with root",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:68,safety,error,errors,68,"> @zhl201226 , what OS are you building this on? Also, a lot of the errors can be due to permission error, are you running this as root? OS:Ubuntu 20.04 , I also running with root",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:89,safety,permiss,permission,89,"> @zhl201226 , what OS are you building this on? Also, a lot of the errors can be due to permission error, are you running this as root? OS:Ubuntu 20.04 , I also running with root",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:100,safety,error,error,100,"> @zhl201226 , what OS are you building this on? Also, a lot of the errors can be due to permission error, are you running this as root? OS:Ubuntu 20.04 , I also running with root",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:68,usability,error,errors,68,"> @zhl201226 , what OS are you building this on? Also, a lot of the errors can be due to permission error, are you running this as root? OS:Ubuntu 20.04 , I also running with root",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/859:100,usability,error,error,100,"> @zhl201226 , what OS are you building this on? Also, a lot of the errors can be due to permission error, are you running this as root? OS:Ubuntu 20.04 , I also running with root",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/859
https://github.com/google/deepvariant/issues/860:134,deployability,contain,contains,134,"Hi @ejc043 , please take a look at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-details-training-data.md, which contains some more information about our training data of each version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/860
https://github.com/google/deepvariant/issues/860:197,deployability,version,version,197,"Hi @ejc043 , please take a look at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-details-training-data.md, which contains some more information about our training data of each version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/860
https://github.com/google/deepvariant/issues/860:197,integrability,version,version,197,"Hi @ejc043 , please take a look at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-details-training-data.md, which contains some more information about our training data of each version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/860
https://github.com/google/deepvariant/issues/860:197,modifiability,version,version,197,"Hi @ejc043 , please take a look at https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-details-training-data.md, which contains some more information about our training data of each version.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/860
https://github.com/google/deepvariant/issues/860:33,usability,help,helpful,33,Thank you so much!! This is very helpful. I will close the issue :~),MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/860
https://github.com/google/deepvariant/issues/860:49,usability,close,close,49,Thank you so much!! This is very helpful. I will close the issue :~),MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/860
https://github.com/google/deepvariant/issues/860:16,deployability,version,version,16,"In terms of the version of truth files we use, we current use GIAB v4.2.1 truth.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/860
https://github.com/google/deepvariant/issues/860:50,energy efficiency,current,current,50,"In terms of the version of truth files we use, we current use GIAB v4.2.1 truth.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/860
https://github.com/google/deepvariant/issues/860:16,integrability,version,version,16,"In terms of the version of truth files we use, we current use GIAB v4.2.1 truth.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/860
https://github.com/google/deepvariant/issues/860:16,modifiability,version,version,16,"In terms of the version of truth files we use, we current use GIAB v4.2.1 truth.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/860
https://github.com/google/deepvariant/issues/861:108,energy efficiency,predict,predict,108,"@ejc043 , . Channel 5, read supports variants highlight each read that supports the allele we are trying to predict. Channel 6, base differs from ref highlights all the bases, irrespective of alleles that do not agree with the reference at that position. Channel 5 captures read status vs reference against the proposed allele while channel 6 captures the base status against the reference irrespective of the allele proposed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/861
https://github.com/google/deepvariant/issues/861:108,safety,predict,predict,108,"@ejc043 , . Channel 5, read supports variants highlight each read that supports the allele we are trying to predict. Channel 6, base differs from ref highlights all the bases, irrespective of alleles that do not agree with the reference at that position. Channel 5 captures read status vs reference against the proposed allele while channel 6 captures the base status against the reference irrespective of the allele proposed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/861
https://github.com/google/deepvariant/issues/861:28,usability,support,supports,28,"@ejc043 , . Channel 5, read supports variants highlight each read that supports the allele we are trying to predict. Channel 6, base differs from ref highlights all the bases, irrespective of alleles that do not agree with the reference at that position. Channel 5 captures read status vs reference against the proposed allele while channel 6 captures the base status against the reference irrespective of the allele proposed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/861
https://github.com/google/deepvariant/issues/861:71,usability,support,supports,71,"@ejc043 , . Channel 5, read supports variants highlight each read that supports the allele we are trying to predict. Channel 6, base differs from ref highlights all the bases, irrespective of alleles that do not agree with the reference at that position. Channel 5 captures read status vs reference against the proposed allele while channel 6 captures the base status against the reference irrespective of the allele proposed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/861
https://github.com/google/deepvariant/issues/861:279,usability,statu,status,279,"@ejc043 , . Channel 5, read supports variants highlight each read that supports the allele we are trying to predict. Channel 6, base differs from ref highlights all the bases, irrespective of alleles that do not agree with the reference at that position. Channel 5 captures read status vs reference against the proposed allele while channel 6 captures the base status against the reference irrespective of the allele proposed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/861
https://github.com/google/deepvariant/issues/861:361,usability,statu,status,361,"@ejc043 , . Channel 5, read supports variants highlight each read that supports the allele we are trying to predict. Channel 6, base differs from ref highlights all the bases, irrespective of alleles that do not agree with the reference at that position. Channel 5 captures read status vs reference against the proposed allele while channel 6 captures the base status against the reference irrespective of the allele proposed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/861
https://github.com/google/deepvariant/issues/861:55,usability,close,close,55,"Hi @ejc043 , hopefully your question is answered. I'll close this issue now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/861
https://github.com/google/deepvariant/issues/862:55,deployability,contain,container,55,"Hi @gambalab,. We don't officially support Singularity container. But, you may check [this issue](https://github.com/google/deepvariant/issues/812#issuecomment-2076206716) where all the step to build and run with Singularity are described. Hope it helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/862
https://github.com/google/deepvariant/issues/862:194,deployability,build,build,194,"Hi @gambalab,. We don't officially support Singularity container. But, you may check [this issue](https://github.com/google/deepvariant/issues/812#issuecomment-2076206716) where all the step to build and run with Singularity are described. Hope it helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/862
https://github.com/google/deepvariant/issues/862:35,usability,support,support,35,"Hi @gambalab,. We don't officially support Singularity container. But, you may check [this issue](https://github.com/google/deepvariant/issues/812#issuecomment-2076206716) where all the step to build and run with Singularity are described. Hope it helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/862
https://github.com/google/deepvariant/issues/862:248,usability,help,helps,248,"Hi @gambalab,. We don't officially support Singularity container. But, you may check [this issue](https://github.com/google/deepvariant/issues/812#issuecomment-2076206716) where all the step to build and run with Singularity are described. Hope it helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/862
https://github.com/google/deepvariant/issues/863:25,integrability,filter,filtered,25,"ah, forgot to mention, I filtered chimeric reads because I had around 60% of them in every tested sample, was curious how much it affects my results (using samplix enrichment + pacbio hifi)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/863
https://github.com/google/deepvariant/issues/863:177,modifiability,pac,pacbio,177,"ah, forgot to mention, I filtered chimeric reads because I had around 60% of them in every tested sample, was curious how much it affects my results (using samplix enrichment + pacbio hifi)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/863
https://github.com/google/deepvariant/issues/863:91,safety,test,tested,91,"ah, forgot to mention, I filtered chimeric reads because I had around 60% of them in every tested sample, was curious how much it affects my results (using samplix enrichment + pacbio hifi)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/863
https://github.com/google/deepvariant/issues/863:91,testability,test,tested,91,"ah, forgot to mention, I filtered chimeric reads because I had around 60% of them in every tested sample, was curious how much it affects my results (using samplix enrichment + pacbio hifi)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/863
https://github.com/google/deepvariant/issues/863:386,deployability,depend,depends,386,"Hi @alisamatisse,. I'm not sure what `samtools view -h -F 2048` does. DeepVariant does not do any special processing for chimeric reads. What reads are used from the input BAM is controlled by the following flags: . * `--keep_duplicates` default to False. * `--keep_supplementary_alignments` default to False. * `--keep_secondary_alignments` default to False. * `--min_mapping_quality` depends on the data, for PacBio it is set to 1. Variants are created for all positions where there are at least two reads support an alt allele.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/863
https://github.com/google/deepvariant/issues/863:386,integrability,depend,depends,386,"Hi @alisamatisse,. I'm not sure what `samtools view -h -F 2048` does. DeepVariant does not do any special processing for chimeric reads. What reads are used from the input BAM is controlled by the following flags: . * `--keep_duplicates` default to False. * `--keep_supplementary_alignments` default to False. * `--keep_secondary_alignments` default to False. * `--min_mapping_quality` depends on the data, for PacBio it is set to 1. Variants are created for all positions where there are at least two reads support an alt allele.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/863
https://github.com/google/deepvariant/issues/863:386,modifiability,depend,depends,386,"Hi @alisamatisse,. I'm not sure what `samtools view -h -F 2048` does. DeepVariant does not do any special processing for chimeric reads. What reads are used from the input BAM is controlled by the following flags: . * `--keep_duplicates` default to False. * `--keep_supplementary_alignments` default to False. * `--keep_secondary_alignments` default to False. * `--min_mapping_quality` depends on the data, for PacBio it is set to 1. Variants are created for all positions where there are at least two reads support an alt allele.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/863
https://github.com/google/deepvariant/issues/863:411,modifiability,Pac,PacBio,411,"Hi @alisamatisse,. I'm not sure what `samtools view -h -F 2048` does. DeepVariant does not do any special processing for chimeric reads. What reads are used from the input BAM is controlled by the following flags: . * `--keep_duplicates` default to False. * `--keep_supplementary_alignments` default to False. * `--keep_secondary_alignments` default to False. * `--min_mapping_quality` depends on the data, for PacBio it is set to 1. Variants are created for all positions where there are at least two reads support an alt allele.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/863
https://github.com/google/deepvariant/issues/863:64,reliability,doe,does,64,"Hi @alisamatisse,. I'm not sure what `samtools view -h -F 2048` does. DeepVariant does not do any special processing for chimeric reads. What reads are used from the input BAM is controlled by the following flags: . * `--keep_duplicates` default to False. * `--keep_supplementary_alignments` default to False. * `--keep_secondary_alignments` default to False. * `--min_mapping_quality` depends on the data, for PacBio it is set to 1. Variants are created for all positions where there are at least two reads support an alt allele.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/863
https://github.com/google/deepvariant/issues/863:82,reliability,doe,does,82,"Hi @alisamatisse,. I'm not sure what `samtools view -h -F 2048` does. DeepVariant does not do any special processing for chimeric reads. What reads are used from the input BAM is controlled by the following flags: . * `--keep_duplicates` default to False. * `--keep_supplementary_alignments` default to False. * `--keep_secondary_alignments` default to False. * `--min_mapping_quality` depends on the data, for PacBio it is set to 1. Variants are created for all positions where there are at least two reads support an alt allele.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/863
https://github.com/google/deepvariant/issues/863:166,safety,input,input,166,"Hi @alisamatisse,. I'm not sure what `samtools view -h -F 2048` does. DeepVariant does not do any special processing for chimeric reads. What reads are used from the input BAM is controlled by the following flags: . * `--keep_duplicates` default to False. * `--keep_supplementary_alignments` default to False. * `--keep_secondary_alignments` default to False. * `--min_mapping_quality` depends on the data, for PacBio it is set to 1. Variants are created for all positions where there are at least two reads support an alt allele.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/863
https://github.com/google/deepvariant/issues/863:386,safety,depend,depends,386,"Hi @alisamatisse,. I'm not sure what `samtools view -h -F 2048` does. DeepVariant does not do any special processing for chimeric reads. What reads are used from the input BAM is controlled by the following flags: . * `--keep_duplicates` default to False. * `--keep_supplementary_alignments` default to False. * `--keep_secondary_alignments` default to False. * `--min_mapping_quality` depends on the data, for PacBio it is set to 1. Variants are created for all positions where there are at least two reads support an alt allele.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/863
https://github.com/google/deepvariant/issues/863:179,security,control,controlled,179,"Hi @alisamatisse,. I'm not sure what `samtools view -h -F 2048` does. DeepVariant does not do any special processing for chimeric reads. What reads are used from the input BAM is controlled by the following flags: . * `--keep_duplicates` default to False. * `--keep_supplementary_alignments` default to False. * `--keep_secondary_alignments` default to False. * `--min_mapping_quality` depends on the data, for PacBio it is set to 1. Variants are created for all positions where there are at least two reads support an alt allele.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/863
https://github.com/google/deepvariant/issues/863:179,testability,control,controlled,179,"Hi @alisamatisse,. I'm not sure what `samtools view -h -F 2048` does. DeepVariant does not do any special processing for chimeric reads. What reads are used from the input BAM is controlled by the following flags: . * `--keep_duplicates` default to False. * `--keep_supplementary_alignments` default to False. * `--keep_secondary_alignments` default to False. * `--min_mapping_quality` depends on the data, for PacBio it is set to 1. Variants are created for all positions where there are at least two reads support an alt allele.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/863
https://github.com/google/deepvariant/issues/863:386,testability,depend,depends,386,"Hi @alisamatisse,. I'm not sure what `samtools view -h -F 2048` does. DeepVariant does not do any special processing for chimeric reads. What reads are used from the input BAM is controlled by the following flags: . * `--keep_duplicates` default to False. * `--keep_supplementary_alignments` default to False. * `--keep_secondary_alignments` default to False. * `--min_mapping_quality` depends on the data, for PacBio it is set to 1. Variants are created for all positions where there are at least two reads support an alt allele.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/863
https://github.com/google/deepvariant/issues/863:166,usability,input,input,166,"Hi @alisamatisse,. I'm not sure what `samtools view -h -F 2048` does. DeepVariant does not do any special processing for chimeric reads. What reads are used from the input BAM is controlled by the following flags: . * `--keep_duplicates` default to False. * `--keep_supplementary_alignments` default to False. * `--keep_secondary_alignments` default to False. * `--min_mapping_quality` depends on the data, for PacBio it is set to 1. Variants are created for all positions where there are at least two reads support an alt allele.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/863
https://github.com/google/deepvariant/issues/863:508,usability,support,support,508,"Hi @alisamatisse,. I'm not sure what `samtools view -h -F 2048` does. DeepVariant does not do any special processing for chimeric reads. What reads are used from the input BAM is controlled by the following flags: . * `--keep_duplicates` default to False. * `--keep_supplementary_alignments` default to False. * `--keep_secondary_alignments` default to False. * `--min_mapping_quality` depends on the data, for PacBio it is set to 1. Variants are created for all positions where there are at least two reads support an alt allele.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/863
https://github.com/google/deepvariant/issues/863:22,usability,help,helpful,22,"Hi @akolesnikov, very helpful answer, I appreciate it. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/863
https://github.com/google/deepvariant/issues/864:32,energy efficiency,model,model,32,"Hi @SirKuikka, . So the RNA-seq model we support is to identify germline variants through RNA-seq data. Details of that can be found in: https://academic.oup.com/bioinformaticsadvances/article/3/1/vbad062/7197031. Similar to whole genome sequencing, if you are trying to identify Somatic variants with RNA-seq our model possibly won't be sensitive enough. For somatic variant calling we have DeepSomatic that you can try but we currently don't support an RNA-seq model for that.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:314,energy efficiency,model,model,314,"Hi @SirKuikka, . So the RNA-seq model we support is to identify germline variants through RNA-seq data. Details of that can be found in: https://academic.oup.com/bioinformaticsadvances/article/3/1/vbad062/7197031. Similar to whole genome sequencing, if you are trying to identify Somatic variants with RNA-seq our model possibly won't be sensitive enough. For somatic variant calling we have DeepSomatic that you can try but we currently don't support an RNA-seq model for that.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:428,energy efficiency,current,currently,428,"Hi @SirKuikka, . So the RNA-seq model we support is to identify germline variants through RNA-seq data. Details of that can be found in: https://academic.oup.com/bioinformaticsadvances/article/3/1/vbad062/7197031. Similar to whole genome sequencing, if you are trying to identify Somatic variants with RNA-seq our model possibly won't be sensitive enough. For somatic variant calling we have DeepSomatic that you can try but we currently don't support an RNA-seq model for that.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:463,energy efficiency,model,model,463,"Hi @SirKuikka, . So the RNA-seq model we support is to identify germline variants through RNA-seq data. Details of that can be found in: https://academic.oup.com/bioinformaticsadvances/article/3/1/vbad062/7197031. Similar to whole genome sequencing, if you are trying to identify Somatic variants with RNA-seq our model possibly won't be sensitive enough. For somatic variant calling we have DeepSomatic that you can try but we currently don't support an RNA-seq model for that.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:32,security,model,model,32,"Hi @SirKuikka, . So the RNA-seq model we support is to identify germline variants through RNA-seq data. Details of that can be found in: https://academic.oup.com/bioinformaticsadvances/article/3/1/vbad062/7197031. Similar to whole genome sequencing, if you are trying to identify Somatic variants with RNA-seq our model possibly won't be sensitive enough. For somatic variant calling we have DeepSomatic that you can try but we currently don't support an RNA-seq model for that.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:55,security,ident,identify,55,"Hi @SirKuikka, . So the RNA-seq model we support is to identify germline variants through RNA-seq data. Details of that can be found in: https://academic.oup.com/bioinformaticsadvances/article/3/1/vbad062/7197031. Similar to whole genome sequencing, if you are trying to identify Somatic variants with RNA-seq our model possibly won't be sensitive enough. For somatic variant calling we have DeepSomatic that you can try but we currently don't support an RNA-seq model for that.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:271,security,ident,identify,271,"Hi @SirKuikka, . So the RNA-seq model we support is to identify germline variants through RNA-seq data. Details of that can be found in: https://academic.oup.com/bioinformaticsadvances/article/3/1/vbad062/7197031. Similar to whole genome sequencing, if you are trying to identify Somatic variants with RNA-seq our model possibly won't be sensitive enough. For somatic variant calling we have DeepSomatic that you can try but we currently don't support an RNA-seq model for that.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:314,security,model,model,314,"Hi @SirKuikka, . So the RNA-seq model we support is to identify germline variants through RNA-seq data. Details of that can be found in: https://academic.oup.com/bioinformaticsadvances/article/3/1/vbad062/7197031. Similar to whole genome sequencing, if you are trying to identify Somatic variants with RNA-seq our model possibly won't be sensitive enough. For somatic variant calling we have DeepSomatic that you can try but we currently don't support an RNA-seq model for that.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:463,security,model,model,463,"Hi @SirKuikka, . So the RNA-seq model we support is to identify germline variants through RNA-seq data. Details of that can be found in: https://academic.oup.com/bioinformaticsadvances/article/3/1/vbad062/7197031. Similar to whole genome sequencing, if you are trying to identify Somatic variants with RNA-seq our model possibly won't be sensitive enough. For somatic variant calling we have DeepSomatic that you can try but we currently don't support an RNA-seq model for that.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:41,usability,support,support,41,"Hi @SirKuikka, . So the RNA-seq model we support is to identify germline variants through RNA-seq data. Details of that can be found in: https://academic.oup.com/bioinformaticsadvances/article/3/1/vbad062/7197031. Similar to whole genome sequencing, if you are trying to identify Somatic variants with RNA-seq our model possibly won't be sensitive enough. For somatic variant calling we have DeepSomatic that you can try but we currently don't support an RNA-seq model for that.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:444,usability,support,support,444,"Hi @SirKuikka, . So the RNA-seq model we support is to identify germline variants through RNA-seq data. Details of that can be found in: https://academic.oup.com/bioinformaticsadvances/article/3/1/vbad062/7197031. Similar to whole genome sequencing, if you are trying to identify Somatic variants with RNA-seq our model possibly won't be sensitive enough. For somatic variant calling we have DeepSomatic that you can try but we currently don't support an RNA-seq model for that.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:258,safety,detect,detect,258,"Hi,. So if there would be a rare somatic variant with e.g. 0.5 VAF, would that be classified as germline, artefact or something else? I'm just trying to understand what happens if there are mutations that are not true germline mutations. Can the tool really detect only germline mutations and not somatic mutations? I don't mean it would need to distinguish between the two types.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:258,security,detect,detect,258,"Hi,. So if there would be a rare somatic variant with e.g. 0.5 VAF, would that be classified as germline, artefact or something else? I'm just trying to understand what happens if there are mutations that are not true germline mutations. Can the tool really detect only germline mutations and not somatic mutations? I don't mean it would need to distinguish between the two types.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:153,testability,understand,understand,153,"Hi,. So if there would be a rare somatic variant with e.g. 0.5 VAF, would that be classified as germline, artefact or something else? I'm just trying to understand what happens if there are mutations that are not true germline mutations. Can the tool really detect only germline mutations and not somatic mutations? I don't mean it would need to distinguish between the two types.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:246,usability,tool,tool,246,"Hi,. So if there would be a rare somatic variant with e.g. 0.5 VAF, would that be classified as germline, artefact or something else? I'm just trying to understand what happens if there are mutations that are not true germline mutations. Can the tool really detect only germline mutations and not somatic mutations? I don't mean it would need to distinguish between the two types.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:72,deployability,observ,observed,72,"@SirKuikka ,. DeepVariant will try to ""genotype"" each candidate variant observed. Currently it does not have the ability to differentiate between ""somatic"" vs ""germline"". If a variant has high allele frequency then the likelihood to be classified as ""het"" or ""hom-alt"" is high. However, DeepVariant does not use strict heuristics for such classifications so it is difficult to answer what would happen to such variants. However, rare variant detection with high-sensitivity has been reported with DeepVariant (https://www.nature.com/articles/s41525-021-00227-3).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:82,energy efficiency,Current,Currently,82,"@SirKuikka ,. DeepVariant will try to ""genotype"" each candidate variant observed. Currently it does not have the ability to differentiate between ""somatic"" vs ""germline"". If a variant has high allele frequency then the likelihood to be classified as ""het"" or ""hom-alt"" is high. However, DeepVariant does not use strict heuristics for such classifications so it is difficult to answer what would happen to such variants. However, rare variant detection with high-sensitivity has been reported with DeepVariant (https://www.nature.com/articles/s41525-021-00227-3).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:200,energy efficiency,frequenc,frequency,200,"@SirKuikka ,. DeepVariant will try to ""genotype"" each candidate variant observed. Currently it does not have the ability to differentiate between ""somatic"" vs ""germline"". If a variant has high allele frequency then the likelihood to be classified as ""het"" or ""hom-alt"" is high. However, DeepVariant does not use strict heuristics for such classifications so it is difficult to answer what would happen to such variants. However, rare variant detection with high-sensitivity has been reported with DeepVariant (https://www.nature.com/articles/s41525-021-00227-3).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:95,reliability,doe,does,95,"@SirKuikka ,. DeepVariant will try to ""genotype"" each candidate variant observed. Currently it does not have the ability to differentiate between ""somatic"" vs ""germline"". If a variant has high allele frequency then the likelihood to be classified as ""het"" or ""hom-alt"" is high. However, DeepVariant does not use strict heuristics for such classifications so it is difficult to answer what would happen to such variants. However, rare variant detection with high-sensitivity has been reported with DeepVariant (https://www.nature.com/articles/s41525-021-00227-3).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:299,reliability,doe,does,299,"@SirKuikka ,. DeepVariant will try to ""genotype"" each candidate variant observed. Currently it does not have the ability to differentiate between ""somatic"" vs ""germline"". If a variant has high allele frequency then the likelihood to be classified as ""het"" or ""hom-alt"" is high. However, DeepVariant does not use strict heuristics for such classifications so it is difficult to answer what would happen to such variants. However, rare variant detection with high-sensitivity has been reported with DeepVariant (https://www.nature.com/articles/s41525-021-00227-3).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:442,safety,detect,detection,442,"@SirKuikka ,. DeepVariant will try to ""genotype"" each candidate variant observed. Currently it does not have the ability to differentiate between ""somatic"" vs ""germline"". If a variant has high allele frequency then the likelihood to be classified as ""het"" or ""hom-alt"" is high. However, DeepVariant does not use strict heuristics for such classifications so it is difficult to answer what would happen to such variants. However, rare variant detection with high-sensitivity has been reported with DeepVariant (https://www.nature.com/articles/s41525-021-00227-3).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:442,security,detect,detection,442,"@SirKuikka ,. DeepVariant will try to ""genotype"" each candidate variant observed. Currently it does not have the ability to differentiate between ""somatic"" vs ""germline"". If a variant has high allele frequency then the likelihood to be classified as ""het"" or ""hom-alt"" is high. However, DeepVariant does not use strict heuristics for such classifications so it is difficult to answer what would happen to such variants. However, rare variant detection with high-sensitivity has been reported with DeepVariant (https://www.nature.com/articles/s41525-021-00227-3).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:72,testability,observ,observed,72,"@SirKuikka ,. DeepVariant will try to ""genotype"" each candidate variant observed. Currently it does not have the ability to differentiate between ""somatic"" vs ""germline"". If a variant has high allele frequency then the likelihood to be classified as ""het"" or ""hom-alt"" is high. However, DeepVariant does not use strict heuristics for such classifications so it is difficult to answer what would happen to such variants. However, rare variant detection with high-sensitivity has been reported with DeepVariant (https://www.nature.com/articles/s41525-021-00227-3).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:61,usability,close,close,61,"Hi @SirKuikka ,. Hopefully your questions are answered. I'll close this issue now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:205,interoperability,distribut,distribution,205,![image-6](https://github.com/user-attachments/assets/b5d5ea7b-a8d5-4f61-8fc7-bafdcd002707). I have one more question. How can VAF for a PASS mutation be sometimes close to 0 if it's germline? This is VAF distribution for an RNA-seq sample.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:30,usability,user,user-attachments,30,![image-6](https://github.com/user-attachments/assets/b5d5ea7b-a8d5-4f61-8fc7-bafdcd002707). I have one more question. How can VAF for a PASS mutation be sometimes close to 0 if it's germline? This is VAF distribution for an RNA-seq sample.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/864:164,usability,close,close,164,![image-6](https://github.com/user-attachments/assets/b5d5ea7b-a8d5-4f61-8fc7-bafdcd002707). I have one more question. How can VAF for a PASS mutation be sometimes close to 0 if it's germline? This is VAF distribution for an RNA-seq sample.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/864
https://github.com/google/deepvariant/issues/865:121,energy efficiency,model,model-case-study,121,"Hi @lynnjo,. You may check [PacBio case study](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-pacbio-model-case-study.md) which uses Conda.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:28,modifiability,Pac,PacBio,28,"Hi @lynnjo,. You may check [PacBio case study](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-pacbio-model-case-study.md) which uses Conda.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:114,modifiability,pac,pacbio-model-case-study,114,"Hi @lynnjo,. You may check [PacBio case study](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-pacbio-model-case-study.md) which uses Conda.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:121,security,model,model-case-study,121,"Hi @lynnjo,. You may check [PacBio case study](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-pacbio-model-case-study.md) which uses Conda.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:313,interoperability,bind,bind,313,"Thanks for the response @akolesnikov . I must be missing something. From your PacBio case study link above, I see conda being used to setup samtools, but deepvariant is still run via singularity. Is it possible to run deepvariant only through conda, or is docker/singularity always required? . singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant_output/output.vcf.gz \. --num_shards $(nproc) \. --regions chr20. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:78,modifiability,Pac,PacBio,78,"Thanks for the response @akolesnikov . I must be missing something. From your PacBio case study link above, I see conda being used to setup samtools, but deepvariant is still run via singularity. Is it possible to run deepvariant only through conda, or is docker/singularity always required? . singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant_output/output.vcf.gz \. --num_shards $(nproc) \. --regions chr20. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:313,modifiability,bind,bind,313,"Thanks for the response @akolesnikov . I must be missing something. From your PacBio case study link above, I see conda being used to setup samtools, but deepvariant is still run via singularity. Is it possible to run deepvariant only through conda, or is docker/singularity always required? . singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant_output/output.vcf.gz \. --num_shards $(nproc) \. --regions chr20. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:437,modifiability,PAC,PACBIO,437,"Thanks for the response @akolesnikov . I must be missing something. From your PacBio case study link above, I see conda being used to setup samtools, but deepvariant is still run via singularity. Is it possible to run deepvariant only through conda, or is docker/singularity always required? . singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant_output/output.vcf.gz \. --num_shards $(nproc) \. --regions chr20. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:507,safety,input,input,507,"Thanks for the response @akolesnikov . I must be missing something. From your PacBio case study link above, I see conda being used to setup samtools, but deepvariant is still run via singularity. Is it possible to run deepvariant only through conda, or is docker/singularity always required? . singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant_output/output.vcf.gz \. --num_shards $(nproc) \. --regions chr20. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:507,usability,input,input,507,"Thanks for the response @akolesnikov . I must be missing something. From your PacBio case study link above, I see conda being used to setup samtools, but deepvariant is still run via singularity. Is it possible to run deepvariant only through conda, or is docker/singularity always required? . singularity exec --bind /usr/lib/locale/ \. docker://google/deepvariant:${BIN_VERSION} \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant_output/output.vcf.gz \. --num_shards $(nproc) \. --regions chr20. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:84,deployability,contain,contains,84,"Please refer to [this](https://github.com/google/deepvariant/issues/736) issue that contains some information on Conda. Unfortunately, we don't support Conda and there is no documentation on how to install through Conda.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:198,deployability,instal,install,198,"Please refer to [this](https://github.com/google/deepvariant/issues/736) issue that contains some information on Conda. Unfortunately, we don't support Conda and there is no documentation on how to install through Conda.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:144,usability,support,support,144,"Please refer to [this](https://github.com/google/deepvariant/issues/736) issue that contains some information on Conda. Unfortunately, we don't support Conda and there is no documentation on how to install through Conda.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:174,usability,document,documentation,174,"Please refer to [this](https://github.com/google/deepvariant/issues/736) issue that contains some information on Conda. Unfortunately, we don't support Conda and there is no documentation on how to install through Conda.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:60,usability,support,support,60,"Hi @lynnjo , as @akolesnikov mentioned, we don't officially support Conda. I'll close this issue now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/865:80,usability,close,close,80,"Hi @lynnjo , as @akolesnikov mentioned, we don't officially support Conda. I'll close this issue now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/865
https://github.com/google/deepvariant/issues/866:293,availability,checkpoint,checkpoints,293,"Hi @helizabeth1103 , the logic is in. https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L529-L559. Can you double check that you have this file:. `/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902/saved_model.pb`? If you have that file, then this should be true:. ```. use_saved_model = tf.io.gfile.exists(. _CUSTOMIZED_MODEL.value. ) and tf.io.gfile.exists(f'{_CUSTOMIZED_MODEL.value}/saved_model.pb'). ```. And then:. ```. if use_saved_model:. logging.info('Using saved model: %s', str(use_saved_model)). ```. You should be able to see the `Using saved model` logging.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:25,deployability,log,logic,25,"Hi @helizabeth1103 , the logic is in. https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L529-L559. Can you double check that you have this file:. `/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902/saved_model.pb`? If you have that file, then this should be true:. ```. use_saved_model = tf.io.gfile.exists(. _CUSTOMIZED_MODEL.value. ) and tf.io.gfile.exists(f'{_CUSTOMIZED_MODEL.value}/saved_model.pb'). ```. And then:. ```. if use_saved_model:. logging.info('Using saved model: %s', str(use_saved_model)). ```. You should be able to see the `Using saved model` logging.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:565,deployability,log,logging,565,"Hi @helizabeth1103 , the logic is in. https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L529-L559. Can you double check that you have this file:. `/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902/saved_model.pb`? If you have that file, then this should be true:. ```. use_saved_model = tf.io.gfile.exists(. _CUSTOMIZED_MODEL.value. ) and tf.io.gfile.exists(f'{_CUSTOMIZED_MODEL.value}/saved_model.pb'). ```. And then:. ```. if use_saved_model:. logging.info('Using saved model: %s', str(use_saved_model)). ```. You should be able to see the `Using saved model` logging.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:681,deployability,log,logging,681,"Hi @helizabeth1103 , the logic is in. https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L529-L559. Can you double check that you have this file:. `/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902/saved_model.pb`? If you have that file, then this should be true:. ```. use_saved_model = tf.io.gfile.exists(. _CUSTOMIZED_MODEL.value. ) and tf.io.gfile.exists(f'{_CUSTOMIZED_MODEL.value}/saved_model.pb'). ```. And then:. ```. if use_saved_model:. logging.info('Using saved model: %s', str(use_saved_model)). ```. You should be able to see the `Using saved model` logging.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:258,energy efficiency,model,modeltrainout,258,"Hi @helizabeth1103 , the logic is in. https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L529-L559. Can you double check that you have this file:. `/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902/saved_model.pb`? If you have that file, then this should be true:. ```. use_saved_model = tf.io.gfile.exists(. _CUSTOMIZED_MODEL.value. ) and tf.io.gfile.exists(f'{_CUSTOMIZED_MODEL.value}/saved_model.pb'). ```. And then:. ```. if use_saved_model:. logging.info('Using saved model: %s', str(use_saved_model)). ```. You should be able to see the `Using saved model` logging.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:591,energy efficiency,model,model,591,"Hi @helizabeth1103 , the logic is in. https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L529-L559. Can you double check that you have this file:. `/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902/saved_model.pb`? If you have that file, then this should be true:. ```. use_saved_model = tf.io.gfile.exists(. _CUSTOMIZED_MODEL.value. ) and tf.io.gfile.exists(f'{_CUSTOMIZED_MODEL.value}/saved_model.pb'). ```. And then:. ```. if use_saved_model:. logging.info('Using saved model: %s', str(use_saved_model)). ```. You should be able to see the `Using saved model` logging.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:674,energy efficiency,model,model,674,"Hi @helizabeth1103 , the logic is in. https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L529-L559. Can you double check that you have this file:. `/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902/saved_model.pb`? If you have that file, then this should be true:. ```. use_saved_model = tf.io.gfile.exists(. _CUSTOMIZED_MODEL.value. ) and tf.io.gfile.exists(f'{_CUSTOMIZED_MODEL.value}/saved_model.pb'). ```. And then:. ```. if use_saved_model:. logging.info('Using saved model: %s', str(use_saved_model)). ```. You should be able to see the `Using saved model` logging.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:293,reliability,checkpoint,checkpoints,293,"Hi @helizabeth1103 , the logic is in. https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L529-L559. Can you double check that you have this file:. `/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902/saved_model.pb`? If you have that file, then this should be true:. ```. use_saved_model = tf.io.gfile.exists(. _CUSTOMIZED_MODEL.value. ) and tf.io.gfile.exists(f'{_CUSTOMIZED_MODEL.value}/saved_model.pb'). ```. And then:. ```. if use_saved_model:. logging.info('Using saved model: %s', str(use_saved_model)). ```. You should be able to see the `Using saved model` logging.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:25,safety,log,logic,25,"Hi @helizabeth1103 , the logic is in. https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L529-L559. Can you double check that you have this file:. `/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902/saved_model.pb`? If you have that file, then this should be true:. ```. use_saved_model = tf.io.gfile.exists(. _CUSTOMIZED_MODEL.value. ) and tf.io.gfile.exists(f'{_CUSTOMIZED_MODEL.value}/saved_model.pb'). ```. And then:. ```. if use_saved_model:. logging.info('Using saved model: %s', str(use_saved_model)). ```. You should be able to see the `Using saved model` logging.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:565,safety,log,logging,565,"Hi @helizabeth1103 , the logic is in. https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L529-L559. Can you double check that you have this file:. `/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902/saved_model.pb`? If you have that file, then this should be true:. ```. use_saved_model = tf.io.gfile.exists(. _CUSTOMIZED_MODEL.value. ) and tf.io.gfile.exists(f'{_CUSTOMIZED_MODEL.value}/saved_model.pb'). ```. And then:. ```. if use_saved_model:. logging.info('Using saved model: %s', str(use_saved_model)). ```. You should be able to see the `Using saved model` logging.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:681,safety,log,logging,681,"Hi @helizabeth1103 , the logic is in. https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L529-L559. Can you double check that you have this file:. `/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902/saved_model.pb`? If you have that file, then this should be true:. ```. use_saved_model = tf.io.gfile.exists(. _CUSTOMIZED_MODEL.value. ) and tf.io.gfile.exists(f'{_CUSTOMIZED_MODEL.value}/saved_model.pb'). ```. And then:. ```. if use_saved_model:. logging.info('Using saved model: %s', str(use_saved_model)). ```. You should be able to see the `Using saved model` logging.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:25,security,log,logic,25,"Hi @helizabeth1103 , the logic is in. https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L529-L559. Can you double check that you have this file:. `/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902/saved_model.pb`? If you have that file, then this should be true:. ```. use_saved_model = tf.io.gfile.exists(. _CUSTOMIZED_MODEL.value. ) and tf.io.gfile.exists(f'{_CUSTOMIZED_MODEL.value}/saved_model.pb'). ```. And then:. ```. if use_saved_model:. logging.info('Using saved model: %s', str(use_saved_model)). ```. You should be able to see the `Using saved model` logging.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:258,security,model,modeltrainout,258,"Hi @helizabeth1103 , the logic is in. https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L529-L559. Can you double check that you have this file:. `/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902/saved_model.pb`? If you have that file, then this should be true:. ```. use_saved_model = tf.io.gfile.exists(. _CUSTOMIZED_MODEL.value. ) and tf.io.gfile.exists(f'{_CUSTOMIZED_MODEL.value}/saved_model.pb'). ```. And then:. ```. if use_saved_model:. logging.info('Using saved model: %s', str(use_saved_model)). ```. You should be able to see the `Using saved model` logging.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:565,security,log,logging,565,"Hi @helizabeth1103 , the logic is in. https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L529-L559. Can you double check that you have this file:. `/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902/saved_model.pb`? If you have that file, then this should be true:. ```. use_saved_model = tf.io.gfile.exists(. _CUSTOMIZED_MODEL.value. ) and tf.io.gfile.exists(f'{_CUSTOMIZED_MODEL.value}/saved_model.pb'). ```. And then:. ```. if use_saved_model:. logging.info('Using saved model: %s', str(use_saved_model)). ```. You should be able to see the `Using saved model` logging.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:591,security,model,model,591,"Hi @helizabeth1103 , the logic is in. https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L529-L559. Can you double check that you have this file:. `/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902/saved_model.pb`? If you have that file, then this should be true:. ```. use_saved_model = tf.io.gfile.exists(. _CUSTOMIZED_MODEL.value. ) and tf.io.gfile.exists(f'{_CUSTOMIZED_MODEL.value}/saved_model.pb'). ```. And then:. ```. if use_saved_model:. logging.info('Using saved model: %s', str(use_saved_model)). ```. You should be able to see the `Using saved model` logging.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:674,security,model,model,674,"Hi @helizabeth1103 , the logic is in. https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L529-L559. Can you double check that you have this file:. `/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902/saved_model.pb`? If you have that file, then this should be true:. ```. use_saved_model = tf.io.gfile.exists(. _CUSTOMIZED_MODEL.value. ) and tf.io.gfile.exists(f'{_CUSTOMIZED_MODEL.value}/saved_model.pb'). ```. And then:. ```. if use_saved_model:. logging.info('Using saved model: %s', str(use_saved_model)). ```. You should be able to see the `Using saved model` logging.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:681,security,log,logging,681,"Hi @helizabeth1103 , the logic is in. https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L529-L559. Can you double check that you have this file:. `/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902/saved_model.pb`? If you have that file, then this should be true:. ```. use_saved_model = tf.io.gfile.exists(. _CUSTOMIZED_MODEL.value. ) and tf.io.gfile.exists(f'{_CUSTOMIZED_MODEL.value}/saved_model.pb'). ```. And then:. ```. if use_saved_model:. logging.info('Using saved model: %s', str(use_saved_model)). ```. You should be able to see the `Using saved model` logging.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:25,testability,log,logic,25,"Hi @helizabeth1103 , the logic is in. https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L529-L559. Can you double check that you have this file:. `/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902/saved_model.pb`? If you have that file, then this should be true:. ```. use_saved_model = tf.io.gfile.exists(. _CUSTOMIZED_MODEL.value. ) and tf.io.gfile.exists(f'{_CUSTOMIZED_MODEL.value}/saved_model.pb'). ```. And then:. ```. if use_saved_model:. logging.info('Using saved model: %s', str(use_saved_model)). ```. You should be able to see the `Using saved model` logging.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:565,testability,log,logging,565,"Hi @helizabeth1103 , the logic is in. https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L529-L559. Can you double check that you have this file:. `/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902/saved_model.pb`? If you have that file, then this should be true:. ```. use_saved_model = tf.io.gfile.exists(. _CUSTOMIZED_MODEL.value. ) and tf.io.gfile.exists(f'{_CUSTOMIZED_MODEL.value}/saved_model.pb'). ```. And then:. ```. if use_saved_model:. logging.info('Using saved model: %s', str(use_saved_model)). ```. You should be able to see the `Using saved model` logging.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:681,testability,log,logging,681,"Hi @helizabeth1103 , the logic is in. https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L529-L559. Can you double check that you have this file:. `/90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/ckpt-14902/saved_model.pb`? If you have that file, then this should be true:. ```. use_saved_model = tf.io.gfile.exists(. _CUSTOMIZED_MODEL.value. ) and tf.io.gfile.exists(f'{_CUSTOMIZED_MODEL.value}/saved_model.pb'). ```. And then:. ```. if use_saved_model:. logging.info('Using saved model: %s', str(use_saved_model)). ```. You should be able to see the `Using saved model` logging.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:127,availability,checkpoint,checkpoints,127,"@helizabeth1103 , closing this due to no activity. Please feel free to reopen if you need further help. It looks like you have checkpoints:. ```bash. /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/. ```. And saved models both. Just trying to understand which one you are trying to use. Please reply with the outputs so we can understand the issue better.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:269,availability,checkpoint,checkpoints,269,"@helizabeth1103 , closing this due to no activity. Please feel free to reopen if you need further help. It looks like you have checkpoints:. ```bash. /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/. ```. And saved models both. Just trying to understand which one you are trying to use. Please reply with the outputs so we can understand the issue better.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:234,energy efficiency,model,modeltrainout,234,"@helizabeth1103 , closing this due to no activity. Please feel free to reopen if you need further help. It looks like you have checkpoints:. ```bash. /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/. ```. And saved models both. Just trying to understand which one you are trying to use. Please reply with the outputs so we can understand the issue better.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:298,energy efficiency,model,models,298,"@helizabeth1103 , closing this due to no activity. Please feel free to reopen if you need further help. It looks like you have checkpoints:. ```bash. /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/. ```. And saved models both. Just trying to understand which one you are trying to use. Please reply with the outputs so we can understand the issue better.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:127,reliability,checkpoint,checkpoints,127,"@helizabeth1103 , closing this due to no activity. Please feel free to reopen if you need further help. It looks like you have checkpoints:. ```bash. /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/. ```. And saved models both. Just trying to understand which one you are trying to use. Please reply with the outputs so we can understand the issue better.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:269,reliability,checkpoint,checkpoints,269,"@helizabeth1103 , closing this due to no activity. Please feel free to reopen if you need further help. It looks like you have checkpoints:. ```bash. /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/. ```. And saved models both. Just trying to understand which one you are trying to use. Please reply with the outputs so we can understand the issue better.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:234,security,model,modeltrainout,234,"@helizabeth1103 , closing this due to no activity. Please feel free to reopen if you need further help. It looks like you have checkpoints:. ```bash. /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/. ```. And saved models both. Just trying to understand which one you are trying to use. Please reply with the outputs so we can understand the issue better.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:298,security,model,models,298,"@helizabeth1103 , closing this due to no activity. Please feel free to reopen if you need further help. It looks like you have checkpoints:. ```bash. /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/. ```. And saved models both. Just trying to understand which one you are trying to use. Please reply with the outputs so we can understand the issue better.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:326,testability,understand,understand,326,"@helizabeth1103 , closing this due to no activity. Please feel free to reopen if you need further help. It looks like you have checkpoints:. ```bash. /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/. ```. And saved models both. Just trying to understand which one you are trying to use. Please reply with the outputs so we can understand the issue better.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:410,testability,understand,understand,410,"@helizabeth1103 , closing this due to no activity. Please feel free to reopen if you need further help. It looks like you have checkpoints:. ```bash. /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/. ```. And saved models both. Just trying to understand which one you are trying to use. Please reply with the outputs so we can understand the issue better.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/866:98,usability,help,help,98,"@helizabeth1103 , closing this due to no activity. Please feel free to reopen if you need further help. It looks like you have checkpoints:. ```bash. /90daydata/pbarc/haley.arnold/AI_Model_Training/Samples/deepvariant_fulltest/output/modeltrainout/2fullindividualmodel/checkpoints/. ```. And saved models both. Just trying to understand which one you are trying to use. Please reply with the outputs so we can understand the issue better.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/866
https://github.com/google/deepvariant/issues/867:225,energy efficiency,cpu,cpu-only-machine,225,"This was due to omitting the --split_skip_reads parameter to make_examples. After adding this following https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-rnaseq-case-study.md#running-deepvariant-rna-seq-on-a-cpu-only-machine on DV 1.5.0, it seems to be running.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:48,modifiability,paramet,parameter,48,"This was due to omitting the --split_skip_reads parameter to make_examples. After adding this following https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-rnaseq-case-study.md#running-deepvariant-rna-seq-on-a-cpu-only-machine on DV 1.5.0, it seems to be running.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/867:225,performance,cpu,cpu-only-machine,225,"This was due to omitting the --split_skip_reads parameter to make_examples. After adding this following https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-rnaseq-case-study.md#running-deepvariant-rna-seq-on-a-cpu-only-machine on DV 1.5.0, it seems to be running.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/867
https://github.com/google/deepvariant/issues/868:737,availability,error,errors,737,"From your log, I suspect that the postprocess_variants step failed. Your log only shows this:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/tmpih5xsned/call_variants_output.tfrecord.gz"" --outfile ""/output/outputdeepvar.vcf"" --nonvariant_site_tfrecord_path ""/tmp/tmpih5xsned/gvcf.tfrecord@10.gz"" --gvcf_outfile ""/output/outputdeepvar.g.vcf"". I0813 04:00:29.233929 140206500009792 postprocess_variants.py:971] Using sample name from call_variants output. Sample name: NA12878. 2024-08-13 04:00:29.242227: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmpih5xsned/call_variants_output.tfrecord.gz. ```. Which is surprising, because I'd expect more errors if anything is wrong. Did you observe any issues with RAM or disk space running out in the last step? ---. By the way, next time you run it, you can set this flag `--intermediate_results_dir`:. like in: . https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command. That way, the output from the make_examples and call_variants steps will be saved, and you can just rerun postprocess_variants step if needed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:10,deployability,log,log,10,"From your log, I suspect that the postprocess_variants step failed. Your log only shows this:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/tmpih5xsned/call_variants_output.tfrecord.gz"" --outfile ""/output/outputdeepvar.vcf"" --nonvariant_site_tfrecord_path ""/tmp/tmpih5xsned/gvcf.tfrecord@10.gz"" --gvcf_outfile ""/output/outputdeepvar.g.vcf"". I0813 04:00:29.233929 140206500009792 postprocess_variants.py:971] Using sample name from call_variants output. Sample name: NA12878. 2024-08-13 04:00:29.242227: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmpih5xsned/call_variants_output.tfrecord.gz. ```. Which is surprising, because I'd expect more errors if anything is wrong. Did you observe any issues with RAM or disk space running out in the last step? ---. By the way, next time you run it, you can set this flag `--intermediate_results_dir`:. like in: . https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command. That way, the output from the make_examples and call_variants steps will be saved, and you can just rerun postprocess_variants step if needed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:60,deployability,fail,failed,60,"From your log, I suspect that the postprocess_variants step failed. Your log only shows this:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/tmpih5xsned/call_variants_output.tfrecord.gz"" --outfile ""/output/outputdeepvar.vcf"" --nonvariant_site_tfrecord_path ""/tmp/tmpih5xsned/gvcf.tfrecord@10.gz"" --gvcf_outfile ""/output/outputdeepvar.g.vcf"". I0813 04:00:29.233929 140206500009792 postprocess_variants.py:971] Using sample name from call_variants output. Sample name: NA12878. 2024-08-13 04:00:29.242227: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmpih5xsned/call_variants_output.tfrecord.gz. ```. Which is surprising, because I'd expect more errors if anything is wrong. Did you observe any issues with RAM or disk space running out in the last step? ---. By the way, next time you run it, you can set this flag `--intermediate_results_dir`:. like in: . https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command. That way, the output from the make_examples and call_variants steps will be saved, and you can just rerun postprocess_variants step if needed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:73,deployability,log,log,73,"From your log, I suspect that the postprocess_variants step failed. Your log only shows this:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/tmpih5xsned/call_variants_output.tfrecord.gz"" --outfile ""/output/outputdeepvar.vcf"" --nonvariant_site_tfrecord_path ""/tmp/tmpih5xsned/gvcf.tfrecord@10.gz"" --gvcf_outfile ""/output/outputdeepvar.g.vcf"". I0813 04:00:29.233929 140206500009792 postprocess_variants.py:971] Using sample name from call_variants output. Sample name: NA12878. 2024-08-13 04:00:29.242227: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmpih5xsned/call_variants_output.tfrecord.gz. ```. Which is surprising, because I'd expect more errors if anything is wrong. Did you observe any issues with RAM or disk space running out in the last step? ---. By the way, next time you run it, you can set this flag `--intermediate_results_dir`:. like in: . https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command. That way, the output from the make_examples and call_variants steps will be saved, and you can just rerun postprocess_variants step if needed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:774,deployability,observ,observe,774,"From your log, I suspect that the postprocess_variants step failed. Your log only shows this:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/tmpih5xsned/call_variants_output.tfrecord.gz"" --outfile ""/output/outputdeepvar.vcf"" --nonvariant_site_tfrecord_path ""/tmp/tmpih5xsned/gvcf.tfrecord@10.gz"" --gvcf_outfile ""/output/outputdeepvar.g.vcf"". I0813 04:00:29.233929 140206500009792 postprocess_variants.py:971] Using sample name from call_variants output. Sample name: NA12878. 2024-08-13 04:00:29.242227: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmpih5xsned/call_variants_output.tfrecord.gz. ```. Which is surprising, because I'd expect more errors if anything is wrong. Did you observe any issues with RAM or disk space running out in the last step? ---. By the way, next time you run it, you can set this flag `--intermediate_results_dir`:. like in: . https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command. That way, the output from the make_examples and call_variants steps will be saved, and you can just rerun postprocess_variants step if needed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:133,performance,time,time,133,"From your log, I suspect that the postprocess_variants step failed. Your log only shows this:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/tmpih5xsned/call_variants_output.tfrecord.gz"" --outfile ""/output/outputdeepvar.vcf"" --nonvariant_site_tfrecord_path ""/tmp/tmpih5xsned/gvcf.tfrecord@10.gz"" --gvcf_outfile ""/output/outputdeepvar.g.vcf"". I0813 04:00:29.233929 140206500009792 postprocess_variants.py:971] Using sample name from call_variants output. Sample name: NA12878. 2024-08-13 04:00:29.242227: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmpih5xsned/call_variants_output.tfrecord.gz. ```. Which is surprising, because I'd expect more errors if anything is wrong. Did you observe any issues with RAM or disk space running out in the last step? ---. By the way, next time you run it, you can set this flag `--intermediate_results_dir`:. like in: . https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command. That way, the output from the make_examples and call_variants steps will be saved, and you can just rerun postprocess_variants step if needed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:737,performance,error,errors,737,"From your log, I suspect that the postprocess_variants step failed. Your log only shows this:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/tmpih5xsned/call_variants_output.tfrecord.gz"" --outfile ""/output/outputdeepvar.vcf"" --nonvariant_site_tfrecord_path ""/tmp/tmpih5xsned/gvcf.tfrecord@10.gz"" --gvcf_outfile ""/output/outputdeepvar.g.vcf"". I0813 04:00:29.233929 140206500009792 postprocess_variants.py:971] Using sample name from call_variants output. Sample name: NA12878. 2024-08-13 04:00:29.242227: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmpih5xsned/call_variants_output.tfrecord.gz. ```. Which is surprising, because I'd expect more errors if anything is wrong. Did you observe any issues with RAM or disk space running out in the last step? ---. By the way, next time you run it, you can set this flag `--intermediate_results_dir`:. like in: . https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command. That way, the output from the make_examples and call_variants steps will be saved, and you can just rerun postprocess_variants step if needed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:805,performance,disk,disk,805,"From your log, I suspect that the postprocess_variants step failed. Your log only shows this:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/tmpih5xsned/call_variants_output.tfrecord.gz"" --outfile ""/output/outputdeepvar.vcf"" --nonvariant_site_tfrecord_path ""/tmp/tmpih5xsned/gvcf.tfrecord@10.gz"" --gvcf_outfile ""/output/outputdeepvar.g.vcf"". I0813 04:00:29.233929 140206500009792 postprocess_variants.py:971] Using sample name from call_variants output. Sample name: NA12878. 2024-08-13 04:00:29.242227: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmpih5xsned/call_variants_output.tfrecord.gz. ```. Which is surprising, because I'd expect more errors if anything is wrong. Did you observe any issues with RAM or disk space running out in the last step? ---. By the way, next time you run it, you can set this flag `--intermediate_results_dir`:. like in: . https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command. That way, the output from the make_examples and call_variants steps will be saved, and you can just rerun postprocess_variants step if needed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:868,performance,time,time,868,"From your log, I suspect that the postprocess_variants step failed. Your log only shows this:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/tmpih5xsned/call_variants_output.tfrecord.gz"" --outfile ""/output/outputdeepvar.vcf"" --nonvariant_site_tfrecord_path ""/tmp/tmpih5xsned/gvcf.tfrecord@10.gz"" --gvcf_outfile ""/output/outputdeepvar.g.vcf"". I0813 04:00:29.233929 140206500009792 postprocess_variants.py:971] Using sample name from call_variants output. Sample name: NA12878. 2024-08-13 04:00:29.242227: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmpih5xsned/call_variants_output.tfrecord.gz. ```. Which is surprising, because I'd expect more errors if anything is wrong. Did you observe any issues with RAM or disk space running out in the last step? ---. By the way, next time you run it, you can set this flag `--intermediate_results_dir`:. like in: . https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command. That way, the output from the make_examples and call_variants steps will be saved, and you can just rerun postprocess_variants step if needed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:60,reliability,fail,failed,60,"From your log, I suspect that the postprocess_variants step failed. Your log only shows this:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/tmpih5xsned/call_variants_output.tfrecord.gz"" --outfile ""/output/outputdeepvar.vcf"" --nonvariant_site_tfrecord_path ""/tmp/tmpih5xsned/gvcf.tfrecord@10.gz"" --gvcf_outfile ""/output/outputdeepvar.g.vcf"". I0813 04:00:29.233929 140206500009792 postprocess_variants.py:971] Using sample name from call_variants output. Sample name: NA12878. 2024-08-13 04:00:29.242227: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmpih5xsned/call_variants_output.tfrecord.gz. ```. Which is surprising, because I'd expect more errors if anything is wrong. Did you observe any issues with RAM or disk space running out in the last step? ---. By the way, next time you run it, you can set this flag `--intermediate_results_dir`:. like in: . https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command. That way, the output from the make_examples and call_variants steps will be saved, and you can just rerun postprocess_variants step if needed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:10,safety,log,log,10,"From your log, I suspect that the postprocess_variants step failed. Your log only shows this:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/tmpih5xsned/call_variants_output.tfrecord.gz"" --outfile ""/output/outputdeepvar.vcf"" --nonvariant_site_tfrecord_path ""/tmp/tmpih5xsned/gvcf.tfrecord@10.gz"" --gvcf_outfile ""/output/outputdeepvar.g.vcf"". I0813 04:00:29.233929 140206500009792 postprocess_variants.py:971] Using sample name from call_variants output. Sample name: NA12878. 2024-08-13 04:00:29.242227: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmpih5xsned/call_variants_output.tfrecord.gz. ```. Which is surprising, because I'd expect more errors if anything is wrong. Did you observe any issues with RAM or disk space running out in the last step? ---. By the way, next time you run it, you can set this flag `--intermediate_results_dir`:. like in: . https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command. That way, the output from the make_examples and call_variants steps will be saved, and you can just rerun postprocess_variants step if needed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:73,safety,log,log,73,"From your log, I suspect that the postprocess_variants step failed. Your log only shows this:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/tmpih5xsned/call_variants_output.tfrecord.gz"" --outfile ""/output/outputdeepvar.vcf"" --nonvariant_site_tfrecord_path ""/tmp/tmpih5xsned/gvcf.tfrecord@10.gz"" --gvcf_outfile ""/output/outputdeepvar.g.vcf"". I0813 04:00:29.233929 140206500009792 postprocess_variants.py:971] Using sample name from call_variants output. Sample name: NA12878. 2024-08-13 04:00:29.242227: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmpih5xsned/call_variants_output.tfrecord.gz. ```. Which is surprising, because I'd expect more errors if anything is wrong. Did you observe any issues with RAM or disk space running out in the last step? ---. By the way, next time you run it, you can set this flag `--intermediate_results_dir`:. like in: . https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command. That way, the output from the make_examples and call_variants steps will be saved, and you can just rerun postprocess_variants step if needed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:188,safety,input,input,188,"From your log, I suspect that the postprocess_variants step failed. Your log only shows this:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/tmpih5xsned/call_variants_output.tfrecord.gz"" --outfile ""/output/outputdeepvar.vcf"" --nonvariant_site_tfrecord_path ""/tmp/tmpih5xsned/gvcf.tfrecord@10.gz"" --gvcf_outfile ""/output/outputdeepvar.g.vcf"". I0813 04:00:29.233929 140206500009792 postprocess_variants.py:971] Using sample name from call_variants output. Sample name: NA12878. 2024-08-13 04:00:29.242227: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmpih5xsned/call_variants_output.tfrecord.gz. ```. Which is surprising, because I'd expect more errors if anything is wrong. Did you observe any issues with RAM or disk space running out in the last step? ---. By the way, next time you run it, you can set this flag `--intermediate_results_dir`:. like in: . https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command. That way, the output from the make_examples and call_variants steps will be saved, and you can just rerun postprocess_variants step if needed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:737,safety,error,errors,737,"From your log, I suspect that the postprocess_variants step failed. Your log only shows this:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/tmpih5xsned/call_variants_output.tfrecord.gz"" --outfile ""/output/outputdeepvar.vcf"" --nonvariant_site_tfrecord_path ""/tmp/tmpih5xsned/gvcf.tfrecord@10.gz"" --gvcf_outfile ""/output/outputdeepvar.g.vcf"". I0813 04:00:29.233929 140206500009792 postprocess_variants.py:971] Using sample name from call_variants output. Sample name: NA12878. 2024-08-13 04:00:29.242227: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmpih5xsned/call_variants_output.tfrecord.gz. ```. Which is surprising, because I'd expect more errors if anything is wrong. Did you observe any issues with RAM or disk space running out in the last step? ---. By the way, next time you run it, you can set this flag `--intermediate_results_dir`:. like in: . https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command. That way, the output from the make_examples and call_variants steps will be saved, and you can just rerun postprocess_variants step if needed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:10,security,log,log,10,"From your log, I suspect that the postprocess_variants step failed. Your log only shows this:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/tmpih5xsned/call_variants_output.tfrecord.gz"" --outfile ""/output/outputdeepvar.vcf"" --nonvariant_site_tfrecord_path ""/tmp/tmpih5xsned/gvcf.tfrecord@10.gz"" --gvcf_outfile ""/output/outputdeepvar.g.vcf"". I0813 04:00:29.233929 140206500009792 postprocess_variants.py:971] Using sample name from call_variants output. Sample name: NA12878. 2024-08-13 04:00:29.242227: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmpih5xsned/call_variants_output.tfrecord.gz. ```. Which is surprising, because I'd expect more errors if anything is wrong. Did you observe any issues with RAM or disk space running out in the last step? ---. By the way, next time you run it, you can set this flag `--intermediate_results_dir`:. like in: . https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command. That way, the output from the make_examples and call_variants steps will be saved, and you can just rerun postprocess_variants step if needed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:73,security,log,log,73,"From your log, I suspect that the postprocess_variants step failed. Your log only shows this:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/tmpih5xsned/call_variants_output.tfrecord.gz"" --outfile ""/output/outputdeepvar.vcf"" --nonvariant_site_tfrecord_path ""/tmp/tmpih5xsned/gvcf.tfrecord@10.gz"" --gvcf_outfile ""/output/outputdeepvar.g.vcf"". I0813 04:00:29.233929 140206500009792 postprocess_variants.py:971] Using sample name from call_variants output. Sample name: NA12878. 2024-08-13 04:00:29.242227: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmpih5xsned/call_variants_output.tfrecord.gz. ```. Which is surprising, because I'd expect more errors if anything is wrong. Did you observe any issues with RAM or disk space running out in the last step? ---. By the way, next time you run it, you can set this flag `--intermediate_results_dir`:. like in: . https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command. That way, the output from the make_examples and call_variants steps will be saved, and you can just rerun postprocess_variants step if needed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:10,testability,log,log,10,"From your log, I suspect that the postprocess_variants step failed. Your log only shows this:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/tmpih5xsned/call_variants_output.tfrecord.gz"" --outfile ""/output/outputdeepvar.vcf"" --nonvariant_site_tfrecord_path ""/tmp/tmpih5xsned/gvcf.tfrecord@10.gz"" --gvcf_outfile ""/output/outputdeepvar.g.vcf"". I0813 04:00:29.233929 140206500009792 postprocess_variants.py:971] Using sample name from call_variants output. Sample name: NA12878. 2024-08-13 04:00:29.242227: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmpih5xsned/call_variants_output.tfrecord.gz. ```. Which is surprising, because I'd expect more errors if anything is wrong. Did you observe any issues with RAM or disk space running out in the last step? ---. By the way, next time you run it, you can set this flag `--intermediate_results_dir`:. like in: . https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command. That way, the output from the make_examples and call_variants steps will be saved, and you can just rerun postprocess_variants step if needed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:73,testability,log,log,73,"From your log, I suspect that the postprocess_variants step failed. Your log only shows this:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/tmpih5xsned/call_variants_output.tfrecord.gz"" --outfile ""/output/outputdeepvar.vcf"" --nonvariant_site_tfrecord_path ""/tmp/tmpih5xsned/gvcf.tfrecord@10.gz"" --gvcf_outfile ""/output/outputdeepvar.g.vcf"". I0813 04:00:29.233929 140206500009792 postprocess_variants.py:971] Using sample name from call_variants output. Sample name: NA12878. 2024-08-13 04:00:29.242227: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmpih5xsned/call_variants_output.tfrecord.gz. ```. Which is surprising, because I'd expect more errors if anything is wrong. Did you observe any issues with RAM or disk space running out in the last step? ---. By the way, next time you run it, you can set this flag `--intermediate_results_dir`:. like in: . https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command. That way, the output from the make_examples and call_variants steps will be saved, and you can just rerun postprocess_variants step if needed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:774,testability,observ,observe,774,"From your log, I suspect that the postprocess_variants step failed. Your log only shows this:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/tmpih5xsned/call_variants_output.tfrecord.gz"" --outfile ""/output/outputdeepvar.vcf"" --nonvariant_site_tfrecord_path ""/tmp/tmpih5xsned/gvcf.tfrecord@10.gz"" --gvcf_outfile ""/output/outputdeepvar.g.vcf"". I0813 04:00:29.233929 140206500009792 postprocess_variants.py:971] Using sample name from call_variants output. Sample name: NA12878. 2024-08-13 04:00:29.242227: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmpih5xsned/call_variants_output.tfrecord.gz. ```. Which is surprising, because I'd expect more errors if anything is wrong. Did you observe any issues with RAM or disk space running out in the last step? ---. By the way, next time you run it, you can set this flag `--intermediate_results_dir`:. like in: . https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command. That way, the output from the make_examples and call_variants steps will be saved, and you can just rerun postprocess_variants step if needed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:118,usability,command,command,118,"From your log, I suspect that the postprocess_variants step failed. Your log only shows this:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/tmpih5xsned/call_variants_output.tfrecord.gz"" --outfile ""/output/outputdeepvar.vcf"" --nonvariant_site_tfrecord_path ""/tmp/tmpih5xsned/gvcf.tfrecord@10.gz"" --gvcf_outfile ""/output/outputdeepvar.g.vcf"". I0813 04:00:29.233929 140206500009792 postprocess_variants.py:971] Using sample name from call_variants output. Sample name: NA12878. 2024-08-13 04:00:29.242227: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmpih5xsned/call_variants_output.tfrecord.gz. ```. Which is surprising, because I'd expect more errors if anything is wrong. Did you observe any issues with RAM or disk space running out in the last step? ---. By the way, next time you run it, you can set this flag `--intermediate_results_dir`:. like in: . https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command. That way, the output from the make_examples and call_variants steps will be saved, and you can just rerun postprocess_variants step if needed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:188,usability,input,input,188,"From your log, I suspect that the postprocess_variants step failed. Your log only shows this:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/tmpih5xsned/call_variants_output.tfrecord.gz"" --outfile ""/output/outputdeepvar.vcf"" --nonvariant_site_tfrecord_path ""/tmp/tmpih5xsned/gvcf.tfrecord@10.gz"" --gvcf_outfile ""/output/outputdeepvar.g.vcf"". I0813 04:00:29.233929 140206500009792 postprocess_variants.py:971] Using sample name from call_variants output. Sample name: NA12878. 2024-08-13 04:00:29.242227: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmpih5xsned/call_variants_output.tfrecord.gz. ```. Which is surprising, because I'd expect more errors if anything is wrong. Did you observe any issues with RAM or disk space running out in the last step? ---. By the way, next time you run it, you can set this flag `--intermediate_results_dir`:. like in: . https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command. That way, the output from the make_examples and call_variants steps will be saved, and you can just rerun postprocess_variants step if needed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:737,usability,error,errors,737,"From your log, I suspect that the postprocess_variants step failed. Your log only shows this:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/tmpih5xsned/call_variants_output.tfrecord.gz"" --outfile ""/output/outputdeepvar.vcf"" --nonvariant_site_tfrecord_path ""/tmp/tmpih5xsned/gvcf.tfrecord@10.gz"" --gvcf_outfile ""/output/outputdeepvar.g.vcf"". I0813 04:00:29.233929 140206500009792 postprocess_variants.py:971] Using sample name from call_variants output. Sample name: NA12878. 2024-08-13 04:00:29.242227: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmpih5xsned/call_variants_output.tfrecord.gz. ```. Which is surprising, because I'd expect more errors if anything is wrong. Did you observe any issues with RAM or disk space running out in the last step? ---. By the way, next time you run it, you can set this flag `--intermediate_results_dir`:. like in: . https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command. That way, the output from the make_examples and call_variants steps will be saved, and you can just rerun postprocess_variants step if needed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:1056,usability,command,command,1056,"From your log, I suspect that the postprocess_variants step failed. Your log only shows this:. ```. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/tmpih5xsned/call_variants_output.tfrecord.gz"" --outfile ""/output/outputdeepvar.vcf"" --nonvariant_site_tfrecord_path ""/tmp/tmpih5xsned/gvcf.tfrecord@10.gz"" --gvcf_outfile ""/output/outputdeepvar.g.vcf"". I0813 04:00:29.233929 140206500009792 postprocess_variants.py:971] Using sample name from call_variants output. Sample name: NA12878. 2024-08-13 04:00:29.242227: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/tmpih5xsned/call_variants_output.tfrecord.gz. ```. Which is surprising, because I'd expect more errors if anything is wrong. Did you observe any issues with RAM or disk space running out in the last step? ---. By the way, next time you run it, you can set this flag `--intermediate_results_dir`:. like in: . https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command. That way, the output from the make_examples and call_variants steps will be saved, and you can just rerun postprocess_variants step if needed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:154,availability,error,error,154,I can confirm this problem on some of my samples. The program never produces the final outputs due to the post processing step ending prematurely (but no error message reported). . Normal log:. `. I0814 02:06:33.719291 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 02:06:33.734191: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmp1gvo5vri/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 02:13:18.938389: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 71894602. I0814 02:35:15.649105 140247404730176 postprocess_variants.py:1313] CVO sorting took 28.698674070835114 minutes. I0814 02:35:15.649988 140247404730176 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 02:40:15.761767 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0814 05:02:43.606994 140247404730176 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 142.46444999376934 minutes. I0814 06:01:36.673851 140247404730176 postprocess_variants.py:1407] Finished writing VCF and gVCF in 58.884093316396076 minutes. real 235m30.029s. user 220m0.378s. sys 13m54.784s. `. Samples with problems:. `. I0814 16:35:25.856544 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 16:35:25.879399: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmpfrusl15j/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 16:44:06.712469: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 92795573. I0814 17:09:30.584156 140492383778624 postprocess_variants.py:1313] CVO sorting took 34.078398688,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:188,deployability,log,log,188,I can confirm this problem on some of my samples. The program never produces the final outputs due to the post processing step ending prematurely (but no error message reported). . Normal log:. `. I0814 02:06:33.719291 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 02:06:33.734191: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmp1gvo5vri/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 02:13:18.938389: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 71894602. I0814 02:35:15.649105 140247404730176 postprocess_variants.py:1313] CVO sorting took 28.698674070835114 minutes. I0814 02:35:15.649988 140247404730176 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 02:40:15.761767 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0814 05:02:43.606994 140247404730176 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 142.46444999376934 minutes. I0814 06:01:36.673851 140247404730176 postprocess_variants.py:1407] Finished writing VCF and gVCF in 58.884093316396076 minutes. real 235m30.029s. user 220m0.378s. sys 13m54.784s. `. Samples with problems:. `. I0814 16:35:25.856544 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 16:35:25.879399: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmpfrusl15j/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 16:44:06.712469: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 92795573. I0814 17:09:30.584156 140492383778624 postprocess_variants.py:1313] CVO sorting took 34.078398688,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:2359,energy efficiency,cpu,cpus,2359,"t_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmp1gvo5vri/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 02:13:18.938389: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 71894602. I0814 02:35:15.649105 140247404730176 postprocess_variants.py:1313] CVO sorting took 28.698674070835114 minutes. I0814 02:35:15.649988 140247404730176 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 02:40:15.761767 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0814 05:02:43.606994 140247404730176 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 142.46444999376934 minutes. I0814 06:01:36.673851 140247404730176 postprocess_variants.py:1407] Finished writing VCF and gVCF in 58.884093316396076 minutes. real 235m30.029s. user 220m0.378s. sys 13m54.784s. `. Samples with problems:. `. I0814 16:35:25.856544 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 16:35:25.879399: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmpfrusl15j/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 16:44:06.712469: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 92795573. I0814 17:09:30.584156 140492383778624 postprocess_variants.py:1313] CVO sorting took 34.07839868863424 minutes. I0814 17:09:30.621869 140492383778624 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 17:15:23.469285 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. real 744m1.767s. user 58m24.804s. sys 64m10.806s. `. I set --postprocess_variants_extra_args=""cpus=0"" following previous suggestions. This allowed more samples to finish but still others did not.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:160,integrability,messag,message,160,I can confirm this problem on some of my samples. The program never produces the final outputs due to the post processing step ending prematurely (but no error message reported). . Normal log:. `. I0814 02:06:33.719291 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 02:06:33.734191: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmp1gvo5vri/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 02:13:18.938389: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 71894602. I0814 02:35:15.649105 140247404730176 postprocess_variants.py:1313] CVO sorting took 28.698674070835114 minutes. I0814 02:35:15.649988 140247404730176 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 02:40:15.761767 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0814 05:02:43.606994 140247404730176 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 142.46444999376934 minutes. I0814 06:01:36.673851 140247404730176 postprocess_variants.py:1407] Finished writing VCF and gVCF in 58.884093316396076 minutes. real 235m30.029s. user 220m0.378s. sys 13m54.784s. `. Samples with problems:. `. I0814 16:35:25.856544 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 16:35:25.879399: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmpfrusl15j/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 16:44:06.712469: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 92795573. I0814 17:09:30.584156 140492383778624 postprocess_variants.py:1313] CVO sorting took 34.078398688,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:868,integrability,Transform,Transforming,868,I can confirm this problem on some of my samples. The program never produces the final outputs due to the post processing step ending prematurely (but no error message reported). . Normal log:. `. I0814 02:06:33.719291 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 02:06:33.734191: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmp1gvo5vri/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 02:13:18.938389: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 71894602. I0814 02:35:15.649105 140247404730176 postprocess_variants.py:1313] CVO sorting took 28.698674070835114 minutes. I0814 02:35:15.649988 140247404730176 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 02:40:15.761767 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0814 05:02:43.606994 140247404730176 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 142.46444999376934 minutes. I0814 06:01:36.673851 140247404730176 postprocess_variants.py:1407] Finished writing VCF and gVCF in 58.884093316396076 minutes. real 235m30.029s. user 220m0.378s. sys 13m54.784s. `. Samples with problems:. `. I0814 16:35:25.856544 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 16:35:25.879399: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmpfrusl15j/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 16:44:06.712469: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 92795573. I0814 17:09:30.584156 140492383778624 postprocess_variants.py:1313] CVO sorting took 34.078398688,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:2083,integrability,Transform,Transforming,2083,"t_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmp1gvo5vri/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 02:13:18.938389: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 71894602. I0814 02:35:15.649105 140247404730176 postprocess_variants.py:1313] CVO sorting took 28.698674070835114 minutes. I0814 02:35:15.649988 140247404730176 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 02:40:15.761767 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0814 05:02:43.606994 140247404730176 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 142.46444999376934 minutes. I0814 06:01:36.673851 140247404730176 postprocess_variants.py:1407] Finished writing VCF and gVCF in 58.884093316396076 minutes. real 235m30.029s. user 220m0.378s. sys 13m54.784s. `. Samples with problems:. `. I0814 16:35:25.856544 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 16:35:25.879399: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmpfrusl15j/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 16:44:06.712469: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 92795573. I0814 17:09:30.584156 140492383778624 postprocess_variants.py:1313] CVO sorting took 34.07839868863424 minutes. I0814 17:09:30.621869 140492383778624 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 17:15:23.469285 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. real 744m1.767s. user 58m24.804s. sys 64m10.806s. `. I set --postprocess_variants_extra_args=""cpus=0"" following previous suggestions. This allowed more samples to finish but still others did not.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:160,interoperability,messag,message,160,I can confirm this problem on some of my samples. The program never produces the final outputs due to the post processing step ending prematurely (but no error message reported). . Normal log:. `. I0814 02:06:33.719291 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 02:06:33.734191: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmp1gvo5vri/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 02:13:18.938389: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 71894602. I0814 02:35:15.649105 140247404730176 postprocess_variants.py:1313] CVO sorting took 28.698674070835114 minutes. I0814 02:35:15.649988 140247404730176 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 02:40:15.761767 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0814 05:02:43.606994 140247404730176 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 142.46444999376934 minutes. I0814 06:01:36.673851 140247404730176 postprocess_variants.py:1407] Finished writing VCF and gVCF in 58.884093316396076 minutes. real 235m30.029s. user 220m0.378s. sys 13m54.784s. `. Samples with problems:. `. I0814 16:35:25.856544 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 16:35:25.879399: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmpfrusl15j/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 16:44:06.712469: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 92795573. I0814 17:09:30.584156 140492383778624 postprocess_variants.py:1313] CVO sorting took 34.078398688,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:437,interoperability,share,shareddata,437,I can confirm this problem on some of my samples. The program never produces the final outputs due to the post processing step ending prematurely (but no error message reported). . Normal log:. `. I0814 02:06:33.719291 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 02:06:33.734191: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmp1gvo5vri/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 02:13:18.938389: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 71894602. I0814 02:35:15.649105 140247404730176 postprocess_variants.py:1313] CVO sorting took 28.698674070835114 minutes. I0814 02:35:15.649988 140247404730176 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 02:40:15.761767 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0814 05:02:43.606994 140247404730176 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 142.46444999376934 minutes. I0814 06:01:36.673851 140247404730176 postprocess_variants.py:1407] Finished writing VCF and gVCF in 58.884093316396076 minutes. real 235m30.029s. user 220m0.378s. sys 13m54.784s. `. Samples with problems:. `. I0814 16:35:25.856544 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 16:35:25.879399: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmpfrusl15j/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 16:44:06.712469: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 92795573. I0814 17:09:30.584156 140492383778624 postprocess_variants.py:1313] CVO sorting took 34.078398688,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:868,interoperability,Transform,Transforming,868,I can confirm this problem on some of my samples. The program never produces the final outputs due to the post processing step ending prematurely (but no error message reported). . Normal log:. `. I0814 02:06:33.719291 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 02:06:33.734191: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmp1gvo5vri/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 02:13:18.938389: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 71894602. I0814 02:35:15.649105 140247404730176 postprocess_variants.py:1313] CVO sorting took 28.698674070835114 minutes. I0814 02:35:15.649988 140247404730176 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 02:40:15.761767 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0814 05:02:43.606994 140247404730176 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 142.46444999376934 minutes. I0814 06:01:36.673851 140247404730176 postprocess_variants.py:1407] Finished writing VCF and gVCF in 58.884093316396076 minutes. real 235m30.029s. user 220m0.378s. sys 13m54.784s. `. Samples with problems:. `. I0814 16:35:25.856544 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 16:35:25.879399: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmpfrusl15j/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 16:44:06.712469: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 92795573. I0814 17:09:30.584156 140492383778624 postprocess_variants.py:1313] CVO sorting took 34.078398688,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:1653,interoperability,share,shareddata,1653,"t_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmp1gvo5vri/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 02:13:18.938389: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 71894602. I0814 02:35:15.649105 140247404730176 postprocess_variants.py:1313] CVO sorting took 28.698674070835114 minutes. I0814 02:35:15.649988 140247404730176 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 02:40:15.761767 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0814 05:02:43.606994 140247404730176 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 142.46444999376934 minutes. I0814 06:01:36.673851 140247404730176 postprocess_variants.py:1407] Finished writing VCF and gVCF in 58.884093316396076 minutes. real 235m30.029s. user 220m0.378s. sys 13m54.784s. `. Samples with problems:. `. I0814 16:35:25.856544 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 16:35:25.879399: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmpfrusl15j/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 16:44:06.712469: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 92795573. I0814 17:09:30.584156 140492383778624 postprocess_variants.py:1313] CVO sorting took 34.07839868863424 minutes. I0814 17:09:30.621869 140492383778624 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 17:15:23.469285 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. real 744m1.767s. user 58m24.804s. sys 64m10.806s. `. I set --postprocess_variants_extra_args=""cpus=0"" following previous suggestions. This allowed more samples to finish but still others did not.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:2083,interoperability,Transform,Transforming,2083,"t_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmp1gvo5vri/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 02:13:18.938389: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 71894602. I0814 02:35:15.649105 140247404730176 postprocess_variants.py:1313] CVO sorting took 28.698674070835114 minutes. I0814 02:35:15.649988 140247404730176 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 02:40:15.761767 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0814 05:02:43.606994 140247404730176 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 142.46444999376934 minutes. I0814 06:01:36.673851 140247404730176 postprocess_variants.py:1407] Finished writing VCF and gVCF in 58.884093316396076 minutes. real 235m30.029s. user 220m0.378s. sys 13m54.784s. `. Samples with problems:. `. I0814 16:35:25.856544 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 16:35:25.879399: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmpfrusl15j/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 16:44:06.712469: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 92795573. I0814 17:09:30.584156 140492383778624 postprocess_variants.py:1313] CVO sorting took 34.07839868863424 minutes. I0814 17:09:30.621869 140492383778624 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 17:15:23.469285 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. real 744m1.767s. user 58m24.804s. sys 64m10.806s. `. I set --postprocess_variants_extra_args=""cpus=0"" following previous suggestions. This allowed more samples to finish but still others did not.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:154,performance,error,error,154,I can confirm this problem on some of my samples. The program never produces the final outputs due to the post processing step ending prematurely (but no error message reported). . Normal log:. `. I0814 02:06:33.719291 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 02:06:33.734191: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmp1gvo5vri/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 02:13:18.938389: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 71894602. I0814 02:35:15.649105 140247404730176 postprocess_variants.py:1313] CVO sorting took 28.698674070835114 minutes. I0814 02:35:15.649988 140247404730176 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 02:40:15.761767 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0814 05:02:43.606994 140247404730176 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 142.46444999376934 minutes. I0814 06:01:36.673851 140247404730176 postprocess_variants.py:1407] Finished writing VCF and gVCF in 58.884093316396076 minutes. real 235m30.029s. user 220m0.378s. sys 13m54.784s. `. Samples with problems:. `. I0814 16:35:25.856544 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 16:35:25.879399: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmpfrusl15j/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 16:44:06.712469: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 92795573. I0814 17:09:30.584156 140492383778624 postprocess_variants.py:1313] CVO sorting took 34.078398688,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:2359,performance,cpu,cpus,2359,"t_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmp1gvo5vri/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 02:13:18.938389: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 71894602. I0814 02:35:15.649105 140247404730176 postprocess_variants.py:1313] CVO sorting took 28.698674070835114 minutes. I0814 02:35:15.649988 140247404730176 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 02:40:15.761767 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0814 05:02:43.606994 140247404730176 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 142.46444999376934 minutes. I0814 06:01:36.673851 140247404730176 postprocess_variants.py:1407] Finished writing VCF and gVCF in 58.884093316396076 minutes. real 235m30.029s. user 220m0.378s. sys 13m54.784s. `. Samples with problems:. `. I0814 16:35:25.856544 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 16:35:25.879399: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmpfrusl15j/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 16:44:06.712469: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 92795573. I0814 17:09:30.584156 140492383778624 postprocess_variants.py:1313] CVO sorting took 34.07839868863424 minutes. I0814 17:09:30.621869 140492383778624 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 17:15:23.469285 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. real 744m1.767s. user 58m24.804s. sys 64m10.806s. `. I set --postprocess_variants_extra_args=""cpus=0"" following previous suggestions. This allowed more samples to finish but still others did not.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:154,safety,error,error,154,I can confirm this problem on some of my samples. The program never produces the final outputs due to the post processing step ending prematurely (but no error message reported). . Normal log:. `. I0814 02:06:33.719291 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 02:06:33.734191: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmp1gvo5vri/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 02:13:18.938389: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 71894602. I0814 02:35:15.649105 140247404730176 postprocess_variants.py:1313] CVO sorting took 28.698674070835114 minutes. I0814 02:35:15.649988 140247404730176 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 02:40:15.761767 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0814 05:02:43.606994 140247404730176 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 142.46444999376934 minutes. I0814 06:01:36.673851 140247404730176 postprocess_variants.py:1407] Finished writing VCF and gVCF in 58.884093316396076 minutes. real 235m30.029s. user 220m0.378s. sys 13m54.784s. `. Samples with problems:. `. I0814 16:35:25.856544 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 16:35:25.879399: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmpfrusl15j/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 16:44:06.712469: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 92795573. I0814 17:09:30.584156 140492383778624 postprocess_variants.py:1313] CVO sorting took 34.078398688,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:188,safety,log,log,188,I can confirm this problem on some of my samples. The program never produces the final outputs due to the post processing step ending prematurely (but no error message reported). . Normal log:. `. I0814 02:06:33.719291 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 02:06:33.734191: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmp1gvo5vri/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 02:13:18.938389: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 71894602. I0814 02:35:15.649105 140247404730176 postprocess_variants.py:1313] CVO sorting took 28.698674070835114 minutes. I0814 02:35:15.649988 140247404730176 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 02:40:15.761767 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0814 05:02:43.606994 140247404730176 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 142.46444999376934 minutes. I0814 06:01:36.673851 140247404730176 postprocess_variants.py:1407] Finished writing VCF and gVCF in 58.884093316396076 minutes. real 235m30.029s. user 220m0.378s. sys 13m54.784s. `. Samples with problems:. `. I0814 16:35:25.856544 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 16:35:25.879399: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmpfrusl15j/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 16:44:06.712469: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 92795573. I0814 17:09:30.584156 140492383778624 postprocess_variants.py:1313] CVO sorting took 34.078398688,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:188,security,log,log,188,I can confirm this problem on some of my samples. The program never produces the final outputs due to the post processing step ending prematurely (but no error message reported). . Normal log:. `. I0814 02:06:33.719291 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 02:06:33.734191: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmp1gvo5vri/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 02:13:18.938389: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 71894602. I0814 02:35:15.649105 140247404730176 postprocess_variants.py:1313] CVO sorting took 28.698674070835114 minutes. I0814 02:35:15.649988 140247404730176 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 02:40:15.761767 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0814 05:02:43.606994 140247404730176 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 142.46444999376934 minutes. I0814 06:01:36.673851 140247404730176 postprocess_variants.py:1407] Finished writing VCF and gVCF in 58.884093316396076 minutes. real 235m30.029s. user 220m0.378s. sys 13m54.784s. `. Samples with problems:. `. I0814 16:35:25.856544 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 16:35:25.879399: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmpfrusl15j/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 16:44:06.712469: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 92795573. I0814 17:09:30.584156 140492383778624 postprocess_variants.py:1313] CVO sorting took 34.078398688,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:188,testability,log,log,188,I can confirm this problem on some of my samples. The program never produces the final outputs due to the post processing step ending prematurely (but no error message reported). . Normal log:. `. I0814 02:06:33.719291 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 02:06:33.734191: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmp1gvo5vri/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 02:13:18.938389: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 71894602. I0814 02:35:15.649105 140247404730176 postprocess_variants.py:1313] CVO sorting took 28.698674070835114 minutes. I0814 02:35:15.649988 140247404730176 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 02:40:15.761767 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0814 05:02:43.606994 140247404730176 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 142.46444999376934 minutes. I0814 06:01:36.673851 140247404730176 postprocess_variants.py:1407] Finished writing VCF and gVCF in 58.884093316396076 minutes. real 235m30.029s. user 220m0.378s. sys 13m54.784s. `. Samples with problems:. `. I0814 16:35:25.856544 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 16:35:25.879399: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmpfrusl15j/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 16:44:06.712469: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 92795573. I0814 17:09:30.584156 140492383778624 postprocess_variants.py:1313] CVO sorting took 34.078398688,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:6,usability,confirm,confirm,6,I can confirm this problem on some of my samples. The program never produces the final outputs due to the post processing step ending prematurely (but no error message reported). . Normal log:. `. I0814 02:06:33.719291 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 02:06:33.734191: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmp1gvo5vri/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 02:13:18.938389: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 71894602. I0814 02:35:15.649105 140247404730176 postprocess_variants.py:1313] CVO sorting took 28.698674070835114 minutes. I0814 02:35:15.649988 140247404730176 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 02:40:15.761767 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0814 05:02:43.606994 140247404730176 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 142.46444999376934 minutes. I0814 06:01:36.673851 140247404730176 postprocess_variants.py:1407] Finished writing VCF and gVCF in 58.884093316396076 minutes. real 235m30.029s. user 220m0.378s. sys 13m54.784s. `. Samples with problems:. `. I0814 16:35:25.856544 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 16:35:25.879399: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmpfrusl15j/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 16:44:06.712469: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 92795573. I0814 17:09:30.584156 140492383778624 postprocess_variants.py:1313] CVO sorting took 34.078398688,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:154,usability,error,error,154,I can confirm this problem on some of my samples. The program never produces the final outputs due to the post processing step ending prematurely (but no error message reported). . Normal log:. `. I0814 02:06:33.719291 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 02:06:33.734191: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmp1gvo5vri/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 02:13:18.938389: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 71894602. I0814 02:35:15.649105 140247404730176 postprocess_variants.py:1313] CVO sorting took 28.698674070835114 minutes. I0814 02:35:15.649988 140247404730176 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 02:40:15.761767 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0814 05:02:43.606994 140247404730176 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 142.46444999376934 minutes. I0814 06:01:36.673851 140247404730176 postprocess_variants.py:1407] Finished writing VCF and gVCF in 58.884093316396076 minutes. real 235m30.029s. user 220m0.378s. sys 13m54.784s. `. Samples with problems:. `. I0814 16:35:25.856544 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 16:35:25.879399: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmpfrusl15j/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 16:44:06.712469: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 92795573. I0814 17:09:30.584156 140492383778624 postprocess_variants.py:1313] CVO sorting took 34.078398688,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:1350,usability,user,user,1350,734191: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmp1gvo5vri/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 02:13:18.938389: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 71894602. I0814 02:35:15.649105 140247404730176 postprocess_variants.py:1313] CVO sorting took 28.698674070835114 minutes. I0814 02:35:15.649988 140247404730176 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 02:40:15.761767 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0814 05:02:43.606994 140247404730176 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 142.46444999376934 minutes. I0814 06:01:36.673851 140247404730176 postprocess_variants.py:1407] Finished writing VCF and gVCF in 58.884093316396076 minutes. real 235m30.029s. user 220m0.378s. sys 13m54.784s. `. Samples with problems:. `. I0814 16:35:25.856544 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 16:35:25.879399: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmpfrusl15j/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 16:44:06.712469: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 92795573. I0814 17:09:30.584156 140492383778624 postprocess_variants.py:1313] CVO sorting took 34.07839868863424 minutes. I0814 17:09:30.621869 140492383778624 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 17:15:23.469285 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. real 744m1.767s. user 58m24.804s. sys 64m10.806s. `. I set --postprocess_variants_extra,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:2282,usability,user,user,2282,"t_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmp1gvo5vri/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 02:13:18.938389: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 71894602. I0814 02:35:15.649105 140247404730176 postprocess_variants.py:1313] CVO sorting took 28.698674070835114 minutes. I0814 02:35:15.649988 140247404730176 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 02:40:15.761767 140247404730176 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. I0814 05:02:43.606994 140247404730176 postprocess_variants.py:1386] Processing variants (and writing to temporary file) took 142.46444999376934 minutes. I0814 06:01:36.673851 140247404730176 postprocess_variants.py:1407] Finished writing VCF and gVCF in 58.884093316396076 minutes. real 235m30.029s. user 220m0.378s. sys 13m54.784s. `. Samples with problems:. `. I0814 16:35:25.856544 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. 2024-08-14 16:35:25.879399: I deepvariant/postprocess_variants.cc:94] Read from: /public4/courses/ec3121/shareddata/Camellia_Sect_Chrysantha/bwa_hapbetter/wgs/deepvariant/tmp/tmpfrusl15j/call_variants_output-00000-of-00001.tfrecord.gz. 2024-08-14 16:44:06.712469: I deepvariant/postprocess_variants.cc:109] Total #entries in single_site_calls = 92795573. I0814 17:09:30.584156 140492383778624 postprocess_variants.py:1313] CVO sorting took 34.07839868863424 minutes. I0814 17:09:30.621869 140492383778624 postprocess_variants.py:1316] Transforming call_variants_output to variants. I0814 17:15:23.469285 140492383778624 postprocess_variants.py:1211] Using sample name from call_variants output. Sample name: default. real 744m1.767s. user 58m24.804s. sys 64m10.806s. `. I set --postprocess_variants_extra_args=""cpus=0"" following previous suggestions. This allowed more samples to finish but still others did not.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:170,deployability,version,versions,170,"This was probably due to running out of RAM, since running on a node with 2TB of RAM produced an output. Perhaps there needs to be a way to limit RAM usage in subsequent versions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:159,integrability,sub,subsequent,159,"This was probably due to running out of RAM, since running on a node with 2TB of RAM produced an output. Perhaps there needs to be a way to limit RAM usage in subsequent versions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:170,integrability,version,versions,170,"This was probably due to running out of RAM, since running on a node with 2TB of RAM produced an output. Perhaps there needs to be a way to limit RAM usage in subsequent versions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:170,modifiability,version,versions,170,"This was probably due to running out of RAM, since running on a node with 2TB of RAM produced an output. Perhaps there needs to be a way to limit RAM usage in subsequent versions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:144,interoperability,standard,standard,144,"Hi @pichuan, I re-ran it with more disk space and had the same issue. Hi @melop, thank you for your input and for exemplifying what should be a standard output; per your recommendation, it should be, as @pichuan had already guessed, a RAM issue. Thank you both. I'll see what I can do on my end to solve the RAM issue, and I'll follow up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:35,performance,disk,disk,35,"Hi @pichuan, I re-ran it with more disk space and had the same issue. Hi @melop, thank you for your input and for exemplifying what should be a standard output; per your recommendation, it should be, as @pichuan had already guessed, a RAM issue. Thank you both. I'll see what I can do on my end to solve the RAM issue, and I'll follow up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:100,safety,input,input,100,"Hi @pichuan, I re-ran it with more disk space and had the same issue. Hi @melop, thank you for your input and for exemplifying what should be a standard output; per your recommendation, it should be, as @pichuan had already guessed, a RAM issue. Thank you both. I'll see what I can do on my end to solve the RAM issue, and I'll follow up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:100,usability,input,input,100,"Hi @pichuan, I re-ran it with more disk space and had the same issue. Hi @melop, thank you for your input and for exemplifying what should be a standard output; per your recommendation, it should be, as @pichuan had already guessed, a RAM issue. Thank you both. I'll see what I can do on my end to solve the RAM issue, and I'll follow up.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:397,deployability,automat,automatically,397,"> Hi @vera-gomes , One possible way to get around the RAM issue is to split the run into two or more, using the `--regions` flag (For example, one run can run the first 8 chromosomes, and the second run can run the rest, or something like that). And then at the end you can combine the VCFs. Perhaps a user-friendly way to implement this is to let deepvariant split the job by chromosomes/regions automatically? If this mainly affects the post processing step, perhaps just make this step automatically process the output by chromosome/regions of a fixed window size?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:489,deployability,automat,automatically,489,"> Hi @vera-gomes , One possible way to get around the RAM issue is to split the run into two or more, using the `--regions` flag (For example, one run can run the first 8 chromosomes, and the second run can run the rest, or something like that). And then at the end you can combine the VCFs. Perhaps a user-friendly way to implement this is to let deepvariant split the job by chromosomes/regions automatically? If this mainly affects the post processing step, perhaps just make this step automatically process the output by chromosome/regions of a fixed window size?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:397,testability,automat,automatically,397,"> Hi @vera-gomes , One possible way to get around the RAM issue is to split the run into two or more, using the `--regions` flag (For example, one run can run the first 8 chromosomes, and the second run can run the rest, or something like that). And then at the end you can combine the VCFs. Perhaps a user-friendly way to implement this is to let deepvariant split the job by chromosomes/regions automatically? If this mainly affects the post processing step, perhaps just make this step automatically process the output by chromosome/regions of a fixed window size?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:489,testability,automat,automatically,489,"> Hi @vera-gomes , One possible way to get around the RAM issue is to split the run into two or more, using the `--regions` flag (For example, one run can run the first 8 chromosomes, and the second run can run the rest, or something like that). And then at the end you can combine the VCFs. Perhaps a user-friendly way to implement this is to let deepvariant split the job by chromosomes/regions automatically? If this mainly affects the post processing step, perhaps just make this step automatically process the output by chromosome/regions of a fixed window size?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:302,usability,user,user-friendly,302,"> Hi @vera-gomes , One possible way to get around the RAM issue is to split the run into two or more, using the `--regions` flag (For example, one run can run the first 8 chromosomes, and the second run can run the rest, or something like that). And then at the end you can combine the VCFs. Perhaps a user-friendly way to implement this is to let deepvariant split the job by chromosomes/regions automatically? If this mainly affects the post processing step, perhaps just make this step automatically process the output by chromosome/regions of a fixed window size?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:88,deployability,releas,release,88,"Hi @melop,. Great suggestion! As luck would have it, this will be a feature in our next release (`1.7.0`). We have parallelized/sharded `postprocess_variants` across multiple CPUs, which helps to reduce its maximum RAM footprint. It also takes in a `--regions` flag directly so you can easily split up the process further if that's necessary (although it shouldn't be). . Until `1.7.0` is released, your only option is to follow @pichuan's suggestion. You can use `bcftools concat` to join the region-specific VCFs back together. I hope that helps!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:389,deployability,releas,released,389,"Hi @melop,. Great suggestion! As luck would have it, this will be a feature in our next release (`1.7.0`). We have parallelized/sharded `postprocess_variants` across multiple CPUs, which helps to reduce its maximum RAM footprint. It also takes in a `--regions` flag directly so you can easily split up the process further if that's necessary (although it shouldn't be). . Until `1.7.0` is released, your only option is to follow @pichuan's suggestion. You can use `bcftools concat` to join the region-specific VCFs back together. I hope that helps!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:175,energy efficiency,CPU,CPUs,175,"Hi @melop,. Great suggestion! As luck would have it, this will be a feature in our next release (`1.7.0`). We have parallelized/sharded `postprocess_variants` across multiple CPUs, which helps to reduce its maximum RAM footprint. It also takes in a `--regions` flag directly so you can easily split up the process further if that's necessary (although it shouldn't be). . Until `1.7.0` is released, your only option is to follow @pichuan's suggestion. You can use `bcftools concat` to join the region-specific VCFs back together. I hope that helps!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:196,energy efficiency,reduc,reduce,196,"Hi @melop,. Great suggestion! As luck would have it, this will be a feature in our next release (`1.7.0`). We have parallelized/sharded `postprocess_variants` across multiple CPUs, which helps to reduce its maximum RAM footprint. It also takes in a `--regions` flag directly so you can easily split up the process further if that's necessary (although it shouldn't be). . Until `1.7.0` is released, your only option is to follow @pichuan's suggestion. You can use `bcftools concat` to join the region-specific VCFs back together. I hope that helps!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:501,interoperability,specif,specific,501,"Hi @melop,. Great suggestion! As luck would have it, this will be a feature in our next release (`1.7.0`). We have parallelized/sharded `postprocess_variants` across multiple CPUs, which helps to reduce its maximum RAM footprint. It also takes in a `--regions` flag directly so you can easily split up the process further if that's necessary (although it shouldn't be). . Until `1.7.0` is released, your only option is to follow @pichuan's suggestion. You can use `bcftools concat` to join the region-specific VCFs back together. I hope that helps!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:115,performance,parallel,parallelized,115,"Hi @melop,. Great suggestion! As luck would have it, this will be a feature in our next release (`1.7.0`). We have parallelized/sharded `postprocess_variants` across multiple CPUs, which helps to reduce its maximum RAM footprint. It also takes in a `--regions` flag directly so you can easily split up the process further if that's necessary (although it shouldn't be). . Until `1.7.0` is released, your only option is to follow @pichuan's suggestion. You can use `bcftools concat` to join the region-specific VCFs back together. I hope that helps!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:175,performance,CPU,CPUs,175,"Hi @melop,. Great suggestion! As luck would have it, this will be a feature in our next release (`1.7.0`). We have parallelized/sharded `postprocess_variants` across multiple CPUs, which helps to reduce its maximum RAM footprint. It also takes in a `--regions` flag directly so you can easily split up the process further if that's necessary (although it shouldn't be). . Until `1.7.0` is released, your only option is to follow @pichuan's suggestion. You can use `bcftools concat` to join the region-specific VCFs back together. I hope that helps!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:187,usability,help,helps,187,"Hi @melop,. Great suggestion! As luck would have it, this will be a feature in our next release (`1.7.0`). We have parallelized/sharded `postprocess_variants` across multiple CPUs, which helps to reduce its maximum RAM footprint. It also takes in a `--regions` flag directly so you can easily split up the process further if that's necessary (although it shouldn't be). . Until `1.7.0` is released, your only option is to follow @pichuan's suggestion. You can use `bcftools concat` to join the region-specific VCFs back together. I hope that helps!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/868:542,usability,help,helps,542,"Hi @melop,. Great suggestion! As luck would have it, this will be a feature in our next release (`1.7.0`). We have parallelized/sharded `postprocess_variants` across multiple CPUs, which helps to reduce its maximum RAM footprint. It also takes in a `--regions` flag directly so you can easily split up the process further if that's necessary (although it shouldn't be). . Until `1.7.0` is released, your only option is to follow @pichuan's suggestion. You can use `bcftools concat` to join the region-specific VCFs back together. I hope that helps!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/868
https://github.com/google/deepvariant/issues/869:103,availability,checkpoint,checkpoint,103,"Hi! Thanks for the kind words. The issue seems to be that `call_variants` expects a JSON file with the checkpoint. ```. model_example_info_json = f'{checkpoint_path}/example_info.json'. model_example_shape = dv_utils.get_shape_and_channels_from_json(. model_example_info_json. ). ```. Can you confirm that this file exists under `""/output/checkpoints/ckpt-679""`? If it exists, could you paste the content of it here? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:339,availability,checkpoint,checkpoints,339,"Hi! Thanks for the kind words. The issue seems to be that `call_variants` expects a JSON file with the checkpoint. ```. model_example_info_json = f'{checkpoint_path}/example_info.json'. model_example_shape = dv_utils.get_shape_and_channels_from_json(. model_example_info_json. ). ```. Can you confirm that this file exists under `""/output/checkpoints/ckpt-679""`? If it exists, could you paste the content of it here? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:397,performance,content,content,397,"Hi! Thanks for the kind words. The issue seems to be that `call_variants` expects a JSON file with the checkpoint. ```. model_example_info_json = f'{checkpoint_path}/example_info.json'. model_example_shape = dv_utils.get_shape_and_channels_from_json(. model_example_info_json. ). ```. Can you confirm that this file exists under `""/output/checkpoints/ckpt-679""`? If it exists, could you paste the content of it here? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:103,reliability,checkpoint,checkpoint,103,"Hi! Thanks for the kind words. The issue seems to be that `call_variants` expects a JSON file with the checkpoint. ```. model_example_info_json = f'{checkpoint_path}/example_info.json'. model_example_shape = dv_utils.get_shape_and_channels_from_json(. model_example_info_json. ). ```. Can you confirm that this file exists under `""/output/checkpoints/ckpt-679""`? If it exists, could you paste the content of it here? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:339,reliability,checkpoint,checkpoints,339,"Hi! Thanks for the kind words. The issue seems to be that `call_variants` expects a JSON file with the checkpoint. ```. model_example_info_json = f'{checkpoint_path}/example_info.json'. model_example_shape = dv_utils.get_shape_and_channels_from_json(. model_example_info_json. ). ```. Can you confirm that this file exists under `""/output/checkpoints/ckpt-679""`? If it exists, could you paste the content of it here? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:293,usability,confirm,confirm,293,"Hi! Thanks for the kind words. The issue seems to be that `call_variants` expects a JSON file with the checkpoint. ```. model_example_info_json = f'{checkpoint_path}/example_info.json'. model_example_shape = dv_utils.get_shape_and_channels_from_json(. model_example_info_json. ). ```. Can you confirm that this file exists under `""/output/checkpoints/ckpt-679""`? If it exists, could you paste the content of it here? .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:111,availability,checkpoint,checkpoint,111,"> Hi! > . > Thanks for the kind words. The issue seems to be that `call_variants` expects a JSON file with the checkpoint. > . > ```. > model_example_info_json = f'{checkpoint_path}/example_info.json'. > model_example_shape = dv_utils.get_shape_and_channels_from_json(. > model_example_info_json. > ). > ```. > . > Can you confirm that this file exists under `""/output/checkpoints/ckpt-679""`? If it exists, could you paste the content of it here? Hello, first, thank you very much for your help. Yes, the example_info.json exist, but do not have any content. Should it contain some information? ![Captura desde 2024-08-27 08-57-05](https://github.com/user-attachments/assets/753ee356-ed61-415f-8156-7932fd1cbce4).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:369,availability,checkpoint,checkpoints,369,"> Hi! > . > Thanks for the kind words. The issue seems to be that `call_variants` expects a JSON file with the checkpoint. > . > ```. > model_example_info_json = f'{checkpoint_path}/example_info.json'. > model_example_shape = dv_utils.get_shape_and_channels_from_json(. > model_example_info_json. > ). > ```. > . > Can you confirm that this file exists under `""/output/checkpoints/ckpt-679""`? If it exists, could you paste the content of it here? Hello, first, thank you very much for your help. Yes, the example_info.json exist, but do not have any content. Should it contain some information? ![Captura desde 2024-08-27 08-57-05](https://github.com/user-attachments/assets/753ee356-ed61-415f-8156-7932fd1cbce4).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:569,deployability,contain,contain,569,"> Hi! > . > Thanks for the kind words. The issue seems to be that `call_variants` expects a JSON file with the checkpoint. > . > ```. > model_example_info_json = f'{checkpoint_path}/example_info.json'. > model_example_shape = dv_utils.get_shape_and_channels_from_json(. > model_example_info_json. > ). > ```. > . > Can you confirm that this file exists under `""/output/checkpoints/ckpt-679""`? If it exists, could you paste the content of it here? Hello, first, thank you very much for your help. Yes, the example_info.json exist, but do not have any content. Should it contain some information? ![Captura desde 2024-08-27 08-57-05](https://github.com/user-attachments/assets/753ee356-ed61-415f-8156-7932fd1cbce4).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:427,performance,content,content,427,"> Hi! > . > Thanks for the kind words. The issue seems to be that `call_variants` expects a JSON file with the checkpoint. > . > ```. > model_example_info_json = f'{checkpoint_path}/example_info.json'. > model_example_shape = dv_utils.get_shape_and_channels_from_json(. > model_example_info_json. > ). > ```. > . > Can you confirm that this file exists under `""/output/checkpoints/ckpt-679""`? If it exists, could you paste the content of it here? Hello, first, thank you very much for your help. Yes, the example_info.json exist, but do not have any content. Should it contain some information? ![Captura desde 2024-08-27 08-57-05](https://github.com/user-attachments/assets/753ee356-ed61-415f-8156-7932fd1cbce4).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:550,performance,content,content,550,"> Hi! > . > Thanks for the kind words. The issue seems to be that `call_variants` expects a JSON file with the checkpoint. > . > ```. > model_example_info_json = f'{checkpoint_path}/example_info.json'. > model_example_shape = dv_utils.get_shape_and_channels_from_json(. > model_example_info_json. > ). > ```. > . > Can you confirm that this file exists under `""/output/checkpoints/ckpt-679""`? If it exists, could you paste the content of it here? Hello, first, thank you very much for your help. Yes, the example_info.json exist, but do not have any content. Should it contain some information? ![Captura desde 2024-08-27 08-57-05](https://github.com/user-attachments/assets/753ee356-ed61-415f-8156-7932fd1cbce4).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:111,reliability,checkpoint,checkpoint,111,"> Hi! > . > Thanks for the kind words. The issue seems to be that `call_variants` expects a JSON file with the checkpoint. > . > ```. > model_example_info_json = f'{checkpoint_path}/example_info.json'. > model_example_shape = dv_utils.get_shape_and_channels_from_json(. > model_example_info_json. > ). > ```. > . > Can you confirm that this file exists under `""/output/checkpoints/ckpt-679""`? If it exists, could you paste the content of it here? Hello, first, thank you very much for your help. Yes, the example_info.json exist, but do not have any content. Should it contain some information? ![Captura desde 2024-08-27 08-57-05](https://github.com/user-attachments/assets/753ee356-ed61-415f-8156-7932fd1cbce4).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:369,reliability,checkpoint,checkpoints,369,"> Hi! > . > Thanks for the kind words. The issue seems to be that `call_variants` expects a JSON file with the checkpoint. > . > ```. > model_example_info_json = f'{checkpoint_path}/example_info.json'. > model_example_shape = dv_utils.get_shape_and_channels_from_json(. > model_example_info_json. > ). > ```. > . > Can you confirm that this file exists under `""/output/checkpoints/ckpt-679""`? If it exists, could you paste the content of it here? Hello, first, thank you very much for your help. Yes, the example_info.json exist, but do not have any content. Should it contain some information? ![Captura desde 2024-08-27 08-57-05](https://github.com/user-attachments/assets/753ee356-ed61-415f-8156-7932fd1cbce4).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:323,usability,confirm,confirm,323,"> Hi! > . > Thanks for the kind words. The issue seems to be that `call_variants` expects a JSON file with the checkpoint. > . > ```. > model_example_info_json = f'{checkpoint_path}/example_info.json'. > model_example_shape = dv_utils.get_shape_and_channels_from_json(. > model_example_info_json. > ). > ```. > . > Can you confirm that this file exists under `""/output/checkpoints/ckpt-679""`? If it exists, could you paste the content of it here? Hello, first, thank you very much for your help. Yes, the example_info.json exist, but do not have any content. Should it contain some information? ![Captura desde 2024-08-27 08-57-05](https://github.com/user-attachments/assets/753ee356-ed61-415f-8156-7932fd1cbce4).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:490,usability,help,help,490,"> Hi! > . > Thanks for the kind words. The issue seems to be that `call_variants` expects a JSON file with the checkpoint. > . > ```. > model_example_info_json = f'{checkpoint_path}/example_info.json'. > model_example_shape = dv_utils.get_shape_and_channels_from_json(. > model_example_info_json. > ). > ```. > . > Can you confirm that this file exists under `""/output/checkpoints/ckpt-679""`? If it exists, could you paste the content of it here? Hello, first, thank you very much for your help. Yes, the example_info.json exist, but do not have any content. Should it contain some information? ![Captura desde 2024-08-27 08-57-05](https://github.com/user-attachments/assets/753ee356-ed61-415f-8156-7932fd1cbce4).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:651,usability,user,user-attachments,651,"> Hi! > . > Thanks for the kind words. The issue seems to be that `call_variants` expects a JSON file with the checkpoint. > . > ```. > model_example_info_json = f'{checkpoint_path}/example_info.json'. > model_example_shape = dv_utils.get_shape_and_channels_from_json(. > model_example_info_json. > ). > ```. > . > Can you confirm that this file exists under `""/output/checkpoints/ckpt-679""`? If it exists, could you paste the content of it here? Hello, first, thank you very much for your help. Yes, the example_info.json exist, but do not have any content. Should it contain some information? ![Captura desde 2024-08-27 08-57-05](https://github.com/user-attachments/assets/753ee356-ed61-415f-8156-7932fd1cbce4).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:140,availability,checkpoint,checkpoints,140,"@bioinformaticaomicalabs , yes it should contain some information like this:. ```bash. gsutil cat gs://deepvariant/models/DeepVariant/1.6.1/checkpoints/wgs/example_info.json. {""version"": ""1.6.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]}. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:41,deployability,contain,contain,41,"@bioinformaticaomicalabs , yes it should contain some information like this:. ```bash. gsutil cat gs://deepvariant/models/DeepVariant/1.6.1/checkpoints/wgs/example_info.json. {""version"": ""1.6.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]}. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:177,deployability,version,version,177,"@bioinformaticaomicalabs , yes it should contain some information like this:. ```bash. gsutil cat gs://deepvariant/models/DeepVariant/1.6.1/checkpoints/wgs/example_info.json. {""version"": ""1.6.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]}. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:115,energy efficiency,model,models,115,"@bioinformaticaomicalabs , yes it should contain some information like this:. ```bash. gsutil cat gs://deepvariant/models/DeepVariant/1.6.1/checkpoints/wgs/example_info.json. {""version"": ""1.6.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]}. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:177,integrability,version,version,177,"@bioinformaticaomicalabs , yes it should contain some information like this:. ```bash. gsutil cat gs://deepvariant/models/DeepVariant/1.6.1/checkpoints/wgs/example_info.json. {""version"": ""1.6.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]}. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:177,modifiability,version,version,177,"@bioinformaticaomicalabs , yes it should contain some information like this:. ```bash. gsutil cat gs://deepvariant/models/DeepVariant/1.6.1/checkpoints/wgs/example_info.json. {""version"": ""1.6.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]}. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:140,reliability,checkpoint,checkpoints,140,"@bioinformaticaomicalabs , yes it should contain some information like this:. ```bash. gsutil cat gs://deepvariant/models/DeepVariant/1.6.1/checkpoints/wgs/example_info.json. {""version"": ""1.6.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]}. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:115,security,model,models,115,"@bioinformaticaomicalabs , yes it should contain some information like this:. ```bash. gsutil cat gs://deepvariant/models/DeepVariant/1.6.1/checkpoints/wgs/example_info.json. {""version"": ""1.6.0"", ""shape"": [100, 221, 7], ""channels"": [1, 2, 3, 4, 5, 6, 19]}. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:288,availability,checkpoint,checkpoint,288,Can you check if you have `example_info.json` output in your training data and validation data generation folders and if they are the same? If same then you can copy it to the directory and use it. The training loop is supposed to copy the `example_info.json` from training folder to the checkpoint output directory. Not sure if it was missing in your setup.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:288,reliability,checkpoint,checkpoint,288,Can you check if you have `example_info.json` output in your training data and validation data generation folders and if they are the same? If same then you can copy it to the directory and use it. The training loop is supposed to copy the `example_info.json` from training folder to the checkpoint output directory. Not sure if it was missing in your setup.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:79,safety,valid,validation,79,Can you check if you have `example_info.json` output in your training data and validation data generation folders and if they are the same? If same then you can copy it to the directory and use it. The training loop is supposed to copy the `example_info.json` from training folder to the checkpoint output directory. Not sure if it was missing in your setup.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:79,security,validat,validation,79,Can you check if you have `example_info.json` output in your training data and validation data generation folders and if they are the same? If same then you can copy it to the directory and use it. The training loop is supposed to copy the `example_info.json` from training folder to the checkpoint output directory. Not sure if it was missing in your setup.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:403,energy efficiency,model,model,403,"Thank you very much, that finally resolved the issue. What happens now is that after performing the evaluation (the training, test, and validation sets are the sequencing of the NA12878 sample from the Coriell Institute sequenced three times), Im getting low recall and precision values. For indels, recall is 0.41 and precision is 0.24, and for SNPs, recall is 0.57 and precision is 0.72. I tried the model you provided for exome sequencing, but I didnt achieve better results (which is why I decided to create my own model). However, with typical tools (like GATK HaplotypeCaller), I get much better results (indels with 0.8 recall and 0.62 precision, and SNPs with 0.89 recall and 0.97 precision). Do you have any idea why this might be happening and any advice on how to solve it? I really believe that using a variant caller trained with my data should yield better results than GATK HaplotypeCaller",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:521,energy efficiency,model,model,521,"Thank you very much, that finally resolved the issue. What happens now is that after performing the evaluation (the training, test, and validation sets are the sequencing of the NA12878 sample from the Coriell Institute sequenced three times), Im getting low recall and precision values. For indels, recall is 0.41 and precision is 0.24, and for SNPs, recall is 0.57 and precision is 0.72. I tried the model you provided for exome sequencing, but I didnt achieve better results (which is why I decided to create my own model). However, with typical tools (like GATK HaplotypeCaller), I get much better results (indels with 0.8 recall and 0.62 precision, and SNPs with 0.89 recall and 0.97 precision). Do you have any idea why this might be happening and any advice on how to solve it? I really believe that using a variant caller trained with my data should yield better results than GATK HaplotypeCaller",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:85,performance,perform,performing,85,"Thank you very much, that finally resolved the issue. What happens now is that after performing the evaluation (the training, test, and validation sets are the sequencing of the NA12878 sample from the Coriell Institute sequenced three times), Im getting low recall and precision values. For indels, recall is 0.41 and precision is 0.24, and for SNPs, recall is 0.57 and precision is 0.72. I tried the model you provided for exome sequencing, but I didnt achieve better results (which is why I decided to create my own model). However, with typical tools (like GATK HaplotypeCaller), I get much better results (indels with 0.8 recall and 0.62 precision, and SNPs with 0.89 recall and 0.97 precision). Do you have any idea why this might be happening and any advice on how to solve it? I really believe that using a variant caller trained with my data should yield better results than GATK HaplotypeCaller",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:236,performance,time,times,236,"Thank you very much, that finally resolved the issue. What happens now is that after performing the evaluation (the training, test, and validation sets are the sequencing of the NA12878 sample from the Coriell Institute sequenced three times), Im getting low recall and precision values. For indels, recall is 0.41 and precision is 0.24, and for SNPs, recall is 0.57 and precision is 0.72. I tried the model you provided for exome sequencing, but I didnt achieve better results (which is why I decided to create my own model). However, with typical tools (like GATK HaplotypeCaller), I get much better results (indels with 0.8 recall and 0.62 precision, and SNPs with 0.89 recall and 0.97 precision). Do you have any idea why this might be happening and any advice on how to solve it? I really believe that using a variant caller trained with my data should yield better results than GATK HaplotypeCaller",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:126,safety,test,test,126,"Thank you very much, that finally resolved the issue. What happens now is that after performing the evaluation (the training, test, and validation sets are the sequencing of the NA12878 sample from the Coriell Institute sequenced three times), Im getting low recall and precision values. For indels, recall is 0.41 and precision is 0.24, and for SNPs, recall is 0.57 and precision is 0.72. I tried the model you provided for exome sequencing, but I didnt achieve better results (which is why I decided to create my own model). However, with typical tools (like GATK HaplotypeCaller), I get much better results (indels with 0.8 recall and 0.62 precision, and SNPs with 0.89 recall and 0.97 precision). Do you have any idea why this might be happening and any advice on how to solve it? I really believe that using a variant caller trained with my data should yield better results than GATK HaplotypeCaller",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:136,safety,valid,validation,136,"Thank you very much, that finally resolved the issue. What happens now is that after performing the evaluation (the training, test, and validation sets are the sequencing of the NA12878 sample from the Coriell Institute sequenced three times), Im getting low recall and precision values. For indels, recall is 0.41 and precision is 0.24, and for SNPs, recall is 0.57 and precision is 0.72. I tried the model you provided for exome sequencing, but I didnt achieve better results (which is why I decided to create my own model). However, with typical tools (like GATK HaplotypeCaller), I get much better results (indels with 0.8 recall and 0.62 precision, and SNPs with 0.89 recall and 0.97 precision). Do you have any idea why this might be happening and any advice on how to solve it? I really believe that using a variant caller trained with my data should yield better results than GATK HaplotypeCaller",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:136,security,validat,validation,136,"Thank you very much, that finally resolved the issue. What happens now is that after performing the evaluation (the training, test, and validation sets are the sequencing of the NA12878 sample from the Coriell Institute sequenced three times), Im getting low recall and precision values. For indels, recall is 0.41 and precision is 0.24, and for SNPs, recall is 0.57 and precision is 0.72. I tried the model you provided for exome sequencing, but I didnt achieve better results (which is why I decided to create my own model). However, with typical tools (like GATK HaplotypeCaller), I get much better results (indels with 0.8 recall and 0.62 precision, and SNPs with 0.89 recall and 0.97 precision). Do you have any idea why this might be happening and any advice on how to solve it? I really believe that using a variant caller trained with my data should yield better results than GATK HaplotypeCaller",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:403,security,model,model,403,"Thank you very much, that finally resolved the issue. What happens now is that after performing the evaluation (the training, test, and validation sets are the sequencing of the NA12878 sample from the Coriell Institute sequenced three times), Im getting low recall and precision values. For indels, recall is 0.41 and precision is 0.24, and for SNPs, recall is 0.57 and precision is 0.72. I tried the model you provided for exome sequencing, but I didnt achieve better results (which is why I decided to create my own model). However, with typical tools (like GATK HaplotypeCaller), I get much better results (indels with 0.8 recall and 0.62 precision, and SNPs with 0.89 recall and 0.97 precision). Do you have any idea why this might be happening and any advice on how to solve it? I really believe that using a variant caller trained with my data should yield better results than GATK HaplotypeCaller",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:521,security,model,model,521,"Thank you very much, that finally resolved the issue. What happens now is that after performing the evaluation (the training, test, and validation sets are the sequencing of the NA12878 sample from the Coriell Institute sequenced three times), Im getting low recall and precision values. For indels, recall is 0.41 and precision is 0.24, and for SNPs, recall is 0.57 and precision is 0.72. I tried the model you provided for exome sequencing, but I didnt achieve better results (which is why I decided to create my own model). However, with typical tools (like GATK HaplotypeCaller), I get much better results (indels with 0.8 recall and 0.62 precision, and SNPs with 0.89 recall and 0.97 precision). Do you have any idea why this might be happening and any advice on how to solve it? I really believe that using a variant caller trained with my data should yield better results than GATK HaplotypeCaller",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:126,testability,test,test,126,"Thank you very much, that finally resolved the issue. What happens now is that after performing the evaluation (the training, test, and validation sets are the sequencing of the NA12878 sample from the Coriell Institute sequenced three times), Im getting low recall and precision values. For indels, recall is 0.41 and precision is 0.24, and for SNPs, recall is 0.57 and precision is 0.72. I tried the model you provided for exome sequencing, but I didnt achieve better results (which is why I decided to create my own model). However, with typical tools (like GATK HaplotypeCaller), I get much better results (indels with 0.8 recall and 0.62 precision, and SNPs with 0.89 recall and 0.97 precision). Do you have any idea why this might be happening and any advice on how to solve it? I really believe that using a variant caller trained with my data should yield better results than GATK HaplotypeCaller",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:85,usability,perform,performing,85,"Thank you very much, that finally resolved the issue. What happens now is that after performing the evaluation (the training, test, and validation sets are the sequencing of the NA12878 sample from the Coriell Institute sequenced three times), Im getting low recall and precision values. For indels, recall is 0.41 and precision is 0.24, and for SNPs, recall is 0.57 and precision is 0.72. I tried the model you provided for exome sequencing, but I didnt achieve better results (which is why I decided to create my own model). However, with typical tools (like GATK HaplotypeCaller), I get much better results (indels with 0.8 recall and 0.62 precision, and SNPs with 0.89 recall and 0.97 precision). Do you have any idea why this might be happening and any advice on how to solve it? I really believe that using a variant caller trained with my data should yield better results than GATK HaplotypeCaller",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:551,usability,tool,tools,551,"Thank you very much, that finally resolved the issue. What happens now is that after performing the evaluation (the training, test, and validation sets are the sequencing of the NA12878 sample from the Coriell Institute sequenced three times), Im getting low recall and precision values. For indels, recall is 0.41 and precision is 0.24, and for SNPs, recall is 0.57 and precision is 0.72. I tried the model you provided for exome sequencing, but I didnt achieve better results (which is why I decided to create my own model). However, with typical tools (like GATK HaplotypeCaller), I get much better results (indels with 0.8 recall and 0.62 precision, and SNPs with 0.89 recall and 0.97 precision). Do you have any idea why this might be happening and any advice on how to solve it? I really believe that using a variant caller trained with my data should yield better results than GATK HaplotypeCaller",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:122,energy efficiency,model,model,122,"@bioinformaticaomicalabs , if you have a benchmarking bam file that you can share then I can try to run it on our default model and see if it matches your expectations. However, why training didn't work would require some more investigation on how exactly you are training and preparing your data.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:76,interoperability,share,share,76,"@bioinformaticaomicalabs , if you have a benchmarking bam file that you can share then I can try to run it on our default model and see if it matches your expectations. However, why training didn't work would require some more investigation on how exactly you are training and preparing your data.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:122,security,model,model,122,"@bioinformaticaomicalabs , if you have a benchmarking bam file that you can share then I can try to run it on our default model and see if it matches your expectations. However, why training didn't work would require some more investigation on how exactly you are training and preparing your data.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:108,energy efficiency,current,currently,108,"@bioinformaticaomicalabs if you have GCP then that would be the best way for us. Any public bucket that you currently use to share data works for us. If the data is uploaded to SRA then you can link it to me but it might take a bit longer in that case. However you prefer, please send it to shafin@google.com",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:85,integrability,pub,public,85,"@bioinformaticaomicalabs if you have GCP then that would be the best way for us. Any public bucket that you currently use to share data works for us. If the data is uploaded to SRA then you can link it to me but it might take a bit longer in that case. However you prefer, please send it to shafin@google.com",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:125,interoperability,share,share,125,"@bioinformaticaomicalabs if you have GCP then that would be the best way for us. Any public bucket that you currently use to share data works for us. If the data is uploaded to SRA then you can link it to me but it might take a bit longer in that case. However you prefer, please send it to shafin@google.com",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:265,usability,prefer,prefer,265,"@bioinformaticaomicalabs if you have GCP then that would be the best way for us. Any public bucket that you currently use to share data works for us. If the data is uploaded to SRA then you can link it to me but it might take a bit longer in that case. However you prefer, please send it to shafin@google.com",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/869:90,usability,help,help,90,"@bioinformaticaomicalabs , closing this due to no activity. If you think you need further help, please reopen or send an email.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/869
https://github.com/google/deepvariant/issues/870:35,availability,error,error,35,"Hi Alisa,. Happy to help! From the error logs, it looks like DeepVariant is unable to parse the header of the `.bam` file. Would it be possible for you to share this bam file (or a small slice of it including the header) with us so we can take a closer look? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:187,availability,sli,slice,187,"Hi Alisa,. Happy to help! From the error logs, it looks like DeepVariant is unable to parse the header of the `.bam` file. Would it be possible for you to share this bam file (or a small slice of it including the header) with us so we can take a closer look? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:41,deployability,log,logs,41,"Hi Alisa,. Happy to help! From the error logs, it looks like DeepVariant is unable to parse the header of the `.bam` file. Would it be possible for you to share this bam file (or a small slice of it including the header) with us so we can take a closer look? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:155,interoperability,share,share,155,"Hi Alisa,. Happy to help! From the error logs, it looks like DeepVariant is unable to parse the header of the `.bam` file. Would it be possible for you to share this bam file (or a small slice of it including the header) with us so we can take a closer look? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:35,performance,error,error,35,"Hi Alisa,. Happy to help! From the error logs, it looks like DeepVariant is unable to parse the header of the `.bam` file. Would it be possible for you to share this bam file (or a small slice of it including the header) with us so we can take a closer look? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:187,reliability,sli,slice,187,"Hi Alisa,. Happy to help! From the error logs, it looks like DeepVariant is unable to parse the header of the `.bam` file. Would it be possible for you to share this bam file (or a small slice of it including the header) with us so we can take a closer look? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:35,safety,error,error,35,"Hi Alisa,. Happy to help! From the error logs, it looks like DeepVariant is unable to parse the header of the `.bam` file. Would it be possible for you to share this bam file (or a small slice of it including the header) with us so we can take a closer look? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:41,safety,log,logs,41,"Hi Alisa,. Happy to help! From the error logs, it looks like DeepVariant is unable to parse the header of the `.bam` file. Would it be possible for you to share this bam file (or a small slice of it including the header) with us so we can take a closer look? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:41,security,log,logs,41,"Hi Alisa,. Happy to help! From the error logs, it looks like DeepVariant is unable to parse the header of the `.bam` file. Would it be possible for you to share this bam file (or a small slice of it including the header) with us so we can take a closer look? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:41,testability,log,logs,41,"Hi Alisa,. Happy to help! From the error logs, it looks like DeepVariant is unable to parse the header of the `.bam` file. Would it be possible for you to share this bam file (or a small slice of it including the header) with us so we can take a closer look? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:20,usability,help,help,20,"Hi Alisa,. Happy to help! From the error logs, it looks like DeepVariant is unable to parse the header of the `.bam` file. Would it be possible for you to share this bam file (or a small slice of it including the header) with us so we can take a closer look? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:35,usability,error,error,35,"Hi Alisa,. Happy to help! From the error logs, it looks like DeepVariant is unable to parse the header of the `.bam` file. Would it be possible for you to share this bam file (or a small slice of it including the header) with us so we can take a closer look? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:246,usability,close,closer,246,"Hi Alisa,. Happy to help! From the error logs, it looks like DeepVariant is unable to parse the header of the `.bam` file. Would it be possible for you to share this bam file (or a small slice of it including the header) with us so we can take a closer look? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/870:30,usability,help,help,30,"Hi Lucas, . I appreciate your help, thanks so much. I did not know where to look.. and yes, it was the header!! My .bam file header had some german umlauts, haha. Fixed now :) . Have a great day!!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/870
https://github.com/google/deepvariant/issues/871:76,deployability,version,version,76,"@mallorygw ,. If you are using docker, the best idea is to pull an existing version (pre-built) and use that. You should be able to do that by running:. ```bash. docker pull google/deepvariant:1.6.1. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:76,integrability,version,version,76,"@mallorygw ,. If you are using docker, the best idea is to pull an existing version (pre-built) and use that. You should be able to do that by running:. ```bash. docker pull google/deepvariant:1.6.1. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:76,modifiability,version,version,76,"@mallorygw ,. If you are using docker, the best idea is to pull an existing version (pre-built) and use that. You should be able to do that by running:. ```bash. docker pull google/deepvariant:1.6.1. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:14,usability,close,close,14,I am going to close this issue for now. Please reopen if you need more help.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/871:71,usability,help,help,71,I am going to close this issue for now. Please reopen if you need more help.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/871
https://github.com/google/deepvariant/issues/872:180,deployability,releas,release-sable,180,"Hi @Axze-rgb . It's a reasonable question. We're in the process of training some non-human models using trio data and hopefully this experiment will both be positive and result in release-sable models. It's going to still take some time, but it remains an important area and one we think about.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:91,energy efficiency,model,models,91,"Hi @Axze-rgb . It's a reasonable question. We're in the process of training some non-human models using trio data and hopefully this experiment will both be positive and result in release-sable models. It's going to still take some time, but it remains an important area and one we think about.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:194,energy efficiency,model,models,194,"Hi @Axze-rgb . It's a reasonable question. We're in the process of training some non-human models using trio data and hopefully this experiment will both be positive and result in release-sable models. It's going to still take some time, but it remains an important area and one we think about.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:232,performance,time,time,232,"Hi @Axze-rgb . It's a reasonable question. We're in the process of training some non-human models using trio data and hopefully this experiment will both be positive and result in release-sable models. It's going to still take some time, but it remains an important area and one we think about.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:91,security,model,models,91,"Hi @Axze-rgb . It's a reasonable question. We're in the process of training some non-human models using trio data and hopefully this experiment will both be positive and result in release-sable models. It's going to still take some time, but it remains an important area and one we think about.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:194,security,model,models,194,"Hi @Axze-rgb . It's a reasonable question. We're in the process of training some non-human models using trio data and hopefully this experiment will both be positive and result in release-sable models. It's going to still take some time, but it remains an important area and one we think about.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:164,interoperability,specif,specific,164,"Thanks for that answer, I was also curious if you thought synthethic data could help (as in, let's simulate a whole genome from fragments we manually analysed in a specific species with high snp counts). I have no intent to do such thing, I am just curious to have your opinion on that kind of synthetic data for training. Sorry, it's really pure curiosity and not really a DeepVariant issue but I thought it could be interesting to know. Thanks a lot! . EDIT: there is still quite a lot of skepticism around those technologies, at least where I am and it's a bit tiring to always answer the question ""yes but are you sure your AI can count?"", this is the origin of my question. . EDIT 2: and yes I always have to re-specify it's not MY AI",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:717,interoperability,specif,specify,717,"Thanks for that answer, I was also curious if you thought synthethic data could help (as in, let's simulate a whole genome from fragments we manually analysed in a specific species with high snp counts). I have no intent to do such thing, I am just curious to have your opinion on that kind of synthetic data for training. Sorry, it's really pure curiosity and not really a DeepVariant issue but I thought it could be interesting to know. Thanks a lot! . EDIT: there is still quite a lot of skepticism around those technologies, at least where I am and it's a bit tiring to always answer the question ""yes but are you sure your AI can count?"", this is the origin of my question. . EDIT 2: and yes I always have to re-specify it's not MY AI",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:99,testability,simul,simulate,99,"Thanks for that answer, I was also curious if you thought synthethic data could help (as in, let's simulate a whole genome from fragments we manually analysed in a specific species with high snp counts). I have no intent to do such thing, I am just curious to have your opinion on that kind of synthetic data for training. Sorry, it's really pure curiosity and not really a DeepVariant issue but I thought it could be interesting to know. Thanks a lot! . EDIT: there is still quite a lot of skepticism around those technologies, at least where I am and it's a bit tiring to always answer the question ""yes but are you sure your AI can count?"", this is the origin of my question. . EDIT 2: and yes I always have to re-specify it's not MY AI",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:80,usability,help,help,80,"Thanks for that answer, I was also curious if you thought synthethic data could help (as in, let's simulate a whole genome from fragments we manually analysed in a specific species with high snp counts). I have no intent to do such thing, I am just curious to have your opinion on that kind of synthetic data for training. Sorry, it's really pure curiosity and not really a DeepVariant issue but I thought it could be interesting to know. Thanks a lot! . EDIT: there is still quite a lot of skepticism around those technologies, at least where I am and it's a bit tiring to always answer the question ""yes but are you sure your AI can count?"", this is the origin of my question. . EDIT 2: and yes I always have to re-specify it's not MY AI",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:151,availability,error,errors,151,"Hi @Axze-rgb . To date, I've been hesitant to include simulated data as I'm very confident that we don't know all of the diverse and complex ways that errors happen to be able to model them. To a limited extent it might be possible to supplement training, but I'm fairly pessimistic on the approach. . For the skepticism component, one of the things we try to work on is investigating explainability - cases where the ML model has learned something that might not have been immediately obvious to a human. Hopefully we'll have some things to share there soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:179,energy efficiency,model,model,179,"Hi @Axze-rgb . To date, I've been hesitant to include simulated data as I'm very confident that we don't know all of the diverse and complex ways that errors happen to be able to model them. To a limited extent it might be possible to supplement training, but I'm fairly pessimistic on the approach. . For the skepticism component, one of the things we try to work on is investigating explainability - cases where the ML model has learned something that might not have been immediately obvious to a human. Hopefully we'll have some things to share there soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:421,energy efficiency,model,model,421,"Hi @Axze-rgb . To date, I've been hesitant to include simulated data as I'm very confident that we don't know all of the diverse and complex ways that errors happen to be able to model them. To a limited extent it might be possible to supplement training, but I'm fairly pessimistic on the approach. . For the skepticism component, one of the things we try to work on is investigating explainability - cases where the ML model has learned something that might not have been immediately obvious to a human. Hopefully we'll have some things to share there soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:321,integrability,compon,component,321,"Hi @Axze-rgb . To date, I've been hesitant to include simulated data as I'm very confident that we don't know all of the diverse and complex ways that errors happen to be able to model them. To a limited extent it might be possible to supplement training, but I'm fairly pessimistic on the approach. . For the skepticism component, one of the things we try to work on is investigating explainability - cases where the ML model has learned something that might not have been immediately obvious to a human. Hopefully we'll have some things to share there soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:321,interoperability,compon,component,321,"Hi @Axze-rgb . To date, I've been hesitant to include simulated data as I'm very confident that we don't know all of the diverse and complex ways that errors happen to be able to model them. To a limited extent it might be possible to supplement training, but I'm fairly pessimistic on the approach. . For the skepticism component, one of the things we try to work on is investigating explainability - cases where the ML model has learned something that might not have been immediately obvious to a human. Hopefully we'll have some things to share there soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:542,interoperability,share,share,542,"Hi @Axze-rgb . To date, I've been hesitant to include simulated data as I'm very confident that we don't know all of the diverse and complex ways that errors happen to be able to model them. To a limited extent it might be possible to supplement training, but I'm fairly pessimistic on the approach. . For the skepticism component, one of the things we try to work on is investigating explainability - cases where the ML model has learned something that might not have been immediately obvious to a human. Hopefully we'll have some things to share there soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:204,modifiability,exten,extent,204,"Hi @Axze-rgb . To date, I've been hesitant to include simulated data as I'm very confident that we don't know all of the diverse and complex ways that errors happen to be able to model them. To a limited extent it might be possible to supplement training, but I'm fairly pessimistic on the approach. . For the skepticism component, one of the things we try to work on is investigating explainability - cases where the ML model has learned something that might not have been immediately obvious to a human. Hopefully we'll have some things to share there soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:321,modifiability,compon,component,321,"Hi @Axze-rgb . To date, I've been hesitant to include simulated data as I'm very confident that we don't know all of the diverse and complex ways that errors happen to be able to model them. To a limited extent it might be possible to supplement training, but I'm fairly pessimistic on the approach. . For the skepticism component, one of the things we try to work on is investigating explainability - cases where the ML model has learned something that might not have been immediately obvious to a human. Hopefully we'll have some things to share there soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:151,performance,error,errors,151,"Hi @Axze-rgb . To date, I've been hesitant to include simulated data as I'm very confident that we don't know all of the diverse and complex ways that errors happen to be able to model them. To a limited extent it might be possible to supplement training, but I'm fairly pessimistic on the approach. . For the skepticism component, one of the things we try to work on is investigating explainability - cases where the ML model has learned something that might not have been immediately obvious to a human. Hopefully we'll have some things to share there soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:133,safety,compl,complex,133,"Hi @Axze-rgb . To date, I've been hesitant to include simulated data as I'm very confident that we don't know all of the diverse and complex ways that errors happen to be able to model them. To a limited extent it might be possible to supplement training, but I'm fairly pessimistic on the approach. . For the skepticism component, one of the things we try to work on is investigating explainability - cases where the ML model has learned something that might not have been immediately obvious to a human. Hopefully we'll have some things to share there soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:151,safety,error,errors,151,"Hi @Axze-rgb . To date, I've been hesitant to include simulated data as I'm very confident that we don't know all of the diverse and complex ways that errors happen to be able to model them. To a limited extent it might be possible to supplement training, but I'm fairly pessimistic on the approach. . For the skepticism component, one of the things we try to work on is investigating explainability - cases where the ML model has learned something that might not have been immediately obvious to a human. Hopefully we'll have some things to share there soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:133,security,compl,complex,133,"Hi @Axze-rgb . To date, I've been hesitant to include simulated data as I'm very confident that we don't know all of the diverse and complex ways that errors happen to be able to model them. To a limited extent it might be possible to supplement training, but I'm fairly pessimistic on the approach. . For the skepticism component, one of the things we try to work on is investigating explainability - cases where the ML model has learned something that might not have been immediately obvious to a human. Hopefully we'll have some things to share there soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:179,security,model,model,179,"Hi @Axze-rgb . To date, I've been hesitant to include simulated data as I'm very confident that we don't know all of the diverse and complex ways that errors happen to be able to model them. To a limited extent it might be possible to supplement training, but I'm fairly pessimistic on the approach. . For the skepticism component, one of the things we try to work on is investigating explainability - cases where the ML model has learned something that might not have been immediately obvious to a human. Hopefully we'll have some things to share there soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:421,security,model,model,421,"Hi @Axze-rgb . To date, I've been hesitant to include simulated data as I'm very confident that we don't know all of the diverse and complex ways that errors happen to be able to model them. To a limited extent it might be possible to supplement training, but I'm fairly pessimistic on the approach. . For the skepticism component, one of the things we try to work on is investigating explainability - cases where the ML model has learned something that might not have been immediately obvious to a human. Hopefully we'll have some things to share there soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:54,testability,simul,simulated,54,"Hi @Axze-rgb . To date, I've been hesitant to include simulated data as I'm very confident that we don't know all of the diverse and complex ways that errors happen to be able to model them. To a limited extent it might be possible to supplement training, but I'm fairly pessimistic on the approach. . For the skepticism component, one of the things we try to work on is investigating explainability - cases where the ML model has learned something that might not have been immediately obvious to a human. Hopefully we'll have some things to share there soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:151,usability,error,errors,151,"Hi @Axze-rgb . To date, I've been hesitant to include simulated data as I'm very confident that we don't know all of the diverse and complex ways that errors happen to be able to model them. To a limited extent it might be possible to supplement training, but I'm fairly pessimistic on the approach. . For the skepticism component, one of the things we try to work on is investigating explainability - cases where the ML model has learned something that might not have been immediately obvious to a human. Hopefully we'll have some things to share there soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:431,usability,learn,learned,431,"Hi @Axze-rgb . To date, I've been hesitant to include simulated data as I'm very confident that we don't know all of the diverse and complex ways that errors happen to be able to model them. To a limited extent it might be possible to supplement training, but I'm fairly pessimistic on the approach. . For the skepticism component, one of the things we try to work on is investigating explainability - cases where the ML model has learned something that might not have been immediately obvious to a human. Hopefully we'll have some things to share there soon.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:911,deployability,pipelin,pipeline,911,"Sorry to answer that late, I am extremely happy to read this and about the complexity of the problem. How many times have I heard ""just lowered the gap penalty"" or ""just increase the score for a mismatch"". While well-meaning, those didn't help me. I have arrived to a point when I am even doubting the validity of the whole field outside of human. Let's make an MA of Daphnia. Then let's ask another team to repeat exactly the experiment. Are you confident you will get the same kind of value? I realise I am absolutely not sure... Sorry I digress. But I am happy because you are a caller developer, which I am not, and you write exactly all the issues I have with the field. I think the complexity of variant calling is vastly underestimated. And many forget that it's not because a program keeps giving you the same answer, that it's correct. Anyway on my side I also have a totally different approach in the pipeline and I would be very excited to compare with yours. Cheers",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:911,integrability,pipelin,pipeline,911,"Sorry to answer that late, I am extremely happy to read this and about the complexity of the problem. How many times have I heard ""just lowered the gap penalty"" or ""just increase the score for a mismatch"". While well-meaning, those didn't help me. I have arrived to a point when I am even doubting the validity of the whole field outside of human. Let's make an MA of Daphnia. Then let's ask another team to repeat exactly the experiment. Are you confident you will get the same kind of value? I realise I am absolutely not sure... Sorry I digress. But I am happy because you are a caller developer, which I am not, and you write exactly all the issues I have with the field. I think the complexity of variant calling is vastly underestimated. And many forget that it's not because a program keeps giving you the same answer, that it's correct. Anyway on my side I also have a totally different approach in the pipeline and I would be very excited to compare with yours. Cheers",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:195,interoperability,mismatch,mismatch,195,"Sorry to answer that late, I am extremely happy to read this and about the complexity of the problem. How many times have I heard ""just lowered the gap penalty"" or ""just increase the score for a mismatch"". While well-meaning, those didn't help me. I have arrived to a point when I am even doubting the validity of the whole field outside of human. Let's make an MA of Daphnia. Then let's ask another team to repeat exactly the experiment. Are you confident you will get the same kind of value? I realise I am absolutely not sure... Sorry I digress. But I am happy because you are a caller developer, which I am not, and you write exactly all the issues I have with the field. I think the complexity of variant calling is vastly underestimated. And many forget that it's not because a program keeps giving you the same answer, that it's correct. Anyway on my side I also have a totally different approach in the pipeline and I would be very excited to compare with yours. Cheers",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:111,performance,time,times,111,"Sorry to answer that late, I am extremely happy to read this and about the complexity of the problem. How many times have I heard ""just lowered the gap penalty"" or ""just increase the score for a mismatch"". While well-meaning, those didn't help me. I have arrived to a point when I am even doubting the validity of the whole field outside of human. Let's make an MA of Daphnia. Then let's ask another team to repeat exactly the experiment. Are you confident you will get the same kind of value? I realise I am absolutely not sure... Sorry I digress. But I am happy because you are a caller developer, which I am not, and you write exactly all the issues I have with the field. I think the complexity of variant calling is vastly underestimated. And many forget that it's not because a program keeps giving you the same answer, that it's correct. Anyway on my side I also have a totally different approach in the pipeline and I would be very excited to compare with yours. Cheers",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:75,safety,compl,complexity,75,"Sorry to answer that late, I am extremely happy to read this and about the complexity of the problem. How many times have I heard ""just lowered the gap penalty"" or ""just increase the score for a mismatch"". While well-meaning, those didn't help me. I have arrived to a point when I am even doubting the validity of the whole field outside of human. Let's make an MA of Daphnia. Then let's ask another team to repeat exactly the experiment. Are you confident you will get the same kind of value? I realise I am absolutely not sure... Sorry I digress. But I am happy because you are a caller developer, which I am not, and you write exactly all the issues I have with the field. I think the complexity of variant calling is vastly underestimated. And many forget that it's not because a program keeps giving you the same answer, that it's correct. Anyway on my side I also have a totally different approach in the pipeline and I would be very excited to compare with yours. Cheers",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:302,safety,valid,validity,302,"Sorry to answer that late, I am extremely happy to read this and about the complexity of the problem. How many times have I heard ""just lowered the gap penalty"" or ""just increase the score for a mismatch"". While well-meaning, those didn't help me. I have arrived to a point when I am even doubting the validity of the whole field outside of human. Let's make an MA of Daphnia. Then let's ask another team to repeat exactly the experiment. Are you confident you will get the same kind of value? I realise I am absolutely not sure... Sorry I digress. But I am happy because you are a caller developer, which I am not, and you write exactly all the issues I have with the field. I think the complexity of variant calling is vastly underestimated. And many forget that it's not because a program keeps giving you the same answer, that it's correct. Anyway on my side I also have a totally different approach in the pipeline and I would be very excited to compare with yours. Cheers",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:688,safety,compl,complexity,688,"Sorry to answer that late, I am extremely happy to read this and about the complexity of the problem. How many times have I heard ""just lowered the gap penalty"" or ""just increase the score for a mismatch"". While well-meaning, those didn't help me. I have arrived to a point when I am even doubting the validity of the whole field outside of human. Let's make an MA of Daphnia. Then let's ask another team to repeat exactly the experiment. Are you confident you will get the same kind of value? I realise I am absolutely not sure... Sorry I digress. But I am happy because you are a caller developer, which I am not, and you write exactly all the issues I have with the field. I think the complexity of variant calling is vastly underestimated. And many forget that it's not because a program keeps giving you the same answer, that it's correct. Anyway on my side I also have a totally different approach in the pipeline and I would be very excited to compare with yours. Cheers",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:75,security,compl,complexity,75,"Sorry to answer that late, I am extremely happy to read this and about the complexity of the problem. How many times have I heard ""just lowered the gap penalty"" or ""just increase the score for a mismatch"". While well-meaning, those didn't help me. I have arrived to a point when I am even doubting the validity of the whole field outside of human. Let's make an MA of Daphnia. Then let's ask another team to repeat exactly the experiment. Are you confident you will get the same kind of value? I realise I am absolutely not sure... Sorry I digress. But I am happy because you are a caller developer, which I am not, and you write exactly all the issues I have with the field. I think the complexity of variant calling is vastly underestimated. And many forget that it's not because a program keeps giving you the same answer, that it's correct. Anyway on my side I also have a totally different approach in the pipeline and I would be very excited to compare with yours. Cheers",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:400,security,team,team,400,"Sorry to answer that late, I am extremely happy to read this and about the complexity of the problem. How many times have I heard ""just lowered the gap penalty"" or ""just increase the score for a mismatch"". While well-meaning, those didn't help me. I have arrived to a point when I am even doubting the validity of the whole field outside of human. Let's make an MA of Daphnia. Then let's ask another team to repeat exactly the experiment. Are you confident you will get the same kind of value? I realise I am absolutely not sure... Sorry I digress. But I am happy because you are a caller developer, which I am not, and you write exactly all the issues I have with the field. I think the complexity of variant calling is vastly underestimated. And many forget that it's not because a program keeps giving you the same answer, that it's correct. Anyway on my side I also have a totally different approach in the pipeline and I would be very excited to compare with yours. Cheers",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:688,security,compl,complexity,688,"Sorry to answer that late, I am extremely happy to read this and about the complexity of the problem. How many times have I heard ""just lowered the gap penalty"" or ""just increase the score for a mismatch"". While well-meaning, those didn't help me. I have arrived to a point when I am even doubting the validity of the whole field outside of human. Let's make an MA of Daphnia. Then let's ask another team to repeat exactly the experiment. Are you confident you will get the same kind of value? I realise I am absolutely not sure... Sorry I digress. But I am happy because you are a caller developer, which I am not, and you write exactly all the issues I have with the field. I think the complexity of variant calling is vastly underestimated. And many forget that it's not because a program keeps giving you the same answer, that it's correct. Anyway on my side I also have a totally different approach in the pipeline and I would be very excited to compare with yours. Cheers",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/872:239,usability,help,help,239,"Sorry to answer that late, I am extremely happy to read this and about the complexity of the problem. How many times have I heard ""just lowered the gap penalty"" or ""just increase the score for a mismatch"". While well-meaning, those didn't help me. I have arrived to a point when I am even doubting the validity of the whole field outside of human. Let's make an MA of Daphnia. Then let's ask another team to repeat exactly the experiment. Are you confident you will get the same kind of value? I realise I am absolutely not sure... Sorry I digress. But I am happy because you are a caller developer, which I am not, and you write exactly all the issues I have with the field. I think the complexity of variant calling is vastly underestimated. And many forget that it's not because a program keeps giving you the same answer, that it's correct. Anyway on my side I also have a totally different approach in the pipeline and I would be very excited to compare with yours. Cheers",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/872
https://github.com/google/deepvariant/issues/873:613,energy efficiency,GPU,GPU,613,"@weiranmmm haha, I half jokingly thought ""I hope DeepTrio doesn't get them into deep trouble"". Good to know DeepTrio de novo analysis is working well for you. Anyways, you can run each step of DeepTrio separately. For that, please set:. ```. --intermediate_results_dir=${OUTPUT_DIR}/intermediate_files. ```. And then, if you run your command using:. ```bash. --dry_run=true. ```. Then you should be able to see the three commands (`make_examples`, `call_variants`, `postprocess_variants`) separately. You can copy the commands and run them one after another instead of running ""run_deeptrio"" and can only ask for GPU for the `call_variants` part. Let me know if you need further instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:613,performance,GPU,GPU,613,"@weiranmmm haha, I half jokingly thought ""I hope DeepTrio doesn't get them into deep trouble"". Good to know DeepTrio de novo analysis is working well for you. Anyways, you can run each step of DeepTrio separately. For that, please set:. ```. --intermediate_results_dir=${OUTPUT_DIR}/intermediate_files. ```. And then, if you run your command using:. ```bash. --dry_run=true. ```. Then you should be able to see the three commands (`make_examples`, `call_variants`, `postprocess_variants`) separately. You can copy the commands and run them one after another instead of running ""run_deeptrio"" and can only ask for GPU for the `call_variants` part. Let me know if you need further instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:58,reliability,doe,doesn,58,"@weiranmmm haha, I half jokingly thought ""I hope DeepTrio doesn't get them into deep trouble"". Good to know DeepTrio de novo analysis is working well for you. Anyways, you can run each step of DeepTrio separately. For that, please set:. ```. --intermediate_results_dir=${OUTPUT_DIR}/intermediate_files. ```. And then, if you run your command using:. ```bash. --dry_run=true. ```. Then you should be able to see the three commands (`make_examples`, `call_variants`, `postprocess_variants`) separately. You can copy the commands and run them one after another instead of running ""run_deeptrio"" and can only ask for GPU for the `call_variants` part. Let me know if you need further instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:334,usability,command,command,334,"@weiranmmm haha, I half jokingly thought ""I hope DeepTrio doesn't get them into deep trouble"". Good to know DeepTrio de novo analysis is working well for you. Anyways, you can run each step of DeepTrio separately. For that, please set:. ```. --intermediate_results_dir=${OUTPUT_DIR}/intermediate_files. ```. And then, if you run your command using:. ```bash. --dry_run=true. ```. Then you should be able to see the three commands (`make_examples`, `call_variants`, `postprocess_variants`) separately. You can copy the commands and run them one after another instead of running ""run_deeptrio"" and can only ask for GPU for the `call_variants` part. Let me know if you need further instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:421,usability,command,commands,421,"@weiranmmm haha, I half jokingly thought ""I hope DeepTrio doesn't get them into deep trouble"". Good to know DeepTrio de novo analysis is working well for you. Anyways, you can run each step of DeepTrio separately. For that, please set:. ```. --intermediate_results_dir=${OUTPUT_DIR}/intermediate_files. ```. And then, if you run your command using:. ```bash. --dry_run=true. ```. Then you should be able to see the three commands (`make_examples`, `call_variants`, `postprocess_variants`) separately. You can copy the commands and run them one after another instead of running ""run_deeptrio"" and can only ask for GPU for the `call_variants` part. Let me know if you need further instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:518,usability,command,commands,518,"@weiranmmm haha, I half jokingly thought ""I hope DeepTrio doesn't get them into deep trouble"". Good to know DeepTrio de novo analysis is working well for you. Anyways, you can run each step of DeepTrio separately. For that, please set:. ```. --intermediate_results_dir=${OUTPUT_DIR}/intermediate_files. ```. And then, if you run your command using:. ```bash. --dry_run=true. ```. Then you should be able to see the three commands (`make_examples`, `call_variants`, `postprocess_variants`) separately. You can copy the commands and run them one after another instead of running ""run_deeptrio"" and can only ask for GPU for the `call_variants` part. Let me know if you need further instructions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:23,usability,command,commands,23,"@kishwarshafin . These commands have been really helpful to me, and I can't wait to try them out. . Thank you so much for your suggestions!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/873:49,usability,help,helpful,49,"@kishwarshafin . These commands have been really helpful to me, and I can't wait to try them out. . Thank you so much for your suggestions!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/873
https://github.com/google/deepvariant/issues/874:83,energy efficiency,model,models,83,"@DineshRavindraRaju, DeepVariant is a small variant caller and we do not train our models against the SV truth set. Generally SVs are defined to be variants that are 50bp+, so DeepVariant will not identify those. However, the INDEL length limit for DeepVariant is 50bp, so you can potentially see some variants called upto that range.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/874
https://github.com/google/deepvariant/issues/874:83,security,model,models,83,"@DineshRavindraRaju, DeepVariant is a small variant caller and we do not train our models against the SV truth set. Generally SVs are defined to be variants that are 50bp+, so DeepVariant will not identify those. However, the INDEL length limit for DeepVariant is 50bp, so you can potentially see some variants called upto that range.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/874
https://github.com/google/deepvariant/issues/874:197,security,ident,identify,197,"@DineshRavindraRaju, DeepVariant is a small variant caller and we do not train our models against the SV truth set. Generally SVs are defined to be variants that are 50bp+, so DeepVariant will not identify those. However, the INDEL length limit for DeepVariant is 50bp, so you can potentially see some variants called upto that range.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/874
https://github.com/google/deepvariant/issues/875:147,deployability,releas,release,147,"hi @sounkou-bioinfo,. Thank you for bringing up this issue. We have not worked on this specifically but I will try to give this a shot in our next release. It's a reasonable request and we may have the right logics to fix this in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/875
https://github.com/google/deepvariant/issues/875:208,deployability,log,logics,208,"hi @sounkou-bioinfo,. Thank you for bringing up this issue. We have not worked on this specifically but I will try to give this a shot in our next release. It's a reasonable request and we may have the right logics to fix this in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/875
https://github.com/google/deepvariant/issues/875:239,deployability,releas,release,239,"hi @sounkou-bioinfo,. Thank you for bringing up this issue. We have not worked on this specifically but I will try to give this a shot in our next release. It's a reasonable request and we may have the right logics to fix this in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/875
https://github.com/google/deepvariant/issues/875:87,interoperability,specif,specifically,87,"hi @sounkou-bioinfo,. Thank you for bringing up this issue. We have not worked on this specifically but I will try to give this a shot in our next release. It's a reasonable request and we may have the right logics to fix this in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/875
https://github.com/google/deepvariant/issues/875:208,safety,log,logics,208,"hi @sounkou-bioinfo,. Thank you for bringing up this issue. We have not worked on this specifically but I will try to give this a shot in our next release. It's a reasonable request and we may have the right logics to fix this in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/875
https://github.com/google/deepvariant/issues/875:208,security,log,logics,208,"hi @sounkou-bioinfo,. Thank you for bringing up this issue. We have not worked on this specifically but I will try to give this a shot in our next release. It's a reasonable request and we may have the right logics to fix this in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/875
https://github.com/google/deepvariant/issues/875:208,testability,log,logics,208,"hi @sounkou-bioinfo,. Thank you for bringing up this issue. We have not worked on this specifically but I will try to give this a shot in our next release. It's a reasonable request and we may have the right logics to fix this in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/875
https://github.com/google/deepvariant/issues/875:89,deployability,releas,release,89,"Thank you for this response dear @kishwarshafin,. Will be looking forward for the coming release. Cheers",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/875
https://github.com/google/deepvariant/issues/876:282,performance,tune,tune,282,"Hi @DanJeffries ,. Can you please paste the output for the following command here:. ```bash. cat /home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt. ```. and also separately run the following and paste the output:. ```bash. cat /home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:69,usability,command,command,69,"Hi @DanJeffries ,. Can you please paste the output for the following command here:. ```bash. cat /home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt. ```. and also separately run the following and paste the output:. ```bash. cat /home/examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:200,availability,cluster,cluster,200,"Hi @kishwarshafin ,. Sure. Just a quick note first to explain the outputs, and maybe its relevant to the problem. Given the number of examples I couldn't easily perform the shuffling step on my local cluster (using DirectRunner) due to memory and wall time limits. So I performed a 2-step shuffle. I.e. I split the examples in half (parts 1 and 2), shuffled each half, then randomly split the outputs from each of the first shuffles into two halves (parts 3 and 4) and ran a second round of shuffling. . I then edited the path in the pbtxt file to accommodate all file names. So `All_samples_training_examples.dataset_config.pbtxt` now contains the following:. ```. > cat /home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt. # Generated by shuffle_tfrecords_beam.py. # class0: 1454377. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt?-?????-of-?????.tfrecord.gz"". num_examples: 1454377. #name: ""Shuffle_global"". #tfrecord_path: ""/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt3-?????-of-?????.tfrecord.gz"". #num_examples: 727189. #. # --input_pattern_list=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_inputs/All_samples_all_training_examples_inc_downsampled_05_pt3.shuffled-000*-of-00020.tfrecord.gz. # --output_pattern_prefix=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt3. #. # Generated by shuffle_tfrecords_beam.py. #name: ""Shuffle_global"". #tfrecord_path: ""/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:200,deployability,cluster,cluster,200,"Hi @kishwarshafin ,. Sure. Just a quick note first to explain the outputs, and maybe its relevant to the problem. Given the number of examples I couldn't easily perform the shuffling step on my local cluster (using DirectRunner) due to memory and wall time limits. So I performed a 2-step shuffle. I.e. I split the examples in half (parts 1 and 2), shuffled each half, then randomly split the outputs from each of the first shuffles into two halves (parts 3 and 4) and ran a second round of shuffling. . I then edited the path in the pbtxt file to accommodate all file names. So `All_samples_training_examples.dataset_config.pbtxt` now contains the following:. ```. > cat /home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt. # Generated by shuffle_tfrecords_beam.py. # class0: 1454377. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt?-?????-of-?????.tfrecord.gz"". num_examples: 1454377. #name: ""Shuffle_global"". #tfrecord_path: ""/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt3-?????-of-?????.tfrecord.gz"". #num_examples: 727189. #. # --input_pattern_list=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_inputs/All_samples_all_training_examples_inc_downsampled_05_pt3.shuffled-000*-of-00020.tfrecord.gz. # --output_pattern_prefix=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt3. #. # Generated by shuffle_tfrecords_beam.py. #name: ""Shuffle_global"". #tfrecord_path: ""/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:636,deployability,contain,contains,636,"Hi @kishwarshafin ,. Sure. Just a quick note first to explain the outputs, and maybe its relevant to the problem. Given the number of examples I couldn't easily perform the shuffling step on my local cluster (using DirectRunner) due to memory and wall time limits. So I performed a 2-step shuffle. I.e. I split the examples in half (parts 1 and 2), shuffled each half, then randomly split the outputs from each of the first shuffles into two halves (parts 3 and 4) and ran a second round of shuffling. . I then edited the path in the pbtxt file to accommodate all file names. So `All_samples_training_examples.dataset_config.pbtxt` now contains the following:. ```. > cat /home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt. # Generated by shuffle_tfrecords_beam.py. # class0: 1454377. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt?-?????-of-?????.tfrecord.gz"". num_examples: 1454377. #name: ""Shuffle_global"". #tfrecord_path: ""/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt3-?????-of-?????.tfrecord.gz"". #num_examples: 727189. #. # --input_pattern_list=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_inputs/All_samples_all_training_examples_inc_downsampled_05_pt3.shuffled-000*-of-00020.tfrecord.gz. # --output_pattern_prefix=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt3. #. # Generated by shuffle_tfrecords_beam.py. #name: ""Shuffle_global"". #tfrecord_path: ""/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:161,performance,perform,perform,161,"Hi @kishwarshafin ,. Sure. Just a quick note first to explain the outputs, and maybe its relevant to the problem. Given the number of examples I couldn't easily perform the shuffling step on my local cluster (using DirectRunner) due to memory and wall time limits. So I performed a 2-step shuffle. I.e. I split the examples in half (parts 1 and 2), shuffled each half, then randomly split the outputs from each of the first shuffles into two halves (parts 3 and 4) and ran a second round of shuffling. . I then edited the path in the pbtxt file to accommodate all file names. So `All_samples_training_examples.dataset_config.pbtxt` now contains the following:. ```. > cat /home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt. # Generated by shuffle_tfrecords_beam.py. # class0: 1454377. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt?-?????-of-?????.tfrecord.gz"". num_examples: 1454377. #name: ""Shuffle_global"". #tfrecord_path: ""/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt3-?????-of-?????.tfrecord.gz"". #num_examples: 727189. #. # --input_pattern_list=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_inputs/All_samples_all_training_examples_inc_downsampled_05_pt3.shuffled-000*-of-00020.tfrecord.gz. # --output_pattern_prefix=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt3. #. # Generated by shuffle_tfrecords_beam.py. #name: ""Shuffle_global"". #tfrecord_path: ""/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:236,performance,memor,memory,236,"Hi @kishwarshafin ,. Sure. Just a quick note first to explain the outputs, and maybe its relevant to the problem. Given the number of examples I couldn't easily perform the shuffling step on my local cluster (using DirectRunner) due to memory and wall time limits. So I performed a 2-step shuffle. I.e. I split the examples in half (parts 1 and 2), shuffled each half, then randomly split the outputs from each of the first shuffles into two halves (parts 3 and 4) and ran a second round of shuffling. . I then edited the path in the pbtxt file to accommodate all file names. So `All_samples_training_examples.dataset_config.pbtxt` now contains the following:. ```. > cat /home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt. # Generated by shuffle_tfrecords_beam.py. # class0: 1454377. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt?-?????-of-?????.tfrecord.gz"". num_examples: 1454377. #name: ""Shuffle_global"". #tfrecord_path: ""/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt3-?????-of-?????.tfrecord.gz"". #num_examples: 727189. #. # --input_pattern_list=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_inputs/All_samples_all_training_examples_inc_downsampled_05_pt3.shuffled-000*-of-00020.tfrecord.gz. # --output_pattern_prefix=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt3. #. # Generated by shuffle_tfrecords_beam.py. #name: ""Shuffle_global"". #tfrecord_path: ""/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:252,performance,time,time,252,"Hi @kishwarshafin ,. Sure. Just a quick note first to explain the outputs, and maybe its relevant to the problem. Given the number of examples I couldn't easily perform the shuffling step on my local cluster (using DirectRunner) due to memory and wall time limits. So I performed a 2-step shuffle. I.e. I split the examples in half (parts 1 and 2), shuffled each half, then randomly split the outputs from each of the first shuffles into two halves (parts 3 and 4) and ran a second round of shuffling. . I then edited the path in the pbtxt file to accommodate all file names. So `All_samples_training_examples.dataset_config.pbtxt` now contains the following:. ```. > cat /home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt. # Generated by shuffle_tfrecords_beam.py. # class0: 1454377. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt?-?????-of-?????.tfrecord.gz"". num_examples: 1454377. #name: ""Shuffle_global"". #tfrecord_path: ""/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt3-?????-of-?????.tfrecord.gz"". #num_examples: 727189. #. # --input_pattern_list=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_inputs/All_samples_all_training_examples_inc_downsampled_05_pt3.shuffled-000*-of-00020.tfrecord.gz. # --output_pattern_prefix=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt3. #. # Generated by shuffle_tfrecords_beam.py. #name: ""Shuffle_global"". #tfrecord_path: ""/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:270,performance,perform,performed,270,"Hi @kishwarshafin ,. Sure. Just a quick note first to explain the outputs, and maybe its relevant to the problem. Given the number of examples I couldn't easily perform the shuffling step on my local cluster (using DirectRunner) due to memory and wall time limits. So I performed a 2-step shuffle. I.e. I split the examples in half (parts 1 and 2), shuffled each half, then randomly split the outputs from each of the first shuffles into two halves (parts 3 and 4) and ran a second round of shuffling. . I then edited the path in the pbtxt file to accommodate all file names. So `All_samples_training_examples.dataset_config.pbtxt` now contains the following:. ```. > cat /home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt. # Generated by shuffle_tfrecords_beam.py. # class0: 1454377. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt?-?????-of-?????.tfrecord.gz"". num_examples: 1454377. #name: ""Shuffle_global"". #tfrecord_path: ""/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt3-?????-of-?????.tfrecord.gz"". #num_examples: 727189. #. # --input_pattern_list=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_inputs/All_samples_all_training_examples_inc_downsampled_05_pt3.shuffled-000*-of-00020.tfrecord.gz. # --output_pattern_prefix=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt3. #. # Generated by shuffle_tfrecords_beam.py. #name: ""Shuffle_global"". #tfrecord_path: ""/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:8544,performance,tune,tune,8544,"nsampled_05.shuffle_2_pt4-00013-of-00020.tfrecord.gz. ./examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt4-00014-of-00020.tfrecord.gz. ./examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt4-00015-of-00020.tfrecord.gz. ./examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt4-00016-of-00020.tfrecord.gz. ./examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt4-00017-of-00020.tfrecord.gz. ./examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt4-00018-of-00020.tfrecord.gz. ./examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt4-00019-of-00020.tfrecord.gz. ```. And for the tuning set (which was shuffled normally using just one step):. ```. >cat ./examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt. # Generated by shuffle_tfrecords_beam.py. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 202421. # class0: 202421. #. # --input_pattern_list=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training//examples/tune_all/*tune_examples*tfrecord-000*-of-00040. # --output_pattern_prefix=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training//examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled. #. ```. and . ```. ls /home/examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-?????-of-?????.tfrecord.gz. ```. gives the desired file list again:. ```. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00000-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:8703,performance,tune,tune,8703,"2_pt4-00014-of-00020.tfrecord.gz. ./examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt4-00015-of-00020.tfrecord.gz. ./examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt4-00016-of-00020.tfrecord.gz. ./examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt4-00017-of-00020.tfrecord.gz. ./examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt4-00018-of-00020.tfrecord.gz. ./examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt4-00019-of-00020.tfrecord.gz. ```. And for the tuning set (which was shuffled normally using just one step):. ```. >cat ./examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt. # Generated by shuffle_tfrecords_beam.py. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 202421. # class0: 202421. #. # --input_pattern_list=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training//examples/tune_all/*tune_examples*tfrecord-000*-of-00040. # --output_pattern_prefix=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training//examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled. #. ```. and . ```. ls /home/examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-?????-of-?????.tfrecord.gz. ```. gives the desired file list again:. ```. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00000-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00001-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00002-of-00020.tfrecord.gz. ./examples_sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:9112,performance,tune,tune,9112,"shuffle_2_pt4-00017-of-00020.tfrecord.gz. ./examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt4-00018-of-00020.tfrecord.gz. ./examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt4-00019-of-00020.tfrecord.gz. ```. And for the tuning set (which was shuffled normally using just one step):. ```. >cat ./examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt. # Generated by shuffle_tfrecords_beam.py. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 202421. # class0: 202421. #. # --input_pattern_list=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training//examples/tune_all/*tune_examples*tfrecord-000*-of-00040. # --output_pattern_prefix=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training//examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled. #. ```. and . ```. ls /home/examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-?????-of-?????.tfrecord.gz. ```. gives the desired file list again:. ```. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00000-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00001-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00002-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00003-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00004-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00005-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00006-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:9222,performance,tune,tune,9222,"_examples_inc_downsampled_05.shuffle_2_pt4-00018-of-00020.tfrecord.gz. ./examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt4-00019-of-00020.tfrecord.gz. ```. And for the tuning set (which was shuffled normally using just one step):. ```. >cat ./examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt. # Generated by shuffle_tfrecords_beam.py. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 202421. # class0: 202421. #. # --input_pattern_list=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training//examples/tune_all/*tune_examples*tfrecord-000*-of-00040. # --output_pattern_prefix=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training//examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled. #. ```. and . ```. ls /home/examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-?????-of-?????.tfrecord.gz. ```. gives the desired file list again:. ```. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00000-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00001-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00002-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00003-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00004-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00005-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00006-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00007",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:9379,performance,tune,tune,9379,"sampled_05.shuffle_2_pt4-00019-of-00020.tfrecord.gz. ```. And for the tuning set (which was shuffled normally using just one step):. ```. >cat ./examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt. # Generated by shuffle_tfrecords_beam.py. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 202421. # class0: 202421. #. # --input_pattern_list=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training//examples/tune_all/*tune_examples*tfrecord-000*-of-00040. # --output_pattern_prefix=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training//examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled. #. ```. and . ```. ls /home/examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-?????-of-?????.tfrecord.gz. ```. gives the desired file list again:. ```. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00000-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00001-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00002-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00003-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00004-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00005-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00006-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00007-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00008-of-00020.tfrecord.gz. ./examples_shuffled/tun",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:9490,performance,tune,tune,9490,"sing just one step):. ```. >cat ./examples_shuffled/tune/All_samples_tune_examples.dataset_config.pbtxt. # Generated by shuffle_tfrecords_beam.py. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 202421. # class0: 202421. #. # --input_pattern_list=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training//examples/tune_all/*tune_examples*tfrecord-000*-of-00040. # --output_pattern_prefix=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training//examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled. #. ```. and . ```. ls /home/examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-?????-of-?????.tfrecord.gz. ```. gives the desired file list again:. ```. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00000-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00001-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00002-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00003-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00004-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00005-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00006-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00007-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00008-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00009-of-00020.tfrecord.gz. ./examples_shuffled/tun",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:9601,performance,tune,tune,9601,"rated by shuffle_tfrecords_beam.py. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 202421. # class0: 202421. #. # --input_pattern_list=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training//examples/tune_all/*tune_examples*tfrecord-000*-of-00040. # --output_pattern_prefix=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training//examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled. #. ```. and . ```. ls /home/examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-?????-of-?????.tfrecord.gz. ```. gives the desired file list again:. ```. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00000-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00001-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00002-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00003-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00004-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00005-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00006-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00007-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00008-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00009-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00010-of-00020.tfrecord.gz. ./examples_shuffled/tun",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:9712,performance,tune,tune,9712,"mples_all_tune_examples_inc_downsampled_05.shuffled-?????-of-?????.tfrecord.gz"". num_examples: 202421. # class0: 202421. #. # --input_pattern_list=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training//examples/tune_all/*tune_examples*tfrecord-000*-of-00040. # --output_pattern_prefix=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training//examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled. #. ```. and . ```. ls /home/examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-?????-of-?????.tfrecord.gz. ```. gives the desired file list again:. ```. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00000-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00001-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00002-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00003-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00004-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00005-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00006-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00007-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00008-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00009-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00010-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00011-of-00020.tfrecord.gz. ./examples_shuffled/tun",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:9823,performance,tune,tune,9823,: 202421. #. # --input_pattern_list=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training//examples/tune_all/*tune_examples*tfrecord-000*-of-00040. # --output_pattern_prefix=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training//examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled. #. ```. and . ```. ls /home/examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-?????-of-?????.tfrecord.gz. ```. gives the desired file list again:. ```. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00000-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00001-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00002-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00003-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00004-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00005-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00006-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00007-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00008-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00009-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00010-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00011-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00012-of-00020.tfrecord.gz. ./examples_shuffled/tun,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:9934,performance,tune,tune,9934,examples/tune_all/*tune_examples*tfrecord-000*-of-00040. # --output_pattern_prefix=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training//examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled. #. ```. and . ```. ls /home/examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-?????-of-?????.tfrecord.gz. ```. gives the desired file list again:. ```. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00000-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00001-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00002-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00003-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00004-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00005-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00006-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00007-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00008-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00009-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00010-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00011-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00012-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00013-of-00020.tfrecord.gz. ./examples_shuffled/tun,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:10045,performance,tune,tune,10045,1/Stickleback/G_aculeatus/FITNESS/DV_training//examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled. #. ```. and . ```. ls /home/examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-?????-of-?????.tfrecord.gz. ```. gives the desired file list again:. ```. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00000-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00001-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00002-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00003-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00004-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00005-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00006-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00007-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00008-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00009-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00010-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00011-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00012-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00013-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00014-of-00020.tfrecord.gz. ./examples_shuffled/tun,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:10156,performance,tune,tune,10156,pled_05.shuffled. #. ```. and . ```. ls /home/examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-?????-of-?????.tfrecord.gz. ```. gives the desired file list again:. ```. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00000-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00001-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00002-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00003-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00004-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00005-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00006-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00007-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00008-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00009-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00010-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00011-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00012-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00013-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00014-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00015-of-00020.tfrecord.gz. ./examples_shuffled/tun,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:10267,performance,tune,tune,10267,led_05.shuffled-?????-of-?????.tfrecord.gz. ```. gives the desired file list again:. ```. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00000-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00001-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00002-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00003-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00004-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00005-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00006-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00007-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00008-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00009-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00010-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00011-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00012-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00013-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00014-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00015-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00016-of-00020.tfrecord.gz. ./examples_shuffled/tun,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:10378,performance,tune,tune,10378,une/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00000-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00001-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00002-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00003-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00004-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00005-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00006-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00007-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00008-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00009-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00010-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00011-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00012-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00013-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00014-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00015-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00016-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00017-of-00020.tfrecord.gz. ./examples_shuffled/tun,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:10489,performance,tune,tune,10489,une/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00001-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00002-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00003-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00004-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00005-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00006-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00007-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00008-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00009-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00010-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00011-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00012-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00013-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00014-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00015-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00016-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00017-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00018-of-00020.tfrecord.gz. ./examples_shuffled/tun,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:10600,performance,tune,tune,10600,une/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00002-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00003-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00004-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00005-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00006-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00007-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00008-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00009-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00010-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00011-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00012-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00013-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00014-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00015-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00016-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00017-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00018-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00019-of-00020.tfrecord.gz. ```. Hope thats useful!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:10711,performance,tune,tune,10711,e/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00002-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00003-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00004-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00005-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00006-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00007-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00008-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00009-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00010-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00011-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00012-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00013-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00014-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00015-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00016-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00017-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00018-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00019-of-00020.tfrecord.gz. ```. Hope thats useful! .,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:10822,performance,tune,tune,10822,e/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00002-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00003-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00004-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00005-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00006-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00007-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00008-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00009-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00010-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00011-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00012-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00013-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00014-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00015-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00016-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00017-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00018-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00019-of-00020.tfrecord.gz. ```. Hope thats useful! .,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:10933,performance,tune,tune,10933,e/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00002-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00003-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00004-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00005-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00006-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00007-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00008-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00009-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00010-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00011-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00012-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00013-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00014-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00015-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00016-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00017-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00018-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00019-of-00020.tfrecord.gz. ```. Hope thats useful! .,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:11044,performance,tune,tune,11044,e/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00002-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00003-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00004-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00005-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00006-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00007-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00008-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00009-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00010-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00011-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00012-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00013-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00014-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00015-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00016-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00017-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00018-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00019-of-00020.tfrecord.gz. ```. Hope thats useful! .,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:11155,performance,tune,tune,11155,e/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00002-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00003-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00004-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00005-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00006-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00007-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00008-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00009-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00010-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00011-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00012-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00013-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00014-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00015-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00016-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00017-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00018-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00019-of-00020.tfrecord.gz. ```. Hope thats useful! .,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:11266,performance,tune,tune,11266,e/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00002-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00003-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00004-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00005-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00006-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00007-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00008-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00009-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00010-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00011-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00012-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00013-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00014-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00015-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00016-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00017-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00018-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00019-of-00020.tfrecord.gz. ```. Hope thats useful! .,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:11377,performance,tune,tune,11377,e/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00002-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00003-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00004-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00005-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00006-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00007-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00008-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00009-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00010-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00011-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00012-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00013-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00014-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00015-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00016-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00017-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00018-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00019-of-00020.tfrecord.gz. ```. Hope thats useful! .,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:11488,performance,tune,tune,11488,e/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00002-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00003-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00004-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00005-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00006-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00007-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00008-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00009-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00010-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00011-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00012-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00013-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00014-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00015-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00016-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00017-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00018-of-00020.tfrecord.gz. ./examples_shuffled/tune/All_samples_all_tune_examples_inc_downsampled_05.shuffled-00019-of-00020.tfrecord.gz. ```. Hope thats useful! .,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:161,usability,perform,perform,161,"Hi @kishwarshafin ,. Sure. Just a quick note first to explain the outputs, and maybe its relevant to the problem. Given the number of examples I couldn't easily perform the shuffling step on my local cluster (using DirectRunner) due to memory and wall time limits. So I performed a 2-step shuffle. I.e. I split the examples in half (parts 1 and 2), shuffled each half, then randomly split the outputs from each of the first shuffles into two halves (parts 3 and 4) and ran a second round of shuffling. . I then edited the path in the pbtxt file to accommodate all file names. So `All_samples_training_examples.dataset_config.pbtxt` now contains the following:. ```. > cat /home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt. # Generated by shuffle_tfrecords_beam.py. # class0: 1454377. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt?-?????-of-?????.tfrecord.gz"". num_examples: 1454377. #name: ""Shuffle_global"". #tfrecord_path: ""/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt3-?????-of-?????.tfrecord.gz"". #num_examples: 727189. #. # --input_pattern_list=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_inputs/All_samples_all_training_examples_inc_downsampled_05_pt3.shuffled-000*-of-00020.tfrecord.gz. # --output_pattern_prefix=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt3. #. # Generated by shuffle_tfrecords_beam.py. #name: ""Shuffle_global"". #tfrecord_path: ""/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:236,usability,memor,memory,236,"Hi @kishwarshafin ,. Sure. Just a quick note first to explain the outputs, and maybe its relevant to the problem. Given the number of examples I couldn't easily perform the shuffling step on my local cluster (using DirectRunner) due to memory and wall time limits. So I performed a 2-step shuffle. I.e. I split the examples in half (parts 1 and 2), shuffled each half, then randomly split the outputs from each of the first shuffles into two halves (parts 3 and 4) and ran a second round of shuffling. . I then edited the path in the pbtxt file to accommodate all file names. So `All_samples_training_examples.dataset_config.pbtxt` now contains the following:. ```. > cat /home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt. # Generated by shuffle_tfrecords_beam.py. # class0: 1454377. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt?-?????-of-?????.tfrecord.gz"". num_examples: 1454377. #name: ""Shuffle_global"". #tfrecord_path: ""/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt3-?????-of-?????.tfrecord.gz"". #num_examples: 727189. #. # --input_pattern_list=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_inputs/All_samples_all_training_examples_inc_downsampled_05_pt3.shuffled-000*-of-00020.tfrecord.gz. # --output_pattern_prefix=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt3. #. # Generated by shuffle_tfrecords_beam.py. #name: ""Shuffle_global"". #tfrecord_path: ""/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:270,usability,perform,performed,270,"Hi @kishwarshafin ,. Sure. Just a quick note first to explain the outputs, and maybe its relevant to the problem. Given the number of examples I couldn't easily perform the shuffling step on my local cluster (using DirectRunner) due to memory and wall time limits. So I performed a 2-step shuffle. I.e. I split the examples in half (parts 1 and 2), shuffled each half, then randomly split the outputs from each of the first shuffles into two halves (parts 3 and 4) and ran a second round of shuffling. . I then edited the path in the pbtxt file to accommodate all file names. So `All_samples_training_examples.dataset_config.pbtxt` now contains the following:. ```. > cat /home/examples_shuffled/train/All_samples_training_examples.dataset_config.pbtxt. # Generated by shuffle_tfrecords_beam.py. # class0: 1454377. name: ""Shuffle_global"". tfrecord_path: ""/home/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt?-?????-of-?????.tfrecord.gz"". num_examples: 1454377. #name: ""Shuffle_global"". #tfrecord_path: ""/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt3-?????-of-?????.tfrecord.gz"". #num_examples: 727189. #. # --input_pattern_list=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_inputs/All_samples_all_training_examples_inc_downsampled_05_pt3.shuffled-000*-of-00020.tfrecord.gz. # --output_pattern_prefix=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt3. #. # Generated by shuffle_tfrecords_beam.py. #name: ""Shuffle_global"". #tfrecord_path: ""/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:110,interoperability,distribut,distribution,110,"@DanJeffries ,. I don't think shuffling is the issue in your training set. You can see that this is the class distribution for your training data:. ```bash. #name: ""Shuffle_global"". #tfrecord_path: ""/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt4-?????-of-?????.tfrecord.gz"". #num_examples: 727188. # class0: 727188. #. # --input_pattern_list=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_inputs/All_samples_all_training_examples_inc_downsampled_05_pt4.shuffled-000*-of-00020.tfrecord.gz. # --output_pattern_prefix=/storage/scratch/iee/dj20y461/Stickleback/G_aculeatus/FITNESS/DV_training/examples_shuffled/train/shuffle_2_outputs/All_samples_all_training_examples_inc_downsampled_05.shuffle_2_pt4. #. ```. Meaning all of the examples you created are of class 0. Can you check if your truth VCF has 1/1 and 0/1 variants?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:5539,deployability,log,log,5539,"51,674:0,0,13,4. NC_053212.1_chromosome_1 42506 . C T,<NON_REF> 1121.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,28,0:28:84:1135,84,0,1135,84,1135:0,0,12,16. NC_053212.1_chromosome_1 46081 . A G,<NON_REF> 620.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,16,0:16:48:634,48,0,634,48,634:0,0,4,12. NC_053212.1_chromosome_1 47173 . G A,<NON_REF> 1059.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,29,0:29:87:1073,87,0,1073,87,1073:0,0,5,24. NC_053212.1_chromosome_1 47399 . TTG T,<NON_REF> 675.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,19,0:19:57:689,57,0,689,57,689:0,0,16,3. NC_053212.1_chromosome_1 47570 . G C,<NON_REF> 385.6 . . GT:AD:DP:GQ:PL:SB 0/1:11,11,0:22:99:393,0,381,426,414,841:6,5,5,6. NC_053212.1_chromosome_1 47768 . ATG A,<NON_REF> 812.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,22,0:22:66:826,66,0,826,66,826:0,0,9,13. NC_053212.1_chromosome_1 48014 . CA C,<NON_REF> 876.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,24,0:24:72:890,72,0,890,72,890:0,0,16,8. NC_053212.1_chromosome_1 48426 . A G,<NON_REF> 780.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,19,0:19:57:794,57,0,794,57,794:0,0,9,10. NC_053212.1_chromosome_1 50624 . T C,<NON_REF> 1021.03 . . GT:AD:DP:GQ:PGT:PID:PL:PS:SB 1|1:0,22,0:22:69:1|1:50616_C_T:1035,69,0,1035,69,1035:5061>. NC_053212.1_chromosome_1 50765 . TC T,<NON_REF> 1005.03 . . GT:AD:DP:GQ:PL:SB 1/1:2,26,0:28:64:1019,64,0,1024,78,1038:1,1,14,12. NC_053212.1_chromosome_1 50887 . G T,<NON_REF> 856.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,23,0:23:69:870,69,0,870,69,870:0,0,10,13. NC_053212.1_chromosome_1 50971 . A T,<NON_REF> 699.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,19,0:19:57:713,57,0,713,57,713:0,0,9,10. NC_053212.1_chromosome_1 51160 . C T,<NON_REF> 1100.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,31,0:31:92:1114,92,0,1114,92,1114:0,0,10,21. NC_053212.1_chromosome_1 53199 . TCA T,<NON_REF> 767.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,20,0:20:60:781,60,0,781,60,781:0,0,7,13. ```. And I have attached the log file for this make_examples for this sample. [MAKE_EX_TRAIN_3148249-3.err.gz](https://github.com/user-attachments/files/16873655/MAKE_EX_TRAIN_3148249-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:487,integrability,buffer,buffer,487,"Hi @kishwarshafin ,. Ah ok that explains it. Yes I definitely have variants in my VCF, between 850k - 1.15M for each of 5 samples. Here is the output of `bcftools stats` for one of the samples:. [SR_male_1_alltruth.stats.gz](https://github.com/user-attachments/files/16905957/SR_male_1_alltruth.stats.gz). Perhaps it is my make_examples command? I made examples for sample separately using the below command. . ```. apptainer run \. -B $WD:/wd \. $DV_PATH \. parallel -q --halt 2 --line-buffer \. /opt/deepvariant/bin/make_examples \. --mode training \. --ref $REF \. --reads /wd/bams/${SAMPLE}.fixmate.coordsorted.bam \. --truth_variants /wd/Filtered_variants/${SAMPLE}.ALL_TRUTH_VARS.CORRECTED.vcf.gz \. --confident_regions /wd/Confident_regions/${SAMPLE_BED_NAME}.conf.bed \. --examples /wd/examples/train/${SAMPLE}/training_examples.tfrecord@20 \. --regions /wd/training_regions/${CROSS}_train_partitions.bed \. --channels ""insert_size"" \. --task {} ::: `seq 0 19` #split the task into 20 jobs. ```. And here's an excert from this sample's VCF:. ```. #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT SR_male_1. NC_053212.1_chromosome_1 1449 . C T,<NON_REF> 347.6 . . GT:AD:DP:GQ:PL:SB 0/1:11,10,0:21:99:355,0,328,388,358,746:4,7,3,7. NC_053212.1_chromosome_1 2214 . T TTGTTTGAC,<NON_REF> 750.06 . . GT:AD:DP:GQ:PL:SB 1/1:0,15,0:15:51:764,51,0,765,51,765:0,0,2,13. NC_053212.1_chromosome_1 4741 . C T,<NON_REF> 807.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,21,0:21:63:821,63,0,821,63,821:0,0,9,12. NC_053212.1_chromosome_1 5560 . G A,<NON_REF> 1001.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,27,0:27:81:1015,81,0,1015,81,1015:0,0,19,8. NC_053212.1_chromosome_1 5876 . C A,<NON_REF> 501.6 . . GT:AD:DP:GQ:PL:SB 0/1:15,16,0:31:99:509,0,495,554,543,1097:3,12,7,9. NC_053212.1_chromosome_1 6440 . C T,<NON_REF> 701.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,19,0:19:57:715,57,0,715,57,715:0,0,9,10. NC_053212.1_chromosome_1 8670 . A G,<NON_REF> 1198.03 . . GT:AD:DP:GQ:PGT:PID:PL:PS:SB 1|1:0,26,0:26:81:1|1:8670_A_G:1212,81,0,1212,81,1212:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:1082,integrability,FILTER,FILTER,1082,", between 850k - 1.15M for each of 5 samples. Here is the output of `bcftools stats` for one of the samples:. [SR_male_1_alltruth.stats.gz](https://github.com/user-attachments/files/16905957/SR_male_1_alltruth.stats.gz). Perhaps it is my make_examples command? I made examples for sample separately using the below command. . ```. apptainer run \. -B $WD:/wd \. $DV_PATH \. parallel -q --halt 2 --line-buffer \. /opt/deepvariant/bin/make_examples \. --mode training \. --ref $REF \. --reads /wd/bams/${SAMPLE}.fixmate.coordsorted.bam \. --truth_variants /wd/Filtered_variants/${SAMPLE}.ALL_TRUTH_VARS.CORRECTED.vcf.gz \. --confident_regions /wd/Confident_regions/${SAMPLE_BED_NAME}.conf.bed \. --examples /wd/examples/train/${SAMPLE}/training_examples.tfrecord@20 \. --regions /wd/training_regions/${CROSS}_train_partitions.bed \. --channels ""insert_size"" \. --task {} ::: `seq 0 19` #split the task into 20 jobs. ```. And here's an excert from this sample's VCF:. ```. #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT SR_male_1. NC_053212.1_chromosome_1 1449 . C T,<NON_REF> 347.6 . . GT:AD:DP:GQ:PL:SB 0/1:11,10,0:21:99:355,0,328,388,358,746:4,7,3,7. NC_053212.1_chromosome_1 2214 . T TTGTTTGAC,<NON_REF> 750.06 . . GT:AD:DP:GQ:PL:SB 1/1:0,15,0:15:51:764,51,0,765,51,765:0,0,2,13. NC_053212.1_chromosome_1 4741 . C T,<NON_REF> 807.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,21,0:21:63:821,63,0,821,63,821:0,0,9,12. NC_053212.1_chromosome_1 5560 . G A,<NON_REF> 1001.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,27,0:27:81:1015,81,0,1015,81,1015:0,0,19,8. NC_053212.1_chromosome_1 5876 . C A,<NON_REF> 501.6 . . GT:AD:DP:GQ:PL:SB 0/1:15,16,0:31:99:509,0,495,554,543,1097:3,12,7,9. NC_053212.1_chromosome_1 6440 . C T,<NON_REF> 701.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,19,0:19:57:715,57,0,715,57,715:0,0,9,10. NC_053212.1_chromosome_1 8670 . A G,<NON_REF> 1198.03 . . GT:AD:DP:GQ:PGT:PID:PL:PS:SB 1|1:0,26,0:26:81:1|1:8670_A_G:1212,81,0,1212,81,1212:8670:>. NC_053212.1_chromosome_1 8682 . G C,<NON_REF> 1281.03 . . GT:AD:DP:GQ:PGT:PID",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:1094,interoperability,FORMAT,FORMAT,1094,"0k - 1.15M for each of 5 samples. Here is the output of `bcftools stats` for one of the samples:. [SR_male_1_alltruth.stats.gz](https://github.com/user-attachments/files/16905957/SR_male_1_alltruth.stats.gz). Perhaps it is my make_examples command? I made examples for sample separately using the below command. . ```. apptainer run \. -B $WD:/wd \. $DV_PATH \. parallel -q --halt 2 --line-buffer \. /opt/deepvariant/bin/make_examples \. --mode training \. --ref $REF \. --reads /wd/bams/${SAMPLE}.fixmate.coordsorted.bam \. --truth_variants /wd/Filtered_variants/${SAMPLE}.ALL_TRUTH_VARS.CORRECTED.vcf.gz \. --confident_regions /wd/Confident_regions/${SAMPLE_BED_NAME}.conf.bed \. --examples /wd/examples/train/${SAMPLE}/training_examples.tfrecord@20 \. --regions /wd/training_regions/${CROSS}_train_partitions.bed \. --channels ""insert_size"" \. --task {} ::: `seq 0 19` #split the task into 20 jobs. ```. And here's an excert from this sample's VCF:. ```. #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT SR_male_1. NC_053212.1_chromosome_1 1449 . C T,<NON_REF> 347.6 . . GT:AD:DP:GQ:PL:SB 0/1:11,10,0:21:99:355,0,328,388,358,746:4,7,3,7. NC_053212.1_chromosome_1 2214 . T TTGTTTGAC,<NON_REF> 750.06 . . GT:AD:DP:GQ:PL:SB 1/1:0,15,0:15:51:764,51,0,765,51,765:0,0,2,13. NC_053212.1_chromosome_1 4741 . C T,<NON_REF> 807.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,21,0:21:63:821,63,0,821,63,821:0,0,9,12. NC_053212.1_chromosome_1 5560 . G A,<NON_REF> 1001.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,27,0:27:81:1015,81,0,1015,81,1015:0,0,19,8. NC_053212.1_chromosome_1 5876 . C A,<NON_REF> 501.6 . . GT:AD:DP:GQ:PL:SB 0/1:15,16,0:31:99:509,0,495,554,543,1097:3,12,7,9. NC_053212.1_chromosome_1 6440 . C T,<NON_REF> 701.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,19,0:19:57:715,57,0,715,57,715:0,0,9,10. NC_053212.1_chromosome_1 8670 . A G,<NON_REF> 1198.03 . . GT:AD:DP:GQ:PGT:PID:PL:PS:SB 1|1:0,26,0:26:81:1|1:8670_A_G:1212,81,0,1212,81,1212:8670:>. NC_053212.1_chromosome_1 8682 . G C,<NON_REF> 1281.03 . . GT:AD:DP:GQ:PGT:PID:PL:PS:SB 1|",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:459,performance,parallel,parallel,459,"Hi @kishwarshafin ,. Ah ok that explains it. Yes I definitely have variants in my VCF, between 850k - 1.15M for each of 5 samples. Here is the output of `bcftools stats` for one of the samples:. [SR_male_1_alltruth.stats.gz](https://github.com/user-attachments/files/16905957/SR_male_1_alltruth.stats.gz). Perhaps it is my make_examples command? I made examples for sample separately using the below command. . ```. apptainer run \. -B $WD:/wd \. $DV_PATH \. parallel -q --halt 2 --line-buffer \. /opt/deepvariant/bin/make_examples \. --mode training \. --ref $REF \. --reads /wd/bams/${SAMPLE}.fixmate.coordsorted.bam \. --truth_variants /wd/Filtered_variants/${SAMPLE}.ALL_TRUTH_VARS.CORRECTED.vcf.gz \. --confident_regions /wd/Confident_regions/${SAMPLE_BED_NAME}.conf.bed \. --examples /wd/examples/train/${SAMPLE}/training_examples.tfrecord@20 \. --regions /wd/training_regions/${CROSS}_train_partitions.bed \. --channels ""insert_size"" \. --task {} ::: `seq 0 19` #split the task into 20 jobs. ```. And here's an excert from this sample's VCF:. ```. #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT SR_male_1. NC_053212.1_chromosome_1 1449 . C T,<NON_REF> 347.6 . . GT:AD:DP:GQ:PL:SB 0/1:11,10,0:21:99:355,0,328,388,358,746:4,7,3,7. NC_053212.1_chromosome_1 2214 . T TTGTTTGAC,<NON_REF> 750.06 . . GT:AD:DP:GQ:PL:SB 1/1:0,15,0:15:51:764,51,0,765,51,765:0,0,2,13. NC_053212.1_chromosome_1 4741 . C T,<NON_REF> 807.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,21,0:21:63:821,63,0,821,63,821:0,0,9,12. NC_053212.1_chromosome_1 5560 . G A,<NON_REF> 1001.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,27,0:27:81:1015,81,0,1015,81,1015:0,0,19,8. NC_053212.1_chromosome_1 5876 . C A,<NON_REF> 501.6 . . GT:AD:DP:GQ:PL:SB 0/1:15,16,0:31:99:509,0,495,554,543,1097:3,12,7,9. NC_053212.1_chromosome_1 6440 . C T,<NON_REF> 701.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,19,0:19:57:715,57,0,715,57,715:0,0,9,10. NC_053212.1_chromosome_1 8670 . A G,<NON_REF> 1198.03 . . GT:AD:DP:GQ:PGT:PID:PL:PS:SB 1|1:0,26,0:26:81:1|1:8670_A_G:1212,81,0,1212,81,1212:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:5539,safety,log,log,5539,"51,674:0,0,13,4. NC_053212.1_chromosome_1 42506 . C T,<NON_REF> 1121.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,28,0:28:84:1135,84,0,1135,84,1135:0,0,12,16. NC_053212.1_chromosome_1 46081 . A G,<NON_REF> 620.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,16,0:16:48:634,48,0,634,48,634:0,0,4,12. NC_053212.1_chromosome_1 47173 . G A,<NON_REF> 1059.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,29,0:29:87:1073,87,0,1073,87,1073:0,0,5,24. NC_053212.1_chromosome_1 47399 . TTG T,<NON_REF> 675.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,19,0:19:57:689,57,0,689,57,689:0,0,16,3. NC_053212.1_chromosome_1 47570 . G C,<NON_REF> 385.6 . . GT:AD:DP:GQ:PL:SB 0/1:11,11,0:22:99:393,0,381,426,414,841:6,5,5,6. NC_053212.1_chromosome_1 47768 . ATG A,<NON_REF> 812.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,22,0:22:66:826,66,0,826,66,826:0,0,9,13. NC_053212.1_chromosome_1 48014 . CA C,<NON_REF> 876.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,24,0:24:72:890,72,0,890,72,890:0,0,16,8. NC_053212.1_chromosome_1 48426 . A G,<NON_REF> 780.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,19,0:19:57:794,57,0,794,57,794:0,0,9,10. NC_053212.1_chromosome_1 50624 . T C,<NON_REF> 1021.03 . . GT:AD:DP:GQ:PGT:PID:PL:PS:SB 1|1:0,22,0:22:69:1|1:50616_C_T:1035,69,0,1035,69,1035:5061>. NC_053212.1_chromosome_1 50765 . TC T,<NON_REF> 1005.03 . . GT:AD:DP:GQ:PL:SB 1/1:2,26,0:28:64:1019,64,0,1024,78,1038:1,1,14,12. NC_053212.1_chromosome_1 50887 . G T,<NON_REF> 856.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,23,0:23:69:870,69,0,870,69,870:0,0,10,13. NC_053212.1_chromosome_1 50971 . A T,<NON_REF> 699.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,19,0:19:57:713,57,0,713,57,713:0,0,9,10. NC_053212.1_chromosome_1 51160 . C T,<NON_REF> 1100.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,31,0:31:92:1114,92,0,1114,92,1114:0,0,10,21. NC_053212.1_chromosome_1 53199 . TCA T,<NON_REF> 767.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,20,0:20:60:781,60,0,781,60,781:0,0,7,13. ```. And I have attached the log file for this make_examples for this sample. [MAKE_EX_TRAIN_3148249-3.err.gz](https://github.com/user-attachments/files/16873655/MAKE_EX_TRAIN_3148249-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:5539,security,log,log,5539,"51,674:0,0,13,4. NC_053212.1_chromosome_1 42506 . C T,<NON_REF> 1121.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,28,0:28:84:1135,84,0,1135,84,1135:0,0,12,16. NC_053212.1_chromosome_1 46081 . A G,<NON_REF> 620.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,16,0:16:48:634,48,0,634,48,634:0,0,4,12. NC_053212.1_chromosome_1 47173 . G A,<NON_REF> 1059.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,29,0:29:87:1073,87,0,1073,87,1073:0,0,5,24. NC_053212.1_chromosome_1 47399 . TTG T,<NON_REF> 675.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,19,0:19:57:689,57,0,689,57,689:0,0,16,3. NC_053212.1_chromosome_1 47570 . G C,<NON_REF> 385.6 . . GT:AD:DP:GQ:PL:SB 0/1:11,11,0:22:99:393,0,381,426,414,841:6,5,5,6. NC_053212.1_chromosome_1 47768 . ATG A,<NON_REF> 812.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,22,0:22:66:826,66,0,826,66,826:0,0,9,13. NC_053212.1_chromosome_1 48014 . CA C,<NON_REF> 876.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,24,0:24:72:890,72,0,890,72,890:0,0,16,8. NC_053212.1_chromosome_1 48426 . A G,<NON_REF> 780.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,19,0:19:57:794,57,0,794,57,794:0,0,9,10. NC_053212.1_chromosome_1 50624 . T C,<NON_REF> 1021.03 . . GT:AD:DP:GQ:PGT:PID:PL:PS:SB 1|1:0,22,0:22:69:1|1:50616_C_T:1035,69,0,1035,69,1035:5061>. NC_053212.1_chromosome_1 50765 . TC T,<NON_REF> 1005.03 . . GT:AD:DP:GQ:PL:SB 1/1:2,26,0:28:64:1019,64,0,1024,78,1038:1,1,14,12. NC_053212.1_chromosome_1 50887 . G T,<NON_REF> 856.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,23,0:23:69:870,69,0,870,69,870:0,0,10,13. NC_053212.1_chromosome_1 50971 . A T,<NON_REF> 699.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,19,0:19:57:713,57,0,713,57,713:0,0,9,10. NC_053212.1_chromosome_1 51160 . C T,<NON_REF> 1100.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,31,0:31:92:1114,92,0,1114,92,1114:0,0,10,21. NC_053212.1_chromosome_1 53199 . TCA T,<NON_REF> 767.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,20,0:20:60:781,60,0,781,60,781:0,0,7,13. ```. And I have attached the log file for this make_examples for this sample. [MAKE_EX_TRAIN_3148249-3.err.gz](https://github.com/user-attachments/files/16873655/MAKE_EX_TRAIN_3148249-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:5539,testability,log,log,5539,"51,674:0,0,13,4. NC_053212.1_chromosome_1 42506 . C T,<NON_REF> 1121.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,28,0:28:84:1135,84,0,1135,84,1135:0,0,12,16. NC_053212.1_chromosome_1 46081 . A G,<NON_REF> 620.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,16,0:16:48:634,48,0,634,48,634:0,0,4,12. NC_053212.1_chromosome_1 47173 . G A,<NON_REF> 1059.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,29,0:29:87:1073,87,0,1073,87,1073:0,0,5,24. NC_053212.1_chromosome_1 47399 . TTG T,<NON_REF> 675.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,19,0:19:57:689,57,0,689,57,689:0,0,16,3. NC_053212.1_chromosome_1 47570 . G C,<NON_REF> 385.6 . . GT:AD:DP:GQ:PL:SB 0/1:11,11,0:22:99:393,0,381,426,414,841:6,5,5,6. NC_053212.1_chromosome_1 47768 . ATG A,<NON_REF> 812.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,22,0:22:66:826,66,0,826,66,826:0,0,9,13. NC_053212.1_chromosome_1 48014 . CA C,<NON_REF> 876.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,24,0:24:72:890,72,0,890,72,890:0,0,16,8. NC_053212.1_chromosome_1 48426 . A G,<NON_REF> 780.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,19,0:19:57:794,57,0,794,57,794:0,0,9,10. NC_053212.1_chromosome_1 50624 . T C,<NON_REF> 1021.03 . . GT:AD:DP:GQ:PGT:PID:PL:PS:SB 1|1:0,22,0:22:69:1|1:50616_C_T:1035,69,0,1035,69,1035:5061>. NC_053212.1_chromosome_1 50765 . TC T,<NON_REF> 1005.03 . . GT:AD:DP:GQ:PL:SB 1/1:2,26,0:28:64:1019,64,0,1024,78,1038:1,1,14,12. NC_053212.1_chromosome_1 50887 . G T,<NON_REF> 856.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,23,0:23:69:870,69,0,870,69,870:0,0,10,13. NC_053212.1_chromosome_1 50971 . A T,<NON_REF> 699.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,19,0:19:57:713,57,0,713,57,713:0,0,9,10. NC_053212.1_chromosome_1 51160 . C T,<NON_REF> 1100.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,31,0:31:92:1114,92,0,1114,92,1114:0,0,10,21. NC_053212.1_chromosome_1 53199 . TCA T,<NON_REF> 767.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,20,0:20:60:781,60,0,781,60,781:0,0,7,13. ```. And I have attached the log file for this make_examples for this sample. [MAKE_EX_TRAIN_3148249-3.err.gz](https://github.com/user-attachments/files/16873655/MAKE_EX_TRAIN_3148249-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:244,usability,user,user-attachments,244,"Hi @kishwarshafin ,. Ah ok that explains it. Yes I definitely have variants in my VCF, between 850k - 1.15M for each of 5 samples. Here is the output of `bcftools stats` for one of the samples:. [SR_male_1_alltruth.stats.gz](https://github.com/user-attachments/files/16905957/SR_male_1_alltruth.stats.gz). Perhaps it is my make_examples command? I made examples for sample separately using the below command. . ```. apptainer run \. -B $WD:/wd \. $DV_PATH \. parallel -q --halt 2 --line-buffer \. /opt/deepvariant/bin/make_examples \. --mode training \. --ref $REF \. --reads /wd/bams/${SAMPLE}.fixmate.coordsorted.bam \. --truth_variants /wd/Filtered_variants/${SAMPLE}.ALL_TRUTH_VARS.CORRECTED.vcf.gz \. --confident_regions /wd/Confident_regions/${SAMPLE_BED_NAME}.conf.bed \. --examples /wd/examples/train/${SAMPLE}/training_examples.tfrecord@20 \. --regions /wd/training_regions/${CROSS}_train_partitions.bed \. --channels ""insert_size"" \. --task {} ::: `seq 0 19` #split the task into 20 jobs. ```. And here's an excert from this sample's VCF:. ```. #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT SR_male_1. NC_053212.1_chromosome_1 1449 . C T,<NON_REF> 347.6 . . GT:AD:DP:GQ:PL:SB 0/1:11,10,0:21:99:355,0,328,388,358,746:4,7,3,7. NC_053212.1_chromosome_1 2214 . T TTGTTTGAC,<NON_REF> 750.06 . . GT:AD:DP:GQ:PL:SB 1/1:0,15,0:15:51:764,51,0,765,51,765:0,0,2,13. NC_053212.1_chromosome_1 4741 . C T,<NON_REF> 807.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,21,0:21:63:821,63,0,821,63,821:0,0,9,12. NC_053212.1_chromosome_1 5560 . G A,<NON_REF> 1001.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,27,0:27:81:1015,81,0,1015,81,1015:0,0,19,8. NC_053212.1_chromosome_1 5876 . C A,<NON_REF> 501.6 . . GT:AD:DP:GQ:PL:SB 0/1:15,16,0:31:99:509,0,495,554,543,1097:3,12,7,9. NC_053212.1_chromosome_1 6440 . C T,<NON_REF> 701.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,19,0:19:57:715,57,0,715,57,715:0,0,9,10. NC_053212.1_chromosome_1 8670 . A G,<NON_REF> 1198.03 . . GT:AD:DP:GQ:PGT:PID:PL:PS:SB 1|1:0,26,0:26:81:1|1:8670_A_G:1212,81,0,1212,81,1212:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:337,usability,command,command,337,"Hi @kishwarshafin ,. Ah ok that explains it. Yes I definitely have variants in my VCF, between 850k - 1.15M for each of 5 samples. Here is the output of `bcftools stats` for one of the samples:. [SR_male_1_alltruth.stats.gz](https://github.com/user-attachments/files/16905957/SR_male_1_alltruth.stats.gz). Perhaps it is my make_examples command? I made examples for sample separately using the below command. . ```. apptainer run \. -B $WD:/wd \. $DV_PATH \. parallel -q --halt 2 --line-buffer \. /opt/deepvariant/bin/make_examples \. --mode training \. --ref $REF \. --reads /wd/bams/${SAMPLE}.fixmate.coordsorted.bam \. --truth_variants /wd/Filtered_variants/${SAMPLE}.ALL_TRUTH_VARS.CORRECTED.vcf.gz \. --confident_regions /wd/Confident_regions/${SAMPLE_BED_NAME}.conf.bed \. --examples /wd/examples/train/${SAMPLE}/training_examples.tfrecord@20 \. --regions /wd/training_regions/${CROSS}_train_partitions.bed \. --channels ""insert_size"" \. --task {} ::: `seq 0 19` #split the task into 20 jobs. ```. And here's an excert from this sample's VCF:. ```. #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT SR_male_1. NC_053212.1_chromosome_1 1449 . C T,<NON_REF> 347.6 . . GT:AD:DP:GQ:PL:SB 0/1:11,10,0:21:99:355,0,328,388,358,746:4,7,3,7. NC_053212.1_chromosome_1 2214 . T TTGTTTGAC,<NON_REF> 750.06 . . GT:AD:DP:GQ:PL:SB 1/1:0,15,0:15:51:764,51,0,765,51,765:0,0,2,13. NC_053212.1_chromosome_1 4741 . C T,<NON_REF> 807.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,21,0:21:63:821,63,0,821,63,821:0,0,9,12. NC_053212.1_chromosome_1 5560 . G A,<NON_REF> 1001.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,27,0:27:81:1015,81,0,1015,81,1015:0,0,19,8. NC_053212.1_chromosome_1 5876 . C A,<NON_REF> 501.6 . . GT:AD:DP:GQ:PL:SB 0/1:15,16,0:31:99:509,0,495,554,543,1097:3,12,7,9. NC_053212.1_chromosome_1 6440 . C T,<NON_REF> 701.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,19,0:19:57:715,57,0,715,57,715:0,0,9,10. NC_053212.1_chromosome_1 8670 . A G,<NON_REF> 1198.03 . . GT:AD:DP:GQ:PGT:PID:PL:PS:SB 1|1:0,26,0:26:81:1|1:8670_A_G:1212,81,0,1212,81,1212:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:400,usability,command,command,400,"Hi @kishwarshafin ,. Ah ok that explains it. Yes I definitely have variants in my VCF, between 850k - 1.15M for each of 5 samples. Here is the output of `bcftools stats` for one of the samples:. [SR_male_1_alltruth.stats.gz](https://github.com/user-attachments/files/16905957/SR_male_1_alltruth.stats.gz). Perhaps it is my make_examples command? I made examples for sample separately using the below command. . ```. apptainer run \. -B $WD:/wd \. $DV_PATH \. parallel -q --halt 2 --line-buffer \. /opt/deepvariant/bin/make_examples \. --mode training \. --ref $REF \. --reads /wd/bams/${SAMPLE}.fixmate.coordsorted.bam \. --truth_variants /wd/Filtered_variants/${SAMPLE}.ALL_TRUTH_VARS.CORRECTED.vcf.gz \. --confident_regions /wd/Confident_regions/${SAMPLE_BED_NAME}.conf.bed \. --examples /wd/examples/train/${SAMPLE}/training_examples.tfrecord@20 \. --regions /wd/training_regions/${CROSS}_train_partitions.bed \. --channels ""insert_size"" \. --task {} ::: `seq 0 19` #split the task into 20 jobs. ```. And here's an excert from this sample's VCF:. ```. #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT SR_male_1. NC_053212.1_chromosome_1 1449 . C T,<NON_REF> 347.6 . . GT:AD:DP:GQ:PL:SB 0/1:11,10,0:21:99:355,0,328,388,358,746:4,7,3,7. NC_053212.1_chromosome_1 2214 . T TTGTTTGAC,<NON_REF> 750.06 . . GT:AD:DP:GQ:PL:SB 1/1:0,15,0:15:51:764,51,0,765,51,765:0,0,2,13. NC_053212.1_chromosome_1 4741 . C T,<NON_REF> 807.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,21,0:21:63:821,63,0,821,63,821:0,0,9,12. NC_053212.1_chromosome_1 5560 . G A,<NON_REF> 1001.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,27,0:27:81:1015,81,0,1015,81,1015:0,0,19,8. NC_053212.1_chromosome_1 5876 . C A,<NON_REF> 501.6 . . GT:AD:DP:GQ:PL:SB 0/1:15,16,0:31:99:509,0,495,554,543,1097:3,12,7,9. NC_053212.1_chromosome_1 6440 . C T,<NON_REF> 701.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,19,0:19:57:715,57,0,715,57,715:0,0,9,10. NC_053212.1_chromosome_1 8670 . A G,<NON_REF> 1198.03 . . GT:AD:DP:GQ:PGT:PID:PL:PS:SB 1|1:0,26,0:26:81:1|1:8670_A_G:1212,81,0,1212,81,1212:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:5640,usability,user,user-attachments,5640,"51,674:0,0,13,4. NC_053212.1_chromosome_1 42506 . C T,<NON_REF> 1121.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,28,0:28:84:1135,84,0,1135,84,1135:0,0,12,16. NC_053212.1_chromosome_1 46081 . A G,<NON_REF> 620.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,16,0:16:48:634,48,0,634,48,634:0,0,4,12. NC_053212.1_chromosome_1 47173 . G A,<NON_REF> 1059.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,29,0:29:87:1073,87,0,1073,87,1073:0,0,5,24. NC_053212.1_chromosome_1 47399 . TTG T,<NON_REF> 675.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,19,0:19:57:689,57,0,689,57,689:0,0,16,3. NC_053212.1_chromosome_1 47570 . G C,<NON_REF> 385.6 . . GT:AD:DP:GQ:PL:SB 0/1:11,11,0:22:99:393,0,381,426,414,841:6,5,5,6. NC_053212.1_chromosome_1 47768 . ATG A,<NON_REF> 812.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,22,0:22:66:826,66,0,826,66,826:0,0,9,13. NC_053212.1_chromosome_1 48014 . CA C,<NON_REF> 876.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,24,0:24:72:890,72,0,890,72,890:0,0,16,8. NC_053212.1_chromosome_1 48426 . A G,<NON_REF> 780.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,19,0:19:57:794,57,0,794,57,794:0,0,9,10. NC_053212.1_chromosome_1 50624 . T C,<NON_REF> 1021.03 . . GT:AD:DP:GQ:PGT:PID:PL:PS:SB 1|1:0,22,0:22:69:1|1:50616_C_T:1035,69,0,1035,69,1035:5061>. NC_053212.1_chromosome_1 50765 . TC T,<NON_REF> 1005.03 . . GT:AD:DP:GQ:PL:SB 1/1:2,26,0:28:64:1019,64,0,1024,78,1038:1,1,14,12. NC_053212.1_chromosome_1 50887 . G T,<NON_REF> 856.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,23,0:23:69:870,69,0,870,69,870:0,0,10,13. NC_053212.1_chromosome_1 50971 . A T,<NON_REF> 699.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,19,0:19:57:713,57,0,713,57,713:0,0,9,10. NC_053212.1_chromosome_1 51160 . C T,<NON_REF> 1100.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,31,0:31:92:1114,92,0,1114,92,1114:0,0,10,21. NC_053212.1_chromosome_1 53199 . TCA T,<NON_REF> 767.03 . . GT:AD:DP:GQ:PL:SB 1/1:0,20,0:20:60:781,60,0,781,60,781:0,0,7,13. ```. And I have attached the log file for this make_examples for this sample. [MAKE_EX_TRAIN_3148249-3.err.gz](https://github.com/user-attachments/files/16873655/MAKE_EX_TRAIN_3148249-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:88,deployability,log,log,88,"@DanJeffries, sorry for the late reply I was traveling for a conference. Looking at the log, most of it looks like this:. ```bash. I0812 17:25:36.970339 140640080795456 make_examples_core.py:301] Task 18/20: 130000 candidates (5465 examples) [24.32s elapsed]. I0812 17:25:38.358597 140641138153280 make_examples_core.py:301] Task 17/20: 136011 candidates (5980 examples) [24.30s elapsed]. I0812 17:25:38.452311 140719761319744 haplotype_labeler.py:449] Not including more because genotype_options_product will be 157464.0, which exceeds max(=100000). I0812 17:25:39.808730 139930050549568 make_examples_core.py:301] Task 19/20: 130009 candidates (5415 examples) [19.65s elapsed]. I0812 17:25:40.161706 140719761319744 make_examples_core.py:301] Task 1/20: 130009 candidates (5656 examples) [26.55s elapsed]. I0812 17:25:39.762312 140656897058624 haplotype_labeler.py:449] Not including more because genotype_options_product will be 118098.0, which exceeds max(=100000). I0812 17:25:40.178942 139929751582528 haplotype_labeler.py:449] Not including more because genotype_options_product will be 118098.0, which exceeds max(=100000). I0812 17:25:41.815151 139685487241024 make_examples_core.py:301] Task 8/20: 134010 candidates (5603 examples) [20.32s elapsed]. I0812 17:25:42.062644 140656897058624 make_examples_core.py:301] Task 14/20: 130007 candidates (5538 examples) [26.62s elapsed]. I0812 17:25:42.944558 139916975953728 haplotype_labeler.py:449] Not including more because genotype_options_product will be 157464.0, which exceeds max(=100000). I0812 17:25:42.945389 139916975953728 haplotype_labeler.py:449] Not including more because genotype_options_product will be 944784.0, which exceeds max(=100000). I0812 17:25:42.940323 140366879631168 make_examples_core.py:301] Task 6/20: 132005 candidates (5726 examples) [25.32s elapsed]. I0812 17:25:43.504171 139929751582528 make_examples_core.py:301] Task 4/20: 132003 candidates (5481 examples) [23.80s elapsed]. I0812 17:25:43.563577 140585679",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:3727,deployability,fail,failing,3727,":43.504171 139929751582528 make_examples_core.py:301] Task 4/20: 132003 candidates (5481 examples) [23.80s elapsed]. I0812 17:25:43.563577 140585679882048 haplotype_labeler.py:449] Not including more because genotype_options_product will be 131220.0, which exceeds max(=100000). I0812 17:25:45.208675 140012542068544 make_examples_core.py:301] Task 12/20: 134003 candidates (5624 examples) [21.31s elapsed]. I0812 17:25:45.249171 140585679882048 haplotype_labeler.py:449] Not including more because genotype_options_product will be 275562.0, which exceeds max(=100000). I0812 17:25:44.861580 140290187421504 make_examples_core.py:301] Task 0/20: 134001 candidates (5695 examples) [22.80s elapsed]. I0812 17:25:44.957572 140719761319744 haplotype_labeler.py:449] Not including more because genotype_options_product will be 157464.0, which exceeds max(=100000). I0812 17:25:44.749801 140624495118144 make_examples_core.py:301] Task 9/20: 132004 candidates (5675 examples) [26.91s elapsed]. I0812 17:25:45.658525 139725838563136 haplotype_labeler.py:449] Not including more because genotype_options_product will be 157464.0, which exceeds max(=100000). I0812 17:25:48.367301 140203250202432 make_examples_core.py:301] Task 3/20: 130018 candidates (5401 examples) [24.78s elapsed]. I0812 17:25:49.316477 140120687957824 haplotype_labeler.py:449] Not including more because genotype_options_product will be 118098.0, which exceeds max(=100000). I0812 17:25:50.556129 140585679882048 make_examples_core.py:301] Task 16/20: 132012 candidates (5581 examples) [21.74s elapsed]. I0812 17:25:51.780121 140641138153280 make_examples_core.py:301] Task 17/20: 138019 candidates (6057 examples) [13.42s elapsed]. ```. It really looks like you have a lot of variants, is this expected for your sample? What's happening here is that the haplotype_labler is trying to label the candidates but failing because there are way too many combinations and it's giving up. What is the truth that you are using for this sample?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:3727,reliability,fail,failing,3727,":43.504171 139929751582528 make_examples_core.py:301] Task 4/20: 132003 candidates (5481 examples) [23.80s elapsed]. I0812 17:25:43.563577 140585679882048 haplotype_labeler.py:449] Not including more because genotype_options_product will be 131220.0, which exceeds max(=100000). I0812 17:25:45.208675 140012542068544 make_examples_core.py:301] Task 12/20: 134003 candidates (5624 examples) [21.31s elapsed]. I0812 17:25:45.249171 140585679882048 haplotype_labeler.py:449] Not including more because genotype_options_product will be 275562.0, which exceeds max(=100000). I0812 17:25:44.861580 140290187421504 make_examples_core.py:301] Task 0/20: 134001 candidates (5695 examples) [22.80s elapsed]. I0812 17:25:44.957572 140719761319744 haplotype_labeler.py:449] Not including more because genotype_options_product will be 157464.0, which exceeds max(=100000). I0812 17:25:44.749801 140624495118144 make_examples_core.py:301] Task 9/20: 132004 candidates (5675 examples) [26.91s elapsed]. I0812 17:25:45.658525 139725838563136 haplotype_labeler.py:449] Not including more because genotype_options_product will be 157464.0, which exceeds max(=100000). I0812 17:25:48.367301 140203250202432 make_examples_core.py:301] Task 3/20: 130018 candidates (5401 examples) [24.78s elapsed]. I0812 17:25:49.316477 140120687957824 haplotype_labeler.py:449] Not including more because genotype_options_product will be 118098.0, which exceeds max(=100000). I0812 17:25:50.556129 140585679882048 make_examples_core.py:301] Task 16/20: 132012 candidates (5581 examples) [21.74s elapsed]. I0812 17:25:51.780121 140641138153280 make_examples_core.py:301] Task 17/20: 138019 candidates (6057 examples) [13.42s elapsed]. ```. It really looks like you have a lot of variants, is this expected for your sample? What's happening here is that the haplotype_labler is trying to label the candidates but failing because there are way too many combinations and it's giving up. What is the truth that you are using for this sample?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:88,safety,log,log,88,"@DanJeffries, sorry for the late reply I was traveling for a conference. Looking at the log, most of it looks like this:. ```bash. I0812 17:25:36.970339 140640080795456 make_examples_core.py:301] Task 18/20: 130000 candidates (5465 examples) [24.32s elapsed]. I0812 17:25:38.358597 140641138153280 make_examples_core.py:301] Task 17/20: 136011 candidates (5980 examples) [24.30s elapsed]. I0812 17:25:38.452311 140719761319744 haplotype_labeler.py:449] Not including more because genotype_options_product will be 157464.0, which exceeds max(=100000). I0812 17:25:39.808730 139930050549568 make_examples_core.py:301] Task 19/20: 130009 candidates (5415 examples) [19.65s elapsed]. I0812 17:25:40.161706 140719761319744 make_examples_core.py:301] Task 1/20: 130009 candidates (5656 examples) [26.55s elapsed]. I0812 17:25:39.762312 140656897058624 haplotype_labeler.py:449] Not including more because genotype_options_product will be 118098.0, which exceeds max(=100000). I0812 17:25:40.178942 139929751582528 haplotype_labeler.py:449] Not including more because genotype_options_product will be 118098.0, which exceeds max(=100000). I0812 17:25:41.815151 139685487241024 make_examples_core.py:301] Task 8/20: 134010 candidates (5603 examples) [20.32s elapsed]. I0812 17:25:42.062644 140656897058624 make_examples_core.py:301] Task 14/20: 130007 candidates (5538 examples) [26.62s elapsed]. I0812 17:25:42.944558 139916975953728 haplotype_labeler.py:449] Not including more because genotype_options_product will be 157464.0, which exceeds max(=100000). I0812 17:25:42.945389 139916975953728 haplotype_labeler.py:449] Not including more because genotype_options_product will be 944784.0, which exceeds max(=100000). I0812 17:25:42.940323 140366879631168 make_examples_core.py:301] Task 6/20: 132005 candidates (5726 examples) [25.32s elapsed]. I0812 17:25:43.504171 139929751582528 make_examples_core.py:301] Task 4/20: 132003 candidates (5481 examples) [23.80s elapsed]. I0812 17:25:43.563577 140585679",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:88,security,log,log,88,"@DanJeffries, sorry for the late reply I was traveling for a conference. Looking at the log, most of it looks like this:. ```bash. I0812 17:25:36.970339 140640080795456 make_examples_core.py:301] Task 18/20: 130000 candidates (5465 examples) [24.32s elapsed]. I0812 17:25:38.358597 140641138153280 make_examples_core.py:301] Task 17/20: 136011 candidates (5980 examples) [24.30s elapsed]. I0812 17:25:38.452311 140719761319744 haplotype_labeler.py:449] Not including more because genotype_options_product will be 157464.0, which exceeds max(=100000). I0812 17:25:39.808730 139930050549568 make_examples_core.py:301] Task 19/20: 130009 candidates (5415 examples) [19.65s elapsed]. I0812 17:25:40.161706 140719761319744 make_examples_core.py:301] Task 1/20: 130009 candidates (5656 examples) [26.55s elapsed]. I0812 17:25:39.762312 140656897058624 haplotype_labeler.py:449] Not including more because genotype_options_product will be 118098.0, which exceeds max(=100000). I0812 17:25:40.178942 139929751582528 haplotype_labeler.py:449] Not including more because genotype_options_product will be 118098.0, which exceeds max(=100000). I0812 17:25:41.815151 139685487241024 make_examples_core.py:301] Task 8/20: 134010 candidates (5603 examples) [20.32s elapsed]. I0812 17:25:42.062644 140656897058624 make_examples_core.py:301] Task 14/20: 130007 candidates (5538 examples) [26.62s elapsed]. I0812 17:25:42.944558 139916975953728 haplotype_labeler.py:449] Not including more because genotype_options_product will be 157464.0, which exceeds max(=100000). I0812 17:25:42.945389 139916975953728 haplotype_labeler.py:449] Not including more because genotype_options_product will be 944784.0, which exceeds max(=100000). I0812 17:25:42.940323 140366879631168 make_examples_core.py:301] Task 6/20: 132005 candidates (5726 examples) [25.32s elapsed]. I0812 17:25:43.504171 139929751582528 make_examples_core.py:301] Task 4/20: 132003 candidates (5481 examples) [23.80s elapsed]. I0812 17:25:43.563577 140585679",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:88,testability,log,log,88,"@DanJeffries, sorry for the late reply I was traveling for a conference. Looking at the log, most of it looks like this:. ```bash. I0812 17:25:36.970339 140640080795456 make_examples_core.py:301] Task 18/20: 130000 candidates (5465 examples) [24.32s elapsed]. I0812 17:25:38.358597 140641138153280 make_examples_core.py:301] Task 17/20: 136011 candidates (5980 examples) [24.30s elapsed]. I0812 17:25:38.452311 140719761319744 haplotype_labeler.py:449] Not including more because genotype_options_product will be 157464.0, which exceeds max(=100000). I0812 17:25:39.808730 139930050549568 make_examples_core.py:301] Task 19/20: 130009 candidates (5415 examples) [19.65s elapsed]. I0812 17:25:40.161706 140719761319744 make_examples_core.py:301] Task 1/20: 130009 candidates (5656 examples) [26.55s elapsed]. I0812 17:25:39.762312 140656897058624 haplotype_labeler.py:449] Not including more because genotype_options_product will be 118098.0, which exceeds max(=100000). I0812 17:25:40.178942 139929751582528 haplotype_labeler.py:449] Not including more because genotype_options_product will be 118098.0, which exceeds max(=100000). I0812 17:25:41.815151 139685487241024 make_examples_core.py:301] Task 8/20: 134010 candidates (5603 examples) [20.32s elapsed]. I0812 17:25:42.062644 140656897058624 make_examples_core.py:301] Task 14/20: 130007 candidates (5538 examples) [26.62s elapsed]. I0812 17:25:42.944558 139916975953728 haplotype_labeler.py:449] Not including more because genotype_options_product will be 157464.0, which exceeds max(=100000). I0812 17:25:42.945389 139916975953728 haplotype_labeler.py:449] Not including more because genotype_options_product will be 944784.0, which exceeds max(=100000). I0812 17:25:42.940323 140366879631168 make_examples_core.py:301] Task 6/20: 132005 candidates (5726 examples) [25.32s elapsed]. I0812 17:25:43.504171 139929751582528 make_examples_core.py:301] Task 4/20: 132003 candidates (5481 examples) [23.80s elapsed]. I0812 17:25:43.563577 140585679",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:990,availability,down,downsampling,990,"Hi @kishwarshafin ,. No worries, thanks for finding the time to get back to me! And thanks for the explanation - I had read that line in the log file ""Not including more"", as it is including some. . So the truth data is generated from the offspring of 5 trios. Variants for the parents and offspring were called (using GATK4) against a reference, mendelian expectations were checked for each locus, and the loci that passed that check, as well as some hard filters (e.g. depth, GQ etc), were kept for the truth set. . The variants in the truth set are the combination of all the variants that passed these filters in all 5 trios, which amounts to around 450,000 variants (split into ~350k training, and ~100k for tuning). The reference is from a different population which which will probably result in more hom_alt SNPs against the ref, but other than that, I don't think this number of SNPs is particularly high for a 400Mb genome of a wild fish with relatively large pop sizes. The 0.5x downsampling of course doubles this number, resulting in ~900,000 truth vars in total. . So, could a solution be to increase the maximum for genotype_options_product? Or would you suggest subsampling the truth variants? . Thanks! Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:141,deployability,log,log,141,"Hi @kishwarshafin ,. No worries, thanks for finding the time to get back to me! And thanks for the explanation - I had read that line in the log file ""Not including more"", as it is including some. . So the truth data is generated from the offspring of 5 trios. Variants for the parents and offspring were called (using GATK4) against a reference, mendelian expectations were checked for each locus, and the loci that passed that check, as well as some hard filters (e.g. depth, GQ etc), were kept for the truth set. . The variants in the truth set are the combination of all the variants that passed these filters in all 5 trios, which amounts to around 450,000 variants (split into ~350k training, and ~100k for tuning). The reference is from a different population which which will probably result in more hom_alt SNPs against the ref, but other than that, I don't think this number of SNPs is particularly high for a 400Mb genome of a wild fish with relatively large pop sizes. The 0.5x downsampling of course doubles this number, resulting in ~900,000 truth vars in total. . So, could a solution be to increase the maximum for genotype_options_product? Or would you suggest subsampling the truth variants? . Thanks! Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:457,integrability,filter,filters,457,"Hi @kishwarshafin ,. No worries, thanks for finding the time to get back to me! And thanks for the explanation - I had read that line in the log file ""Not including more"", as it is including some. . So the truth data is generated from the offspring of 5 trios. Variants for the parents and offspring were called (using GATK4) against a reference, mendelian expectations were checked for each locus, and the loci that passed that check, as well as some hard filters (e.g. depth, GQ etc), were kept for the truth set. . The variants in the truth set are the combination of all the variants that passed these filters in all 5 trios, which amounts to around 450,000 variants (split into ~350k training, and ~100k for tuning). The reference is from a different population which which will probably result in more hom_alt SNPs against the ref, but other than that, I don't think this number of SNPs is particularly high for a 400Mb genome of a wild fish with relatively large pop sizes. The 0.5x downsampling of course doubles this number, resulting in ~900,000 truth vars in total. . So, could a solution be to increase the maximum for genotype_options_product? Or would you suggest subsampling the truth variants? . Thanks! Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:606,integrability,filter,filters,606,"Hi @kishwarshafin ,. No worries, thanks for finding the time to get back to me! And thanks for the explanation - I had read that line in the log file ""Not including more"", as it is including some. . So the truth data is generated from the offspring of 5 trios. Variants for the parents and offspring were called (using GATK4) against a reference, mendelian expectations were checked for each locus, and the loci that passed that check, as well as some hard filters (e.g. depth, GQ etc), were kept for the truth set. . The variants in the truth set are the combination of all the variants that passed these filters in all 5 trios, which amounts to around 450,000 variants (split into ~350k training, and ~100k for tuning). The reference is from a different population which which will probably result in more hom_alt SNPs against the ref, but other than that, I don't think this number of SNPs is particularly high for a 400Mb genome of a wild fish with relatively large pop sizes. The 0.5x downsampling of course doubles this number, resulting in ~900,000 truth vars in total. . So, could a solution be to increase the maximum for genotype_options_product? Or would you suggest subsampling the truth variants? . Thanks! Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:1178,integrability,sub,subsampling,1178,"Hi @kishwarshafin ,. No worries, thanks for finding the time to get back to me! And thanks for the explanation - I had read that line in the log file ""Not including more"", as it is including some. . So the truth data is generated from the offspring of 5 trios. Variants for the parents and offspring were called (using GATK4) against a reference, mendelian expectations were checked for each locus, and the loci that passed that check, as well as some hard filters (e.g. depth, GQ etc), were kept for the truth set. . The variants in the truth set are the combination of all the variants that passed these filters in all 5 trios, which amounts to around 450,000 variants (split into ~350k training, and ~100k for tuning). The reference is from a different population which which will probably result in more hom_alt SNPs against the ref, but other than that, I don't think this number of SNPs is particularly high for a 400Mb genome of a wild fish with relatively large pop sizes. The 0.5x downsampling of course doubles this number, resulting in ~900,000 truth vars in total. . So, could a solution be to increase the maximum for genotype_options_product? Or would you suggest subsampling the truth variants? . Thanks! Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:56,performance,time,time,56,"Hi @kishwarshafin ,. No worries, thanks for finding the time to get back to me! And thanks for the explanation - I had read that line in the log file ""Not including more"", as it is including some. . So the truth data is generated from the offspring of 5 trios. Variants for the parents and offspring were called (using GATK4) against a reference, mendelian expectations were checked for each locus, and the loci that passed that check, as well as some hard filters (e.g. depth, GQ etc), were kept for the truth set. . The variants in the truth set are the combination of all the variants that passed these filters in all 5 trios, which amounts to around 450,000 variants (split into ~350k training, and ~100k for tuning). The reference is from a different population which which will probably result in more hom_alt SNPs against the ref, but other than that, I don't think this number of SNPs is particularly high for a 400Mb genome of a wild fish with relatively large pop sizes. The 0.5x downsampling of course doubles this number, resulting in ~900,000 truth vars in total. . So, could a solution be to increase the maximum for genotype_options_product? Or would you suggest subsampling the truth variants? . Thanks! Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:141,safety,log,log,141,"Hi @kishwarshafin ,. No worries, thanks for finding the time to get back to me! And thanks for the explanation - I had read that line in the log file ""Not including more"", as it is including some. . So the truth data is generated from the offspring of 5 trios. Variants for the parents and offspring were called (using GATK4) against a reference, mendelian expectations were checked for each locus, and the loci that passed that check, as well as some hard filters (e.g. depth, GQ etc), were kept for the truth set. . The variants in the truth set are the combination of all the variants that passed these filters in all 5 trios, which amounts to around 450,000 variants (split into ~350k training, and ~100k for tuning). The reference is from a different population which which will probably result in more hom_alt SNPs against the ref, but other than that, I don't think this number of SNPs is particularly high for a 400Mb genome of a wild fish with relatively large pop sizes. The 0.5x downsampling of course doubles this number, resulting in ~900,000 truth vars in total. . So, could a solution be to increase the maximum for genotype_options_product? Or would you suggest subsampling the truth variants? . Thanks! Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:141,security,log,log,141,"Hi @kishwarshafin ,. No worries, thanks for finding the time to get back to me! And thanks for the explanation - I had read that line in the log file ""Not including more"", as it is including some. . So the truth data is generated from the offspring of 5 trios. Variants for the parents and offspring were called (using GATK4) against a reference, mendelian expectations were checked for each locus, and the loci that passed that check, as well as some hard filters (e.g. depth, GQ etc), were kept for the truth set. . The variants in the truth set are the combination of all the variants that passed these filters in all 5 trios, which amounts to around 450,000 variants (split into ~350k training, and ~100k for tuning). The reference is from a different population which which will probably result in more hom_alt SNPs against the ref, but other than that, I don't think this number of SNPs is particularly high for a 400Mb genome of a wild fish with relatively large pop sizes. The 0.5x downsampling of course doubles this number, resulting in ~900,000 truth vars in total. . So, could a solution be to increase the maximum for genotype_options_product? Or would you suggest subsampling the truth variants? . Thanks! Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:141,testability,log,log,141,"Hi @kishwarshafin ,. No worries, thanks for finding the time to get back to me! And thanks for the explanation - I had read that line in the log file ""Not including more"", as it is including some. . So the truth data is generated from the offspring of 5 trios. Variants for the parents and offspring were called (using GATK4) against a reference, mendelian expectations were checked for each locus, and the loci that passed that check, as well as some hard filters (e.g. depth, GQ etc), were kept for the truth set. . The variants in the truth set are the combination of all the variants that passed these filters in all 5 trios, which amounts to around 450,000 variants (split into ~350k training, and ~100k for tuning). The reference is from a different population which which will probably result in more hom_alt SNPs against the ref, but other than that, I don't think this number of SNPs is particularly high for a 400Mb genome of a wild fish with relatively large pop sizes. The 0.5x downsampling of course doubles this number, resulting in ~900,000 truth vars in total. . So, could a solution be to increase the maximum for genotype_options_product? Or would you suggest subsampling the truth variants? . Thanks! Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:73,usability,command,command,73,"Hi @DanJeffries ,. To start with, can you add this to your make_examples command and see if it helps:. ```bash. --labeler_algorithm=positional_labeler \. ```. This should switch the labeling from haplotype to positional and it should solve this issue. Let me know if this works.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:95,usability,help,helps,95,"Hi @DanJeffries ,. To start with, can you add this to your make_examples command and see if it helps:. ```bash. --labeler_algorithm=positional_labeler \. ```. This should switch the labeling from haplotype to positional and it should solve this issue. Let me know if this works.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:194,deployability,fail,failed,194,"Hi @kishwarshafin ,. I made the change you suggested. It didn't fix the issue, however you did help point me to the real cause. It turns out that when I created the confident regions bed file I failed to include the positions of the variants (only confident hom_ref positions). Having gone back and added these positions, examples now contain all 3 classes of site. . One last question - given that the labeler was not the issue, should I switch back to using the haplotype aware labeller? I read somewhere that this is the better approach, though I am not sure why that is. . Once I have heard from you on this last point I'll close the issue. . Thanks. Dan.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:335,deployability,contain,contain,335,"Hi @kishwarshafin ,. I made the change you suggested. It didn't fix the issue, however you did help point me to the real cause. It turns out that when I created the confident regions bed file I failed to include the positions of the variants (only confident hom_ref positions). Having gone back and added these positions, examples now contain all 3 classes of site. . One last question - given that the labeler was not the issue, should I switch back to using the haplotype aware labeller? I read somewhere that this is the better approach, though I am not sure why that is. . Once I have heard from you on this last point I'll close the issue. . Thanks. Dan.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:194,reliability,fail,failed,194,"Hi @kishwarshafin ,. I made the change you suggested. It didn't fix the issue, however you did help point me to the real cause. It turns out that when I created the confident regions bed file I failed to include the positions of the variants (only confident hom_ref positions). Having gone back and added these positions, examples now contain all 3 classes of site. . One last question - given that the labeler was not the issue, should I switch back to using the haplotype aware labeller? I read somewhere that this is the better approach, though I am not sure why that is. . Once I have heard from you on this last point I'll close the issue. . Thanks. Dan.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:95,usability,help,help,95,"Hi @kishwarshafin ,. I made the change you suggested. It didn't fix the issue, however you did help point me to the real cause. It turns out that when I created the confident regions bed file I failed to include the positions of the variants (only confident hom_ref positions). Having gone back and added these positions, examples now contain all 3 classes of site. . One last question - given that the labeler was not the issue, should I switch back to using the haplotype aware labeller? I read somewhere that this is the better approach, though I am not sure why that is. . Once I have heard from you on this last point I'll close the issue. . Thanks. Dan.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:628,usability,close,close,628,"Hi @kishwarshafin ,. I made the change you suggested. It didn't fix the issue, however you did help point me to the real cause. It turns out that when I created the confident regions bed file I failed to include the positions of the variants (only confident hom_ref positions). Having gone back and added these positions, examples now contain all 3 classes of site. . One last question - given that the labeler was not the issue, should I switch back to using the haplotype aware labeller? I read somewhere that this is the better approach, though I am not sure why that is. . Once I have heard from you on this last point I'll close the issue. . Thanks. Dan.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:112,deployability,observ,observe,112,"Glad you figured it out! So, `haplotype_labler` is very good for labeling INDELs specially in regions where you observe global alignment jitter. On the other hand, SNPs usually get placed at the correct position almost every time so with positional_labler you will see more SNPs correctly annotated. There's pros and cons to both, but, given you have SO MANY SNP variants, I think I'd try positional_labler for this use-case if I were you given how sophisticated haplotype_labler is and it will not annotate in many variant dense regions. But, you are welcome to try them both, usually the difference should be minimal. Sorry for the vaguest answer, but there's no correct answer here. Hope your training goes well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:225,performance,time,time,225,"Glad you figured it out! So, `haplotype_labler` is very good for labeling INDELs specially in regions where you observe global alignment jitter. On the other hand, SNPs usually get placed at the correct position almost every time so with positional_labler you will see more SNPs correctly annotated. There's pros and cons to both, but, given you have SO MANY SNP variants, I think I'd try positional_labler for this use-case if I were you given how sophisticated haplotype_labler is and it will not annotate in many variant dense regions. But, you are welcome to try them both, usually the difference should be minimal. Sorry for the vaguest answer, but there's no correct answer here. Hope your training goes well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:112,testability,observ,observe,112,"Glad you figured it out! So, `haplotype_labler` is very good for labeling INDELs specially in regions where you observe global alignment jitter. On the other hand, SNPs usually get placed at the correct position almost every time so with positional_labler you will see more SNPs correctly annotated. There's pros and cons to both, but, given you have SO MANY SNP variants, I think I'd try positional_labler for this use-case if I were you given how sophisticated haplotype_labler is and it will not annotate in many variant dense regions. But, you are welcome to try them both, usually the difference should be minimal. Sorry for the vaguest answer, but there's no correct answer here. Hope your training goes well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:611,usability,minim,minimal,611,"Glad you figured it out! So, `haplotype_labler` is very good for labeling INDELs specially in regions where you observe global alignment jitter. On the other hand, SNPs usually get placed at the correct position almost every time so with positional_labler you will see more SNPs correctly annotated. There's pros and cons to both, but, given you have SO MANY SNP variants, I think I'd try positional_labler for this use-case if I were you given how sophisticated haplotype_labler is and it will not annotate in many variant dense regions. But, you are welcome to try them both, usually the difference should be minimal. Sorry for the vaguest answer, but there's no correct answer here. Hope your training goes well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:269,availability,error,error,269,"Hi @kishwarshafin,. Ok thanks for the explanation. . Unfortunately, I am still having trouble. For some reason when I use positional_labeler my make_examples jobs fail. But they complete successfully using haplotype_labeler. I can't figure out what the issue is as the error message isn't particularly informative, at least not to me. I attach two log files from the make_examples step. Both are for the same sample, the only difference is that one uses haplotype_labeler (job succeeded) and the other uses positional_labeler (job failed). . It would be great to get your opinion on what is going on. Note that I have tested positional labeler a few times and it does seem to work for one sample, but there is no reason this sample should be distinct from the others. . haplotype_labeler:. [MAKE_EX_TRAIN_NEW_4926611-3.err.gz](https://github.com/user-attachments/files/16974777/MAKE_EX_TRAIN_NEW_4926611-3.err.gz). positional_labeler:. [MAKE_EX_TRAIN_NEW_4930167-3.err.gz](https://github.com/user-attachments/files/16974781/MAKE_EX_TRAIN_NEW_4930167-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:163,deployability,fail,fail,163,"Hi @kishwarshafin,. Ok thanks for the explanation. . Unfortunately, I am still having trouble. For some reason when I use positional_labeler my make_examples jobs fail. But they complete successfully using haplotype_labeler. I can't figure out what the issue is as the error message isn't particularly informative, at least not to me. I attach two log files from the make_examples step. Both are for the same sample, the only difference is that one uses haplotype_labeler (job succeeded) and the other uses positional_labeler (job failed). . It would be great to get your opinion on what is going on. Note that I have tested positional labeler a few times and it does seem to work for one sample, but there is no reason this sample should be distinct from the others. . haplotype_labeler:. [MAKE_EX_TRAIN_NEW_4926611-3.err.gz](https://github.com/user-attachments/files/16974777/MAKE_EX_TRAIN_NEW_4926611-3.err.gz). positional_labeler:. [MAKE_EX_TRAIN_NEW_4930167-3.err.gz](https://github.com/user-attachments/files/16974781/MAKE_EX_TRAIN_NEW_4930167-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:348,deployability,log,log,348,"Hi @kishwarshafin,. Ok thanks for the explanation. . Unfortunately, I am still having trouble. For some reason when I use positional_labeler my make_examples jobs fail. But they complete successfully using haplotype_labeler. I can't figure out what the issue is as the error message isn't particularly informative, at least not to me. I attach two log files from the make_examples step. Both are for the same sample, the only difference is that one uses haplotype_labeler (job succeeded) and the other uses positional_labeler (job failed). . It would be great to get your opinion on what is going on. Note that I have tested positional labeler a few times and it does seem to work for one sample, but there is no reason this sample should be distinct from the others. . haplotype_labeler:. [MAKE_EX_TRAIN_NEW_4926611-3.err.gz](https://github.com/user-attachments/files/16974777/MAKE_EX_TRAIN_NEW_4926611-3.err.gz). positional_labeler:. [MAKE_EX_TRAIN_NEW_4930167-3.err.gz](https://github.com/user-attachments/files/16974781/MAKE_EX_TRAIN_NEW_4930167-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:531,deployability,fail,failed,531,"Hi @kishwarshafin,. Ok thanks for the explanation. . Unfortunately, I am still having trouble. For some reason when I use positional_labeler my make_examples jobs fail. But they complete successfully using haplotype_labeler. I can't figure out what the issue is as the error message isn't particularly informative, at least not to me. I attach two log files from the make_examples step. Both are for the same sample, the only difference is that one uses haplotype_labeler (job succeeded) and the other uses positional_labeler (job failed). . It would be great to get your opinion on what is going on. Note that I have tested positional labeler a few times and it does seem to work for one sample, but there is no reason this sample should be distinct from the others. . haplotype_labeler:. [MAKE_EX_TRAIN_NEW_4926611-3.err.gz](https://github.com/user-attachments/files/16974777/MAKE_EX_TRAIN_NEW_4926611-3.err.gz). positional_labeler:. [MAKE_EX_TRAIN_NEW_4930167-3.err.gz](https://github.com/user-attachments/files/16974781/MAKE_EX_TRAIN_NEW_4930167-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:275,integrability,messag,message,275,"Hi @kishwarshafin,. Ok thanks for the explanation. . Unfortunately, I am still having trouble. For some reason when I use positional_labeler my make_examples jobs fail. But they complete successfully using haplotype_labeler. I can't figure out what the issue is as the error message isn't particularly informative, at least not to me. I attach two log files from the make_examples step. Both are for the same sample, the only difference is that one uses haplotype_labeler (job succeeded) and the other uses positional_labeler (job failed). . It would be great to get your opinion on what is going on. Note that I have tested positional labeler a few times and it does seem to work for one sample, but there is no reason this sample should be distinct from the others. . haplotype_labeler:. [MAKE_EX_TRAIN_NEW_4926611-3.err.gz](https://github.com/user-attachments/files/16974777/MAKE_EX_TRAIN_NEW_4926611-3.err.gz). positional_labeler:. [MAKE_EX_TRAIN_NEW_4930167-3.err.gz](https://github.com/user-attachments/files/16974781/MAKE_EX_TRAIN_NEW_4930167-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:275,interoperability,messag,message,275,"Hi @kishwarshafin,. Ok thanks for the explanation. . Unfortunately, I am still having trouble. For some reason when I use positional_labeler my make_examples jobs fail. But they complete successfully using haplotype_labeler. I can't figure out what the issue is as the error message isn't particularly informative, at least not to me. I attach two log files from the make_examples step. Both are for the same sample, the only difference is that one uses haplotype_labeler (job succeeded) and the other uses positional_labeler (job failed). . It would be great to get your opinion on what is going on. Note that I have tested positional labeler a few times and it does seem to work for one sample, but there is no reason this sample should be distinct from the others. . haplotype_labeler:. [MAKE_EX_TRAIN_NEW_4926611-3.err.gz](https://github.com/user-attachments/files/16974777/MAKE_EX_TRAIN_NEW_4926611-3.err.gz). positional_labeler:. [MAKE_EX_TRAIN_NEW_4930167-3.err.gz](https://github.com/user-attachments/files/16974781/MAKE_EX_TRAIN_NEW_4930167-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:269,performance,error,error,269,"Hi @kishwarshafin,. Ok thanks for the explanation. . Unfortunately, I am still having trouble. For some reason when I use positional_labeler my make_examples jobs fail. But they complete successfully using haplotype_labeler. I can't figure out what the issue is as the error message isn't particularly informative, at least not to me. I attach two log files from the make_examples step. Both are for the same sample, the only difference is that one uses haplotype_labeler (job succeeded) and the other uses positional_labeler (job failed). . It would be great to get your opinion on what is going on. Note that I have tested positional labeler a few times and it does seem to work for one sample, but there is no reason this sample should be distinct from the others. . haplotype_labeler:. [MAKE_EX_TRAIN_NEW_4926611-3.err.gz](https://github.com/user-attachments/files/16974777/MAKE_EX_TRAIN_NEW_4926611-3.err.gz). positional_labeler:. [MAKE_EX_TRAIN_NEW_4930167-3.err.gz](https://github.com/user-attachments/files/16974781/MAKE_EX_TRAIN_NEW_4930167-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:650,performance,time,times,650,"Hi @kishwarshafin,. Ok thanks for the explanation. . Unfortunately, I am still having trouble. For some reason when I use positional_labeler my make_examples jobs fail. But they complete successfully using haplotype_labeler. I can't figure out what the issue is as the error message isn't particularly informative, at least not to me. I attach two log files from the make_examples step. Both are for the same sample, the only difference is that one uses haplotype_labeler (job succeeded) and the other uses positional_labeler (job failed). . It would be great to get your opinion on what is going on. Note that I have tested positional labeler a few times and it does seem to work for one sample, but there is no reason this sample should be distinct from the others. . haplotype_labeler:. [MAKE_EX_TRAIN_NEW_4926611-3.err.gz](https://github.com/user-attachments/files/16974777/MAKE_EX_TRAIN_NEW_4926611-3.err.gz). positional_labeler:. [MAKE_EX_TRAIN_NEW_4930167-3.err.gz](https://github.com/user-attachments/files/16974781/MAKE_EX_TRAIN_NEW_4930167-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:163,reliability,fail,fail,163,"Hi @kishwarshafin,. Ok thanks for the explanation. . Unfortunately, I am still having trouble. For some reason when I use positional_labeler my make_examples jobs fail. But they complete successfully using haplotype_labeler. I can't figure out what the issue is as the error message isn't particularly informative, at least not to me. I attach two log files from the make_examples step. Both are for the same sample, the only difference is that one uses haplotype_labeler (job succeeded) and the other uses positional_labeler (job failed). . It would be great to get your opinion on what is going on. Note that I have tested positional labeler a few times and it does seem to work for one sample, but there is no reason this sample should be distinct from the others. . haplotype_labeler:. [MAKE_EX_TRAIN_NEW_4926611-3.err.gz](https://github.com/user-attachments/files/16974777/MAKE_EX_TRAIN_NEW_4926611-3.err.gz). positional_labeler:. [MAKE_EX_TRAIN_NEW_4930167-3.err.gz](https://github.com/user-attachments/files/16974781/MAKE_EX_TRAIN_NEW_4930167-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:531,reliability,fail,failed,531,"Hi @kishwarshafin,. Ok thanks for the explanation. . Unfortunately, I am still having trouble. For some reason when I use positional_labeler my make_examples jobs fail. But they complete successfully using haplotype_labeler. I can't figure out what the issue is as the error message isn't particularly informative, at least not to me. I attach two log files from the make_examples step. Both are for the same sample, the only difference is that one uses haplotype_labeler (job succeeded) and the other uses positional_labeler (job failed). . It would be great to get your opinion on what is going on. Note that I have tested positional labeler a few times and it does seem to work for one sample, but there is no reason this sample should be distinct from the others. . haplotype_labeler:. [MAKE_EX_TRAIN_NEW_4926611-3.err.gz](https://github.com/user-attachments/files/16974777/MAKE_EX_TRAIN_NEW_4926611-3.err.gz). positional_labeler:. [MAKE_EX_TRAIN_NEW_4930167-3.err.gz](https://github.com/user-attachments/files/16974781/MAKE_EX_TRAIN_NEW_4930167-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:663,reliability,doe,does,663,"Hi @kishwarshafin,. Ok thanks for the explanation. . Unfortunately, I am still having trouble. For some reason when I use positional_labeler my make_examples jobs fail. But they complete successfully using haplotype_labeler. I can't figure out what the issue is as the error message isn't particularly informative, at least not to me. I attach two log files from the make_examples step. Both are for the same sample, the only difference is that one uses haplotype_labeler (job succeeded) and the other uses positional_labeler (job failed). . It would be great to get your opinion on what is going on. Note that I have tested positional labeler a few times and it does seem to work for one sample, but there is no reason this sample should be distinct from the others. . haplotype_labeler:. [MAKE_EX_TRAIN_NEW_4926611-3.err.gz](https://github.com/user-attachments/files/16974777/MAKE_EX_TRAIN_NEW_4926611-3.err.gz). positional_labeler:. [MAKE_EX_TRAIN_NEW_4930167-3.err.gz](https://github.com/user-attachments/files/16974781/MAKE_EX_TRAIN_NEW_4930167-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:178,safety,compl,complete,178,"Hi @kishwarshafin,. Ok thanks for the explanation. . Unfortunately, I am still having trouble. For some reason when I use positional_labeler my make_examples jobs fail. But they complete successfully using haplotype_labeler. I can't figure out what the issue is as the error message isn't particularly informative, at least not to me. I attach two log files from the make_examples step. Both are for the same sample, the only difference is that one uses haplotype_labeler (job succeeded) and the other uses positional_labeler (job failed). . It would be great to get your opinion on what is going on. Note that I have tested positional labeler a few times and it does seem to work for one sample, but there is no reason this sample should be distinct from the others. . haplotype_labeler:. [MAKE_EX_TRAIN_NEW_4926611-3.err.gz](https://github.com/user-attachments/files/16974777/MAKE_EX_TRAIN_NEW_4926611-3.err.gz). positional_labeler:. [MAKE_EX_TRAIN_NEW_4930167-3.err.gz](https://github.com/user-attachments/files/16974781/MAKE_EX_TRAIN_NEW_4930167-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:269,safety,error,error,269,"Hi @kishwarshafin,. Ok thanks for the explanation. . Unfortunately, I am still having trouble. For some reason when I use positional_labeler my make_examples jobs fail. But they complete successfully using haplotype_labeler. I can't figure out what the issue is as the error message isn't particularly informative, at least not to me. I attach two log files from the make_examples step. Both are for the same sample, the only difference is that one uses haplotype_labeler (job succeeded) and the other uses positional_labeler (job failed). . It would be great to get your opinion on what is going on. Note that I have tested positional labeler a few times and it does seem to work for one sample, but there is no reason this sample should be distinct from the others. . haplotype_labeler:. [MAKE_EX_TRAIN_NEW_4926611-3.err.gz](https://github.com/user-attachments/files/16974777/MAKE_EX_TRAIN_NEW_4926611-3.err.gz). positional_labeler:. [MAKE_EX_TRAIN_NEW_4930167-3.err.gz](https://github.com/user-attachments/files/16974781/MAKE_EX_TRAIN_NEW_4930167-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:348,safety,log,log,348,"Hi @kishwarshafin,. Ok thanks for the explanation. . Unfortunately, I am still having trouble. For some reason when I use positional_labeler my make_examples jobs fail. But they complete successfully using haplotype_labeler. I can't figure out what the issue is as the error message isn't particularly informative, at least not to me. I attach two log files from the make_examples step. Both are for the same sample, the only difference is that one uses haplotype_labeler (job succeeded) and the other uses positional_labeler (job failed). . It would be great to get your opinion on what is going on. Note that I have tested positional labeler a few times and it does seem to work for one sample, but there is no reason this sample should be distinct from the others. . haplotype_labeler:. [MAKE_EX_TRAIN_NEW_4926611-3.err.gz](https://github.com/user-attachments/files/16974777/MAKE_EX_TRAIN_NEW_4926611-3.err.gz). positional_labeler:. [MAKE_EX_TRAIN_NEW_4930167-3.err.gz](https://github.com/user-attachments/files/16974781/MAKE_EX_TRAIN_NEW_4930167-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:618,safety,test,tested,618,"Hi @kishwarshafin,. Ok thanks for the explanation. . Unfortunately, I am still having trouble. For some reason when I use positional_labeler my make_examples jobs fail. But they complete successfully using haplotype_labeler. I can't figure out what the issue is as the error message isn't particularly informative, at least not to me. I attach two log files from the make_examples step. Both are for the same sample, the only difference is that one uses haplotype_labeler (job succeeded) and the other uses positional_labeler (job failed). . It would be great to get your opinion on what is going on. Note that I have tested positional labeler a few times and it does seem to work for one sample, but there is no reason this sample should be distinct from the others. . haplotype_labeler:. [MAKE_EX_TRAIN_NEW_4926611-3.err.gz](https://github.com/user-attachments/files/16974777/MAKE_EX_TRAIN_NEW_4926611-3.err.gz). positional_labeler:. [MAKE_EX_TRAIN_NEW_4930167-3.err.gz](https://github.com/user-attachments/files/16974781/MAKE_EX_TRAIN_NEW_4930167-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:178,security,compl,complete,178,"Hi @kishwarshafin,. Ok thanks for the explanation. . Unfortunately, I am still having trouble. For some reason when I use positional_labeler my make_examples jobs fail. But they complete successfully using haplotype_labeler. I can't figure out what the issue is as the error message isn't particularly informative, at least not to me. I attach two log files from the make_examples step. Both are for the same sample, the only difference is that one uses haplotype_labeler (job succeeded) and the other uses positional_labeler (job failed). . It would be great to get your opinion on what is going on. Note that I have tested positional labeler a few times and it does seem to work for one sample, but there is no reason this sample should be distinct from the others. . haplotype_labeler:. [MAKE_EX_TRAIN_NEW_4926611-3.err.gz](https://github.com/user-attachments/files/16974777/MAKE_EX_TRAIN_NEW_4926611-3.err.gz). positional_labeler:. [MAKE_EX_TRAIN_NEW_4930167-3.err.gz](https://github.com/user-attachments/files/16974781/MAKE_EX_TRAIN_NEW_4930167-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:348,security,log,log,348,"Hi @kishwarshafin,. Ok thanks for the explanation. . Unfortunately, I am still having trouble. For some reason when I use positional_labeler my make_examples jobs fail. But they complete successfully using haplotype_labeler. I can't figure out what the issue is as the error message isn't particularly informative, at least not to me. I attach two log files from the make_examples step. Both are for the same sample, the only difference is that one uses haplotype_labeler (job succeeded) and the other uses positional_labeler (job failed). . It would be great to get your opinion on what is going on. Note that I have tested positional labeler a few times and it does seem to work for one sample, but there is no reason this sample should be distinct from the others. . haplotype_labeler:. [MAKE_EX_TRAIN_NEW_4926611-3.err.gz](https://github.com/user-attachments/files/16974777/MAKE_EX_TRAIN_NEW_4926611-3.err.gz). positional_labeler:. [MAKE_EX_TRAIN_NEW_4930167-3.err.gz](https://github.com/user-attachments/files/16974781/MAKE_EX_TRAIN_NEW_4930167-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:348,testability,log,log,348,"Hi @kishwarshafin,. Ok thanks for the explanation. . Unfortunately, I am still having trouble. For some reason when I use positional_labeler my make_examples jobs fail. But they complete successfully using haplotype_labeler. I can't figure out what the issue is as the error message isn't particularly informative, at least not to me. I attach two log files from the make_examples step. Both are for the same sample, the only difference is that one uses haplotype_labeler (job succeeded) and the other uses positional_labeler (job failed). . It would be great to get your opinion on what is going on. Note that I have tested positional labeler a few times and it does seem to work for one sample, but there is no reason this sample should be distinct from the others. . haplotype_labeler:. [MAKE_EX_TRAIN_NEW_4926611-3.err.gz](https://github.com/user-attachments/files/16974777/MAKE_EX_TRAIN_NEW_4926611-3.err.gz). positional_labeler:. [MAKE_EX_TRAIN_NEW_4930167-3.err.gz](https://github.com/user-attachments/files/16974781/MAKE_EX_TRAIN_NEW_4930167-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:618,testability,test,tested,618,"Hi @kishwarshafin,. Ok thanks for the explanation. . Unfortunately, I am still having trouble. For some reason when I use positional_labeler my make_examples jobs fail. But they complete successfully using haplotype_labeler. I can't figure out what the issue is as the error message isn't particularly informative, at least not to me. I attach two log files from the make_examples step. Both are for the same sample, the only difference is that one uses haplotype_labeler (job succeeded) and the other uses positional_labeler (job failed). . It would be great to get your opinion on what is going on. Note that I have tested positional labeler a few times and it does seem to work for one sample, but there is no reason this sample should be distinct from the others. . haplotype_labeler:. [MAKE_EX_TRAIN_NEW_4926611-3.err.gz](https://github.com/user-attachments/files/16974777/MAKE_EX_TRAIN_NEW_4926611-3.err.gz). positional_labeler:. [MAKE_EX_TRAIN_NEW_4930167-3.err.gz](https://github.com/user-attachments/files/16974781/MAKE_EX_TRAIN_NEW_4930167-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:269,usability,error,error,269,"Hi @kishwarshafin,. Ok thanks for the explanation. . Unfortunately, I am still having trouble. For some reason when I use positional_labeler my make_examples jobs fail. But they complete successfully using haplotype_labeler. I can't figure out what the issue is as the error message isn't particularly informative, at least not to me. I attach two log files from the make_examples step. Both are for the same sample, the only difference is that one uses haplotype_labeler (job succeeded) and the other uses positional_labeler (job failed). . It would be great to get your opinion on what is going on. Note that I have tested positional labeler a few times and it does seem to work for one sample, but there is no reason this sample should be distinct from the others. . haplotype_labeler:. [MAKE_EX_TRAIN_NEW_4926611-3.err.gz](https://github.com/user-attachments/files/16974777/MAKE_EX_TRAIN_NEW_4926611-3.err.gz). positional_labeler:. [MAKE_EX_TRAIN_NEW_4930167-3.err.gz](https://github.com/user-attachments/files/16974781/MAKE_EX_TRAIN_NEW_4930167-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:846,usability,user,user-attachments,846,"Hi @kishwarshafin,. Ok thanks for the explanation. . Unfortunately, I am still having trouble. For some reason when I use positional_labeler my make_examples jobs fail. But they complete successfully using haplotype_labeler. I can't figure out what the issue is as the error message isn't particularly informative, at least not to me. I attach two log files from the make_examples step. Both are for the same sample, the only difference is that one uses haplotype_labeler (job succeeded) and the other uses positional_labeler (job failed). . It would be great to get your opinion on what is going on. Note that I have tested positional labeler a few times and it does seem to work for one sample, but there is no reason this sample should be distinct from the others. . haplotype_labeler:. [MAKE_EX_TRAIN_NEW_4926611-3.err.gz](https://github.com/user-attachments/files/16974777/MAKE_EX_TRAIN_NEW_4926611-3.err.gz). positional_labeler:. [MAKE_EX_TRAIN_NEW_4930167-3.err.gz](https://github.com/user-attachments/files/16974781/MAKE_EX_TRAIN_NEW_4930167-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:992,usability,user,user-attachments,992,"Hi @kishwarshafin,. Ok thanks for the explanation. . Unfortunately, I am still having trouble. For some reason when I use positional_labeler my make_examples jobs fail. But they complete successfully using haplotype_labeler. I can't figure out what the issue is as the error message isn't particularly informative, at least not to me. I attach two log files from the make_examples step. Both are for the same sample, the only difference is that one uses haplotype_labeler (job succeeded) and the other uses positional_labeler (job failed). . It would be great to get your opinion on what is going on. Note that I have tested positional labeler a few times and it does seem to work for one sample, but there is no reason this sample should be distinct from the others. . haplotype_labeler:. [MAKE_EX_TRAIN_NEW_4926611-3.err.gz](https://github.com/user-attachments/files/16974777/MAKE_EX_TRAIN_NEW_4926611-3.err.gz). positional_labeler:. [MAKE_EX_TRAIN_NEW_4930167-3.err.gz](https://github.com/user-attachments/files/16974781/MAKE_EX_TRAIN_NEW_4930167-3.err.gz). Thanks. Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:942,availability,consist,consistent,942,"So it looks like the VCF parsing is failing here:. ```bash. I0911 20:23:50.839811 140713511122752 positional_labeler.py:163] Multiple matches detected; no good match found. Fall back to first. variant: reference_bases: ""G"". alternate_bases: ""A"". info {. key: ""BAM_FNAME"". value {. values {. string_value: ""SR_male_1.fixmate.coordsorted.bam"". }. }. }. calls {. info {. key: ""AD"". value {. values {. int_value: 0. }. values {. int_value: 22. }. }. }. info {. key: ""DP"". value {. values {. int_value: 22. }. }. }. info {. key: ""VAF"". value {. values {. number_value: 1.0. }. }. }. genotype: -1. genotype: -1. call_set_name: ""SR_male_1"". }. end: 14057936. reference_name: ""NC_053213.1_chromosome_2"". start: 14057935. : matches: [reference_bases: ""G"". alternate_bases: ""A"". alternate_bases: ""<NON_REF>"". ```. Looks like your truth contains alleles like ""<NON_REF>"" and when positional lableler tries to match something it fails. Is your truth VCF consistent with the regular VCF standards? You may need to filter non-standard calls like ""NON_REF"" as an alt allele from the truth to fix this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:36,deployability,fail,failing,36,"So it looks like the VCF parsing is failing here:. ```bash. I0911 20:23:50.839811 140713511122752 positional_labeler.py:163] Multiple matches detected; no good match found. Fall back to first. variant: reference_bases: ""G"". alternate_bases: ""A"". info {. key: ""BAM_FNAME"". value {. values {. string_value: ""SR_male_1.fixmate.coordsorted.bam"". }. }. }. calls {. info {. key: ""AD"". value {. values {. int_value: 0. }. values {. int_value: 22. }. }. }. info {. key: ""DP"". value {. values {. int_value: 22. }. }. }. info {. key: ""VAF"". value {. values {. number_value: 1.0. }. }. }. genotype: -1. genotype: -1. call_set_name: ""SR_male_1"". }. end: 14057936. reference_name: ""NC_053213.1_chromosome_2"". start: 14057935. : matches: [reference_bases: ""G"". alternate_bases: ""A"". alternate_bases: ""<NON_REF>"". ```. Looks like your truth contains alleles like ""<NON_REF>"" and when positional lableler tries to match something it fails. Is your truth VCF consistent with the regular VCF standards? You may need to filter non-standard calls like ""NON_REF"" as an alt allele from the truth to fix this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:826,deployability,contain,contains,826,"So it looks like the VCF parsing is failing here:. ```bash. I0911 20:23:50.839811 140713511122752 positional_labeler.py:163] Multiple matches detected; no good match found. Fall back to first. variant: reference_bases: ""G"". alternate_bases: ""A"". info {. key: ""BAM_FNAME"". value {. values {. string_value: ""SR_male_1.fixmate.coordsorted.bam"". }. }. }. calls {. info {. key: ""AD"". value {. values {. int_value: 0. }. values {. int_value: 22. }. }. }. info {. key: ""DP"". value {. values {. int_value: 22. }. }. }. info {. key: ""VAF"". value {. values {. number_value: 1.0. }. }. }. genotype: -1. genotype: -1. call_set_name: ""SR_male_1"". }. end: 14057936. reference_name: ""NC_053213.1_chromosome_2"". start: 14057935. : matches: [reference_bases: ""G"". alternate_bases: ""A"". alternate_bases: ""<NON_REF>"". ```. Looks like your truth contains alleles like ""<NON_REF>"" and when positional lableler tries to match something it fails. Is your truth VCF consistent with the regular VCF standards? You may need to filter non-standard calls like ""NON_REF"" as an alt allele from the truth to fix this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:917,deployability,fail,fails,917,"So it looks like the VCF parsing is failing here:. ```bash. I0911 20:23:50.839811 140713511122752 positional_labeler.py:163] Multiple matches detected; no good match found. Fall back to first. variant: reference_bases: ""G"". alternate_bases: ""A"". info {. key: ""BAM_FNAME"". value {. values {. string_value: ""SR_male_1.fixmate.coordsorted.bam"". }. }. }. calls {. info {. key: ""AD"". value {. values {. int_value: 0. }. values {. int_value: 22. }. }. }. info {. key: ""DP"". value {. values {. int_value: 22. }. }. }. info {. key: ""VAF"". value {. values {. number_value: 1.0. }. }. }. genotype: -1. genotype: -1. call_set_name: ""SR_male_1"". }. end: 14057936. reference_name: ""NC_053213.1_chromosome_2"". start: 14057935. : matches: [reference_bases: ""G"". alternate_bases: ""A"". alternate_bases: ""<NON_REF>"". ```. Looks like your truth contains alleles like ""<NON_REF>"" and when positional lableler tries to match something it fails. Is your truth VCF consistent with the regular VCF standards? You may need to filter non-standard calls like ""NON_REF"" as an alt allele from the truth to fix this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:1001,integrability,filter,filter,1001,"So it looks like the VCF parsing is failing here:. ```bash. I0911 20:23:50.839811 140713511122752 positional_labeler.py:163] Multiple matches detected; no good match found. Fall back to first. variant: reference_bases: ""G"". alternate_bases: ""A"". info {. key: ""BAM_FNAME"". value {. values {. string_value: ""SR_male_1.fixmate.coordsorted.bam"". }. }. }. calls {. info {. key: ""AD"". value {. values {. int_value: 0. }. values {. int_value: 22. }. }. }. info {. key: ""DP"". value {. values {. int_value: 22. }. }. }. info {. key: ""VAF"". value {. values {. number_value: 1.0. }. }. }. genotype: -1. genotype: -1. call_set_name: ""SR_male_1"". }. end: 14057936. reference_name: ""NC_053213.1_chromosome_2"". start: 14057935. : matches: [reference_bases: ""G"". alternate_bases: ""A"". alternate_bases: ""<NON_REF>"". ```. Looks like your truth contains alleles like ""<NON_REF>"" and when positional lableler tries to match something it fails. Is your truth VCF consistent with the regular VCF standards? You may need to filter non-standard calls like ""NON_REF"" as an alt allele from the truth to fix this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:974,interoperability,standard,standards,974,"So it looks like the VCF parsing is failing here:. ```bash. I0911 20:23:50.839811 140713511122752 positional_labeler.py:163] Multiple matches detected; no good match found. Fall back to first. variant: reference_bases: ""G"". alternate_bases: ""A"". info {. key: ""BAM_FNAME"". value {. values {. string_value: ""SR_male_1.fixmate.coordsorted.bam"". }. }. }. calls {. info {. key: ""AD"". value {. values {. int_value: 0. }. values {. int_value: 22. }. }. }. info {. key: ""DP"". value {. values {. int_value: 22. }. }. }. info {. key: ""VAF"". value {. values {. number_value: 1.0. }. }. }. genotype: -1. genotype: -1. call_set_name: ""SR_male_1"". }. end: 14057936. reference_name: ""NC_053213.1_chromosome_2"". start: 14057935. : matches: [reference_bases: ""G"". alternate_bases: ""A"". alternate_bases: ""<NON_REF>"". ```. Looks like your truth contains alleles like ""<NON_REF>"" and when positional lableler tries to match something it fails. Is your truth VCF consistent with the regular VCF standards? You may need to filter non-standard calls like ""NON_REF"" as an alt allele from the truth to fix this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:1012,interoperability,standard,standard,1012,"So it looks like the VCF parsing is failing here:. ```bash. I0911 20:23:50.839811 140713511122752 positional_labeler.py:163] Multiple matches detected; no good match found. Fall back to first. variant: reference_bases: ""G"". alternate_bases: ""A"". info {. key: ""BAM_FNAME"". value {. values {. string_value: ""SR_male_1.fixmate.coordsorted.bam"". }. }. }. calls {. info {. key: ""AD"". value {. values {. int_value: 0. }. values {. int_value: 22. }. }. }. info {. key: ""DP"". value {. values {. int_value: 22. }. }. }. info {. key: ""VAF"". value {. values {. number_value: 1.0. }. }. }. genotype: -1. genotype: -1. call_set_name: ""SR_male_1"". }. end: 14057936. reference_name: ""NC_053213.1_chromosome_2"". start: 14057935. : matches: [reference_bases: ""G"". alternate_bases: ""A"". alternate_bases: ""<NON_REF>"". ```. Looks like your truth contains alleles like ""<NON_REF>"" and when positional lableler tries to match something it fails. Is your truth VCF consistent with the regular VCF standards? You may need to filter non-standard calls like ""NON_REF"" as an alt allele from the truth to fix this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:36,reliability,fail,failing,36,"So it looks like the VCF parsing is failing here:. ```bash. I0911 20:23:50.839811 140713511122752 positional_labeler.py:163] Multiple matches detected; no good match found. Fall back to first. variant: reference_bases: ""G"". alternate_bases: ""A"". info {. key: ""BAM_FNAME"". value {. values {. string_value: ""SR_male_1.fixmate.coordsorted.bam"". }. }. }. calls {. info {. key: ""AD"". value {. values {. int_value: 0. }. values {. int_value: 22. }. }. }. info {. key: ""DP"". value {. values {. int_value: 22. }. }. }. info {. key: ""VAF"". value {. values {. number_value: 1.0. }. }. }. genotype: -1. genotype: -1. call_set_name: ""SR_male_1"". }. end: 14057936. reference_name: ""NC_053213.1_chromosome_2"". start: 14057935. : matches: [reference_bases: ""G"". alternate_bases: ""A"". alternate_bases: ""<NON_REF>"". ```. Looks like your truth contains alleles like ""<NON_REF>"" and when positional lableler tries to match something it fails. Is your truth VCF consistent with the regular VCF standards? You may need to filter non-standard calls like ""NON_REF"" as an alt allele from the truth to fix this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:917,reliability,fail,fails,917,"So it looks like the VCF parsing is failing here:. ```bash. I0911 20:23:50.839811 140713511122752 positional_labeler.py:163] Multiple matches detected; no good match found. Fall back to first. variant: reference_bases: ""G"". alternate_bases: ""A"". info {. key: ""BAM_FNAME"". value {. values {. string_value: ""SR_male_1.fixmate.coordsorted.bam"". }. }. }. calls {. info {. key: ""AD"". value {. values {. int_value: 0. }. values {. int_value: 22. }. }. }. info {. key: ""DP"". value {. values {. int_value: 22. }. }. }. info {. key: ""VAF"". value {. values {. number_value: 1.0. }. }. }. genotype: -1. genotype: -1. call_set_name: ""SR_male_1"". }. end: 14057936. reference_name: ""NC_053213.1_chromosome_2"". start: 14057935. : matches: [reference_bases: ""G"". alternate_bases: ""A"". alternate_bases: ""<NON_REF>"". ```. Looks like your truth contains alleles like ""<NON_REF>"" and when positional lableler tries to match something it fails. Is your truth VCF consistent with the regular VCF standards? You may need to filter non-standard calls like ""NON_REF"" as an alt allele from the truth to fix this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:142,safety,detect,detected,142,"So it looks like the VCF parsing is failing here:. ```bash. I0911 20:23:50.839811 140713511122752 positional_labeler.py:163] Multiple matches detected; no good match found. Fall back to first. variant: reference_bases: ""G"". alternate_bases: ""A"". info {. key: ""BAM_FNAME"". value {. values {. string_value: ""SR_male_1.fixmate.coordsorted.bam"". }. }. }. calls {. info {. key: ""AD"". value {. values {. int_value: 0. }. values {. int_value: 22. }. }. }. info {. key: ""DP"". value {. values {. int_value: 22. }. }. }. info {. key: ""VAF"". value {. values {. number_value: 1.0. }. }. }. genotype: -1. genotype: -1. call_set_name: ""SR_male_1"". }. end: 14057936. reference_name: ""NC_053213.1_chromosome_2"". start: 14057935. : matches: [reference_bases: ""G"". alternate_bases: ""A"". alternate_bases: ""<NON_REF>"". ```. Looks like your truth contains alleles like ""<NON_REF>"" and when positional lableler tries to match something it fails. Is your truth VCF consistent with the regular VCF standards? You may need to filter non-standard calls like ""NON_REF"" as an alt allele from the truth to fix this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:142,security,detect,detected,142,"So it looks like the VCF parsing is failing here:. ```bash. I0911 20:23:50.839811 140713511122752 positional_labeler.py:163] Multiple matches detected; no good match found. Fall back to first. variant: reference_bases: ""G"". alternate_bases: ""A"". info {. key: ""BAM_FNAME"". value {. values {. string_value: ""SR_male_1.fixmate.coordsorted.bam"". }. }. }. calls {. info {. key: ""AD"". value {. values {. int_value: 0. }. values {. int_value: 22. }. }. }. info {. key: ""DP"". value {. values {. int_value: 22. }. }. }. info {. key: ""VAF"". value {. values {. number_value: 1.0. }. }. }. genotype: -1. genotype: -1. call_set_name: ""SR_male_1"". }. end: 14057936. reference_name: ""NC_053213.1_chromosome_2"". start: 14057935. : matches: [reference_bases: ""G"". alternate_bases: ""A"". alternate_bases: ""<NON_REF>"". ```. Looks like your truth contains alleles like ""<NON_REF>"" and when positional lableler tries to match something it fails. Is your truth VCF consistent with the regular VCF standards? You may need to filter non-standard calls like ""NON_REF"" as an alt allele from the truth to fix this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:942,usability,consist,consistent,942,"So it looks like the VCF parsing is failing here:. ```bash. I0911 20:23:50.839811 140713511122752 positional_labeler.py:163] Multiple matches detected; no good match found. Fall back to first. variant: reference_bases: ""G"". alternate_bases: ""A"". info {. key: ""BAM_FNAME"". value {. values {. string_value: ""SR_male_1.fixmate.coordsorted.bam"". }. }. }. calls {. info {. key: ""AD"". value {. values {. int_value: 0. }. values {. int_value: 22. }. }. }. info {. key: ""DP"". value {. values {. int_value: 22. }. }. }. info {. key: ""VAF"". value {. values {. number_value: 1.0. }. }. }. genotype: -1. genotype: -1. call_set_name: ""SR_male_1"". }. end: 14057936. reference_name: ""NC_053213.1_chromosome_2"". start: 14057935. : matches: [reference_bases: ""G"". alternate_bases: ""A"". alternate_bases: ""<NON_REF>"". ```. Looks like your truth contains alleles like ""<NON_REF>"" and when positional lableler tries to match something it fails. Is your truth VCF consistent with the regular VCF standards? You may need to filter non-standard calls like ""NON_REF"" as an alt allele from the truth to fix this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:301,deployability,fail,fails,301,"Hi @kishwarshafin ,. Yeh these are standard VCFs, outputted by GenotypeGVCFs (GATK 4.1.3) and filtered by BCFtools. . After having done some more tests, I don't think the existence of <NON_REF> alleles is the issue for several reasons. 1) These alleles occur many times in the VCF well before the job fails. 2) The job often fails on loci that do not have such alleles. 3) After removing them (and all ALT alleles not found in the sample in each VCF) the jobs still fail. . I cannot see any pattern in the loci reported in the log file at the point at which the job fails. And still, some jobs succeed. Anyway, I will keep digging and close this issue as the original question was solved. . Thanks for the help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:325,deployability,fail,fails,325,"Hi @kishwarshafin ,. Yeh these are standard VCFs, outputted by GenotypeGVCFs (GATK 4.1.3) and filtered by BCFtools. . After having done some more tests, I don't think the existence of <NON_REF> alleles is the issue for several reasons. 1) These alleles occur many times in the VCF well before the job fails. 2) The job often fails on loci that do not have such alleles. 3) After removing them (and all ALT alleles not found in the sample in each VCF) the jobs still fail. . I cannot see any pattern in the loci reported in the log file at the point at which the job fails. And still, some jobs succeed. Anyway, I will keep digging and close this issue as the original question was solved. . Thanks for the help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:466,deployability,fail,fail,466,"Hi @kishwarshafin ,. Yeh these are standard VCFs, outputted by GenotypeGVCFs (GATK 4.1.3) and filtered by BCFtools. . After having done some more tests, I don't think the existence of <NON_REF> alleles is the issue for several reasons. 1) These alleles occur many times in the VCF well before the job fails. 2) The job often fails on loci that do not have such alleles. 3) After removing them (and all ALT alleles not found in the sample in each VCF) the jobs still fail. . I cannot see any pattern in the loci reported in the log file at the point at which the job fails. And still, some jobs succeed. Anyway, I will keep digging and close this issue as the original question was solved. . Thanks for the help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:527,deployability,log,log,527,"Hi @kishwarshafin ,. Yeh these are standard VCFs, outputted by GenotypeGVCFs (GATK 4.1.3) and filtered by BCFtools. . After having done some more tests, I don't think the existence of <NON_REF> alleles is the issue for several reasons. 1) These alleles occur many times in the VCF well before the job fails. 2) The job often fails on loci that do not have such alleles. 3) After removing them (and all ALT alleles not found in the sample in each VCF) the jobs still fail. . I cannot see any pattern in the loci reported in the log file at the point at which the job fails. And still, some jobs succeed. Anyway, I will keep digging and close this issue as the original question was solved. . Thanks for the help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:566,deployability,fail,fails,566,"Hi @kishwarshafin ,. Yeh these are standard VCFs, outputted by GenotypeGVCFs (GATK 4.1.3) and filtered by BCFtools. . After having done some more tests, I don't think the existence of <NON_REF> alleles is the issue for several reasons. 1) These alleles occur many times in the VCF well before the job fails. 2) The job often fails on loci that do not have such alleles. 3) After removing them (and all ALT alleles not found in the sample in each VCF) the jobs still fail. . I cannot see any pattern in the loci reported in the log file at the point at which the job fails. And still, some jobs succeed. Anyway, I will keep digging and close this issue as the original question was solved. . Thanks for the help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:94,integrability,filter,filtered,94,"Hi @kishwarshafin ,. Yeh these are standard VCFs, outputted by GenotypeGVCFs (GATK 4.1.3) and filtered by BCFtools. . After having done some more tests, I don't think the existence of <NON_REF> alleles is the issue for several reasons. 1) These alleles occur many times in the VCF well before the job fails. 2) The job often fails on loci that do not have such alleles. 3) After removing them (and all ALT alleles not found in the sample in each VCF) the jobs still fail. . I cannot see any pattern in the loci reported in the log file at the point at which the job fails. And still, some jobs succeed. Anyway, I will keep digging and close this issue as the original question was solved. . Thanks for the help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:35,interoperability,standard,standard,35,"Hi @kishwarshafin ,. Yeh these are standard VCFs, outputted by GenotypeGVCFs (GATK 4.1.3) and filtered by BCFtools. . After having done some more tests, I don't think the existence of <NON_REF> alleles is the issue for several reasons. 1) These alleles occur many times in the VCF well before the job fails. 2) The job often fails on loci that do not have such alleles. 3) After removing them (and all ALT alleles not found in the sample in each VCF) the jobs still fail. . I cannot see any pattern in the loci reported in the log file at the point at which the job fails. And still, some jobs succeed. Anyway, I will keep digging and close this issue as the original question was solved. . Thanks for the help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:264,performance,time,times,264,"Hi @kishwarshafin ,. Yeh these are standard VCFs, outputted by GenotypeGVCFs (GATK 4.1.3) and filtered by BCFtools. . After having done some more tests, I don't think the existence of <NON_REF> alleles is the issue for several reasons. 1) These alleles occur many times in the VCF well before the job fails. 2) The job often fails on loci that do not have such alleles. 3) After removing them (and all ALT alleles not found in the sample in each VCF) the jobs still fail. . I cannot see any pattern in the loci reported in the log file at the point at which the job fails. And still, some jobs succeed. Anyway, I will keep digging and close this issue as the original question was solved. . Thanks for the help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:301,reliability,fail,fails,301,"Hi @kishwarshafin ,. Yeh these are standard VCFs, outputted by GenotypeGVCFs (GATK 4.1.3) and filtered by BCFtools. . After having done some more tests, I don't think the existence of <NON_REF> alleles is the issue for several reasons. 1) These alleles occur many times in the VCF well before the job fails. 2) The job often fails on loci that do not have such alleles. 3) After removing them (and all ALT alleles not found in the sample in each VCF) the jobs still fail. . I cannot see any pattern in the loci reported in the log file at the point at which the job fails. And still, some jobs succeed. Anyway, I will keep digging and close this issue as the original question was solved. . Thanks for the help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:325,reliability,fail,fails,325,"Hi @kishwarshafin ,. Yeh these are standard VCFs, outputted by GenotypeGVCFs (GATK 4.1.3) and filtered by BCFtools. . After having done some more tests, I don't think the existence of <NON_REF> alleles is the issue for several reasons. 1) These alleles occur many times in the VCF well before the job fails. 2) The job often fails on loci that do not have such alleles. 3) After removing them (and all ALT alleles not found in the sample in each VCF) the jobs still fail. . I cannot see any pattern in the loci reported in the log file at the point at which the job fails. And still, some jobs succeed. Anyway, I will keep digging and close this issue as the original question was solved. . Thanks for the help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:466,reliability,fail,fail,466,"Hi @kishwarshafin ,. Yeh these are standard VCFs, outputted by GenotypeGVCFs (GATK 4.1.3) and filtered by BCFtools. . After having done some more tests, I don't think the existence of <NON_REF> alleles is the issue for several reasons. 1) These alleles occur many times in the VCF well before the job fails. 2) The job often fails on loci that do not have such alleles. 3) After removing them (and all ALT alleles not found in the sample in each VCF) the jobs still fail. . I cannot see any pattern in the loci reported in the log file at the point at which the job fails. And still, some jobs succeed. Anyway, I will keep digging and close this issue as the original question was solved. . Thanks for the help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:566,reliability,fail,fails,566,"Hi @kishwarshafin ,. Yeh these are standard VCFs, outputted by GenotypeGVCFs (GATK 4.1.3) and filtered by BCFtools. . After having done some more tests, I don't think the existence of <NON_REF> alleles is the issue for several reasons. 1) These alleles occur many times in the VCF well before the job fails. 2) The job often fails on loci that do not have such alleles. 3) After removing them (and all ALT alleles not found in the sample in each VCF) the jobs still fail. . I cannot see any pattern in the loci reported in the log file at the point at which the job fails. And still, some jobs succeed. Anyway, I will keep digging and close this issue as the original question was solved. . Thanks for the help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:146,safety,test,tests,146,"Hi @kishwarshafin ,. Yeh these are standard VCFs, outputted by GenotypeGVCFs (GATK 4.1.3) and filtered by BCFtools. . After having done some more tests, I don't think the existence of <NON_REF> alleles is the issue for several reasons. 1) These alleles occur many times in the VCF well before the job fails. 2) The job often fails on loci that do not have such alleles. 3) After removing them (and all ALT alleles not found in the sample in each VCF) the jobs still fail. . I cannot see any pattern in the loci reported in the log file at the point at which the job fails. And still, some jobs succeed. Anyway, I will keep digging and close this issue as the original question was solved. . Thanks for the help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:527,safety,log,log,527,"Hi @kishwarshafin ,. Yeh these are standard VCFs, outputted by GenotypeGVCFs (GATK 4.1.3) and filtered by BCFtools. . After having done some more tests, I don't think the existence of <NON_REF> alleles is the issue for several reasons. 1) These alleles occur many times in the VCF well before the job fails. 2) The job often fails on loci that do not have such alleles. 3) After removing them (and all ALT alleles not found in the sample in each VCF) the jobs still fail. . I cannot see any pattern in the loci reported in the log file at the point at which the job fails. And still, some jobs succeed. Anyway, I will keep digging and close this issue as the original question was solved. . Thanks for the help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:527,security,log,log,527,"Hi @kishwarshafin ,. Yeh these are standard VCFs, outputted by GenotypeGVCFs (GATK 4.1.3) and filtered by BCFtools. . After having done some more tests, I don't think the existence of <NON_REF> alleles is the issue for several reasons. 1) These alleles occur many times in the VCF well before the job fails. 2) The job often fails on loci that do not have such alleles. 3) After removing them (and all ALT alleles not found in the sample in each VCF) the jobs still fail. . I cannot see any pattern in the loci reported in the log file at the point at which the job fails. And still, some jobs succeed. Anyway, I will keep digging and close this issue as the original question was solved. . Thanks for the help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:146,testability,test,tests,146,"Hi @kishwarshafin ,. Yeh these are standard VCFs, outputted by GenotypeGVCFs (GATK 4.1.3) and filtered by BCFtools. . After having done some more tests, I don't think the existence of <NON_REF> alleles is the issue for several reasons. 1) These alleles occur many times in the VCF well before the job fails. 2) The job often fails on loci that do not have such alleles. 3) After removing them (and all ALT alleles not found in the sample in each VCF) the jobs still fail. . I cannot see any pattern in the loci reported in the log file at the point at which the job fails. And still, some jobs succeed. Anyway, I will keep digging and close this issue as the original question was solved. . Thanks for the help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:527,testability,log,log,527,"Hi @kishwarshafin ,. Yeh these are standard VCFs, outputted by GenotypeGVCFs (GATK 4.1.3) and filtered by BCFtools. . After having done some more tests, I don't think the existence of <NON_REF> alleles is the issue for several reasons. 1) These alleles occur many times in the VCF well before the job fails. 2) The job often fails on loci that do not have such alleles. 3) After removing them (and all ALT alleles not found in the sample in each VCF) the jobs still fail. . I cannot see any pattern in the loci reported in the log file at the point at which the job fails. And still, some jobs succeed. Anyway, I will keep digging and close this issue as the original question was solved. . Thanks for the help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:635,usability,close,close,635,"Hi @kishwarshafin ,. Yeh these are standard VCFs, outputted by GenotypeGVCFs (GATK 4.1.3) and filtered by BCFtools. . After having done some more tests, I don't think the existence of <NON_REF> alleles is the issue for several reasons. 1) These alleles occur many times in the VCF well before the job fails. 2) The job often fails on loci that do not have such alleles. 3) After removing them (and all ALT alleles not found in the sample in each VCF) the jobs still fail. . I cannot see any pattern in the loci reported in the log file at the point at which the job fails. And still, some jobs succeed. Anyway, I will keep digging and close this issue as the original question was solved. . Thanks for the help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/876:706,usability,help,help,706,"Hi @kishwarshafin ,. Yeh these are standard VCFs, outputted by GenotypeGVCFs (GATK 4.1.3) and filtered by BCFtools. . After having done some more tests, I don't think the existence of <NON_REF> alleles is the issue for several reasons. 1) These alleles occur many times in the VCF well before the job fails. 2) The job often fails on loci that do not have such alleles. 3) After removing them (and all ALT alleles not found in the sample in each VCF) the jobs still fail. . I cannot see any pattern in the loci reported in the log file at the point at which the job fails. And still, some jobs succeed. Anyway, I will keep digging and close this issue as the original question was solved. . Thanks for the help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/876
https://github.com/google/deepvariant/issues/877:179,energy efficiency,model,model,179,"@Yousuk-Song , It looks like your bam file does not have base-qualities. For DeepVariant, you need the base qualities associated with reads as we use that as input feature to the model.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:43,reliability,doe,does,43,"@Yousuk-Song , It looks like your bam file does not have base-qualities. For DeepVariant, you need the base qualities associated with reads as we use that as input feature to the model.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:158,safety,input,input,158,"@Yousuk-Song , It looks like your bam file does not have base-qualities. For DeepVariant, you need the base qualities associated with reads as we use that as input feature to the model.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:179,security,model,model,179,"@Yousuk-Song , It looks like your bam file does not have base-qualities. For DeepVariant, you need the base qualities associated with reads as we use that as input feature to the model.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:158,usability,input,input,158,"@Yousuk-Song , It looks like your bam file does not have base-qualities. For DeepVariant, you need the base qualities associated with reads as we use that as input feature to the model.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:644,integrability,filter,filtering,644,"Thank you! I added the base quality scores to the bam file and finally it worked! Additional question: . I detected a mutation at a query position in the bam file using igv browser. However, deep variant didn't call it as a variant in output vcf file, but only recored it as a non-variant position in the output gvcf file. <img width=""424"" alt="" 2024-09-05  1 07 05"" src=""https://github.com/user-attachments/assets/3e0f4a5d-5c37-489c-b8e7-6673a04cb9c5"">. <img width=""760"" alt="" 2024-09-05  1 07 42"" src=""https://github.com/user-attachments/assets/9c76e316-6131-4117-964d-5134f9e92505"">. Are there any ways to adjust filtering option of deep variant to make deep variant detect it?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:107,safety,detect,detected,107,"Thank you! I added the base quality scores to the bam file and finally it worked! Additional question: . I detected a mutation at a query position in the bam file using igv browser. However, deep variant didn't call it as a variant in output vcf file, but only recored it as a non-variant position in the output gvcf file. <img width=""424"" alt="" 2024-09-05  1 07 05"" src=""https://github.com/user-attachments/assets/3e0f4a5d-5c37-489c-b8e7-6673a04cb9c5"">. <img width=""760"" alt="" 2024-09-05  1 07 42"" src=""https://github.com/user-attachments/assets/9c76e316-6131-4117-964d-5134f9e92505"">. Are there any ways to adjust filtering option of deep variant to make deep variant detect it?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:698,safety,detect,detect,698,"Thank you! I added the base quality scores to the bam file and finally it worked! Additional question: . I detected a mutation at a query position in the bam file using igv browser. However, deep variant didn't call it as a variant in output vcf file, but only recored it as a non-variant position in the output gvcf file. <img width=""424"" alt="" 2024-09-05  1 07 05"" src=""https://github.com/user-attachments/assets/3e0f4a5d-5c37-489c-b8e7-6673a04cb9c5"">. <img width=""760"" alt="" 2024-09-05  1 07 42"" src=""https://github.com/user-attachments/assets/9c76e316-6131-4117-964d-5134f9e92505"">. Are there any ways to adjust filtering option of deep variant to make deep variant detect it?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:107,security,detect,detected,107,"Thank you! I added the base quality scores to the bam file and finally it worked! Additional question: . I detected a mutation at a query position in the bam file using igv browser. However, deep variant didn't call it as a variant in output vcf file, but only recored it as a non-variant position in the output gvcf file. <img width=""424"" alt="" 2024-09-05  1 07 05"" src=""https://github.com/user-attachments/assets/3e0f4a5d-5c37-489c-b8e7-6673a04cb9c5"">. <img width=""760"" alt="" 2024-09-05  1 07 42"" src=""https://github.com/user-attachments/assets/9c76e316-6131-4117-964d-5134f9e92505"">. Are there any ways to adjust filtering option of deep variant to make deep variant detect it?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:698,security,detect,detect,698,"Thank you! I added the base quality scores to the bam file and finally it worked! Additional question: . I detected a mutation at a query position in the bam file using igv browser. However, deep variant didn't call it as a variant in output vcf file, but only recored it as a non-variant position in the output gvcf file. <img width=""424"" alt="" 2024-09-05  1 07 05"" src=""https://github.com/user-attachments/assets/3e0f4a5d-5c37-489c-b8e7-6673a04cb9c5"">. <img width=""760"" alt="" 2024-09-05  1 07 42"" src=""https://github.com/user-attachments/assets/9c76e316-6131-4117-964d-5134f9e92505"">. Are there any ways to adjust filtering option of deep variant to make deep variant detect it?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:405,usability,user,user-attachments,405,"Thank you! I added the base quality scores to the bam file and finally it worked! Additional question: . I detected a mutation at a query position in the bam file using igv browser. However, deep variant didn't call it as a variant in output vcf file, but only recored it as a non-variant position in the output gvcf file. <img width=""424"" alt="" 2024-09-05  1 07 05"" src=""https://github.com/user-attachments/assets/3e0f4a5d-5c37-489c-b8e7-6673a04cb9c5"">. <img width=""760"" alt="" 2024-09-05  1 07 42"" src=""https://github.com/user-attachments/assets/9c76e316-6131-4117-964d-5134f9e92505"">. Are there any ways to adjust filtering option of deep variant to make deep variant detect it?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:551,usability,user,user-attachments,551,"Thank you! I added the base quality scores to the bam file and finally it worked! Additional question: . I detected a mutation at a query position in the bam file using igv browser. However, deep variant didn't call it as a variant in output vcf file, but only recored it as a non-variant position in the output gvcf file. <img width=""424"" alt="" 2024-09-05  1 07 05"" src=""https://github.com/user-attachments/assets/3e0f4a5d-5c37-489c-b8e7-6673a04cb9c5"">. <img width=""760"" alt="" 2024-09-05  1 07 42"" src=""https://github.com/user-attachments/assets/9c76e316-6131-4117-964d-5134f9e92505"">. Are there any ways to adjust filtering option of deep variant to make deep variant detect it?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:19,reliability,Doe,Does,19,"Hi @Yousuk-Song ,. Does your VCF file has that variant as a RefCall? If so, can you post the line in the VCF fiel?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:247,reliability,doe,does,247,"Hi @Yousuk-Song ,. There might be some confusion here. Let me clarify:. You asked ""Can I regard the variant as a true somatic mutation and proceed ?"". Please note that you're running **DeepVariant**, which is a **germline** variant caller. So, it does not call **somatic** mutations. If you're interested in detecting somatic variants instead of germline variants, please make sure to use DeepSomatic (https://github.com/google/deepsomatic) instead. Hope this helps!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:308,safety,detect,detecting,308,"Hi @Yousuk-Song ,. There might be some confusion here. Let me clarify:. You asked ""Can I regard the variant as a true somatic mutation and proceed ?"". Please note that you're running **DeepVariant**, which is a **germline** variant caller. So, it does not call **somatic** mutations. If you're interested in detecting somatic variants instead of germline variants, please make sure to use DeepSomatic (https://github.com/google/deepsomatic) instead. Hope this helps!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:308,security,detect,detecting,308,"Hi @Yousuk-Song ,. There might be some confusion here. Let me clarify:. You asked ""Can I regard the variant as a true somatic mutation and proceed ?"". Please note that you're running **DeepVariant**, which is a **germline** variant caller. So, it does not call **somatic** mutations. If you're interested in detecting somatic variants instead of germline variants, please make sure to use DeepSomatic (https://github.com/google/deepsomatic) instead. Hope this helps!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/877:460,usability,help,helps,460,"Hi @Yousuk-Song ,. There might be some confusion here. Let me clarify:. You asked ""Can I regard the variant as a true somatic mutation and proceed ?"". Please note that you're running **DeepVariant**, which is a **germline** variant caller. So, it does not call **somatic** mutations. If you're interested in detecting somatic variants instead of germline variants, please make sure to use DeepSomatic (https://github.com/google/deepsomatic) instead. Hope this helps!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/877
https://github.com/google/deepvariant/issues/878:199,availability,down,downstream,199,"Hi @desmodus1984 ,. For many of the non-human applications, we see many use cases where people just apply our release models. . I think directly using our model would be a good enough start for your downstream application. If you have some way to evaluate (e.g., Mendelian violation), then you can do some comparison to assess how good the calls are. If you have trio data, you can try to run DeepTrio (also using our release model) , which I think will be more accurate.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:110,deployability,releas,release,110,"Hi @desmodus1984 ,. For many of the non-human applications, we see many use cases where people just apply our release models. . I think directly using our model would be a good enough start for your downstream application. If you have some way to evaluate (e.g., Mendelian violation), then you can do some comparison to assess how good the calls are. If you have trio data, you can try to run DeepTrio (also using our release model) , which I think will be more accurate.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:418,deployability,releas,release,418,"Hi @desmodus1984 ,. For many of the non-human applications, we see many use cases where people just apply our release models. . I think directly using our model would be a good enough start for your downstream application. If you have some way to evaluate (e.g., Mendelian violation), then you can do some comparison to assess how good the calls are. If you have trio data, you can try to run DeepTrio (also using our release model) , which I think will be more accurate.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:118,energy efficiency,model,models,118,"Hi @desmodus1984 ,. For many of the non-human applications, we see many use cases where people just apply our release models. . I think directly using our model would be a good enough start for your downstream application. If you have some way to evaluate (e.g., Mendelian violation), then you can do some comparison to assess how good the calls are. If you have trio data, you can try to run DeepTrio (also using our release model) , which I think will be more accurate.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:155,energy efficiency,model,model,155,"Hi @desmodus1984 ,. For many of the non-human applications, we see many use cases where people just apply our release models. . I think directly using our model would be a good enough start for your downstream application. If you have some way to evaluate (e.g., Mendelian violation), then you can do some comparison to assess how good the calls are. If you have trio data, you can try to run DeepTrio (also using our release model) , which I think will be more accurate.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:426,energy efficiency,model,model,426,"Hi @desmodus1984 ,. For many of the non-human applications, we see many use cases where people just apply our release models. . I think directly using our model would be a good enough start for your downstream application. If you have some way to evaluate (e.g., Mendelian violation), then you can do some comparison to assess how good the calls are. If you have trio data, you can try to run DeepTrio (also using our release model) , which I think will be more accurate.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:118,security,model,models,118,"Hi @desmodus1984 ,. For many of the non-human applications, we see many use cases where people just apply our release models. . I think directly using our model would be a good enough start for your downstream application. If you have some way to evaluate (e.g., Mendelian violation), then you can do some comparison to assess how good the calls are. If you have trio data, you can try to run DeepTrio (also using our release model) , which I think will be more accurate.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:155,security,model,model,155,"Hi @desmodus1984 ,. For many of the non-human applications, we see many use cases where people just apply our release models. . I think directly using our model would be a good enough start for your downstream application. If you have some way to evaluate (e.g., Mendelian violation), then you can do some comparison to assess how good the calls are. If you have trio data, you can try to run DeepTrio (also using our release model) , which I think will be more accurate.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:320,security,assess,assess,320,"Hi @desmodus1984 ,. For many of the non-human applications, we see many use cases where people just apply our release models. . I think directly using our model would be a good enough start for your downstream application. If you have some way to evaluate (e.g., Mendelian violation), then you can do some comparison to assess how good the calls are. If you have trio data, you can try to run DeepTrio (also using our release model) , which I think will be more accurate.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:426,security,model,model,426,"Hi @desmodus1984 ,. For many of the non-human applications, we see many use cases where people just apply our release models. . I think directly using our model would be a good enough start for your downstream application. If you have some way to evaluate (e.g., Mendelian violation), then you can do some comparison to assess how good the calls are. If you have trio data, you can try to run DeepTrio (also using our release model) , which I think will be more accurate.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:485,integrability,filter,filter,485,"Hi,. I would like to know how should I preprocess my samples to generate the bam files, since perhaps DeepVariant might need more or less preprocessing. I have short-read data, and I plan to:. 1. Merge the reads that overlap, and then map the nonoverlapping reads and the merged ones separately, and then combine the two sam files. Do I need to add any additional parameters during mapping with bwa-mem2? 2. Then convert the combined sam, to bam, and then coordinate-sort it. Should I filter the reads during conversion, like using a minimum mapping quality, or just proceed with all? 3. Next, I used to mark duplicate reads and eliminate them. Thanks for your comment and suggestions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:456,interoperability,coordinat,coordinate-sort,456,"Hi,. I would like to know how should I preprocess my samples to generate the bam files, since perhaps DeepVariant might need more or less preprocessing. I have short-read data, and I plan to:. 1. Merge the reads that overlap, and then map the nonoverlapping reads and the merged ones separately, and then combine the two sam files. Do I need to add any additional parameters during mapping with bwa-mem2? 2. Then convert the combined sam, to bam, and then coordinate-sort it. Should I filter the reads during conversion, like using a minimum mapping quality, or just proceed with all? 3. Next, I used to mark duplicate reads and eliminate them. Thanks for your comment and suggestions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:509,interoperability,convers,conversion,509,"Hi,. I would like to know how should I preprocess my samples to generate the bam files, since perhaps DeepVariant might need more or less preprocessing. I have short-read data, and I plan to:. 1. Merge the reads that overlap, and then map the nonoverlapping reads and the merged ones separately, and then combine the two sam files. Do I need to add any additional parameters during mapping with bwa-mem2? 2. Then convert the combined sam, to bam, and then coordinate-sort it. Should I filter the reads during conversion, like using a minimum mapping quality, or just proceed with all? 3. Next, I used to mark duplicate reads and eliminate them. Thanks for your comment and suggestions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:364,modifiability,paramet,parameters,364,"Hi,. I would like to know how should I preprocess my samples to generate the bam files, since perhaps DeepVariant might need more or less preprocessing. I have short-read data, and I plan to:. 1. Merge the reads that overlap, and then map the nonoverlapping reads and the merged ones separately, and then combine the two sam files. Do I need to add any additional parameters during mapping with bwa-mem2? 2. Then convert the combined sam, to bam, and then coordinate-sort it. Should I filter the reads during conversion, like using a minimum mapping quality, or just proceed with all? 3. Next, I used to mark duplicate reads and eliminate them. Thanks for your comment and suggestions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:183,testability,plan,plan,183,"Hi,. I would like to know how should I preprocess my samples to generate the bam files, since perhaps DeepVariant might need more or less preprocessing. I have short-read data, and I plan to:. 1. Merge the reads that overlap, and then map the nonoverlapping reads and the merged ones separately, and then combine the two sam files. Do I need to add any additional parameters during mapping with bwa-mem2? 2. Then convert the combined sam, to bam, and then coordinate-sort it. Should I filter the reads during conversion, like using a minimum mapping quality, or just proceed with all? 3. Next, I used to mark duplicate reads and eliminate them. Thanks for your comment and suggestions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:534,usability,minim,minimum,534,"Hi,. I would like to know how should I preprocess my samples to generate the bam files, since perhaps DeepVariant might need more or less preprocessing. I have short-read data, and I plan to:. 1. Merge the reads that overlap, and then map the nonoverlapping reads and the merged ones separately, and then combine the two sam files. Do I need to add any additional parameters during mapping with bwa-mem2? 2. Then convert the combined sam, to bam, and then coordinate-sort it. Should I filter the reads during conversion, like using a minimum mapping quality, or just proceed with all? 3. Next, I used to mark duplicate reads and eliminate them. Thanks for your comment and suggestions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:87,security,lineag,lineage,87,"@desmodus1984, I think in your process of creating the truth, you will dilute a lot of lineage information. Among the samples you have, do you have generational information among the sample? As in, can you tell which samples can be considered as ancestors vs which are children?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:108,availability,state,states,108,"Hi. No, I don't have generational information. I have like 2 or 4 individuals per population from different states/provinces, that were collected on years.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:108,integrability,state,states,108,"Hi. No, I don't have generational information. I have like 2 or 4 individuals per population from different states/provinces, that were collected on years.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:583,energy efficiency,current,current,583,"Ok, then this would probably be my approach:. 1) Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". 2) Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs. 3) Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks. Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:670,energy efficiency,model,model,670,"Ok, then this would probably be my approach:. 1) Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". 2) Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs. 3) Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks. Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:213,modifiability,paramet,parameters,213,"Ok, then this would probably be my approach:. 1) Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". 2) Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs. 3) Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks. Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:560,security,Assess,Assess,560,"Ok, then this would probably be my approach:. 1) Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". 2) Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs. 3) Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks. Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:670,security,model,model,670,"Ok, then this would probably be my approach:. 1) Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". 2) Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs. 3) Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks. Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:777,testability,simpl,simplest,777,"Ok, then this would probably be my approach:. 1) Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". 2) Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs. 3) Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks. Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:229,usability,minim,minimum,229,"Ok, then this would probably be my approach:. 1) Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". 2) Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs. 3) Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks. Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:777,usability,simpl,simplest,777,"Ok, then this would probably be my approach:. 1) Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". 2) Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs. 3) Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks. Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1490,availability,reliab,reliable,1490,"Hi,. Thanks for the reply, but it doesn't address my question. My doubt is about how to generate the bam file for doing the variant calling. For the checking/validation approach, I would like to ask a few questions. > Ok, then this would probably be my approach:. > . > 1. Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". I did medium coverage sequencing based on some literature, but since my species might have high genetic diversity I used depth higher than recommended (1x), about ~10X per individual. https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0079667. https://onlinelibrary.wiley.com/doi/10.1111/mec.12105. https://pubmed.ncbi.nlm.nih.gov/34250668/. Then, I can't use the minimum depth you suggest of 15; my data should be good quality, hence GQ of 20 is fine, but depth of 15 is not achievable. > 2. Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs. I am new in Bioinformatics, could you suggest a program to use to find those ""confident blocks"". I can't think of any program for doing it. I have short-reads not long-reads, hence finding SV is not very reliable. Any suggestion on how to check if a variant falls within a SV? > 3. Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks. > . > Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment. As mentioned before, I do not have trios data. @pichuan , Is it possible to train a model without trios data?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1591,energy efficiency,current,current,1591,"Hi,. Thanks for the reply, but it doesn't address my question. My doubt is about how to generate the bam file for doing the variant calling. For the checking/validation approach, I would like to ask a few questions. > Ok, then this would probably be my approach:. > . > 1. Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". I did medium coverage sequencing based on some literature, but since my species might have high genetic diversity I used depth higher than recommended (1x), about ~10X per individual. https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0079667. https://onlinelibrary.wiley.com/doi/10.1111/mec.12105. https://pubmed.ncbi.nlm.nih.gov/34250668/. Then, I can't use the minimum depth you suggest of 15; my data should be good quality, hence GQ of 20 is fine, but depth of 15 is not achievable. > 2. Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs. I am new in Bioinformatics, could you suggest a program to use to find those ""confident blocks"". I can't think of any program for doing it. I have short-reads not long-reads, hence finding SV is not very reliable. Any suggestion on how to check if a variant falls within a SV? > 3. Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks. > . > Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment. As mentioned before, I do not have trios data. @pichuan , Is it possible to train a model without trios data?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1684,energy efficiency,model,model,1684,"Hi,. Thanks for the reply, but it doesn't address my question. My doubt is about how to generate the bam file for doing the variant calling. For the checking/validation approach, I would like to ask a few questions. > Ok, then this would probably be my approach:. > . > 1. Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". I did medium coverage sequencing based on some literature, but since my species might have high genetic diversity I used depth higher than recommended (1x), about ~10X per individual. https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0079667. https://onlinelibrary.wiley.com/doi/10.1111/mec.12105. https://pubmed.ncbi.nlm.nih.gov/34250668/. Then, I can't use the minimum depth you suggest of 15; my data should be good quality, hence GQ of 20 is fine, but depth of 15 is not achievable. > 2. Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs. I am new in Bioinformatics, could you suggest a program to use to find those ""confident blocks"". I can't think of any program for doing it. I have short-reads not long-reads, hence finding SV is not very reliable. Any suggestion on how to check if a variant falls within a SV? > 3. Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks. > . > Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment. As mentioned before, I do not have trios data. @pichuan , Is it possible to train a model without trios data?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1929,energy efficiency,model,model,1929,"Hi,. Thanks for the reply, but it doesn't address my question. My doubt is about how to generate the bam file for doing the variant calling. For the checking/validation approach, I would like to ask a few questions. > Ok, then this would probably be my approach:. > . > 1. Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". I did medium coverage sequencing based on some literature, but since my species might have high genetic diversity I used depth higher than recommended (1x), about ~10X per individual. https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0079667. https://onlinelibrary.wiley.com/doi/10.1111/mec.12105. https://pubmed.ncbi.nlm.nih.gov/34250668/. Then, I can't use the minimum depth you suggest of 15; my data should be good quality, hence GQ of 20 is fine, but depth of 15 is not achievable. > 2. Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs. I am new in Bioinformatics, could you suggest a program to use to find those ""confident blocks"". I can't think of any program for doing it. I have short-reads not long-reads, hence finding SV is not very reliable. Any suggestion on how to check if a variant falls within a SV? > 3. Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks. > . > Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment. As mentioned before, I do not have trios data. @pichuan , Is it possible to train a model without trios data?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:864,integrability,pub,pubmed,864,"Hi,. Thanks for the reply, but it doesn't address my question. My doubt is about how to generate the bam file for doing the variant calling. For the checking/validation approach, I would like to ask a few questions. > Ok, then this would probably be my approach:. > . > 1. Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". I did medium coverage sequencing based on some literature, but since my species might have high genetic diversity I used depth higher than recommended (1x), about ~10X per individual. https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0079667. https://onlinelibrary.wiley.com/doi/10.1111/mec.12105. https://pubmed.ncbi.nlm.nih.gov/34250668/. Then, I can't use the minimum depth you suggest of 15; my data should be good quality, hence GQ of 20 is fine, but depth of 15 is not achievable. > 2. Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs. I am new in Bioinformatics, could you suggest a program to use to find those ""confident blocks"". I can't think of any program for doing it. I have short-reads not long-reads, hence finding SV is not very reliable. Any suggestion on how to check if a variant falls within a SV? > 3. Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks. > . > Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment. As mentioned before, I do not have trios data. @pichuan , Is it possible to train a model without trios data?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:437,modifiability,paramet,parameters,437,"Hi,. Thanks for the reply, but it doesn't address my question. My doubt is about how to generate the bam file for doing the variant calling. For the checking/validation approach, I would like to ask a few questions. > Ok, then this would probably be my approach:. > . > 1. Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". I did medium coverage sequencing based on some literature, but since my species might have high genetic diversity I used depth higher than recommended (1x), about ~10X per individual. https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0079667. https://onlinelibrary.wiley.com/doi/10.1111/mec.12105. https://pubmed.ncbi.nlm.nih.gov/34250668/. Then, I can't use the minimum depth you suggest of 15; my data should be good quality, hence GQ of 20 is fine, but depth of 15 is not achievable. > 2. Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs. I am new in Bioinformatics, could you suggest a program to use to find those ""confident blocks"". I can't think of any program for doing it. I have short-reads not long-reads, hence finding SV is not very reliable. Any suggestion on how to check if a variant falls within a SV? > 3. Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks. > . > Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment. As mentioned before, I do not have trios data. @pichuan , Is it possible to train a model without trios data?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:34,reliability,doe,doesn,34,"Hi,. Thanks for the reply, but it doesn't address my question. My doubt is about how to generate the bam file for doing the variant calling. For the checking/validation approach, I would like to ask a few questions. > Ok, then this would probably be my approach:. > . > 1. Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". I did medium coverage sequencing based on some literature, but since my species might have high genetic diversity I used depth higher than recommended (1x), about ~10X per individual. https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0079667. https://onlinelibrary.wiley.com/doi/10.1111/mec.12105. https://pubmed.ncbi.nlm.nih.gov/34250668/. Then, I can't use the minimum depth you suggest of 15; my data should be good quality, hence GQ of 20 is fine, but depth of 15 is not achievable. > 2. Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs. I am new in Bioinformatics, could you suggest a program to use to find those ""confident blocks"". I can't think of any program for doing it. I have short-reads not long-reads, hence finding SV is not very reliable. Any suggestion on how to check if a variant falls within a SV? > 3. Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks. > . > Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment. As mentioned before, I do not have trios data. @pichuan , Is it possible to train a model without trios data?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1490,reliability,reliab,reliable,1490,"Hi,. Thanks for the reply, but it doesn't address my question. My doubt is about how to generate the bam file for doing the variant calling. For the checking/validation approach, I would like to ask a few questions. > Ok, then this would probably be my approach:. > . > 1. Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". I did medium coverage sequencing based on some literature, but since my species might have high genetic diversity I used depth higher than recommended (1x), about ~10X per individual. https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0079667. https://onlinelibrary.wiley.com/doi/10.1111/mec.12105. https://pubmed.ncbi.nlm.nih.gov/34250668/. Then, I can't use the minimum depth you suggest of 15; my data should be good quality, hence GQ of 20 is fine, but depth of 15 is not achievable. > 2. Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs. I am new in Bioinformatics, could you suggest a program to use to find those ""confident blocks"". I can't think of any program for doing it. I have short-reads not long-reads, hence finding SV is not very reliable. Any suggestion on how to check if a variant falls within a SV? > 3. Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks. > . > Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment. As mentioned before, I do not have trios data. @pichuan , Is it possible to train a model without trios data?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:158,safety,valid,validation,158,"Hi,. Thanks for the reply, but it doesn't address my question. My doubt is about how to generate the bam file for doing the variant calling. For the checking/validation approach, I would like to ask a few questions. > Ok, then this would probably be my approach:. > . > 1. Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". I did medium coverage sequencing based on some literature, but since my species might have high genetic diversity I used depth higher than recommended (1x), about ~10X per individual. https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0079667. https://onlinelibrary.wiley.com/doi/10.1111/mec.12105. https://pubmed.ncbi.nlm.nih.gov/34250668/. Then, I can't use the minimum depth you suggest of 15; my data should be good quality, hence GQ of 20 is fine, but depth of 15 is not achievable. > 2. Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs. I am new in Bioinformatics, could you suggest a program to use to find those ""confident blocks"". I can't think of any program for doing it. I have short-reads not long-reads, hence finding SV is not very reliable. Any suggestion on how to check if a variant falls within a SV? > 3. Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks. > . > Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment. As mentioned before, I do not have trios data. @pichuan , Is it possible to train a model without trios data?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:158,security,validat,validation,158,"Hi,. Thanks for the reply, but it doesn't address my question. My doubt is about how to generate the bam file for doing the variant calling. For the checking/validation approach, I would like to ask a few questions. > Ok, then this would probably be my approach:. > . > 1. Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". I did medium coverage sequencing based on some literature, but since my species might have high genetic diversity I used depth higher than recommended (1x), about ~10X per individual. https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0079667. https://onlinelibrary.wiley.com/doi/10.1111/mec.12105. https://pubmed.ncbi.nlm.nih.gov/34250668/. Then, I can't use the minimum depth you suggest of 15; my data should be good quality, hence GQ of 20 is fine, but depth of 15 is not achievable. > 2. Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs. I am new in Bioinformatics, could you suggest a program to use to find those ""confident blocks"". I can't think of any program for doing it. I have short-reads not long-reads, hence finding SV is not very reliable. Any suggestion on how to check if a variant falls within a SV? > 3. Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks. > . > Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment. As mentioned before, I do not have trios data. @pichuan , Is it possible to train a model without trios data?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1568,security,Assess,Assess,1568,"Hi,. Thanks for the reply, but it doesn't address my question. My doubt is about how to generate the bam file for doing the variant calling. For the checking/validation approach, I would like to ask a few questions. > Ok, then this would probably be my approach:. > . > 1. Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". I did medium coverage sequencing based on some literature, but since my species might have high genetic diversity I used depth higher than recommended (1x), about ~10X per individual. https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0079667. https://onlinelibrary.wiley.com/doi/10.1111/mec.12105. https://pubmed.ncbi.nlm.nih.gov/34250668/. Then, I can't use the minimum depth you suggest of 15; my data should be good quality, hence GQ of 20 is fine, but depth of 15 is not achievable. > 2. Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs. I am new in Bioinformatics, could you suggest a program to use to find those ""confident blocks"". I can't think of any program for doing it. I have short-reads not long-reads, hence finding SV is not very reliable. Any suggestion on how to check if a variant falls within a SV? > 3. Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks. > . > Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment. As mentioned before, I do not have trios data. @pichuan , Is it possible to train a model without trios data?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1684,security,model,model,1684,"Hi,. Thanks for the reply, but it doesn't address my question. My doubt is about how to generate the bam file for doing the variant calling. For the checking/validation approach, I would like to ask a few questions. > Ok, then this would probably be my approach:. > . > 1. Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". I did medium coverage sequencing based on some literature, but since my species might have high genetic diversity I used depth higher than recommended (1x), about ~10X per individual. https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0079667. https://onlinelibrary.wiley.com/doi/10.1111/mec.12105. https://pubmed.ncbi.nlm.nih.gov/34250668/. Then, I can't use the minimum depth you suggest of 15; my data should be good quality, hence GQ of 20 is fine, but depth of 15 is not achievable. > 2. Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs. I am new in Bioinformatics, could you suggest a program to use to find those ""confident blocks"". I can't think of any program for doing it. I have short-reads not long-reads, hence finding SV is not very reliable. Any suggestion on how to check if a variant falls within a SV? > 3. Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks. > . > Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment. As mentioned before, I do not have trios data. @pichuan , Is it possible to train a model without trios data?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1929,security,model,model,1929,"Hi,. Thanks for the reply, but it doesn't address my question. My doubt is about how to generate the bam file for doing the variant calling. For the checking/validation approach, I would like to ask a few questions. > Ok, then this would probably be my approach:. > . > 1. Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". I did medium coverage sequencing based on some literature, but since my species might have high genetic diversity I used depth higher than recommended (1x), about ~10X per individual. https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0079667. https://onlinelibrary.wiley.com/doi/10.1111/mec.12105. https://pubmed.ncbi.nlm.nih.gov/34250668/. Then, I can't use the minimum depth you suggest of 15; my data should be good quality, hence GQ of 20 is fine, but depth of 15 is not achievable. > 2. Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs. I am new in Bioinformatics, could you suggest a program to use to find those ""confident blocks"". I can't think of any program for doing it. I have short-reads not long-reads, hence finding SV is not very reliable. Any suggestion on how to check if a variant falls within a SV? > 3. Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks. > . > Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment. As mentioned before, I do not have trios data. @pichuan , Is it possible to train a model without trios data?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:555,testability,coverag,coverage,555,"Hi,. Thanks for the reply, but it doesn't address my question. My doubt is about how to generate the bam file for doing the variant calling. For the checking/validation approach, I would like to ask a few questions. > Ok, then this would probably be my approach:. > . > 1. Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". I did medium coverage sequencing based on some literature, but since my species might have high genetic diversity I used depth higher than recommended (1x), about ~10X per individual. https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0079667. https://onlinelibrary.wiley.com/doi/10.1111/mec.12105. https://pubmed.ncbi.nlm.nih.gov/34250668/. Then, I can't use the minimum depth you suggest of 15; my data should be good quality, hence GQ of 20 is fine, but depth of 15 is not achievable. > 2. Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs. I am new in Bioinformatics, could you suggest a program to use to find those ""confident blocks"". I can't think of any program for doing it. I have short-reads not long-reads, hence finding SV is not very reliable. Any suggestion on how to check if a variant falls within a SV? > 3. Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks. > . > Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment. As mentioned before, I do not have trios data. @pichuan , Is it possible to train a model without trios data?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1791,testability,simpl,simplest,1791,"Hi,. Thanks for the reply, but it doesn't address my question. My doubt is about how to generate the bam file for doing the variant calling. For the checking/validation approach, I would like to ask a few questions. > Ok, then this would probably be my approach:. > . > 1. Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". I did medium coverage sequencing based on some literature, but since my species might have high genetic diversity I used depth higher than recommended (1x), about ~10X per individual. https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0079667. https://onlinelibrary.wiley.com/doi/10.1111/mec.12105. https://pubmed.ncbi.nlm.nih.gov/34250668/. Then, I can't use the minimum depth you suggest of 15; my data should be good quality, hence GQ of 20 is fine, but depth of 15 is not achievable. > 2. Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs. I am new in Bioinformatics, could you suggest a program to use to find those ""confident blocks"". I can't think of any program for doing it. I have short-reads not long-reads, hence finding SV is not very reliable. Any suggestion on how to check if a variant falls within a SV? > 3. Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks. > . > Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment. As mentioned before, I do not have trios data. @pichuan , Is it possible to train a model without trios data?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:453,usability,minim,minimum,453,"Hi,. Thanks for the reply, but it doesn't address my question. My doubt is about how to generate the bam file for doing the variant calling. For the checking/validation approach, I would like to ask a few questions. > Ok, then this would probably be my approach:. > . > 1. Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". I did medium coverage sequencing based on some literature, but since my species might have high genetic diversity I used depth higher than recommended (1x), about ~10X per individual. https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0079667. https://onlinelibrary.wiley.com/doi/10.1111/mec.12105. https://pubmed.ncbi.nlm.nih.gov/34250668/. Then, I can't use the minimum depth you suggest of 15; my data should be good quality, hence GQ of 20 is fine, but depth of 15 is not achievable. > 2. Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs. I am new in Bioinformatics, could you suggest a program to use to find those ""confident blocks"". I can't think of any program for doing it. I have short-reads not long-reads, hence finding SV is not very reliable. Any suggestion on how to check if a variant falls within a SV? > 3. Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks. > . > Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment. As mentioned before, I do not have trios data. @pichuan , Is it possible to train a model without trios data?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:921,usability,minim,minimum,921,"Hi,. Thanks for the reply, but it doesn't address my question. My doubt is about how to generate the bam file for doing the variant calling. For the checking/validation approach, I would like to ask a few questions. > Ok, then this would probably be my approach:. > . > 1. Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". I did medium coverage sequencing based on some literature, but since my species might have high genetic diversity I used depth higher than recommended (1x), about ~10X per individual. https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0079667. https://onlinelibrary.wiley.com/doi/10.1111/mec.12105. https://pubmed.ncbi.nlm.nih.gov/34250668/. Then, I can't use the minimum depth you suggest of 15; my data should be good quality, hence GQ of 20 is fine, but depth of 15 is not achievable. > 2. Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs. I am new in Bioinformatics, could you suggest a program to use to find those ""confident blocks"". I can't think of any program for doing it. I have short-reads not long-reads, hence finding SV is not very reliable. Any suggestion on how to check if a variant falls within a SV? > 3. Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks. > . > Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment. As mentioned before, I do not have trios data. @pichuan , Is it possible to train a model without trios data?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1791,usability,simpl,simplest,1791,"Hi,. Thanks for the reply, but it doesn't address my question. My doubt is about how to generate the bam file for doing the variant calling. For the checking/validation approach, I would like to ask a few questions. > Ok, then this would probably be my approach:. > . > 1. Call variants individually on all of the samples indepedently (not using a trio caller, use DeepVariant or something) and create a combined gVCF using glnexus. Set parameters like minimum depth of 15 and GQ 20. Then find blocks that you can use as ""confident regions"". I did medium coverage sequencing based on some literature, but since my species might have high genetic diversity I used depth higher than recommended (1x), about ~10X per individual. https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0079667. https://onlinelibrary.wiley.com/doi/10.1111/mec.12105. https://pubmed.ncbi.nlm.nih.gov/34250668/. Then, I can't use the minimum depth you suggest of 15; my data should be good quality, hence GQ of 20 is fine, but depth of 15 is not achievable. > 2. Pick a few samples and apply the confident regions on them and see if you get mostly variants with GQ>=20 with them. At this point you may need to make sure they are not falling within an SV for some samples. This gives you truth VCFs. I am new in Bioinformatics, could you suggest a program to use to find those ""confident blocks"". I can't think of any program for doing it. I have short-reads not long-reads, hence finding SV is not very reliable. Any suggestion on how to check if a variant falls within a SV? > 3. Assess the F1-score of current DeepVariant using your truth vcf and bed and see how it looks. > . > Finally train a model and see if the F1-score improves. I am sure there are better ways to do this, but, this would be the simplest and least blocking path for this experiment. As mentioned before, I do not have trios data. @pichuan , Is it possible to train a model without trios data?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:996,availability,avail,available,996,"Hi @desmodus1984 ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: **Would you be able to get truth data for the bats you're studying**? I quickly looked through your recent discussion with @kishwarshafin . I believe @kishwarshafin has been trying to give you some tips on ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:839,deployability,releas,release,839,"Hi @desmodus1984 ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: **Would you be able to get truth data for the bats you're studying**? I quickly looked through your recent discussion with @kishwarshafin . I believe @kishwarshafin has been trying to give you some tips on ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:122,energy efficiency,core,core,122,"Hi @desmodus1984 ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: **Would you be able to get truth data for the bats you're studying**? I quickly looked through your recent discussion with @kishwarshafin . I believe @kishwarshafin has been trying to give you some tips on ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:468,energy efficiency,model,models,468,"Hi @desmodus1984 ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: **Would you be able to get truth data for the bats you're studying**? I quickly looked through your recent discussion with @kishwarshafin . I believe @kishwarshafin has been trying to give you some tips on ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:734,energy efficiency,model,model,734,"Hi @desmodus1984 ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: **Would you be able to get truth data for the bats you're studying**? I quickly looked through your recent discussion with @kishwarshafin . I believe @kishwarshafin has been trying to give you some tips on ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:847,energy efficiency,model,models,847,"Hi @desmodus1984 ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: **Would you be able to get truth data for the bats you're studying**? I quickly looked through your recent discussion with @kishwarshafin . I believe @kishwarshafin has been trying to give you some tips on ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:944,energy efficiency,model,model,944,"Hi @desmodus1984 ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: **Would you be able to get truth data for the bats you're studying**? I quickly looked through your recent discussion with @kishwarshafin . I believe @kishwarshafin has been trying to give you some tips on ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1040,energy efficiency,model,model,1040,"Hi @desmodus1984 ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: **Would you be able to get truth data for the bats you're studying**? I quickly looked through your recent discussion with @kishwarshafin . I believe @kishwarshafin has been trying to give you some tips on ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:406,integrability,topic,topic,406,"Hi @desmodus1984 ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: **Would you be able to get truth data for the bats you're studying**? I quickly looked through your recent discussion with @kishwarshafin . I believe @kishwarshafin has been trying to give you some tips on ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:996,reliability,availab,available,996,"Hi @desmodus1984 ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: **Would you be able to get truth data for the bats you're studying**? I quickly looked through your recent discussion with @kishwarshafin . I believe @kishwarshafin has been trying to give you some tips on ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1065,reliability,Doe,Does,1065,"Hi @desmodus1984 ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: **Would you be able to get truth data for the bats you're studying**? I quickly looked through your recent discussion with @kishwarshafin . I believe @kishwarshafin has been trying to give you some tips on ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:996,safety,avail,available,996,"Hi @desmodus1984 ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: **Would you be able to get truth data for the bats you're studying**? I quickly looked through your recent discussion with @kishwarshafin . I believe @kishwarshafin has been trying to give you some tips on ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:468,security,model,models,468,"Hi @desmodus1984 ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: **Would you be able to get truth data for the bats you're studying**? I quickly looked through your recent discussion with @kishwarshafin . I believe @kishwarshafin has been trying to give you some tips on ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:734,security,model,model,734,"Hi @desmodus1984 ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: **Would you be able to get truth data for the bats you're studying**? I quickly looked through your recent discussion with @kishwarshafin . I believe @kishwarshafin has been trying to give you some tips on ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:847,security,model,models,847,"Hi @desmodus1984 ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: **Would you be able to get truth data for the bats you're studying**? I quickly looked through your recent discussion with @kishwarshafin . I believe @kishwarshafin has been trying to give you some tips on ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:944,security,model,model,944,"Hi @desmodus1984 ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: **Would you be able to get truth data for the bats you're studying**? I quickly looked through your recent discussion with @kishwarshafin . I believe @kishwarshafin has been trying to give you some tips on ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:996,security,availab,available,996,"Hi @desmodus1984 ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: **Would you be able to get truth data for the bats you're studying**? I quickly looked through your recent discussion with @kishwarshafin . I believe @kishwarshafin has been trying to give you some tips on ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1040,security,model,model,1040,"Hi @desmodus1984 ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: **Would you be able to get truth data for the bats you're studying**? I quickly looked through your recent discussion with @kishwarshafin . I believe @kishwarshafin has been trying to give you some tips on ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:928,testability,plan,plan,928,"Hi @desmodus1984 ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: **Would you be able to get truth data for the bats you're studying**? I quickly looked through your recent discussion with @kishwarshafin . I believe @kishwarshafin has been trying to give you some tips on ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:343,usability,tip,tips,343,"Hi @desmodus1984 ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: **Would you be able to get truth data for the bats you're studying**? I quickly looked through your recent discussion with @kishwarshafin . I believe @kishwarshafin has been trying to give you some tips on ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:441,usability,user,users,441,"Hi @desmodus1984 ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: **Would you be able to get truth data for the bats you're studying**? I quickly looked through your recent discussion with @kishwarshafin . I believe @kishwarshafin has been trying to give you some tips on ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:612,usability,document,documentation,612,"Hi @desmodus1984 ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: **Would you be able to get truth data for the bats you're studying**? I quickly looked through your recent discussion with @kishwarshafin . I believe @kishwarshafin has been trying to give you some tips on ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1075,usability,help,help,1075,"Hi @desmodus1984 ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: **Would you be able to get truth data for the bats you're studying**? I quickly looked through your recent discussion with @kishwarshafin . I believe @kishwarshafin has been trying to give you some tips on ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:2000,availability,avail,available,2000,"gy, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know. . Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/878#issuecomment-2364726373>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AJWD2VJ75MSKTWY7ILOFVM3ZXSRLBAVCNFSM6AAAAABNXT6B26VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGNRUG4ZDMMZXGM>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1843,deployability,releas,release,1843,"gy, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know. . Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/878#issuecomment-2364726373>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AJWD2VJ75MSKTWY7ILOFVM3ZXSRLBAVCNFSM6AAAAABNXT6B26VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGNRUG4ZDMMZXGM>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1057,energy efficiency,core,core,1057,"out how to make the bam files for DeepVariant. ""DeepVariant is a deep learning-based variant caller that takes aligned reads (in BAM or CRAM format)"". The documentation doesn't say anything about how to make it/them. For instance, one can filter reads based on mapping quality- which is not mentioned in the workflow of GATK, or mark PCR duplicates and also remove them. For example, GATK needs read group information like sample ID, sequencing technology, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is workin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1472,energy efficiency,model,models,1472,"n like sample ID, sequencing technology, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know. . Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/878#issuecomment-2364726373>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AJWD2VJ75MSKTWY7ILOFVM3ZXSRLBAVCNFSM6AAAAABNXT6B26VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGNRUG4ZDMMZXGM>. You are receiving this because you wer",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1738,energy efficiency,model,model,1738,"gy, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know. . Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/878#issuecomment-2364726373>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AJWD2VJ75MSKTWY7ILOFVM3ZXSRLBAVCNFSM6AAAAABNXT6B26VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGNRUG4ZDMMZXGM>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1851,energy efficiency,model,models,1851,"gy, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know. . Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/878#issuecomment-2364726373>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AJWD2VJ75MSKTWY7ILOFVM3ZXSRLBAVCNFSM6AAAAABNXT6B26VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGNRUG4ZDMMZXGM>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1948,energy efficiency,model,model,1948,"gy, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know. . Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/878#issuecomment-2364726373>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AJWD2VJ75MSKTWY7ILOFVM3ZXSRLBAVCNFSM6AAAAABNXT6B26VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGNRUG4ZDMMZXGM>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:2044,energy efficiency,model,model,2044,"gy, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know. . Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/878#issuecomment-2364726373>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AJWD2VJ75MSKTWY7ILOFVM3ZXSRLBAVCNFSM6AAAAABNXT6B26VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGNRUG4ZDMMZXGM>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:298,integrability,filter,filter,298,"Hi,. Yes, my main question has not been addressed, it is about how to make the bam files for DeepVariant. ""DeepVariant is a deep learning-based variant caller that takes aligned reads (in BAM or CRAM format)"". The documentation doesn't say anything about how to make it/them. For instance, one can filter reads based on mapping quality- which is not mentioned in the workflow of GATK, or mark PCR duplicates and also remove them. For example, GATK needs read group information like sample ID, sequencing technology, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:760,integrability,Sub,Subject,760,"Hi,. Yes, my main question has not been addressed, it is about how to make the bam files for DeepVariant. ""DeepVariant is a deep learning-based variant caller that takes aligned reads (in BAM or CRAM format)"". The documentation doesn't say anything about how to make it/them. For instance, one can filter reads based on mapping quality- which is not mentioned in the workflow of GATK, or mark PCR duplicates and also remove them. For example, GATK needs read group information like sample ID, sequencing technology, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1410,integrability,topic,topic,1410,"lso remove them. For example, GATK needs read group information like sample ID, sequencing technology, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know. . Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/878#issuecomment-2364726373>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AJWD2VJ75MSKTWY7ILOFVM3ZXSRLBAVCNFSM6AAAAABNXT6B26VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:2487,integrability,Messag,Message,2487,"gy, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know. . Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/878#issuecomment-2364726373>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AJWD2VJ75MSKTWY7ILOFVM3ZXSRLBAVCNFSM6AAAAABNXT6B26VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGNRUG4ZDMMZXGM>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:200,interoperability,format,format,200,"Hi,. Yes, my main question has not been addressed, it is about how to make the bam files for DeepVariant. ""DeepVariant is a deep learning-based variant caller that takes aligned reads (in BAM or CRAM format)"". The documentation doesn't say anything about how to make it/them. For instance, one can filter reads based on mapping quality- which is not mentioned in the workflow of GATK, or mark PCR duplicates and also remove them. For example, GATK needs read group information like sample ID, sequencing technology, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:2487,interoperability,Messag,Message,2487,"gy, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know. . Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/878#issuecomment-2364726373>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AJWD2VJ75MSKTWY7ILOFVM3ZXSRLBAVCNFSM6AAAAABNXT6B26VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGNRUG4ZDMMZXGM>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:228,reliability,doe,doesn,228,"Hi,. Yes, my main question has not been addressed, it is about how to make the bam files for DeepVariant. ""DeepVariant is a deep learning-based variant caller that takes aligned reads (in BAM or CRAM format)"". The documentation doesn't say anything about how to make it/them. For instance, one can filter reads based on mapping quality- which is not mentioned in the workflow of GATK, or mark PCR duplicates and also remove them. For example, GATK needs read group information like sample ID, sequencing technology, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:2000,reliability,availab,available,2000,"gy, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know. . Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/878#issuecomment-2364726373>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AJWD2VJ75MSKTWY7ILOFVM3ZXSRLBAVCNFSM6AAAAABNXT6B26VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGNRUG4ZDMMZXGM>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:2069,reliability,Doe,Does,2069,"gy, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know. . Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/878#issuecomment-2364726373>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AJWD2VJ75MSKTWY7ILOFVM3ZXSRLBAVCNFSM6AAAAABNXT6B26VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGNRUG4ZDMMZXGM>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:2000,safety,avail,available,2000,"gy, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know. . Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/878#issuecomment-2364726373>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AJWD2VJ75MSKTWY7ILOFVM3ZXSRLBAVCNFSM6AAAAABNXT6B26VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGNRUG4ZDMMZXGM>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1472,security,model,models,1472,"n like sample ID, sequencing technology, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know. . Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/878#issuecomment-2364726373>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AJWD2VJ75MSKTWY7ILOFVM3ZXSRLBAVCNFSM6AAAAABNXT6B26VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGNRUG4ZDMMZXGM>. You are receiving this because you wer",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1738,security,model,model,1738,"gy, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know. . Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/878#issuecomment-2364726373>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AJWD2VJ75MSKTWY7ILOFVM3ZXSRLBAVCNFSM6AAAAABNXT6B26VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGNRUG4ZDMMZXGM>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1851,security,model,models,1851,"gy, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know. . Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/878#issuecomment-2364726373>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AJWD2VJ75MSKTWY7ILOFVM3ZXSRLBAVCNFSM6AAAAABNXT6B26VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGNRUG4ZDMMZXGM>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1948,security,model,model,1948,"gy, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know. . Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/878#issuecomment-2364726373>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AJWD2VJ75MSKTWY7ILOFVM3ZXSRLBAVCNFSM6AAAAABNXT6B26VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGNRUG4ZDMMZXGM>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:2000,security,availab,available,2000,"gy, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know. . Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/878#issuecomment-2364726373>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AJWD2VJ75MSKTWY7ILOFVM3ZXSRLBAVCNFSM6AAAAABNXT6B26VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGNRUG4ZDMMZXGM>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:2044,security,model,model,2044,"gy, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know. . Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/878#issuecomment-2364726373>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AJWD2VJ75MSKTWY7ILOFVM3ZXSRLBAVCNFSM6AAAAABNXT6B26VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGNRUG4ZDMMZXGM>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:2323,security,auth,auth,2323,"gy, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know. . Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/878#issuecomment-2364726373>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AJWD2VJ75MSKTWY7ILOFVM3ZXSRLBAVCNFSM6AAAAABNXT6B26VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGNRUG4ZDMMZXGM>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1932,testability,plan,plan,1932,"gy, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know. . Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/878#issuecomment-2364726373>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AJWD2VJ75MSKTWY7ILOFVM3ZXSRLBAVCNFSM6AAAAABNXT6B26VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGNRUG4ZDMMZXGM>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:129,usability,learn,learning-based,129,"Hi,. Yes, my main question has not been addressed, it is about how to make the bam files for DeepVariant. ""DeepVariant is a deep learning-based variant caller that takes aligned reads (in BAM or CRAM format)"". The documentation doesn't say anything about how to make it/them. For instance, one can filter reads based on mapping quality- which is not mentioned in the workflow of GATK, or mark PCR duplicates and also remove them. For example, GATK needs read group information like sample ID, sequencing technology, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:214,usability,document,documentation,214,"Hi,. Yes, my main question has not been addressed, it is about how to make the bam files for DeepVariant. ""DeepVariant is a deep learning-based variant caller that takes aligned reads (in BAM or CRAM format)"". The documentation doesn't say anything about how to make it/them. For instance, one can filter reads based on mapping quality- which is not mentioned in the workflow of GATK, or mark PCR duplicates and also remove them. For example, GATK needs read group information like sample ID, sequencing technology, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:367,usability,workflow,workflow,367,"Hi,. Yes, my main question has not been addressed, it is about how to make the bam files for DeepVariant. ""DeepVariant is a deep learning-based variant caller that takes aligned reads (in BAM or CRAM format)"". The documentation doesn't say anything about how to make it/them. For instance, one can filter reads based on mapping quality- which is not mentioned in the workflow of GATK, or mark PCR duplicates and also remove them. For example, GATK needs read group information like sample ID, sequencing technology, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1342,usability,tip,tips,1342,"s not mentioned in the workflow of GATK, or mark PCR duplicates and also remove them. For example, GATK needs read group information like sample ID, sequencing technology, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know. . Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/878#issuecomment-2364726373>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AJWD2VJ75MSKTWY7",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1445,usability,user,users,1445,"needs read group information like sample ID, sequencing technology, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know. . Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/878#issuecomment-2364726373>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AJWD2VJ75MSKTWY7ILOFVM3ZXSRLBAVCNFSM6AAAAABNXT6B26VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGNRUG4ZDMMZXGM>. You are rec",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:1616,usability,document,documentation,1616,"gy, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know. . Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/878#issuecomment-2364726373>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AJWD2VJ75MSKTWY7ILOFVM3ZXSRLBAVCNFSM6AAAAABNXT6B26VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGNRUG4ZDMMZXGM>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:2079,usability,help,help,2079,"gy, etc. Juan Pablo Aguilar. ________________________________. From: Pi-Chuan Chang ***@***.***>. Sent: Friday, September 20, 2024 6:52:36 PM. To: google/deepvariant ***@***.***>. Cc: Aguilar Cabezas, Juan Pablo ***@***.***>; Mention ***@***.***>. Subject: [External] Re: [google/deepvariant] Retraining DeepVariant without trios data? (Issue #878). Use caution with links and attachments. Hi @desmodus1984<https://github.com/desmodus1984> ,. Fundamentally, training a DeepVariant requires truth data (truth variants and confident regions). The core question here is: Would you be able to get truth data for the bats you're studying? I quickly looked through your recent discussion with @kishwarshafin<https://github.com/kishwarshafin> . I believe @kishwarshafin<https://github.com/kishwarshafin> has been trying to give you some tips on some ways to construct truth. Note that this is an advanced topic. We don't expect most of our users to train DeepVariant models, or to construct truth data. However, if you do have truth data (truth variants and confident regions), you should be able to follow the documentation https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md to try to train a model. From your description above, I still think the best way to proceed is to directly use DeepVariant release models. Once you have the callsets, try to evaluate the calls first. Even if you plan to train a model, it'll be good to have those baseline metrics available, so you know whether your trained model is working or not. Does this help? If I'm misunderstanding your question, let me know. . Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/878#issuecomment-2364726373>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AJWD2VJ75MSKTWY7ILOFVM3ZXSRLBAVCNFSM6AAAAABNXT6B26VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGNRUG4ZDMMZXGM>. You are receiving this because you were mentioned.Message ID: ***@***.***>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:89,deployability,observ,observed,89,"Hi @desmodus1984 . For short-read sequencing, we generally recommend BWA MEM. We've also observed that minimap2 in short read mode works fairly well. There is no need to additionally filter based on mapping quality as that is already a parameter within DeepVariant. For short read (WGS and WES) presets, this already applies a minimum mapping quality threshold of 5. We don't observe any meaningful difference with or without duplicate marking, so we tend not to recommend that, but it's certain;y fine to add. DeepVariant doesn't require additional read group information either, though we add RGID and RGSM to be able to do things like populate the VCF header appropriately.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:376,deployability,observ,observe,376,"Hi @desmodus1984 . For short-read sequencing, we generally recommend BWA MEM. We've also observed that minimap2 in short read mode works fairly well. There is no need to additionally filter based on mapping quality as that is already a parameter within DeepVariant. For short read (WGS and WES) presets, this already applies a minimum mapping quality threshold of 5. We don't observe any meaningful difference with or without duplicate marking, so we tend not to recommend that, but it's certain;y fine to add. DeepVariant doesn't require additional read group information either, though we add RGID and RGSM to be able to do things like populate the VCF header appropriately.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:183,integrability,filter,filter,183,"Hi @desmodus1984 . For short-read sequencing, we generally recommend BWA MEM. We've also observed that minimap2 in short read mode works fairly well. There is no need to additionally filter based on mapping quality as that is already a parameter within DeepVariant. For short read (WGS and WES) presets, this already applies a minimum mapping quality threshold of 5. We don't observe any meaningful difference with or without duplicate marking, so we tend not to recommend that, but it's certain;y fine to add. DeepVariant doesn't require additional read group information either, though we add RGID and RGSM to be able to do things like populate the VCF header appropriately.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:236,modifiability,paramet,parameter,236,"Hi @desmodus1984 . For short-read sequencing, we generally recommend BWA MEM. We've also observed that minimap2 in short read mode works fairly well. There is no need to additionally filter based on mapping quality as that is already a parameter within DeepVariant. For short read (WGS and WES) presets, this already applies a minimum mapping quality threshold of 5. We don't observe any meaningful difference with or without duplicate marking, so we tend not to recommend that, but it's certain;y fine to add. DeepVariant doesn't require additional read group information either, though we add RGID and RGSM to be able to do things like populate the VCF header appropriately.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:523,reliability,doe,doesn,523,"Hi @desmodus1984 . For short-read sequencing, we generally recommend BWA MEM. We've also observed that minimap2 in short read mode works fairly well. There is no need to additionally filter based on mapping quality as that is already a parameter within DeepVariant. For short read (WGS and WES) presets, this already applies a minimum mapping quality threshold of 5. We don't observe any meaningful difference with or without duplicate marking, so we tend not to recommend that, but it's certain;y fine to add. DeepVariant doesn't require additional read group information either, though we add RGID and RGSM to be able to do things like populate the VCF header appropriately.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:89,testability,observ,observed,89,"Hi @desmodus1984 . For short-read sequencing, we generally recommend BWA MEM. We've also observed that minimap2 in short read mode works fairly well. There is no need to additionally filter based on mapping quality as that is already a parameter within DeepVariant. For short read (WGS and WES) presets, this already applies a minimum mapping quality threshold of 5. We don't observe any meaningful difference with or without duplicate marking, so we tend not to recommend that, but it's certain;y fine to add. DeepVariant doesn't require additional read group information either, though we add RGID and RGSM to be able to do things like populate the VCF header appropriately.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:376,testability,observ,observe,376,"Hi @desmodus1984 . For short-read sequencing, we generally recommend BWA MEM. We've also observed that minimap2 in short read mode works fairly well. There is no need to additionally filter based on mapping quality as that is already a parameter within DeepVariant. For short read (WGS and WES) presets, this already applies a minimum mapping quality threshold of 5. We don't observe any meaningful difference with or without duplicate marking, so we tend not to recommend that, but it's certain;y fine to add. DeepVariant doesn't require additional read group information either, though we add RGID and RGSM to be able to do things like populate the VCF header appropriately.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/878:327,usability,minim,minimum,327,"Hi @desmodus1984 . For short-read sequencing, we generally recommend BWA MEM. We've also observed that minimap2 in short read mode works fairly well. There is no need to additionally filter based on mapping quality as that is already a parameter within DeepVariant. For short read (WGS and WES) presets, this already applies a minimum mapping quality threshold of 5. We don't observe any meaningful difference with or without duplicate marking, so we tend not to recommend that, but it's certain;y fine to add. DeepVariant doesn't require additional read group information either, though we add RGID and RGSM to be able to do things like populate the VCF header appropriately.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/878
https://github.com/google/deepvariant/issues/879:324,availability,error,errors,324,"Hi @jellycatfish195 . This is interesting. You mention that Dockerfile did not work for directly, do you have more information on that? I notice you run `deepvbuild:latest` as opposed to `google/deepvariant:""${BIN_VERSION}""`, what prompted that decision? You also mention that you ran `build-prereq.sh` and encountered some errors. Do you have a log file of those errors? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:364,availability,error,errors,364,"Hi @jellycatfish195 . This is interesting. You mention that Dockerfile did not work for directly, do you have more information on that? I notice you run `deepvbuild:latest` as opposed to `google/deepvariant:""${BIN_VERSION}""`, what prompted that decision? You also mention that you ran `build-prereq.sh` and encountered some errors. Do you have a log file of those errors? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:286,deployability,build,build-prereq,286,"Hi @jellycatfish195 . This is interesting. You mention that Dockerfile did not work for directly, do you have more information on that? I notice you run `deepvbuild:latest` as opposed to `google/deepvariant:""${BIN_VERSION}""`, what prompted that decision? You also mention that you ran `build-prereq.sh` and encountered some errors. Do you have a log file of those errors? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:346,deployability,log,log,346,"Hi @jellycatfish195 . This is interesting. You mention that Dockerfile did not work for directly, do you have more information on that? I notice you run `deepvbuild:latest` as opposed to `google/deepvariant:""${BIN_VERSION}""`, what prompted that decision? You also mention that you ran `build-prereq.sh` and encountered some errors. Do you have a log file of those errors? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:324,performance,error,errors,324,"Hi @jellycatfish195 . This is interesting. You mention that Dockerfile did not work for directly, do you have more information on that? I notice you run `deepvbuild:latest` as opposed to `google/deepvariant:""${BIN_VERSION}""`, what prompted that decision? You also mention that you ran `build-prereq.sh` and encountered some errors. Do you have a log file of those errors? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:364,performance,error,errors,364,"Hi @jellycatfish195 . This is interesting. You mention that Dockerfile did not work for directly, do you have more information on that? I notice you run `deepvbuild:latest` as opposed to `google/deepvariant:""${BIN_VERSION}""`, what prompted that decision? You also mention that you ran `build-prereq.sh` and encountered some errors. Do you have a log file of those errors? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:324,safety,error,errors,324,"Hi @jellycatfish195 . This is interesting. You mention that Dockerfile did not work for directly, do you have more information on that? I notice you run `deepvbuild:latest` as opposed to `google/deepvariant:""${BIN_VERSION}""`, what prompted that decision? You also mention that you ran `build-prereq.sh` and encountered some errors. Do you have a log file of those errors? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:346,safety,log,log,346,"Hi @jellycatfish195 . This is interesting. You mention that Dockerfile did not work for directly, do you have more information on that? I notice you run `deepvbuild:latest` as opposed to `google/deepvariant:""${BIN_VERSION}""`, what prompted that decision? You also mention that you ran `build-prereq.sh` and encountered some errors. Do you have a log file of those errors? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:364,safety,error,errors,364,"Hi @jellycatfish195 . This is interesting. You mention that Dockerfile did not work for directly, do you have more information on that? I notice you run `deepvbuild:latest` as opposed to `google/deepvariant:""${BIN_VERSION}""`, what prompted that decision? You also mention that you ran `build-prereq.sh` and encountered some errors. Do you have a log file of those errors? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:346,security,log,log,346,"Hi @jellycatfish195 . This is interesting. You mention that Dockerfile did not work for directly, do you have more information on that? I notice you run `deepvbuild:latest` as opposed to `google/deepvariant:""${BIN_VERSION}""`, what prompted that decision? You also mention that you ran `build-prereq.sh` and encountered some errors. Do you have a log file of those errors? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:346,testability,log,log,346,"Hi @jellycatfish195 . This is interesting. You mention that Dockerfile did not work for directly, do you have more information on that? I notice you run `deepvbuild:latest` as opposed to `google/deepvariant:""${BIN_VERSION}""`, what prompted that decision? You also mention that you ran `build-prereq.sh` and encountered some errors. Do you have a log file of those errors? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:324,usability,error,errors,324,"Hi @jellycatfish195 . This is interesting. You mention that Dockerfile did not work for directly, do you have more information on that? I notice you run `deepvbuild:latest` as opposed to `google/deepvariant:""${BIN_VERSION}""`, what prompted that decision? You also mention that you ran `build-prereq.sh` and encountered some errors. Do you have a log file of those errors? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:364,usability,error,errors,364,"Hi @jellycatfish195 . This is interesting. You mention that Dockerfile did not work for directly, do you have more information on that? I notice you run `deepvbuild:latest` as opposed to `google/deepvariant:""${BIN_VERSION}""`, what prompted that decision? You also mention that you ran `build-prereq.sh` and encountered some errors. Do you have a log file of those errors? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:653,availability,down,downloaded,653,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:761,availability,error,errors,761,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1409,availability,error,error,1409,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1516,availability,error,error,1516,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:86,deployability,contain,container,86,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:161,deployability,contain,container,161,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:347,deployability,version,version,347,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:379,deployability,version,version,379,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:517,deployability,build,build,517,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:559,deployability,instal,install,559,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:634,deployability,build,build-prereq,634,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:724,deployability,build,building,724,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:794,deployability,modul,modules,794,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:895,deployability,build,build,895,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1430,deployability,depend,dependencies,1430,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:347,integrability,version,version,347,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:379,integrability,version,version,379,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1430,integrability,depend,dependencies,1430,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:387,interoperability,conflict,conflicts,387,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:347,modifiability,version,version,347,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:379,modifiability,version,version,379,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:794,modifiability,modul,modules,794,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1430,modifiability,depend,dependencies,1430,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:761,performance,error,errors,761,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1409,performance,error,error,1409,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1516,performance,error,error,1516,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:611,reliability,doe,does,611,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:761,safety,error,errors,761,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:794,safety,modul,modules,794,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1324,safety,test,tests,1324,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1409,safety,error,error,1409,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1430,safety,depend,dependencies,1430,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1516,safety,error,error,1516,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1324,testability,test,tests,1324,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1430,testability,depend,dependencies,1430,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1522,testability,trace,trace,1522,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:761,usability,error,errors,761,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1409,usability,error,error,1409,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1516,usability,error,error,1516,"Hi @lucasbrambrink ,. Thanks for your prompt response. I started with an empty docker container and ran each script manually. And after I built, I committed the container to create a new image: deepvbuild:latest. Because I made quite a few changes, I have lost track of all the changes I have made. . For example, I made quite some changes to the version numbers because pip has version conflicts. The main ones are that I had to use python3.9 and pandas 1.4.4. Also, I kind of have to switch between numpy 2.0.2 (to build) and 1.24.1 (to run). I also had to install tensorflow-addons from git repo because pip does not have that. In build-prereq.sh, I downloaded bazel 7.3.1 linux arm64 binary. The main difficulty lies in building pyclif. There were a lot of errors related to protobuf cmake modules or linking abseil but it worked in the end. I don't think they should cause problems if they build successfully. For `build_release_binaries.sh`, I had to change the folder name from `k8-opt` to `aarch64-opt`. I am not sure whether this would cause problems but I also commented out line 59: `find ""runfiles/com_google_deepvariant"" -name '*.so' -exec ln --force -s --relative ""runfiles/com_google_protobuf/python/google/protobuf/pyext/_message.so"" {} \;` because there were no such folders or .so files. Because all bazel tests are passed and the binaries are successfully built, I would think it is not an error related to the dependencies. I am not sure how to get more information on what may go wrong from the error trace. Please feel free to let me know if there is anything else I can run to generate more useful information. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2128,availability,echo,echo,2128,"prereq scripts install the CUDA libraries. # If you already have CUDA installed, such as on a properly provisioned. # Docker image, it shouldn't be necessary. export DV_INSTALL_GPU_DRIVERS=""${DV_INSTALL_GPU_DRIVERS:-0}"". . -export PYTHON_VERSION=3.8. +export PYTHON_VERSION=3.9. # shellcheck disable=SC2155. export PYTHON_BIN_PATH=""$(which python${PYTHON_VERSION})"". export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. index ad34e285..1fc2d203 100755. --- a/build-prereq.sh. +++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2554,availability,echo,echo,2554,"ON}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. index ad34e285..1fc2d203 100755. --- a/build-prereq.sh. +++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PI",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2724,availability,down,download,2724,"bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. index ad34e285..1fc2d203 100755. --- a/build-prereq.sh. +++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"".",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:3047,availability,down,download,3047,"ing_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. index ad34e285..1fc2d203 100755. --- a/build-prereq.sh. +++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:3439,availability,echo,echo,3439,"h. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dis",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5116,availability,error,error,5116,"ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5323,availability,operat,operator,5323,"@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5892,availability,operat,operator,5892,"${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6321,availability,error,error,6321,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6453,availability,Error,Error,6453,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6549,availability,Error,Error,6549,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6646,availability,Error,Error,6646,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6694,availability,Error,Error,6694,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6723,availability,error,error,6723,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:46,deployability,build,building,46,"Hi @lucasbrambrink ,. I tried to recreate the building process, so here are some changes I made to the scripts:. ```. diff --git a/settings.sh b/settings.sh. index 9d5f58c0..649b1bb8 100755. --- a/settings.sh. +++ b/settings.sh. @@ -89,18 +89,18 @@ export DV_GPU_BUILD=""${DV_GPU_BUILD:-0}"". # DeepVariant's call_variants step by >3x. This is called the GCP (Google Cloud. # Platform) optimized wheel because all GCP instances have at least Sandy Bridge. # or better chipsets, so this wheel should run anywhere on GCP. -export DV_USE_GCP_OPTIMIZED_TF_WHL=""${DV_USE_GCP_OPTIMIZED_TF_WHL:-1}"". +export DV_USE_GCP_OPTIMIZED_TF_WHL=""${DV_USE_GCP_OPTIMIZED_TF_WHL:-0}"". export GCP_OPTIMIZED_TF_WHL_FILENAME=""tensorflow-${DV_GCP_OPTIMIZED_TF_WHL_VERSION}.deepvariant_gcp-cp27-none-linux_x86_64.whl"". export GCP_OPTIMIZED_TF_WHL_PATH=""${DV_PACKAGE_BUCKET_PATH}/tensorflow"". export GCP_OPTIMIZED_TF_WHL_CURL_PATH=""${DV_PACKAGE_CURL_PATH}/tensorflow"". -export DV_TF_NUMPY_VERSION=""1.19.2"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. +export DV_TF_NUMPY_VERSION=""1.24.1"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. . # Set this to 1 to make our prereq scripts install the CUDA libraries. # If you already have CUDA installed, such as on a properly provisioned. # Docker image, it shouldn't be necessary. export DV_INSTALL_GPU_DRIVERS=""${DV_INSTALL_GPU_DRIVERS:-0}"". . -export PYTHON_VERSION=3.8. +export PYTHON_VERSION=3.9. # shellcheck disable=SC2155. export PYTHON_BIN_PATH=""$(which python${PYTHON_VERSION})"". export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1145,deployability,instal,install,1145,"ings.sh. index 9d5f58c0..649b1bb8 100755. --- a/settings.sh. +++ b/settings.sh. @@ -89,18 +89,18 @@ export DV_GPU_BUILD=""${DV_GPU_BUILD:-0}"". # DeepVariant's call_variants step by >3x. This is called the GCP (Google Cloud. # Platform) optimized wheel because all GCP instances have at least Sandy Bridge. # or better chipsets, so this wheel should run anywhere on GCP. -export DV_USE_GCP_OPTIMIZED_TF_WHL=""${DV_USE_GCP_OPTIMIZED_TF_WHL:-1}"". +export DV_USE_GCP_OPTIMIZED_TF_WHL=""${DV_USE_GCP_OPTIMIZED_TF_WHL:-0}"". export GCP_OPTIMIZED_TF_WHL_FILENAME=""tensorflow-${DV_GCP_OPTIMIZED_TF_WHL_VERSION}.deepvariant_gcp-cp27-none-linux_x86_64.whl"". export GCP_OPTIMIZED_TF_WHL_PATH=""${DV_PACKAGE_BUCKET_PATH}/tensorflow"". export GCP_OPTIMIZED_TF_WHL_CURL_PATH=""${DV_PACKAGE_CURL_PATH}/tensorflow"". -export DV_TF_NUMPY_VERSION=""1.19.2"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. +export DV_TF_NUMPY_VERSION=""1.24.1"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. . # Set this to 1 to make our prereq scripts install the CUDA libraries. # If you already have CUDA installed, such as on a properly provisioned. # Docker image, it shouldn't be necessary. export DV_INSTALL_GPU_DRIVERS=""${DV_INSTALL_GPU_DRIVERS:-0}"". . -export PYTHON_VERSION=3.8. +export PYTHON_VERSION=3.9. # shellcheck disable=SC2155. export PYTHON_BIN_PATH=""$(which python${PYTHON_VERSION})"". export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1200,deployability,instal,installed,1200,".sh. +++ b/settings.sh. @@ -89,18 +89,18 @@ export DV_GPU_BUILD=""${DV_GPU_BUILD:-0}"". # DeepVariant's call_variants step by >3x. This is called the GCP (Google Cloud. # Platform) optimized wheel because all GCP instances have at least Sandy Bridge. # or better chipsets, so this wheel should run anywhere on GCP. -export DV_USE_GCP_OPTIMIZED_TF_WHL=""${DV_USE_GCP_OPTIMIZED_TF_WHL:-1}"". +export DV_USE_GCP_OPTIMIZED_TF_WHL=""${DV_USE_GCP_OPTIMIZED_TF_WHL:-0}"". export GCP_OPTIMIZED_TF_WHL_FILENAME=""tensorflow-${DV_GCP_OPTIMIZED_TF_WHL_VERSION}.deepvariant_gcp-cp27-none-linux_x86_64.whl"". export GCP_OPTIMIZED_TF_WHL_PATH=""${DV_PACKAGE_BUCKET_PATH}/tensorflow"". export GCP_OPTIMIZED_TF_WHL_CURL_PATH=""${DV_PACKAGE_CURL_PATH}/tensorflow"". -export DV_TF_NUMPY_VERSION=""1.19.2"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. +export DV_TF_NUMPY_VERSION=""1.24.1"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. . # Set this to 1 to make our prereq scripts install the CUDA libraries. # If you already have CUDA installed, such as on a properly provisioned. # Docker image, it shouldn't be necessary. export DV_INSTALL_GPU_DRIVERS=""${DV_INSTALL_GPU_DRIVERS:-0}"". . -export PYTHON_VERSION=3.8. +export PYTHON_VERSION=3.9. # shellcheck disable=SC2155. export PYTHON_BIN_PATH=""$(which python${PYTHON_VERSION})"". export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/bui",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1233,deployability,provis,provisioned,1233,"+89,18 @@ export DV_GPU_BUILD=""${DV_GPU_BUILD:-0}"". # DeepVariant's call_variants step by >3x. This is called the GCP (Google Cloud. # Platform) optimized wheel because all GCP instances have at least Sandy Bridge. # or better chipsets, so this wheel should run anywhere on GCP. -export DV_USE_GCP_OPTIMIZED_TF_WHL=""${DV_USE_GCP_OPTIMIZED_TF_WHL:-1}"". +export DV_USE_GCP_OPTIMIZED_TF_WHL=""${DV_USE_GCP_OPTIMIZED_TF_WHL:-0}"". export GCP_OPTIMIZED_TF_WHL_FILENAME=""tensorflow-${DV_GCP_OPTIMIZED_TF_WHL_VERSION}.deepvariant_gcp-cp27-none-linux_x86_64.whl"". export GCP_OPTIMIZED_TF_WHL_PATH=""${DV_PACKAGE_BUCKET_PATH}/tensorflow"". export GCP_OPTIMIZED_TF_WHL_CURL_PATH=""${DV_PACKAGE_CURL_PATH}/tensorflow"". -export DV_TF_NUMPY_VERSION=""1.19.2"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. +export DV_TF_NUMPY_VERSION=""1.24.1"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. . # Set this to 1 to make our prereq scripts install the CUDA libraries. # If you already have CUDA installed, such as on a properly provisioned. # Docker image, it shouldn't be necessary. export DV_INSTALL_GPU_DRIVERS=""${DV_INSTALL_GPU_DRIVERS:-0}"". . -export PYTHON_VERSION=3.8. +export PYTHON_VERSION=3.9. # shellcheck disable=SC2155. export PYTHON_BIN_PATH=""$(which python${PYTHON_VERSION})"". export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. in",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1747,deployability,upgrad,upgraded,1747,"pvariant_gcp-cp27-none-linux_x86_64.whl"". export GCP_OPTIMIZED_TF_WHL_PATH=""${DV_PACKAGE_BUCKET_PATH}/tensorflow"". export GCP_OPTIMIZED_TF_WHL_CURL_PATH=""${DV_PACKAGE_CURL_PATH}/tensorflow"". -export DV_TF_NUMPY_VERSION=""1.19.2"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. +export DV_TF_NUMPY_VERSION=""1.24.1"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. . # Set this to 1 to make our prereq scripts install the CUDA libraries. # If you already have CUDA installed, such as on a properly provisioned. # Docker image, it shouldn't be necessary. export DV_INSTALL_GPU_DRIVERS=""${DV_INSTALL_GPU_DRIVERS:-0}"". . -export PYTHON_VERSION=3.8. +export PYTHON_VERSION=3.9. # shellcheck disable=SC2155. export PYTHON_BIN_PATH=""$(which python${PYTHON_VERSION})"". export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. index ad34e285..1fc2d203 100755. --- a/build-prereq.sh. +++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_ve",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2155,deployability,Stage,Stage,2155,"UDA libraries. # If you already have CUDA installed, such as on a properly provisioned. # Docker image, it shouldn't be necessary. export DV_INSTALL_GPU_DRIVERS=""${DV_INSTALL_GPU_DRIVERS:-0}"". . -export PYTHON_VERSION=3.8. +export PYTHON_VERSION=3.9. # shellcheck disable=SC2155. export PYTHON_BIN_PATH=""$(which python${PYTHON_VERSION})"". export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. index ad34e285..1fc2d203 100755. --- a/build-prereq.sh. +++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-lin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2202,deployability,build,build-prereq,2202,"d, such as on a properly provisioned. # Docker image, it shouldn't be necessary. export DV_INSTALL_GPU_DRIVERS=""${DV_INSTALL_GPU_DRIVERS:-0}"". . -export PYTHON_VERSION=3.8. +export PYTHON_VERSION=3.9. # shellcheck disable=SC2155. export PYTHON_BIN_PATH=""$(which python${PYTHON_VERSION})"". export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. index ad34e285..1fc2d203 100755. --- a/build-prereq.sh. +++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2220,deployability,build,build-prereq,2220,"operly provisioned. # Docker image, it shouldn't be necessary. export DV_INSTALL_GPU_DRIVERS=""${DV_INSTALL_GPU_DRIVERS:-0}"". . -export PYTHON_VERSION=3.8. +export PYTHON_VERSION=3.9. # shellcheck disable=SC2155. export PYTHON_BIN_PATH=""$(which python${PYTHON_VERSION})"". export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. index ad34e285..1fc2d203 100755. --- a/build-prereq.sh. +++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. +",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2276,deployability,build,build-prereq,2276,"ssary. export DV_INSTALL_GPU_DRIVERS=""${DV_INSTALL_GPU_DRIVERS:-0}"". . -export PYTHON_VERSION=3.8. +export PYTHON_VERSION=3.9. # shellcheck disable=SC2155. export PYTHON_BIN_PATH=""$(which python${PYTHON_VERSION})"". export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. index ad34e285..1fc2d203 100755. --- a/build-prereq.sh. +++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2299,deployability,build,build-prereq,2299,"L_GPU_DRIVERS=""${DV_INSTALL_GPU_DRIVERS:-0}"". . -export PYTHON_VERSION=3.8. +export PYTHON_VERSION=3.9. # shellcheck disable=SC2155. export PYTHON_BIN_PATH=""$(which python${PYTHON_VERSION})"". export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. index ad34e285..1fc2d203 100755. --- a/build-prereq.sh. +++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_cl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2374,deployability,Instal,Install,2374,"8. +export PYTHON_VERSION=3.9. # shellcheck disable=SC2155. export PYTHON_BIN_PATH=""$(which python${PYTHON_VERSION})"". export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. index ad34e285..1fc2d203 100755. --- a/build-prereq.sh. +++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2464,deployability,Updat,Update,2464,"ch python${PYTHON_VERSION})"". export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. index ad34e285..1fc2d203 100755. --- a/build-prereq.sh. +++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this scr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2598,deployability,instal,installed,2598,"USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. index ad34e285..1fc2d203 100755. --- a/build-prereq.sh. +++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". P",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2715,deployability,releas,releases,2715,"int when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. index ad34e285..1fc2d203 100755. --- a/build-prereq.sh. +++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSI",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2791,deployability,instal,installer-linux-,2791,"=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. index ad34e285..1fc2d203 100755. --- a/build-prereq.sh. +++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2877,deployability,instal,installer-linux-,2877,"g_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. index ad34e285..1fc2d203 100755. --- a/build-prereq.sh. +++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2960,deployability,instal,installer-linux-,2960,"corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. index ad34e285..1fc2d203 100755. --- a/build-prereq.sh. +++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. w",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:3038,deployability,releas,releases,3038,"uild_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. index ad34e285..1fc2d203 100755. --- a/build-prereq.sh. +++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/li",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:3915,deployability,instal,install,3915,"ll. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. g",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:3945,deployability,instal,install-recommends,3945,"ion}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:3993,deployability,instal,install,3993,"wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/module",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4234,deployability,instal,install,4234,"sr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::l",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4279,deployability,instal,install,4279,"--git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4307,deployability,instal,install,4307,"b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4361,deployability,instal,install,4361,". --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. ma",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4371,deployability,upgrad,upgrade,4371,"ols/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4678,deployability,toolchain,toolchain,4678,"_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4743,deployability,instal,install,4743,"set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4991,deployability,modul,modules,4991,"stall ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMess",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5019,deployability,INSTAL,INSTALL,5019,"n3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5077,deployability,build,building,5077,"kg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5265,deployability,Log,LogMessage,5265,"ev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_strin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5311,deployability,Log,LogMessage,5311,"${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. colle",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5592,deployability,Log,LogMessage,5592,"add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5659,deployability,Log,LogMessage,5659,"se -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: ***",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5834,deployability,Log,LogMessage,5834,"hon3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5880,deployability,Log,LogMessage,5880,"if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the chang",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6161,deployability,Log,LogMessage,6161,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6228,deployability,Log,LogMessage,6228,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6410,deployability,build,build,6410,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6787,deployability,build,build,6787,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:365,energy efficiency,Cloud,Cloud,365,"Hi @lucasbrambrink ,. I tried to recreate the building process, so here are some changes I made to the scripts:. ```. diff --git a/settings.sh b/settings.sh. index 9d5f58c0..649b1bb8 100755. --- a/settings.sh. +++ b/settings.sh. @@ -89,18 +89,18 @@ export DV_GPU_BUILD=""${DV_GPU_BUILD:-0}"". # DeepVariant's call_variants step by >3x. This is called the GCP (Google Cloud. # Platform) optimized wheel because all GCP instances have at least Sandy Bridge. # or better chipsets, so this wheel should run anywhere on GCP. -export DV_USE_GCP_OPTIMIZED_TF_WHL=""${DV_USE_GCP_OPTIMIZED_TF_WHL:-1}"". +export DV_USE_GCP_OPTIMIZED_TF_WHL=""${DV_USE_GCP_OPTIMIZED_TF_WHL:-0}"". export GCP_OPTIMIZED_TF_WHL_FILENAME=""tensorflow-${DV_GCP_OPTIMIZED_TF_WHL_VERSION}.deepvariant_gcp-cp27-none-linux_x86_64.whl"". export GCP_OPTIMIZED_TF_WHL_PATH=""${DV_PACKAGE_BUCKET_PATH}/tensorflow"". export GCP_OPTIMIZED_TF_WHL_CURL_PATH=""${DV_PACKAGE_CURL_PATH}/tensorflow"". -export DV_TF_NUMPY_VERSION=""1.19.2"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. +export DV_TF_NUMPY_VERSION=""1.24.1"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. . # Set this to 1 to make our prereq scripts install the CUDA libraries. # If you already have CUDA installed, such as on a properly provisioned. # Docker image, it shouldn't be necessary. export DV_INSTALL_GPU_DRIVERS=""${DV_INSTALL_GPU_DRIVERS:-0}"". . -export PYTHON_VERSION=3.8. +export PYTHON_VERSION=3.9. # shellcheck disable=SC2155. export PYTHON_BIN_PATH=""$(which python${PYTHON_VERSION})"". export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:384,energy efficiency,optim,optimized,384,"Hi @lucasbrambrink ,. I tried to recreate the building process, so here are some changes I made to the scripts:. ```. diff --git a/settings.sh b/settings.sh. index 9d5f58c0..649b1bb8 100755. --- a/settings.sh. +++ b/settings.sh. @@ -89,18 +89,18 @@ export DV_GPU_BUILD=""${DV_GPU_BUILD:-0}"". # DeepVariant's call_variants step by >3x. This is called the GCP (Google Cloud. # Platform) optimized wheel because all GCP instances have at least Sandy Bridge. # or better chipsets, so this wheel should run anywhere on GCP. -export DV_USE_GCP_OPTIMIZED_TF_WHL=""${DV_USE_GCP_OPTIMIZED_TF_WHL:-1}"". +export DV_USE_GCP_OPTIMIZED_TF_WHL=""${DV_USE_GCP_OPTIMIZED_TF_WHL:-0}"". export GCP_OPTIMIZED_TF_WHL_FILENAME=""tensorflow-${DV_GCP_OPTIMIZED_TF_WHL_VERSION}.deepvariant_gcp-cp27-none-linux_x86_64.whl"". export GCP_OPTIMIZED_TF_WHL_PATH=""${DV_PACKAGE_BUCKET_PATH}/tensorflow"". export GCP_OPTIMIZED_TF_WHL_CURL_PATH=""${DV_PACKAGE_CURL_PATH}/tensorflow"". -export DV_TF_NUMPY_VERSION=""1.19.2"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. +export DV_TF_NUMPY_VERSION=""1.24.1"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. . # Set this to 1 to make our prereq scripts install the CUDA libraries. # If you already have CUDA installed, such as on a properly provisioned. # Docker image, it shouldn't be necessary. export DV_INSTALL_GPU_DRIVERS=""${DV_INSTALL_GPU_DRIVERS:-0}"". . -export PYTHON_VERSION=3.8. +export PYTHON_VERSION=3.9. # shellcheck disable=SC2155. export PYTHON_BIN_PATH=""$(which python${PYTHON_VERSION})"". export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:446,integrability,Bridg,Bridge,446,"Hi @lucasbrambrink ,. I tried to recreate the building process, so here are some changes I made to the scripts:. ```. diff --git a/settings.sh b/settings.sh. index 9d5f58c0..649b1bb8 100755. --- a/settings.sh. +++ b/settings.sh. @@ -89,18 +89,18 @@ export DV_GPU_BUILD=""${DV_GPU_BUILD:-0}"". # DeepVariant's call_variants step by >3x. This is called the GCP (Google Cloud. # Platform) optimized wheel because all GCP instances have at least Sandy Bridge. # or better chipsets, so this wheel should run anywhere on GCP. -export DV_USE_GCP_OPTIMIZED_TF_WHL=""${DV_USE_GCP_OPTIMIZED_TF_WHL:-1}"". +export DV_USE_GCP_OPTIMIZED_TF_WHL=""${DV_USE_GCP_OPTIMIZED_TF_WHL:-0}"". export GCP_OPTIMIZED_TF_WHL_FILENAME=""tensorflow-${DV_GCP_OPTIMIZED_TF_WHL_VERSION}.deepvariant_gcp-cp27-none-linux_x86_64.whl"". export GCP_OPTIMIZED_TF_WHL_PATH=""${DV_PACKAGE_BUCKET_PATH}/tensorflow"". export GCP_OPTIMIZED_TF_WHL_CURL_PATH=""${DV_PACKAGE_CURL_PATH}/tensorflow"". -export DV_TF_NUMPY_VERSION=""1.19.2"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. +export DV_TF_NUMPY_VERSION=""1.24.1"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. . # Set this to 1 to make our prereq scripts install the CUDA libraries. # If you already have CUDA installed, such as on a properly provisioned. # Docker image, it shouldn't be necessary. export DV_INSTALL_GPU_DRIVERS=""${DV_INSTALL_GPU_DRIVERS:-0}"". . -export PYTHON_VERSION=3.8. +export PYTHON_VERSION=3.9. # shellcheck disable=SC2155. export PYTHON_BIN_PATH=""$(which python${PYTHON_VERSION})"". export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4500,integrability,Configur,Configure,4500,"""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4522,integrability,repositor,repository,4522,"-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4617,integrability,repositor,repository,4617,"3.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:374,interoperability,Platform,Platform,374,"Hi @lucasbrambrink ,. I tried to recreate the building process, so here are some changes I made to the scripts:. ```. diff --git a/settings.sh b/settings.sh. index 9d5f58c0..649b1bb8 100755. --- a/settings.sh. +++ b/settings.sh. @@ -89,18 +89,18 @@ export DV_GPU_BUILD=""${DV_GPU_BUILD:-0}"". # DeepVariant's call_variants step by >3x. This is called the GCP (Google Cloud. # Platform) optimized wheel because all GCP instances have at least Sandy Bridge. # or better chipsets, so this wheel should run anywhere on GCP. -export DV_USE_GCP_OPTIMIZED_TF_WHL=""${DV_USE_GCP_OPTIMIZED_TF_WHL:-1}"". +export DV_USE_GCP_OPTIMIZED_TF_WHL=""${DV_USE_GCP_OPTIMIZED_TF_WHL:-0}"". export GCP_OPTIMIZED_TF_WHL_FILENAME=""tensorflow-${DV_GCP_OPTIMIZED_TF_WHL_VERSION}.deepvariant_gcp-cp27-none-linux_x86_64.whl"". export GCP_OPTIMIZED_TF_WHL_PATH=""${DV_PACKAGE_BUCKET_PATH}/tensorflow"". export GCP_OPTIMIZED_TF_WHL_CURL_PATH=""${DV_PACKAGE_CURL_PATH}/tensorflow"". -export DV_TF_NUMPY_VERSION=""1.19.2"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. +export DV_TF_NUMPY_VERSION=""1.24.1"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. . # Set this to 1 to make our prereq scripts install the CUDA libraries. # If you already have CUDA installed, such as on a properly provisioned. # Docker image, it shouldn't be necessary. export DV_INSTALL_GPU_DRIVERS=""${DV_INSTALL_GPU_DRIVERS:-0}"". . -export PYTHON_VERSION=3.8. +export PYTHON_VERSION=3.9. # shellcheck disable=SC2155. export PYTHON_BIN_PATH=""$(which python${PYTHON_VERSION})"". export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:446,interoperability,Bridg,Bridge,446,"Hi @lucasbrambrink ,. I tried to recreate the building process, so here are some changes I made to the scripts:. ```. diff --git a/settings.sh b/settings.sh. index 9d5f58c0..649b1bb8 100755. --- a/settings.sh. +++ b/settings.sh. @@ -89,18 +89,18 @@ export DV_GPU_BUILD=""${DV_GPU_BUILD:-0}"". # DeepVariant's call_variants step by >3x. This is called the GCP (Google Cloud. # Platform) optimized wheel because all GCP instances have at least Sandy Bridge. # or better chipsets, so this wheel should run anywhere on GCP. -export DV_USE_GCP_OPTIMIZED_TF_WHL=""${DV_USE_GCP_OPTIMIZED_TF_WHL:-1}"". +export DV_USE_GCP_OPTIMIZED_TF_WHL=""${DV_USE_GCP_OPTIMIZED_TF_WHL:-0}"". export GCP_OPTIMIZED_TF_WHL_FILENAME=""tensorflow-${DV_GCP_OPTIMIZED_TF_WHL_VERSION}.deepvariant_gcp-cp27-none-linux_x86_64.whl"". export GCP_OPTIMIZED_TF_WHL_PATH=""${DV_PACKAGE_BUCKET_PATH}/tensorflow"". export GCP_OPTIMIZED_TF_WHL_CURL_PATH=""${DV_PACKAGE_CURL_PATH}/tensorflow"". -export DV_TF_NUMPY_VERSION=""1.19.2"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. +export DV_TF_NUMPY_VERSION=""1.24.1"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. . # Set this to 1 to make our prereq scripts install the CUDA libraries. # If you already have CUDA installed, such as on a properly provisioned. # Docker image, it shouldn't be necessary. export DV_INSTALL_GPU_DRIVERS=""${DV_INSTALL_GPU_DRIVERS:-0}"". . -export PYTHON_VERSION=3.8. +export PYTHON_VERSION=3.9. # shellcheck disable=SC2155. export PYTHON_BIN_PATH=""$(which python${PYTHON_VERSION})"". export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:3756,interoperability,specif,specific,3756,"azel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_AR",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4522,interoperability,repositor,repository,4522,"-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4617,interoperability,repositor,repository,4617,"3.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1565,modifiability,pac,packages,1565,"PTIMIZED_TF_WHL:-1}"". +export DV_USE_GCP_OPTIMIZED_TF_WHL=""${DV_USE_GCP_OPTIMIZED_TF_WHL:-0}"". export GCP_OPTIMIZED_TF_WHL_FILENAME=""tensorflow-${DV_GCP_OPTIMIZED_TF_WHL_VERSION}.deepvariant_gcp-cp27-none-linux_x86_64.whl"". export GCP_OPTIMIZED_TF_WHL_PATH=""${DV_PACKAGE_BUCKET_PATH}/tensorflow"". export GCP_OPTIMIZED_TF_WHL_CURL_PATH=""${DV_PACKAGE_CURL_PATH}/tensorflow"". -export DV_TF_NUMPY_VERSION=""1.19.2"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. +export DV_TF_NUMPY_VERSION=""1.24.1"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. . # Set this to 1 to make our prereq scripts install the CUDA libraries. # If you already have CUDA installed, such as on a properly provisioned. # Docker image, it shouldn't be necessary. export DV_INSTALL_GPU_DRIVERS=""${DV_INSTALL_GPU_DRIVERS:-0}"". . -export PYTHON_VERSION=3.8. +export PYTHON_VERSION=3.9. # shellcheck disable=SC2155. export PYTHON_BIN_PATH=""$(which python${PYTHON_VERSION})"". export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. index ad34e285..1fc2d203 100755. --- a/build-prereq.sh. +++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${w",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1747,modifiability,upgrad,upgraded,1747,"pvariant_gcp-cp27-none-linux_x86_64.whl"". export GCP_OPTIMIZED_TF_WHL_PATH=""${DV_PACKAGE_BUCKET_PATH}/tensorflow"". export GCP_OPTIMIZED_TF_WHL_CURL_PATH=""${DV_PACKAGE_CURL_PATH}/tensorflow"". -export DV_TF_NUMPY_VERSION=""1.19.2"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. +export DV_TF_NUMPY_VERSION=""1.24.1"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. . # Set this to 1 to make our prereq scripts install the CUDA libraries. # If you already have CUDA installed, such as on a properly provisioned. # Docker image, it shouldn't be necessary. export DV_INSTALL_GPU_DRIVERS=""${DV_INSTALL_GPU_DRIVERS:-0}"". . -export PYTHON_VERSION=3.8. +export PYTHON_VERSION=3.9. # shellcheck disable=SC2155. export PYTHON_BIN_PATH=""$(which python${PYTHON_VERSION})"". export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. index ad34e285..1fc2d203 100755. --- a/build-prereq.sh. +++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_ve",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2394,modifiability,pac,packages,2394,"RSION=3.9. # shellcheck disable=SC2155. export PYTHON_BIN_PATH=""$(which python${PYTHON_VERSION})"". export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. index ad34e285..1fc2d203 100755. --- a/build-prereq.sh. +++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2471,modifiability,pac,package,2471,"n${PYTHON_VERSION})"". export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. index ad34e285..1fc2d203 100755. --- a/build-prereq.sh. +++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in r",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4057,modifiability,pac,packages,4057,"/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4371,modifiability,upgrad,upgrade,4371,"ols/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4443,modifiability,pac,packages,4443,"======= Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4500,modifiability,Configur,Configure,4500,"""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4991,modifiability,modul,modules,4991,"stall ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMess",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:384,performance,optimiz,optimized,384,"Hi @lucasbrambrink ,. I tried to recreate the building process, so here are some changes I made to the scripts:. ```. diff --git a/settings.sh b/settings.sh. index 9d5f58c0..649b1bb8 100755. --- a/settings.sh. +++ b/settings.sh. @@ -89,18 +89,18 @@ export DV_GPU_BUILD=""${DV_GPU_BUILD:-0}"". # DeepVariant's call_variants step by >3x. This is called the GCP (Google Cloud. # Platform) optimized wheel because all GCP instances have at least Sandy Bridge. # or better chipsets, so this wheel should run anywhere on GCP. -export DV_USE_GCP_OPTIMIZED_TF_WHL=""${DV_USE_GCP_OPTIMIZED_TF_WHL:-1}"". +export DV_USE_GCP_OPTIMIZED_TF_WHL=""${DV_USE_GCP_OPTIMIZED_TF_WHL:-0}"". export GCP_OPTIMIZED_TF_WHL_FILENAME=""tensorflow-${DV_GCP_OPTIMIZED_TF_WHL_VERSION}.deepvariant_gcp-cp27-none-linux_x86_64.whl"". export GCP_OPTIMIZED_TF_WHL_PATH=""${DV_PACKAGE_BUCKET_PATH}/tensorflow"". export GCP_OPTIMIZED_TF_WHL_CURL_PATH=""${DV_PACKAGE_CURL_PATH}/tensorflow"". -export DV_TF_NUMPY_VERSION=""1.19.2"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. +export DV_TF_NUMPY_VERSION=""1.24.1"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. . # Set this to 1 to make our prereq scripts install the CUDA libraries. # If you already have CUDA installed, such as on a properly provisioned. # Docker image, it shouldn't be necessary. export DV_INSTALL_GPU_DRIVERS=""${DV_INSTALL_GPU_DRIVERS:-0}"". . -export PYTHON_VERSION=3.8. +export PYTHON_VERSION=3.9. # shellcheck disable=SC2155. export PYTHON_BIN_PATH=""$(which python${PYTHON_VERSION})"". export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5116,performance,error,error,5116,"ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6321,performance,error,error,6321,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6453,performance,Error,Error,6453,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6549,performance,Error,Error,6549,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6646,performance,Error,Error,6646,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6694,performance,Error,Error,6694,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6723,performance,error,error,6723,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6734,performance,time,time,6734,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2464,safety,Updat,Update,2464,"ch python${PYTHON_VERSION})"". export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. index ad34e285..1fc2d203 100755. --- a/build-prereq.sh. +++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this scr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4991,safety,modul,modules,4991,"stall ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMess",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5116,safety,error,error,5116,"ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5265,safety,Log,LogMessage,5265,"ev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_strin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5311,safety,Log,LogMessage,5311,"${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. colle",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5592,safety,Log,LogMessage,5592,"add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5659,safety,Log,LogMessage,5659,"se -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: ***",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5834,safety,Log,LogMessage,5834,"hon3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5880,safety,Log,LogMessage,5880,"if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the chang",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6161,safety,Log,LogMessage,6161,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6228,safety,Log,LogMessage,6228,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6321,safety,error,error,6321,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6453,safety,Error,Error,6453,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6549,safety,Error,Error,6549,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6646,safety,Error,Error,6646,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6694,safety,Error,Error,6694,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6723,safety,error,error,6723,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1819,security,sign,sign-compare,1819,"=""${DV_PACKAGE_BUCKET_PATH}/tensorflow"". export GCP_OPTIMIZED_TF_WHL_CURL_PATH=""${DV_PACKAGE_CURL_PATH}/tensorflow"". -export DV_TF_NUMPY_VERSION=""1.19.2"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. +export DV_TF_NUMPY_VERSION=""1.24.1"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. . # Set this to 1 to make our prereq scripts install the CUDA libraries. # If you already have CUDA installed, such as on a properly provisioned. # Docker image, it shouldn't be necessary. export DV_INSTALL_GPU_DRIVERS=""${DV_INSTALL_GPU_DRIVERS:-0}"". . -export PYTHON_VERSION=3.8. +export PYTHON_VERSION=3.9. # shellcheck disable=SC2155. export PYTHON_BIN_PATH=""$(which python${PYTHON_VERSION})"". export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. index ad34e285..1fc2d203 100755. --- a/build-prereq.sh. +++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1987,security,sign,sign-compare,1987,"_OPTIMIZED_TF_WHL_FILENAME. +export DV_TF_NUMPY_VERSION=""1.24.1"" # To match GCP_OPTIMIZED_TF_WHL_FILENAME. . # Set this to 1 to make our prereq scripts install the CUDA libraries. # If you already have CUDA installed, such as on a properly provisioned. # Docker image, it shouldn't be necessary. export DV_INSTALL_GPU_DRIVERS=""${DV_INSTALL_GPU_DRIVERS:-0}"". . -export PYTHON_VERSION=3.8. +export PYTHON_VERSION=3.9. # shellcheck disable=SC2155. export PYTHON_BIN_PATH=""$(which python${PYTHON_VERSION})"". export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. index ad34e285..1fc2d203 100755. --- a/build-prereq.sh. +++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2464,security,Updat,Update,2464,"ch python${PYTHON_VERSION})"". export PYTHON_LIB_PATH=""/usr/local/lib/python${PYTHON_VERSION}/dist-packages"". @@ -112,7 +112,7 @@ export USE_DEFAULT_PYTHON_LIB_PATH=1. # --experimental_build_setting_api"". # Presumably it won't be needed at some later point when bazel_skylib is. # upgraded again. -export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. index ad34e285..1fc2d203 100755. --- a/build-prereq.sh. +++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this scr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:3772,security,hash,hash,3772,"_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. lib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:3907,security,apt,apt-get,3907," /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]];",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:3985,security,apt,apt-get,3985,"popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmak",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4026,security,apt,apt,4026,"ild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4226,security,apt,apt-get,4226,"od +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4299,security,apt,apt-get,4299,"clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_in",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4500,security,Configur,Configure,4500,"""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4518,security,apt,apt,4518,"VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4552,security,apt,apt,4552,"PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `v",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4589,security,apt,apt-key,4589,"a404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::L",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4613,security,apt,apt-repository,4613,".13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4640,security,apt,apt,4640,"RSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_2023080",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4735,security,apt,apt-get,4735," can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5265,security,Log,LogMessage,5265,"ev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_strin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5311,security,Log,LogMessage,5311,"${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. colle",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5592,security,Log,LogMessage,5592,"add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5659,security,Log,LogMessage,5659,"se -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: ***",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5834,security,Log,LogMessage,5834,"hon3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5880,security,Log,LogMessage,5880,"if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the chang",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6161,security,Log,LogMessage,6161,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6228,security,Log,LogMessage,6228,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5265,testability,Log,LogMessage,5265,"ev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_strin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5311,testability,Log,LogMessage,5311,"${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. colle",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5592,testability,Log,LogMessage,5592,"add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5659,testability,Log,LogMessage,5659,"se -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: ***",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5834,testability,Log,LogMessage,5834,"hon3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5880,testability,Log,LogMessage,5880,"if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the chang",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6161,testability,Log,LogMessage,6161,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6228,testability,Log,LogMessage,6228,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:2905,usability,user,user,2905,"ersion=remotejdk_11"". +# export DV_COPT_FLAGS=""--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings --experimental_build_setting_api --java_runtime_version=remotejdk_11"". . function note_build_stage {. echo ""========== [$(date)] Stage '${1}' starting"". ```. ```. diff --git a/build-prereq.sh b/build-prereq.sh. index ad34e285..1fc2d203 100755. --- a/build-prereq.sh. +++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:3291,usability,tool,tools,3291,"++ b/build-prereq.sh. @@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobje",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:3313,usability,tool,tools,3313,"@@ -41,7 +41,7 @@ source settings.sh. . note_build_stage ""Install the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install """,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:3373,usability,tool,tools,3373,"stall the runtime packages"". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgra",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:3400,usability,tool,tools,3400,". . -./run-prereq.sh. +#./run-prereq.sh. . note_build_stage ""Update package list"". . @@ -71,12 +71,17 @@ function ensure_wanted_bazel_version {. then. echo ""Bazel ${wanted_bazel_version} already installed on the machine, not reinstalling"". else. - pushd ~/bazel. - curl -L -O https://github.com/bazelbuild/bazel/releases/download/""${wanted_bazel_version}""/bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - chmod +x bazel-*.sh. - ./bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh --user > /dev/null. - rm bazel-""${wanted_bazel_version}""-installer-linux-x86_64.sh. - popd. + wget https://github.com/bazelbuild/bazel/releases/download/7.3.1/bazel-7.3.1-linux-arm64. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazel. + cp bazel-7.3.1-linux-arm64 /usr/local/bin/bazelisk. + chmod +x /usr/local/bin/bazel. + chmod +x /usr/local/bin/bazelisk. fi. }. ```. ```. diff --git a/tools/build_clif.sh b/tools/build_clif.sh. index c7c3378b..a08ab475 100755. --- a/tools/build_clif.sh. +++ b/tools/build_clif.sh. @@ -39,7 +39,7 @@ echo ========== Run this script in root mode. CLIF_UBUNTU_VERSION=""${CLIF_UBUNTU_VERSION-20.04}"". ABSL_PIN=""${ABSL_PIN-29bf8085f3bf17b84d30e34b3d7ff8248fda404e}"". PROTOBUF_VERSION=3.13.0. -CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.8}"". +CLIF_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/is",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4678,usability,tool,toolchain,4678,"_PYTHON_VERSION=""${CLIF_PYTHON_VERSION-3.9}"". # CLIF_PIN can be set to a specific commit hash on. # https://github.com/google/clif/commits/main. # If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:4827,usability,tool,tools,4827,"If not set, the default is to checkout the latest commit. @@ -65,6 +65,21 @@ apt-get install ""${APT_ARGS[@]}"" --no-install-recommends \. wget \. unzip. . +apt-get install ""${APT_ARGS[@]}"" python3-apt. +cd /usr/lib/python3/dist-packages. +if [ -e apt_pkg.so ]; then. + rm apt_pkg.so. +fi. +ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_intern",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:5116,usability,error,error,5116,"ln -s apt_pkg.cpython-38-aarch64-linux-gnu.so apt_pkg.so. +cd -. +. +export PATH=/root/.local/bin/:$PATH. +apt-get install ""${APT_ARGS[@]}"" libcairo2-dev. +pip install pygobject. +apt-get install ""${APT_ARGS[@]}"" libgirepository1.0-dev. +pip install --upgrade pygobject. +sed -i 's/isAlive/is_alive/g' /usr/lib/python3/dist-packages/softwareproperties/SoftwareProperties.py . +. # Configure LLVM 11 apt repository. wget -O - https://apt.llvm.org/llvm-snapshot.gpg.key | apt-key add - && \. add-apt-repository ""deb http://apt.llvm.org/$(lsb_release -sc)/ llvm-toolchain-$(lsb_release -sc)-11 main"". @@ -79,7 +94,6 @@ apt-get install ""${APT_ARGS[@]}"" \. libllvm11 \. llvm-11 \. llvm-11-dev \. - llvm-11-linker-tools \. python3-dev \. zlib1g-dev. . @@ -147,4 +161,5 @@ if [[ ! -z ${CLIF_PIN} ]]; then. git checkout ""${CLIF_PIN}"". fi. . +sed -i 's/11.1.0/11.0.0/g' clif/cmake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6321,usability,error,error,6321,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6347,usability,statu,status,6347,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6453,usability,Error,Error,6453,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6549,usability,Error,Error,6549,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6646,usability,Error,Error,6646,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6694,usability,Error,Error,6694,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:6723,usability,error,error,6723,"ake/modules/CLIFUtils.cmake . ./INSTALL.sh. ```. After these changes, I am stuck again at building clif because of the following error:. ```. [100%] Linking CXX executable clif-matcher. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <27>(char const (&) [27])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi27EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. /usr/bin/ld: libclifMatcher.a(matcher.cc.o): in function `absl::lts_20230802::log_internal::LogMessage& absl::lts_20230802::log_internal::LogMessage::operator<< <24>(char const (&) [24])':. matcher.cc:(.text._ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc[_ZN4absl12lts_2023080212log_internal10LogMessagelsILi24EEERS2_RAT__Kc]+0x38): undefined reference to `void absl::lts_20230802::log_internal::LogMessage::CopyToEncodedBuffer<(absl::lts_20230802::log_internal::LogMessage::StringType)0>(std::basic_string_view<char, std::char_traits<char> >)'. collect2: error: ld returned 1 exit status. make[3]: *** [clif/backend/CMakeFiles/clif-matcher.dir/build.make:147: clif/backend/clif-matcher] Error 1. make[2]: *** [CMakeFiles/Makefile2:1342: clif/backend/CMakeFiles/clif-matcher.dir/all] Error 2. make[1]: *** [CMakeFiles/Makefile2:1349: clif/backend/CMakeFiles/clif-matcher.dir/rule] Error 2. make: *** [Makefile:617: clif-matcher] Error 2. ```. I had the same error last time but it somehow worked magically when I removed `build/` folder after a while. I think these are the major changes I have made apart from the changes to the `build_release_binaries.sh`. Please feel free to let me know if anything looks weird to you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:278,availability,fault,fault,278,"Hi,. Thanks for providing all of that information, it is very helpful. The issue does actually lie in pyclif and protobuf. We use an older version of protobuf that is stable with pyclif; updating it will break the interoperability between C++ and Python (the source of that seg fault). Our tests in `build_and_test.sh` do not appear to catch this, of which I have made a note to update in the future. . Is there a reason you cannot use our Docker builds from `1.6.1`? Also, if docker does not work for you, are you able to use singularity? I am unsure that brute forcing a docker build will lead to a container that runs everything as intended.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:139,deployability,version,version,139,"Hi,. Thanks for providing all of that information, it is very helpful. The issue does actually lie in pyclif and protobuf. We use an older version of protobuf that is stable with pyclif; updating it will break the interoperability between C++ and Python (the source of that seg fault). Our tests in `build_and_test.sh` do not appear to catch this, of which I have made a note to update in the future. . Is there a reason you cannot use our Docker builds from `1.6.1`? Also, if docker does not work for you, are you able to use singularity? I am unsure that brute forcing a docker build will lead to a container that runs everything as intended.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:187,deployability,updat,updating,187,"Hi,. Thanks for providing all of that information, it is very helpful. The issue does actually lie in pyclif and protobuf. We use an older version of protobuf that is stable with pyclif; updating it will break the interoperability between C++ and Python (the source of that seg fault). Our tests in `build_and_test.sh` do not appear to catch this, of which I have made a note to update in the future. . Is there a reason you cannot use our Docker builds from `1.6.1`? Also, if docker does not work for you, are you able to use singularity? I am unsure that brute forcing a docker build will lead to a container that runs everything as intended.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:379,deployability,updat,update,379,"Hi,. Thanks for providing all of that information, it is very helpful. The issue does actually lie in pyclif and protobuf. We use an older version of protobuf that is stable with pyclif; updating it will break the interoperability between C++ and Python (the source of that seg fault). Our tests in `build_and_test.sh` do not appear to catch this, of which I have made a note to update in the future. . Is there a reason you cannot use our Docker builds from `1.6.1`? Also, if docker does not work for you, are you able to use singularity? I am unsure that brute forcing a docker build will lead to a container that runs everything as intended.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:447,deployability,build,builds,447,"Hi,. Thanks for providing all of that information, it is very helpful. The issue does actually lie in pyclif and protobuf. We use an older version of protobuf that is stable with pyclif; updating it will break the interoperability between C++ and Python (the source of that seg fault). Our tests in `build_and_test.sh` do not appear to catch this, of which I have made a note to update in the future. . Is there a reason you cannot use our Docker builds from `1.6.1`? Also, if docker does not work for you, are you able to use singularity? I am unsure that brute forcing a docker build will lead to a container that runs everything as intended.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:580,deployability,build,build,580,"Hi,. Thanks for providing all of that information, it is very helpful. The issue does actually lie in pyclif and protobuf. We use an older version of protobuf that is stable with pyclif; updating it will break the interoperability between C++ and Python (the source of that seg fault). Our tests in `build_and_test.sh` do not appear to catch this, of which I have made a note to update in the future. . Is there a reason you cannot use our Docker builds from `1.6.1`? Also, if docker does not work for you, are you able to use singularity? I am unsure that brute forcing a docker build will lead to a container that runs everything as intended.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:601,deployability,contain,container,601,"Hi,. Thanks for providing all of that information, it is very helpful. The issue does actually lie in pyclif and protobuf. We use an older version of protobuf that is stable with pyclif; updating it will break the interoperability between C++ and Python (the source of that seg fault). Our tests in `build_and_test.sh` do not appear to catch this, of which I have made a note to update in the future. . Is there a reason you cannot use our Docker builds from `1.6.1`? Also, if docker does not work for you, are you able to use singularity? I am unsure that brute forcing a docker build will lead to a container that runs everything as intended.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:278,energy efficiency,fault,fault,278,"Hi,. Thanks for providing all of that information, it is very helpful. The issue does actually lie in pyclif and protobuf. We use an older version of protobuf that is stable with pyclif; updating it will break the interoperability between C++ and Python (the source of that seg fault). Our tests in `build_and_test.sh` do not appear to catch this, of which I have made a note to update in the future. . Is there a reason you cannot use our Docker builds from `1.6.1`? Also, if docker does not work for you, are you able to use singularity? I am unsure that brute forcing a docker build will lead to a container that runs everything as intended.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:139,integrability,version,version,139,"Hi,. Thanks for providing all of that information, it is very helpful. The issue does actually lie in pyclif and protobuf. We use an older version of protobuf that is stable with pyclif; updating it will break the interoperability between C++ and Python (the source of that seg fault). Our tests in `build_and_test.sh` do not appear to catch this, of which I have made a note to update in the future. . Is there a reason you cannot use our Docker builds from `1.6.1`? Also, if docker does not work for you, are you able to use singularity? I am unsure that brute forcing a docker build will lead to a container that runs everything as intended.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:214,interoperability,interoperab,interoperability,214,"Hi,. Thanks for providing all of that information, it is very helpful. The issue does actually lie in pyclif and protobuf. We use an older version of protobuf that is stable with pyclif; updating it will break the interoperability between C++ and Python (the source of that seg fault). Our tests in `build_and_test.sh` do not appear to catch this, of which I have made a note to update in the future. . Is there a reason you cannot use our Docker builds from `1.6.1`? Also, if docker does not work for you, are you able to use singularity? I am unsure that brute forcing a docker build will lead to a container that runs everything as intended.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:139,modifiability,version,version,139,"Hi,. Thanks for providing all of that information, it is very helpful. The issue does actually lie in pyclif and protobuf. We use an older version of protobuf that is stable with pyclif; updating it will break the interoperability between C++ and Python (the source of that seg fault). Our tests in `build_and_test.sh` do not appear to catch this, of which I have made a note to update in the future. . Is there a reason you cannot use our Docker builds from `1.6.1`? Also, if docker does not work for you, are you able to use singularity? I am unsure that brute forcing a docker build will lead to a container that runs everything as intended.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:214,modifiability,interop,interoperability,214,"Hi,. Thanks for providing all of that information, it is very helpful. The issue does actually lie in pyclif and protobuf. We use an older version of protobuf that is stable with pyclif; updating it will break the interoperability between C++ and Python (the source of that seg fault). Our tests in `build_and_test.sh` do not appear to catch this, of which I have made a note to update in the future. . Is there a reason you cannot use our Docker builds from `1.6.1`? Also, if docker does not work for you, are you able to use singularity? I am unsure that brute forcing a docker build will lead to a container that runs everything as intended.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:278,performance,fault,fault,278,"Hi,. Thanks for providing all of that information, it is very helpful. The issue does actually lie in pyclif and protobuf. We use an older version of protobuf that is stable with pyclif; updating it will break the interoperability between C++ and Python (the source of that seg fault). Our tests in `build_and_test.sh` do not appear to catch this, of which I have made a note to update in the future. . Is there a reason you cannot use our Docker builds from `1.6.1`? Also, if docker does not work for you, are you able to use singularity? I am unsure that brute forcing a docker build will lead to a container that runs everything as intended.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:81,reliability,doe,does,81,"Hi,. Thanks for providing all of that information, it is very helpful. The issue does actually lie in pyclif and protobuf. We use an older version of protobuf that is stable with pyclif; updating it will break the interoperability between C++ and Python (the source of that seg fault). Our tests in `build_and_test.sh` do not appear to catch this, of which I have made a note to update in the future. . Is there a reason you cannot use our Docker builds from `1.6.1`? Also, if docker does not work for you, are you able to use singularity? I am unsure that brute forcing a docker build will lead to a container that runs everything as intended.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:278,reliability,fault,fault,278,"Hi,. Thanks for providing all of that information, it is very helpful. The issue does actually lie in pyclif and protobuf. We use an older version of protobuf that is stable with pyclif; updating it will break the interoperability between C++ and Python (the source of that seg fault). Our tests in `build_and_test.sh` do not appear to catch this, of which I have made a note to update in the future. . Is there a reason you cannot use our Docker builds from `1.6.1`? Also, if docker does not work for you, are you able to use singularity? I am unsure that brute forcing a docker build will lead to a container that runs everything as intended.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:484,reliability,doe,does,484,"Hi,. Thanks for providing all of that information, it is very helpful. The issue does actually lie in pyclif and protobuf. We use an older version of protobuf that is stable with pyclif; updating it will break the interoperability between C++ and Python (the source of that seg fault). Our tests in `build_and_test.sh` do not appear to catch this, of which I have made a note to update in the future. . Is there a reason you cannot use our Docker builds from `1.6.1`? Also, if docker does not work for you, are you able to use singularity? I am unsure that brute forcing a docker build will lead to a container that runs everything as intended.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:187,safety,updat,updating,187,"Hi,. Thanks for providing all of that information, it is very helpful. The issue does actually lie in pyclif and protobuf. We use an older version of protobuf that is stable with pyclif; updating it will break the interoperability between C++ and Python (the source of that seg fault). Our tests in `build_and_test.sh` do not appear to catch this, of which I have made a note to update in the future. . Is there a reason you cannot use our Docker builds from `1.6.1`? Also, if docker does not work for you, are you able to use singularity? I am unsure that brute forcing a docker build will lead to a container that runs everything as intended.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:278,safety,fault,fault,278,"Hi,. Thanks for providing all of that information, it is very helpful. The issue does actually lie in pyclif and protobuf. We use an older version of protobuf that is stable with pyclif; updating it will break the interoperability between C++ and Python (the source of that seg fault). Our tests in `build_and_test.sh` do not appear to catch this, of which I have made a note to update in the future. . Is there a reason you cannot use our Docker builds from `1.6.1`? Also, if docker does not work for you, are you able to use singularity? I am unsure that brute forcing a docker build will lead to a container that runs everything as intended.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:290,safety,test,tests,290,"Hi,. Thanks for providing all of that information, it is very helpful. The issue does actually lie in pyclif and protobuf. We use an older version of protobuf that is stable with pyclif; updating it will break the interoperability between C++ and Python (the source of that seg fault). Our tests in `build_and_test.sh` do not appear to catch this, of which I have made a note to update in the future. . Is there a reason you cannot use our Docker builds from `1.6.1`? Also, if docker does not work for you, are you able to use singularity? I am unsure that brute forcing a docker build will lead to a container that runs everything as intended.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:379,safety,updat,update,379,"Hi,. Thanks for providing all of that information, it is very helpful. The issue does actually lie in pyclif and protobuf. We use an older version of protobuf that is stable with pyclif; updating it will break the interoperability between C++ and Python (the source of that seg fault). Our tests in `build_and_test.sh` do not appear to catch this, of which I have made a note to update in the future. . Is there a reason you cannot use our Docker builds from `1.6.1`? Also, if docker does not work for you, are you able to use singularity? I am unsure that brute forcing a docker build will lead to a container that runs everything as intended.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:187,security,updat,updating,187,"Hi,. Thanks for providing all of that information, it is very helpful. The issue does actually lie in pyclif and protobuf. We use an older version of protobuf that is stable with pyclif; updating it will break the interoperability between C++ and Python (the source of that seg fault). Our tests in `build_and_test.sh` do not appear to catch this, of which I have made a note to update in the future. . Is there a reason you cannot use our Docker builds from `1.6.1`? Also, if docker does not work for you, are you able to use singularity? I am unsure that brute forcing a docker build will lead to a container that runs everything as intended.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:379,security,updat,update,379,"Hi,. Thanks for providing all of that information, it is very helpful. The issue does actually lie in pyclif and protobuf. We use an older version of protobuf that is stable with pyclif; updating it will break the interoperability between C++ and Python (the source of that seg fault). Our tests in `build_and_test.sh` do not appear to catch this, of which I have made a note to update in the future. . Is there a reason you cannot use our Docker builds from `1.6.1`? Also, if docker does not work for you, are you able to use singularity? I am unsure that brute forcing a docker build will lead to a container that runs everything as intended.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:290,testability,test,tests,290,"Hi,. Thanks for providing all of that information, it is very helpful. The issue does actually lie in pyclif and protobuf. We use an older version of protobuf that is stable with pyclif; updating it will break the interoperability between C++ and Python (the source of that seg fault). Our tests in `build_and_test.sh` do not appear to catch this, of which I have made a note to update in the future. . Is there a reason you cannot use our Docker builds from `1.6.1`? Also, if docker does not work for you, are you able to use singularity? I am unsure that brute forcing a docker build will lead to a container that runs everything as intended.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:62,usability,help,helpful,62,"Hi,. Thanks for providing all of that information, it is very helpful. The issue does actually lie in pyclif and protobuf. We use an older version of protobuf that is stable with pyclif; updating it will break the interoperability between C++ and Python (the source of that seg fault). Our tests in `build_and_test.sh` do not appear to catch this, of which I have made a note to update in the future. . Is there a reason you cannot use our Docker builds from `1.6.1`? Also, if docker does not work for you, are you able to use singularity? I am unsure that brute forcing a docker build will lead to a container that runs everything as intended.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1045,availability,error,error,1045,"Hi,. Thanks for your answer. It is good to know that pyclif and protobuf is the problem. I think I did not change the version of protobuf and pyclif because I did not change the commit numbers of the repositories, i.e. `ABSL_PIN`, `PROTOBUF_VERSION` or `CLIF_PYTHON_VERSION` in `tools/build_clif.sh`. I did change the python version number though because otherwise some packages are not installable through pip, e.g. jaxlib from clu requires python >= 3.9. I am not sure whether this is normal or it is the root cause of the problem. I did pull the Docker builds before I tried to build my own image but it seems it is built only for amd64 platform. The machine I use is in arm architecture, i.e. aarch64, so the docker build did not work for me. Please feel free to let me know if I am wrong. But I don't think singularity would solve this problem because it still needs the docker to be built for the target architecture or using multi-platform builds. Do you think it is feasible to have such a build in the future? P.S. I solved the linking error for clif by building abseil-cpp again right before building clif. I am not sure whether it is because something in between overwrites the path.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:118,deployability,version,version,118,"Hi,. Thanks for your answer. It is good to know that pyclif and protobuf is the problem. I think I did not change the version of protobuf and pyclif because I did not change the commit numbers of the repositories, i.e. `ABSL_PIN`, `PROTOBUF_VERSION` or `CLIF_PYTHON_VERSION` in `tools/build_clif.sh`. I did change the python version number though because otherwise some packages are not installable through pip, e.g. jaxlib from clu requires python >= 3.9. I am not sure whether this is normal or it is the root cause of the problem. I did pull the Docker builds before I tried to build my own image but it seems it is built only for amd64 platform. The machine I use is in arm architecture, i.e. aarch64, so the docker build did not work for me. Please feel free to let me know if I am wrong. But I don't think singularity would solve this problem because it still needs the docker to be built for the target architecture or using multi-platform builds. Do you think it is feasible to have such a build in the future? P.S. I solved the linking error for clif by building abseil-cpp again right before building clif. I am not sure whether it is because something in between overwrites the path.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:325,deployability,version,version,325,"Hi,. Thanks for your answer. It is good to know that pyclif and protobuf is the problem. I think I did not change the version of protobuf and pyclif because I did not change the commit numbers of the repositories, i.e. `ABSL_PIN`, `PROTOBUF_VERSION` or `CLIF_PYTHON_VERSION` in `tools/build_clif.sh`. I did change the python version number though because otherwise some packages are not installable through pip, e.g. jaxlib from clu requires python >= 3.9. I am not sure whether this is normal or it is the root cause of the problem. I did pull the Docker builds before I tried to build my own image but it seems it is built only for amd64 platform. The machine I use is in arm architecture, i.e. aarch64, so the docker build did not work for me. Please feel free to let me know if I am wrong. But I don't think singularity would solve this problem because it still needs the docker to be built for the target architecture or using multi-platform builds. Do you think it is feasible to have such a build in the future? P.S. I solved the linking error for clif by building abseil-cpp again right before building clif. I am not sure whether it is because something in between overwrites the path.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:387,deployability,instal,installable,387,"Hi,. Thanks for your answer. It is good to know that pyclif and protobuf is the problem. I think I did not change the version of protobuf and pyclif because I did not change the commit numbers of the repositories, i.e. `ABSL_PIN`, `PROTOBUF_VERSION` or `CLIF_PYTHON_VERSION` in `tools/build_clif.sh`. I did change the python version number though because otherwise some packages are not installable through pip, e.g. jaxlib from clu requires python >= 3.9. I am not sure whether this is normal or it is the root cause of the problem. I did pull the Docker builds before I tried to build my own image but it seems it is built only for amd64 platform. The machine I use is in arm architecture, i.e. aarch64, so the docker build did not work for me. Please feel free to let me know if I am wrong. But I don't think singularity would solve this problem because it still needs the docker to be built for the target architecture or using multi-platform builds. Do you think it is feasible to have such a build in the future? P.S. I solved the linking error for clif by building abseil-cpp again right before building clif. I am not sure whether it is because something in between overwrites the path.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:556,deployability,build,builds,556,"Hi,. Thanks for your answer. It is good to know that pyclif and protobuf is the problem. I think I did not change the version of protobuf and pyclif because I did not change the commit numbers of the repositories, i.e. `ABSL_PIN`, `PROTOBUF_VERSION` or `CLIF_PYTHON_VERSION` in `tools/build_clif.sh`. I did change the python version number though because otherwise some packages are not installable through pip, e.g. jaxlib from clu requires python >= 3.9. I am not sure whether this is normal or it is the root cause of the problem. I did pull the Docker builds before I tried to build my own image but it seems it is built only for amd64 platform. The machine I use is in arm architecture, i.e. aarch64, so the docker build did not work for me. Please feel free to let me know if I am wrong. But I don't think singularity would solve this problem because it still needs the docker to be built for the target architecture or using multi-platform builds. Do you think it is feasible to have such a build in the future? P.S. I solved the linking error for clif by building abseil-cpp again right before building clif. I am not sure whether it is because something in between overwrites the path.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:581,deployability,build,build,581,"Hi,. Thanks for your answer. It is good to know that pyclif and protobuf is the problem. I think I did not change the version of protobuf and pyclif because I did not change the commit numbers of the repositories, i.e. `ABSL_PIN`, `PROTOBUF_VERSION` or `CLIF_PYTHON_VERSION` in `tools/build_clif.sh`. I did change the python version number though because otherwise some packages are not installable through pip, e.g. jaxlib from clu requires python >= 3.9. I am not sure whether this is normal or it is the root cause of the problem. I did pull the Docker builds before I tried to build my own image but it seems it is built only for amd64 platform. The machine I use is in arm architecture, i.e. aarch64, so the docker build did not work for me. Please feel free to let me know if I am wrong. But I don't think singularity would solve this problem because it still needs the docker to be built for the target architecture or using multi-platform builds. Do you think it is feasible to have such a build in the future? P.S. I solved the linking error for clif by building abseil-cpp again right before building clif. I am not sure whether it is because something in between overwrites the path.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:720,deployability,build,build,720,"Hi,. Thanks for your answer. It is good to know that pyclif and protobuf is the problem. I think I did not change the version of protobuf and pyclif because I did not change the commit numbers of the repositories, i.e. `ABSL_PIN`, `PROTOBUF_VERSION` or `CLIF_PYTHON_VERSION` in `tools/build_clif.sh`. I did change the python version number though because otherwise some packages are not installable through pip, e.g. jaxlib from clu requires python >= 3.9. I am not sure whether this is normal or it is the root cause of the problem. I did pull the Docker builds before I tried to build my own image but it seems it is built only for amd64 platform. The machine I use is in arm architecture, i.e. aarch64, so the docker build did not work for me. Please feel free to let me know if I am wrong. But I don't think singularity would solve this problem because it still needs the docker to be built for the target architecture or using multi-platform builds. Do you think it is feasible to have such a build in the future? P.S. I solved the linking error for clif by building abseil-cpp again right before building clif. I am not sure whether it is because something in between overwrites the path.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:947,deployability,build,builds,947,"Hi,. Thanks for your answer. It is good to know that pyclif and protobuf is the problem. I think I did not change the version of protobuf and pyclif because I did not change the commit numbers of the repositories, i.e. `ABSL_PIN`, `PROTOBUF_VERSION` or `CLIF_PYTHON_VERSION` in `tools/build_clif.sh`. I did change the python version number though because otherwise some packages are not installable through pip, e.g. jaxlib from clu requires python >= 3.9. I am not sure whether this is normal or it is the root cause of the problem. I did pull the Docker builds before I tried to build my own image but it seems it is built only for amd64 platform. The machine I use is in arm architecture, i.e. aarch64, so the docker build did not work for me. Please feel free to let me know if I am wrong. But I don't think singularity would solve this problem because it still needs the docker to be built for the target architecture or using multi-platform builds. Do you think it is feasible to have such a build in the future? P.S. I solved the linking error for clif by building abseil-cpp again right before building clif. I am not sure whether it is because something in between overwrites the path.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:998,deployability,build,build,998,"Hi,. Thanks for your answer. It is good to know that pyclif and protobuf is the problem. I think I did not change the version of protobuf and pyclif because I did not change the commit numbers of the repositories, i.e. `ABSL_PIN`, `PROTOBUF_VERSION` or `CLIF_PYTHON_VERSION` in `tools/build_clif.sh`. I did change the python version number though because otherwise some packages are not installable through pip, e.g. jaxlib from clu requires python >= 3.9. I am not sure whether this is normal or it is the root cause of the problem. I did pull the Docker builds before I tried to build my own image but it seems it is built only for amd64 platform. The machine I use is in arm architecture, i.e. aarch64, so the docker build did not work for me. Please feel free to let me know if I am wrong. But I don't think singularity would solve this problem because it still needs the docker to be built for the target architecture or using multi-platform builds. Do you think it is feasible to have such a build in the future? P.S. I solved the linking error for clif by building abseil-cpp again right before building clif. I am not sure whether it is because something in between overwrites the path.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1063,deployability,build,building,1063,"Hi,. Thanks for your answer. It is good to know that pyclif and protobuf is the problem. I think I did not change the version of protobuf and pyclif because I did not change the commit numbers of the repositories, i.e. `ABSL_PIN`, `PROTOBUF_VERSION` or `CLIF_PYTHON_VERSION` in `tools/build_clif.sh`. I did change the python version number though because otherwise some packages are not installable through pip, e.g. jaxlib from clu requires python >= 3.9. I am not sure whether this is normal or it is the root cause of the problem. I did pull the Docker builds before I tried to build my own image but it seems it is built only for amd64 platform. The machine I use is in arm architecture, i.e. aarch64, so the docker build did not work for me. Please feel free to let me know if I am wrong. But I don't think singularity would solve this problem because it still needs the docker to be built for the target architecture or using multi-platform builds. Do you think it is feasible to have such a build in the future? P.S. I solved the linking error for clif by building abseil-cpp again right before building clif. I am not sure whether it is because something in between overwrites the path.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1102,deployability,build,building,1102,"Hi,. Thanks for your answer. It is good to know that pyclif and protobuf is the problem. I think I did not change the version of protobuf and pyclif because I did not change the commit numbers of the repositories, i.e. `ABSL_PIN`, `PROTOBUF_VERSION` or `CLIF_PYTHON_VERSION` in `tools/build_clif.sh`. I did change the python version number though because otherwise some packages are not installable through pip, e.g. jaxlib from clu requires python >= 3.9. I am not sure whether this is normal or it is the root cause of the problem. I did pull the Docker builds before I tried to build my own image but it seems it is built only for amd64 platform. The machine I use is in arm architecture, i.e. aarch64, so the docker build did not work for me. Please feel free to let me know if I am wrong. But I don't think singularity would solve this problem because it still needs the docker to be built for the target architecture or using multi-platform builds. Do you think it is feasible to have such a build in the future? P.S. I solved the linking error for clif by building abseil-cpp again right before building clif. I am not sure whether it is because something in between overwrites the path.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:118,integrability,version,version,118,"Hi,. Thanks for your answer. It is good to know that pyclif and protobuf is the problem. I think I did not change the version of protobuf and pyclif because I did not change the commit numbers of the repositories, i.e. `ABSL_PIN`, `PROTOBUF_VERSION` or `CLIF_PYTHON_VERSION` in `tools/build_clif.sh`. I did change the python version number though because otherwise some packages are not installable through pip, e.g. jaxlib from clu requires python >= 3.9. I am not sure whether this is normal or it is the root cause of the problem. I did pull the Docker builds before I tried to build my own image but it seems it is built only for amd64 platform. The machine I use is in arm architecture, i.e. aarch64, so the docker build did not work for me. Please feel free to let me know if I am wrong. But I don't think singularity would solve this problem because it still needs the docker to be built for the target architecture or using multi-platform builds. Do you think it is feasible to have such a build in the future? P.S. I solved the linking error for clif by building abseil-cpp again right before building clif. I am not sure whether it is because something in between overwrites the path.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:200,integrability,repositor,repositories,200,"Hi,. Thanks for your answer. It is good to know that pyclif and protobuf is the problem. I think I did not change the version of protobuf and pyclif because I did not change the commit numbers of the repositories, i.e. `ABSL_PIN`, `PROTOBUF_VERSION` or `CLIF_PYTHON_VERSION` in `tools/build_clif.sh`. I did change the python version number though because otherwise some packages are not installable through pip, e.g. jaxlib from clu requires python >= 3.9. I am not sure whether this is normal or it is the root cause of the problem. I did pull the Docker builds before I tried to build my own image but it seems it is built only for amd64 platform. The machine I use is in arm architecture, i.e. aarch64, so the docker build did not work for me. Please feel free to let me know if I am wrong. But I don't think singularity would solve this problem because it still needs the docker to be built for the target architecture or using multi-platform builds. Do you think it is feasible to have such a build in the future? P.S. I solved the linking error for clif by building abseil-cpp again right before building clif. I am not sure whether it is because something in between overwrites the path.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:325,integrability,version,version,325,"Hi,. Thanks for your answer. It is good to know that pyclif and protobuf is the problem. I think I did not change the version of protobuf and pyclif because I did not change the commit numbers of the repositories, i.e. `ABSL_PIN`, `PROTOBUF_VERSION` or `CLIF_PYTHON_VERSION` in `tools/build_clif.sh`. I did change the python version number though because otherwise some packages are not installable through pip, e.g. jaxlib from clu requires python >= 3.9. I am not sure whether this is normal or it is the root cause of the problem. I did pull the Docker builds before I tried to build my own image but it seems it is built only for amd64 platform. The machine I use is in arm architecture, i.e. aarch64, so the docker build did not work for me. Please feel free to let me know if I am wrong. But I don't think singularity would solve this problem because it still needs the docker to be built for the target architecture or using multi-platform builds. Do you think it is feasible to have such a build in the future? P.S. I solved the linking error for clif by building abseil-cpp again right before building clif. I am not sure whether it is because something in between overwrites the path.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:200,interoperability,repositor,repositories,200,"Hi,. Thanks for your answer. It is good to know that pyclif and protobuf is the problem. I think I did not change the version of protobuf and pyclif because I did not change the commit numbers of the repositories, i.e. `ABSL_PIN`, `PROTOBUF_VERSION` or `CLIF_PYTHON_VERSION` in `tools/build_clif.sh`. I did change the python version number though because otherwise some packages are not installable through pip, e.g. jaxlib from clu requires python >= 3.9. I am not sure whether this is normal or it is the root cause of the problem. I did pull the Docker builds before I tried to build my own image but it seems it is built only for amd64 platform. The machine I use is in arm architecture, i.e. aarch64, so the docker build did not work for me. Please feel free to let me know if I am wrong. But I don't think singularity would solve this problem because it still needs the docker to be built for the target architecture or using multi-platform builds. Do you think it is feasible to have such a build in the future? P.S. I solved the linking error for clif by building abseil-cpp again right before building clif. I am not sure whether it is because something in between overwrites the path.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:640,interoperability,platform,platform,640,"Hi,. Thanks for your answer. It is good to know that pyclif and protobuf is the problem. I think I did not change the version of protobuf and pyclif because I did not change the commit numbers of the repositories, i.e. `ABSL_PIN`, `PROTOBUF_VERSION` or `CLIF_PYTHON_VERSION` in `tools/build_clif.sh`. I did change the python version number though because otherwise some packages are not installable through pip, e.g. jaxlib from clu requires python >= 3.9. I am not sure whether this is normal or it is the root cause of the problem. I did pull the Docker builds before I tried to build my own image but it seems it is built only for amd64 platform. The machine I use is in arm architecture, i.e. aarch64, so the docker build did not work for me. Please feel free to let me know if I am wrong. But I don't think singularity would solve this problem because it still needs the docker to be built for the target architecture or using multi-platform builds. Do you think it is feasible to have such a build in the future? P.S. I solved the linking error for clif by building abseil-cpp again right before building clif. I am not sure whether it is because something in between overwrites the path.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:678,interoperability,architectur,architecture,678,"Hi,. Thanks for your answer. It is good to know that pyclif and protobuf is the problem. I think I did not change the version of protobuf and pyclif because I did not change the commit numbers of the repositories, i.e. `ABSL_PIN`, `PROTOBUF_VERSION` or `CLIF_PYTHON_VERSION` in `tools/build_clif.sh`. I did change the python version number though because otherwise some packages are not installable through pip, e.g. jaxlib from clu requires python >= 3.9. I am not sure whether this is normal or it is the root cause of the problem. I did pull the Docker builds before I tried to build my own image but it seems it is built only for amd64 platform. The machine I use is in arm architecture, i.e. aarch64, so the docker build did not work for me. Please feel free to let me know if I am wrong. But I don't think singularity would solve this problem because it still needs the docker to be built for the target architecture or using multi-platform builds. Do you think it is feasible to have such a build in the future? P.S. I solved the linking error for clif by building abseil-cpp again right before building clif. I am not sure whether it is because something in between overwrites the path.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:910,interoperability,architectur,architecture,910,"Hi,. Thanks for your answer. It is good to know that pyclif and protobuf is the problem. I think I did not change the version of protobuf and pyclif because I did not change the commit numbers of the repositories, i.e. `ABSL_PIN`, `PROTOBUF_VERSION` or `CLIF_PYTHON_VERSION` in `tools/build_clif.sh`. I did change the python version number though because otherwise some packages are not installable through pip, e.g. jaxlib from clu requires python >= 3.9. I am not sure whether this is normal or it is the root cause of the problem. I did pull the Docker builds before I tried to build my own image but it seems it is built only for amd64 platform. The machine I use is in arm architecture, i.e. aarch64, so the docker build did not work for me. Please feel free to let me know if I am wrong. But I don't think singularity would solve this problem because it still needs the docker to be built for the target architecture or using multi-platform builds. Do you think it is feasible to have such a build in the future? P.S. I solved the linking error for clif by building abseil-cpp again right before building clif. I am not sure whether it is because something in between overwrites the path.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:938,interoperability,platform,platform,938,"Hi,. Thanks for your answer. It is good to know that pyclif and protobuf is the problem. I think I did not change the version of protobuf and pyclif because I did not change the commit numbers of the repositories, i.e. `ABSL_PIN`, `PROTOBUF_VERSION` or `CLIF_PYTHON_VERSION` in `tools/build_clif.sh`. I did change the python version number though because otherwise some packages are not installable through pip, e.g. jaxlib from clu requires python >= 3.9. I am not sure whether this is normal or it is the root cause of the problem. I did pull the Docker builds before I tried to build my own image but it seems it is built only for amd64 platform. The machine I use is in arm architecture, i.e. aarch64, so the docker build did not work for me. Please feel free to let me know if I am wrong. But I don't think singularity would solve this problem because it still needs the docker to be built for the target architecture or using multi-platform builds. Do you think it is feasible to have such a build in the future? P.S. I solved the linking error for clif by building abseil-cpp again right before building clif. I am not sure whether it is because something in between overwrites the path.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:118,modifiability,version,version,118,"Hi,. Thanks for your answer. It is good to know that pyclif and protobuf is the problem. I think I did not change the version of protobuf and pyclif because I did not change the commit numbers of the repositories, i.e. `ABSL_PIN`, `PROTOBUF_VERSION` or `CLIF_PYTHON_VERSION` in `tools/build_clif.sh`. I did change the python version number though because otherwise some packages are not installable through pip, e.g. jaxlib from clu requires python >= 3.9. I am not sure whether this is normal or it is the root cause of the problem. I did pull the Docker builds before I tried to build my own image but it seems it is built only for amd64 platform. The machine I use is in arm architecture, i.e. aarch64, so the docker build did not work for me. Please feel free to let me know if I am wrong. But I don't think singularity would solve this problem because it still needs the docker to be built for the target architecture or using multi-platform builds. Do you think it is feasible to have such a build in the future? P.S. I solved the linking error for clif by building abseil-cpp again right before building clif. I am not sure whether it is because something in between overwrites the path.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:325,modifiability,version,version,325,"Hi,. Thanks for your answer. It is good to know that pyclif and protobuf is the problem. I think I did not change the version of protobuf and pyclif because I did not change the commit numbers of the repositories, i.e. `ABSL_PIN`, `PROTOBUF_VERSION` or `CLIF_PYTHON_VERSION` in `tools/build_clif.sh`. I did change the python version number though because otherwise some packages are not installable through pip, e.g. jaxlib from clu requires python >= 3.9. I am not sure whether this is normal or it is the root cause of the problem. I did pull the Docker builds before I tried to build my own image but it seems it is built only for amd64 platform. The machine I use is in arm architecture, i.e. aarch64, so the docker build did not work for me. Please feel free to let me know if I am wrong. But I don't think singularity would solve this problem because it still needs the docker to be built for the target architecture or using multi-platform builds. Do you think it is feasible to have such a build in the future? P.S. I solved the linking error for clif by building abseil-cpp again right before building clif. I am not sure whether it is because something in between overwrites the path.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:370,modifiability,pac,packages,370,"Hi,. Thanks for your answer. It is good to know that pyclif and protobuf is the problem. I think I did not change the version of protobuf and pyclif because I did not change the commit numbers of the repositories, i.e. `ABSL_PIN`, `PROTOBUF_VERSION` or `CLIF_PYTHON_VERSION` in `tools/build_clif.sh`. I did change the python version number though because otherwise some packages are not installable through pip, e.g. jaxlib from clu requires python >= 3.9. I am not sure whether this is normal or it is the root cause of the problem. I did pull the Docker builds before I tried to build my own image but it seems it is built only for amd64 platform. The machine I use is in arm architecture, i.e. aarch64, so the docker build did not work for me. Please feel free to let me know if I am wrong. But I don't think singularity would solve this problem because it still needs the docker to be built for the target architecture or using multi-platform builds. Do you think it is feasible to have such a build in the future? P.S. I solved the linking error for clif by building abseil-cpp again right before building clif. I am not sure whether it is because something in between overwrites the path.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1045,performance,error,error,1045,"Hi,. Thanks for your answer. It is good to know that pyclif and protobuf is the problem. I think I did not change the version of protobuf and pyclif because I did not change the commit numbers of the repositories, i.e. `ABSL_PIN`, `PROTOBUF_VERSION` or `CLIF_PYTHON_VERSION` in `tools/build_clif.sh`. I did change the python version number though because otherwise some packages are not installable through pip, e.g. jaxlib from clu requires python >= 3.9. I am not sure whether this is normal or it is the root cause of the problem. I did pull the Docker builds before I tried to build my own image but it seems it is built only for amd64 platform. The machine I use is in arm architecture, i.e. aarch64, so the docker build did not work for me. Please feel free to let me know if I am wrong. But I don't think singularity would solve this problem because it still needs the docker to be built for the target architecture or using multi-platform builds. Do you think it is feasible to have such a build in the future? P.S. I solved the linking error for clif by building abseil-cpp again right before building clif. I am not sure whether it is because something in between overwrites the path.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1045,safety,error,error,1045,"Hi,. Thanks for your answer. It is good to know that pyclif and protobuf is the problem. I think I did not change the version of protobuf and pyclif because I did not change the commit numbers of the repositories, i.e. `ABSL_PIN`, `PROTOBUF_VERSION` or `CLIF_PYTHON_VERSION` in `tools/build_clif.sh`. I did change the python version number though because otherwise some packages are not installable through pip, e.g. jaxlib from clu requires python >= 3.9. I am not sure whether this is normal or it is the root cause of the problem. I did pull the Docker builds before I tried to build my own image but it seems it is built only for amd64 platform. The machine I use is in arm architecture, i.e. aarch64, so the docker build did not work for me. Please feel free to let me know if I am wrong. But I don't think singularity would solve this problem because it still needs the docker to be built for the target architecture or using multi-platform builds. Do you think it is feasible to have such a build in the future? P.S. I solved the linking error for clif by building abseil-cpp again right before building clif. I am not sure whether it is because something in between overwrites the path.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:279,usability,tool,tools,279,"Hi,. Thanks for your answer. It is good to know that pyclif and protobuf is the problem. I think I did not change the version of protobuf and pyclif because I did not change the commit numbers of the repositories, i.e. `ABSL_PIN`, `PROTOBUF_VERSION` or `CLIF_PYTHON_VERSION` in `tools/build_clif.sh`. I did change the python version number though because otherwise some packages are not installable through pip, e.g. jaxlib from clu requires python >= 3.9. I am not sure whether this is normal or it is the root cause of the problem. I did pull the Docker builds before I tried to build my own image but it seems it is built only for amd64 platform. The machine I use is in arm architecture, i.e. aarch64, so the docker build did not work for me. Please feel free to let me know if I am wrong. But I don't think singularity would solve this problem because it still needs the docker to be built for the target architecture or using multi-platform builds. Do you think it is feasible to have such a build in the future? P.S. I solved the linking error for clif by building abseil-cpp again right before building clif. I am not sure whether it is because something in between overwrites the path.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:1045,usability,error,error,1045,"Hi,. Thanks for your answer. It is good to know that pyclif and protobuf is the problem. I think I did not change the version of protobuf and pyclif because I did not change the commit numbers of the repositories, i.e. `ABSL_PIN`, `PROTOBUF_VERSION` or `CLIF_PYTHON_VERSION` in `tools/build_clif.sh`. I did change the python version number though because otherwise some packages are not installable through pip, e.g. jaxlib from clu requires python >= 3.9. I am not sure whether this is normal or it is the root cause of the problem. I did pull the Docker builds before I tried to build my own image but it seems it is built only for amd64 platform. The machine I use is in arm architecture, i.e. aarch64, so the docker build did not work for me. Please feel free to let me know if I am wrong. But I don't think singularity would solve this problem because it still needs the docker to be built for the target architecture or using multi-platform builds. Do you think it is feasible to have such a build in the future? P.S. I solved the linking error for clif by building abseil-cpp again right before building clif. I am not sure whether it is because something in between overwrites the path.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:84,deployability,build,build,84,"@jellycatfish195 ,. Unfortunately aarch64 is not currently supported by DeepVariant build and it seems like you have to modify the build a lot and ultimately it breaks the build. Given the issue of supporting aarch64 has not been requested many times so we haven't looked into it. Is to possible for you to get a machine with x64 and use DeepVariant via that?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:131,deployability,build,build,131,"@jellycatfish195 ,. Unfortunately aarch64 is not currently supported by DeepVariant build and it seems like you have to modify the build a lot and ultimately it breaks the build. Given the issue of supporting aarch64 has not been requested many times so we haven't looked into it. Is to possible for you to get a machine with x64 and use DeepVariant via that?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:172,deployability,build,build,172,"@jellycatfish195 ,. Unfortunately aarch64 is not currently supported by DeepVariant build and it seems like you have to modify the build a lot and ultimately it breaks the build. Given the issue of supporting aarch64 has not been requested many times so we haven't looked into it. Is to possible for you to get a machine with x64 and use DeepVariant via that?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:49,energy efficiency,current,currently,49,"@jellycatfish195 ,. Unfortunately aarch64 is not currently supported by DeepVariant build and it seems like you have to modify the build a lot and ultimately it breaks the build. Given the issue of supporting aarch64 has not been requested many times so we haven't looked into it. Is to possible for you to get a machine with x64 and use DeepVariant via that?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:245,performance,time,times,245,"@jellycatfish195 ,. Unfortunately aarch64 is not currently supported by DeepVariant build and it seems like you have to modify the build a lot and ultimately it breaks the build. Given the issue of supporting aarch64 has not been requested many times so we haven't looked into it. Is to possible for you to get a machine with x64 and use DeepVariant via that?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:120,security,modif,modify,120,"@jellycatfish195 ,. Unfortunately aarch64 is not currently supported by DeepVariant build and it seems like you have to modify the build a lot and ultimately it breaks the build. Given the issue of supporting aarch64 has not been requested many times so we haven't looked into it. Is to possible for you to get a machine with x64 and use DeepVariant via that?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:59,usability,support,supported,59,"@jellycatfish195 ,. Unfortunately aarch64 is not currently supported by DeepVariant build and it seems like you have to modify the build a lot and ultimately it breaks the build. Given the issue of supporting aarch64 has not been requested many times so we haven't looked into it. Is to possible for you to get a machine with x64 and use DeepVariant via that?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:198,usability,support,supporting,198,"@jellycatfish195 ,. Unfortunately aarch64 is not currently supported by DeepVariant build and it seems like you have to modify the build a lot and ultimately it breaks the build. Given the issue of supporting aarch64 has not been requested many times so we haven't looked into it. Is to possible for you to get a machine with x64 and use DeepVariant via that?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:157,deployability,build,build,157,"Hi @kishwarshafin ,. I am doing profiling on my machine so I guess switching to an x64 machine is not an option for me. . It would be great to have a stable build for aarch64 in the future though if it is not too much trouble.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:32,energy efficiency,profil,profiling,32,"Hi @kishwarshafin ,. I am doing profiling on my machine so I guess switching to an x64 machine is not an option for me. . It would be great to have a stable build for aarch64 in the future though if it is not too much trouble.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:32,performance,profil,profiling,32,"Hi @kishwarshafin ,. I am doing profiling on my machine so I guess switching to an x64 machine is not an option for me. . It would be great to have a stable build for aarch64 in the future though if it is not too much trouble.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:228,deployability,releas,release,228,"In your first comment you said: ""I am running this on an AWS graviton4 machine (aarch64 architecture)."" so I thought switching instance type was an option for you. I am sorry for your trouble. We can give it a shot but the next release is pretty close and we may not have enough bandwidth to support aarch64. However, I will file a bug internally and see if we can support aarch64 in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:88,interoperability,architectur,architecture,88,"In your first comment you said: ""I am running this on an AWS graviton4 machine (aarch64 architecture)."" so I thought switching instance type was an option for you. I am sorry for your trouble. We can give it a shot but the next release is pretty close and we may not have enough bandwidth to support aarch64. However, I will file a bug internally and see if we can support aarch64 in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:246,usability,close,close,246,"In your first comment you said: ""I am running this on an AWS graviton4 machine (aarch64 architecture)."" so I thought switching instance type was an option for you. I am sorry for your trouble. We can give it a shot but the next release is pretty close and we may not have enough bandwidth to support aarch64. However, I will file a bug internally and see if we can support aarch64 in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:292,usability,support,support,292,"In your first comment you said: ""I am running this on an AWS graviton4 machine (aarch64 architecture)."" so I thought switching instance type was an option for you. I am sorry for your trouble. We can give it a shot but the next release is pretty close and we may not have enough bandwidth to support aarch64. However, I will file a bug internally and see if we can support aarch64 in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/879:365,usability,support,support,365,"In your first comment you said: ""I am running this on an AWS graviton4 machine (aarch64 architecture)."" so I thought switching instance type was an option for you. I am sorry for your trouble. We can give it a shot but the next release is pretty close and we may not have enough bandwidth to support aarch64. However, I will file a bug internally and see if we can support aarch64 in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/879
https://github.com/google/deepvariant/issues/880:925,deployability,contain,containing,925,"Hi @minw2828 , VAF as it stands is variant allele frequency. . This is how it's calculated for the two variants:. ```bash. chr13	32323151	.	A	AT	45.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:21:24:6,6:0.25:45,24,44. GT:GQ:DP:AD:VAF:PL 0/1:21:24:6,6:0.25:45,24,44. # which means. GT=0/1 (genotype). DP=24 (depth). AD=[6,6] (Allelic depths of two allele 0 and 1). ```. So the VAF becomes:. VAF=AD[1]/DP = 6/6 = 0.25 . AD[1] is because we are taking the alternate allele. For the second one:. ```bash. chr13	32349216	.	CA	C	8.3	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:8:23:6,12:0.521739:7,0,22. GT:GQ:DP:AD:VAF:PL 0/1:8:23:6,12:0.521739:7,0,22. # which means. GT=0/1 (genotype). DP=23 (depth). AD=[6,12] (Allelic depths of two allele 0 and 1). ```. So the VAF becomes:. VAF=AD[1]/DP = 12/23 = 0.521739130434783. Which is the reported to the sixth precision point. AD[1] + AD[0] does not always equal to depth (DP) because there could be a few reads containing alleles that we don't pick up as they don't cross the threshold of candidate finer. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/880
https://github.com/google/deepvariant/issues/880:50,energy efficiency,frequenc,frequency,50,"Hi @minw2828 , VAF as it stands is variant allele frequency. . This is how it's calculated for the two variants:. ```bash. chr13	32323151	.	A	AT	45.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:21:24:6,6:0.25:45,24,44. GT:GQ:DP:AD:VAF:PL 0/1:21:24:6,6:0.25:45,24,44. # which means. GT=0/1 (genotype). DP=24 (depth). AD=[6,6] (Allelic depths of two allele 0 and 1). ```. So the VAF becomes:. VAF=AD[1]/DP = 6/6 = 0.25 . AD[1] is because we are taking the alternate allele. For the second one:. ```bash. chr13	32349216	.	CA	C	8.3	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:8:23:6,12:0.521739:7,0,22. GT:GQ:DP:AD:VAF:PL 0/1:8:23:6,12:0.521739:7,0,22. # which means. GT=0/1 (genotype). DP=23 (depth). AD=[6,12] (Allelic depths of two allele 0 and 1). ```. So the VAF becomes:. VAF=AD[1]/DP = 12/23 = 0.521739130434783. Which is the reported to the sixth precision point. AD[1] + AD[0] does not always equal to depth (DP) because there could be a few reads containing alleles that we don't pick up as they don't cross the threshold of candidate finer. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/880
https://github.com/google/deepvariant/issues/880:854,reliability,doe,does,854,"Hi @minw2828 , VAF as it stands is variant allele frequency. . This is how it's calculated for the two variants:. ```bash. chr13	32323151	.	A	AT	45.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:21:24:6,6:0.25:45,24,44. GT:GQ:DP:AD:VAF:PL 0/1:21:24:6,6:0.25:45,24,44. # which means. GT=0/1 (genotype). DP=24 (depth). AD=[6,6] (Allelic depths of two allele 0 and 1). ```. So the VAF becomes:. VAF=AD[1]/DP = 6/6 = 0.25 . AD[1] is because we are taking the alternate allele. For the second one:. ```bash. chr13	32349216	.	CA	C	8.3	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:8:23:6,12:0.521739:7,0,22. GT:GQ:DP:AD:VAF:PL 0/1:8:23:6,12:0.521739:7,0,22. # which means. GT=0/1 (genotype). DP=23 (depth). AD=[6,12] (Allelic depths of two allele 0 and 1). ```. So the VAF becomes:. VAF=AD[1]/DP = 12/23 = 0.521739130434783. Which is the reported to the sixth precision point. AD[1] + AD[0] does not always equal to depth (DP) because there could be a few reads containing alleles that we don't pick up as they don't cross the threshold of candidate finer. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/880
https://github.com/google/deepvariant/issues/880:1030,usability,help,helps,1030,"Hi @minw2828 , VAF as it stands is variant allele frequency. . This is how it's calculated for the two variants:. ```bash. chr13	32323151	.	A	AT	45.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:21:24:6,6:0.25:45,24,44. GT:GQ:DP:AD:VAF:PL 0/1:21:24:6,6:0.25:45,24,44. # which means. GT=0/1 (genotype). DP=24 (depth). AD=[6,6] (Allelic depths of two allele 0 and 1). ```. So the VAF becomes:. VAF=AD[1]/DP = 6/6 = 0.25 . AD[1] is because we are taking the alternate allele. For the second one:. ```bash. chr13	32349216	.	CA	C	8.3	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:8:23:6,12:0.521739:7,0,22. GT:GQ:DP:AD:VAF:PL 0/1:8:23:6,12:0.521739:7,0,22. # which means. GT=0/1 (genotype). DP=23 (depth). AD=[6,12] (Allelic depths of two allele 0 and 1). ```. So the VAF becomes:. VAF=AD[1]/DP = 12/23 = 0.521739130434783. Which is the reported to the sixth precision point. AD[1] + AD[0] does not always equal to depth (DP) because there could be a few reads containing alleles that we don't pick up as they don't cross the threshold of candidate finer. Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/880
https://github.com/google/deepvariant/issues/881:146,energy efficiency,model,model,146,"I do not know which line you mean exactly, but i am going to give you an example variant from three different variant callers:. **Deepvariant RNA model:**. chr11	115166697	.	G	T	10	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:3:5:0,5:1:6,0,0. **HaplotypeCaller:**. chr11	115166697	.	G	T	156.96	.	AC=2;AF=1.00;AN=2;DP=7;ExcessHet=0.0000;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=31.39;SOR=3.611	GT:AD:DP:GQ:PL	1/1:0,5:5:15:171,15,0. **Freebayes:**. chr11	115166697	.	G	T	90.0627	.	AB=0;ABP=0;AC=2;AF=1;AN=2;AO=5;CIGAR=1X;DP=5;DPB=5;DPRA=0;EPP=13.8677;EPPR=0;GTI=0;LEN=1;MEANALT=1;MQM=60;MQMR=0;NS=1;NUMALT=1;ODDS=10.1503;PAIRED=0;PAIREDR=0;PAO=0;PQA=0;PQR=0;PRO=0;QA=147;QR=0;RO=0;RPL=5;RPP=13.8677;RPPR=0;RPR=0;RUN=1;SAF=5;SAP=13.8677;SAR=0;SRF=0;SRP=0;SRR=0;TYPE=snp;technology.Illumina=1	GT:DP:AD:RO:QR:AO:QA:GL	1/1:5:0,5:0:0:5:147:-13.5217,-1.50515,0. The three variant callers are run on the same BAM, and i also forgot to mention that i am variant calling RNA data not DNA so i followed the Deepvariant RNA Casestudy.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:146,security,model,model,146,"I do not know which line you mean exactly, but i am going to give you an example variant from three different variant callers:. **Deepvariant RNA model:**. chr11	115166697	.	G	T	10	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:3:5:0,5:1:6,0,0. **HaplotypeCaller:**. chr11	115166697	.	G	T	156.96	.	AC=2;AF=1.00;AN=2;DP=7;ExcessHet=0.0000;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=31.39;SOR=3.611	GT:AD:DP:GQ:PL	1/1:0,5:5:15:171,15,0. **Freebayes:**. chr11	115166697	.	G	T	90.0627	.	AB=0;ABP=0;AC=2;AF=1;AN=2;AO=5;CIGAR=1X;DP=5;DPB=5;DPRA=0;EPP=13.8677;EPPR=0;GTI=0;LEN=1;MEANALT=1;MQM=60;MQMR=0;NS=1;NUMALT=1;ODDS=10.1503;PAIRED=0;PAIREDR=0;PAO=0;PQA=0;PQR=0;PRO=0;QA=147;QR=0;RO=0;RPL=5;RPP=13.8677;RPPR=0;RPR=0;RUN=1;SAF=5;SAP=13.8677;SAR=0;SRF=0;SRP=0;SRR=0;TYPE=snp;technology.Illumina=1	GT:DP:AD:RO:QR:AO:QA:GL	1/1:5:0,5:0:0:5:147:-13.5217,-1.50515,0. The three variant callers are run on the same BAM, and i also forgot to mention that i am variant calling RNA data not DNA so i followed the Deepvariant RNA Casestudy.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:315,availability,error,error,315,"Hi @esraaelmligy . One thing we find is that DeepVariant is much more conservative in assigning quality values compared to other callers. These values come from the probability of the call from the neural network. Generally, we observe that DeepVariant's probabilities are reasonably well-calibrated with empirical error rates. For an example of this, please see Figure 2 from the DeepVariant paper (https://www.nature.com/articles/nbt.4235 or the open preprint of the same work https://www.biorxiv.org/content/10.1101/092890v6.full.pdf). As a consequence, you should probably not filter in the same way as with other callers. You should likely have a lower threshold for DeepVariant calls. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:228,deployability,observ,observe,228,"Hi @esraaelmligy . One thing we find is that DeepVariant is much more conservative in assigning quality values compared to other callers. These values come from the probability of the call from the neural network. Generally, we observe that DeepVariant's probabilities are reasonably well-calibrated with empirical error rates. For an example of this, please see Figure 2 from the DeepVariant paper (https://www.nature.com/articles/nbt.4235 or the open preprint of the same work https://www.biorxiv.org/content/10.1101/092890v6.full.pdf). As a consequence, you should probably not filter in the same way as with other callers. You should likely have a lower threshold for DeepVariant calls. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:581,integrability,filter,filter,581,"Hi @esraaelmligy . One thing we find is that DeepVariant is much more conservative in assigning quality values compared to other callers. These values come from the probability of the call from the neural network. Generally, we observe that DeepVariant's probabilities are reasonably well-calibrated with empirical error rates. For an example of this, please see Figure 2 from the DeepVariant paper (https://www.nature.com/articles/nbt.4235 or the open preprint of the same work https://www.biorxiv.org/content/10.1101/092890v6.full.pdf). As a consequence, you should probably not filter in the same way as with other callers. You should likely have a lower threshold for DeepVariant calls. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:205,performance,network,network,205,"Hi @esraaelmligy . One thing we find is that DeepVariant is much more conservative in assigning quality values compared to other callers. These values come from the probability of the call from the neural network. Generally, we observe that DeepVariant's probabilities are reasonably well-calibrated with empirical error rates. For an example of this, please see Figure 2 from the DeepVariant paper (https://www.nature.com/articles/nbt.4235 or the open preprint of the same work https://www.biorxiv.org/content/10.1101/092890v6.full.pdf). As a consequence, you should probably not filter in the same way as with other callers. You should likely have a lower threshold for DeepVariant calls. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:315,performance,error,error,315,"Hi @esraaelmligy . One thing we find is that DeepVariant is much more conservative in assigning quality values compared to other callers. These values come from the probability of the call from the neural network. Generally, we observe that DeepVariant's probabilities are reasonably well-calibrated with empirical error rates. For an example of this, please see Figure 2 from the DeepVariant paper (https://www.nature.com/articles/nbt.4235 or the open preprint of the same work https://www.biorxiv.org/content/10.1101/092890v6.full.pdf). As a consequence, you should probably not filter in the same way as with other callers. You should likely have a lower threshold for DeepVariant calls. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:503,performance,content,content,503,"Hi @esraaelmligy . One thing we find is that DeepVariant is much more conservative in assigning quality values compared to other callers. These values come from the probability of the call from the neural network. Generally, we observe that DeepVariant's probabilities are reasonably well-calibrated with empirical error rates. For an example of this, please see Figure 2 from the DeepVariant paper (https://www.nature.com/articles/nbt.4235 or the open preprint of the same work https://www.biorxiv.org/content/10.1101/092890v6.full.pdf). As a consequence, you should probably not filter in the same way as with other callers. You should likely have a lower threshold for DeepVariant calls. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:315,safety,error,error,315,"Hi @esraaelmligy . One thing we find is that DeepVariant is much more conservative in assigning quality values compared to other callers. These values come from the probability of the call from the neural network. Generally, we observe that DeepVariant's probabilities are reasonably well-calibrated with empirical error rates. For an example of this, please see Figure 2 from the DeepVariant paper (https://www.nature.com/articles/nbt.4235 or the open preprint of the same work https://www.biorxiv.org/content/10.1101/092890v6.full.pdf). As a consequence, you should probably not filter in the same way as with other callers. You should likely have a lower threshold for DeepVariant calls. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:205,security,network,network,205,"Hi @esraaelmligy . One thing we find is that DeepVariant is much more conservative in assigning quality values compared to other callers. These values come from the probability of the call from the neural network. Generally, we observe that DeepVariant's probabilities are reasonably well-calibrated with empirical error rates. For an example of this, please see Figure 2 from the DeepVariant paper (https://www.nature.com/articles/nbt.4235 or the open preprint of the same work https://www.biorxiv.org/content/10.1101/092890v6.full.pdf). As a consequence, you should probably not filter in the same way as with other callers. You should likely have a lower threshold for DeepVariant calls. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:228,testability,observ,observe,228,"Hi @esraaelmligy . One thing we find is that DeepVariant is much more conservative in assigning quality values compared to other callers. These values come from the probability of the call from the neural network. Generally, we observe that DeepVariant's probabilities are reasonably well-calibrated with empirical error rates. For an example of this, please see Figure 2 from the DeepVariant paper (https://www.nature.com/articles/nbt.4235 or the open preprint of the same work https://www.biorxiv.org/content/10.1101/092890v6.full.pdf). As a consequence, you should probably not filter in the same way as with other callers. You should likely have a lower threshold for DeepVariant calls. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:315,usability,error,error,315,"Hi @esraaelmligy . One thing we find is that DeepVariant is much more conservative in assigning quality values compared to other callers. These values come from the probability of the call from the neural network. Generally, we observe that DeepVariant's probabilities are reasonably well-calibrated with empirical error rates. For an example of this, please see Figure 2 from the DeepVariant paper (https://www.nature.com/articles/nbt.4235 or the open preprint of the same work https://www.biorxiv.org/content/10.1101/092890v6.full.pdf). As a consequence, you should probably not filter in the same way as with other callers. You should likely have a lower threshold for DeepVariant calls. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:260,energy efficiency,model,model,260,"Thank you so much for the detailed explanation! I have checked the paper and understand your point now. Last thing i want to ask if there is a general recommended filtration criteria for variants generated by Deepvariant, specially those produced from the RNA model?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:260,security,model,model,260,"Thank you so much for the detailed explanation! I have checked the paper and understand your point now. Last thing i want to ask if there is a general recommended filtration criteria for variants generated by Deepvariant, specially those produced from the RNA model?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:77,testability,understand,understand,77,"Thank you so much for the detailed explanation! I have checked the paper and understand your point now. Last thing i want to ask if there is a general recommended filtration criteria for variants generated by Deepvariant, specially those produced from the RNA model?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:75,availability,toler,tolerance,75,"Hi @esraaelmligy . The quality threshold for filtering will depend on your tolerance for false positives versus false negatives. We find the quality is well-calibrated with error, so Qual of 20 is ~1% false discovery probability, Qual of 10 is ~10% false discovery probability and so on. . So if you value precision, something between Qual 10 and Qual 20 as a threshold is probably a good place to start.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:173,availability,error,error,173,"Hi @esraaelmligy . The quality threshold for filtering will depend on your tolerance for false positives versus false negatives. We find the quality is well-calibrated with error, so Qual of 20 is ~1% false discovery probability, Qual of 10 is ~10% false discovery probability and so on. . So if you value precision, something between Qual 10 and Qual 20 as a threshold is probably a good place to start.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:60,deployability,depend,depend,60,"Hi @esraaelmligy . The quality threshold for filtering will depend on your tolerance for false positives versus false negatives. We find the quality is well-calibrated with error, so Qual of 20 is ~1% false discovery probability, Qual of 10 is ~10% false discovery probability and so on. . So if you value precision, something between Qual 10 and Qual 20 as a threshold is probably a good place to start.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:45,integrability,filter,filtering,45,"Hi @esraaelmligy . The quality threshold for filtering will depend on your tolerance for false positives versus false negatives. We find the quality is well-calibrated with error, so Qual of 20 is ~1% false discovery probability, Qual of 10 is ~10% false discovery probability and so on. . So if you value precision, something between Qual 10 and Qual 20 as a threshold is probably a good place to start.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:60,integrability,depend,depend,60,"Hi @esraaelmligy . The quality threshold for filtering will depend on your tolerance for false positives versus false negatives. We find the quality is well-calibrated with error, so Qual of 20 is ~1% false discovery probability, Qual of 10 is ~10% false discovery probability and so on. . So if you value precision, something between Qual 10 and Qual 20 as a threshold is probably a good place to start.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:207,integrability,discover,discovery,207,"Hi @esraaelmligy . The quality threshold for filtering will depend on your tolerance for false positives versus false negatives. We find the quality is well-calibrated with error, so Qual of 20 is ~1% false discovery probability, Qual of 10 is ~10% false discovery probability and so on. . So if you value precision, something between Qual 10 and Qual 20 as a threshold is probably a good place to start.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:255,integrability,discover,discovery,255,"Hi @esraaelmligy . The quality threshold for filtering will depend on your tolerance for false positives versus false negatives. We find the quality is well-calibrated with error, so Qual of 20 is ~1% false discovery probability, Qual of 10 is ~10% false discovery probability and so on. . So if you value precision, something between Qual 10 and Qual 20 as a threshold is probably a good place to start.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:207,interoperability,discover,discovery,207,"Hi @esraaelmligy . The quality threshold for filtering will depend on your tolerance for false positives versus false negatives. We find the quality is well-calibrated with error, so Qual of 20 is ~1% false discovery probability, Qual of 10 is ~10% false discovery probability and so on. . So if you value precision, something between Qual 10 and Qual 20 as a threshold is probably a good place to start.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:255,interoperability,discover,discovery,255,"Hi @esraaelmligy . The quality threshold for filtering will depend on your tolerance for false positives versus false negatives. We find the quality is well-calibrated with error, so Qual of 20 is ~1% false discovery probability, Qual of 10 is ~10% false discovery probability and so on. . So if you value precision, something between Qual 10 and Qual 20 as a threshold is probably a good place to start.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:60,modifiability,depend,depend,60,"Hi @esraaelmligy . The quality threshold for filtering will depend on your tolerance for false positives versus false negatives. We find the quality is well-calibrated with error, so Qual of 20 is ~1% false discovery probability, Qual of 10 is ~10% false discovery probability and so on. . So if you value precision, something between Qual 10 and Qual 20 as a threshold is probably a good place to start.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:173,performance,error,error,173,"Hi @esraaelmligy . The quality threshold for filtering will depend on your tolerance for false positives versus false negatives. We find the quality is well-calibrated with error, so Qual of 20 is ~1% false discovery probability, Qual of 10 is ~10% false discovery probability and so on. . So if you value precision, something between Qual 10 and Qual 20 as a threshold is probably a good place to start.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:75,reliability,toleran,tolerance,75,"Hi @esraaelmligy . The quality threshold for filtering will depend on your tolerance for false positives versus false negatives. We find the quality is well-calibrated with error, so Qual of 20 is ~1% false discovery probability, Qual of 10 is ~10% false discovery probability and so on. . So if you value precision, something between Qual 10 and Qual 20 as a threshold is probably a good place to start.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:60,safety,depend,depend,60,"Hi @esraaelmligy . The quality threshold for filtering will depend on your tolerance for false positives versus false negatives. We find the quality is well-calibrated with error, so Qual of 20 is ~1% false discovery probability, Qual of 10 is ~10% false discovery probability and so on. . So if you value precision, something between Qual 10 and Qual 20 as a threshold is probably a good place to start.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:173,safety,error,error,173,"Hi @esraaelmligy . The quality threshold for filtering will depend on your tolerance for false positives versus false negatives. We find the quality is well-calibrated with error, so Qual of 20 is ~1% false discovery probability, Qual of 10 is ~10% false discovery probability and so on. . So if you value precision, something between Qual 10 and Qual 20 as a threshold is probably a good place to start.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:60,testability,depend,depend,60,"Hi @esraaelmligy . The quality threshold for filtering will depend on your tolerance for false positives versus false negatives. We find the quality is well-calibrated with error, so Qual of 20 is ~1% false discovery probability, Qual of 10 is ~10% false discovery probability and so on. . So if you value precision, something between Qual 10 and Qual 20 as a threshold is probably a good place to start.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:173,usability,error,error,173,"Hi @esraaelmligy . The quality threshold for filtering will depend on your tolerance for false positives versus false negatives. We find the quality is well-calibrated with error, so Qual of 20 is ~1% false discovery probability, Qual of 10 is ~10% false discovery probability and so on. . So if you value precision, something between Qual 10 and Qual 20 as a threshold is probably a good place to start.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:207,usability,discov,discovery,207,"Hi @esraaelmligy . The quality threshold for filtering will depend on your tolerance for false positives versus false negatives. We find the quality is well-calibrated with error, so Qual of 20 is ~1% false discovery probability, Qual of 10 is ~10% false discovery probability and so on. . So if you value precision, something between Qual 10 and Qual 20 as a threshold is probably a good place to start.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/881:255,usability,discov,discovery,255,"Hi @esraaelmligy . The quality threshold for filtering will depend on your tolerance for false positives versus false negatives. We find the quality is well-calibrated with error, so Qual of 20 is ~1% false discovery probability, Qual of 10 is ~10% false discovery probability and so on. . So if you value precision, something between Qual 10 and Qual 20 as a threshold is probably a good place to start.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/881
https://github.com/google/deepvariant/issues/883:27,performance,content,content,27,Could you please paste the content of your `deepvariant_log.txt`?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:147,availability,error,error,147,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:88,deployability,log,log,88,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:202,deployability,log,log,202,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:317,deployability,integr,integration,317,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:369,deployability,integr,integration,369,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:433,deployability,integr,integration,433,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:486,deployability,integr,integration,486,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1732,deployability,integr,integration,1732,"t and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached. [nextflow.log](https://github.com/user-attachments/files/17008943/nextflow.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1798,deployability,version,version,1798,"t and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached. [nextflow.log](https://github.com/user-attachments/files/17008943/nextflow.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1983,deployability,log,log,1983,"t and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached. [nextflow.log](https://github.com/user-attachments/files/17008943/nextflow.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:2012,deployability,log,log,2012,"t and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached. [nextflow.log](https://github.com/user-attachments/files/17008943/nextflow.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:2077,deployability,log,log,2077,"t and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached. [nextflow.log](https://github.com/user-attachments/files/17008943/nextflow.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:924,energy efficiency,cpu,cpus,924,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1649,energy efficiency,cpu,cpus,1649,"t and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached. [nextflow.log](https://github.com/user-attachments/files/17008943/nextflow.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:317,integrability,integr,integration,317,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:369,integrability,integr,integration,369,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:433,integrability,integr,integration,433,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:486,integrability,integr,integration,486,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:865,integrability,pub,publishDir,865,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1732,integrability,integr,integration,1732,"t and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached. [nextflow.log](https://github.com/user-attachments/files/17008943/nextflow.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1798,integrability,version,version,1798,"t and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached. [nextflow.log](https://github.com/user-attachments/files/17008943/nextflow.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:317,interoperability,integr,integration,317,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:369,interoperability,integr,integration,369,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:433,interoperability,integr,integration,433,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:486,interoperability,integr,integration,486,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1732,interoperability,integr,integration,1732,"t and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached. [nextflow.log](https://github.com/user-attachments/files/17008943/nextflow.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:317,modifiability,integr,integration,317,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:369,modifiability,integr,integration,369,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:433,modifiability,integr,integration,433,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:486,modifiability,integr,integration,486,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1732,modifiability,integr,integration,1732,"t and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached. [nextflow.log](https://github.com/user-attachments/files/17008943/nextflow.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1798,modifiability,version,version,1798,"t and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached. [nextflow.log](https://github.com/user-attachments/files/17008943/nextflow.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:147,performance,error,error,147,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:924,performance,cpu,cpus,924,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1649,performance,cpu,cpus,1649,"t and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached. [nextflow.log](https://github.com/user-attachments/files/17008943/nextflow.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:317,reliability,integr,integration,317,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:369,reliability,integr,integration,369,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:433,reliability,integr,integration,433,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:486,reliability,integr,integration,486,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1732,reliability,integr,integration,1732,"t and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached. [nextflow.log](https://github.com/user-attachments/files/17008943/nextflow.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:88,safety,log,log,88,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:147,safety,error,error,147,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:202,safety,log,log,202,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:535,safety,input,input,535,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:953,safety,input,input,953,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1983,safety,log,log,1983,"t and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached. [nextflow.log](https://github.com/user-attachments/files/17008943/nextflow.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:2012,safety,log,log,2012,"t and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached. [nextflow.log](https://github.com/user-attachments/files/17008943/nextflow.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:2077,safety,log,log,2077,"t and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached. [nextflow.log](https://github.com/user-attachments/files/17008943/nextflow.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:88,security,log,log,88,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:202,security,log,log,202,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:317,security,integr,integration,317,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:369,security,integr,integration,369,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:433,security,integr,integration,433,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:486,security,integr,integration,486,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1732,security,integr,integration,1732,"t and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached. [nextflow.log](https://github.com/user-attachments/files/17008943/nextflow.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1983,security,log,log,1983,"t and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached. [nextflow.log](https://github.com/user-attachments/files/17008943/nextflow.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:2012,security,log,log,2012,"t and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached. [nextflow.log](https://github.com/user-attachments/files/17008943/nextflow.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:2077,security,log,log,2077,"t and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached. [nextflow.log](https://github.com/user-attachments/files/17008943/nextflow.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:88,testability,log,log,88,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:202,testability,log,log,202,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:317,testability,integr,integration,317,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:369,testability,integr,integration,369,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:433,testability,integr,integration,433,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:486,testability,integr,integration,486,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1732,testability,integr,integration,1732,"t and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached. [nextflow.log](https://github.com/user-attachments/files/17008943/nextflow.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:1983,testability,log,log,1983,"t and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached. [nextflow.log](https://github.com/user-attachments/files/17008943/nextflow.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:2012,testability,log,log,2012,"t and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached. [nextflow.log](https://github.com/user-attachments/files/17008943/nextflow.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:2077,testability,log,log,2077,"t and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached. [nextflow.log](https://github.com/user-attachments/files/17008943/nextflow.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:147,usability,error,error,147,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:500,usability,workflow,workflow,500,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:535,usability,input,input,535,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:953,usability,input,input,953,"Hi @akolesnikov , thank you for your response here i attached code, terminal output and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:2036,usability,user,user-attachments,2036,"t and log file. code is running but neither output generating or error throwing just running. please see below code and log file. ###### code #############. #!/usr/bin/env nextflow. nextflow.enable.dsl=2. params.outdir = '/home/deepak/integration/resu1'. params.data_dir = '/home/deepak/integration/resu1/4.markDupliM'. params.refhg38 = '/home/deepak/integration/hg381_22XYM'. params.bed = '/home/deepak/integration'. workflow {. // Define channels for input data. Channel. .fromPath(""${params.data_dir}/*_sorted_md.bam""). .map { file -> . def sample_id = file.baseName.replace('_sorted_md', ''). return [sample_id, file]. }. .set { read_pairs }. /// Step 1. DeepVariant. DeepVariant(read_pairs, params.refhg38, params.bed). }. process DeepVariant {. tag ""deepavar on ${sample_id}"". publishDir ""${params.outdir}/5.finaleepvar"", mode: 'copy'. cpus 4. //BIN_VERSION 1.6.1. input:. tuple val(sample_id), path(read_files). val(params.refhg38). val(params.bed). . output:. //tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), path(""${sample_id}_rawd.gvcf.gz""), emit: raw_vcfs. tuple val(sample_id), path(""${sample_id}_rawd.vcf.gz""), emit: raw_vcfs. script:. """""". docker run \. -v ""${params.data_dir}"":/opt/bam -v ""${params.refhg38}"":/opt/refhg38 -v ""${params.bed}"":/opt/bed \. google/deepvariant:latest \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /opt/refhg38/Homo_sapiens_assembly38cleaned.fasta \. --reads /opt/bam/${read_files} \. --regions /opt/bed/hg38_exomeY.bed \. --output_vcf /opt/bam/${sample_id}_rawd.vcf.gz \. --num_shards ${task.cpus}. """""". }. ######## code ################. terminal:. (base) deepak@ubuntu22:~/integration$ nextflow run final_deepvarian.nf . N E X T F L O W ~ version 24.04.4. Launching `final_deepvarian.nf` [hungry_stonebraker] DSL2 - revision: 4dab17f4f2. executor > local (1). [dd/64034b] DeepVariant (deepavar on SRR26512958) [ 0%] 0 of 2. log file attached. [nextflow.log](https://github.com/user-attachments/files/17008943/nextflow.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:47,availability,error,error,47,In order to debug the issue we need to see the error from DeepVariant. I see that you redirected stdout to `deepvariant_log.txt`. What is the content of this file?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:47,performance,error,error,47,In order to debug the issue we need to see the error from DeepVariant. I see that you redirected stdout to `deepvariant_log.txt`. What is the content of this file?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:142,performance,content,content,142,In order to debug the issue we need to see the error from DeepVariant. I see that you redirected stdout to `deepvariant_log.txt`. What is the content of this file?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:47,safety,error,error,47,In order to debug the issue we need to see the error from DeepVariant. I see that you redirected stdout to `deepvariant_log.txt`. What is the content of this file?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:47,usability,error,error,47,In order to debug the issue we need to see the error from DeepVariant. I see that you redirected stdout to `deepvariant_log.txt`. What is the content of this file?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:31,deployability,log,log,31,"Hi @akolesnikov ,. Please find log files. [nextflow.log](https://github.com/user-attachments/files/17056737/nextflow.log). [stderr.log](https://github.com/user-attachments/files/17056738/stderr.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:52,deployability,log,log,52,"Hi @akolesnikov ,. Please find log files. [nextflow.log](https://github.com/user-attachments/files/17056737/nextflow.log). [stderr.log](https://github.com/user-attachments/files/17056738/stderr.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:117,deployability,log,log,117,"Hi @akolesnikov ,. Please find log files. [nextflow.log](https://github.com/user-attachments/files/17056737/nextflow.log). [stderr.log](https://github.com/user-attachments/files/17056738/stderr.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:131,deployability,log,log,131,"Hi @akolesnikov ,. Please find log files. [nextflow.log](https://github.com/user-attachments/files/17056737/nextflow.log). [stderr.log](https://github.com/user-attachments/files/17056738/stderr.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:194,deployability,log,log,194,"Hi @akolesnikov ,. Please find log files. [nextflow.log](https://github.com/user-attachments/files/17056737/nextflow.log). [stderr.log](https://github.com/user-attachments/files/17056738/stderr.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:31,safety,log,log,31,"Hi @akolesnikov ,. Please find log files. [nextflow.log](https://github.com/user-attachments/files/17056737/nextflow.log). [stderr.log](https://github.com/user-attachments/files/17056738/stderr.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:52,safety,log,log,52,"Hi @akolesnikov ,. Please find log files. [nextflow.log](https://github.com/user-attachments/files/17056737/nextflow.log). [stderr.log](https://github.com/user-attachments/files/17056738/stderr.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:117,safety,log,log,117,"Hi @akolesnikov ,. Please find log files. [nextflow.log](https://github.com/user-attachments/files/17056737/nextflow.log). [stderr.log](https://github.com/user-attachments/files/17056738/stderr.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:131,safety,log,log,131,"Hi @akolesnikov ,. Please find log files. [nextflow.log](https://github.com/user-attachments/files/17056737/nextflow.log). [stderr.log](https://github.com/user-attachments/files/17056738/stderr.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:194,safety,log,log,194,"Hi @akolesnikov ,. Please find log files. [nextflow.log](https://github.com/user-attachments/files/17056737/nextflow.log). [stderr.log](https://github.com/user-attachments/files/17056738/stderr.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:31,security,log,log,31,"Hi @akolesnikov ,. Please find log files. [nextflow.log](https://github.com/user-attachments/files/17056737/nextflow.log). [stderr.log](https://github.com/user-attachments/files/17056738/stderr.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:52,security,log,log,52,"Hi @akolesnikov ,. Please find log files. [nextflow.log](https://github.com/user-attachments/files/17056737/nextflow.log). [stderr.log](https://github.com/user-attachments/files/17056738/stderr.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:117,security,log,log,117,"Hi @akolesnikov ,. Please find log files. [nextflow.log](https://github.com/user-attachments/files/17056737/nextflow.log). [stderr.log](https://github.com/user-attachments/files/17056738/stderr.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:131,security,log,log,131,"Hi @akolesnikov ,. Please find log files. [nextflow.log](https://github.com/user-attachments/files/17056737/nextflow.log). [stderr.log](https://github.com/user-attachments/files/17056738/stderr.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:194,security,log,log,194,"Hi @akolesnikov ,. Please find log files. [nextflow.log](https://github.com/user-attachments/files/17056737/nextflow.log). [stderr.log](https://github.com/user-attachments/files/17056738/stderr.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:31,testability,log,log,31,"Hi @akolesnikov ,. Please find log files. [nextflow.log](https://github.com/user-attachments/files/17056737/nextflow.log). [stderr.log](https://github.com/user-attachments/files/17056738/stderr.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:52,testability,log,log,52,"Hi @akolesnikov ,. Please find log files. [nextflow.log](https://github.com/user-attachments/files/17056737/nextflow.log). [stderr.log](https://github.com/user-attachments/files/17056738/stderr.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:117,testability,log,log,117,"Hi @akolesnikov ,. Please find log files. [nextflow.log](https://github.com/user-attachments/files/17056737/nextflow.log). [stderr.log](https://github.com/user-attachments/files/17056738/stderr.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:131,testability,log,log,131,"Hi @akolesnikov ,. Please find log files. [nextflow.log](https://github.com/user-attachments/files/17056737/nextflow.log). [stderr.log](https://github.com/user-attachments/files/17056738/stderr.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:194,testability,log,log,194,"Hi @akolesnikov ,. Please find log files. [nextflow.log](https://github.com/user-attachments/files/17056737/nextflow.log). [stderr.log](https://github.com/user-attachments/files/17056738/stderr.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:76,usability,user,user-attachments,76,"Hi @akolesnikov ,. Please find log files. [nextflow.log](https://github.com/user-attachments/files/17056737/nextflow.log). [stderr.log](https://github.com/user-attachments/files/17056738/stderr.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:155,usability,user,user-attachments,155,"Hi @akolesnikov ,. Please find log files. [nextflow.log](https://github.com/user-attachments/files/17056737/nextflow.log). [stderr.log](https://github.com/user-attachments/files/17056738/stderr.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:25,deployability,log,log,25,"Hi @dbhayal9 , from your log, it seems like DeepVariant finished running, and generated an output VCF here: /home/ubuntu/rgenx/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz. Can you try looking for the file? Something like. `ls /home/ubuntu/rgenx/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz`. and if it exist, you can `zcat` it to see if it has the expected content?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:362,performance,content,content,362,"Hi @dbhayal9 , from your log, it seems like DeepVariant finished running, and generated an output VCF here: /home/ubuntu/rgenx/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz. Can you try looking for the file? Something like. `ls /home/ubuntu/rgenx/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz`. and if it exist, you can `zcat` it to see if it has the expected content?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:25,safety,log,log,25,"Hi @dbhayal9 , from your log, it seems like DeepVariant finished running, and generated an output VCF here: /home/ubuntu/rgenx/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz. Can you try looking for the file? Something like. `ls /home/ubuntu/rgenx/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz`. and if it exist, you can `zcat` it to see if it has the expected content?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:25,security,log,log,25,"Hi @dbhayal9 , from your log, it seems like DeepVariant finished running, and generated an output VCF here: /home/ubuntu/rgenx/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz. Can you try looking for the file? Something like. `ls /home/ubuntu/rgenx/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz`. and if it exist, you can `zcat` it to see if it has the expected content?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/883:25,testability,log,log,25,"Hi @dbhayal9 , from your log, it seems like DeepVariant finished running, and generated an output VCF here: /home/ubuntu/rgenx/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz. Can you try looking for the file? Something like. `ls /home/ubuntu/rgenx/nextflow2/output/5.snvS/SRR26512958_raw.vcf.gz`. and if it exist, you can `zcat` it to see if it has the expected content?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/883
https://github.com/google/deepvariant/issues/884:91,deployability,updat,update,91,"Hi, . This is duplicate of https://github.com/google/deepsomatic/issues/22. I will give an update there and close this issue as this is unrelated to DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/884
https://github.com/google/deepvariant/issues/884:91,safety,updat,update,91,"Hi, . This is duplicate of https://github.com/google/deepsomatic/issues/22. I will give an update there and close this issue as this is unrelated to DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/884
https://github.com/google/deepvariant/issues/884:91,security,updat,update,91,"Hi, . This is duplicate of https://github.com/google/deepsomatic/issues/22. I will give an update there and close this issue as this is unrelated to DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/884
https://github.com/google/deepvariant/issues/884:108,usability,close,close,108,"Hi, . This is duplicate of https://github.com/google/deepsomatic/issues/22. I will give an update there and close this issue as this is unrelated to DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/884
https://github.com/google/deepvariant/issues/885:313,deployability,updat,update,313,"Hi,. It is actually possible to train DeepVariant on multiple GPUs, using the [MirroredStrategy](https://github.com/google/deepvariant/blob/r1.6.1/deepvariant/train.py#L112). You can find the tensorflow documentation here: [link](https://www.tensorflow.org/guide/distributed_training). . It looks like we need to update the [FAQ](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus) to reflect thatthanks for brining it to our attention! The [training case study](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train) is up-to-date, so feel to continue to reference that. It looks like it already applies the `mirrored ` strategy.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:644,deployability,continu,continue,644,"Hi,. It is actually possible to train DeepVariant on multiple GPUs, using the [MirroredStrategy](https://github.com/google/deepvariant/blob/r1.6.1/deepvariant/train.py#L112). You can find the tensorflow documentation here: [link](https://www.tensorflow.org/guide/distributed_training). . It looks like we need to update the [FAQ](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus) to reflect thatthanks for brining it to our attention! The [training case study](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train) is up-to-date, so feel to continue to reference that. It looks like it already applies the `mirrored ` strategy.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:62,energy efficiency,GPU,GPUs,62,"Hi,. It is actually possible to train DeepVariant on multiple GPUs, using the [MirroredStrategy](https://github.com/google/deepvariant/blob/r1.6.1/deepvariant/train.py#L112). You can find the tensorflow documentation here: [link](https://www.tensorflow.org/guide/distributed_training). . It looks like we need to update the [FAQ](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus) to reflect thatthanks for brining it to our attention! The [training case study](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train) is up-to-date, so feel to continue to reference that. It looks like it already applies the `mirrored ` strategy.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:427,energy efficiency,gpu,gpus,427,"Hi,. It is actually possible to train DeepVariant on multiple GPUs, using the [MirroredStrategy](https://github.com/google/deepvariant/blob/r1.6.1/deepvariant/train.py#L112). You can find the tensorflow documentation here: [link](https://www.tensorflow.org/guide/distributed_training). . It looks like we need to update the [FAQ](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus) to reflect thatthanks for brining it to our attention! The [training case study](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train) is up-to-date, so feel to continue to reference that. It looks like it already applies the `mirrored ` strategy.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:62,performance,GPU,GPUs,62,"Hi,. It is actually possible to train DeepVariant on multiple GPUs, using the [MirroredStrategy](https://github.com/google/deepvariant/blob/r1.6.1/deepvariant/train.py#L112). You can find the tensorflow documentation here: [link](https://www.tensorflow.org/guide/distributed_training). . It looks like we need to update the [FAQ](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus) to reflect thatthanks for brining it to our attention! The [training case study](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train) is up-to-date, so feel to continue to reference that. It looks like it already applies the `mirrored ` strategy.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:427,performance,gpu,gpus,427,"Hi,. It is actually possible to train DeepVariant on multiple GPUs, using the [MirroredStrategy](https://github.com/google/deepvariant/blob/r1.6.1/deepvariant/train.py#L112). You can find the tensorflow documentation here: [link](https://www.tensorflow.org/guide/distributed_training). . It looks like we need to update the [FAQ](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus) to reflect thatthanks for brining it to our attention! The [training case study](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train) is up-to-date, so feel to continue to reference that. It looks like it already applies the `mirrored ` strategy.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:313,safety,updat,update,313,"Hi,. It is actually possible to train DeepVariant on multiple GPUs, using the [MirroredStrategy](https://github.com/google/deepvariant/blob/r1.6.1/deepvariant/train.py#L112). You can find the tensorflow documentation here: [link](https://www.tensorflow.org/guide/distributed_training). . It looks like we need to update the [FAQ](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus) to reflect thatthanks for brining it to our attention! The [training case study](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train) is up-to-date, so feel to continue to reference that. It looks like it already applies the `mirrored ` strategy.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:313,security,updat,update,313,"Hi,. It is actually possible to train DeepVariant on multiple GPUs, using the [MirroredStrategy](https://github.com/google/deepvariant/blob/r1.6.1/deepvariant/train.py#L112). You can find the tensorflow documentation here: [link](https://www.tensorflow.org/guide/distributed_training). . It looks like we need to update the [FAQ](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus) to reflect thatthanks for brining it to our attention! The [training case study](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train) is up-to-date, so feel to continue to reference that. It looks like it already applies the `mirrored ` strategy.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:203,usability,document,documentation,203,"Hi,. It is actually possible to train DeepVariant on multiple GPUs, using the [MirroredStrategy](https://github.com/google/deepvariant/blob/r1.6.1/deepvariant/train.py#L112). You can find the tensorflow documentation here: [link](https://www.tensorflow.org/guide/distributed_training). . It looks like we need to update the [FAQ](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus) to reflect thatthanks for brining it to our attention! The [training case study](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train) is up-to-date, so feel to continue to reference that. It looks like it already applies the `mirrored ` strategy.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/885:257,usability,guid,guide,257,"Hi,. It is actually possible to train DeepVariant on multiple GPUs, using the [MirroredStrategy](https://github.com/google/deepvariant/blob/r1.6.1/deepvariant/train.py#L112). You can find the tensorflow documentation here: [link](https://www.tensorflow.org/guide/distributed_training). . It looks like we need to update the [FAQ](https://github.com/google/deepvariant/blob/r1.6.1/docs/FAQ.md#can-model_train-be-run-on-multiple-gpus) to reflect thatthanks for brining it to our attention! The [training case study](https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-training-case-study.md#start-train) is up-to-date, so feel to continue to reference that. It looks like it already applies the `mirrored ` strategy.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/885
https://github.com/google/deepvariant/issues/886:212,deployability,instal,installed,212,"Hi @desmodus1984 ,. I just checked our singularity solution and it works on a n2-standard-64 GCP machine. Without knowing much about your system, my guess is it's probably something related to how singularity is installed in your system? Are you on an HPC?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:81,interoperability,standard,standard-,81,"Hi @desmodus1984 ,. I just checked our singularity solution and it works on a n2-standard-64 GCP machine. Without knowing much about your system, my guess is it's probably something related to how singularity is installed in your system? Are you on an HPC?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:154,availability,down,download,154,"Hi @kishwarshafin . I did install Singularity in a conda environment and then I used the singularity installed in the HPC, and in both systems I couldn't download the container.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:26,deployability,instal,install,26,"Hi @kishwarshafin . I did install Singularity in a conda environment and then I used the singularity installed in the HPC, and in both systems I couldn't download the container.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:101,deployability,instal,installed,101,"Hi @kishwarshafin . I did install Singularity in a conda environment and then I used the singularity installed in the HPC, and in both systems I couldn't download the container.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:167,deployability,contain,container,167,"Hi @kishwarshafin . I did install Singularity in a conda environment and then I used the singularity installed in the HPC, and in both systems I couldn't download the container.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:187,availability,down,download,187,"@desmodus1984 ,. Can you verify this issue is specific to DeepVariant and not your system? Can you run:. ```bash. singularity pull docker://ubuntu:latest. ```. And see if you are able to download that?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:46,interoperability,specif,specific,46,"@desmodus1984 ,. Can you verify this issue is specific to DeepVariant and not your system? Can you run:. ```bash. singularity pull docker://ubuntu:latest. ```. And see if you are able to download that?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:25,testability,verif,verify,25,"@desmodus1984 ,. Can you verify this issue is specific to DeepVariant and not your system? Can you run:. ```bash. singularity pull docker://ubuntu:latest. ```. And see if you are able to download that?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/886:70,usability,help,help,70,Closing this for no activity. Feel free to reopen if you need further help.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/886
https://github.com/google/deepvariant/issues/887:17,energy efficiency,Current,Currently,17,"Hi @0809zheng ,. Currently, there is not solution provided by us to look at call variants output. However, call variants output go to postprocess variants and that converts the calls into a VCF which you can look into.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/887
https://github.com/google/deepvariant/issues/887:45,usability,close,close,45,"Thank you very much for your comment, I will close this issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/887
https://github.com/google/deepvariant/issues/888:3,modifiability,Pac,PacBio,3,"1. PacBio encourages to use `pbmm2` on unaligned HiFi BAM files. 2. DeepVariant ignores MM/ML tags. There's no need to map twice, proceed with your `bam-to-bam` workflow.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/888
https://github.com/google/deepvariant/issues/888:161,usability,workflow,workflow,161,"1. PacBio encourages to use `pbmm2` on unaligned HiFi BAM files. 2. DeepVariant ignores MM/ML tags. There's no need to map twice, proceed with your `bam-to-bam` workflow.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/888
https://github.com/google/deepvariant/issues/889:251,safety,input,input,251,"Hi @abosco4406 , . DeepVariant is a germline variant caller, so it's not suitable for this use case. You can look at DeepSomatic: https://github.com/google/deepsomatic , but it's also not exactly the same as your use case which has very high coverage input data.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/889
https://github.com/google/deepvariant/issues/889:242,testability,coverag,coverage,242,"Hi @abosco4406 , . DeepVariant is a germline variant caller, so it's not suitable for this use case. You can look at DeepSomatic: https://github.com/google/deepsomatic , but it's also not exactly the same as your use case which has very high coverage input data.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/889
https://github.com/google/deepvariant/issues/889:251,usability,input,input,251,"Hi @abosco4406 , . DeepVariant is a germline variant caller, so it's not suitable for this use case. You can look at DeepSomatic: https://github.com/google/deepsomatic , but it's also not exactly the same as your use case which has very high coverage input data.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/889
https://github.com/google/deepvariant/issues/890:213,availability,avail,available,213,"Hi @camelest . Thanks for the issue. We have trained a DeepVariant isoseq model specifically for the type of data you have (I presume you have done: splitNCigarReads + FlagCorrection). We're planning to make that available to everyone soon. If you like, we can give you a custom model for this application in advance. If so, please email awcarroll@google.com and I can send you the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:74,energy efficiency,model,model,74,"Hi @camelest . Thanks for the issue. We have trained a DeepVariant isoseq model specifically for the type of data you have (I presume you have done: splitNCigarReads + FlagCorrection). We're planning to make that available to everyone soon. If you like, we can give you a custom model for this application in advance. If so, please email awcarroll@google.com and I can send you the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:279,energy efficiency,model,model,279,"Hi @camelest . Thanks for the issue. We have trained a DeepVariant isoseq model specifically for the type of data you have (I presume you have done: splitNCigarReads + FlagCorrection). We're planning to make that available to everyone soon. If you like, we can give you a custom model for this application in advance. If so, please email awcarroll@google.com and I can send you the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:80,interoperability,specif,specifically,80,"Hi @camelest . Thanks for the issue. We have trained a DeepVariant isoseq model specifically for the type of data you have (I presume you have done: splitNCigarReads + FlagCorrection). We're planning to make that available to everyone soon. If you like, we can give you a custom model for this application in advance. If so, please email awcarroll@google.com and I can send you the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:213,reliability,availab,available,213,"Hi @camelest . Thanks for the issue. We have trained a DeepVariant isoseq model specifically for the type of data you have (I presume you have done: splitNCigarReads + FlagCorrection). We're planning to make that available to everyone soon. If you like, we can give you a custom model for this application in advance. If so, please email awcarroll@google.com and I can send you the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:213,safety,avail,available,213,"Hi @camelest . Thanks for the issue. We have trained a DeepVariant isoseq model specifically for the type of data you have (I presume you have done: splitNCigarReads + FlagCorrection). We're planning to make that available to everyone soon. If you like, we can give you a custom model for this application in advance. If so, please email awcarroll@google.com and I can send you the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:67,security,iso,isoseq,67,"Hi @camelest . Thanks for the issue. We have trained a DeepVariant isoseq model specifically for the type of data you have (I presume you have done: splitNCigarReads + FlagCorrection). We're planning to make that available to everyone soon. If you like, we can give you a custom model for this application in advance. If so, please email awcarroll@google.com and I can send you the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:74,security,model,model,74,"Hi @camelest . Thanks for the issue. We have trained a DeepVariant isoseq model specifically for the type of data you have (I presume you have done: splitNCigarReads + FlagCorrection). We're planning to make that available to everyone soon. If you like, we can give you a custom model for this application in advance. If so, please email awcarroll@google.com and I can send you the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:213,security,availab,available,213,"Hi @camelest . Thanks for the issue. We have trained a DeepVariant isoseq model specifically for the type of data you have (I presume you have done: splitNCigarReads + FlagCorrection). We're planning to make that available to everyone soon. If you like, we can give you a custom model for this application in advance. If so, please email awcarroll@google.com and I can send you the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:279,security,model,model,279,"Hi @camelest . Thanks for the issue. We have trained a DeepVariant isoseq model specifically for the type of data you have (I presume you have done: splitNCigarReads + FlagCorrection). We're planning to make that available to everyone soon. If you like, we can give you a custom model for this application in advance. If so, please email awcarroll@google.com and I can send you the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:191,testability,plan,planning,191,"Hi @camelest . Thanks for the issue. We have trained a DeepVariant isoseq model specifically for the type of data you have (I presume you have done: splitNCigarReads + FlagCorrection). We're planning to make that available to everyone soon. If you like, we can give you a custom model for this application in advance. If so, please email awcarroll@google.com and I can send you the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:272,usability,custom,custom,272,"Hi @camelest . Thanks for the issue. We have trained a DeepVariant isoseq model specifically for the type of data you have (I presume you have done: splitNCigarReads + FlagCorrection). We're planning to make that available to everyone soon. If you like, we can give you a custom model for this application in advance. If so, please email awcarroll@google.com and I can send you the files.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/890:81,usability,help,helpful,81,"Hi, @AndrewCarroll,. Thank you so much for your kind offer. That would be really helpful. I will send an email at the address. Best,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/890
https://github.com/google/deepvariant/issues/891:141,energy efficiency,model,model,141,"Hi @kishwarshafin, . As far as I understand, the license is for the DeepVariant software. Is the same license applicable for the DeepVariant model?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/891
https://github.com/google/deepvariant/issues/891:141,security,model,model,141,"Hi @kishwarshafin, . As far as I understand, the license is for the DeepVariant software. Is the same license applicable for the DeepVariant model?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/891
https://github.com/google/deepvariant/issues/891:33,testability,understand,understand,33,"Hi @kishwarshafin, . As far as I understand, the license is for the DeepVariant software. Is the same license applicable for the DeepVariant model?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/891
https://github.com/google/deepvariant/issues/891:49,energy efficiency,model,models,49,"@sanchit-misra , yes, the license extends to the models.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/891
https://github.com/google/deepvariant/issues/891:34,modifiability,exten,extends,34,"@sanchit-misra , yes, the license extends to the models.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/891
https://github.com/google/deepvariant/issues/891:49,security,model,models,49,"@sanchit-misra , yes, the license extends to the models.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/891
https://github.com/google/deepvariant/issues/892:672,deployability,updat,update,672,"this is everything that is in the vcf, so the deviations are not picked up at all. It is just one line with the 5' deviation. If I include other genomic region, than I do see more variations there, but for this region it is not recognized at all. ![image](https://github.com/user-attachments/assets/cb092f42-5285-48f5-b2c8-dc1f9590e9c2). [output.vcf.txt](https://github.com/user-attachments/files/17303859/output.vcf.txt). However both positions (3948 and 3949) show up in the output.g.vcf. [output.g.vcf.txt](https://github.com/user-attachments/files/17303928/output.g.vcf.txt). ![image](https://github.com/user-attachments/assets/408893bd-27a6-48ac-9f6c-4260a96741c9). *update: I just tried the same data with clair3 and it also does not call these two positions. . I then aligned against only the transgen in the genomic context (~50 kb each side) and then the variants are called correctly, so it seemed to have something to do with the reads also mapping to the other region. So I checked the reads again in more detail and it turns out that at the 5' SNP only 2 reads are primary and at the two 3' SNPs there is only one primary alignment, the others are supplementary. Therefore vsc_min_count_snps=2 filters the 3' SNPs out, while the 5' barely passes. I then reduced vsc_min_count_snps to 1 and now I find also the two 3' SNPs in the vcf output, with one passing and the other being Refcall. Of course plenty of other SNPs show up as well, but with low QUAL values and being RefCall ... So this is an issue of the way that I make the reference FASTA, but I don't see any other way of doing this, because otherwise I would have to duplicate the surrounding genomic DNA postentially ending up with many supplementary alignments as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:1267,energy efficiency,reduc,reduced,1267,"this is everything that is in the vcf, so the deviations are not picked up at all. It is just one line with the 5' deviation. If I include other genomic region, than I do see more variations there, but for this region it is not recognized at all. ![image](https://github.com/user-attachments/assets/cb092f42-5285-48f5-b2c8-dc1f9590e9c2). [output.vcf.txt](https://github.com/user-attachments/files/17303859/output.vcf.txt). However both positions (3948 and 3949) show up in the output.g.vcf. [output.g.vcf.txt](https://github.com/user-attachments/files/17303928/output.g.vcf.txt). ![image](https://github.com/user-attachments/assets/408893bd-27a6-48ac-9f6c-4260a96741c9). *update: I just tried the same data with clair3 and it also does not call these two positions. . I then aligned against only the transgen in the genomic context (~50 kb each side) and then the variants are called correctly, so it seemed to have something to do with the reads also mapping to the other region. So I checked the reads again in more detail and it turns out that at the 5' SNP only 2 reads are primary and at the two 3' SNPs there is only one primary alignment, the others are supplementary. Therefore vsc_min_count_snps=2 filters the 3' SNPs out, while the 5' barely passes. I then reduced vsc_min_count_snps to 1 and now I find also the two 3' SNPs in the vcf output, with one passing and the other being Refcall. Of course plenty of other SNPs show up as well, but with low QUAL values and being RefCall ... So this is an issue of the way that I make the reference FASTA, but I don't see any other way of doing this, because otherwise I would have to duplicate the surrounding genomic DNA postentially ending up with many supplementary alignments as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:1207,integrability,filter,filters,1207,"this is everything that is in the vcf, so the deviations are not picked up at all. It is just one line with the 5' deviation. If I include other genomic region, than I do see more variations there, but for this region it is not recognized at all. ![image](https://github.com/user-attachments/assets/cb092f42-5285-48f5-b2c8-dc1f9590e9c2). [output.vcf.txt](https://github.com/user-attachments/files/17303859/output.vcf.txt). However both positions (3948 and 3949) show up in the output.g.vcf. [output.g.vcf.txt](https://github.com/user-attachments/files/17303928/output.g.vcf.txt). ![image](https://github.com/user-attachments/assets/408893bd-27a6-48ac-9f6c-4260a96741c9). *update: I just tried the same data with clair3 and it also does not call these two positions. . I then aligned against only the transgen in the genomic context (~50 kb each side) and then the variants are called correctly, so it seemed to have something to do with the reads also mapping to the other region. So I checked the reads again in more detail and it turns out that at the 5' SNP only 2 reads are primary and at the two 3' SNPs there is only one primary alignment, the others are supplementary. Therefore vsc_min_count_snps=2 filters the 3' SNPs out, while the 5' barely passes. I then reduced vsc_min_count_snps to 1 and now I find also the two 3' SNPs in the vcf output, with one passing and the other being Refcall. Of course plenty of other SNPs show up as well, but with low QUAL values and being RefCall ... So this is an issue of the way that I make the reference FASTA, but I don't see any other way of doing this, because otherwise I would have to duplicate the surrounding genomic DNA postentially ending up with many supplementary alignments as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:731,reliability,doe,does,731,"this is everything that is in the vcf, so the deviations are not picked up at all. It is just one line with the 5' deviation. If I include other genomic region, than I do see more variations there, but for this region it is not recognized at all. ![image](https://github.com/user-attachments/assets/cb092f42-5285-48f5-b2c8-dc1f9590e9c2). [output.vcf.txt](https://github.com/user-attachments/files/17303859/output.vcf.txt). However both positions (3948 and 3949) show up in the output.g.vcf. [output.g.vcf.txt](https://github.com/user-attachments/files/17303928/output.g.vcf.txt). ![image](https://github.com/user-attachments/assets/408893bd-27a6-48ac-9f6c-4260a96741c9). *update: I just tried the same data with clair3 and it also does not call these two positions. . I then aligned against only the transgen in the genomic context (~50 kb each side) and then the variants are called correctly, so it seemed to have something to do with the reads also mapping to the other region. So I checked the reads again in more detail and it turns out that at the 5' SNP only 2 reads are primary and at the two 3' SNPs there is only one primary alignment, the others are supplementary. Therefore vsc_min_count_snps=2 filters the 3' SNPs out, while the 5' barely passes. I then reduced vsc_min_count_snps to 1 and now I find also the two 3' SNPs in the vcf output, with one passing and the other being Refcall. Of course plenty of other SNPs show up as well, but with low QUAL values and being RefCall ... So this is an issue of the way that I make the reference FASTA, but I don't see any other way of doing this, because otherwise I would have to duplicate the surrounding genomic DNA postentially ending up with many supplementary alignments as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:672,safety,updat,update,672,"this is everything that is in the vcf, so the deviations are not picked up at all. It is just one line with the 5' deviation. If I include other genomic region, than I do see more variations there, but for this region it is not recognized at all. ![image](https://github.com/user-attachments/assets/cb092f42-5285-48f5-b2c8-dc1f9590e9c2). [output.vcf.txt](https://github.com/user-attachments/files/17303859/output.vcf.txt). However both positions (3948 and 3949) show up in the output.g.vcf. [output.g.vcf.txt](https://github.com/user-attachments/files/17303928/output.g.vcf.txt). ![image](https://github.com/user-attachments/assets/408893bd-27a6-48ac-9f6c-4260a96741c9). *update: I just tried the same data with clair3 and it also does not call these two positions. . I then aligned against only the transgen in the genomic context (~50 kb each side) and then the variants are called correctly, so it seemed to have something to do with the reads also mapping to the other region. So I checked the reads again in more detail and it turns out that at the 5' SNP only 2 reads are primary and at the two 3' SNPs there is only one primary alignment, the others are supplementary. Therefore vsc_min_count_snps=2 filters the 3' SNPs out, while the 5' barely passes. I then reduced vsc_min_count_snps to 1 and now I find also the two 3' SNPs in the vcf output, with one passing and the other being Refcall. Of course plenty of other SNPs show up as well, but with low QUAL values and being RefCall ... So this is an issue of the way that I make the reference FASTA, but I don't see any other way of doing this, because otherwise I would have to duplicate the surrounding genomic DNA postentially ending up with many supplementary alignments as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:672,security,updat,update,672,"this is everything that is in the vcf, so the deviations are not picked up at all. It is just one line with the 5' deviation. If I include other genomic region, than I do see more variations there, but for this region it is not recognized at all. ![image](https://github.com/user-attachments/assets/cb092f42-5285-48f5-b2c8-dc1f9590e9c2). [output.vcf.txt](https://github.com/user-attachments/files/17303859/output.vcf.txt). However both positions (3948 and 3949) show up in the output.g.vcf. [output.g.vcf.txt](https://github.com/user-attachments/files/17303928/output.g.vcf.txt). ![image](https://github.com/user-attachments/assets/408893bd-27a6-48ac-9f6c-4260a96741c9). *update: I just tried the same data with clair3 and it also does not call these two positions. . I then aligned against only the transgen in the genomic context (~50 kb each side) and then the variants are called correctly, so it seemed to have something to do with the reads also mapping to the other region. So I checked the reads again in more detail and it turns out that at the 5' SNP only 2 reads are primary and at the two 3' SNPs there is only one primary alignment, the others are supplementary. Therefore vsc_min_count_snps=2 filters the 3' SNPs out, while the 5' barely passes. I then reduced vsc_min_count_snps to 1 and now I find also the two 3' SNPs in the vcf output, with one passing and the other being Refcall. Of course plenty of other SNPs show up as well, but with low QUAL values and being RefCall ... So this is an issue of the way that I make the reference FASTA, but I don't see any other way of doing this, because otherwise I would have to duplicate the surrounding genomic DNA postentially ending up with many supplementary alignments as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:824,testability,context,context,824,"this is everything that is in the vcf, so the deviations are not picked up at all. It is just one line with the 5' deviation. If I include other genomic region, than I do see more variations there, but for this region it is not recognized at all. ![image](https://github.com/user-attachments/assets/cb092f42-5285-48f5-b2c8-dc1f9590e9c2). [output.vcf.txt](https://github.com/user-attachments/files/17303859/output.vcf.txt). However both positions (3948 and 3949) show up in the output.g.vcf. [output.g.vcf.txt](https://github.com/user-attachments/files/17303928/output.g.vcf.txt). ![image](https://github.com/user-attachments/assets/408893bd-27a6-48ac-9f6c-4260a96741c9). *update: I just tried the same data with clair3 and it also does not call these two positions. . I then aligned against only the transgen in the genomic context (~50 kb each side) and then the variants are called correctly, so it seemed to have something to do with the reads also mapping to the other region. So I checked the reads again in more detail and it turns out that at the 5' SNP only 2 reads are primary and at the two 3' SNPs there is only one primary alignment, the others are supplementary. Therefore vsc_min_count_snps=2 filters the 3' SNPs out, while the 5' barely passes. I then reduced vsc_min_count_snps to 1 and now I find also the two 3' SNPs in the vcf output, with one passing and the other being Refcall. Of course plenty of other SNPs show up as well, but with low QUAL values and being RefCall ... So this is an issue of the way that I make the reference FASTA, but I don't see any other way of doing this, because otherwise I would have to duplicate the surrounding genomic DNA postentially ending up with many supplementary alignments as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:275,usability,user,user-attachments,275,"this is everything that is in the vcf, so the deviations are not picked up at all. It is just one line with the 5' deviation. If I include other genomic region, than I do see more variations there, but for this region it is not recognized at all. ![image](https://github.com/user-attachments/assets/cb092f42-5285-48f5-b2c8-dc1f9590e9c2). [output.vcf.txt](https://github.com/user-attachments/files/17303859/output.vcf.txt). However both positions (3948 and 3949) show up in the output.g.vcf. [output.g.vcf.txt](https://github.com/user-attachments/files/17303928/output.g.vcf.txt). ![image](https://github.com/user-attachments/assets/408893bd-27a6-48ac-9f6c-4260a96741c9). *update: I just tried the same data with clair3 and it also does not call these two positions. . I then aligned against only the transgen in the genomic context (~50 kb each side) and then the variants are called correctly, so it seemed to have something to do with the reads also mapping to the other region. So I checked the reads again in more detail and it turns out that at the 5' SNP only 2 reads are primary and at the two 3' SNPs there is only one primary alignment, the others are supplementary. Therefore vsc_min_count_snps=2 filters the 3' SNPs out, while the 5' barely passes. I then reduced vsc_min_count_snps to 1 and now I find also the two 3' SNPs in the vcf output, with one passing and the other being Refcall. Of course plenty of other SNPs show up as well, but with low QUAL values and being RefCall ... So this is an issue of the way that I make the reference FASTA, but I don't see any other way of doing this, because otherwise I would have to duplicate the surrounding genomic DNA postentially ending up with many supplementary alignments as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:374,usability,user,user-attachments,374,"this is everything that is in the vcf, so the deviations are not picked up at all. It is just one line with the 5' deviation. If I include other genomic region, than I do see more variations there, but for this region it is not recognized at all. ![image](https://github.com/user-attachments/assets/cb092f42-5285-48f5-b2c8-dc1f9590e9c2). [output.vcf.txt](https://github.com/user-attachments/files/17303859/output.vcf.txt). However both positions (3948 and 3949) show up in the output.g.vcf. [output.g.vcf.txt](https://github.com/user-attachments/files/17303928/output.g.vcf.txt). ![image](https://github.com/user-attachments/assets/408893bd-27a6-48ac-9f6c-4260a96741c9). *update: I just tried the same data with clair3 and it also does not call these two positions. . I then aligned against only the transgen in the genomic context (~50 kb each side) and then the variants are called correctly, so it seemed to have something to do with the reads also mapping to the other region. So I checked the reads again in more detail and it turns out that at the 5' SNP only 2 reads are primary and at the two 3' SNPs there is only one primary alignment, the others are supplementary. Therefore vsc_min_count_snps=2 filters the 3' SNPs out, while the 5' barely passes. I then reduced vsc_min_count_snps to 1 and now I find also the two 3' SNPs in the vcf output, with one passing and the other being Refcall. Of course plenty of other SNPs show up as well, but with low QUAL values and being RefCall ... So this is an issue of the way that I make the reference FASTA, but I don't see any other way of doing this, because otherwise I would have to duplicate the surrounding genomic DNA postentially ending up with many supplementary alignments as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:529,usability,user,user-attachments,529,"this is everything that is in the vcf, so the deviations are not picked up at all. It is just one line with the 5' deviation. If I include other genomic region, than I do see more variations there, but for this region it is not recognized at all. ![image](https://github.com/user-attachments/assets/cb092f42-5285-48f5-b2c8-dc1f9590e9c2). [output.vcf.txt](https://github.com/user-attachments/files/17303859/output.vcf.txt). However both positions (3948 and 3949) show up in the output.g.vcf. [output.g.vcf.txt](https://github.com/user-attachments/files/17303928/output.g.vcf.txt). ![image](https://github.com/user-attachments/assets/408893bd-27a6-48ac-9f6c-4260a96741c9). *update: I just tried the same data with clair3 and it also does not call these two positions. . I then aligned against only the transgen in the genomic context (~50 kb each side) and then the variants are called correctly, so it seemed to have something to do with the reads also mapping to the other region. So I checked the reads again in more detail and it turns out that at the 5' SNP only 2 reads are primary and at the two 3' SNPs there is only one primary alignment, the others are supplementary. Therefore vsc_min_count_snps=2 filters the 3' SNPs out, while the 5' barely passes. I then reduced vsc_min_count_snps to 1 and now I find also the two 3' SNPs in the vcf output, with one passing and the other being Refcall. Of course plenty of other SNPs show up as well, but with low QUAL values and being RefCall ... So this is an issue of the way that I make the reference FASTA, but I don't see any other way of doing this, because otherwise I would have to duplicate the surrounding genomic DNA postentially ending up with many supplementary alignments as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:608,usability,user,user-attachments,608,"this is everything that is in the vcf, so the deviations are not picked up at all. It is just one line with the 5' deviation. If I include other genomic region, than I do see more variations there, but for this region it is not recognized at all. ![image](https://github.com/user-attachments/assets/cb092f42-5285-48f5-b2c8-dc1f9590e9c2). [output.vcf.txt](https://github.com/user-attachments/files/17303859/output.vcf.txt). However both positions (3948 and 3949) show up in the output.g.vcf. [output.g.vcf.txt](https://github.com/user-attachments/files/17303928/output.g.vcf.txt). ![image](https://github.com/user-attachments/assets/408893bd-27a6-48ac-9f6c-4260a96741c9). *update: I just tried the same data with clair3 and it also does not call these two positions. . I then aligned against only the transgen in the genomic context (~50 kb each side) and then the variants are called correctly, so it seemed to have something to do with the reads also mapping to the other region. So I checked the reads again in more detail and it turns out that at the 5' SNP only 2 reads are primary and at the two 3' SNPs there is only one primary alignment, the others are supplementary. Therefore vsc_min_count_snps=2 filters the 3' SNPs out, while the 5' barely passes. I then reduced vsc_min_count_snps to 1 and now I find also the two 3' SNPs in the vcf output, with one passing and the other being Refcall. Of course plenty of other SNPs show up as well, but with low QUAL values and being RefCall ... So this is an issue of the way that I make the reference FASTA, but I don't see any other way of doing this, because otherwise I would have to duplicate the surrounding genomic DNA postentially ending up with many supplementary alignments as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:151,availability,operat,operating,151,"@hagen-wende ,. Thank you for looking into this. In your use-case, variant calling would be extremely difficult as mapping is difficult. Also, you are operating at 5x coverage. We only see the performance of ONT that are considered to be good from 15x. With that said, you can use DeepVariant create alleles for your use. Just drop the values under the threshold and all alleles will be reported so it at least gives you some idea of where the variants could be.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:193,performance,perform,performance,193,"@hagen-wende ,. Thank you for looking into this. In your use-case, variant calling would be extremely difficult as mapping is difficult. Also, you are operating at 5x coverage. We only see the performance of ONT that are considered to be good from 15x. With that said, you can use DeepVariant create alleles for your use. Just drop the values under the threshold and all alleles will be reported so it at least gives you some idea of where the variants could be.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:167,testability,coverag,coverage,167,"@hagen-wende ,. Thank you for looking into this. In your use-case, variant calling would be extremely difficult as mapping is difficult. Also, you are operating at 5x coverage. We only see the performance of ONT that are considered to be good from 15x. With that said, you can use DeepVariant create alleles for your use. Just drop the values under the threshold and all alleles will be reported so it at least gives you some idea of where the variants could be.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:193,usability,perform,performance,193,"@hagen-wende ,. Thank you for looking into this. In your use-case, variant calling would be extremely difficult as mapping is difficult. Also, you are operating at 5x coverage. We only see the performance of ONT that are considered to be good from 15x. With that said, you can use DeepVariant create alleles for your use. Just drop the values under the threshold and all alleles will be reported so it at least gives you some idea of where the variants could be.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:8,testability,coverag,coverage,8,"well 5x coverage is in part because I just look at one allele here and it is also underrepresented, our overall WGS coverage is usually between 20-30x. I will also think of how to deal with this issue, but it is at least good to know, where the issue is. I can still align against the transgene in the genomic context and call the variants for this alignment and then do a separate alignment against the entire genome and call variants outside the transgene (if I need it). Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:116,testability,coverag,coverage,116,"well 5x coverage is in part because I just look at one allele here and it is also underrepresented, our overall WGS coverage is usually between 20-30x. I will also think of how to deal with this issue, but it is at least good to know, where the issue is. I can still align against the transgene in the genomic context and call the variants for this alignment and then do a separate alignment against the entire genome and call variants outside the transgene (if I need it). Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/892:310,testability,context,context,310,"well 5x coverage is in part because I just look at one allele here and it is also underrepresented, our overall WGS coverage is usually between 20-30x. I will also think of how to deal with this issue, but it is at least good to know, where the issue is. I can still align against the transgene in the genomic context and call the variants for this alignment and then do a separate alignment against the entire genome and call variants outside the transgene (if I need it). Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/892
https://github.com/google/deepvariant/issues/893:215,availability,down,downsampled,215,"Hi @sophienguyen01,. The correct way would be to add the parameter during the inference. That way examples are created with the correct height. The difference in accuracy can be explained by the fact that reads are downsampled to the `pileup_image_height` max coverage. There are probably locations where the coverage is larger than 75 and more reads get into the image. Although, model does not use those extra reads but since reads are sorted by position we may have more support in certain cases.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:381,energy efficiency,model,model,381,"Hi @sophienguyen01,. The correct way would be to add the parameter during the inference. That way examples are created with the correct height. The difference in accuracy can be explained by the fact that reads are downsampled to the `pileup_image_height` max coverage. There are probably locations where the coverage is larger than 75 and more reads get into the image. Although, model does not use those extra reads but since reads are sorted by position we may have more support in certain cases.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:57,modifiability,paramet,parameter,57,"Hi @sophienguyen01,. The correct way would be to add the parameter during the inference. That way examples are created with the correct height. The difference in accuracy can be explained by the fact that reads are downsampled to the `pileup_image_height` max coverage. There are probably locations where the coverage is larger than 75 and more reads get into the image. Although, model does not use those extra reads but since reads are sorted by position we may have more support in certain cases.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:387,reliability,doe,does,387,"Hi @sophienguyen01,. The correct way would be to add the parameter during the inference. That way examples are created with the correct height. The difference in accuracy can be explained by the fact that reads are downsampled to the `pileup_image_height` max coverage. There are probably locations where the coverage is larger than 75 and more reads get into the image. Although, model does not use those extra reads but since reads are sorted by position we may have more support in certain cases.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:381,security,model,model,381,"Hi @sophienguyen01,. The correct way would be to add the parameter during the inference. That way examples are created with the correct height. The difference in accuracy can be explained by the fact that reads are downsampled to the `pileup_image_height` max coverage. There are probably locations where the coverage is larger than 75 and more reads get into the image. Although, model does not use those extra reads but since reads are sorted by position we may have more support in certain cases.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:260,testability,coverag,coverage,260,"Hi @sophienguyen01,. The correct way would be to add the parameter during the inference. That way examples are created with the correct height. The difference in accuracy can be explained by the fact that reads are downsampled to the `pileup_image_height` max coverage. There are probably locations where the coverage is larger than 75 and more reads get into the image. Although, model does not use those extra reads but since reads are sorted by position we may have more support in certain cases.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:309,testability,coverag,coverage,309,"Hi @sophienguyen01,. The correct way would be to add the parameter during the inference. That way examples are created with the correct height. The difference in accuracy can be explained by the fact that reads are downsampled to the `pileup_image_height` max coverage. There are probably locations where the coverage is larger than 75 and more reads get into the image. Although, model does not use those extra reads but since reads are sorted by position we may have more support in certain cases.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:474,usability,support,support,474,"Hi @sophienguyen01,. The correct way would be to add the parameter during the inference. That way examples are created with the correct height. The difference in accuracy can be explained by the fact that reads are downsampled to the `pileup_image_height` max coverage. There are probably locations where the coverage is larger than 75 and more reads get into the image. Although, model does not use those extra reads but since reads are sorted by position we may have more support in certain cases.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:78,energy efficiency,model,model,78,"Thank you,. Because adding pileup_image_height is necessary using the trained model, do I need to add the same additional parameters when running DeepVariant for evaluation as when I do during creating examples for training DeepVariant (such as --min_base_quality, --min_mapping_quality...)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:122,modifiability,paramet,parameters,122,"Thank you,. Because adding pileup_image_height is necessary using the trained model, do I need to add the same additional parameters when running DeepVariant for evaluation as when I do during creating examples for training DeepVariant (such as --min_base_quality, --min_mapping_quality...)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:78,security,model,model,78,"Thank you,. Because adding pileup_image_height is necessary using the trained model, do I need to add the same additional parameters when running DeepVariant for evaluation as when I do during creating examples for training DeepVariant (such as --min_base_quality, --min_mapping_quality...)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:42,modifiability,paramet,parameters,42,"Yes, the best practice is to use the same parameters for evaluation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/893:14,reliability,pra,practice,14,"Yes, the best practice is to use the same parameters for evaluation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/893
https://github.com/google/deepvariant/issues/894:301,interoperability,specif,specific,301,"Hi,. You can provide a [--intermediate_results_dir](https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L117-L125) flag to `run_deepvariant`, which will save all the intermediate outputs (from make examples and call_variants). . If you are interested at looking at the PIL of specific examples, you can use the [show_examples](https://github.com/google/deepvariant/blob/r1.6.1/docs/show-examples.md) tool. If you are interested in increasing recall, you can adjust the various [vsc_*](https://github.com/google/deepvariant/blob/r1.6.1/deepvariant/make_examples_options.py#L284-L346) parameters to `make_examples`, which will either increase or decrease the number of candidates generated. . Hopefully that helps! .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:191,modifiability,interm,intermediate,191,"Hi,. You can provide a [--intermediate_results_dir](https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L117-L125) flag to `run_deepvariant`, which will save all the intermediate outputs (from make examples and call_variants). . If you are interested at looking at the PIL of specific examples, you can use the [show_examples](https://github.com/google/deepvariant/blob/r1.6.1/docs/show-examples.md) tool. If you are interested in increasing recall, you can adjust the various [vsc_*](https://github.com/google/deepvariant/blob/r1.6.1/deepvariant/make_examples_options.py#L284-L346) parameters to `make_examples`, which will either increase or decrease the number of candidates generated. . Hopefully that helps! .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:608,modifiability,paramet,parameters,608,"Hi,. You can provide a [--intermediate_results_dir](https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L117-L125) flag to `run_deepvariant`, which will save all the intermediate outputs (from make examples and call_variants). . If you are interested at looking at the PIL of specific examples, you can use the [show_examples](https://github.com/google/deepvariant/blob/r1.6.1/docs/show-examples.md) tool. If you are interested in increasing recall, you can adjust the various [vsc_*](https://github.com/google/deepvariant/blob/r1.6.1/deepvariant/make_examples_options.py#L284-L346) parameters to `make_examples`, which will either increase or decrease the number of candidates generated. . Hopefully that helps! .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:425,usability,tool,tool,425,"Hi,. You can provide a [--intermediate_results_dir](https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L117-L125) flag to `run_deepvariant`, which will save all the intermediate outputs (from make examples and call_variants). . If you are interested at looking at the PIL of specific examples, you can use the [show_examples](https://github.com/google/deepvariant/blob/r1.6.1/docs/show-examples.md) tool. If you are interested in increasing recall, you can adjust the various [vsc_*](https://github.com/google/deepvariant/blob/r1.6.1/deepvariant/make_examples_options.py#L284-L346) parameters to `make_examples`, which will either increase or decrease the number of candidates generated. . Hopefully that helps! .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:731,usability,help,helps,731,"Hi,. You can provide a [--intermediate_results_dir](https://github.com/google/deepvariant/blob/r1.6.1/scripts/run_deepvariant.py#L117-L125) flag to `run_deepvariant`, which will save all the intermediate outputs (from make examples and call_variants). . If you are interested at looking at the PIL of specific examples, you can use the [show_examples](https://github.com/google/deepvariant/blob/r1.6.1/docs/show-examples.md) tool. If you are interested in increasing recall, you can adjust the various [vsc_*](https://github.com/google/deepvariant/blob/r1.6.1/deepvariant/make_examples_options.py#L284-L346) parameters to `make_examples`, which will either increase or decrease the number of candidates generated. . Hopefully that helps! .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:152,energy efficiency,model,model,152,"Hi, I did look at some images at some locus using `show_examples` tool. Interestingly, the image of the locus is the same between default and retrained model but the variant interpretation is different. I did also use `vsc_*` parameter in `make_examples` when I trained my model. Here I attach an image from retrained examples at locus 11479054. From the image, I expect the variant to be heterozygous from retrained model classifies it as homozygous reference. I also extract the line of this locus from vcf here. . I appreciate if you guys have any ideas why the retrained model misinterpret variant like this. . Thank you . ![Image](https://github.com/user-attachments/assets/3e5274ec-ba47-47ed-8e63-b68debade582). default:. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. retrain:. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:273,energy efficiency,model,model,273,"Hi, I did look at some images at some locus using `show_examples` tool. Interestingly, the image of the locus is the same between default and retrained model but the variant interpretation is different. I did also use `vsc_*` parameter in `make_examples` when I trained my model. Here I attach an image from retrained examples at locus 11479054. From the image, I expect the variant to be heterozygous from retrained model classifies it as homozygous reference. I also extract the line of this locus from vcf here. . I appreciate if you guys have any ideas why the retrained model misinterpret variant like this. . Thank you . ![Image](https://github.com/user-attachments/assets/3e5274ec-ba47-47ed-8e63-b68debade582). default:. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. retrain:. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:417,energy efficiency,model,model,417,"Hi, I did look at some images at some locus using `show_examples` tool. Interestingly, the image of the locus is the same between default and retrained model but the variant interpretation is different. I did also use `vsc_*` parameter in `make_examples` when I trained my model. Here I attach an image from retrained examples at locus 11479054. From the image, I expect the variant to be heterozygous from retrained model classifies it as homozygous reference. I also extract the line of this locus from vcf here. . I appreciate if you guys have any ideas why the retrained model misinterpret variant like this. . Thank you . ![Image](https://github.com/user-attachments/assets/3e5274ec-ba47-47ed-8e63-b68debade582). default:. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. retrain:. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:575,energy efficiency,model,model,575,"Hi, I did look at some images at some locus using `show_examples` tool. Interestingly, the image of the locus is the same between default and retrained model but the variant interpretation is different. I did also use `vsc_*` parameter in `make_examples` when I trained my model. Here I attach an image from retrained examples at locus 11479054. From the image, I expect the variant to be heterozygous from retrained model classifies it as homozygous reference. I also extract the line of this locus from vcf here. . I appreciate if you guys have any ideas why the retrained model misinterpret variant like this. . Thank you . ![Image](https://github.com/user-attachments/assets/3e5274ec-ba47-47ed-8e63-b68debade582). default:. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. retrain:. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:226,modifiability,paramet,parameter,226,"Hi, I did look at some images at some locus using `show_examples` tool. Interestingly, the image of the locus is the same between default and retrained model but the variant interpretation is different. I did also use `vsc_*` parameter in `make_examples` when I trained my model. Here I attach an image from retrained examples at locus 11479054. From the image, I expect the variant to be heterozygous from retrained model classifies it as homozygous reference. I also extract the line of this locus from vcf here. . I appreciate if you guys have any ideas why the retrained model misinterpret variant like this. . Thank you . ![Image](https://github.com/user-attachments/assets/3e5274ec-ba47-47ed-8e63-b68debade582). default:. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. retrain:. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:152,security,model,model,152,"Hi, I did look at some images at some locus using `show_examples` tool. Interestingly, the image of the locus is the same between default and retrained model but the variant interpretation is different. I did also use `vsc_*` parameter in `make_examples` when I trained my model. Here I attach an image from retrained examples at locus 11479054. From the image, I expect the variant to be heterozygous from retrained model classifies it as homozygous reference. I also extract the line of this locus from vcf here. . I appreciate if you guys have any ideas why the retrained model misinterpret variant like this. . Thank you . ![Image](https://github.com/user-attachments/assets/3e5274ec-ba47-47ed-8e63-b68debade582). default:. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. retrain:. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:273,security,model,model,273,"Hi, I did look at some images at some locus using `show_examples` tool. Interestingly, the image of the locus is the same between default and retrained model but the variant interpretation is different. I did also use `vsc_*` parameter in `make_examples` when I trained my model. Here I attach an image from retrained examples at locus 11479054. From the image, I expect the variant to be heterozygous from retrained model classifies it as homozygous reference. I also extract the line of this locus from vcf here. . I appreciate if you guys have any ideas why the retrained model misinterpret variant like this. . Thank you . ![Image](https://github.com/user-attachments/assets/3e5274ec-ba47-47ed-8e63-b68debade582). default:. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. retrain:. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:417,security,model,model,417,"Hi, I did look at some images at some locus using `show_examples` tool. Interestingly, the image of the locus is the same between default and retrained model but the variant interpretation is different. I did also use `vsc_*` parameter in `make_examples` when I trained my model. Here I attach an image from retrained examples at locus 11479054. From the image, I expect the variant to be heterozygous from retrained model classifies it as homozygous reference. I also extract the line of this locus from vcf here. . I appreciate if you guys have any ideas why the retrained model misinterpret variant like this. . Thank you . ![Image](https://github.com/user-attachments/assets/3e5274ec-ba47-47ed-8e63-b68debade582). default:. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. retrain:. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:575,security,model,model,575,"Hi, I did look at some images at some locus using `show_examples` tool. Interestingly, the image of the locus is the same between default and retrained model but the variant interpretation is different. I did also use `vsc_*` parameter in `make_examples` when I trained my model. Here I attach an image from retrained examples at locus 11479054. From the image, I expect the variant to be heterozygous from retrained model classifies it as homozygous reference. I also extract the line of this locus from vcf here. . I appreciate if you guys have any ideas why the retrained model misinterpret variant like this. . Thank you . ![Image](https://github.com/user-attachments/assets/3e5274ec-ba47-47ed-8e63-b68debade582). default:. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. retrain:. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:66,usability,tool,tool,66,"Hi, I did look at some images at some locus using `show_examples` tool. Interestingly, the image of the locus is the same between default and retrained model but the variant interpretation is different. I did also use `vsc_*` parameter in `make_examples` when I trained my model. Here I attach an image from retrained examples at locus 11479054. From the image, I expect the variant to be heterozygous from retrained model classifies it as homozygous reference. I also extract the line of this locus from vcf here. . I appreciate if you guys have any ideas why the retrained model misinterpret variant like this. . Thank you . ![Image](https://github.com/user-attachments/assets/3e5274ec-ba47-47ed-8e63-b68debade582). default:. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. retrain:. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/894:655,usability,user,user-attachments,655,"Hi, I did look at some images at some locus using `show_examples` tool. Interestingly, the image of the locus is the same between default and retrained model but the variant interpretation is different. I did also use `vsc_*` parameter in `make_examples` when I trained my model. Here I attach an image from retrained examples at locus 11479054. From the image, I expect the variant to be heterozygous from retrained model classifies it as homozygous reference. I also extract the line of this locus from vcf here. . I appreciate if you guys have any ideas why the retrained model misinterpret variant like this. . Thank you . ![Image](https://github.com/user-attachments/assets/3e5274ec-ba47-47ed-8e63-b68debade582). default:. chr20 11479054 . A G 56.6 PASS . GT:GQ:DP:AD:VAF:PL 1/1:53:29:0,29:1:56,55,0. retrain:. chr20 11479054 . A G 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:36:29:0,29:1:0,47,36",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/894
https://github.com/google/deepvariant/issues/895:86,energy efficiency,model,models,86,"Hi @westonelison ,. Thank you for the question. We have experimented with single cell models, but not with ATAC seq specifically. I think the most similar model should be the RNAseq model. I don't have an instinct for how this might perform.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/895
https://github.com/google/deepvariant/issues/895:155,energy efficiency,model,model,155,"Hi @westonelison ,. Thank you for the question. We have experimented with single cell models, but not with ATAC seq specifically. I think the most similar model should be the RNAseq model. I don't have an instinct for how this might perform.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/895
https://github.com/google/deepvariant/issues/895:182,energy efficiency,model,model,182,"Hi @westonelison ,. Thank you for the question. We have experimented with single cell models, but not with ATAC seq specifically. I think the most similar model should be the RNAseq model. I don't have an instinct for how this might perform.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/895
https://github.com/google/deepvariant/issues/895:116,interoperability,specif,specifically,116,"Hi @westonelison ,. Thank you for the question. We have experimented with single cell models, but not with ATAC seq specifically. I think the most similar model should be the RNAseq model. I don't have an instinct for how this might perform.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/895
https://github.com/google/deepvariant/issues/895:233,performance,perform,perform,233,"Hi @westonelison ,. Thank you for the question. We have experimented with single cell models, but not with ATAC seq specifically. I think the most similar model should be the RNAseq model. I don't have an instinct for how this might perform.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/895
https://github.com/google/deepvariant/issues/895:86,security,model,models,86,"Hi @westonelison ,. Thank you for the question. We have experimented with single cell models, but not with ATAC seq specifically. I think the most similar model should be the RNAseq model. I don't have an instinct for how this might perform.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/895
https://github.com/google/deepvariant/issues/895:155,security,model,model,155,"Hi @westonelison ,. Thank you for the question. We have experimented with single cell models, but not with ATAC seq specifically. I think the most similar model should be the RNAseq model. I don't have an instinct for how this might perform.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/895
https://github.com/google/deepvariant/issues/895:182,security,model,model,182,"Hi @westonelison ,. Thank you for the question. We have experimented with single cell models, but not with ATAC seq specifically. I think the most similar model should be the RNAseq model. I don't have an instinct for how this might perform.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/895
https://github.com/google/deepvariant/issues/895:233,usability,perform,perform,233,"Hi @westonelison ,. Thank you for the question. We have experimented with single cell models, but not with ATAC seq specifically. I think the most similar model should be the RNAseq model. I don't have an instinct for how this might perform.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/895
https://github.com/google/deepvariant/issues/896:155,interoperability,share,share,155,"Great question, always happy to help! Setting `keep_supplementary_alignments=true` shouldn't dramatically change the accuracy. . Is it possible for you to share the BAM and VCF/truth set used? One possibility is that the truth set doesn't match HG003. For example if you run happy for HG003 using HG002 truth set the accuracy would be around 0.4.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/896
https://github.com/google/deepvariant/issues/896:231,reliability,doe,doesn,231,"Great question, always happy to help! Setting `keep_supplementary_alignments=true` shouldn't dramatically change the accuracy. . Is it possible for you to share the BAM and VCF/truth set used? One possibility is that the truth set doesn't match HG003. For example if you run happy for HG003 using HG002 truth set the accuracy would be around 0.4.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/896
https://github.com/google/deepvariant/issues/896:32,usability,help,help,32,"Great question, always happy to help! Setting `keep_supplementary_alignments=true` shouldn't dramatically change the accuracy. . Is it possible for you to share the BAM and VCF/truth set used? One possibility is that the truth set doesn't match HG003. For example if you run happy for HG003 using HG002 truth set the accuracy would be around 0.4.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/896
https://github.com/google/deepvariant/issues/896:58,energy efficiency,current,currently,58,"Hi Lucas and John,. Thank you so much for your input. Im currently trying to figure out whats happening with different references..! Kind regards,. Alisa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/896
https://github.com/google/deepvariant/issues/896:47,safety,input,input,47,"Hi Lucas and John,. Thank you so much for your input. Im currently trying to figure out whats happening with different references..! Kind regards,. Alisa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/896
https://github.com/google/deepvariant/issues/896:47,usability,input,input,47,"Hi Lucas and John,. Thank you so much for your input. Im currently trying to figure out whats happening with different references..! Kind regards,. Alisa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/896
https://github.com/google/deepvariant/issues/897:24,deployability,updat,updated,24,"Thank you, this will be updated in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/897
https://github.com/google/deepvariant/issues/897:44,deployability,releas,release,44,"Thank you, this will be updated in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/897
https://github.com/google/deepvariant/issues/897:24,safety,updat,updated,24,"Thank you, this will be updated in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/897
https://github.com/google/deepvariant/issues/897:24,security,updat,updated,24,"Thank you, this will be updated in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/897
https://github.com/google/deepvariant/issues/898:428,energy efficiency,model,models,428,"Hi Zuyao,. You can certainly create a training set using illumina data by having blocks where variant calls that you are confident about and train on that. Although not a cross-technology training has been demonstrated here, but you can take some ideas on how to construct the truth from this blog post: https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/898
https://github.com/google/deepvariant/issues/898:407,interoperability,specif,specific-deepvariant-models,407,"Hi Zuyao,. You can certainly create a training set using illumina data by having blocks where variant calls that you are confident about and train on that. Although not a cross-technology training has been demonstrated here, but you can take some ideas on how to construct the truth from this blog post: https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/898
https://github.com/google/deepvariant/issues/898:428,security,model,models,428,"Hi Zuyao,. You can certainly create a training set using illumina data by having blocks where variant calls that you are confident about and train on that. Although not a cross-technology training has been demonstrated here, but you can take some ideas on how to construct the truth from this blog post: https://google.github.io/deepvariant/posts/2018-12-05-improved-non-human-variant-calling-using-species-specific-deepvariant-models/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/898
https://github.com/google/deepvariant/issues/900:17,safety,test,tested,17,"Hi,. We have not tested DeepVariant's accuracy in paralogous regions outside of the GIAB high-confidence regions. Both of your solution can potentially improve the accuracy. The only suggestion we can give you is to look at the pangenome mapping + DeepVariant case-study here: https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-vg-case-study.md where dropping mapq=0 might give you better resolution in the paralogous regions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/900
https://github.com/google/deepvariant/issues/900:17,testability,test,tested,17,"Hi,. We have not tested DeepVariant's accuracy in paralogous regions outside of the GIAB high-confidence regions. Both of your solution can potentially improve the accuracy. The only suggestion we can give you is to look at the pangenome mapping + DeepVariant case-study here: https://github.com/google/deepvariant/blob/r1.6.1/docs/deepvariant-vg-case-study.md where dropping mapq=0 might give you better resolution in the paralogous regions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/900
https://github.com/google/deepvariant/issues/901:39,usability,command,command,39,@sushruta can you please post the full command you are running?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:124,safety,test,testdata,124,"Here's the full command --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz \. --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz \. --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir \. --num_shards=1 --verbosity=2. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:203,safety,test,testdata,203,"Here's the full command --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz \. --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz \. --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir \. --num_shards=1 --verbosity=2. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:124,testability,test,testdata,124,"Here's the full command --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz \. --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz \. --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir \. --num_shards=1 --verbosity=2. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:149,testability,unit,unittest,149,"Here's the full command --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz \. --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz \. --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir \. --num_shards=1 --verbosity=2. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:203,testability,test,testdata,203,"Here's the full command --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz \. --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz \. --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir \. --num_shards=1 --verbosity=2. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/901:16,usability,command,command,16,"Here's the full command --. ```. /opt/deepvariant/bin/run_deepvariant --model_type=WGS \. --ref=/opt/deepvariant/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta \. --reads=/opt/deepvariant/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/opt/deepvariant/quickstart-output/output.vcf.gz \. --output_gvcf=/opt/deepvariant/quickstart-output/output.g.vcf.gz \. --intermediate_results_dir /opt/deepvariant/quickstart-output/intermediate_results_dir \. --num_shards=1 --verbosity=2. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/901
https://github.com/google/deepvariant/issues/902:14,availability,error,error,14,"@sushruta the error mainly is here:. ```bash. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Did you clone the entire repository correctly? Also, what OS you are trying to build this on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:46,availability,ERROR,ERROR,46,"@sushruta the error mainly is here:. ```bash. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Did you clone the entire repository correctly? Also, what OS you are trying to build this on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:53,deployability,fail,failed,53,"@sushruta the error mainly is here:. ```bash. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Did you clone the entire repository correctly? Also, what OS you are trying to build this on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:92,deployability,build,build-prereq,92,"@sushruta the error mainly is here:. ```bash. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Did you clone the entire repository correctly? Also, what OS you are trying to build this on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:317,deployability,build,build,317,"@sushruta the error mainly is here:. ```bash. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Did you clone the entire repository correctly? Also, what OS you are trying to build this on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:263,integrability,repositor,repository,263,"@sushruta the error mainly is here:. ```bash. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Did you clone the entire repository correctly? Also, what OS you are trying to build this on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:263,interoperability,repositor,repository,263,"@sushruta the error mainly is here:. ```bash. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Did you clone the entire repository correctly? Also, what OS you are trying to build this on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:14,performance,error,error,14,"@sushruta the error mainly is here:. ```bash. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Did you clone the entire repository correctly? Also, what OS you are trying to build this on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:46,performance,ERROR,ERROR,46,"@sushruta the error mainly is here:. ```bash. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Did you clone the entire repository correctly? Also, what OS you are trying to build this on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:53,reliability,fail,failed,53,"@sushruta the error mainly is here:. ```bash. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Did you clone the entire repository correctly? Also, what OS you are trying to build this on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:14,safety,error,error,14,"@sushruta the error mainly is here:. ```bash. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Did you clone the entire repository correctly? Also, what OS you are trying to build this on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:46,safety,ERROR,ERROR,46,"@sushruta the error mainly is here:. ```bash. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Did you clone the entire repository correctly? Also, what OS you are trying to build this on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:194,safety,compl,complete,194,"@sushruta the error mainly is here:. ```bash. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Did you clone the entire repository correctly? Also, what OS you are trying to build this on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:194,security,compl,complete,194,"@sushruta the error mainly is here:. ```bash. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Did you clone the entire repository correctly? Also, what OS you are trying to build this on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:14,usability,error,error,14,"@sushruta the error mainly is here:. ```bash. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Did you clone the entire repository correctly? Also, what OS you are trying to build this on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/902:46,usability,ERROR,ERROR,46,"@sushruta the error mainly is here:. ```bash. ERROR: failed to solve: process ""/bin/sh -c ./build-prereq.sh && PATH=\""${HOME}/bin:${PATH}\"" ./build_release_binaries.sh # PATH for bazel"" did not complete successfully: exit code: 100. ```. Did you clone the entire repository correctly? Also, what OS you are trying to build this on?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/902
https://github.com/google/deepvariant/issues/903:153,interoperability,standard,standard-,153,Please see https://github.com/google/deepvariant/blob/r1.6.1/docs/metrics.md page for details on expected runtime. The runtimes reported here are on `n2-standard-64` GCP instances with 64 vCPUs.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/903
https://github.com/google/deepvariant/issues/904:74,energy efficiency,model,model,74,"Hi @DanJeffries , two questions for you:. **1. Have you already trained a model to the end, and completed a variant calling + hap.py evaluation?**. At the end of the day, you'll want to know the variant calling accuracy against a metrics that makes most sense to you. If your truth VCF and confident regions is high quality, I'd suggest directly using hap.py to evaluate. Or, if you want to use other metrics such as Mendelian violation rate as a check, that might be a good idea too. The class0 (hom_ref) formulation is internal to DeepVariant, and might not be the best way to tell how the training has been. **2. How good is your truth set and confident regions?**. One possibility is: In your confident regions, if there are many real variants where you don't have in your truth VCF, this might cause DeepVariant to call them as variants, but then could contribute to lower ""recall"" of homrefs. If you know your truth VCF and confident regions is high quality, then this should not be the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:96,safety,compl,completed,96,"Hi @DanJeffries , two questions for you:. **1. Have you already trained a model to the end, and completed a variant calling + hap.py evaluation?**. At the end of the day, you'll want to know the variant calling accuracy against a metrics that makes most sense to you. If your truth VCF and confident regions is high quality, I'd suggest directly using hap.py to evaluate. Or, if you want to use other metrics such as Mendelian violation rate as a check, that might be a good idea too. The class0 (hom_ref) formulation is internal to DeepVariant, and might not be the best way to tell how the training has been. **2. How good is your truth set and confident regions?**. One possibility is: In your confident regions, if there are many real variants where you don't have in your truth VCF, this might cause DeepVariant to call them as variants, but then could contribute to lower ""recall"" of homrefs. If you know your truth VCF and confident regions is high quality, then this should not be the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:74,security,model,model,74,"Hi @DanJeffries , two questions for you:. **1. Have you already trained a model to the end, and completed a variant calling + hap.py evaluation?**. At the end of the day, you'll want to know the variant calling accuracy against a metrics that makes most sense to you. If your truth VCF and confident regions is high quality, I'd suggest directly using hap.py to evaluate. Or, if you want to use other metrics such as Mendelian violation rate as a check, that might be a good idea too. The class0 (hom_ref) formulation is internal to DeepVariant, and might not be the best way to tell how the training has been. **2. How good is your truth set and confident regions?**. One possibility is: In your confident regions, if there are many real variants where you don't have in your truth VCF, this might cause DeepVariant to call them as variants, but then could contribute to lower ""recall"" of homrefs. If you know your truth VCF and confident regions is high quality, then this should not be the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:96,security,compl,completed,96,"Hi @DanJeffries , two questions for you:. **1. Have you already trained a model to the end, and completed a variant calling + hap.py evaluation?**. At the end of the day, you'll want to know the variant calling accuracy against a metrics that makes most sense to you. If your truth VCF and confident regions is high quality, I'd suggest directly using hap.py to evaluate. Or, if you want to use other metrics such as Mendelian violation rate as a check, that might be a good idea too. The class0 (hom_ref) formulation is internal to DeepVariant, and might not be the best way to tell how the training has been. **2. How good is your truth set and confident regions?**. One possibility is: In your confident regions, if there are many real variants where you don't have in your truth VCF, this might cause DeepVariant to call them as variants, but then could contribute to lower ""recall"" of homrefs. If you know your truth VCF and confident regions is high quality, then this should not be the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:165,energy efficiency,model,models,165,"Hi @pichuan ,. Thanks for the quick response! Regarding your questions:. 1. I have completed training and run some test calls, though this was just to make sure the models were vaguely sensible, I ran hap.py but didn't spend too much time evaluating the results because I am not yet finished optimising the training. But I take your point that real-world metrics will be more useful than the internal stats. . 2. As we are not working in a model organism, our truth set is unlikely to be of the same quality of, say, humans. Though my hope is that it is good enough. We defined confident regions and truth variants via some relatively strict alignment quality filters plus mendelian segregation patterns (the training data are from 5 trios). But no further validation, so I certainly think it is possible that there are real variants in the confident regions that are not in the truth VCF. I can see how this would lower hom_ref recall so I will explore this and see how many might be there. . I'll post back here once I have explored these points further. . Thanks! Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:292,energy efficiency,optim,optimising,292,"Hi @pichuan ,. Thanks for the quick response! Regarding your questions:. 1. I have completed training and run some test calls, though this was just to make sure the models were vaguely sensible, I ran hap.py but didn't spend too much time evaluating the results because I am not yet finished optimising the training. But I take your point that real-world metrics will be more useful than the internal stats. . 2. As we are not working in a model organism, our truth set is unlikely to be of the same quality of, say, humans. Though my hope is that it is good enough. We defined confident regions and truth variants via some relatively strict alignment quality filters plus mendelian segregation patterns (the training data are from 5 trios). But no further validation, so I certainly think it is possible that there are real variants in the confident regions that are not in the truth VCF. I can see how this would lower hom_ref recall so I will explore this and see how many might be there. . I'll post back here once I have explored these points further. . Thanks! Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:440,energy efficiency,model,model,440,"Hi @pichuan ,. Thanks for the quick response! Regarding your questions:. 1. I have completed training and run some test calls, though this was just to make sure the models were vaguely sensible, I ran hap.py but didn't spend too much time evaluating the results because I am not yet finished optimising the training. But I take your point that real-world metrics will be more useful than the internal stats. . 2. As we are not working in a model organism, our truth set is unlikely to be of the same quality of, say, humans. Though my hope is that it is good enough. We defined confident regions and truth variants via some relatively strict alignment quality filters plus mendelian segregation patterns (the training data are from 5 trios). But no further validation, so I certainly think it is possible that there are real variants in the confident regions that are not in the truth VCF. I can see how this would lower hom_ref recall so I will explore this and see how many might be there. . I'll post back here once I have explored these points further. . Thanks! Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:660,integrability,filter,filters,660,"Hi @pichuan ,. Thanks for the quick response! Regarding your questions:. 1. I have completed training and run some test calls, though this was just to make sure the models were vaguely sensible, I ran hap.py but didn't spend too much time evaluating the results because I am not yet finished optimising the training. But I take your point that real-world metrics will be more useful than the internal stats. . 2. As we are not working in a model organism, our truth set is unlikely to be of the same quality of, say, humans. Though my hope is that it is good enough. We defined confident regions and truth variants via some relatively strict alignment quality filters plus mendelian segregation patterns (the training data are from 5 trios). But no further validation, so I certainly think it is possible that there are real variants in the confident regions that are not in the truth VCF. I can see how this would lower hom_ref recall so I will explore this and see how many might be there. . I'll post back here once I have explored these points further. . Thanks! Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:234,performance,time,time,234,"Hi @pichuan ,. Thanks for the quick response! Regarding your questions:. 1. I have completed training and run some test calls, though this was just to make sure the models were vaguely sensible, I ran hap.py but didn't spend too much time evaluating the results because I am not yet finished optimising the training. But I take your point that real-world metrics will be more useful than the internal stats. . 2. As we are not working in a model organism, our truth set is unlikely to be of the same quality of, say, humans. Though my hope is that it is good enough. We defined confident regions and truth variants via some relatively strict alignment quality filters plus mendelian segregation patterns (the training data are from 5 trios). But no further validation, so I certainly think it is possible that there are real variants in the confident regions that are not in the truth VCF. I can see how this would lower hom_ref recall so I will explore this and see how many might be there. . I'll post back here once I have explored these points further. . Thanks! Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:83,safety,compl,completed,83,"Hi @pichuan ,. Thanks for the quick response! Regarding your questions:. 1. I have completed training and run some test calls, though this was just to make sure the models were vaguely sensible, I ran hap.py but didn't spend too much time evaluating the results because I am not yet finished optimising the training. But I take your point that real-world metrics will be more useful than the internal stats. . 2. As we are not working in a model organism, our truth set is unlikely to be of the same quality of, say, humans. Though my hope is that it is good enough. We defined confident regions and truth variants via some relatively strict alignment quality filters plus mendelian segregation patterns (the training data are from 5 trios). But no further validation, so I certainly think it is possible that there are real variants in the confident regions that are not in the truth VCF. I can see how this would lower hom_ref recall so I will explore this and see how many might be there. . I'll post back here once I have explored these points further. . Thanks! Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:115,safety,test,test,115,"Hi @pichuan ,. Thanks for the quick response! Regarding your questions:. 1. I have completed training and run some test calls, though this was just to make sure the models were vaguely sensible, I ran hap.py but didn't spend too much time evaluating the results because I am not yet finished optimising the training. But I take your point that real-world metrics will be more useful than the internal stats. . 2. As we are not working in a model organism, our truth set is unlikely to be of the same quality of, say, humans. Though my hope is that it is good enough. We defined confident regions and truth variants via some relatively strict alignment quality filters plus mendelian segregation patterns (the training data are from 5 trios). But no further validation, so I certainly think it is possible that there are real variants in the confident regions that are not in the truth VCF. I can see how this would lower hom_ref recall so I will explore this and see how many might be there. . I'll post back here once I have explored these points further. . Thanks! Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:757,safety,valid,validation,757,"Hi @pichuan ,. Thanks for the quick response! Regarding your questions:. 1. I have completed training and run some test calls, though this was just to make sure the models were vaguely sensible, I ran hap.py but didn't spend too much time evaluating the results because I am not yet finished optimising the training. But I take your point that real-world metrics will be more useful than the internal stats. . 2. As we are not working in a model organism, our truth set is unlikely to be of the same quality of, say, humans. Though my hope is that it is good enough. We defined confident regions and truth variants via some relatively strict alignment quality filters plus mendelian segregation patterns (the training data are from 5 trios). But no further validation, so I certainly think it is possible that there are real variants in the confident regions that are not in the truth VCF. I can see how this would lower hom_ref recall so I will explore this and see how many might be there. . I'll post back here once I have explored these points further. . Thanks! Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:83,security,compl,completed,83,"Hi @pichuan ,. Thanks for the quick response! Regarding your questions:. 1. I have completed training and run some test calls, though this was just to make sure the models were vaguely sensible, I ran hap.py but didn't spend too much time evaluating the results because I am not yet finished optimising the training. But I take your point that real-world metrics will be more useful than the internal stats. . 2. As we are not working in a model organism, our truth set is unlikely to be of the same quality of, say, humans. Though my hope is that it is good enough. We defined confident regions and truth variants via some relatively strict alignment quality filters plus mendelian segregation patterns (the training data are from 5 trios). But no further validation, so I certainly think it is possible that there are real variants in the confident regions that are not in the truth VCF. I can see how this would lower hom_ref recall so I will explore this and see how many might be there. . I'll post back here once I have explored these points further. . Thanks! Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:165,security,model,models,165,"Hi @pichuan ,. Thanks for the quick response! Regarding your questions:. 1. I have completed training and run some test calls, though this was just to make sure the models were vaguely sensible, I ran hap.py but didn't spend too much time evaluating the results because I am not yet finished optimising the training. But I take your point that real-world metrics will be more useful than the internal stats. . 2. As we are not working in a model organism, our truth set is unlikely to be of the same quality of, say, humans. Though my hope is that it is good enough. We defined confident regions and truth variants via some relatively strict alignment quality filters plus mendelian segregation patterns (the training data are from 5 trios). But no further validation, so I certainly think it is possible that there are real variants in the confident regions that are not in the truth VCF. I can see how this would lower hom_ref recall so I will explore this and see how many might be there. . I'll post back here once I have explored these points further. . Thanks! Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:440,security,model,model,440,"Hi @pichuan ,. Thanks for the quick response! Regarding your questions:. 1. I have completed training and run some test calls, though this was just to make sure the models were vaguely sensible, I ran hap.py but didn't spend too much time evaluating the results because I am not yet finished optimising the training. But I take your point that real-world metrics will be more useful than the internal stats. . 2. As we are not working in a model organism, our truth set is unlikely to be of the same quality of, say, humans. Though my hope is that it is good enough. We defined confident regions and truth variants via some relatively strict alignment quality filters plus mendelian segregation patterns (the training data are from 5 trios). But no further validation, so I certainly think it is possible that there are real variants in the confident regions that are not in the truth VCF. I can see how this would lower hom_ref recall so I will explore this and see how many might be there. . I'll post back here once I have explored these points further. . Thanks! Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:757,security,validat,validation,757,"Hi @pichuan ,. Thanks for the quick response! Regarding your questions:. 1. I have completed training and run some test calls, though this was just to make sure the models were vaguely sensible, I ran hap.py but didn't spend too much time evaluating the results because I am not yet finished optimising the training. But I take your point that real-world metrics will be more useful than the internal stats. . 2. As we are not working in a model organism, our truth set is unlikely to be of the same quality of, say, humans. Though my hope is that it is good enough. We defined confident regions and truth variants via some relatively strict alignment quality filters plus mendelian segregation patterns (the training data are from 5 trios). But no further validation, so I certainly think it is possible that there are real variants in the confident regions that are not in the truth VCF. I can see how this would lower hom_ref recall so I will explore this and see how many might be there. . I'll post back here once I have explored these points further. . Thanks! Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/904:115,testability,test,test,115,"Hi @pichuan ,. Thanks for the quick response! Regarding your questions:. 1. I have completed training and run some test calls, though this was just to make sure the models were vaguely sensible, I ran hap.py but didn't spend too much time evaluating the results because I am not yet finished optimising the training. But I take your point that real-world metrics will be more useful than the internal stats. . 2. As we are not working in a model organism, our truth set is unlikely to be of the same quality of, say, humans. Though my hope is that it is good enough. We defined confident regions and truth variants via some relatively strict alignment quality filters plus mendelian segregation patterns (the training data are from 5 trios). But no further validation, so I certainly think it is possible that there are real variants in the confident regions that are not in the truth VCF. I can see how this would lower hom_ref recall so I will explore this and see how many might be there. . I'll post back here once I have explored these points further. . Thanks! Dan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/904
https://github.com/google/deepvariant/issues/905:39,deployability,stage,stages,39,"Hi @CanWood , DeepVariant has multiple stages, as you observed. If you ran with the `--dry_run=true` flag, the command above will instead just printing out the commands for each of the stages. (We mentioned this in the https://github.com/google/deepvariant?tab=readme-ov-file#how-to-run-deepvariant section). That way, you can adjust how to you want to run each of the stages. You could even run them on different machines if you like.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:54,deployability,observ,observed,54,"Hi @CanWood , DeepVariant has multiple stages, as you observed. If you ran with the `--dry_run=true` flag, the command above will instead just printing out the commands for each of the stages. (We mentioned this in the https://github.com/google/deepvariant?tab=readme-ov-file#how-to-run-deepvariant section). That way, you can adjust how to you want to run each of the stages. You could even run them on different machines if you like.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:185,deployability,stage,stages,185,"Hi @CanWood , DeepVariant has multiple stages, as you observed. If you ran with the `--dry_run=true` flag, the command above will instead just printing out the commands for each of the stages. (We mentioned this in the https://github.com/google/deepvariant?tab=readme-ov-file#how-to-run-deepvariant section). That way, you can adjust how to you want to run each of the stages. You could even run them on different machines if you like.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:369,deployability,stage,stages,369,"Hi @CanWood , DeepVariant has multiple stages, as you observed. If you ran with the `--dry_run=true` flag, the command above will instead just printing out the commands for each of the stages. (We mentioned this in the https://github.com/google/deepvariant?tab=readme-ov-file#how-to-run-deepvariant section). That way, you can adjust how to you want to run each of the stages. You could even run them on different machines if you like.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:54,testability,observ,observed,54,"Hi @CanWood , DeepVariant has multiple stages, as you observed. If you ran with the `--dry_run=true` flag, the command above will instead just printing out the commands for each of the stages. (We mentioned this in the https://github.com/google/deepvariant?tab=readme-ov-file#how-to-run-deepvariant section). That way, you can adjust how to you want to run each of the stages. You could even run them on different machines if you like.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:111,usability,command,command,111,"Hi @CanWood , DeepVariant has multiple stages, as you observed. If you ran with the `--dry_run=true` flag, the command above will instead just printing out the commands for each of the stages. (We mentioned this in the https://github.com/google/deepvariant?tab=readme-ov-file#how-to-run-deepvariant section). That way, you can adjust how to you want to run each of the stages. You could even run them on different machines if you like.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:160,usability,command,commands,160,"Hi @CanWood , DeepVariant has multiple stages, as you observed. If you ran with the `--dry_run=true` flag, the command above will instead just printing out the commands for each of the stages. (We mentioned this in the https://github.com/google/deepvariant?tab=readme-ov-file#how-to-run-deepvariant section). That way, you can adjust how to you want to run each of the stages. You could even run them on different machines if you like.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
https://github.com/google/deepvariant/issues/905:38,usability,user,users,38,"Thank you, @pichuan . I'll direct the users to your response. . Cheers",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/905
