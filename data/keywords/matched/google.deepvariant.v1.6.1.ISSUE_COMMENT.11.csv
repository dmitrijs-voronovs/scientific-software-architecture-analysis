id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/google/deepvariant/issues/214:8,deployability,releas,released,8,We just released a new docker image located at `gcr.io/cloud-lifesciences/gcp-deepvariant-runner`. Please let us know if you still observe gcsfuse issue using the latest release.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:131,deployability,observ,observe,131,We just released a new docker image located at `gcr.io/cloud-lifesciences/gcp-deepvariant-runner`. Please let us know if you still observe gcsfuse issue using the latest release.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:170,deployability,releas,release,170,We just released a new docker image located at `gcr.io/cloud-lifesciences/gcp-deepvariant-runner`. Please let us know if you still observe gcsfuse issue using the latest release.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:55,energy efficiency,cloud,cloud-lifesciences,55,We just released a new docker image located at `gcr.io/cloud-lifesciences/gcp-deepvariant-runner`. Please let us know if you still observe gcsfuse issue using the latest release.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/issues/214:131,testability,observ,observe,131,We just released a new docker image located at `gcr.io/cloud-lifesciences/gcp-deepvariant-runner`. Please let us know if you still observe gcsfuse issue using the latest release.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/214
https://github.com/google/deepvariant/pull/215:38,safety,review,review,38,"Wow, that's a huge amount of files to review!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/215
https://github.com/google/deepvariant/pull/215:38,testability,review,review,38,"Wow, that's a huge amount of files to review!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/215
https://github.com/google/deepvariant/issues/217:239,deployability,stack,stackoverflow,239,"Hi Hamid,. **Short answer**: There is no pre-built docker that would work on an old hardware (with no AVX support). **Long answer**: It may be possible to run DeepVariant with custom TensorFlow library (this is what I found online https://stackoverflow.com/questions/53723217/is-there-a-version-of-tensorflow-not-compiled-for-avx-instructions). Then you may follow directions [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-build-test.md) to manually build DeepVariant and then follow instructions to run DeepVariant without docker [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md). To use custom version of TensorFlow you would need to modify ./run-prereq.sh. Unfortunately there is no guaranty this will work. . Another option is to try running DeepVariant Quick Study on Google Cloud Platform. It is fairly straight forward to set up a project and start creating virtual machines on Google Cloud. You may start from [here](https://cloud.google.com/compute/docs/instances/create-start-instance).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:287,deployability,version,version-of-tensorflow-not-compiled-for-avx-instructions,287,"Hi Hamid,. **Short answer**: There is no pre-built docker that would work on an old hardware (with no AVX support). **Long answer**: It may be possible to run DeepVariant with custom TensorFlow library (this is what I found online https://stackoverflow.com/questions/53723217/is-there-a-version-of-tensorflow-not-compiled-for-avx-instructions). Then you may follow directions [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-build-test.md) to manually build DeepVariant and then follow instructions to run DeepVariant without docker [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md). To use custom version of TensorFlow you would need to modify ./run-prereq.sh. Unfortunately there is no guaranty this will work. . Another option is to try running DeepVariant Quick Study on Google Cloud Platform. It is fairly straight forward to set up a project and start creating virtual machines on Google Cloud. You may start from [here](https://cloud.google.com/compute/docs/instances/create-start-instance).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:448,deployability,build,build-test,448,"Hi Hamid,. **Short answer**: There is no pre-built docker that would work on an old hardware (with no AVX support). **Long answer**: It may be possible to run DeepVariant with custom TensorFlow library (this is what I found online https://stackoverflow.com/questions/53723217/is-there-a-version-of-tensorflow-not-compiled-for-avx-instructions). Then you may follow directions [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-build-test.md) to manually build DeepVariant and then follow instructions to run DeepVariant without docker [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md). To use custom version of TensorFlow you would need to modify ./run-prereq.sh. Unfortunately there is no guaranty this will work. . Another option is to try running DeepVariant Quick Study on Google Cloud Platform. It is fairly straight forward to set up a project and start creating virtual machines on Google Cloud. You may start from [here](https://cloud.google.com/compute/docs/instances/create-start-instance).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:475,deployability,build,build,475,"Hi Hamid,. **Short answer**: There is no pre-built docker that would work on an old hardware (with no AVX support). **Long answer**: It may be possible to run DeepVariant with custom TensorFlow library (this is what I found online https://stackoverflow.com/questions/53723217/is-there-a-version-of-tensorflow-not-compiled-for-avx-instructions). Then you may follow directions [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-build-test.md) to manually build DeepVariant and then follow instructions to run DeepVariant without docker [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md). To use custom version of TensorFlow you would need to modify ./run-prereq.sh. Unfortunately there is no guaranty this will work. . Another option is to try running DeepVariant Quick Study on Google Cloud Platform. It is fairly straight forward to set up a project and start creating virtual machines on Google Cloud. You may start from [here](https://cloud.google.com/compute/docs/instances/create-start-instance).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:659,deployability,version,version,659,"Hi Hamid,. **Short answer**: There is no pre-built docker that would work on an old hardware (with no AVX support). **Long answer**: It may be possible to run DeepVariant with custom TensorFlow library (this is what I found online https://stackoverflow.com/questions/53723217/is-there-a-version-of-tensorflow-not-compiled-for-avx-instructions). Then you may follow directions [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-build-test.md) to manually build DeepVariant and then follow instructions to run DeepVariant without docker [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md). To use custom version of TensorFlow you would need to modify ./run-prereq.sh. Unfortunately there is no guaranty this will work. . Another option is to try running DeepVariant Quick Study on Google Cloud Platform. It is fairly straight forward to set up a project and start creating virtual machines on Google Cloud. You may start from [here](https://cloud.google.com/compute/docs/instances/create-start-instance).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:843,energy efficiency,Cloud,Cloud,843,"Hi Hamid,. **Short answer**: There is no pre-built docker that would work on an old hardware (with no AVX support). **Long answer**: It may be possible to run DeepVariant with custom TensorFlow library (this is what I found online https://stackoverflow.com/questions/53723217/is-there-a-version-of-tensorflow-not-compiled-for-avx-instructions). Then you may follow directions [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-build-test.md) to manually build DeepVariant and then follow instructions to run DeepVariant without docker [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md). To use custom version of TensorFlow you would need to modify ./run-prereq.sh. Unfortunately there is no guaranty this will work. . Another option is to try running DeepVariant Quick Study on Google Cloud Platform. It is fairly straight forward to set up a project and start creating virtual machines on Google Cloud. You may start from [here](https://cloud.google.com/compute/docs/instances/create-start-instance).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:955,energy efficiency,Cloud,Cloud,955,"Hi Hamid,. **Short answer**: There is no pre-built docker that would work on an old hardware (with no AVX support). **Long answer**: It may be possible to run DeepVariant with custom TensorFlow library (this is what I found online https://stackoverflow.com/questions/53723217/is-there-a-version-of-tensorflow-not-compiled-for-avx-instructions). Then you may follow directions [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-build-test.md) to manually build DeepVariant and then follow instructions to run DeepVariant without docker [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md). To use custom version of TensorFlow you would need to modify ./run-prereq.sh. Unfortunately there is no guaranty this will work. . Another option is to try running DeepVariant Quick Study on Google Cloud Platform. It is fairly straight forward to set up a project and start creating virtual machines on Google Cloud. You may start from [here](https://cloud.google.com/compute/docs/instances/create-start-instance).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:996,energy efficiency,cloud,cloud,996,"Hi Hamid,. **Short answer**: There is no pre-built docker that would work on an old hardware (with no AVX support). **Long answer**: It may be possible to run DeepVariant with custom TensorFlow library (this is what I found online https://stackoverflow.com/questions/53723217/is-there-a-version-of-tensorflow-not-compiled-for-avx-instructions). Then you may follow directions [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-build-test.md) to manually build DeepVariant and then follow instructions to run DeepVariant without docker [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md). To use custom version of TensorFlow you would need to modify ./run-prereq.sh. Unfortunately there is no guaranty this will work. . Another option is to try running DeepVariant Quick Study on Google Cloud Platform. It is fairly straight forward to set up a project and start creating virtual machines on Google Cloud. You may start from [here](https://cloud.google.com/compute/docs/instances/create-start-instance).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:287,integrability,version,version-of-tensorflow-not-compiled-for-avx-instructions,287,"Hi Hamid,. **Short answer**: There is no pre-built docker that would work on an old hardware (with no AVX support). **Long answer**: It may be possible to run DeepVariant with custom TensorFlow library (this is what I found online https://stackoverflow.com/questions/53723217/is-there-a-version-of-tensorflow-not-compiled-for-avx-instructions). Then you may follow directions [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-build-test.md) to manually build DeepVariant and then follow instructions to run DeepVariant without docker [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md). To use custom version of TensorFlow you would need to modify ./run-prereq.sh. Unfortunately there is no guaranty this will work. . Another option is to try running DeepVariant Quick Study on Google Cloud Platform. It is fairly straight forward to set up a project and start creating virtual machines on Google Cloud. You may start from [here](https://cloud.google.com/compute/docs/instances/create-start-instance).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:659,integrability,version,version,659,"Hi Hamid,. **Short answer**: There is no pre-built docker that would work on an old hardware (with no AVX support). **Long answer**: It may be possible to run DeepVariant with custom TensorFlow library (this is what I found online https://stackoverflow.com/questions/53723217/is-there-a-version-of-tensorflow-not-compiled-for-avx-instructions). Then you may follow directions [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-build-test.md) to manually build DeepVariant and then follow instructions to run DeepVariant without docker [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md). To use custom version of TensorFlow you would need to modify ./run-prereq.sh. Unfortunately there is no guaranty this will work. . Another option is to try running DeepVariant Quick Study on Google Cloud Platform. It is fairly straight forward to set up a project and start creating virtual machines on Google Cloud. You may start from [here](https://cloud.google.com/compute/docs/instances/create-start-instance).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:849,interoperability,Platform,Platform,849,"Hi Hamid,. **Short answer**: There is no pre-built docker that would work on an old hardware (with no AVX support). **Long answer**: It may be possible to run DeepVariant with custom TensorFlow library (this is what I found online https://stackoverflow.com/questions/53723217/is-there-a-version-of-tensorflow-not-compiled-for-avx-instructions). Then you may follow directions [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-build-test.md) to manually build DeepVariant and then follow instructions to run DeepVariant without docker [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md). To use custom version of TensorFlow you would need to modify ./run-prereq.sh. Unfortunately there is no guaranty this will work. . Another option is to try running DeepVariant Quick Study on Google Cloud Platform. It is fairly straight forward to set up a project and start creating virtual machines on Google Cloud. You may start from [here](https://cloud.google.com/compute/docs/instances/create-start-instance).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:287,modifiability,version,version-of-tensorflow-not-compiled-for-avx-instructions,287,"Hi Hamid,. **Short answer**: There is no pre-built docker that would work on an old hardware (with no AVX support). **Long answer**: It may be possible to run DeepVariant with custom TensorFlow library (this is what I found online https://stackoverflow.com/questions/53723217/is-there-a-version-of-tensorflow-not-compiled-for-avx-instructions). Then you may follow directions [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-build-test.md) to manually build DeepVariant and then follow instructions to run DeepVariant without docker [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md). To use custom version of TensorFlow you would need to modify ./run-prereq.sh. Unfortunately there is no guaranty this will work. . Another option is to try running DeepVariant Quick Study on Google Cloud Platform. It is fairly straight forward to set up a project and start creating virtual machines on Google Cloud. You may start from [here](https://cloud.google.com/compute/docs/instances/create-start-instance).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:659,modifiability,version,version,659,"Hi Hamid,. **Short answer**: There is no pre-built docker that would work on an old hardware (with no AVX support). **Long answer**: It may be possible to run DeepVariant with custom TensorFlow library (this is what I found online https://stackoverflow.com/questions/53723217/is-there-a-version-of-tensorflow-not-compiled-for-avx-instructions). Then you may follow directions [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-build-test.md) to manually build DeepVariant and then follow instructions to run DeepVariant without docker [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md). To use custom version of TensorFlow you would need to modify ./run-prereq.sh. Unfortunately there is no guaranty this will work. . Another option is to try running DeepVariant Quick Study on Google Cloud Platform. It is fairly straight forward to set up a project and start creating virtual machines on Google Cloud. You may start from [here](https://cloud.google.com/compute/docs/instances/create-start-instance).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:454,safety,test,test,454,"Hi Hamid,. **Short answer**: There is no pre-built docker that would work on an old hardware (with no AVX support). **Long answer**: It may be possible to run DeepVariant with custom TensorFlow library (this is what I found online https://stackoverflow.com/questions/53723217/is-there-a-version-of-tensorflow-not-compiled-for-avx-instructions). Then you may follow directions [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-build-test.md) to manually build DeepVariant and then follow instructions to run DeepVariant without docker [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md). To use custom version of TensorFlow you would need to modify ./run-prereq.sh. Unfortunately there is no guaranty this will work. . Another option is to try running DeepVariant Quick Study on Google Cloud Platform. It is fairly straight forward to set up a project and start creating virtual machines on Google Cloud. You may start from [here](https://cloud.google.com/compute/docs/instances/create-start-instance).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:699,security,modif,modify,699,"Hi Hamid,. **Short answer**: There is no pre-built docker that would work on an old hardware (with no AVX support). **Long answer**: It may be possible to run DeepVariant with custom TensorFlow library (this is what I found online https://stackoverflow.com/questions/53723217/is-there-a-version-of-tensorflow-not-compiled-for-avx-instructions). Then you may follow directions [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-build-test.md) to manually build DeepVariant and then follow instructions to run DeepVariant without docker [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md). To use custom version of TensorFlow you would need to modify ./run-prereq.sh. Unfortunately there is no guaranty this will work. . Another option is to try running DeepVariant Quick Study on Google Cloud Platform. It is fairly straight forward to set up a project and start creating virtual machines on Google Cloud. You may start from [here](https://cloud.google.com/compute/docs/instances/create-start-instance).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:454,testability,test,test,454,"Hi Hamid,. **Short answer**: There is no pre-built docker that would work on an old hardware (with no AVX support). **Long answer**: It may be possible to run DeepVariant with custom TensorFlow library (this is what I found online https://stackoverflow.com/questions/53723217/is-there-a-version-of-tensorflow-not-compiled-for-avx-instructions). Then you may follow directions [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-build-test.md) to manually build DeepVariant and then follow instructions to run DeepVariant without docker [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md). To use custom version of TensorFlow you would need to modify ./run-prereq.sh. Unfortunately there is no guaranty this will work. . Another option is to try running DeepVariant Quick Study on Google Cloud Platform. It is fairly straight forward to set up a project and start creating virtual machines on Google Cloud. You may start from [here](https://cloud.google.com/compute/docs/instances/create-start-instance).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:106,usability,support,support,106,"Hi Hamid,. **Short answer**: There is no pre-built docker that would work on an old hardware (with no AVX support). **Long answer**: It may be possible to run DeepVariant with custom TensorFlow library (this is what I found online https://stackoverflow.com/questions/53723217/is-there-a-version-of-tensorflow-not-compiled-for-avx-instructions). Then you may follow directions [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-build-test.md) to manually build DeepVariant and then follow instructions to run DeepVariant without docker [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md). To use custom version of TensorFlow you would need to modify ./run-prereq.sh. Unfortunately there is no guaranty this will work. . Another option is to try running DeepVariant Quick Study on Google Cloud Platform. It is fairly straight forward to set up a project and start creating virtual machines on Google Cloud. You may start from [here](https://cloud.google.com/compute/docs/instances/create-start-instance).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:176,usability,custom,custom,176,"Hi Hamid,. **Short answer**: There is no pre-built docker that would work on an old hardware (with no AVX support). **Long answer**: It may be possible to run DeepVariant with custom TensorFlow library (this is what I found online https://stackoverflow.com/questions/53723217/is-there-a-version-of-tensorflow-not-compiled-for-avx-instructions). Then you may follow directions [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-build-test.md) to manually build DeepVariant and then follow instructions to run DeepVariant without docker [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md). To use custom version of TensorFlow you would need to modify ./run-prereq.sh. Unfortunately there is no guaranty this will work. . Another option is to try running DeepVariant Quick Study on Google Cloud Platform. It is fairly straight forward to set up a project and start creating virtual machines on Google Cloud. You may start from [here](https://cloud.google.com/compute/docs/instances/create-start-instance).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/issues/217:652,usability,custom,custom,652,"Hi Hamid,. **Short answer**: There is no pre-built docker that would work on an old hardware (with no AVX support). **Long answer**: It may be possible to run DeepVariant with custom TensorFlow library (this is what I found online https://stackoverflow.com/questions/53723217/is-there-a-version-of-tensorflow-not-compiled-for-avx-instructions). Then you may follow directions [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-build-test.md) to manually build DeepVariant and then follow instructions to run DeepVariant without docker [here](https://github.com/google/deepvariant/blob/r0.6/docs/deepvariant-quick-start.md). To use custom version of TensorFlow you would need to modify ./run-prereq.sh. Unfortunately there is no guaranty this will work. . Another option is to try running DeepVariant Quick Study on Google Cloud Platform. It is fairly straight forward to set up a project and start creating virtual machines on Google Cloud. You may start from [here](https://cloud.google.com/compute/docs/instances/create-start-instance).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/217
https://github.com/google/deepvariant/pull/218:26,deployability,updat,updating,26,Looks awesome! Thanks for updating the README.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/218
https://github.com/google/deepvariant/pull/218:26,safety,updat,updating,26,Looks awesome! Thanks for updating the README.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/218
https://github.com/google/deepvariant/pull/218:26,security,updat,updating,26,Looks awesome! Thanks for updating the README.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/218
https://github.com/google/deepvariant/issues/219:17,availability,error,error,17,"Hi PlatonB,. The error you get is ""Could not open /home/platon/test/seq1.bam"". Did you forget to add ""-v"" flag to your docker run command to mount your input directory? Take a look at DeepVariant documentation [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command) for the example on how to run DeepVariant from docker image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:17,performance,error,error,17,"Hi PlatonB,. The error you get is ""Could not open /home/platon/test/seq1.bam"". Did you forget to add ""-v"" flag to your docker run command to mount your input directory? Take a look at DeepVariant documentation [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command) for the example on how to run DeepVariant from docker image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:17,safety,error,error,17,"Hi PlatonB,. The error you get is ""Could not open /home/platon/test/seq1.bam"". Did you forget to add ""-v"" flag to your docker run command to mount your input directory? Take a look at DeepVariant documentation [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command) for the example on how to run DeepVariant from docker image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:63,safety,test,test,63,"Hi PlatonB,. The error you get is ""Could not open /home/platon/test/seq1.bam"". Did you forget to add ""-v"" flag to your docker run command to mount your input directory? Take a look at DeepVariant documentation [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command) for the example on how to run DeepVariant from docker image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:152,safety,input,input,152,"Hi PlatonB,. The error you get is ""Could not open /home/platon/test/seq1.bam"". Did you forget to add ""-v"" flag to your docker run command to mount your input directory? Take a look at DeepVariant documentation [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command) for the example on how to run DeepVariant from docker image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:63,testability,test,test,63,"Hi PlatonB,. The error you get is ""Could not open /home/platon/test/seq1.bam"". Did you forget to add ""-v"" flag to your docker run command to mount your input directory? Take a look at DeepVariant documentation [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command) for the example on how to run DeepVariant from docker image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:17,usability,error,error,17,"Hi PlatonB,. The error you get is ""Could not open /home/platon/test/seq1.bam"". Did you forget to add ""-v"" flag to your docker run command to mount your input directory? Take a look at DeepVariant documentation [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command) for the example on how to run DeepVariant from docker image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:130,usability,command,command,130,"Hi PlatonB,. The error you get is ""Could not open /home/platon/test/seq1.bam"". Did you forget to add ""-v"" flag to your docker run command to mount your input directory? Take a look at DeepVariant documentation [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command) for the example on how to run DeepVariant from docker image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:152,usability,input,input,152,"Hi PlatonB,. The error you get is ""Could not open /home/platon/test/seq1.bam"". Did you forget to add ""-v"" flag to your docker run command to mount your input directory? Take a look at DeepVariant documentation [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command) for the example on how to run DeepVariant from docker image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:196,usability,document,documentation,196,"Hi PlatonB,. The error you get is ""Could not open /home/platon/test/seq1.bam"". Did you forget to add ""-v"" flag to your docker run command to mount your input directory? Take a look at DeepVariant documentation [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command) for the example on how to run DeepVariant from docker image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/219:322,usability,command,command,322,"Hi PlatonB,. The error you get is ""Could not open /home/platon/test/seq1.bam"". Did you forget to add ""-v"" flag to your docker run command to mount your input directory? Take a look at DeepVariant documentation [here](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md#run-deepvariant-with-one-command) for the example on how to run DeepVariant from docker image.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/219
https://github.com/google/deepvariant/issues/220:83,availability,avail,available,83,"Hi @bopohdr . I cannot speak to the dataset referenced in this paper, as it is not available, and I am not sure how merging would have been performed, and the paper references an earlier DeepVariant version. However, a higher de novo rate of DeepVariant relative to other callers is not something that we observe in the investigations we have conducted. I am attaching (if they will upload) two VCF files for the Oslo University HG002-HG003-HG004 trio available in Genome in a Bottle FTP. The DeepVariant trio is called with DeepVariant exome model and merged with GLnexus. The GATK4 trio is called with HaplotypeCaller and merged with GenotypeGVCFs. In these trios, DeepVariant has 87 de novo calls where the child is not 0/0 but both parents are 0/0. The GATK4 trio has 270 de novo cases with the same criteria. We have a set of documentation for best practices in merging a trio that we are hoping to release in the near future. If you would like me to share that with you privately now, you can reach out directly at awcarroll@google.com. Thanks,. Andrew. [deepvariant.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623783/deepvariant.cohort.vcf.gz). [gatk4.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623784/gatk4.cohort.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/220
https://github.com/google/deepvariant/issues/220:452,availability,avail,available,452,"Hi @bopohdr . I cannot speak to the dataset referenced in this paper, as it is not available, and I am not sure how merging would have been performed, and the paper references an earlier DeepVariant version. However, a higher de novo rate of DeepVariant relative to other callers is not something that we observe in the investigations we have conducted. I am attaching (if they will upload) two VCF files for the Oslo University HG002-HG003-HG004 trio available in Genome in a Bottle FTP. The DeepVariant trio is called with DeepVariant exome model and merged with GLnexus. The GATK4 trio is called with HaplotypeCaller and merged with GenotypeGVCFs. In these trios, DeepVariant has 87 de novo calls where the child is not 0/0 but both parents are 0/0. The GATK4 trio has 270 de novo cases with the same criteria. We have a set of documentation for best practices in merging a trio that we are hoping to release in the near future. If you would like me to share that with you privately now, you can reach out directly at awcarroll@google.com. Thanks,. Andrew. [deepvariant.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623783/deepvariant.cohort.vcf.gz). [gatk4.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623784/gatk4.cohort.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/220
https://github.com/google/deepvariant/issues/220:199,deployability,version,version,199,"Hi @bopohdr . I cannot speak to the dataset referenced in this paper, as it is not available, and I am not sure how merging would have been performed, and the paper references an earlier DeepVariant version. However, a higher de novo rate of DeepVariant relative to other callers is not something that we observe in the investigations we have conducted. I am attaching (if they will upload) two VCF files for the Oslo University HG002-HG003-HG004 trio available in Genome in a Bottle FTP. The DeepVariant trio is called with DeepVariant exome model and merged with GLnexus. The GATK4 trio is called with HaplotypeCaller and merged with GenotypeGVCFs. In these trios, DeepVariant has 87 de novo calls where the child is not 0/0 but both parents are 0/0. The GATK4 trio has 270 de novo cases with the same criteria. We have a set of documentation for best practices in merging a trio that we are hoping to release in the near future. If you would like me to share that with you privately now, you can reach out directly at awcarroll@google.com. Thanks,. Andrew. [deepvariant.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623783/deepvariant.cohort.vcf.gz). [gatk4.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623784/gatk4.cohort.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/220
https://github.com/google/deepvariant/issues/220:305,deployability,observ,observe,305,"Hi @bopohdr . I cannot speak to the dataset referenced in this paper, as it is not available, and I am not sure how merging would have been performed, and the paper references an earlier DeepVariant version. However, a higher de novo rate of DeepVariant relative to other callers is not something that we observe in the investigations we have conducted. I am attaching (if they will upload) two VCF files for the Oslo University HG002-HG003-HG004 trio available in Genome in a Bottle FTP. The DeepVariant trio is called with DeepVariant exome model and merged with GLnexus. The GATK4 trio is called with HaplotypeCaller and merged with GenotypeGVCFs. In these trios, DeepVariant has 87 de novo calls where the child is not 0/0 but both parents are 0/0. The GATK4 trio has 270 de novo cases with the same criteria. We have a set of documentation for best practices in merging a trio that we are hoping to release in the near future. If you would like me to share that with you privately now, you can reach out directly at awcarroll@google.com. Thanks,. Andrew. [deepvariant.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623783/deepvariant.cohort.vcf.gz). [gatk4.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623784/gatk4.cohort.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/220
https://github.com/google/deepvariant/issues/220:904,deployability,releas,release,904,"Hi @bopohdr . I cannot speak to the dataset referenced in this paper, as it is not available, and I am not sure how merging would have been performed, and the paper references an earlier DeepVariant version. However, a higher de novo rate of DeepVariant relative to other callers is not something that we observe in the investigations we have conducted. I am attaching (if they will upload) two VCF files for the Oslo University HG002-HG003-HG004 trio available in Genome in a Bottle FTP. The DeepVariant trio is called with DeepVariant exome model and merged with GLnexus. The GATK4 trio is called with HaplotypeCaller and merged with GenotypeGVCFs. In these trios, DeepVariant has 87 de novo calls where the child is not 0/0 but both parents are 0/0. The GATK4 trio has 270 de novo cases with the same criteria. We have a set of documentation for best practices in merging a trio that we are hoping to release in the near future. If you would like me to share that with you privately now, you can reach out directly at awcarroll@google.com. Thanks,. Andrew. [deepvariant.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623783/deepvariant.cohort.vcf.gz). [gatk4.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623784/gatk4.cohort.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/220
https://github.com/google/deepvariant/issues/220:543,energy efficiency,model,model,543,"Hi @bopohdr . I cannot speak to the dataset referenced in this paper, as it is not available, and I am not sure how merging would have been performed, and the paper references an earlier DeepVariant version. However, a higher de novo rate of DeepVariant relative to other callers is not something that we observe in the investigations we have conducted. I am attaching (if they will upload) two VCF files for the Oslo University HG002-HG003-HG004 trio available in Genome in a Bottle FTP. The DeepVariant trio is called with DeepVariant exome model and merged with GLnexus. The GATK4 trio is called with HaplotypeCaller and merged with GenotypeGVCFs. In these trios, DeepVariant has 87 de novo calls where the child is not 0/0 but both parents are 0/0. The GATK4 trio has 270 de novo cases with the same criteria. We have a set of documentation for best practices in merging a trio that we are hoping to release in the near future. If you would like me to share that with you privately now, you can reach out directly at awcarroll@google.com. Thanks,. Andrew. [deepvariant.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623783/deepvariant.cohort.vcf.gz). [gatk4.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623784/gatk4.cohort.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/220
https://github.com/google/deepvariant/issues/220:199,integrability,version,version,199,"Hi @bopohdr . I cannot speak to the dataset referenced in this paper, as it is not available, and I am not sure how merging would have been performed, and the paper references an earlier DeepVariant version. However, a higher de novo rate of DeepVariant relative to other callers is not something that we observe in the investigations we have conducted. I am attaching (if they will upload) two VCF files for the Oslo University HG002-HG003-HG004 trio available in Genome in a Bottle FTP. The DeepVariant trio is called with DeepVariant exome model and merged with GLnexus. The GATK4 trio is called with HaplotypeCaller and merged with GenotypeGVCFs. In these trios, DeepVariant has 87 de novo calls where the child is not 0/0 but both parents are 0/0. The GATK4 trio has 270 de novo cases with the same criteria. We have a set of documentation for best practices in merging a trio that we are hoping to release in the near future. If you would like me to share that with you privately now, you can reach out directly at awcarroll@google.com. Thanks,. Andrew. [deepvariant.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623783/deepvariant.cohort.vcf.gz). [gatk4.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623784/gatk4.cohort.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/220
https://github.com/google/deepvariant/issues/220:956,interoperability,share,share,956,"Hi @bopohdr . I cannot speak to the dataset referenced in this paper, as it is not available, and I am not sure how merging would have been performed, and the paper references an earlier DeepVariant version. However, a higher de novo rate of DeepVariant relative to other callers is not something that we observe in the investigations we have conducted. I am attaching (if they will upload) two VCF files for the Oslo University HG002-HG003-HG004 trio available in Genome in a Bottle FTP. The DeepVariant trio is called with DeepVariant exome model and merged with GLnexus. The GATK4 trio is called with HaplotypeCaller and merged with GenotypeGVCFs. In these trios, DeepVariant has 87 de novo calls where the child is not 0/0 but both parents are 0/0. The GATK4 trio has 270 de novo cases with the same criteria. We have a set of documentation for best practices in merging a trio that we are hoping to release in the near future. If you would like me to share that with you privately now, you can reach out directly at awcarroll@google.com. Thanks,. Andrew. [deepvariant.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623783/deepvariant.cohort.vcf.gz). [gatk4.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623784/gatk4.cohort.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/220
https://github.com/google/deepvariant/issues/220:199,modifiability,version,version,199,"Hi @bopohdr . I cannot speak to the dataset referenced in this paper, as it is not available, and I am not sure how merging would have been performed, and the paper references an earlier DeepVariant version. However, a higher de novo rate of DeepVariant relative to other callers is not something that we observe in the investigations we have conducted. I am attaching (if they will upload) two VCF files for the Oslo University HG002-HG003-HG004 trio available in Genome in a Bottle FTP. The DeepVariant trio is called with DeepVariant exome model and merged with GLnexus. The GATK4 trio is called with HaplotypeCaller and merged with GenotypeGVCFs. In these trios, DeepVariant has 87 de novo calls where the child is not 0/0 but both parents are 0/0. The GATK4 trio has 270 de novo cases with the same criteria. We have a set of documentation for best practices in merging a trio that we are hoping to release in the near future. If you would like me to share that with you privately now, you can reach out directly at awcarroll@google.com. Thanks,. Andrew. [deepvariant.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623783/deepvariant.cohort.vcf.gz). [gatk4.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623784/gatk4.cohort.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/220
https://github.com/google/deepvariant/issues/220:140,performance,perform,performed,140,"Hi @bopohdr . I cannot speak to the dataset referenced in this paper, as it is not available, and I am not sure how merging would have been performed, and the paper references an earlier DeepVariant version. However, a higher de novo rate of DeepVariant relative to other callers is not something that we observe in the investigations we have conducted. I am attaching (if they will upload) two VCF files for the Oslo University HG002-HG003-HG004 trio available in Genome in a Bottle FTP. The DeepVariant trio is called with DeepVariant exome model and merged with GLnexus. The GATK4 trio is called with HaplotypeCaller and merged with GenotypeGVCFs. In these trios, DeepVariant has 87 de novo calls where the child is not 0/0 but both parents are 0/0. The GATK4 trio has 270 de novo cases with the same criteria. We have a set of documentation for best practices in merging a trio that we are hoping to release in the near future. If you would like me to share that with you privately now, you can reach out directly at awcarroll@google.com. Thanks,. Andrew. [deepvariant.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623783/deepvariant.cohort.vcf.gz). [gatk4.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623784/gatk4.cohort.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/220
https://github.com/google/deepvariant/issues/220:83,reliability,availab,available,83,"Hi @bopohdr . I cannot speak to the dataset referenced in this paper, as it is not available, and I am not sure how merging would have been performed, and the paper references an earlier DeepVariant version. However, a higher de novo rate of DeepVariant relative to other callers is not something that we observe in the investigations we have conducted. I am attaching (if they will upload) two VCF files for the Oslo University HG002-HG003-HG004 trio available in Genome in a Bottle FTP. The DeepVariant trio is called with DeepVariant exome model and merged with GLnexus. The GATK4 trio is called with HaplotypeCaller and merged with GenotypeGVCFs. In these trios, DeepVariant has 87 de novo calls where the child is not 0/0 but both parents are 0/0. The GATK4 trio has 270 de novo cases with the same criteria. We have a set of documentation for best practices in merging a trio that we are hoping to release in the near future. If you would like me to share that with you privately now, you can reach out directly at awcarroll@google.com. Thanks,. Andrew. [deepvariant.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623783/deepvariant.cohort.vcf.gz). [gatk4.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623784/gatk4.cohort.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/220
https://github.com/google/deepvariant/issues/220:452,reliability,availab,available,452,"Hi @bopohdr . I cannot speak to the dataset referenced in this paper, as it is not available, and I am not sure how merging would have been performed, and the paper references an earlier DeepVariant version. However, a higher de novo rate of DeepVariant relative to other callers is not something that we observe in the investigations we have conducted. I am attaching (if they will upload) two VCF files for the Oslo University HG002-HG003-HG004 trio available in Genome in a Bottle FTP. The DeepVariant trio is called with DeepVariant exome model and merged with GLnexus. The GATK4 trio is called with HaplotypeCaller and merged with GenotypeGVCFs. In these trios, DeepVariant has 87 de novo calls where the child is not 0/0 but both parents are 0/0. The GATK4 trio has 270 de novo cases with the same criteria. We have a set of documentation for best practices in merging a trio that we are hoping to release in the near future. If you would like me to share that with you privately now, you can reach out directly at awcarroll@google.com. Thanks,. Andrew. [deepvariant.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623783/deepvariant.cohort.vcf.gz). [gatk4.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623784/gatk4.cohort.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/220
https://github.com/google/deepvariant/issues/220:854,reliability,pra,practices,854,"Hi @bopohdr . I cannot speak to the dataset referenced in this paper, as it is not available, and I am not sure how merging would have been performed, and the paper references an earlier DeepVariant version. However, a higher de novo rate of DeepVariant relative to other callers is not something that we observe in the investigations we have conducted. I am attaching (if they will upload) two VCF files for the Oslo University HG002-HG003-HG004 trio available in Genome in a Bottle FTP. The DeepVariant trio is called with DeepVariant exome model and merged with GLnexus. The GATK4 trio is called with HaplotypeCaller and merged with GenotypeGVCFs. In these trios, DeepVariant has 87 de novo calls where the child is not 0/0 but both parents are 0/0. The GATK4 trio has 270 de novo cases with the same criteria. We have a set of documentation for best practices in merging a trio that we are hoping to release in the near future. If you would like me to share that with you privately now, you can reach out directly at awcarroll@google.com. Thanks,. Andrew. [deepvariant.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623783/deepvariant.cohort.vcf.gz). [gatk4.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623784/gatk4.cohort.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/220
https://github.com/google/deepvariant/issues/220:83,safety,avail,available,83,"Hi @bopohdr . I cannot speak to the dataset referenced in this paper, as it is not available, and I am not sure how merging would have been performed, and the paper references an earlier DeepVariant version. However, a higher de novo rate of DeepVariant relative to other callers is not something that we observe in the investigations we have conducted. I am attaching (if they will upload) two VCF files for the Oslo University HG002-HG003-HG004 trio available in Genome in a Bottle FTP. The DeepVariant trio is called with DeepVariant exome model and merged with GLnexus. The GATK4 trio is called with HaplotypeCaller and merged with GenotypeGVCFs. In these trios, DeepVariant has 87 de novo calls where the child is not 0/0 but both parents are 0/0. The GATK4 trio has 270 de novo cases with the same criteria. We have a set of documentation for best practices in merging a trio that we are hoping to release in the near future. If you would like me to share that with you privately now, you can reach out directly at awcarroll@google.com. Thanks,. Andrew. [deepvariant.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623783/deepvariant.cohort.vcf.gz). [gatk4.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623784/gatk4.cohort.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/220
https://github.com/google/deepvariant/issues/220:452,safety,avail,available,452,"Hi @bopohdr . I cannot speak to the dataset referenced in this paper, as it is not available, and I am not sure how merging would have been performed, and the paper references an earlier DeepVariant version. However, a higher de novo rate of DeepVariant relative to other callers is not something that we observe in the investigations we have conducted. I am attaching (if they will upload) two VCF files for the Oslo University HG002-HG003-HG004 trio available in Genome in a Bottle FTP. The DeepVariant trio is called with DeepVariant exome model and merged with GLnexus. The GATK4 trio is called with HaplotypeCaller and merged with GenotypeGVCFs. In these trios, DeepVariant has 87 de novo calls where the child is not 0/0 but both parents are 0/0. The GATK4 trio has 270 de novo cases with the same criteria. We have a set of documentation for best practices in merging a trio that we are hoping to release in the near future. If you would like me to share that with you privately now, you can reach out directly at awcarroll@google.com. Thanks,. Andrew. [deepvariant.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623783/deepvariant.cohort.vcf.gz). [gatk4.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623784/gatk4.cohort.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/220
https://github.com/google/deepvariant/issues/220:83,security,availab,available,83,"Hi @bopohdr . I cannot speak to the dataset referenced in this paper, as it is not available, and I am not sure how merging would have been performed, and the paper references an earlier DeepVariant version. However, a higher de novo rate of DeepVariant relative to other callers is not something that we observe in the investigations we have conducted. I am attaching (if they will upload) two VCF files for the Oslo University HG002-HG003-HG004 trio available in Genome in a Bottle FTP. The DeepVariant trio is called with DeepVariant exome model and merged with GLnexus. The GATK4 trio is called with HaplotypeCaller and merged with GenotypeGVCFs. In these trios, DeepVariant has 87 de novo calls where the child is not 0/0 but both parents are 0/0. The GATK4 trio has 270 de novo cases with the same criteria. We have a set of documentation for best practices in merging a trio that we are hoping to release in the near future. If you would like me to share that with you privately now, you can reach out directly at awcarroll@google.com. Thanks,. Andrew. [deepvariant.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623783/deepvariant.cohort.vcf.gz). [gatk4.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623784/gatk4.cohort.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/220
https://github.com/google/deepvariant/issues/220:452,security,availab,available,452,"Hi @bopohdr . I cannot speak to the dataset referenced in this paper, as it is not available, and I am not sure how merging would have been performed, and the paper references an earlier DeepVariant version. However, a higher de novo rate of DeepVariant relative to other callers is not something that we observe in the investigations we have conducted. I am attaching (if they will upload) two VCF files for the Oslo University HG002-HG003-HG004 trio available in Genome in a Bottle FTP. The DeepVariant trio is called with DeepVariant exome model and merged with GLnexus. The GATK4 trio is called with HaplotypeCaller and merged with GenotypeGVCFs. In these trios, DeepVariant has 87 de novo calls where the child is not 0/0 but both parents are 0/0. The GATK4 trio has 270 de novo cases with the same criteria. We have a set of documentation for best practices in merging a trio that we are hoping to release in the near future. If you would like me to share that with you privately now, you can reach out directly at awcarroll@google.com. Thanks,. Andrew. [deepvariant.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623783/deepvariant.cohort.vcf.gz). [gatk4.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623784/gatk4.cohort.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/220
https://github.com/google/deepvariant/issues/220:543,security,model,model,543,"Hi @bopohdr . I cannot speak to the dataset referenced in this paper, as it is not available, and I am not sure how merging would have been performed, and the paper references an earlier DeepVariant version. However, a higher de novo rate of DeepVariant relative to other callers is not something that we observe in the investigations we have conducted. I am attaching (if they will upload) two VCF files for the Oslo University HG002-HG003-HG004 trio available in Genome in a Bottle FTP. The DeepVariant trio is called with DeepVariant exome model and merged with GLnexus. The GATK4 trio is called with HaplotypeCaller and merged with GenotypeGVCFs. In these trios, DeepVariant has 87 de novo calls where the child is not 0/0 but both parents are 0/0. The GATK4 trio has 270 de novo cases with the same criteria. We have a set of documentation for best practices in merging a trio that we are hoping to release in the near future. If you would like me to share that with you privately now, you can reach out directly at awcarroll@google.com. Thanks,. Andrew. [deepvariant.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623783/deepvariant.cohort.vcf.gz). [gatk4.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623784/gatk4.cohort.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/220
https://github.com/google/deepvariant/issues/220:305,testability,observ,observe,305,"Hi @bopohdr . I cannot speak to the dataset referenced in this paper, as it is not available, and I am not sure how merging would have been performed, and the paper references an earlier DeepVariant version. However, a higher de novo rate of DeepVariant relative to other callers is not something that we observe in the investigations we have conducted. I am attaching (if they will upload) two VCF files for the Oslo University HG002-HG003-HG004 trio available in Genome in a Bottle FTP. The DeepVariant trio is called with DeepVariant exome model and merged with GLnexus. The GATK4 trio is called with HaplotypeCaller and merged with GenotypeGVCFs. In these trios, DeepVariant has 87 de novo calls where the child is not 0/0 but both parents are 0/0. The GATK4 trio has 270 de novo cases with the same criteria. We have a set of documentation for best practices in merging a trio that we are hoping to release in the near future. If you would like me to share that with you privately now, you can reach out directly at awcarroll@google.com. Thanks,. Andrew. [deepvariant.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623783/deepvariant.cohort.vcf.gz). [gatk4.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623784/gatk4.cohort.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/220
https://github.com/google/deepvariant/issues/220:140,usability,perform,performed,140,"Hi @bopohdr . I cannot speak to the dataset referenced in this paper, as it is not available, and I am not sure how merging would have been performed, and the paper references an earlier DeepVariant version. However, a higher de novo rate of DeepVariant relative to other callers is not something that we observe in the investigations we have conducted. I am attaching (if they will upload) two VCF files for the Oslo University HG002-HG003-HG004 trio available in Genome in a Bottle FTP. The DeepVariant trio is called with DeepVariant exome model and merged with GLnexus. The GATK4 trio is called with HaplotypeCaller and merged with GenotypeGVCFs. In these trios, DeepVariant has 87 de novo calls where the child is not 0/0 but both parents are 0/0. The GATK4 trio has 270 de novo cases with the same criteria. We have a set of documentation for best practices in merging a trio that we are hoping to release in the near future. If you would like me to share that with you privately now, you can reach out directly at awcarroll@google.com. Thanks,. Andrew. [deepvariant.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623783/deepvariant.cohort.vcf.gz). [gatk4.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623784/gatk4.cohort.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/220
https://github.com/google/deepvariant/issues/220:831,usability,document,documentation,831,"Hi @bopohdr . I cannot speak to the dataset referenced in this paper, as it is not available, and I am not sure how merging would have been performed, and the paper references an earlier DeepVariant version. However, a higher de novo rate of DeepVariant relative to other callers is not something that we observe in the investigations we have conducted. I am attaching (if they will upload) two VCF files for the Oslo University HG002-HG003-HG004 trio available in Genome in a Bottle FTP. The DeepVariant trio is called with DeepVariant exome model and merged with GLnexus. The GATK4 trio is called with HaplotypeCaller and merged with GenotypeGVCFs. In these trios, DeepVariant has 87 de novo calls where the child is not 0/0 but both parents are 0/0. The GATK4 trio has 270 de novo cases with the same criteria. We have a set of documentation for best practices in merging a trio that we are hoping to release in the near future. If you would like me to share that with you privately now, you can reach out directly at awcarroll@google.com. Thanks,. Andrew. [deepvariant.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623783/deepvariant.cohort.vcf.gz). [gatk4.cohort.vcf.gz](https://github.com/google/deepvariant/files/3623784/gatk4.cohort.vcf.gz).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/220
https://github.com/google/deepvariant/issues/221:144,energy efficiency,cloud,cloud,144,DeepVariant docker images are located here:. `gcr.io/deepvariant-docker/deepvariant`. For more details you can refer to [this tutorial](https://cloud.google.com/genomics/docs/tutorials/deepvariant).,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/221
https://github.com/google/deepvariant/issues/222:111,deployability,stage,stage,111,"Hi, it looks like you need to provide a value for the sample_name flag, but to do that you'll need to run each stage of DeepVariant separately. See https://github.com/google/deepvariant/issues/173 for an explanation of how and why to do this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:179,availability,avail,available,179,"Alternatively, you can use [DeepVarianatRunner](https://cloud.google.com/genomics/docs/tutorials/deepvariant#run_deepvariant). It will run all 3 stages and final VCF file will be available at the output bucket. Note that if you want gVCF output you need to also set the [corresponding flag](https://cloud.google.com/genomics/docs/tutorials/deepvariant#genomic_vcf_gvcf_configuration). Similarly if your index files does not follow standard naming convention (such as `.bam.bai`) you need to set them using their flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:145,deployability,stage,stages,145,"Alternatively, you can use [DeepVarianatRunner](https://cloud.google.com/genomics/docs/tutorials/deepvariant#run_deepvariant). It will run all 3 stages and final VCF file will be available at the output bucket. Note that if you want gVCF output you need to also set the [corresponding flag](https://cloud.google.com/genomics/docs/tutorials/deepvariant#genomic_vcf_gvcf_configuration). Similarly if your index files does not follow standard naming convention (such as `.bam.bai`) you need to set them using their flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:56,energy efficiency,cloud,cloud,56,"Alternatively, you can use [DeepVarianatRunner](https://cloud.google.com/genomics/docs/tutorials/deepvariant#run_deepvariant). It will run all 3 stages and final VCF file will be available at the output bucket. Note that if you want gVCF output you need to also set the [corresponding flag](https://cloud.google.com/genomics/docs/tutorials/deepvariant#genomic_vcf_gvcf_configuration). Similarly if your index files does not follow standard naming convention (such as `.bam.bai`) you need to set them using their flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:299,energy efficiency,cloud,cloud,299,"Alternatively, you can use [DeepVarianatRunner](https://cloud.google.com/genomics/docs/tutorials/deepvariant#run_deepvariant). It will run all 3 stages and final VCF file will be available at the output bucket. Note that if you want gVCF output you need to also set the [corresponding flag](https://cloud.google.com/genomics/docs/tutorials/deepvariant#genomic_vcf_gvcf_configuration). Similarly if your index files does not follow standard naming convention (such as `.bam.bai`) you need to set them using their flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:431,interoperability,standard,standard,431,"Alternatively, you can use [DeepVarianatRunner](https://cloud.google.com/genomics/docs/tutorials/deepvariant#run_deepvariant). It will run all 3 stages and final VCF file will be available at the output bucket. Note that if you want gVCF output you need to also set the [corresponding flag](https://cloud.google.com/genomics/docs/tutorials/deepvariant#genomic_vcf_gvcf_configuration). Similarly if your index files does not follow standard naming convention (such as `.bam.bai`) you need to set them using their flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:179,reliability,availab,available,179,"Alternatively, you can use [DeepVarianatRunner](https://cloud.google.com/genomics/docs/tutorials/deepvariant#run_deepvariant). It will run all 3 stages and final VCF file will be available at the output bucket. Note that if you want gVCF output you need to also set the [corresponding flag](https://cloud.google.com/genomics/docs/tutorials/deepvariant#genomic_vcf_gvcf_configuration). Similarly if your index files does not follow standard naming convention (such as `.bam.bai`) you need to set them using their flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:415,reliability,doe,does,415,"Alternatively, you can use [DeepVarianatRunner](https://cloud.google.com/genomics/docs/tutorials/deepvariant#run_deepvariant). It will run all 3 stages and final VCF file will be available at the output bucket. Note that if you want gVCF output you need to also set the [corresponding flag](https://cloud.google.com/genomics/docs/tutorials/deepvariant#genomic_vcf_gvcf_configuration). Similarly if your index files does not follow standard naming convention (such as `.bam.bai`) you need to set them using their flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:179,safety,avail,available,179,"Alternatively, you can use [DeepVarianatRunner](https://cloud.google.com/genomics/docs/tutorials/deepvariant#run_deepvariant). It will run all 3 stages and final VCF file will be available at the output bucket. Note that if you want gVCF output you need to also set the [corresponding flag](https://cloud.google.com/genomics/docs/tutorials/deepvariant#genomic_vcf_gvcf_configuration). Similarly if your index files does not follow standard naming convention (such as `.bam.bai`) you need to set them using their flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:179,security,availab,available,179,"Alternatively, you can use [DeepVarianatRunner](https://cloud.google.com/genomics/docs/tutorials/deepvariant#run_deepvariant). It will run all 3 stages and final VCF file will be available at the output bucket. Note that if you want gVCF output you need to also set the [corresponding flag](https://cloud.google.com/genomics/docs/tutorials/deepvariant#genomic_vcf_gvcf_configuration). Similarly if your index files does not follow standard naming convention (such as `.bam.bai`) you need to set them using their flags.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:346,deployability,releas,release,346,"Hi @anitagh . From my experience it's not too uncommon for BAM files in the wild to have either no sample name in the BAM file, or multiple sample names (which will crash DeepVariant right now). We can easily add `--sample_name` to the run_deepvariant.py script, so you can still run that script once. We'll do this so it'll come out in the next release. So far, we want users to explicitly add this --sample_name this flag because we want to make sure users are aware that their BAM file has more than one (or 0) sample names. But it seems like all the cases I've seen so far, none of them actually intended for them to be different sample names anyway. So I might consider just removing this constraint and just make it a warning message instead. Either way, in our next release, you should be expecting to have `--sample_name` flag in the run_deepvariant.py script which you can do in one step. Thanks for reporting.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:773,deployability,releas,release,773,"Hi @anitagh . From my experience it's not too uncommon for BAM files in the wild to have either no sample name in the BAM file, or multiple sample names (which will crash DeepVariant right now). We can easily add `--sample_name` to the run_deepvariant.py script, so you can still run that script once. We'll do this so it'll come out in the next release. So far, we want users to explicitly add this --sample_name this flag because we want to make sure users are aware that their BAM file has more than one (or 0) sample names. But it seems like all the cases I've seen so far, none of them actually intended for them to be different sample names anyway. So I might consider just removing this constraint and just make it a warning message instead. Either way, in our next release, you should be expecting to have `--sample_name` flag in the run_deepvariant.py script which you can do in one step. Thanks for reporting.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:732,integrability,messag,message,732,"Hi @anitagh . From my experience it's not too uncommon for BAM files in the wild to have either no sample name in the BAM file, or multiple sample names (which will crash DeepVariant right now). We can easily add `--sample_name` to the run_deepvariant.py script, so you can still run that script once. We'll do this so it'll come out in the next release. So far, we want users to explicitly add this --sample_name this flag because we want to make sure users are aware that their BAM file has more than one (or 0) sample names. But it seems like all the cases I've seen so far, none of them actually intended for them to be different sample names anyway. So I might consider just removing this constraint and just make it a warning message instead. Either way, in our next release, you should be expecting to have `--sample_name` flag in the run_deepvariant.py script which you can do in one step. Thanks for reporting.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:732,interoperability,messag,message,732,"Hi @anitagh . From my experience it's not too uncommon for BAM files in the wild to have either no sample name in the BAM file, or multiple sample names (which will crash DeepVariant right now). We can easily add `--sample_name` to the run_deepvariant.py script, so you can still run that script once. We'll do this so it'll come out in the next release. So far, we want users to explicitly add this --sample_name this flag because we want to make sure users are aware that their BAM file has more than one (or 0) sample names. But it seems like all the cases I've seen so far, none of them actually intended for them to be different sample names anyway. So I might consider just removing this constraint and just make it a warning message instead. Either way, in our next release, you should be expecting to have `--sample_name` flag in the run_deepvariant.py script which you can do in one step. Thanks for reporting.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:22,usability,experien,experience,22,"Hi @anitagh . From my experience it's not too uncommon for BAM files in the wild to have either no sample name in the BAM file, or multiple sample names (which will crash DeepVariant right now). We can easily add `--sample_name` to the run_deepvariant.py script, so you can still run that script once. We'll do this so it'll come out in the next release. So far, we want users to explicitly add this --sample_name this flag because we want to make sure users are aware that their BAM file has more than one (or 0) sample names. But it seems like all the cases I've seen so far, none of them actually intended for them to be different sample names anyway. So I might consider just removing this constraint and just make it a warning message instead. Either way, in our next release, you should be expecting to have `--sample_name` flag in the run_deepvariant.py script which you can do in one step. Thanks for reporting.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:371,usability,user,users,371,"Hi @anitagh . From my experience it's not too uncommon for BAM files in the wild to have either no sample name in the BAM file, or multiple sample names (which will crash DeepVariant right now). We can easily add `--sample_name` to the run_deepvariant.py script, so you can still run that script once. We'll do this so it'll come out in the next release. So far, we want users to explicitly add this --sample_name this flag because we want to make sure users are aware that their BAM file has more than one (or 0) sample names. But it seems like all the cases I've seen so far, none of them actually intended for them to be different sample names anyway. So I might consider just removing this constraint and just make it a warning message instead. Either way, in our next release, you should be expecting to have `--sample_name` flag in the run_deepvariant.py script which you can do in one step. Thanks for reporting.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:453,usability,user,users,453,"Hi @anitagh . From my experience it's not too uncommon for BAM files in the wild to have either no sample name in the BAM file, or multiple sample names (which will crash DeepVariant right now). We can easily add `--sample_name` to the run_deepvariant.py script, so you can still run that script once. We'll do this so it'll come out in the next release. So far, we want users to explicitly add this --sample_name this flag because we want to make sure users are aware that their BAM file has more than one (or 0) sample names. But it seems like all the cases I've seen so far, none of them actually intended for them to be different sample names anyway. So I might consider just removing this constraint and just make it a warning message instead. Either way, in our next release, you should be expecting to have `--sample_name` flag in the run_deepvariant.py script which you can do in one step. Thanks for reporting.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:258,availability,error,error,258,"Hi @anitagh and @PlatonB , . to give you an update on this issue, we have made a change internally that:. 1) Added `--sample_name` to run_deepvariant.py. 2) When input BAM files has no sample names or more than one sample names, instead of crashing with the error message you reported, we now use a default string as the sample name (or pick one from the multiple names) and prints out a warning. This behavior should be less cumbersome to our users, and shouldn't cause any issues for most use cases. Our team is working towards a next release. Once the release is out, I can post another update to this issue to let you know. For now, please bear with us and use the solution in https://github.com/google/deepvariant/issues/222#issuecomment-534768468. We'll keep you posted!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:44,deployability,updat,update,44,"Hi @anitagh and @PlatonB , . to give you an update on this issue, we have made a change internally that:. 1) Added `--sample_name` to run_deepvariant.py. 2) When input BAM files has no sample names or more than one sample names, instead of crashing with the error message you reported, we now use a default string as the sample name (or pick one from the multiple names) and prints out a warning. This behavior should be less cumbersome to our users, and shouldn't cause any issues for most use cases. Our team is working towards a next release. Once the release is out, I can post another update to this issue to let you know. For now, please bear with us and use the solution in https://github.com/google/deepvariant/issues/222#issuecomment-534768468. We'll keep you posted!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:537,deployability,releas,release,537,"Hi @anitagh and @PlatonB , . to give you an update on this issue, we have made a change internally that:. 1) Added `--sample_name` to run_deepvariant.py. 2) When input BAM files has no sample names or more than one sample names, instead of crashing with the error message you reported, we now use a default string as the sample name (or pick one from the multiple names) and prints out a warning. This behavior should be less cumbersome to our users, and shouldn't cause any issues for most use cases. Our team is working towards a next release. Once the release is out, I can post another update to this issue to let you know. For now, please bear with us and use the solution in https://github.com/google/deepvariant/issues/222#issuecomment-534768468. We'll keep you posted!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:555,deployability,releas,release,555,"Hi @anitagh and @PlatonB , . to give you an update on this issue, we have made a change internally that:. 1) Added `--sample_name` to run_deepvariant.py. 2) When input BAM files has no sample names or more than one sample names, instead of crashing with the error message you reported, we now use a default string as the sample name (or pick one from the multiple names) and prints out a warning. This behavior should be less cumbersome to our users, and shouldn't cause any issues for most use cases. Our team is working towards a next release. Once the release is out, I can post another update to this issue to let you know. For now, please bear with us and use the solution in https://github.com/google/deepvariant/issues/222#issuecomment-534768468. We'll keep you posted!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:590,deployability,updat,update,590,"Hi @anitagh and @PlatonB , . to give you an update on this issue, we have made a change internally that:. 1) Added `--sample_name` to run_deepvariant.py. 2) When input BAM files has no sample names or more than one sample names, instead of crashing with the error message you reported, we now use a default string as the sample name (or pick one from the multiple names) and prints out a warning. This behavior should be less cumbersome to our users, and shouldn't cause any issues for most use cases. Our team is working towards a next release. Once the release is out, I can post another update to this issue to let you know. For now, please bear with us and use the solution in https://github.com/google/deepvariant/issues/222#issuecomment-534768468. We'll keep you posted!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:264,integrability,messag,message,264,"Hi @anitagh and @PlatonB , . to give you an update on this issue, we have made a change internally that:. 1) Added `--sample_name` to run_deepvariant.py. 2) When input BAM files has no sample names or more than one sample names, instead of crashing with the error message you reported, we now use a default string as the sample name (or pick one from the multiple names) and prints out a warning. This behavior should be less cumbersome to our users, and shouldn't cause any issues for most use cases. Our team is working towards a next release. Once the release is out, I can post another update to this issue to let you know. For now, please bear with us and use the solution in https://github.com/google/deepvariant/issues/222#issuecomment-534768468. We'll keep you posted!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:264,interoperability,messag,message,264,"Hi @anitagh and @PlatonB , . to give you an update on this issue, we have made a change internally that:. 1) Added `--sample_name` to run_deepvariant.py. 2) When input BAM files has no sample names or more than one sample names, instead of crashing with the error message you reported, we now use a default string as the sample name (or pick one from the multiple names) and prints out a warning. This behavior should be less cumbersome to our users, and shouldn't cause any issues for most use cases. Our team is working towards a next release. Once the release is out, I can post another update to this issue to let you know. For now, please bear with us and use the solution in https://github.com/google/deepvariant/issues/222#issuecomment-534768468. We'll keep you posted!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:258,performance,error,error,258,"Hi @anitagh and @PlatonB , . to give you an update on this issue, we have made a change internally that:. 1) Added `--sample_name` to run_deepvariant.py. 2) When input BAM files has no sample names or more than one sample names, instead of crashing with the error message you reported, we now use a default string as the sample name (or pick one from the multiple names) and prints out a warning. This behavior should be less cumbersome to our users, and shouldn't cause any issues for most use cases. Our team is working towards a next release. Once the release is out, I can post another update to this issue to let you know. For now, please bear with us and use the solution in https://github.com/google/deepvariant/issues/222#issuecomment-534768468. We'll keep you posted!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:44,safety,updat,update,44,"Hi @anitagh and @PlatonB , . to give you an update on this issue, we have made a change internally that:. 1) Added `--sample_name` to run_deepvariant.py. 2) When input BAM files has no sample names or more than one sample names, instead of crashing with the error message you reported, we now use a default string as the sample name (or pick one from the multiple names) and prints out a warning. This behavior should be less cumbersome to our users, and shouldn't cause any issues for most use cases. Our team is working towards a next release. Once the release is out, I can post another update to this issue to let you know. For now, please bear with us and use the solution in https://github.com/google/deepvariant/issues/222#issuecomment-534768468. We'll keep you posted!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:162,safety,input,input,162,"Hi @anitagh and @PlatonB , . to give you an update on this issue, we have made a change internally that:. 1) Added `--sample_name` to run_deepvariant.py. 2) When input BAM files has no sample names or more than one sample names, instead of crashing with the error message you reported, we now use a default string as the sample name (or pick one from the multiple names) and prints out a warning. This behavior should be less cumbersome to our users, and shouldn't cause any issues for most use cases. Our team is working towards a next release. Once the release is out, I can post another update to this issue to let you know. For now, please bear with us and use the solution in https://github.com/google/deepvariant/issues/222#issuecomment-534768468. We'll keep you posted!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:258,safety,error,error,258,"Hi @anitagh and @PlatonB , . to give you an update on this issue, we have made a change internally that:. 1) Added `--sample_name` to run_deepvariant.py. 2) When input BAM files has no sample names or more than one sample names, instead of crashing with the error message you reported, we now use a default string as the sample name (or pick one from the multiple names) and prints out a warning. This behavior should be less cumbersome to our users, and shouldn't cause any issues for most use cases. Our team is working towards a next release. Once the release is out, I can post another update to this issue to let you know. For now, please bear with us and use the solution in https://github.com/google/deepvariant/issues/222#issuecomment-534768468. We'll keep you posted!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:590,safety,updat,update,590,"Hi @anitagh and @PlatonB , . to give you an update on this issue, we have made a change internally that:. 1) Added `--sample_name` to run_deepvariant.py. 2) When input BAM files has no sample names or more than one sample names, instead of crashing with the error message you reported, we now use a default string as the sample name (or pick one from the multiple names) and prints out a warning. This behavior should be less cumbersome to our users, and shouldn't cause any issues for most use cases. Our team is working towards a next release. Once the release is out, I can post another update to this issue to let you know. For now, please bear with us and use the solution in https://github.com/google/deepvariant/issues/222#issuecomment-534768468. We'll keep you posted!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:44,security,updat,update,44,"Hi @anitagh and @PlatonB , . to give you an update on this issue, we have made a change internally that:. 1) Added `--sample_name` to run_deepvariant.py. 2) When input BAM files has no sample names or more than one sample names, instead of crashing with the error message you reported, we now use a default string as the sample name (or pick one from the multiple names) and prints out a warning. This behavior should be less cumbersome to our users, and shouldn't cause any issues for most use cases. Our team is working towards a next release. Once the release is out, I can post another update to this issue to let you know. For now, please bear with us and use the solution in https://github.com/google/deepvariant/issues/222#issuecomment-534768468. We'll keep you posted!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:506,security,team,team,506,"Hi @anitagh and @PlatonB , . to give you an update on this issue, we have made a change internally that:. 1) Added `--sample_name` to run_deepvariant.py. 2) When input BAM files has no sample names or more than one sample names, instead of crashing with the error message you reported, we now use a default string as the sample name (or pick one from the multiple names) and prints out a warning. This behavior should be less cumbersome to our users, and shouldn't cause any issues for most use cases. Our team is working towards a next release. Once the release is out, I can post another update to this issue to let you know. For now, please bear with us and use the solution in https://github.com/google/deepvariant/issues/222#issuecomment-534768468. We'll keep you posted!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:590,security,updat,update,590,"Hi @anitagh and @PlatonB , . to give you an update on this issue, we have made a change internally that:. 1) Added `--sample_name` to run_deepvariant.py. 2) When input BAM files has no sample names or more than one sample names, instead of crashing with the error message you reported, we now use a default string as the sample name (or pick one from the multiple names) and prints out a warning. This behavior should be less cumbersome to our users, and shouldn't cause any issues for most use cases. Our team is working towards a next release. Once the release is out, I can post another update to this issue to let you know. For now, please bear with us and use the solution in https://github.com/google/deepvariant/issues/222#issuecomment-534768468. We'll keep you posted!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:162,usability,input,input,162,"Hi @anitagh and @PlatonB , . to give you an update on this issue, we have made a change internally that:. 1) Added `--sample_name` to run_deepvariant.py. 2) When input BAM files has no sample names or more than one sample names, instead of crashing with the error message you reported, we now use a default string as the sample name (or pick one from the multiple names) and prints out a warning. This behavior should be less cumbersome to our users, and shouldn't cause any issues for most use cases. Our team is working towards a next release. Once the release is out, I can post another update to this issue to let you know. For now, please bear with us and use the solution in https://github.com/google/deepvariant/issues/222#issuecomment-534768468. We'll keep you posted!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:258,usability,error,error,258,"Hi @anitagh and @PlatonB , . to give you an update on this issue, we have made a change internally that:. 1) Added `--sample_name` to run_deepvariant.py. 2) When input BAM files has no sample names or more than one sample names, instead of crashing with the error message you reported, we now use a default string as the sample name (or pick one from the multiple names) and prints out a warning. This behavior should be less cumbersome to our users, and shouldn't cause any issues for most use cases. Our team is working towards a next release. Once the release is out, I can post another update to this issue to let you know. For now, please bear with us and use the solution in https://github.com/google/deepvariant/issues/222#issuecomment-534768468. We'll keep you posted!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:402,usability,behavi,behavior,402,"Hi @anitagh and @PlatonB , . to give you an update on this issue, we have made a change internally that:. 1) Added `--sample_name` to run_deepvariant.py. 2) When input BAM files has no sample names or more than one sample names, instead of crashing with the error message you reported, we now use a default string as the sample name (or pick one from the multiple names) and prints out a warning. This behavior should be less cumbersome to our users, and shouldn't cause any issues for most use cases. Our team is working towards a next release. Once the release is out, I can post another update to this issue to let you know. For now, please bear with us and use the solution in https://github.com/google/deepvariant/issues/222#issuecomment-534768468. We'll keep you posted!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:444,usability,user,users,444,"Hi @anitagh and @PlatonB , . to give you an update on this issue, we have made a change internally that:. 1) Added `--sample_name` to run_deepvariant.py. 2) When input BAM files has no sample names or more than one sample names, instead of crashing with the error message you reported, we now use a default string as the sample name (or pick one from the multiple names) and prints out a warning. This behavior should be less cumbersome to our users, and shouldn't cause any issues for most use cases. Our team is working towards a next release. Once the release is out, I can post another update to this issue to let you know. For now, please bear with us and use the solution in https://github.com/google/deepvariant/issues/222#issuecomment-534768468. We'll keep you posted!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:417,deployability,contain,contain,417,"Thanks for the quick response. . I checked my bam file and see only one sample name in the header as shown below. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 ./references/bwa_index/RHA.fa ./SNP_Control_Fastq/SNP-Cnt-5p_S6_L001_R1_001.fastq.gz ./SNP_Control_Fastq/SNP-Cnt-5p_S6_L001_R2_001.fastq.gz. I also check the content of the bam file and all records contain the same sample name. > samtools view SNP-Cnt-5p_S6_L001_001_paired.bam | cut -f 3 | sort | uniq -c. 418776 RHA. Do you know when the next release is out? I have to complete my analysis within a week. I guess for now I should figure out how to call the three steps separately. . Thanks again, . Azita.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:564,deployability,releas,release,564,"Thanks for the quick response. . I checked my bam file and see only one sample name in the header as shown below. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 ./references/bwa_index/RHA.fa ./SNP_Control_Fastq/SNP-Cnt-5p_S6_L001_R1_001.fastq.gz ./SNP_Control_Fastq/SNP-Cnt-5p_S6_L001_R2_001.fastq.gz. I also check the content of the bam file and all records contain the same sample name. > samtools view SNP-Cnt-5p_S6_L001_001_paired.bam | cut -f 3 | sort | uniq -c. 418776 RHA. Do you know when the next release is out? I have to complete my analysis within a week. I guess for now I should figure out how to call the three steps separately. . Thanks again, . Azita.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:128,interoperability,coordinat,coordinate,128,"Thanks for the quick response. . I checked my bam file and see only one sample name in the header as shown below. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 ./references/bwa_index/RHA.fa ./SNP_Control_Fastq/SNP-Cnt-5p_S6_L001_R1_001.fastq.gz ./SNP_Control_Fastq/SNP-Cnt-5p_S6_L001_R2_001.fastq.gz. I also check the content of the bam file and all records contain the same sample name. > samtools view SNP-Cnt-5p_S6_L001_001_paired.bam | cut -f 3 | sort | uniq -c. 418776 RHA. Do you know when the next release is out? I have to complete my analysis within a week. I guess for now I should figure out how to call the three steps separately. . Thanks again, . Azita.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:377,performance,content,content,377,"Thanks for the quick response. . I checked my bam file and see only one sample name in the header as shown below. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 ./references/bwa_index/RHA.fa ./SNP_Control_Fastq/SNP-Cnt-5p_S6_L001_R1_001.fastq.gz ./SNP_Control_Fastq/SNP-Cnt-5p_S6_L001_R2_001.fastq.gz. I also check the content of the bam file and all records contain the same sample name. > samtools view SNP-Cnt-5p_S6_L001_001_paired.bam | cut -f 3 | sort | uniq -c. 418776 RHA. Do you know when the next release is out? I have to complete my analysis within a week. I guess for now I should figure out how to call the three steps separately. . Thanks again, . Azita.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:590,safety,compl,complete,590,"Thanks for the quick response. . I checked my bam file and see only one sample name in the header as shown below. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 ./references/bwa_index/RHA.fa ./SNP_Control_Fastq/SNP-Cnt-5p_S6_L001_R1_001.fastq.gz ./SNP_Control_Fastq/SNP-Cnt-5p_S6_L001_R2_001.fastq.gz. I also check the content of the bam file and all records contain the same sample name. > samtools view SNP-Cnt-5p_S6_L001_001_paired.bam | cut -f 3 | sort | uniq -c. 418776 RHA. Do you know when the next release is out? I have to complete my analysis within a week. I guess for now I should figure out how to call the three steps separately. . Thanks again, . Azita.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:590,security,compl,complete,590,"Thanks for the quick response. . I checked my bam file and see only one sample name in the header as shown below. @HD VN:1.6 SO:coordinate. @SQ SN:RHA LN:911. @PG ID:bwa PN:bwa VN:0.7.17-r1194-dirty CL:bwa mem -M -t 10 ./references/bwa_index/RHA.fa ./SNP_Control_Fastq/SNP-Cnt-5p_S6_L001_R1_001.fastq.gz ./SNP_Control_Fastq/SNP-Cnt-5p_S6_L001_R2_001.fastq.gz. I also check the content of the bam file and all records contain the same sample name. > samtools view SNP-Cnt-5p_S6_L001_001_paired.bam | cut -f 3 | sort | uniq -c. 418776 RHA. Do you know when the next release is out? I have to complete my analysis within a week. I guess for now I should figure out how to call the three steps separately. . Thanks again, . Azita.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:119,deployability,stage,stages,119,@anitagh [DeepVarianatRunner](https://cloud.google.com/genomics/docs/tutorials/deepvariant#run_deepvariant) runs all 3 stages and passes the `--sample_name` to all 3 stages if you set it. @pichuan another option is to use (part of) BAM filename. > use a default string as the sample name (or pick one from the multiple names),MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:166,deployability,stage,stages,166,@anitagh [DeepVarianatRunner](https://cloud.google.com/genomics/docs/tutorials/deepvariant#run_deepvariant) runs all 3 stages and passes the `--sample_name` to all 3 stages if you set it. @pichuan another option is to use (part of) BAM filename. > use a default string as the sample name (or pick one from the multiple names),MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:38,energy efficiency,cloud,cloud,38,@anitagh [DeepVarianatRunner](https://cloud.google.com/genomics/docs/tutorials/deepvariant#run_deepvariant) runs all 3 stages and passes the `--sample_name` to all 3 stages if you set it. @pichuan another option is to use (part of) BAM filename. > use a default string as the sample name (or pick one from the multiple names),MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:19,deployability,releas,release,19,"Hi @anitagh ,. the release won't come out within a week. Sorry for the inconvenience. For now you'll have to run make_examples separately and add the `--sample_name` flag. Another way to fix this is to make sure your BAM file header has one SM tag in it. If your BAM file is not very big, using `samtools reheader` to add a proper SM tag might also be a reasonable solution for now. If you're using GCP, you can try out the Google Cloud version that @samanvp pointed to in earlier comments. (If you have any feedback on that tool, please report to https://github.com/googlegenomics/gcp-deepvariant-runner/issues.).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:437,deployability,version,version,437,"Hi @anitagh ,. the release won't come out within a week. Sorry for the inconvenience. For now you'll have to run make_examples separately and add the `--sample_name` flag. Another way to fix this is to make sure your BAM file header has one SM tag in it. If your BAM file is not very big, using `samtools reheader` to add a proper SM tag might also be a reasonable solution for now. If you're using GCP, you can try out the Google Cloud version that @samanvp pointed to in earlier comments. (If you have any feedback on that tool, please report to https://github.com/googlegenomics/gcp-deepvariant-runner/issues.).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:431,energy efficiency,Cloud,Cloud,431,"Hi @anitagh ,. the release won't come out within a week. Sorry for the inconvenience. For now you'll have to run make_examples separately and add the `--sample_name` flag. Another way to fix this is to make sure your BAM file header has one SM tag in it. If your BAM file is not very big, using `samtools reheader` to add a proper SM tag might also be a reasonable solution for now. If you're using GCP, you can try out the Google Cloud version that @samanvp pointed to in earlier comments. (If you have any feedback on that tool, please report to https://github.com/googlegenomics/gcp-deepvariant-runner/issues.).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:437,integrability,version,version,437,"Hi @anitagh ,. the release won't come out within a week. Sorry for the inconvenience. For now you'll have to run make_examples separately and add the `--sample_name` flag. Another way to fix this is to make sure your BAM file header has one SM tag in it. If your BAM file is not very big, using `samtools reheader` to add a proper SM tag might also be a reasonable solution for now. If you're using GCP, you can try out the Google Cloud version that @samanvp pointed to in earlier comments. (If you have any feedback on that tool, please report to https://github.com/googlegenomics/gcp-deepvariant-runner/issues.).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:437,modifiability,version,version,437,"Hi @anitagh ,. the release won't come out within a week. Sorry for the inconvenience. For now you'll have to run make_examples separately and add the `--sample_name` flag. Another way to fix this is to make sure your BAM file header has one SM tag in it. If your BAM file is not very big, using `samtools reheader` to add a proper SM tag might also be a reasonable solution for now. If you're using GCP, you can try out the Google Cloud version that @samanvp pointed to in earlier comments. (If you have any feedback on that tool, please report to https://github.com/googlegenomics/gcp-deepvariant-runner/issues.).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:508,usability,feedback,feedback,508,"Hi @anitagh ,. the release won't come out within a week. Sorry for the inconvenience. For now you'll have to run make_examples separately and add the `--sample_name` flag. Another way to fix this is to make sure your BAM file header has one SM tag in it. If your BAM file is not very big, using `samtools reheader` to add a proper SM tag might also be a reasonable solution for now. If you're using GCP, you can try out the Google Cloud version that @samanvp pointed to in earlier comments. (If you have any feedback on that tool, please report to https://github.com/googlegenomics/gcp-deepvariant-runner/issues.).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:525,usability,tool,tool,525,"Hi @anitagh ,. the release won't come out within a week. Sorry for the inconvenience. For now you'll have to run make_examples separately and add the `--sample_name` flag. Another way to fix this is to make sure your BAM file header has one SM tag in it. If your BAM file is not very big, using `samtools reheader` to add a proper SM tag might also be a reasonable solution for now. If you're using GCP, you can try out the Google Cloud version that @samanvp pointed to in earlier comments. (If you have any feedback on that tool, please report to https://github.com/googlegenomics/gcp-deepvariant-runner/issues.).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:1270,availability,checkpoint,checkpoint,1270,"Thanks @samanvp - unfortunately, because of confidentially issues, we won't be able to use GCP . @pichuan - I managed to run the three scripts but am seeing a surprising result. We have sequenced a panel of control amplicons with spiked inputs containing SNP at position 41. I aligned the reads to the ref using bwa mem and filtered paired reads. Then I ran GATK Mutect2, Illumina Pisces, and Deepvariants to confirm the presence of SNP at position 41. Below is my result. . ![image](https://user-images.githubusercontent.com/24441131/65831442-65545a00-e287-11e9-8c55-8541a8ef3fce.png). I'm not sure what mistake I have made. Below is the set of commands I used to generate the vcf files from the 10% spiked-in sample. BIN_VERSION=""0.8.0"". docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode=calling \. --sample_name=RHA \. --examples=/tmpdir/make_examples.tfrecord.gz \. --ref=/home/RHA.fa \. --reads=/home/SNP-Cnt-10p_S7_L001_001.bam \. --gvcf=/tmpdir/gvcf.tfrecord.gztest.gv. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --checkpoint=/opt/models/wgs/model.ckpt \. --examples=/tmpdir/make_examples.tfrecord.gz \. --outfile=/tmpdir/call_variants_output.tfrecord.gz. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/postprocess_variants \. --ref=/home/RHA.fa \. --infile=/tmpdir/call_variants_output.tfrecord.gz \. --nonvariant_site_tfrecord_path=/tmpdir/gvcf.tfrecord.gztest.gv \. --outfile=/home/out.vcf \. --gvcf_outfile=/home/out.gvcf. Thanks for all your help. Azita.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:110,deployability,manag,managed,110,"Thanks @samanvp - unfortunately, because of confidentially issues, we won't be able to use GCP . @pichuan - I managed to run the three scripts but am seeing a surprising result. We have sequenced a panel of control amplicons with spiked inputs containing SNP at position 41. I aligned the reads to the ref using bwa mem and filtered paired reads. Then I ran GATK Mutect2, Illumina Pisces, and Deepvariants to confirm the presence of SNP at position 41. Below is my result. . ![image](https://user-images.githubusercontent.com/24441131/65831442-65545a00-e287-11e9-8c55-8541a8ef3fce.png). I'm not sure what mistake I have made. Below is the set of commands I used to generate the vcf files from the 10% spiked-in sample. BIN_VERSION=""0.8.0"". docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode=calling \. --sample_name=RHA \. --examples=/tmpdir/make_examples.tfrecord.gz \. --ref=/home/RHA.fa \. --reads=/home/SNP-Cnt-10p_S7_L001_001.bam \. --gvcf=/tmpdir/gvcf.tfrecord.gztest.gv. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --checkpoint=/opt/models/wgs/model.ckpt \. --examples=/tmpdir/make_examples.tfrecord.gz \. --outfile=/tmpdir/call_variants_output.tfrecord.gz. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/postprocess_variants \. --ref=/home/RHA.fa \. --infile=/tmpdir/call_variants_output.tfrecord.gz \. --nonvariant_site_tfrecord_path=/tmpdir/gvcf.tfrecord.gztest.gv \. --outfile=/home/out.vcf \. --gvcf_outfile=/home/out.gvcf. Thanks for all your help. Azita.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:244,deployability,contain,containing,244,"Thanks @samanvp - unfortunately, because of confidentially issues, we won't be able to use GCP . @pichuan - I managed to run the three scripts but am seeing a surprising result. We have sequenced a panel of control amplicons with spiked inputs containing SNP at position 41. I aligned the reads to the ref using bwa mem and filtered paired reads. Then I ran GATK Mutect2, Illumina Pisces, and Deepvariants to confirm the presence of SNP at position 41. Below is my result. . ![image](https://user-images.githubusercontent.com/24441131/65831442-65545a00-e287-11e9-8c55-8541a8ef3fce.png). I'm not sure what mistake I have made. Below is the set of commands I used to generate the vcf files from the 10% spiked-in sample. BIN_VERSION=""0.8.0"". docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode=calling \. --sample_name=RHA \. --examples=/tmpdir/make_examples.tfrecord.gz \. --ref=/home/RHA.fa \. --reads=/home/SNP-Cnt-10p_S7_L001_001.bam \. --gvcf=/tmpdir/gvcf.tfrecord.gztest.gv. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --checkpoint=/opt/models/wgs/model.ckpt \. --examples=/tmpdir/make_examples.tfrecord.gz \. --outfile=/tmpdir/call_variants_output.tfrecord.gz. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/postprocess_variants \. --ref=/home/RHA.fa \. --infile=/tmpdir/call_variants_output.tfrecord.gz \. --nonvariant_site_tfrecord_path=/tmpdir/gvcf.tfrecord.gztest.gv \. --outfile=/home/out.vcf \. --gvcf_outfile=/home/out.gvcf. Thanks for all your help. Azita.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:110,energy efficiency,manag,managed,110,"Thanks @samanvp - unfortunately, because of confidentially issues, we won't be able to use GCP . @pichuan - I managed to run the three scripts but am seeing a surprising result. We have sequenced a panel of control amplicons with spiked inputs containing SNP at position 41. I aligned the reads to the ref using bwa mem and filtered paired reads. Then I ran GATK Mutect2, Illumina Pisces, and Deepvariants to confirm the presence of SNP at position 41. Below is my result. . ![image](https://user-images.githubusercontent.com/24441131/65831442-65545a00-e287-11e9-8c55-8541a8ef3fce.png). I'm not sure what mistake I have made. Below is the set of commands I used to generate the vcf files from the 10% spiked-in sample. BIN_VERSION=""0.8.0"". docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode=calling \. --sample_name=RHA \. --examples=/tmpdir/make_examples.tfrecord.gz \. --ref=/home/RHA.fa \. --reads=/home/SNP-Cnt-10p_S7_L001_001.bam \. --gvcf=/tmpdir/gvcf.tfrecord.gztest.gv. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --checkpoint=/opt/models/wgs/model.ckpt \. --examples=/tmpdir/make_examples.tfrecord.gz \. --outfile=/tmpdir/call_variants_output.tfrecord.gz. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/postprocess_variants \. --ref=/home/RHA.fa \. --infile=/tmpdir/call_variants_output.tfrecord.gz \. --nonvariant_site_tfrecord_path=/tmpdir/gvcf.tfrecord.gztest.gv \. --outfile=/home/out.vcf \. --gvcf_outfile=/home/out.gvcf. Thanks for all your help. Azita.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:1286,energy efficiency,model,models,1286,"Thanks @samanvp - unfortunately, because of confidentially issues, we won't be able to use GCP . @pichuan - I managed to run the three scripts but am seeing a surprising result. We have sequenced a panel of control amplicons with spiked inputs containing SNP at position 41. I aligned the reads to the ref using bwa mem and filtered paired reads. Then I ran GATK Mutect2, Illumina Pisces, and Deepvariants to confirm the presence of SNP at position 41. Below is my result. . ![image](https://user-images.githubusercontent.com/24441131/65831442-65545a00-e287-11e9-8c55-8541a8ef3fce.png). I'm not sure what mistake I have made. Below is the set of commands I used to generate the vcf files from the 10% spiked-in sample. BIN_VERSION=""0.8.0"". docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode=calling \. --sample_name=RHA \. --examples=/tmpdir/make_examples.tfrecord.gz \. --ref=/home/RHA.fa \. --reads=/home/SNP-Cnt-10p_S7_L001_001.bam \. --gvcf=/tmpdir/gvcf.tfrecord.gztest.gv. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --checkpoint=/opt/models/wgs/model.ckpt \. --examples=/tmpdir/make_examples.tfrecord.gz \. --outfile=/tmpdir/call_variants_output.tfrecord.gz. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/postprocess_variants \. --ref=/home/RHA.fa \. --infile=/tmpdir/call_variants_output.tfrecord.gz \. --nonvariant_site_tfrecord_path=/tmpdir/gvcf.tfrecord.gztest.gv \. --outfile=/home/out.vcf \. --gvcf_outfile=/home/out.gvcf. Thanks for all your help. Azita.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:1297,energy efficiency,model,model,1297,"Thanks @samanvp - unfortunately, because of confidentially issues, we won't be able to use GCP . @pichuan - I managed to run the three scripts but am seeing a surprising result. We have sequenced a panel of control amplicons with spiked inputs containing SNP at position 41. I aligned the reads to the ref using bwa mem and filtered paired reads. Then I ran GATK Mutect2, Illumina Pisces, and Deepvariants to confirm the presence of SNP at position 41. Below is my result. . ![image](https://user-images.githubusercontent.com/24441131/65831442-65545a00-e287-11e9-8c55-8541a8ef3fce.png). I'm not sure what mistake I have made. Below is the set of commands I used to generate the vcf files from the 10% spiked-in sample. BIN_VERSION=""0.8.0"". docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode=calling \. --sample_name=RHA \. --examples=/tmpdir/make_examples.tfrecord.gz \. --ref=/home/RHA.fa \. --reads=/home/SNP-Cnt-10p_S7_L001_001.bam \. --gvcf=/tmpdir/gvcf.tfrecord.gztest.gv. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --checkpoint=/opt/models/wgs/model.ckpt \. --examples=/tmpdir/make_examples.tfrecord.gz \. --outfile=/tmpdir/call_variants_output.tfrecord.gz. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/postprocess_variants \. --ref=/home/RHA.fa \. --infile=/tmpdir/call_variants_output.tfrecord.gz \. --nonvariant_site_tfrecord_path=/tmpdir/gvcf.tfrecord.gztest.gv \. --outfile=/home/out.vcf \. --gvcf_outfile=/home/out.gvcf. Thanks for all your help. Azita.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:324,integrability,filter,filtered,324,"Thanks @samanvp - unfortunately, because of confidentially issues, we won't be able to use GCP . @pichuan - I managed to run the three scripts but am seeing a surprising result. We have sequenced a panel of control amplicons with spiked inputs containing SNP at position 41. I aligned the reads to the ref using bwa mem and filtered paired reads. Then I ran GATK Mutect2, Illumina Pisces, and Deepvariants to confirm the presence of SNP at position 41. Below is my result. . ![image](https://user-images.githubusercontent.com/24441131/65831442-65545a00-e287-11e9-8c55-8541a8ef3fce.png). I'm not sure what mistake I have made. Below is the set of commands I used to generate the vcf files from the 10% spiked-in sample. BIN_VERSION=""0.8.0"". docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode=calling \. --sample_name=RHA \. --examples=/tmpdir/make_examples.tfrecord.gz \. --ref=/home/RHA.fa \. --reads=/home/SNP-Cnt-10p_S7_L001_001.bam \. --gvcf=/tmpdir/gvcf.tfrecord.gztest.gv. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --checkpoint=/opt/models/wgs/model.ckpt \. --examples=/tmpdir/make_examples.tfrecord.gz \. --outfile=/tmpdir/call_variants_output.tfrecord.gz. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/postprocess_variants \. --ref=/home/RHA.fa \. --infile=/tmpdir/call_variants_output.tfrecord.gz \. --nonvariant_site_tfrecord_path=/tmpdir/gvcf.tfrecord.gztest.gv \. --outfile=/home/out.vcf \. --gvcf_outfile=/home/out.gvcf. Thanks for all your help. Azita.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:1270,reliability,checkpoint,checkpoint,1270,"Thanks @samanvp - unfortunately, because of confidentially issues, we won't be able to use GCP . @pichuan - I managed to run the three scripts but am seeing a surprising result. We have sequenced a panel of control amplicons with spiked inputs containing SNP at position 41. I aligned the reads to the ref using bwa mem and filtered paired reads. Then I ran GATK Mutect2, Illumina Pisces, and Deepvariants to confirm the presence of SNP at position 41. Below is my result. . ![image](https://user-images.githubusercontent.com/24441131/65831442-65545a00-e287-11e9-8c55-8541a8ef3fce.png). I'm not sure what mistake I have made. Below is the set of commands I used to generate the vcf files from the 10% spiked-in sample. BIN_VERSION=""0.8.0"". docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode=calling \. --sample_name=RHA \. --examples=/tmpdir/make_examples.tfrecord.gz \. --ref=/home/RHA.fa \. --reads=/home/SNP-Cnt-10p_S7_L001_001.bam \. --gvcf=/tmpdir/gvcf.tfrecord.gztest.gv. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --checkpoint=/opt/models/wgs/model.ckpt \. --examples=/tmpdir/make_examples.tfrecord.gz \. --outfile=/tmpdir/call_variants_output.tfrecord.gz. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/postprocess_variants \. --ref=/home/RHA.fa \. --infile=/tmpdir/call_variants_output.tfrecord.gz \. --nonvariant_site_tfrecord_path=/tmpdir/gvcf.tfrecord.gztest.gv \. --outfile=/home/out.vcf \. --gvcf_outfile=/home/out.gvcf. Thanks for all your help. Azita.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:110,safety,manag,managed,110,"Thanks @samanvp - unfortunately, because of confidentially issues, we won't be able to use GCP . @pichuan - I managed to run the three scripts but am seeing a surprising result. We have sequenced a panel of control amplicons with spiked inputs containing SNP at position 41. I aligned the reads to the ref using bwa mem and filtered paired reads. Then I ran GATK Mutect2, Illumina Pisces, and Deepvariants to confirm the presence of SNP at position 41. Below is my result. . ![image](https://user-images.githubusercontent.com/24441131/65831442-65545a00-e287-11e9-8c55-8541a8ef3fce.png). I'm not sure what mistake I have made. Below is the set of commands I used to generate the vcf files from the 10% spiked-in sample. BIN_VERSION=""0.8.0"". docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode=calling \. --sample_name=RHA \. --examples=/tmpdir/make_examples.tfrecord.gz \. --ref=/home/RHA.fa \. --reads=/home/SNP-Cnt-10p_S7_L001_001.bam \. --gvcf=/tmpdir/gvcf.tfrecord.gztest.gv. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --checkpoint=/opt/models/wgs/model.ckpt \. --examples=/tmpdir/make_examples.tfrecord.gz \. --outfile=/tmpdir/call_variants_output.tfrecord.gz. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/postprocess_variants \. --ref=/home/RHA.fa \. --infile=/tmpdir/call_variants_output.tfrecord.gz \. --nonvariant_site_tfrecord_path=/tmpdir/gvcf.tfrecord.gztest.gv \. --outfile=/home/out.vcf \. --gvcf_outfile=/home/out.gvcf. Thanks for all your help. Azita.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:237,safety,input,inputs,237,"Thanks @samanvp - unfortunately, because of confidentially issues, we won't be able to use GCP . @pichuan - I managed to run the three scripts but am seeing a surprising result. We have sequenced a panel of control amplicons with spiked inputs containing SNP at position 41. I aligned the reads to the ref using bwa mem and filtered paired reads. Then I ran GATK Mutect2, Illumina Pisces, and Deepvariants to confirm the presence of SNP at position 41. Below is my result. . ![image](https://user-images.githubusercontent.com/24441131/65831442-65545a00-e287-11e9-8c55-8541a8ef3fce.png). I'm not sure what mistake I have made. Below is the set of commands I used to generate the vcf files from the 10% spiked-in sample. BIN_VERSION=""0.8.0"". docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode=calling \. --sample_name=RHA \. --examples=/tmpdir/make_examples.tfrecord.gz \. --ref=/home/RHA.fa \. --reads=/home/SNP-Cnt-10p_S7_L001_001.bam \. --gvcf=/tmpdir/gvcf.tfrecord.gztest.gv. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --checkpoint=/opt/models/wgs/model.ckpt \. --examples=/tmpdir/make_examples.tfrecord.gz \. --outfile=/tmpdir/call_variants_output.tfrecord.gz. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/postprocess_variants \. --ref=/home/RHA.fa \. --infile=/tmpdir/call_variants_output.tfrecord.gz \. --nonvariant_site_tfrecord_path=/tmpdir/gvcf.tfrecord.gztest.gv \. --outfile=/home/out.vcf \. --gvcf_outfile=/home/out.gvcf. Thanks for all your help. Azita.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:44,security,confidential,confidentially,44,"Thanks @samanvp - unfortunately, because of confidentially issues, we won't be able to use GCP . @pichuan - I managed to run the three scripts but am seeing a surprising result. We have sequenced a panel of control amplicons with spiked inputs containing SNP at position 41. I aligned the reads to the ref using bwa mem and filtered paired reads. Then I ran GATK Mutect2, Illumina Pisces, and Deepvariants to confirm the presence of SNP at position 41. Below is my result. . ![image](https://user-images.githubusercontent.com/24441131/65831442-65545a00-e287-11e9-8c55-8541a8ef3fce.png). I'm not sure what mistake I have made. Below is the set of commands I used to generate the vcf files from the 10% spiked-in sample. BIN_VERSION=""0.8.0"". docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode=calling \. --sample_name=RHA \. --examples=/tmpdir/make_examples.tfrecord.gz \. --ref=/home/RHA.fa \. --reads=/home/SNP-Cnt-10p_S7_L001_001.bam \. --gvcf=/tmpdir/gvcf.tfrecord.gztest.gv. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --checkpoint=/opt/models/wgs/model.ckpt \. --examples=/tmpdir/make_examples.tfrecord.gz \. --outfile=/tmpdir/call_variants_output.tfrecord.gz. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/postprocess_variants \. --ref=/home/RHA.fa \. --infile=/tmpdir/call_variants_output.tfrecord.gz \. --nonvariant_site_tfrecord_path=/tmpdir/gvcf.tfrecord.gztest.gv \. --outfile=/home/out.vcf \. --gvcf_outfile=/home/out.gvcf. Thanks for all your help. Azita.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:207,security,control,control,207,"Thanks @samanvp - unfortunately, because of confidentially issues, we won't be able to use GCP . @pichuan - I managed to run the three scripts but am seeing a surprising result. We have sequenced a panel of control amplicons with spiked inputs containing SNP at position 41. I aligned the reads to the ref using bwa mem and filtered paired reads. Then I ran GATK Mutect2, Illumina Pisces, and Deepvariants to confirm the presence of SNP at position 41. Below is my result. . ![image](https://user-images.githubusercontent.com/24441131/65831442-65545a00-e287-11e9-8c55-8541a8ef3fce.png). I'm not sure what mistake I have made. Below is the set of commands I used to generate the vcf files from the 10% spiked-in sample. BIN_VERSION=""0.8.0"". docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode=calling \. --sample_name=RHA \. --examples=/tmpdir/make_examples.tfrecord.gz \. --ref=/home/RHA.fa \. --reads=/home/SNP-Cnt-10p_S7_L001_001.bam \. --gvcf=/tmpdir/gvcf.tfrecord.gztest.gv. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --checkpoint=/opt/models/wgs/model.ckpt \. --examples=/tmpdir/make_examples.tfrecord.gz \. --outfile=/tmpdir/call_variants_output.tfrecord.gz. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/postprocess_variants \. --ref=/home/RHA.fa \. --infile=/tmpdir/call_variants_output.tfrecord.gz \. --nonvariant_site_tfrecord_path=/tmpdir/gvcf.tfrecord.gztest.gv \. --outfile=/home/out.vcf \. --gvcf_outfile=/home/out.gvcf. Thanks for all your help. Azita.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:1286,security,model,models,1286,"Thanks @samanvp - unfortunately, because of confidentially issues, we won't be able to use GCP . @pichuan - I managed to run the three scripts but am seeing a surprising result. We have sequenced a panel of control amplicons with spiked inputs containing SNP at position 41. I aligned the reads to the ref using bwa mem and filtered paired reads. Then I ran GATK Mutect2, Illumina Pisces, and Deepvariants to confirm the presence of SNP at position 41. Below is my result. . ![image](https://user-images.githubusercontent.com/24441131/65831442-65545a00-e287-11e9-8c55-8541a8ef3fce.png). I'm not sure what mistake I have made. Below is the set of commands I used to generate the vcf files from the 10% spiked-in sample. BIN_VERSION=""0.8.0"". docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode=calling \. --sample_name=RHA \. --examples=/tmpdir/make_examples.tfrecord.gz \. --ref=/home/RHA.fa \. --reads=/home/SNP-Cnt-10p_S7_L001_001.bam \. --gvcf=/tmpdir/gvcf.tfrecord.gztest.gv. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --checkpoint=/opt/models/wgs/model.ckpt \. --examples=/tmpdir/make_examples.tfrecord.gz \. --outfile=/tmpdir/call_variants_output.tfrecord.gz. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/postprocess_variants \. --ref=/home/RHA.fa \. --infile=/tmpdir/call_variants_output.tfrecord.gz \. --nonvariant_site_tfrecord_path=/tmpdir/gvcf.tfrecord.gztest.gv \. --outfile=/home/out.vcf \. --gvcf_outfile=/home/out.gvcf. Thanks for all your help. Azita.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:1297,security,model,model,1297,"Thanks @samanvp - unfortunately, because of confidentially issues, we won't be able to use GCP . @pichuan - I managed to run the three scripts but am seeing a surprising result. We have sequenced a panel of control amplicons with spiked inputs containing SNP at position 41. I aligned the reads to the ref using bwa mem and filtered paired reads. Then I ran GATK Mutect2, Illumina Pisces, and Deepvariants to confirm the presence of SNP at position 41. Below is my result. . ![image](https://user-images.githubusercontent.com/24441131/65831442-65545a00-e287-11e9-8c55-8541a8ef3fce.png). I'm not sure what mistake I have made. Below is the set of commands I used to generate the vcf files from the 10% spiked-in sample. BIN_VERSION=""0.8.0"". docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode=calling \. --sample_name=RHA \. --examples=/tmpdir/make_examples.tfrecord.gz \. --ref=/home/RHA.fa \. --reads=/home/SNP-Cnt-10p_S7_L001_001.bam \. --gvcf=/tmpdir/gvcf.tfrecord.gztest.gv. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --checkpoint=/opt/models/wgs/model.ckpt \. --examples=/tmpdir/make_examples.tfrecord.gz \. --outfile=/tmpdir/call_variants_output.tfrecord.gz. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/postprocess_variants \. --ref=/home/RHA.fa \. --infile=/tmpdir/call_variants_output.tfrecord.gz \. --nonvariant_site_tfrecord_path=/tmpdir/gvcf.tfrecord.gztest.gv \. --outfile=/home/out.vcf \. --gvcf_outfile=/home/out.gvcf. Thanks for all your help. Azita.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:207,testability,control,control,207,"Thanks @samanvp - unfortunately, because of confidentially issues, we won't be able to use GCP . @pichuan - I managed to run the three scripts but am seeing a surprising result. We have sequenced a panel of control amplicons with spiked inputs containing SNP at position 41. I aligned the reads to the ref using bwa mem and filtered paired reads. Then I ran GATK Mutect2, Illumina Pisces, and Deepvariants to confirm the presence of SNP at position 41. Below is my result. . ![image](https://user-images.githubusercontent.com/24441131/65831442-65545a00-e287-11e9-8c55-8541a8ef3fce.png). I'm not sure what mistake I have made. Below is the set of commands I used to generate the vcf files from the 10% spiked-in sample. BIN_VERSION=""0.8.0"". docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode=calling \. --sample_name=RHA \. --examples=/tmpdir/make_examples.tfrecord.gz \. --ref=/home/RHA.fa \. --reads=/home/SNP-Cnt-10p_S7_L001_001.bam \. --gvcf=/tmpdir/gvcf.tfrecord.gztest.gv. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --checkpoint=/opt/models/wgs/model.ckpt \. --examples=/tmpdir/make_examples.tfrecord.gz \. --outfile=/tmpdir/call_variants_output.tfrecord.gz. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/postprocess_variants \. --ref=/home/RHA.fa \. --infile=/tmpdir/call_variants_output.tfrecord.gz \. --nonvariant_site_tfrecord_path=/tmpdir/gvcf.tfrecord.gztest.gv \. --outfile=/home/out.vcf \. --gvcf_outfile=/home/out.gvcf. Thanks for all your help. Azita.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:237,usability,input,inputs,237,"Thanks @samanvp - unfortunately, because of confidentially issues, we won't be able to use GCP . @pichuan - I managed to run the three scripts but am seeing a surprising result. We have sequenced a panel of control amplicons with spiked inputs containing SNP at position 41. I aligned the reads to the ref using bwa mem and filtered paired reads. Then I ran GATK Mutect2, Illumina Pisces, and Deepvariants to confirm the presence of SNP at position 41. Below is my result. . ![image](https://user-images.githubusercontent.com/24441131/65831442-65545a00-e287-11e9-8c55-8541a8ef3fce.png). I'm not sure what mistake I have made. Below is the set of commands I used to generate the vcf files from the 10% spiked-in sample. BIN_VERSION=""0.8.0"". docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode=calling \. --sample_name=RHA \. --examples=/tmpdir/make_examples.tfrecord.gz \. --ref=/home/RHA.fa \. --reads=/home/SNP-Cnt-10p_S7_L001_001.bam \. --gvcf=/tmpdir/gvcf.tfrecord.gztest.gv. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --checkpoint=/opt/models/wgs/model.ckpt \. --examples=/tmpdir/make_examples.tfrecord.gz \. --outfile=/tmpdir/call_variants_output.tfrecord.gz. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/postprocess_variants \. --ref=/home/RHA.fa \. --infile=/tmpdir/call_variants_output.tfrecord.gz \. --nonvariant_site_tfrecord_path=/tmpdir/gvcf.tfrecord.gztest.gv \. --outfile=/home/out.vcf \. --gvcf_outfile=/home/out.gvcf. Thanks for all your help. Azita.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:409,usability,confirm,confirm,409,"Thanks @samanvp - unfortunately, because of confidentially issues, we won't be able to use GCP . @pichuan - I managed to run the three scripts but am seeing a surprising result. We have sequenced a panel of control amplicons with spiked inputs containing SNP at position 41. I aligned the reads to the ref using bwa mem and filtered paired reads. Then I ran GATK Mutect2, Illumina Pisces, and Deepvariants to confirm the presence of SNP at position 41. Below is my result. . ![image](https://user-images.githubusercontent.com/24441131/65831442-65545a00-e287-11e9-8c55-8541a8ef3fce.png). I'm not sure what mistake I have made. Below is the set of commands I used to generate the vcf files from the 10% spiked-in sample. BIN_VERSION=""0.8.0"". docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode=calling \. --sample_name=RHA \. --examples=/tmpdir/make_examples.tfrecord.gz \. --ref=/home/RHA.fa \. --reads=/home/SNP-Cnt-10p_S7_L001_001.bam \. --gvcf=/tmpdir/gvcf.tfrecord.gztest.gv. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --checkpoint=/opt/models/wgs/model.ckpt \. --examples=/tmpdir/make_examples.tfrecord.gz \. --outfile=/tmpdir/call_variants_output.tfrecord.gz. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/postprocess_variants \. --ref=/home/RHA.fa \. --infile=/tmpdir/call_variants_output.tfrecord.gz \. --nonvariant_site_tfrecord_path=/tmpdir/gvcf.tfrecord.gztest.gv \. --outfile=/home/out.vcf \. --gvcf_outfile=/home/out.gvcf. Thanks for all your help. Azita.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:492,usability,user,user-images,492,"Thanks @samanvp - unfortunately, because of confidentially issues, we won't be able to use GCP . @pichuan - I managed to run the three scripts but am seeing a surprising result. We have sequenced a panel of control amplicons with spiked inputs containing SNP at position 41. I aligned the reads to the ref using bwa mem and filtered paired reads. Then I ran GATK Mutect2, Illumina Pisces, and Deepvariants to confirm the presence of SNP at position 41. Below is my result. . ![image](https://user-images.githubusercontent.com/24441131/65831442-65545a00-e287-11e9-8c55-8541a8ef3fce.png). I'm not sure what mistake I have made. Below is the set of commands I used to generate the vcf files from the 10% spiked-in sample. BIN_VERSION=""0.8.0"". docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode=calling \. --sample_name=RHA \. --examples=/tmpdir/make_examples.tfrecord.gz \. --ref=/home/RHA.fa \. --reads=/home/SNP-Cnt-10p_S7_L001_001.bam \. --gvcf=/tmpdir/gvcf.tfrecord.gztest.gv. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --checkpoint=/opt/models/wgs/model.ckpt \. --examples=/tmpdir/make_examples.tfrecord.gz \. --outfile=/tmpdir/call_variants_output.tfrecord.gz. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/postprocess_variants \. --ref=/home/RHA.fa \. --infile=/tmpdir/call_variants_output.tfrecord.gz \. --nonvariant_site_tfrecord_path=/tmpdir/gvcf.tfrecord.gztest.gv \. --outfile=/home/out.vcf \. --gvcf_outfile=/home/out.gvcf. Thanks for all your help. Azita.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:646,usability,command,commands,646,"Thanks @samanvp - unfortunately, because of confidentially issues, we won't be able to use GCP . @pichuan - I managed to run the three scripts but am seeing a surprising result. We have sequenced a panel of control amplicons with spiked inputs containing SNP at position 41. I aligned the reads to the ref using bwa mem and filtered paired reads. Then I ran GATK Mutect2, Illumina Pisces, and Deepvariants to confirm the presence of SNP at position 41. Below is my result. . ![image](https://user-images.githubusercontent.com/24441131/65831442-65545a00-e287-11e9-8c55-8541a8ef3fce.png). I'm not sure what mistake I have made. Below is the set of commands I used to generate the vcf files from the 10% spiked-in sample. BIN_VERSION=""0.8.0"". docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode=calling \. --sample_name=RHA \. --examples=/tmpdir/make_examples.tfrecord.gz \. --ref=/home/RHA.fa \. --reads=/home/SNP-Cnt-10p_S7_L001_001.bam \. --gvcf=/tmpdir/gvcf.tfrecord.gztest.gv. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --checkpoint=/opt/models/wgs/model.ckpt \. --examples=/tmpdir/make_examples.tfrecord.gz \. --outfile=/tmpdir/call_variants_output.tfrecord.gz. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/postprocess_variants \. --ref=/home/RHA.fa \. --infile=/tmpdir/call_variants_output.tfrecord.gz \. --nonvariant_site_tfrecord_path=/tmpdir/gvcf.tfrecord.gztest.gv \. --outfile=/home/out.vcf \. --gvcf_outfile=/home/out.gvcf. Thanks for all your help. Azita.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:1805,usability,help,help,1805,"Thanks @samanvp - unfortunately, because of confidentially issues, we won't be able to use GCP . @pichuan - I managed to run the three scripts but am seeing a surprising result. We have sequenced a panel of control amplicons with spiked inputs containing SNP at position 41. I aligned the reads to the ref using bwa mem and filtered paired reads. Then I ran GATK Mutect2, Illumina Pisces, and Deepvariants to confirm the presence of SNP at position 41. Below is my result. . ![image](https://user-images.githubusercontent.com/24441131/65831442-65545a00-e287-11e9-8c55-8541a8ef3fce.png). I'm not sure what mistake I have made. Below is the set of commands I used to generate the vcf files from the 10% spiked-in sample. BIN_VERSION=""0.8.0"". docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/make_examples \. --mode=calling \. --sample_name=RHA \. --examples=/tmpdir/make_examples.tfrecord.gz \. --ref=/home/RHA.fa \. --reads=/home/SNP-Cnt-10p_S7_L001_001.bam \. --gvcf=/tmpdir/gvcf.tfrecord.gztest.gv. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --checkpoint=/opt/models/wgs/model.ckpt \. --examples=/tmpdir/make_examples.tfrecord.gz \. --outfile=/tmpdir/call_variants_output.tfrecord.gz. docker run \. -v ""${HOME_DIR}"":""/home"" \. -v ""${TMP_DIR}"":""/tmpdir"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/postprocess_variants \. --ref=/home/RHA.fa \. --infile=/tmpdir/call_variants_output.tfrecord.gz \. --nonvariant_site_tfrecord_path=/tmpdir/gvcf.tfrecord.gztest.gv \. --outfile=/home/out.vcf \. --gvcf_outfile=/home/out.gvcf. Thanks for all your help. Azita.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:757,availability,avail,available,757,"Hi @anitagh . Thank you for putting effort into detailed analyses. However, there is a key mistake. DeepVariant is not a somatic caller. It is not designed to detect subclonal variants. In the same way that for GATK you would not use HaplotypeCaller, you would use a different tool, Mutect2, you would not use DeepVariant for this problem. Before DeepVariant's neural net, there is a human-written candidate generation component which finds candidate positions. There is a threshold for this to even nominate a candidate for later classification. This is set to 12% (based on tuning for germline calling), so we would not expect that DeepVariant would nominate a 10% mix as candidates. . We do have a somatic calling tool in early access that we are making available to trusted partners. If you would be interested in that method, you can email me (awcarroll@google.com). Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:166,integrability,sub,subclonal,166,"Hi @anitagh . Thank you for putting effort into detailed analyses. However, there is a key mistake. DeepVariant is not a somatic caller. It is not designed to detect subclonal variants. In the same way that for GATK you would not use HaplotypeCaller, you would use a different tool, Mutect2, you would not use DeepVariant for this problem. Before DeepVariant's neural net, there is a human-written candidate generation component which finds candidate positions. There is a threshold for this to even nominate a candidate for later classification. This is set to 12% (based on tuning for germline calling), so we would not expect that DeepVariant would nominate a 10% mix as candidates. . We do have a somatic calling tool in early access that we are making available to trusted partners. If you would be interested in that method, you can email me (awcarroll@google.com). Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:419,integrability,compon,component,419,"Hi @anitagh . Thank you for putting effort into detailed analyses. However, there is a key mistake. DeepVariant is not a somatic caller. It is not designed to detect subclonal variants. In the same way that for GATK you would not use HaplotypeCaller, you would use a different tool, Mutect2, you would not use DeepVariant for this problem. Before DeepVariant's neural net, there is a human-written candidate generation component which finds candidate positions. There is a threshold for this to even nominate a candidate for later classification. This is set to 12% (based on tuning for germline calling), so we would not expect that DeepVariant would nominate a 10% mix as candidates. . We do have a somatic calling tool in early access that we are making available to trusted partners. If you would be interested in that method, you can email me (awcarroll@google.com). Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:419,interoperability,compon,component,419,"Hi @anitagh . Thank you for putting effort into detailed analyses. However, there is a key mistake. DeepVariant is not a somatic caller. It is not designed to detect subclonal variants. In the same way that for GATK you would not use HaplotypeCaller, you would use a different tool, Mutect2, you would not use DeepVariant for this problem. Before DeepVariant's neural net, there is a human-written candidate generation component which finds candidate positions. There is a threshold for this to even nominate a candidate for later classification. This is set to 12% (based on tuning for germline calling), so we would not expect that DeepVariant would nominate a 10% mix as candidates. . We do have a somatic calling tool in early access that we are making available to trusted partners. If you would be interested in that method, you can email me (awcarroll@google.com). Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:419,modifiability,compon,component,419,"Hi @anitagh . Thank you for putting effort into detailed analyses. However, there is a key mistake. DeepVariant is not a somatic caller. It is not designed to detect subclonal variants. In the same way that for GATK you would not use HaplotypeCaller, you would use a different tool, Mutect2, you would not use DeepVariant for this problem. Before DeepVariant's neural net, there is a human-written candidate generation component which finds candidate positions. There is a threshold for this to even nominate a candidate for later classification. This is set to 12% (based on tuning for germline calling), so we would not expect that DeepVariant would nominate a 10% mix as candidates. . We do have a somatic calling tool in early access that we are making available to trusted partners. If you would be interested in that method, you can email me (awcarroll@google.com). Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:757,reliability,availab,available,757,"Hi @anitagh . Thank you for putting effort into detailed analyses. However, there is a key mistake. DeepVariant is not a somatic caller. It is not designed to detect subclonal variants. In the same way that for GATK you would not use HaplotypeCaller, you would use a different tool, Mutect2, you would not use DeepVariant for this problem. Before DeepVariant's neural net, there is a human-written candidate generation component which finds candidate positions. There is a threshold for this to even nominate a candidate for later classification. This is set to 12% (based on tuning for germline calling), so we would not expect that DeepVariant would nominate a 10% mix as candidates. . We do have a somatic calling tool in early access that we are making available to trusted partners. If you would be interested in that method, you can email me (awcarroll@google.com). Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:159,safety,detect,detect,159,"Hi @anitagh . Thank you for putting effort into detailed analyses. However, there is a key mistake. DeepVariant is not a somatic caller. It is not designed to detect subclonal variants. In the same way that for GATK you would not use HaplotypeCaller, you would use a different tool, Mutect2, you would not use DeepVariant for this problem. Before DeepVariant's neural net, there is a human-written candidate generation component which finds candidate positions. There is a threshold for this to even nominate a candidate for later classification. This is set to 12% (based on tuning for germline calling), so we would not expect that DeepVariant would nominate a 10% mix as candidates. . We do have a somatic calling tool in early access that we are making available to trusted partners. If you would be interested in that method, you can email me (awcarroll@google.com). Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:757,safety,avail,available,757,"Hi @anitagh . Thank you for putting effort into detailed analyses. However, there is a key mistake. DeepVariant is not a somatic caller. It is not designed to detect subclonal variants. In the same way that for GATK you would not use HaplotypeCaller, you would use a different tool, Mutect2, you would not use DeepVariant for this problem. Before DeepVariant's neural net, there is a human-written candidate generation component which finds candidate positions. There is a threshold for this to even nominate a candidate for later classification. This is set to 12% (based on tuning for germline calling), so we would not expect that DeepVariant would nominate a 10% mix as candidates. . We do have a somatic calling tool in early access that we are making available to trusted partners. If you would be interested in that method, you can email me (awcarroll@google.com). Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:159,security,detect,detect,159,"Hi @anitagh . Thank you for putting effort into detailed analyses. However, there is a key mistake. DeepVariant is not a somatic caller. It is not designed to detect subclonal variants. In the same way that for GATK you would not use HaplotypeCaller, you would use a different tool, Mutect2, you would not use DeepVariant for this problem. Before DeepVariant's neural net, there is a human-written candidate generation component which finds candidate positions. There is a threshold for this to even nominate a candidate for later classification. This is set to 12% (based on tuning for germline calling), so we would not expect that DeepVariant would nominate a 10% mix as candidates. . We do have a somatic calling tool in early access that we are making available to trusted partners. If you would be interested in that method, you can email me (awcarroll@google.com). Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:731,security,access,access,731,"Hi @anitagh . Thank you for putting effort into detailed analyses. However, there is a key mistake. DeepVariant is not a somatic caller. It is not designed to detect subclonal variants. In the same way that for GATK you would not use HaplotypeCaller, you would use a different tool, Mutect2, you would not use DeepVariant for this problem. Before DeepVariant's neural net, there is a human-written candidate generation component which finds candidate positions. There is a threshold for this to even nominate a candidate for later classification. This is set to 12% (based on tuning for germline calling), so we would not expect that DeepVariant would nominate a 10% mix as candidates. . We do have a somatic calling tool in early access that we are making available to trusted partners. If you would be interested in that method, you can email me (awcarroll@google.com). Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:757,security,availab,available,757,"Hi @anitagh . Thank you for putting effort into detailed analyses. However, there is a key mistake. DeepVariant is not a somatic caller. It is not designed to detect subclonal variants. In the same way that for GATK you would not use HaplotypeCaller, you would use a different tool, Mutect2, you would not use DeepVariant for this problem. Before DeepVariant's neural net, there is a human-written candidate generation component which finds candidate positions. There is a threshold for this to even nominate a candidate for later classification. This is set to 12% (based on tuning for germline calling), so we would not expect that DeepVariant would nominate a 10% mix as candidates. . We do have a somatic calling tool in early access that we are making available to trusted partners. If you would be interested in that method, you can email me (awcarroll@google.com). Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:770,security,trust,trusted,770,"Hi @anitagh . Thank you for putting effort into detailed analyses. However, there is a key mistake. DeepVariant is not a somatic caller. It is not designed to detect subclonal variants. In the same way that for GATK you would not use HaplotypeCaller, you would use a different tool, Mutect2, you would not use DeepVariant for this problem. Before DeepVariant's neural net, there is a human-written candidate generation component which finds candidate positions. There is a threshold for this to even nominate a candidate for later classification. This is set to 12% (based on tuning for germline calling), so we would not expect that DeepVariant would nominate a 10% mix as candidates. . We do have a somatic calling tool in early access that we are making available to trusted partners. If you would be interested in that method, you can email me (awcarroll@google.com). Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:277,usability,tool,tool,277,"Hi @anitagh . Thank you for putting effort into detailed analyses. However, there is a key mistake. DeepVariant is not a somatic caller. It is not designed to detect subclonal variants. In the same way that for GATK you would not use HaplotypeCaller, you would use a different tool, Mutect2, you would not use DeepVariant for this problem. Before DeepVariant's neural net, there is a human-written candidate generation component which finds candidate positions. There is a threshold for this to even nominate a candidate for later classification. This is set to 12% (based on tuning for germline calling), so we would not expect that DeepVariant would nominate a 10% mix as candidates. . We do have a somatic calling tool in early access that we are making available to trusted partners. If you would be interested in that method, you can email me (awcarroll@google.com). Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:717,usability,tool,tool,717,"Hi @anitagh . Thank you for putting effort into detailed analyses. However, there is a key mistake. DeepVariant is not a somatic caller. It is not designed to detect subclonal variants. In the same way that for GATK you would not use HaplotypeCaller, you would use a different tool, Mutect2, you would not use DeepVariant for this problem. Before DeepVariant's neural net, there is a human-written candidate generation component which finds candidate positions. There is a threshold for this to even nominate a candidate for later classification. This is set to 12% (based on tuning for germline calling), so we would not expect that DeepVariant would nominate a 10% mix as candidates. . We do have a somatic calling tool in early access that we are making available to trusted partners. If you would be interested in that method, you can email me (awcarroll@google.com). Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:77,usability,tool,tool,77,"Thanks @AndrewCarroll. I'm interested in trying out your new somatic calling tool. I'll contact you shortly. . Thanks so much, . Azita.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:263,availability,robust,robust,263,"Hi @anitagh , I want to give you an update that after today's release (v0.9.0), you can now use the `--sample_name` flag with run_deepvariant.py:. https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py#L89. And, we also made the behavior more robust so that even with multiple or no sample names, we'll try to assign a reasonable default, and proceed with a warning (but without crashing). If you have more questions please feel free to follow up here, or file new issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:36,deployability,updat,update,36,"Hi @anitagh , I want to give you an update that after today's release (v0.9.0), you can now use the `--sample_name` flag with run_deepvariant.py:. https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py#L89. And, we also made the behavior more robust so that even with multiple or no sample names, we'll try to assign a reasonable default, and proceed with a warning (but without crashing). If you have more questions please feel free to follow up here, or file new issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:62,deployability,releas,release,62,"Hi @anitagh , I want to give you an update that after today's release (v0.9.0), you can now use the `--sample_name` flag with run_deepvariant.py:. https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py#L89. And, we also made the behavior more robust so that even with multiple or no sample names, we'll try to assign a reasonable default, and proceed with a warning (but without crashing). If you have more questions please feel free to follow up here, or file new issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:263,reliability,robust,robust,263,"Hi @anitagh , I want to give you an update that after today's release (v0.9.0), you can now use the `--sample_name` flag with run_deepvariant.py:. https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py#L89. And, we also made the behavior more robust so that even with multiple or no sample names, we'll try to assign a reasonable default, and proceed with a warning (but without crashing). If you have more questions please feel free to follow up here, or file new issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:36,safety,updat,update,36,"Hi @anitagh , I want to give you an update that after today's release (v0.9.0), you can now use the `--sample_name` flag with run_deepvariant.py:. https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py#L89. And, we also made the behavior more robust so that even with multiple or no sample names, we'll try to assign a reasonable default, and proceed with a warning (but without crashing). If you have more questions please feel free to follow up here, or file new issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:263,safety,robust,robust,263,"Hi @anitagh , I want to give you an update that after today's release (v0.9.0), you can now use the `--sample_name` flag with run_deepvariant.py:. https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py#L89. And, we also made the behavior more robust so that even with multiple or no sample names, we'll try to assign a reasonable default, and proceed with a warning (but without crashing). If you have more questions please feel free to follow up here, or file new issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:36,security,updat,update,36,"Hi @anitagh , I want to give you an update that after today's release (v0.9.0), you can now use the `--sample_name` flag with run_deepvariant.py:. https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py#L89. And, we also made the behavior more robust so that even with multiple or no sample names, we'll try to assign a reasonable default, and proceed with a warning (but without crashing). If you have more questions please feel free to follow up here, or file new issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/222:249,usability,behavi,behavior,249,"Hi @anitagh , I want to give you an update that after today's release (v0.9.0), you can now use the `--sample_name` flag with run_deepvariant.py:. https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py#L89. And, we also made the behavior more robust so that even with multiple or no sample names, we'll try to assign a reasonable default, and proceed with a warning (but without crashing). If you have more questions please feel free to follow up here, or file new issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/222
https://github.com/google/deepvariant/issues/223:130,safety,input,input,130,"Thanks @rogeriobioinfo for a detailed report. I was able to run with your setup, and. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. ```. works for me as well. As @weisystak suggested, can you check for the invisible char and try again? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:295,safety,input,input,295,"Thanks @rogeriobioinfo for a detailed report. I was able to run with your setup, and. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. ```. works for me as well. As @weisystak suggested, can you check for the invisible char and try again? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:344,safety,input,input,344,"Thanks @rogeriobioinfo for a detailed report. I was able to run with your setup, and. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. ```. works for me as well. As @weisystak suggested, can you check for the invisible char and try again? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:317,testability,unit,unittest,317,"Thanks @rogeriobioinfo for a detailed report. I was able to run with your setup, and. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. ```. works for me as well. As @weisystak suggested, can you check for the invisible char and try again? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:130,usability,input,input,130,"Thanks @rogeriobioinfo for a detailed report. I was able to run with your setup, and. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. ```. works for me as well. As @weisystak suggested, can you check for the invisible char and try again? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:295,usability,input,input,295,"Thanks @rogeriobioinfo for a detailed report. I was able to run with your setup, and. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. ```. works for me as well. As @weisystak suggested, can you check for the invisible char and try again? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:344,usability,input,input,344,"Thanks @rogeriobioinfo for a detailed report. I was able to run with your setup, and. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --num_shards=1. ```. works for me as well. As @weisystak suggested, can you check for the invisible char and try again? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/223:60,usability,command,command,60,"Dears, . I eliminate all ""\"" and ran the script in a single command line, it works now. thanks a lot",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/223
https://github.com/google/deepvariant/issues/224:175,availability,avail,available,175,"Hi @anands-repo . The major factor was the length of chromosomes, selecting sizes that would allow enough data for comparison of tune and test while still maximizing the data available for training. The tuning and test chromosomes should also be roughly representative of the overall genome content. There are some chromosomes that should probably be avoided for tune or test choices - specifically ones that have regions quite different from the rest of the genome. Chromosome 6 is an example, since it contains the MHC regions. So it is mostly arbitrary, though other methods such as Clairvoyante seem to have adopted the convention as well. It is nice for the choices to align, since it allows comparisons with the same regions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:504,deployability,contain,contains,504,"Hi @anands-repo . The major factor was the length of chromosomes, selecting sizes that would allow enough data for comparison of tune and test while still maximizing the data available for training. The tuning and test chromosomes should also be roughly representative of the overall genome content. There are some chromosomes that should probably be avoided for tune or test choices - specifically ones that have regions quite different from the rest of the genome. Chromosome 6 is an example, since it contains the MHC regions. So it is mostly arbitrary, though other methods such as Clairvoyante seem to have adopted the convention as well. It is nice for the choices to align, since it allows comparisons with the same regions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:386,interoperability,specif,specifically,386,"Hi @anands-repo . The major factor was the length of chromosomes, selecting sizes that would allow enough data for comparison of tune and test while still maximizing the data available for training. The tuning and test chromosomes should also be roughly representative of the overall genome content. There are some chromosomes that should probably be avoided for tune or test choices - specifically ones that have regions quite different from the rest of the genome. Chromosome 6 is an example, since it contains the MHC regions. So it is mostly arbitrary, though other methods such as Clairvoyante seem to have adopted the convention as well. It is nice for the choices to align, since it allows comparisons with the same regions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:129,performance,tune,tune,129,"Hi @anands-repo . The major factor was the length of chromosomes, selecting sizes that would allow enough data for comparison of tune and test while still maximizing the data available for training. The tuning and test chromosomes should also be roughly representative of the overall genome content. There are some chromosomes that should probably be avoided for tune or test choices - specifically ones that have regions quite different from the rest of the genome. Chromosome 6 is an example, since it contains the MHC regions. So it is mostly arbitrary, though other methods such as Clairvoyante seem to have adopted the convention as well. It is nice for the choices to align, since it allows comparisons with the same regions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:291,performance,content,content,291,"Hi @anands-repo . The major factor was the length of chromosomes, selecting sizes that would allow enough data for comparison of tune and test while still maximizing the data available for training. The tuning and test chromosomes should also be roughly representative of the overall genome content. There are some chromosomes that should probably be avoided for tune or test choices - specifically ones that have regions quite different from the rest of the genome. Chromosome 6 is an example, since it contains the MHC regions. So it is mostly arbitrary, though other methods such as Clairvoyante seem to have adopted the convention as well. It is nice for the choices to align, since it allows comparisons with the same regions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:363,performance,tune,tune,363,"Hi @anands-repo . The major factor was the length of chromosomes, selecting sizes that would allow enough data for comparison of tune and test while still maximizing the data available for training. The tuning and test chromosomes should also be roughly representative of the overall genome content. There are some chromosomes that should probably be avoided for tune or test choices - specifically ones that have regions quite different from the rest of the genome. Chromosome 6 is an example, since it contains the MHC regions. So it is mostly arbitrary, though other methods such as Clairvoyante seem to have adopted the convention as well. It is nice for the choices to align, since it allows comparisons with the same regions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:175,reliability,availab,available,175,"Hi @anands-repo . The major factor was the length of chromosomes, selecting sizes that would allow enough data for comparison of tune and test while still maximizing the data available for training. The tuning and test chromosomes should also be roughly representative of the overall genome content. There are some chromosomes that should probably be avoided for tune or test choices - specifically ones that have regions quite different from the rest of the genome. Chromosome 6 is an example, since it contains the MHC regions. So it is mostly arbitrary, though other methods such as Clairvoyante seem to have adopted the convention as well. It is nice for the choices to align, since it allows comparisons with the same regions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:138,safety,test,test,138,"Hi @anands-repo . The major factor was the length of chromosomes, selecting sizes that would allow enough data for comparison of tune and test while still maximizing the data available for training. The tuning and test chromosomes should also be roughly representative of the overall genome content. There are some chromosomes that should probably be avoided for tune or test choices - specifically ones that have regions quite different from the rest of the genome. Chromosome 6 is an example, since it contains the MHC regions. So it is mostly arbitrary, though other methods such as Clairvoyante seem to have adopted the convention as well. It is nice for the choices to align, since it allows comparisons with the same regions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:175,safety,avail,available,175,"Hi @anands-repo . The major factor was the length of chromosomes, selecting sizes that would allow enough data for comparison of tune and test while still maximizing the data available for training. The tuning and test chromosomes should also be roughly representative of the overall genome content. There are some chromosomes that should probably be avoided for tune or test choices - specifically ones that have regions quite different from the rest of the genome. Chromosome 6 is an example, since it contains the MHC regions. So it is mostly arbitrary, though other methods such as Clairvoyante seem to have adopted the convention as well. It is nice for the choices to align, since it allows comparisons with the same regions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:214,safety,test,test,214,"Hi @anands-repo . The major factor was the length of chromosomes, selecting sizes that would allow enough data for comparison of tune and test while still maximizing the data available for training. The tuning and test chromosomes should also be roughly representative of the overall genome content. There are some chromosomes that should probably be avoided for tune or test choices - specifically ones that have regions quite different from the rest of the genome. Chromosome 6 is an example, since it contains the MHC regions. So it is mostly arbitrary, though other methods such as Clairvoyante seem to have adopted the convention as well. It is nice for the choices to align, since it allows comparisons with the same regions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:351,safety,avoid,avoided,351,"Hi @anands-repo . The major factor was the length of chromosomes, selecting sizes that would allow enough data for comparison of tune and test while still maximizing the data available for training. The tuning and test chromosomes should also be roughly representative of the overall genome content. There are some chromosomes that should probably be avoided for tune or test choices - specifically ones that have regions quite different from the rest of the genome. Chromosome 6 is an example, since it contains the MHC regions. So it is mostly arbitrary, though other methods such as Clairvoyante seem to have adopted the convention as well. It is nice for the choices to align, since it allows comparisons with the same regions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:371,safety,test,test,371,"Hi @anands-repo . The major factor was the length of chromosomes, selecting sizes that would allow enough data for comparison of tune and test while still maximizing the data available for training. The tuning and test chromosomes should also be roughly representative of the overall genome content. There are some chromosomes that should probably be avoided for tune or test choices - specifically ones that have regions quite different from the rest of the genome. Chromosome 6 is an example, since it contains the MHC regions. So it is mostly arbitrary, though other methods such as Clairvoyante seem to have adopted the convention as well. It is nice for the choices to align, since it allows comparisons with the same regions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:175,security,availab,available,175,"Hi @anands-repo . The major factor was the length of chromosomes, selecting sizes that would allow enough data for comparison of tune and test while still maximizing the data available for training. The tuning and test chromosomes should also be roughly representative of the overall genome content. There are some chromosomes that should probably be avoided for tune or test choices - specifically ones that have regions quite different from the rest of the genome. Chromosome 6 is an example, since it contains the MHC regions. So it is mostly arbitrary, though other methods such as Clairvoyante seem to have adopted the convention as well. It is nice for the choices to align, since it allows comparisons with the same regions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:138,testability,test,test,138,"Hi @anands-repo . The major factor was the length of chromosomes, selecting sizes that would allow enough data for comparison of tune and test while still maximizing the data available for training. The tuning and test chromosomes should also be roughly representative of the overall genome content. There are some chromosomes that should probably be avoided for tune or test choices - specifically ones that have regions quite different from the rest of the genome. Chromosome 6 is an example, since it contains the MHC regions. So it is mostly arbitrary, though other methods such as Clairvoyante seem to have adopted the convention as well. It is nice for the choices to align, since it allows comparisons with the same regions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:214,testability,test,test,214,"Hi @anands-repo . The major factor was the length of chromosomes, selecting sizes that would allow enough data for comparison of tune and test while still maximizing the data available for training. The tuning and test chromosomes should also be roughly representative of the overall genome content. There are some chromosomes that should probably be avoided for tune or test choices - specifically ones that have regions quite different from the rest of the genome. Chromosome 6 is an example, since it contains the MHC regions. So it is mostly arbitrary, though other methods such as Clairvoyante seem to have adopted the convention as well. It is nice for the choices to align, since it allows comparisons with the same regions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/224:371,testability,test,test,371,"Hi @anands-repo . The major factor was the length of chromosomes, selecting sizes that would allow enough data for comparison of tune and test while still maximizing the data available for training. The tuning and test chromosomes should also be roughly representative of the overall genome content. There are some chromosomes that should probably be avoided for tune or test choices - specifically ones that have regions quite different from the rest of the genome. Chromosome 6 is an example, since it contains the MHC regions. So it is mostly arbitrary, though other methods such as Clairvoyante seem to have adopted the convention as well. It is nice for the choices to align, since it allows comparisons with the same regions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/224
https://github.com/google/deepvariant/issues/225:30,safety,input,input,30,Contig names in reference and input BAM files have to match. What happened is basically no common contigs between reference and BAM were found.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/225:30,usability,input,input,30,Contig names in reference and input BAM files have to match. What happened is basically no common contigs between reference and BAM were found.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/225
https://github.com/google/deepvariant/issues/226:19,usability,close,close,19,"@ccartermices I'll close this issue for now, but feel free to reopen if you have any other questions. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/226
https://github.com/google/deepvariant/issues/227:125,deployability,API,API,125,"Hi @jackycsie, there is currently no way to run `call_variants` on multiple GPUs. The codebase uses the TensorFlow Estimator API, which does not support prediction using multiple GPUs.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/227
https://github.com/google/deepvariant/issues/227:24,energy efficiency,current,currently,24,"Hi @jackycsie, there is currently no way to run `call_variants` on multiple GPUs. The codebase uses the TensorFlow Estimator API, which does not support prediction using multiple GPUs.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/227
https://github.com/google/deepvariant/issues/227:76,energy efficiency,GPU,GPUs,76,"Hi @jackycsie, there is currently no way to run `call_variants` on multiple GPUs. The codebase uses the TensorFlow Estimator API, which does not support prediction using multiple GPUs.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/227
https://github.com/google/deepvariant/issues/227:115,energy efficiency,Estimat,Estimator,115,"Hi @jackycsie, there is currently no way to run `call_variants` on multiple GPUs. The codebase uses the TensorFlow Estimator API, which does not support prediction using multiple GPUs.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/227
https://github.com/google/deepvariant/issues/227:153,energy efficiency,predict,prediction,153,"Hi @jackycsie, there is currently no way to run `call_variants` on multiple GPUs. The codebase uses the TensorFlow Estimator API, which does not support prediction using multiple GPUs.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/227
https://github.com/google/deepvariant/issues/227:179,energy efficiency,GPU,GPUs,179,"Hi @jackycsie, there is currently no way to run `call_variants` on multiple GPUs. The codebase uses the TensorFlow Estimator API, which does not support prediction using multiple GPUs.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/227
https://github.com/google/deepvariant/issues/227:125,integrability,API,API,125,"Hi @jackycsie, there is currently no way to run `call_variants` on multiple GPUs. The codebase uses the TensorFlow Estimator API, which does not support prediction using multiple GPUs.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/227
https://github.com/google/deepvariant/issues/227:125,interoperability,API,API,125,"Hi @jackycsie, there is currently no way to run `call_variants` on multiple GPUs. The codebase uses the TensorFlow Estimator API, which does not support prediction using multiple GPUs.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/227
https://github.com/google/deepvariant/issues/227:76,performance,GPU,GPUs,76,"Hi @jackycsie, there is currently no way to run `call_variants` on multiple GPUs. The codebase uses the TensorFlow Estimator API, which does not support prediction using multiple GPUs.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/227
https://github.com/google/deepvariant/issues/227:179,performance,GPU,GPUs,179,"Hi @jackycsie, there is currently no way to run `call_variants` on multiple GPUs. The codebase uses the TensorFlow Estimator API, which does not support prediction using multiple GPUs.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/227
https://github.com/google/deepvariant/issues/227:136,reliability,doe,does,136,"Hi @jackycsie, there is currently no way to run `call_variants` on multiple GPUs. The codebase uses the TensorFlow Estimator API, which does not support prediction using multiple GPUs.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/227
https://github.com/google/deepvariant/issues/227:153,safety,predict,prediction,153,"Hi @jackycsie, there is currently no way to run `call_variants` on multiple GPUs. The codebase uses the TensorFlow Estimator API, which does not support prediction using multiple GPUs.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/227
https://github.com/google/deepvariant/issues/227:145,usability,support,support,145,"Hi @jackycsie, there is currently no way to run `call_variants` on multiple GPUs. The codebase uses the TensorFlow Estimator API, which does not support prediction using multiple GPUs.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/227
https://github.com/google/deepvariant/issues/228:55,modifiability,pac,package,55,Hi @ydLiu-HIT . I'll add @chapmanb (owner of the conda package) to this thread and see if he can provide some support here. Thanks!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:110,usability,support,support,110,Hi @ydLiu-HIT . I'll add @chapmanb (owner of the conda package) to this thread and see if he can provide some support here. Thanks!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:91,availability,down,download,91,"Thanks for the question and sorry about these issues. It seems like there was some kind of download issue with the deepvariant conda package in your environment. The 0.8.0 package has been around ~6 months and not changed recently, so I'm guessing maybe you got a partial download or other issue. If you remove your local download (` /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2`) and re-run, does it work cleanly? Is there anything about your network or other messages that might indicate an issue that could help us debug more? Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:272,availability,down,download,272,"Thanks for the question and sorry about these issues. It seems like there was some kind of download issue with the deepvariant conda package in your environment. The 0.8.0 package has been around ~6 months and not changed recently, so I'm guessing maybe you got a partial download or other issue. If you remove your local download (` /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2`) and re-run, does it work cleanly? Is there anything about your network or other messages that might indicate an issue that could help us debug more? Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:322,availability,down,download,322,"Thanks for the question and sorry about these issues. It seems like there was some kind of download issue with the deepvariant conda package in your environment. The 0.8.0 package has been around ~6 months and not changed recently, so I'm guessing maybe you got a partial download or other issue. If you remove your local download (` /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2`) and re-run, does it work cleanly? Is there anything about your network or other messages that might indicate an issue that could help us debug more? Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:484,integrability,messag,messages,484,"Thanks for the question and sorry about these issues. It seems like there was some kind of download issue with the deepvariant conda package in your environment. The 0.8.0 package has been around ~6 months and not changed recently, so I'm guessing maybe you got a partial download or other issue. If you remove your local download (` /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2`) and re-run, does it work cleanly? Is there anything about your network or other messages that might indicate an issue that could help us debug more? Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:484,interoperability,messag,messages,484,"Thanks for the question and sorry about these issues. It seems like there was some kind of download issue with the deepvariant conda package in your environment. The 0.8.0 package has been around ~6 months and not changed recently, so I'm guessing maybe you got a partial download or other issue. If you remove your local download (` /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2`) and re-run, does it work cleanly? Is there anything about your network or other messages that might indicate an issue that could help us debug more? Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:133,modifiability,pac,package,133,"Thanks for the question and sorry about these issues. It seems like there was some kind of download issue with the deepvariant conda package in your environment. The 0.8.0 package has been around ~6 months and not changed recently, so I'm guessing maybe you got a partial download or other issue. If you remove your local download (` /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2`) and re-run, does it work cleanly? Is there anything about your network or other messages that might indicate an issue that could help us debug more? Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:172,modifiability,pac,package,172,"Thanks for the question and sorry about these issues. It seems like there was some kind of download issue with the deepvariant conda package in your environment. The 0.8.0 package has been around ~6 months and not changed recently, so I'm guessing maybe you got a partial download or other issue. If you remove your local download (` /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2`) and re-run, does it work cleanly? Is there anything about your network or other messages that might indicate an issue that could help us debug more? Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:467,performance,network,network,467,"Thanks for the question and sorry about these issues. It seems like there was some kind of download issue with the deepvariant conda package in your environment. The 0.8.0 package has been around ~6 months and not changed recently, so I'm guessing maybe you got a partial download or other issue. If you remove your local download (` /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2`) and re-run, does it work cleanly? Is there anything about your network or other messages that might indicate an issue that could help us debug more? Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:416,reliability,doe,does,416,"Thanks for the question and sorry about these issues. It seems like there was some kind of download issue with the deepvariant conda package in your environment. The 0.8.0 package has been around ~6 months and not changed recently, so I'm guessing maybe you got a partial download or other issue. If you remove your local download (` /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2`) and re-run, does it work cleanly? Is there anything about your network or other messages that might indicate an issue that could help us debug more? Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:467,security,network,network,467,"Thanks for the question and sorry about these issues. It seems like there was some kind of download issue with the deepvariant conda package in your environment. The 0.8.0 package has been around ~6 months and not changed recently, so I'm guessing maybe you got a partial download or other issue. If you remove your local download (` /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2`) and re-run, does it work cleanly? Is there anything about your network or other messages that might indicate an issue that could help us debug more? Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:504,usability,indicat,indicate,504,"Thanks for the question and sorry about these issues. It seems like there was some kind of download issue with the deepvariant conda package in your environment. The 0.8.0 package has been around ~6 months and not changed recently, so I'm guessing maybe you got a partial download or other issue. If you remove your local download (` /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2`) and re-run, does it work cleanly? Is there anything about your network or other messages that might indicate an issue that could help us debug more? Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:533,usability,help,help,533,"Thanks for the question and sorry about these issues. It seems like there was some kind of download issue with the deepvariant conda package in your environment. The 0.8.0 package has been around ~6 months and not changed recently, so I'm guessing maybe you got a partial download or other issue. If you remove your local download (` /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2`) and re-run, does it work cleanly? Is there anything about your network or other messages that might indicate an issue that could help us debug more? Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:563,usability,help,helps,563,"Thanks for the question and sorry about these issues. It seems like there was some kind of download issue with the deepvariant conda package in your environment. The 0.8.0 package has been around ~6 months and not changed recently, so I'm guessing maybe you got a partial download or other issue. If you remove your local download (` /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2`) and re-run, does it work cleanly? Is there anything about your network or other messages that might indicate an issue that could help us debug more? Hope this helps.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:20,availability,error,error,20,"Hi, . I got another error when I remove my local download ( /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2) and re-run as follows. Preparing transaction: done. Verifying transaction: done. Executing transaction: done. ERROR conda.core.link:_execute(700): An error occurred while installing package 'bioconda::deepvariant-0.8.0-py27h7333d49_0'. Rolling back transaction: done. LinkError: post-link script failed for package bioconda::deepvariant-0.8.0-py27h7333d49_0. location of failed script: /home/ydliu/anaconda3/envs/py2.7/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ==> script output <==. stdout: . stderr: INFO 1101 14:33:31.774699 util.py] Retrying request, attempt #1... INFO 1101 14:34:33.764798 util.py] Retrying request, attempt #2... INFO 1101 14:35:36.852041 util.py] Retrying request, attempt #3... INFO 1101 14:36:43.774008 util.py] Retrying request, attempt #4... INFO 1101 14:37:59.406010 util.py] Retrying request, attempt #5... INFO 1101 14:39:31.468027 util.py] Retrying request, attempt #6... INFO 1101 14:41:03.574773 util.py] Retrying request, attempt #7... INFO 1101 14:42:35.649608 util.py] Retrying request, attempt #8... INFO 1101 14:44:07.752737 util.py] Retrying request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:49,availability,down,download,49,"Hi, . I got another error when I remove my local download ( /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2) and re-run as follows. Preparing transaction: done. Verifying transaction: done. Executing transaction: done. ERROR conda.core.link:_execute(700): An error occurred while installing package 'bioconda::deepvariant-0.8.0-py27h7333d49_0'. Rolling back transaction: done. LinkError: post-link script failed for package bioconda::deepvariant-0.8.0-py27h7333d49_0. location of failed script: /home/ydliu/anaconda3/envs/py2.7/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ==> script output <==. stdout: . stderr: INFO 1101 14:33:31.774699 util.py] Retrying request, attempt #1... INFO 1101 14:34:33.764798 util.py] Retrying request, attempt #2... INFO 1101 14:35:36.852041 util.py] Retrying request, attempt #3... INFO 1101 14:36:43.774008 util.py] Retrying request, attempt #4... INFO 1101 14:37:59.406010 util.py] Retrying request, attempt #5... INFO 1101 14:39:31.468027 util.py] Retrying request, attempt #6... INFO 1101 14:41:03.574773 util.py] Retrying request, attempt #7... INFO 1101 14:42:35.649608 util.py] Retrying request, attempt #8... INFO 1101 14:44:07.752737 util.py] Retrying request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:239,availability,ERROR,ERROR,239,"Hi, . I got another error when I remove my local download ( /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2) and re-run as follows. Preparing transaction: done. Verifying transaction: done. Executing transaction: done. ERROR conda.core.link:_execute(700): An error occurred while installing package 'bioconda::deepvariant-0.8.0-py27h7333d49_0'. Rolling back transaction: done. LinkError: post-link script failed for package bioconda::deepvariant-0.8.0-py27h7333d49_0. location of failed script: /home/ydliu/anaconda3/envs/py2.7/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ==> script output <==. stdout: . stderr: INFO 1101 14:33:31.774699 util.py] Retrying request, attempt #1... INFO 1101 14:34:33.764798 util.py] Retrying request, attempt #2... INFO 1101 14:35:36.852041 util.py] Retrying request, attempt #3... INFO 1101 14:36:43.774008 util.py] Retrying request, attempt #4... INFO 1101 14:37:59.406010 util.py] Retrying request, attempt #5... INFO 1101 14:39:31.468027 util.py] Retrying request, attempt #6... INFO 1101 14:41:03.574773 util.py] Retrying request, attempt #7... INFO 1101 14:42:35.649608 util.py] Retrying request, attempt #8... INFO 1101 14:44:07.752737 util.py] Retrying request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:279,availability,error,error,279,"Hi, . I got another error when I remove my local download ( /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2) and re-run as follows. Preparing transaction: done. Verifying transaction: done. Executing transaction: done. ERROR conda.core.link:_execute(700): An error occurred while installing package 'bioconda::deepvariant-0.8.0-py27h7333d49_0'. Rolling back transaction: done. LinkError: post-link script failed for package bioconda::deepvariant-0.8.0-py27h7333d49_0. location of failed script: /home/ydliu/anaconda3/envs/py2.7/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ==> script output <==. stdout: . stderr: INFO 1101 14:33:31.774699 util.py] Retrying request, attempt #1... INFO 1101 14:34:33.764798 util.py] Retrying request, attempt #2... INFO 1101 14:35:36.852041 util.py] Retrying request, attempt #3... INFO 1101 14:36:43.774008 util.py] Retrying request, attempt #4... INFO 1101 14:37:59.406010 util.py] Retrying request, attempt #5... INFO 1101 14:39:31.468027 util.py] Retrying request, attempt #6... INFO 1101 14:41:03.574773 util.py] Retrying request, attempt #7... INFO 1101 14:42:35.649608 util.py] Retrying request, attempt #8... INFO 1101 14:44:07.752737 util.py] Retrying request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:300,deployability,instal,installing,300,"Hi, . I got another error when I remove my local download ( /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2) and re-run as follows. Preparing transaction: done. Verifying transaction: done. Executing transaction: done. ERROR conda.core.link:_execute(700): An error occurred while installing package 'bioconda::deepvariant-0.8.0-py27h7333d49_0'. Rolling back transaction: done. LinkError: post-link script failed for package bioconda::deepvariant-0.8.0-py27h7333d49_0. location of failed script: /home/ydliu/anaconda3/envs/py2.7/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ==> script output <==. stdout: . stderr: INFO 1101 14:33:31.774699 util.py] Retrying request, attempt #1... INFO 1101 14:34:33.764798 util.py] Retrying request, attempt #2... INFO 1101 14:35:36.852041 util.py] Retrying request, attempt #3... INFO 1101 14:36:43.774008 util.py] Retrying request, attempt #4... INFO 1101 14:37:59.406010 util.py] Retrying request, attempt #5... INFO 1101 14:39:31.468027 util.py] Retrying request, attempt #6... INFO 1101 14:41:03.574773 util.py] Retrying request, attempt #7... INFO 1101 14:42:35.649608 util.py] Retrying request, attempt #8... INFO 1101 14:44:07.752737 util.py] Retrying request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:365,deployability,Roll,Rolling,365,"Hi, . I got another error when I remove my local download ( /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2) and re-run as follows. Preparing transaction: done. Verifying transaction: done. Executing transaction: done. ERROR conda.core.link:_execute(700): An error occurred while installing package 'bioconda::deepvariant-0.8.0-py27h7333d49_0'. Rolling back transaction: done. LinkError: post-link script failed for package bioconda::deepvariant-0.8.0-py27h7333d49_0. location of failed script: /home/ydliu/anaconda3/envs/py2.7/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ==> script output <==. stdout: . stderr: INFO 1101 14:33:31.774699 util.py] Retrying request, attempt #1... INFO 1101 14:34:33.764798 util.py] Retrying request, attempt #2... INFO 1101 14:35:36.852041 util.py] Retrying request, attempt #3... INFO 1101 14:36:43.774008 util.py] Retrying request, attempt #4... INFO 1101 14:37:59.406010 util.py] Retrying request, attempt #5... INFO 1101 14:39:31.468027 util.py] Retrying request, attempt #6... INFO 1101 14:41:03.574773 util.py] Retrying request, attempt #7... INFO 1101 14:42:35.649608 util.py] Retrying request, attempt #8... INFO 1101 14:44:07.752737 util.py] Retrying request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:425,deployability,fail,failed,425,"Hi, . I got another error when I remove my local download ( /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2) and re-run as follows. Preparing transaction: done. Verifying transaction: done. Executing transaction: done. ERROR conda.core.link:_execute(700): An error occurred while installing package 'bioconda::deepvariant-0.8.0-py27h7333d49_0'. Rolling back transaction: done. LinkError: post-link script failed for package bioconda::deepvariant-0.8.0-py27h7333d49_0. location of failed script: /home/ydliu/anaconda3/envs/py2.7/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ==> script output <==. stdout: . stderr: INFO 1101 14:33:31.774699 util.py] Retrying request, attempt #1... INFO 1101 14:34:33.764798 util.py] Retrying request, attempt #2... INFO 1101 14:35:36.852041 util.py] Retrying request, attempt #3... INFO 1101 14:36:43.774008 util.py] Retrying request, attempt #4... INFO 1101 14:37:59.406010 util.py] Retrying request, attempt #5... INFO 1101 14:39:31.468027 util.py] Retrying request, attempt #6... INFO 1101 14:41:03.574773 util.py] Retrying request, attempt #7... INFO 1101 14:42:35.649608 util.py] Retrying request, attempt #8... INFO 1101 14:44:07.752737 util.py] Retrying request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:500,deployability,fail,failed,500,"Hi, . I got another error when I remove my local download ( /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2) and re-run as follows. Preparing transaction: done. Verifying transaction: done. Executing transaction: done. ERROR conda.core.link:_execute(700): An error occurred while installing package 'bioconda::deepvariant-0.8.0-py27h7333d49_0'. Rolling back transaction: done. LinkError: post-link script failed for package bioconda::deepvariant-0.8.0-py27h7333d49_0. location of failed script: /home/ydliu/anaconda3/envs/py2.7/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ==> script output <==. stdout: . stderr: INFO 1101 14:33:31.774699 util.py] Retrying request, attempt #1... INFO 1101 14:34:33.764798 util.py] Retrying request, attempt #2... INFO 1101 14:35:36.852041 util.py] Retrying request, attempt #3... INFO 1101 14:36:43.774008 util.py] Retrying request, attempt #4... INFO 1101 14:37:59.406010 util.py] Retrying request, attempt #5... INFO 1101 14:39:31.468027 util.py] Retrying request, attempt #6... INFO 1101 14:41:03.574773 util.py] Retrying request, attempt #7... INFO 1101 14:42:35.649608 util.py] Retrying request, attempt #8... INFO 1101 14:44:07.752737 util.py] Retrying request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:2286,deployability,modul,module,2286,"] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20... INFO 1101 15:02:32.828025 util.py] Retrying request, attempt #21... INFO 1101 15:04:04.934843 util.py] Retrying request, attempt #22... Traceback (most recent call last):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>. gsutil.RunMain(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:5870,deployability,api,apitools,5870,"66.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:5879,deployability,api,apitools,5879,"platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6064,deployability,api,apitools,6064,"/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httpli",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6073,deployability,api,apitools,6073,"/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6276,deployability,api,apitools,6276,"ib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6285,deployability,api,apitools,6285,"rd_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018, in conne",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:251,energy efficiency,core,core,251,"Hi, . I got another error when I remove my local download ( /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2) and re-run as follows. Preparing transaction: done. Verifying transaction: done. Executing transaction: done. ERROR conda.core.link:_execute(700): An error occurred while installing package 'bioconda::deepvariant-0.8.0-py27h7333d49_0'. Rolling back transaction: done. LinkError: post-link script failed for package bioconda::deepvariant-0.8.0-py27h7333d49_0. location of failed script: /home/ydliu/anaconda3/envs/py2.7/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ==> script output <==. stdout: . stderr: INFO 1101 14:33:31.774699 util.py] Retrying request, attempt #1... INFO 1101 14:34:33.764798 util.py] Retrying request, attempt #2... INFO 1101 14:35:36.852041 util.py] Retrying request, attempt #3... INFO 1101 14:36:43.774008 util.py] Retrying request, attempt #4... INFO 1101 14:37:59.406010 util.py] Retrying request, attempt #5... INFO 1101 14:39:31.468027 util.py] Retrying request, attempt #6... INFO 1101 14:41:03.574773 util.py] Retrying request, attempt #7... INFO 1101 14:42:35.649608 util.py] Retrying request, attempt #8... INFO 1101 14:44:07.752737 util.py] Retrying request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:2228,energy efficiency,cloud,cloud-sdk-,2228,"request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20... INFO 1101 15:02:32.828025 util.py] Retrying request, attempt #21... INFO 1101 15:04:04.934843 util.py] Retrying request, attempt #22... Traceback (most recent call last):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>. gsutil.RunMain(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-clo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:2365,energy efficiency,cloud,cloud-sdk-,2365,"quest, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20... INFO 1101 15:02:32.828025 util.py] Retrying request, attempt #21... INFO 1101 15:04:04.934843 util.py] Retrying request, attempt #22... Traceback (most recent call last):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>. gsutil.RunMain(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:2520,energy efficiency,cloud,cloud-sdk-,2520,".. INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20... INFO 1101 15:02:32.828025 util.py] Retrying request, attempt #21... INFO 1101 15:04:04.934843 util.py] Retrying request, attempt #22... Traceback (most recent call last):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>. gsutil.RunMain(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next().",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:2683,energy efficiency,cloud,cloud-sdk-,2683,"6 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20... INFO 1101 15:02:32.828025 util.py] Retrying request, attempt #21... INFO 1101 15:04:04.934843 util.py] Retrying request, attempt #22... Traceback (most recent call last):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>. gsutil.RunMain(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:2866,energy efficiency,cloud,cloud-sdk-,2866,"O 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20... INFO 1101 15:02:32.828025 util.py] Retrying request, attempt #21... INFO 1101 15:04:04.934843 util.py] Retrying request, attempt #22... Traceback (most recent call last):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>. gsutil.RunMain(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:3051,energy efficiency,cloud,cloud-sdk-,3051," attempt #21... INFO 1101 15:04:04.934843 util.py] Retrying request, attempt #22... Traceback (most recent call last):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>. gsutil.RunMain(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_con",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:3230,energy efficiency,cloud,cloud-sdk-,3230,"dk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>. gsutil.RunMain(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _Popu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:3410,energy efficiency,cloud,cloud-sdk-,3410,"ne 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. fo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:3578,energy efficiency,cloud,cloud-sdk-,3578,"3, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:3771,energy efficiency,cloud,cloud-sdk-,3771,"eExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:3957,energy efficiency,cloud,cloud-sdk-,3957,"rn_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:4142,energy efficiency,cloud,cloud-sdk-,4142,"iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:4328,energy efficiency,cloud,cloud-sdk-,4328,"results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. prov",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:4513,energy efficiency,cloud,cloud-sdk-,4513,"next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in List",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:4699,energy efficiency,cloud,cloud-sdk-,4699,"n_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", l",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:4863,energy efficiency,cloud,cloud-sdk-,4863,"Head. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_part",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:5049,energy efficiency,cloud,cloud-sdk-,5049,"ontainer, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:5241,energy efficiency,cloud,cloud-sdk-,5241," = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:5441,energy efficiency,cloud,cloud-sdk-,5441,"f.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/env",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:5609,energy efficiency,cloud,cloud-sdk-,5609,". e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:5822,energy efficiency,cloud,cloud-sdk-,5822,"u/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__in",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6016,energy efficiency,cloud,cloud-sdk-,6016,"da3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/plat",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6228,energy efficiency,cloud,cloud-sdk-,6228,"/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/htt",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6467,energy efficiency,cloud,cloud-sdk-,6467,"util/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018, in connect. sock.connect((self.host, self.port)). File ""/home/ydliu/anaconda3/envs/py2.7/lib/python2.7/socket.py"", line 228, in meth. return getattr(self._sock,name)(*args). socket.timeout: t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6749,energy efficiency,cloud,cloud-sdk-,6749,"line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018, in connect. sock.connect((self.host, self.port)). File ""/home/ydliu/anaconda3/envs/py2.7/lib/python2.7/socket.py"", line 228, in meth. return getattr(self._sock,name)(*args). socket.timeout: timed out. return code: 1. ().",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6997,energy efficiency,cloud,cloud-sdk-,6997,"line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018, in connect. sock.connect((self.host, self.port)). File ""/home/ydliu/anaconda3/envs/py2.7/lib/python2.7/socket.py"", line 228, in meth. return getattr(self._sock,name)(*args). socket.timeout: timed out. return code: 1. ().",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:7182,energy efficiency,cloud,cloud-sdk-,7182,"line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018, in connect. sock.connect((self.host, self.port)). File ""/home/ydliu/anaconda3/envs/py2.7/lib/python2.7/socket.py"", line 228, in meth. return getattr(self._sock,name)(*args). socket.timeout: timed out. return code: 1. ().",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:590,integrability,messag,messages,590,"Hi, . I got another error when I remove my local download ( /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2) and re-run as follows. Preparing transaction: done. Verifying transaction: done. Executing transaction: done. ERROR conda.core.link:_execute(700): An error occurred while installing package 'bioconda::deepvariant-0.8.0-py27h7333d49_0'. Rolling back transaction: done. LinkError: post-link script failed for package bioconda::deepvariant-0.8.0-py27h7333d49_0. location of failed script: /home/ydliu/anaconda3/envs/py2.7/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ==> script output <==. stdout: . stderr: INFO 1101 14:33:31.774699 util.py] Retrying request, attempt #1... INFO 1101 14:34:33.764798 util.py] Retrying request, attempt #2... INFO 1101 14:35:36.852041 util.py] Retrying request, attempt #3... INFO 1101 14:36:43.774008 util.py] Retrying request, attempt #4... INFO 1101 14:37:59.406010 util.py] Retrying request, attempt #5... INFO 1101 14:39:31.468027 util.py] Retrying request, attempt #6... INFO 1101 14:41:03.574773 util.py] Retrying request, attempt #7... INFO 1101 14:42:35.649608 util.py] Retrying request, attempt #8... INFO 1101 14:44:07.752737 util.py] Retrying request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:5870,integrability,api,apitools,5870,"66.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:5879,integrability,api,apitools,5879,"platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6064,integrability,api,apitools,6064,"/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httpli",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6073,integrability,api,apitools,6073,"/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6276,integrability,api,apitools,6276,"ib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6285,integrability,api,apitools,6285,"rd_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018, in conne",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:590,interoperability,messag,messages,590,"Hi, . I got another error when I remove my local download ( /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2) and re-run as follows. Preparing transaction: done. Verifying transaction: done. Executing transaction: done. ERROR conda.core.link:_execute(700): An error occurred while installing package 'bioconda::deepvariant-0.8.0-py27h7333d49_0'. Rolling back transaction: done. LinkError: post-link script failed for package bioconda::deepvariant-0.8.0-py27h7333d49_0. location of failed script: /home/ydliu/anaconda3/envs/py2.7/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ==> script output <==. stdout: . stderr: INFO 1101 14:33:31.774699 util.py] Retrying request, attempt #1... INFO 1101 14:34:33.764798 util.py] Retrying request, attempt #2... INFO 1101 14:35:36.852041 util.py] Retrying request, attempt #3... INFO 1101 14:36:43.774008 util.py] Retrying request, attempt #4... INFO 1101 14:37:59.406010 util.py] Retrying request, attempt #5... INFO 1101 14:39:31.468027 util.py] Retrying request, attempt #6... INFO 1101 14:41:03.574773 util.py] Retrying request, attempt #7... INFO 1101 14:42:35.649608 util.py] Retrying request, attempt #8... INFO 1101 14:44:07.752737 util.py] Retrying request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:2215,interoperability,share,share,2215,"l.py] Retrying request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20... INFO 1101 15:02:32.828025 util.py] Retrying request, attempt #21... INFO 1101 15:04:04.934843 util.py] Retrying request, attempt #22... Traceback (most recent call last):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>. gsutil.RunMain(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:2248,interoperability,platform,platform,2248,"... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20... INFO 1101 15:02:32.828025 util.py] Retrying request, attempt #21... INFO 1101 15:04:04.934843 util.py] Retrying request, attempt #22... Traceback (most recent call last):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>. gsutil.RunMain(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/pl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:2352,interoperability,share,share,2352,"py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20... INFO 1101 15:02:32.828025 util.py] Retrying request, attempt #21... INFO 1101 15:04:04.934843 util.py] Retrying request, attempt #22... Traceback (most recent call last):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>. gsutil.RunMain(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:2385,interoperability,platform,platform,2385,".. INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20... INFO 1101 15:02:32.828025 util.py] Retrying request, attempt #21... INFO 1101 15:04:04.934843 util.py] Retrying request, attempt #22... Traceback (most recent call last):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>. gsutil.RunMain(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/env",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:2507,interoperability,share,share,2507,"t, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20... INFO 1101 15:02:32.828025 util.py] Retrying request, attempt #21... INFO 1101 15:04:04.934843 util.py] Retrying request, attempt #22... Traceback (most recent call last):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>. gsutil.RunMain(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:2540,interoperability,platform,platform,2540,"48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20... INFO 1101 15:02:32.828025 util.py] Retrying request, attempt #21... INFO 1101 15:04:04.934843 util.py] Retrying request, attempt #22... Traceback (most recent call last):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>. gsutil.RunMain(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:2670,interoperability,share,share,2670," 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20... INFO 1101 15:02:32.828025 util.py] Retrying request, attempt #21... INFO 1101 15:04:04.934843 util.py] Retrying request, attempt #22... Traceback (most recent call last):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>. gsutil.RunMain(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:2703,interoperability,platform,platform,2703," request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20... INFO 1101 15:02:32.828025 util.py] Retrying request, attempt #21... INFO 1101 15:04:04.934843 util.py] Retrying request, attempt #22... Traceback (most recent call last):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>. gsutil.RunMain(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:2853,interoperability,share,share,2853,"empt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20... INFO 1101 15:02:32.828025 util.py] Retrying request, attempt #21... INFO 1101 15:04:04.934843 util.py] Retrying request, attempt #22... Traceback (most recent call last):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>. gsutil.RunMain(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:2886,interoperability,platform,platform,2886,"781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20... INFO 1101 15:02:32.828025 util.py] Retrying request, attempt #21... INFO 1101 15:04:04.934843 util.py] Retrying request, attempt #22... Traceback (most recent call last):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>. gsutil.RunMain(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_it",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:3038,interoperability,share,share,3038,"trying request, attempt #21... INFO 1101 15:04:04.934843 util.py] Retrying request, attempt #22... Traceback (most recent call last):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>. gsutil.RunMain(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:3071,interoperability,platform,platform,3071,"O 1101 15:04:04.934843 util.py] Retrying request, attempt #22... Traceback (most recent call last):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>. gsutil.RunMain(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in pos",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:3217,interoperability,share,share,3217,"/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>. gsutil.RunMain(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", li",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:3250,interoperability,platform,platform,3250,"rm/gsutil/gsutil"", line 22, in <module>. gsutil.RunMain(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:3397,interoperability,share,share,3397,"/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:3430,interoperability,platform,platform,3430," sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:3565,interoperability,share,share,3565,"__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_che",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:3598,interoperability,platform,platform,3598,"ace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:3758,interoperability,share,share,3758,"CommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:3791,interoperability,platform,platform,3791,"t_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:3944,interoperability,share,share,3944,"edCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:3977,interoperability,platform,platform,3977,"nst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:4129,interoperability,share,share,4129,"nd. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterA",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:4162,interoperability,platform,platform,4162,"_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expan",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:4315,interoperability,share,share,4315," should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:4348,interoperability,platform,platform,4348,"ror). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:4500,interoperability,share,share,4500," args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", li",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:4533,interoperability,platform,platform,4533,"/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_par",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:4686,interoperability,share,share,4686,"urrent_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:4719,interoperability,platform,platform,4719," ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:4850,interoperability,share,share,4850,"0, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:4883,interoperability,platform,platform,4883,"_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:5036,interoperability,share,share,5036,"_. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/pla",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:5069,interoperability,platform,platform,5069,"ost_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:5228,interoperability,share,share,5228,"PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-clo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:5261,interoperability,platform,platform,5261,"or.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:5428,interoperability,share,share,5428,"er, blr) in self.tuple_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydli",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:5461,interoperability,platform,platform,5461," ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/googl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:5596,interoperability,share,share,5596,"n _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) =",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:5629,interoperability,platform,platform,5629,"rator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 432, in __iter__. for blr in self.blr_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, ur",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:5809,interoperability,share,share,5809,"ile ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:5842,interoperability,platform,platform,5842,"2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:5870,interoperability,api,apitools,5870,"66.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:5879,interoperability,api,apitools,5879,"platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6003,interoperability,share,share,6003,"me/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6036,interoperability,platform,platform,6036,"e/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6064,interoperability,api,apitools,6064,"/platform/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httpli",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6073,interoperability,api,apitools,6073,"/gsutil/gslib/wildcard_iterator.py"", line 476, in IterAll. expand_top_level_buckets=expand_top_level_buckets):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6215,interoperability,share,share,6215,"nvs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6248,interoperability,platform,platform,6248,"66.0.0-0/platform/gsutil/gslib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httpl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6276,interoperability,api,apitools,6276,"ib/wildcard_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6285,interoperability,api,apitools,6285,"rd_iterator.py"", line 215, in __iter__. provider=self.wildcard_url.scheme, fields=listing_fields):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018, in conne",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6454,interoperability,share,share,6454,"0-0/platform/gsutil/gslib/gcs_json_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018, in connect. sock.connect((self.host, self.port)). File ""/home/ydliu/anaconda3/envs/py2.7/lib/python2.7/socket.py"", line 228, in meth. return getattr(self._sock,name)(*args). so",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6487,interoperability,platform,platform,6487,"_api.py"", line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018, in connect. sock.connect((self.host, self.port)). File ""/home/ydliu/anaconda3/envs/py2.7/lib/python2.7/socket.py"", line 228, in meth. return getattr(self._sock,name)(*args). socket.timeout: timed out. return co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6736,interoperability,share,share,6736,"line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018, in connect. sock.connect((self.host, self.port)). File ""/home/ydliu/anaconda3/envs/py2.7/lib/python2.7/socket.py"", line 228, in meth. return getattr(self._sock,name)(*args). socket.timeout: timed out. return code: 1. ().",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6769,interoperability,platform,platform,6769,"line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018, in connect. sock.connect((self.host, self.port)). File ""/home/ydliu/anaconda3/envs/py2.7/lib/python2.7/socket.py"", line 228, in meth. return getattr(self._sock,name)(*args). socket.timeout: timed out. return code: 1. ().",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6984,interoperability,share,share,6984,"line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018, in connect. sock.connect((self.host, self.port)). File ""/home/ydliu/anaconda3/envs/py2.7/lib/python2.7/socket.py"", line 228, in meth. return getattr(self._sock,name)(*args). socket.timeout: timed out. return code: 1. ().",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:7017,interoperability,platform,platform,7017,"line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018, in connect. sock.connect((self.host, self.port)). File ""/home/ydliu/anaconda3/envs/py2.7/lib/python2.7/socket.py"", line 228, in meth. return getattr(self._sock,name)(*args). socket.timeout: timed out. return code: 1. ().",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:7169,interoperability,share,share,7169,"line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018, in connect. sock.connect((self.host, self.port)). File ""/home/ydliu/anaconda3/envs/py2.7/lib/python2.7/socket.py"", line 228, in meth. return getattr(self._sock,name)(*args). socket.timeout: timed out. return code: 1. ().",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:7202,interoperability,platform,platform,7202,"line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018, in connect. sock.connect((self.host, self.port)). File ""/home/ydliu/anaconda3/envs/py2.7/lib/python2.7/socket.py"", line 228, in meth. return getattr(self._sock,name)(*args). socket.timeout: timed out. return code: 1. ().",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:7384,interoperability,socket,socket,7384,"line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018, in connect. sock.connect((self.host, self.port)). File ""/home/ydliu/anaconda3/envs/py2.7/lib/python2.7/socket.py"", line 228, in meth. return getattr(self._sock,name)(*args). socket.timeout: timed out. return code: 1. ().",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:7455,interoperability,socket,socket,7455,"line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018, in connect. sock.connect((self.host, self.port)). File ""/home/ydliu/anaconda3/envs/py2.7/lib/python2.7/socket.py"", line 228, in meth. return getattr(self._sock,name)(*args). socket.timeout: timed out. return code: 1. ().",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:311,modifiability,pac,package,311,"Hi, . I got another error when I remove my local download ( /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2) and re-run as follows. Preparing transaction: done. Verifying transaction: done. Executing transaction: done. ERROR conda.core.link:_execute(700): An error occurred while installing package 'bioconda::deepvariant-0.8.0-py27h7333d49_0'. Rolling back transaction: done. LinkError: post-link script failed for package bioconda::deepvariant-0.8.0-py27h7333d49_0. location of failed script: /home/ydliu/anaconda3/envs/py2.7/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ==> script output <==. stdout: . stderr: INFO 1101 14:33:31.774699 util.py] Retrying request, attempt #1... INFO 1101 14:34:33.764798 util.py] Retrying request, attempt #2... INFO 1101 14:35:36.852041 util.py] Retrying request, attempt #3... INFO 1101 14:36:43.774008 util.py] Retrying request, attempt #4... INFO 1101 14:37:59.406010 util.py] Retrying request, attempt #5... INFO 1101 14:39:31.468027 util.py] Retrying request, attempt #6... INFO 1101 14:41:03.574773 util.py] Retrying request, attempt #7... INFO 1101 14:42:35.649608 util.py] Retrying request, attempt #8... INFO 1101 14:44:07.752737 util.py] Retrying request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:436,modifiability,pac,package,436,"Hi, . I got another error when I remove my local download ( /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2) and re-run as follows. Preparing transaction: done. Verifying transaction: done. Executing transaction: done. ERROR conda.core.link:_execute(700): An error occurred while installing package 'bioconda::deepvariant-0.8.0-py27h7333d49_0'. Rolling back transaction: done. LinkError: post-link script failed for package bioconda::deepvariant-0.8.0-py27h7333d49_0. location of failed script: /home/ydliu/anaconda3/envs/py2.7/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ==> script output <==. stdout: . stderr: INFO 1101 14:33:31.774699 util.py] Retrying request, attempt #1... INFO 1101 14:34:33.764798 util.py] Retrying request, attempt #2... INFO 1101 14:35:36.852041 util.py] Retrying request, attempt #3... INFO 1101 14:36:43.774008 util.py] Retrying request, attempt #4... INFO 1101 14:37:59.406010 util.py] Retrying request, attempt #5... INFO 1101 14:39:31.468027 util.py] Retrying request, attempt #6... INFO 1101 14:41:03.574773 util.py] Retrying request, attempt #7... INFO 1101 14:42:35.649608 util.py] Retrying request, attempt #8... INFO 1101 14:44:07.752737 util.py] Retrying request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:2286,modifiability,modul,module,2286,"] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20... INFO 1101 15:02:32.828025 util.py] Retrying request, attempt #21... INFO 1101 15:04:04.934843 util.py] Retrying request, attempt #22... Traceback (most recent call last):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>. gsutil.RunMain(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:20,performance,error,error,20,"Hi, . I got another error when I remove my local download ( /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2) and re-run as follows. Preparing transaction: done. Verifying transaction: done. Executing transaction: done. ERROR conda.core.link:_execute(700): An error occurred while installing package 'bioconda::deepvariant-0.8.0-py27h7333d49_0'. Rolling back transaction: done. LinkError: post-link script failed for package bioconda::deepvariant-0.8.0-py27h7333d49_0. location of failed script: /home/ydliu/anaconda3/envs/py2.7/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ==> script output <==. stdout: . stderr: INFO 1101 14:33:31.774699 util.py] Retrying request, attempt #1... INFO 1101 14:34:33.764798 util.py] Retrying request, attempt #2... INFO 1101 14:35:36.852041 util.py] Retrying request, attempt #3... INFO 1101 14:36:43.774008 util.py] Retrying request, attempt #4... INFO 1101 14:37:59.406010 util.py] Retrying request, attempt #5... INFO 1101 14:39:31.468027 util.py] Retrying request, attempt #6... INFO 1101 14:41:03.574773 util.py] Retrying request, attempt #7... INFO 1101 14:42:35.649608 util.py] Retrying request, attempt #8... INFO 1101 14:44:07.752737 util.py] Retrying request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:239,performance,ERROR,ERROR,239,"Hi, . I got another error when I remove my local download ( /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2) and re-run as follows. Preparing transaction: done. Verifying transaction: done. Executing transaction: done. ERROR conda.core.link:_execute(700): An error occurred while installing package 'bioconda::deepvariant-0.8.0-py27h7333d49_0'. Rolling back transaction: done. LinkError: post-link script failed for package bioconda::deepvariant-0.8.0-py27h7333d49_0. location of failed script: /home/ydliu/anaconda3/envs/py2.7/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ==> script output <==. stdout: . stderr: INFO 1101 14:33:31.774699 util.py] Retrying request, attempt #1... INFO 1101 14:34:33.764798 util.py] Retrying request, attempt #2... INFO 1101 14:35:36.852041 util.py] Retrying request, attempt #3... INFO 1101 14:36:43.774008 util.py] Retrying request, attempt #4... INFO 1101 14:37:59.406010 util.py] Retrying request, attempt #5... INFO 1101 14:39:31.468027 util.py] Retrying request, attempt #6... INFO 1101 14:41:03.574773 util.py] Retrying request, attempt #7... INFO 1101 14:42:35.649608 util.py] Retrying request, attempt #8... INFO 1101 14:44:07.752737 util.py] Retrying request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:279,performance,error,error,279,"Hi, . I got another error when I remove my local download ( /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2) and re-run as follows. Preparing transaction: done. Verifying transaction: done. Executing transaction: done. ERROR conda.core.link:_execute(700): An error occurred while installing package 'bioconda::deepvariant-0.8.0-py27h7333d49_0'. Rolling back transaction: done. LinkError: post-link script failed for package bioconda::deepvariant-0.8.0-py27h7333d49_0. location of failed script: /home/ydliu/anaconda3/envs/py2.7/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ==> script output <==. stdout: . stderr: INFO 1101 14:33:31.774699 util.py] Retrying request, attempt #1... INFO 1101 14:34:33.764798 util.py] Retrying request, attempt #2... INFO 1101 14:35:36.852041 util.py] Retrying request, attempt #3... INFO 1101 14:36:43.774008 util.py] Retrying request, attempt #4... INFO 1101 14:37:59.406010 util.py] Retrying request, attempt #5... INFO 1101 14:39:31.468027 util.py] Retrying request, attempt #6... INFO 1101 14:41:03.574773 util.py] Retrying request, attempt #7... INFO 1101 14:42:35.649608 util.py] Retrying request, attempt #8... INFO 1101 14:44:07.752737 util.py] Retrying request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6589,performance,content,content,6589,"line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018, in connect. sock.connect((self.host, self.port)). File ""/home/ydliu/anaconda3/envs/py2.7/lib/python2.7/socket.py"", line 228, in meth. return getattr(self._sock,name)(*args). socket.timeout: timed out. return code: 1. ().",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6686,performance,cach,cachekey,6686,"line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018, in connect. sock.connect((self.host, self.port)). File ""/home/ydliu/anaconda3/envs/py2.7/lib/python2.7/socket.py"", line 228, in meth. return getattr(self._sock,name)(*args). socket.timeout: timed out. return code: 1. ().",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6872,performance,content,content,6872,"line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018, in connect. sock.connect((self.host, self.port)). File ""/home/ydliu/anaconda3/envs/py2.7/lib/python2.7/socket.py"", line 228, in meth. return getattr(self._sock,name)(*args). socket.timeout: timed out. return code: 1. ().",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:7462,performance,time,timeout,7462,"line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018, in connect. sock.connect((self.host, self.port)). File ""/home/ydliu/anaconda3/envs/py2.7/lib/python2.7/socket.py"", line 228, in meth. return getattr(self._sock,name)(*args). socket.timeout: timed out. return code: 1. ().",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:7471,performance,time,timed,7471,"line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018, in connect. sock.connect((self.host, self.port)). File ""/home/ydliu/anaconda3/envs/py2.7/lib/python2.7/socket.py"", line 228, in meth. return getattr(self._sock,name)(*args). socket.timeout: timed out. return code: 1. ().",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:425,reliability,fail,failed,425,"Hi, . I got another error when I remove my local download ( /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2) and re-run as follows. Preparing transaction: done. Verifying transaction: done. Executing transaction: done. ERROR conda.core.link:_execute(700): An error occurred while installing package 'bioconda::deepvariant-0.8.0-py27h7333d49_0'. Rolling back transaction: done. LinkError: post-link script failed for package bioconda::deepvariant-0.8.0-py27h7333d49_0. location of failed script: /home/ydliu/anaconda3/envs/py2.7/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ==> script output <==. stdout: . stderr: INFO 1101 14:33:31.774699 util.py] Retrying request, attempt #1... INFO 1101 14:34:33.764798 util.py] Retrying request, attempt #2... INFO 1101 14:35:36.852041 util.py] Retrying request, attempt #3... INFO 1101 14:36:43.774008 util.py] Retrying request, attempt #4... INFO 1101 14:37:59.406010 util.py] Retrying request, attempt #5... INFO 1101 14:39:31.468027 util.py] Retrying request, attempt #6... INFO 1101 14:41:03.574773 util.py] Retrying request, attempt #7... INFO 1101 14:42:35.649608 util.py] Retrying request, attempt #8... INFO 1101 14:44:07.752737 util.py] Retrying request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:500,reliability,fail,failed,500,"Hi, . I got another error when I remove my local download ( /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2) and re-run as follows. Preparing transaction: done. Verifying transaction: done. Executing transaction: done. ERROR conda.core.link:_execute(700): An error occurred while installing package 'bioconda::deepvariant-0.8.0-py27h7333d49_0'. Rolling back transaction: done. LinkError: post-link script failed for package bioconda::deepvariant-0.8.0-py27h7333d49_0. location of failed script: /home/ydliu/anaconda3/envs/py2.7/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ==> script output <==. stdout: . stderr: INFO 1101 14:33:31.774699 util.py] Retrying request, attempt #1... INFO 1101 14:34:33.764798 util.py] Retrying request, attempt #2... INFO 1101 14:35:36.852041 util.py] Retrying request, attempt #3... INFO 1101 14:36:43.774008 util.py] Retrying request, attempt #4... INFO 1101 14:37:59.406010 util.py] Retrying request, attempt #5... INFO 1101 14:39:31.468027 util.py] Retrying request, attempt #6... INFO 1101 14:41:03.574773 util.py] Retrying request, attempt #7... INFO 1101 14:42:35.649608 util.py] Retrying request, attempt #8... INFO 1101 14:44:07.752737 util.py] Retrying request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:20,safety,error,error,20,"Hi, . I got another error when I remove my local download ( /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2) and re-run as follows. Preparing transaction: done. Verifying transaction: done. Executing transaction: done. ERROR conda.core.link:_execute(700): An error occurred while installing package 'bioconda::deepvariant-0.8.0-py27h7333d49_0'. Rolling back transaction: done. LinkError: post-link script failed for package bioconda::deepvariant-0.8.0-py27h7333d49_0. location of failed script: /home/ydliu/anaconda3/envs/py2.7/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ==> script output <==. stdout: . stderr: INFO 1101 14:33:31.774699 util.py] Retrying request, attempt #1... INFO 1101 14:34:33.764798 util.py] Retrying request, attempt #2... INFO 1101 14:35:36.852041 util.py] Retrying request, attempt #3... INFO 1101 14:36:43.774008 util.py] Retrying request, attempt #4... INFO 1101 14:37:59.406010 util.py] Retrying request, attempt #5... INFO 1101 14:39:31.468027 util.py] Retrying request, attempt #6... INFO 1101 14:41:03.574773 util.py] Retrying request, attempt #7... INFO 1101 14:42:35.649608 util.py] Retrying request, attempt #8... INFO 1101 14:44:07.752737 util.py] Retrying request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:239,safety,ERROR,ERROR,239,"Hi, . I got another error when I remove my local download ( /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2) and re-run as follows. Preparing transaction: done. Verifying transaction: done. Executing transaction: done. ERROR conda.core.link:_execute(700): An error occurred while installing package 'bioconda::deepvariant-0.8.0-py27h7333d49_0'. Rolling back transaction: done. LinkError: post-link script failed for package bioconda::deepvariant-0.8.0-py27h7333d49_0. location of failed script: /home/ydliu/anaconda3/envs/py2.7/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ==> script output <==. stdout: . stderr: INFO 1101 14:33:31.774699 util.py] Retrying request, attempt #1... INFO 1101 14:34:33.764798 util.py] Retrying request, attempt #2... INFO 1101 14:35:36.852041 util.py] Retrying request, attempt #3... INFO 1101 14:36:43.774008 util.py] Retrying request, attempt #4... INFO 1101 14:37:59.406010 util.py] Retrying request, attempt #5... INFO 1101 14:39:31.468027 util.py] Retrying request, attempt #6... INFO 1101 14:41:03.574773 util.py] Retrying request, attempt #7... INFO 1101 14:42:35.649608 util.py] Retrying request, attempt #8... INFO 1101 14:44:07.752737 util.py] Retrying request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:279,safety,error,error,279,"Hi, . I got another error when I remove my local download ( /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2) and re-run as follows. Preparing transaction: done. Verifying transaction: done. Executing transaction: done. ERROR conda.core.link:_execute(700): An error occurred while installing package 'bioconda::deepvariant-0.8.0-py27h7333d49_0'. Rolling back transaction: done. LinkError: post-link script failed for package bioconda::deepvariant-0.8.0-py27h7333d49_0. location of failed script: /home/ydliu/anaconda3/envs/py2.7/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ==> script output <==. stdout: . stderr: INFO 1101 14:33:31.774699 util.py] Retrying request, attempt #1... INFO 1101 14:34:33.764798 util.py] Retrying request, attempt #2... INFO 1101 14:35:36.852041 util.py] Retrying request, attempt #3... INFO 1101 14:36:43.774008 util.py] Retrying request, attempt #4... INFO 1101 14:37:59.406010 util.py] Retrying request, attempt #5... INFO 1101 14:39:31.468027 util.py] Retrying request, attempt #6... INFO 1101 14:41:03.574773 util.py] Retrying request, attempt #7... INFO 1101 14:42:35.649608 util.py] Retrying request, attempt #8... INFO 1101 14:44:07.752737 util.py] Retrying request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:2286,safety,modul,module,2286,"] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20... INFO 1101 15:02:32.828025 util.py] Retrying request, attempt #21... INFO 1101 15:04:04.934843 util.py] Retrying request, attempt #22... Traceback (most recent call last):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>. gsutil.RunMain(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:7462,safety,timeout,timeout,7462,"line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018, in connect. sock.connect((self.host, self.port)). File ""/home/ydliu/anaconda3/envs/py2.7/lib/python2.7/socket.py"", line 228, in meth. return getattr(self._sock,name)(*args). socket.timeout: timed out. return code: 1. ().",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:6620,security,auth,authority,6620,"line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018, in connect. sock.connect((self.host, self.port)). File ""/home/ydliu/anaconda3/envs/py2.7/lib/python2.7/socket.py"", line 228, in meth. return getattr(self._sock,name)(*args). socket.timeout: timed out. return code: 1. ().",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:7293,security,soc,sock,7293,"line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018, in connect. sock.connect((self.host, self.port)). File ""/home/ydliu/anaconda3/envs/py2.7/lib/python2.7/socket.py"", line 228, in meth. return getattr(self._sock,name)(*args). socket.timeout: timed out. return code: 1. ().",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:7384,security,soc,socket,7384,"line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018, in connect. sock.connect((self.host, self.port)). File ""/home/ydliu/anaconda3/envs/py2.7/lib/python2.7/socket.py"", line 228, in meth. return getattr(self._sock,name)(*args). socket.timeout: timed out. return code: 1. ().",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:7455,security,soc,socket,7455,"line 595, in ListObjects. global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/third_party/storage_apitools/storage_v1_client.py"", line 1237, in List. config, request, global_params=global_params). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/base_api.py"", line 701, in _RunMethod. http, http_request, **opts). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 341, in MakeRequest. check_response_func=check_response_func). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/apitools/apitools/base/py/http_wrapper.py"", line 391, in _MakeRequestNoRetry. redirections=redirections, connection_type=connection_type). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1570, in request. (response, content) = self._request(conn, authority, uri, request_uri, method, body, headers, redirections, cachekey). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1317, in _request. (response, content) = self._conn_request(conn, request_uri, method, body, headers). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1252, in _conn_request. conn.connect(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/third_party/httplib2/python2/httplib2/__init__.py"", line 1018, in connect. sock.connect((self.host, self.port)). File ""/home/ydliu/anaconda3/envs/py2.7/lib/python2.7/socket.py"", line 228, in meth. return getattr(self._sock,name)(*args). socket.timeout: timed out. return code: 1. ().",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:181,testability,Verif,Verifying,181,"Hi, . I got another error when I remove my local download ( /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2) and re-run as follows. Preparing transaction: done. Verifying transaction: done. Executing transaction: done. ERROR conda.core.link:_execute(700): An error occurred while installing package 'bioconda::deepvariant-0.8.0-py27h7333d49_0'. Rolling back transaction: done. LinkError: post-link script failed for package bioconda::deepvariant-0.8.0-py27h7333d49_0. location of failed script: /home/ydliu/anaconda3/envs/py2.7/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ==> script output <==. stdout: . stderr: INFO 1101 14:33:31.774699 util.py] Retrying request, attempt #1... INFO 1101 14:34:33.764798 util.py] Retrying request, attempt #2... INFO 1101 14:35:36.852041 util.py] Retrying request, attempt #3... INFO 1101 14:36:43.774008 util.py] Retrying request, attempt #4... INFO 1101 14:37:59.406010 util.py] Retrying request, attempt #5... INFO 1101 14:39:31.468027 util.py] Retrying request, attempt #6... INFO 1101 14:41:03.574773 util.py] Retrying request, attempt #7... INFO 1101 14:42:35.649608 util.py] Retrying request, attempt #8... INFO 1101 14:44:07.752737 util.py] Retrying request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:2140,testability,Trace,Traceback,2140,"08 util.py] Retrying request, attempt #8... INFO 1101 14:44:07.752737 util.py] Retrying request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20... INFO 1101 15:02:32.828025 util.py] Retrying request, attempt #21... INFO 1101 15:04:04.934843 util.py] Retrying request, attempt #22... Traceback (most recent call last):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>. gsutil.RunMain(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:20,usability,error,error,20,"Hi, . I got another error when I remove my local download ( /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2) and re-run as follows. Preparing transaction: done. Verifying transaction: done. Executing transaction: done. ERROR conda.core.link:_execute(700): An error occurred while installing package 'bioconda::deepvariant-0.8.0-py27h7333d49_0'. Rolling back transaction: done. LinkError: post-link script failed for package bioconda::deepvariant-0.8.0-py27h7333d49_0. location of failed script: /home/ydliu/anaconda3/envs/py2.7/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ==> script output <==. stdout: . stderr: INFO 1101 14:33:31.774699 util.py] Retrying request, attempt #1... INFO 1101 14:34:33.764798 util.py] Retrying request, attempt #2... INFO 1101 14:35:36.852041 util.py] Retrying request, attempt #3... INFO 1101 14:36:43.774008 util.py] Retrying request, attempt #4... INFO 1101 14:37:59.406010 util.py] Retrying request, attempt #5... INFO 1101 14:39:31.468027 util.py] Retrying request, attempt #6... INFO 1101 14:41:03.574773 util.py] Retrying request, attempt #7... INFO 1101 14:42:35.649608 util.py] Retrying request, attempt #8... INFO 1101 14:44:07.752737 util.py] Retrying request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:239,usability,ERROR,ERROR,239,"Hi, . I got another error when I remove my local download ( /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2) and re-run as follows. Preparing transaction: done. Verifying transaction: done. Executing transaction: done. ERROR conda.core.link:_execute(700): An error occurred while installing package 'bioconda::deepvariant-0.8.0-py27h7333d49_0'. Rolling back transaction: done. LinkError: post-link script failed for package bioconda::deepvariant-0.8.0-py27h7333d49_0. location of failed script: /home/ydliu/anaconda3/envs/py2.7/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ==> script output <==. stdout: . stderr: INFO 1101 14:33:31.774699 util.py] Retrying request, attempt #1... INFO 1101 14:34:33.764798 util.py] Retrying request, attempt #2... INFO 1101 14:35:36.852041 util.py] Retrying request, attempt #3... INFO 1101 14:36:43.774008 util.py] Retrying request, attempt #4... INFO 1101 14:37:59.406010 util.py] Retrying request, attempt #5... INFO 1101 14:39:31.468027 util.py] Retrying request, attempt #6... INFO 1101 14:41:03.574773 util.py] Retrying request, attempt #7... INFO 1101 14:42:35.649608 util.py] Retrying request, attempt #8... INFO 1101 14:44:07.752737 util.py] Retrying request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:279,usability,error,error,279,"Hi, . I got another error when I remove my local download ( /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2) and re-run as follows. Preparing transaction: done. Verifying transaction: done. Executing transaction: done. ERROR conda.core.link:_execute(700): An error occurred while installing package 'bioconda::deepvariant-0.8.0-py27h7333d49_0'. Rolling back transaction: done. LinkError: post-link script failed for package bioconda::deepvariant-0.8.0-py27h7333d49_0. location of failed script: /home/ydliu/anaconda3/envs/py2.7/bin/.deepvariant-post-link.sh. ==> script messages <==. <None>. ==> script output <==. stdout: . stderr: INFO 1101 14:33:31.774699 util.py] Retrying request, attempt #1... INFO 1101 14:34:33.764798 util.py] Retrying request, attempt #2... INFO 1101 14:35:36.852041 util.py] Retrying request, attempt #3... INFO 1101 14:36:43.774008 util.py] Retrying request, attempt #4... INFO 1101 14:37:59.406010 util.py] Retrying request, attempt #5... INFO 1101 14:39:31.468027 util.py] Retrying request, attempt #6... INFO 1101 14:41:03.574773 util.py] Retrying request, attempt #7... INFO 1101 14:42:35.649608 util.py] Retrying request, attempt #8... INFO 1101 14:44:07.752737 util.py] Retrying request, attempt #9... INFO 1101 14:45:39.836059 util.py] Retrying request, attempt #10... INFO 1101 14:47:11.942440 util.py] Retrying request, attempt #11... INFO 1101 14:48:43.990016 util.py] Retrying request, attempt #12... INFO 1101 14:50:16.078940 util.py] Retrying request, attempt #13... INFO 1101 14:51:48.200379 util.py] Retrying request, attempt #14... INFO 1101 14:53:20.307419 util.py] Retrying request, attempt #15... INFO 1101 14:54:52.388456 util.py] Retrying request, attempt #16... INFO 1101 14:56:24.486618 util.py] Retrying request, attempt #17... INFO 1101 14:57:56.579738 util.py] Retrying request, attempt #18... INFO 1101 14:59:28.640781 util.py] Retrying request, attempt #19... INFO 1101 15:01:00.705409 util.py] Retrying request, attempt #20",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:3093,usability,command,commands,3093," util.py] Retrying request, attempt #22... Traceback (most recent call last):. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil"", line 22, in <module>. gsutil.RunMain(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:3272,usability,command,command,3272,"e 22, in <module>. gsutil.RunMain(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gsutil.py"", line 114, in RunMain. sys.exit(gslib.__main__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:3452,usability,command,command,3452,"__.main()). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 383, in main. perf_trace_token=perf_trace_token). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/__main__.py"", line 577, in _RunNamedCommandAndHandleExceptions. collect_analytics=True). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command_runner.py"", line 317, in RunNamedCommand. return_code = command_inst.RunCommand(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/commands/cp.py"", line 1139, in RunCommand. seek_ahead_iterator=seek_ahead_iterator). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1368, in Apply. arg_checker, should_return_results, fail_on_error). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/command.py"", line 1414, in _SequentialApply. args = args_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 622, in next. name_expansion_result = self.current_expansion_iter.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 265, in __iter__. for (names_container, blr) in post_step3_iter:. File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/plurality_checkable_iterator.py"", line 60, in _PopulateHead. e = self.base_iterator.next(). File ""/home/ydliu/anaconda3/envs/py2.7/share/google-cloud-sdk-166.0.0-0/platform/gsutil/gslib/name_expansion.py"", line 468, in __iter__. for (names_container, blr) in self.tuple_it",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:45,availability,error,error,45,"Thanks for following up and for the detailed error log. This looks again like a connectivity issue. The deepvariant recipe needs to pull down the training files from a Google Bucket and is timing out trying to connect. Either there was a general internet issue or there is something blocking access to the bucket. If you re-try multiple times, does it fail in the same way? If so, you may need to investigate if the machine can access Google buckets for download. Hope this helps with tracking down the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:137,availability,down,down,137,"Thanks for following up and for the detailed error log. This looks again like a connectivity issue. The deepvariant recipe needs to pull down the training files from a Google Bucket and is timing out trying to connect. Either there was a general internet issue or there is something blocking access to the bucket. If you re-try multiple times, does it fail in the same way? If so, you may need to investigate if the machine can access Google buckets for download. Hope this helps with tracking down the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:454,availability,down,download,454,"Thanks for following up and for the detailed error log. This looks again like a connectivity issue. The deepvariant recipe needs to pull down the training files from a Google Bucket and is timing out trying to connect. Either there was a general internet issue or there is something blocking access to the bucket. If you re-try multiple times, does it fail in the same way? If so, you may need to investigate if the machine can access Google buckets for download. Hope this helps with tracking down the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:494,availability,down,down,494,"Thanks for following up and for the detailed error log. This looks again like a connectivity issue. The deepvariant recipe needs to pull down the training files from a Google Bucket and is timing out trying to connect. Either there was a general internet issue or there is something blocking access to the bucket. If you re-try multiple times, does it fail in the same way? If so, you may need to investigate if the machine can access Google buckets for download. Hope this helps with tracking down the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:51,deployability,log,log,51,"Thanks for following up and for the detailed error log. This looks again like a connectivity issue. The deepvariant recipe needs to pull down the training files from a Google Bucket and is timing out trying to connect. Either there was a general internet issue or there is something blocking access to the bucket. If you re-try multiple times, does it fail in the same way? If so, you may need to investigate if the machine can access Google buckets for download. Hope this helps with tracking down the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:352,deployability,fail,fail,352,"Thanks for following up and for the detailed error log. This looks again like a connectivity issue. The deepvariant recipe needs to pull down the training files from a Google Bucket and is timing out trying to connect. Either there was a general internet issue or there is something blocking access to the bucket. If you re-try multiple times, does it fail in the same way? If so, you may need to investigate if the machine can access Google buckets for download. Hope this helps with tracking down the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:45,performance,error,error,45,"Thanks for following up and for the detailed error log. This looks again like a connectivity issue. The deepvariant recipe needs to pull down the training files from a Google Bucket and is timing out trying to connect. Either there was a general internet issue or there is something blocking access to the bucket. If you re-try multiple times, does it fail in the same way? If so, you may need to investigate if the machine can access Google buckets for download. Hope this helps with tracking down the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:337,performance,time,times,337,"Thanks for following up and for the detailed error log. This looks again like a connectivity issue. The deepvariant recipe needs to pull down the training files from a Google Bucket and is timing out trying to connect. Either there was a general internet issue or there is something blocking access to the bucket. If you re-try multiple times, does it fail in the same way? If so, you may need to investigate if the machine can access Google buckets for download. Hope this helps with tracking down the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:344,reliability,doe,does,344,"Thanks for following up and for the detailed error log. This looks again like a connectivity issue. The deepvariant recipe needs to pull down the training files from a Google Bucket and is timing out trying to connect. Either there was a general internet issue or there is something blocking access to the bucket. If you re-try multiple times, does it fail in the same way? If so, you may need to investigate if the machine can access Google buckets for download. Hope this helps with tracking down the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:352,reliability,fail,fail,352,"Thanks for following up and for the detailed error log. This looks again like a connectivity issue. The deepvariant recipe needs to pull down the training files from a Google Bucket and is timing out trying to connect. Either there was a general internet issue or there is something blocking access to the bucket. If you re-try multiple times, does it fail in the same way? If so, you may need to investigate if the machine can access Google buckets for download. Hope this helps with tracking down the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:45,safety,error,error,45,"Thanks for following up and for the detailed error log. This looks again like a connectivity issue. The deepvariant recipe needs to pull down the training files from a Google Bucket and is timing out trying to connect. Either there was a general internet issue or there is something blocking access to the bucket. If you re-try multiple times, does it fail in the same way? If so, you may need to investigate if the machine can access Google buckets for download. Hope this helps with tracking down the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:51,safety,log,log,51,"Thanks for following up and for the detailed error log. This looks again like a connectivity issue. The deepvariant recipe needs to pull down the training files from a Google Bucket and is timing out trying to connect. Either there was a general internet issue or there is something blocking access to the bucket. If you re-try multiple times, does it fail in the same way? If so, you may need to investigate if the machine can access Google buckets for download. Hope this helps with tracking down the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:51,security,log,log,51,"Thanks for following up and for the detailed error log. This looks again like a connectivity issue. The deepvariant recipe needs to pull down the training files from a Google Bucket and is timing out trying to connect. Either there was a general internet issue or there is something blocking access to the bucket. If you re-try multiple times, does it fail in the same way? If so, you may need to investigate if the machine can access Google buckets for download. Hope this helps with tracking down the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:292,security,access,access,292,"Thanks for following up and for the detailed error log. This looks again like a connectivity issue. The deepvariant recipe needs to pull down the training files from a Google Bucket and is timing out trying to connect. Either there was a general internet issue or there is something blocking access to the bucket. If you re-try multiple times, does it fail in the same way? If so, you may need to investigate if the machine can access Google buckets for download. Hope this helps with tracking down the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:428,security,access,access,428,"Thanks for following up and for the detailed error log. This looks again like a connectivity issue. The deepvariant recipe needs to pull down the training files from a Google Bucket and is timing out trying to connect. Either there was a general internet issue or there is something blocking access to the bucket. If you re-try multiple times, does it fail in the same way? If so, you may need to investigate if the machine can access Google buckets for download. Hope this helps with tracking down the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:51,testability,log,log,51,"Thanks for following up and for the detailed error log. This looks again like a connectivity issue. The deepvariant recipe needs to pull down the training files from a Google Bucket and is timing out trying to connect. Either there was a general internet issue or there is something blocking access to the bucket. If you re-try multiple times, does it fail in the same way? If so, you may need to investigate if the machine can access Google buckets for download. Hope this helps with tracking down the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:45,usability,error,error,45,"Thanks for following up and for the detailed error log. This looks again like a connectivity issue. The deepvariant recipe needs to pull down the training files from a Google Bucket and is timing out trying to connect. Either there was a general internet issue or there is something blocking access to the bucket. If you re-try multiple times, does it fail in the same way? If so, you may need to investigate if the machine can access Google buckets for download. Hope this helps with tracking down the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:474,usability,help,helps,474,"Thanks for following up and for the detailed error log. This looks again like a connectivity issue. The deepvariant recipe needs to pull down the training files from a Google Bucket and is timing out trying to connect. Either there was a general internet issue or there is something blocking access to the bucket. If you re-try multiple times, does it fail in the same way? If so, you may need to investigate if the machine can access Google buckets for download. Hope this helps with tracking down the issue.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:100,availability,down,download,100,Thanks. . I have solved this problem. The main reason is my machine can't access Google buckets for download as you say. I will close this issue.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:74,security,access,access,74,Thanks. . I have solved this problem. The main reason is my machine can't access Google buckets for download as you say. I will close this issue.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:128,usability,close,close,128,Thanks. . I have solved this problem. The main reason is my machine can't access Google buckets for download as you say. I will close this issue.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:163,availability,error,errors,163,"> Hi,. > when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. > . > CondaError: Downloaded bytes did not match Content-Length. > url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > Content-Length: 229846992. > downloaded bytes: 217650750. > . > Best. hey i have got the same error. can you pls help if it's solved by you ?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:217,availability,Down,Downloaded,217,"> Hi,. > when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. > . > CondaError: Downloaded bytes did not match Content-Length. > url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > Content-Length: 229846992. > downloaded bytes: 217650750. > . > Best. hey i have got the same error. can you pls help if it's solved by you ?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:473,availability,down,downloaded,473,"> Hi,. > when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. > . > CondaError: Downloaded bytes did not match Content-Length. > url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > Content-Length: 229846992. > downloaded bytes: 217650750. > . > Best. hey i have got the same error. can you pls help if it's solved by you ?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:538,availability,error,error,538,"> Hi,. > when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. > . > CondaError: Downloaded bytes did not match Content-Length. > url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > Content-Length: 229846992. > downloaded bytes: 217650750. > . > Best. hey i have got the same error. can you pls help if it's solved by you ?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:16,deployability,instal,install,16,"> Hi,. > when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. > . > CondaError: Downloaded bytes did not match Content-Length. > url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > Content-Length: 229846992. > downloaded bytes: 217650750. > . > Best. hey i have got the same error. can you pls help if it's solved by you ?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:72,deployability,instal,install,72,"> Hi,. > when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. > . > CondaError: Downloaded bytes did not match Content-Length. > url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > Content-Length: 229846992. > downloaded bytes: 217650750. > . > Best. hey i have got the same error. can you pls help if it's solved by you ?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:106,deployability,version,version,106,"> Hi,. > when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. > . > CondaError: Downloaded bytes did not match Content-Length. > url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > Content-Length: 229846992. > downloaded bytes: 217650750. > . > Best. hey i have got the same error. can you pls help if it's solved by you ?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:128,deployability,instal,installed,128,"> Hi,. > when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. > . > CondaError: Downloaded bytes did not match Content-Length. > url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > Content-Length: 229846992. > downloaded bytes: 217650750. > . > Best. hey i have got the same error. can you pls help if it's solved by you ?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:184,deployability,instal,installation,184,"> Hi,. > when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. > . > CondaError: Downloaded bytes did not match Content-Length. > url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > Content-Length: 229846992. > downloaded bytes: 217650750. > . > Best. hey i have got the same error. can you pls help if it's solved by you ?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:106,integrability,version,version,106,"> Hi,. > when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. > . > CondaError: Downloaded bytes did not match Content-Length. > url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > Content-Length: 229846992. > downloaded bytes: 217650750. > . > Best. hey i have got the same error. can you pls help if it's solved by you ?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:106,modifiability,version,version,106,"> Hi,. > when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. > . > CondaError: Downloaded bytes did not match Content-Length. > url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > Content-Length: 229846992. > downloaded bytes: 217650750. > . > Best. hey i have got the same error. can you pls help if it's solved by you ?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:163,performance,error,errors,163,"> Hi,. > when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. > . > CondaError: Downloaded bytes did not match Content-Length. > url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > Content-Length: 229846992. > downloaded bytes: 217650750. > . > Best. hey i have got the same error. can you pls help if it's solved by you ?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:248,performance,Content,Content-Length,248,"> Hi,. > when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. > . > CondaError: Downloaded bytes did not match Content-Length. > url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > Content-Length: 229846992. > downloaded bytes: 217650750. > . > Best. hey i have got the same error. can you pls help if it's solved by you ?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:444,performance,Content,Content-Length,444,"> Hi,. > when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. > . > CondaError: Downloaded bytes did not match Content-Length. > url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > Content-Length: 229846992. > downloaded bytes: 217650750. > . > Best. hey i have got the same error. can you pls help if it's solved by you ?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:538,performance,error,error,538,"> Hi,. > when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. > . > CondaError: Downloaded bytes did not match Content-Length. > url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > Content-Length: 229846992. > downloaded bytes: 217650750. > . > Best. hey i have got the same error. can you pls help if it's solved by you ?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:163,safety,error,errors,163,"> Hi,. > when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. > . > CondaError: Downloaded bytes did not match Content-Length. > url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > Content-Length: 229846992. > downloaded bytes: 217650750. > . > Best. hey i have got the same error. can you pls help if it's solved by you ?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:538,safety,error,error,538,"> Hi,. > when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. > . > CondaError: Downloaded bytes did not match Content-Length. > url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > Content-Length: 229846992. > downloaded bytes: 217650750. > . > Best. hey i have got the same error. can you pls help if it's solved by you ?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:57,usability,command,command,57,"> Hi,. > when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. > . > CondaError: Downloaded bytes did not match Content-Length. > url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > Content-Length: 229846992. > downloaded bytes: 217650750. > . > Best. hey i have got the same error. can you pls help if it's solved by you ?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:163,usability,error,errors,163,"> Hi,. > when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. > . > CondaError: Downloaded bytes did not match Content-Length. > url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > Content-Length: 229846992. > downloaded bytes: 217650750. > . > Best. hey i have got the same error. can you pls help if it's solved by you ?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:538,usability,error,error,538,"> Hi,. > when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. > . > CondaError: Downloaded bytes did not match Content-Length. > url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > Content-Length: 229846992. > downloaded bytes: 217650750. > . > Best. hey i have got the same error. can you pls help if it's solved by you ?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/228:557,usability,help,help,557,"> Hi,. > when I install deepvariant by anaconda with the command ""conda install -c bioconda deepvariant"", version 0.8.0 will be installed, but I got the following errors at the end of installation:. > . > CondaError: Downloaded bytes did not match Content-Length. > url: https://conda.anaconda.org/bioconda/linux-64/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > target_path: /home/ydliu/anaconda3/pkgs/deepvariant-0.8.0-py27h7333d49_0.tar.bz2. > Content-Length: 229846992. > downloaded bytes: 217650750. > . > Best. hey i have got the same error. can you pls help if it's solved by you ?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/228
https://github.com/google/deepvariant/issues/229:27,integrability,coupl,couple,27,"Hi @BowenKwan, there are a couple things I'll point you to --. 1. When you run `run_deepvariant` you can specify the `--intermediate_results_dir` flag where the examples will be saved. 2. In order to visualize, we have [this notebook](https://github.com/google/deepvariant/blob/r0.8/docs/visualizing_examples.ipynb). That should allow you to visualize the pileup images, let me know if you face any issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/229
https://github.com/google/deepvariant/issues/229:105,interoperability,specif,specify,105,"Hi @BowenKwan, there are a couple things I'll point you to --. 1. When you run `run_deepvariant` you can specify the `--intermediate_results_dir` flag where the examples will be saved. 2. In order to visualize, we have [this notebook](https://github.com/google/deepvariant/blob/r0.8/docs/visualizing_examples.ipynb). That should allow you to visualize the pileup images, let me know if you face any issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/229
https://github.com/google/deepvariant/issues/229:27,modifiability,coupl,couple,27,"Hi @BowenKwan, there are a couple things I'll point you to --. 1. When you run `run_deepvariant` you can specify the `--intermediate_results_dir` flag where the examples will be saved. 2. In order to visualize, we have [this notebook](https://github.com/google/deepvariant/blob/r0.8/docs/visualizing_examples.ipynb). That should allow you to visualize the pileup images, let me know if you face any issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/229
https://github.com/google/deepvariant/issues/229:27,testability,coupl,couple,27,"Hi @BowenKwan, there are a couple things I'll point you to --. 1. When you run `run_deepvariant` you can specify the `--intermediate_results_dir` flag where the examples will be saved. 2. In order to visualize, we have [this notebook](https://github.com/google/deepvariant/blob/r0.8/docs/visualizing_examples.ipynb). That should allow you to visualize the pileup images, let me know if you face any issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/229
https://github.com/google/deepvariant/issues/229:200,usability,visual,visualize,200,"Hi @BowenKwan, there are a couple things I'll point you to --. 1. When you run `run_deepvariant` you can specify the `--intermediate_results_dir` flag where the examples will be saved. 2. In order to visualize, we have [this notebook](https://github.com/google/deepvariant/blob/r0.8/docs/visualizing_examples.ipynb). That should allow you to visualize the pileup images, let me know if you face any issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/229
https://github.com/google/deepvariant/issues/229:342,usability,visual,visualize,342,"Hi @BowenKwan, there are a couple things I'll point you to --. 1. When you run `run_deepvariant` you can specify the `--intermediate_results_dir` flag where the examples will be saved. 2. In order to visualize, we have [this notebook](https://github.com/google/deepvariant/blob/r0.8/docs/visualizing_examples.ipynb). That should allow you to visualize the pileup images, let me know if you face any issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/229
https://github.com/google/deepvariant/issues/229:416,availability,state,stated,416,"Thank you very much for your reply. However I have 2 questions regarding the example visualization. . 1. As I am using multiple cores, the example files are splitted in to . examples.tfrecord-00000-of-00008.gz to examples.tfrecord-00007-of-00008.gz. can I simply use ""examples.tfrecord-00000-of-00008.gz"" as the source path? or do I have to combine the 8 examples file together first? 2. I cannot run the program as stated in the notebook as the `label` is not one of the features in the example for deepvariant. Is the label in the notebook the same as `alt_allele_indices/encoded` in Deepvariant? If so, how can I extract the information from the feature? I have tried 'alt_allele_indices/encoded': tf.FixedLenFeature([], tf.string), but it just gives my random symbols.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/229
https://github.com/google/deepvariant/issues/229:128,energy efficiency,core,cores,128,"Thank you very much for your reply. However I have 2 questions regarding the example visualization. . 1. As I am using multiple cores, the example files are splitted in to . examples.tfrecord-00000-of-00008.gz to examples.tfrecord-00007-of-00008.gz. can I simply use ""examples.tfrecord-00000-of-00008.gz"" as the source path? or do I have to combine the 8 examples file together first? 2. I cannot run the program as stated in the notebook as the `label` is not one of the features in the example for deepvariant. Is the label in the notebook the same as `alt_allele_indices/encoded` in Deepvariant? If so, how can I extract the information from the feature? I have tried 'alt_allele_indices/encoded': tf.FixedLenFeature([], tf.string), but it just gives my random symbols.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/229
https://github.com/google/deepvariant/issues/229:416,integrability,state,stated,416,"Thank you very much for your reply. However I have 2 questions regarding the example visualization. . 1. As I am using multiple cores, the example files are splitted in to . examples.tfrecord-00000-of-00008.gz to examples.tfrecord-00007-of-00008.gz. can I simply use ""examples.tfrecord-00000-of-00008.gz"" as the source path? or do I have to combine the 8 examples file together first? 2. I cannot run the program as stated in the notebook as the `label` is not one of the features in the example for deepvariant. Is the label in the notebook the same as `alt_allele_indices/encoded` in Deepvariant? If so, how can I extract the information from the feature? I have tried 'alt_allele_indices/encoded': tf.FixedLenFeature([], tf.string), but it just gives my random symbols.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/229
https://github.com/google/deepvariant/issues/229:256,testability,simpl,simply,256,"Thank you very much for your reply. However I have 2 questions regarding the example visualization. . 1. As I am using multiple cores, the example files are splitted in to . examples.tfrecord-00000-of-00008.gz to examples.tfrecord-00007-of-00008.gz. can I simply use ""examples.tfrecord-00000-of-00008.gz"" as the source path? or do I have to combine the 8 examples file together first? 2. I cannot run the program as stated in the notebook as the `label` is not one of the features in the example for deepvariant. Is the label in the notebook the same as `alt_allele_indices/encoded` in Deepvariant? If so, how can I extract the information from the feature? I have tried 'alt_allele_indices/encoded': tf.FixedLenFeature([], tf.string), but it just gives my random symbols.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/229
https://github.com/google/deepvariant/issues/229:85,usability,visual,visualization,85,"Thank you very much for your reply. However I have 2 questions regarding the example visualization. . 1. As I am using multiple cores, the example files are splitted in to . examples.tfrecord-00000-of-00008.gz to examples.tfrecord-00007-of-00008.gz. can I simply use ""examples.tfrecord-00000-of-00008.gz"" as the source path? or do I have to combine the 8 examples file together first? 2. I cannot run the program as stated in the notebook as the `label` is not one of the features in the example for deepvariant. Is the label in the notebook the same as `alt_allele_indices/encoded` in Deepvariant? If so, how can I extract the information from the feature? I have tried 'alt_allele_indices/encoded': tf.FixedLenFeature([], tf.string), but it just gives my random symbols.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/229
https://github.com/google/deepvariant/issues/229:256,usability,simpl,simply,256,"Thank you very much for your reply. However I have 2 questions regarding the example visualization. . 1. As I am using multiple cores, the example files are splitted in to . examples.tfrecord-00000-of-00008.gz to examples.tfrecord-00007-of-00008.gz. can I simply use ""examples.tfrecord-00000-of-00008.gz"" as the source path? or do I have to combine the 8 examples file together first? 2. I cannot run the program as stated in the notebook as the `label` is not one of the features in the example for deepvariant. Is the label in the notebook the same as `alt_allele_indices/encoded` in Deepvariant? If so, how can I extract the information from the feature? I have tried 'alt_allele_indices/encoded': tf.FixedLenFeature([], tf.string), but it just gives my random symbols.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/229
https://github.com/google/deepvariant/issues/229:69,security,Modif,Modify,69,"1. You can use each shard as the source path, no need to combine. 2. Modify the notebook as needed - the notebook goes through training examples, but in your case there won't be labels for the examples, since you're running inference (see [this](https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L852) for difference). My general recommendation is to use the notebook as a reference/template for what the Example parsing should look like, but feel free to only include keys that you are interested in.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/229
https://github.com/google/deepvariant/issues/230:553,interoperability,share,share,553,"On the first point, your understanding is correct. We have separate runs with the fraction set to different values, and these examples are merged and shuffled. Also see [this description](https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L163) from make_examples:. > Reads will be kept (randomly) with a probability of downsample_fraction from the input BAM. This argument makes it easy to create examples as though the input BAM had less coverage. For the second point, @AndrewCarroll can share some details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:411,safety,input,input,411,"On the first point, your understanding is correct. We have separate runs with the fraction set to different values, and these examples are merged and shuffled. Also see [this description](https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L163) from make_examples:. > Reads will be kept (randomly) with a probability of downsample_fraction from the input BAM. This argument makes it easy to create examples as though the input BAM had less coverage. For the second point, @AndrewCarroll can share some details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:483,safety,input,input,483,"On the first point, your understanding is correct. We have separate runs with the fraction set to different values, and these examples are merged and shuffled. Also see [this description](https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L163) from make_examples:. > Reads will be kept (randomly) with a probability of downsample_fraction from the input BAM. This argument makes it easy to create examples as though the input BAM had less coverage. For the second point, @AndrewCarroll can share some details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:25,testability,understand,understanding,25,"On the first point, your understanding is correct. We have separate runs with the fraction set to different values, and these examples are merged and shuffled. Also see [this description](https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L163) from make_examples:. > Reads will be kept (randomly) with a probability of downsample_fraction from the input BAM. This argument makes it easy to create examples as though the input BAM had less coverage. For the second point, @AndrewCarroll can share some details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:502,testability,coverag,coverage,502,"On the first point, your understanding is correct. We have separate runs with the fraction set to different values, and these examples are merged and shuffled. Also see [this description](https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L163) from make_examples:. > Reads will be kept (randomly) with a probability of downsample_fraction from the input BAM. This argument makes it easy to create examples as though the input BAM had less coverage. For the second point, @AndrewCarroll can share some details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:411,usability,input,input,411,"On the first point, your understanding is correct. We have separate runs with the fraction set to different values, and these examples are merged and shuffled. Also see [this description](https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L163) from make_examples:. > Reads will be kept (randomly) with a probability of downsample_fraction from the input BAM. This argument makes it easy to create examples as though the input BAM had less coverage. For the second point, @AndrewCarroll can share some details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:483,usability,input,input,483,"On the first point, your understanding is correct. We have separate runs with the fraction set to different values, and these examples are merged and shuffled. Also see [this description](https://github.com/google/deepvariant/blob/aff131aac3bd0cb63ee8314e32bcbf5590987fb8/deepvariant/make_examples.py#L163) from make_examples:. > Reads will be kept (randomly) with a probability of downsample_fraction from the input BAM. This argument makes it easy to create examples as though the input BAM had less coverage. For the second point, @AndrewCarroll can share some details.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:187,availability,down,downsampling,187,"Hi @anands-repo . With respect to your second point - The starting training data begins from various coverages, ranging roughly from 27x-60x. From the starting coverage of the BAM files, downsampling is applied in 0.1 increments until the coverage would reach around 20x. As a result, higher coverage ranges are slightly less represented than the 30x-20x range, but not by a substantial amount. There are two main purposes of this - the first is to allow DeepVariant to perform well across many different coverages. The second is to ensure that there are many hard examples to learn from. Our strategy in downsampling is not fixed - for example, as we add more training data in the future, we may decide to have fewer downsample increments to generally keep the same range of examples. The coverage range has also evolved over time, for example in v0.7, the range was roughly 60x-30x. Extending the range to 20x caused a very small decline in accuracy at 50x (and also therefore the case study), but resulted in more substantial gains in the 20x-30x range. I would stress that there isn't one correct downsampling strategy, as long as it represents a diversity of coverages and helps create hard examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:312,availability,sli,slightly,312,"Hi @anands-repo . With respect to your second point - The starting training data begins from various coverages, ranging roughly from 27x-60x. From the starting coverage of the BAM files, downsampling is applied in 0.1 increments until the coverage would reach around 20x. As a result, higher coverage ranges are slightly less represented than the 30x-20x range, but not by a substantial amount. There are two main purposes of this - the first is to allow DeepVariant to perform well across many different coverages. The second is to ensure that there are many hard examples to learn from. Our strategy in downsampling is not fixed - for example, as we add more training data in the future, we may decide to have fewer downsample increments to generally keep the same range of examples. The coverage range has also evolved over time, for example in v0.7, the range was roughly 60x-30x. Extending the range to 20x caused a very small decline in accuracy at 50x (and also therefore the case study), but resulted in more substantial gains in the 20x-30x range. I would stress that there isn't one correct downsampling strategy, as long as it represents a diversity of coverages and helps create hard examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:605,availability,down,downsampling,605,"Hi @anands-repo . With respect to your second point - The starting training data begins from various coverages, ranging roughly from 27x-60x. From the starting coverage of the BAM files, downsampling is applied in 0.1 increments until the coverage would reach around 20x. As a result, higher coverage ranges are slightly less represented than the 30x-20x range, but not by a substantial amount. There are two main purposes of this - the first is to allow DeepVariant to perform well across many different coverages. The second is to ensure that there are many hard examples to learn from. Our strategy in downsampling is not fixed - for example, as we add more training data in the future, we may decide to have fewer downsample increments to generally keep the same range of examples. The coverage range has also evolved over time, for example in v0.7, the range was roughly 60x-30x. Extending the range to 20x caused a very small decline in accuracy at 50x (and also therefore the case study), but resulted in more substantial gains in the 20x-30x range. I would stress that there isn't one correct downsampling strategy, as long as it represents a diversity of coverages and helps create hard examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:718,availability,down,downsample,718,"Hi @anands-repo . With respect to your second point - The starting training data begins from various coverages, ranging roughly from 27x-60x. From the starting coverage of the BAM files, downsampling is applied in 0.1 increments until the coverage would reach around 20x. As a result, higher coverage ranges are slightly less represented than the 30x-20x range, but not by a substantial amount. There are two main purposes of this - the first is to allow DeepVariant to perform well across many different coverages. The second is to ensure that there are many hard examples to learn from. Our strategy in downsampling is not fixed - for example, as we add more training data in the future, we may decide to have fewer downsample increments to generally keep the same range of examples. The coverage range has also evolved over time, for example in v0.7, the range was roughly 60x-30x. Extending the range to 20x caused a very small decline in accuracy at 50x (and also therefore the case study), but resulted in more substantial gains in the 20x-30x range. I would stress that there isn't one correct downsampling strategy, as long as it represents a diversity of coverages and helps create hard examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:1101,availability,down,downsampling,1101,"Hi @anands-repo . With respect to your second point - The starting training data begins from various coverages, ranging roughly from 27x-60x. From the starting coverage of the BAM files, downsampling is applied in 0.1 increments until the coverage would reach around 20x. As a result, higher coverage ranges are slightly less represented than the 30x-20x range, but not by a substantial amount. There are two main purposes of this - the first is to allow DeepVariant to perform well across many different coverages. The second is to ensure that there are many hard examples to learn from. Our strategy in downsampling is not fixed - for example, as we add more training data in the future, we may decide to have fewer downsample increments to generally keep the same range of examples. The coverage range has also evolved over time, for example in v0.7, the range was roughly 60x-30x. Extending the range to 20x caused a very small decline in accuracy at 50x (and also therefore the case study), but resulted in more substantial gains in the 20x-30x range. I would stress that there isn't one correct downsampling strategy, as long as it represents a diversity of coverages and helps create hard examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:375,integrability,sub,substantial,375,"Hi @anands-repo . With respect to your second point - The starting training data begins from various coverages, ranging roughly from 27x-60x. From the starting coverage of the BAM files, downsampling is applied in 0.1 increments until the coverage would reach around 20x. As a result, higher coverage ranges are slightly less represented than the 30x-20x range, but not by a substantial amount. There are two main purposes of this - the first is to allow DeepVariant to perform well across many different coverages. The second is to ensure that there are many hard examples to learn from. Our strategy in downsampling is not fixed - for example, as we add more training data in the future, we may decide to have fewer downsample increments to generally keep the same range of examples. The coverage range has also evolved over time, for example in v0.7, the range was roughly 60x-30x. Extending the range to 20x caused a very small decline in accuracy at 50x (and also therefore the case study), but resulted in more substantial gains in the 20x-30x range. I would stress that there isn't one correct downsampling strategy, as long as it represents a diversity of coverages and helps create hard examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:1017,integrability,sub,substantial,1017,"Hi @anands-repo . With respect to your second point - The starting training data begins from various coverages, ranging roughly from 27x-60x. From the starting coverage of the BAM files, downsampling is applied in 0.1 increments until the coverage would reach around 20x. As a result, higher coverage ranges are slightly less represented than the 30x-20x range, but not by a substantial amount. There are two main purposes of this - the first is to allow DeepVariant to perform well across many different coverages. The second is to ensure that there are many hard examples to learn from. Our strategy in downsampling is not fixed - for example, as we add more training data in the future, we may decide to have fewer downsample increments to generally keep the same range of examples. The coverage range has also evolved over time, for example in v0.7, the range was roughly 60x-30x. Extending the range to 20x caused a very small decline in accuracy at 50x (and also therefore the case study), but resulted in more substantial gains in the 20x-30x range. I would stress that there isn't one correct downsampling strategy, as long as it represents a diversity of coverages and helps create hard examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:814,modifiability,evolv,evolved,814,"Hi @anands-repo . With respect to your second point - The starting training data begins from various coverages, ranging roughly from 27x-60x. From the starting coverage of the BAM files, downsampling is applied in 0.1 increments until the coverage would reach around 20x. As a result, higher coverage ranges are slightly less represented than the 30x-20x range, but not by a substantial amount. There are two main purposes of this - the first is to allow DeepVariant to perform well across many different coverages. The second is to ensure that there are many hard examples to learn from. Our strategy in downsampling is not fixed - for example, as we add more training data in the future, we may decide to have fewer downsample increments to generally keep the same range of examples. The coverage range has also evolved over time, for example in v0.7, the range was roughly 60x-30x. Extending the range to 20x caused a very small decline in accuracy at 50x (and also therefore the case study), but resulted in more substantial gains in the 20x-30x range. I would stress that there isn't one correct downsampling strategy, as long as it represents a diversity of coverages and helps create hard examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:885,modifiability,Exten,Extending,885,"Hi @anands-repo . With respect to your second point - The starting training data begins from various coverages, ranging roughly from 27x-60x. From the starting coverage of the BAM files, downsampling is applied in 0.1 increments until the coverage would reach around 20x. As a result, higher coverage ranges are slightly less represented than the 30x-20x range, but not by a substantial amount. There are two main purposes of this - the first is to allow DeepVariant to perform well across many different coverages. The second is to ensure that there are many hard examples to learn from. Our strategy in downsampling is not fixed - for example, as we add more training data in the future, we may decide to have fewer downsample increments to generally keep the same range of examples. The coverage range has also evolved over time, for example in v0.7, the range was roughly 60x-30x. Extending the range to 20x caused a very small decline in accuracy at 50x (and also therefore the case study), but resulted in more substantial gains in the 20x-30x range. I would stress that there isn't one correct downsampling strategy, as long as it represents a diversity of coverages and helps create hard examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:470,performance,perform,perform,470,"Hi @anands-repo . With respect to your second point - The starting training data begins from various coverages, ranging roughly from 27x-60x. From the starting coverage of the BAM files, downsampling is applied in 0.1 increments until the coverage would reach around 20x. As a result, higher coverage ranges are slightly less represented than the 30x-20x range, but not by a substantial amount. There are two main purposes of this - the first is to allow DeepVariant to perform well across many different coverages. The second is to ensure that there are many hard examples to learn from. Our strategy in downsampling is not fixed - for example, as we add more training data in the future, we may decide to have fewer downsample increments to generally keep the same range of examples. The coverage range has also evolved over time, for example in v0.7, the range was roughly 60x-30x. Extending the range to 20x caused a very small decline in accuracy at 50x (and also therefore the case study), but resulted in more substantial gains in the 20x-30x range. I would stress that there isn't one correct downsampling strategy, as long as it represents a diversity of coverages and helps create hard examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:827,performance,time,time,827,"Hi @anands-repo . With respect to your second point - The starting training data begins from various coverages, ranging roughly from 27x-60x. From the starting coverage of the BAM files, downsampling is applied in 0.1 increments until the coverage would reach around 20x. As a result, higher coverage ranges are slightly less represented than the 30x-20x range, but not by a substantial amount. There are two main purposes of this - the first is to allow DeepVariant to perform well across many different coverages. The second is to ensure that there are many hard examples to learn from. Our strategy in downsampling is not fixed - for example, as we add more training data in the future, we may decide to have fewer downsample increments to generally keep the same range of examples. The coverage range has also evolved over time, for example in v0.7, the range was roughly 60x-30x. Extending the range to 20x caused a very small decline in accuracy at 50x (and also therefore the case study), but resulted in more substantial gains in the 20x-30x range. I would stress that there isn't one correct downsampling strategy, as long as it represents a diversity of coverages and helps create hard examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:312,reliability,sli,slightly,312,"Hi @anands-repo . With respect to your second point - The starting training data begins from various coverages, ranging roughly from 27x-60x. From the starting coverage of the BAM files, downsampling is applied in 0.1 increments until the coverage would reach around 20x. As a result, higher coverage ranges are slightly less represented than the 30x-20x range, but not by a substantial amount. There are two main purposes of this - the first is to allow DeepVariant to perform well across many different coverages. The second is to ensure that there are many hard examples to learn from. Our strategy in downsampling is not fixed - for example, as we add more training data in the future, we may decide to have fewer downsample increments to generally keep the same range of examples. The coverage range has also evolved over time, for example in v0.7, the range was roughly 60x-30x. Extending the range to 20x caused a very small decline in accuracy at 50x (and also therefore the case study), but resulted in more substantial gains in the 20x-30x range. I would stress that there isn't one correct downsampling strategy, as long as it represents a diversity of coverages and helps create hard examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:101,testability,coverag,coverages,101,"Hi @anands-repo . With respect to your second point - The starting training data begins from various coverages, ranging roughly from 27x-60x. From the starting coverage of the BAM files, downsampling is applied in 0.1 increments until the coverage would reach around 20x. As a result, higher coverage ranges are slightly less represented than the 30x-20x range, but not by a substantial amount. There are two main purposes of this - the first is to allow DeepVariant to perform well across many different coverages. The second is to ensure that there are many hard examples to learn from. Our strategy in downsampling is not fixed - for example, as we add more training data in the future, we may decide to have fewer downsample increments to generally keep the same range of examples. The coverage range has also evolved over time, for example in v0.7, the range was roughly 60x-30x. Extending the range to 20x caused a very small decline in accuracy at 50x (and also therefore the case study), but resulted in more substantial gains in the 20x-30x range. I would stress that there isn't one correct downsampling strategy, as long as it represents a diversity of coverages and helps create hard examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:160,testability,coverag,coverage,160,"Hi @anands-repo . With respect to your second point - The starting training data begins from various coverages, ranging roughly from 27x-60x. From the starting coverage of the BAM files, downsampling is applied in 0.1 increments until the coverage would reach around 20x. As a result, higher coverage ranges are slightly less represented than the 30x-20x range, but not by a substantial amount. There are two main purposes of this - the first is to allow DeepVariant to perform well across many different coverages. The second is to ensure that there are many hard examples to learn from. Our strategy in downsampling is not fixed - for example, as we add more training data in the future, we may decide to have fewer downsample increments to generally keep the same range of examples. The coverage range has also evolved over time, for example in v0.7, the range was roughly 60x-30x. Extending the range to 20x caused a very small decline in accuracy at 50x (and also therefore the case study), but resulted in more substantial gains in the 20x-30x range. I would stress that there isn't one correct downsampling strategy, as long as it represents a diversity of coverages and helps create hard examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:239,testability,coverag,coverage,239,"Hi @anands-repo . With respect to your second point - The starting training data begins from various coverages, ranging roughly from 27x-60x. From the starting coverage of the BAM files, downsampling is applied in 0.1 increments until the coverage would reach around 20x. As a result, higher coverage ranges are slightly less represented than the 30x-20x range, but not by a substantial amount. There are two main purposes of this - the first is to allow DeepVariant to perform well across many different coverages. The second is to ensure that there are many hard examples to learn from. Our strategy in downsampling is not fixed - for example, as we add more training data in the future, we may decide to have fewer downsample increments to generally keep the same range of examples. The coverage range has also evolved over time, for example in v0.7, the range was roughly 60x-30x. Extending the range to 20x caused a very small decline in accuracy at 50x (and also therefore the case study), but resulted in more substantial gains in the 20x-30x range. I would stress that there isn't one correct downsampling strategy, as long as it represents a diversity of coverages and helps create hard examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:292,testability,coverag,coverage,292,"Hi @anands-repo . With respect to your second point - The starting training data begins from various coverages, ranging roughly from 27x-60x. From the starting coverage of the BAM files, downsampling is applied in 0.1 increments until the coverage would reach around 20x. As a result, higher coverage ranges are slightly less represented than the 30x-20x range, but not by a substantial amount. There are two main purposes of this - the first is to allow DeepVariant to perform well across many different coverages. The second is to ensure that there are many hard examples to learn from. Our strategy in downsampling is not fixed - for example, as we add more training data in the future, we may decide to have fewer downsample increments to generally keep the same range of examples. The coverage range has also evolved over time, for example in v0.7, the range was roughly 60x-30x. Extending the range to 20x caused a very small decline in accuracy at 50x (and also therefore the case study), but resulted in more substantial gains in the 20x-30x range. I would stress that there isn't one correct downsampling strategy, as long as it represents a diversity of coverages and helps create hard examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:505,testability,coverag,coverages,505,"Hi @anands-repo . With respect to your second point - The starting training data begins from various coverages, ranging roughly from 27x-60x. From the starting coverage of the BAM files, downsampling is applied in 0.1 increments until the coverage would reach around 20x. As a result, higher coverage ranges are slightly less represented than the 30x-20x range, but not by a substantial amount. There are two main purposes of this - the first is to allow DeepVariant to perform well across many different coverages. The second is to ensure that there are many hard examples to learn from. Our strategy in downsampling is not fixed - for example, as we add more training data in the future, we may decide to have fewer downsample increments to generally keep the same range of examples. The coverage range has also evolved over time, for example in v0.7, the range was roughly 60x-30x. Extending the range to 20x caused a very small decline in accuracy at 50x (and also therefore the case study), but resulted in more substantial gains in the 20x-30x range. I would stress that there isn't one correct downsampling strategy, as long as it represents a diversity of coverages and helps create hard examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:790,testability,coverag,coverage,790,"Hi @anands-repo . With respect to your second point - The starting training data begins from various coverages, ranging roughly from 27x-60x. From the starting coverage of the BAM files, downsampling is applied in 0.1 increments until the coverage would reach around 20x. As a result, higher coverage ranges are slightly less represented than the 30x-20x range, but not by a substantial amount. There are two main purposes of this - the first is to allow DeepVariant to perform well across many different coverages. The second is to ensure that there are many hard examples to learn from. Our strategy in downsampling is not fixed - for example, as we add more training data in the future, we may decide to have fewer downsample increments to generally keep the same range of examples. The coverage range has also evolved over time, for example in v0.7, the range was roughly 60x-30x. Extending the range to 20x caused a very small decline in accuracy at 50x (and also therefore the case study), but resulted in more substantial gains in the 20x-30x range. I would stress that there isn't one correct downsampling strategy, as long as it represents a diversity of coverages and helps create hard examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:1164,testability,coverag,coverages,1164,"Hi @anands-repo . With respect to your second point - The starting training data begins from various coverages, ranging roughly from 27x-60x. From the starting coverage of the BAM files, downsampling is applied in 0.1 increments until the coverage would reach around 20x. As a result, higher coverage ranges are slightly less represented than the 30x-20x range, but not by a substantial amount. There are two main purposes of this - the first is to allow DeepVariant to perform well across many different coverages. The second is to ensure that there are many hard examples to learn from. Our strategy in downsampling is not fixed - for example, as we add more training data in the future, we may decide to have fewer downsample increments to generally keep the same range of examples. The coverage range has also evolved over time, for example in v0.7, the range was roughly 60x-30x. Extending the range to 20x caused a very small decline in accuracy at 50x (and also therefore the case study), but resulted in more substantial gains in the 20x-30x range. I would stress that there isn't one correct downsampling strategy, as long as it represents a diversity of coverages and helps create hard examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:470,usability,perform,perform,470,"Hi @anands-repo . With respect to your second point - The starting training data begins from various coverages, ranging roughly from 27x-60x. From the starting coverage of the BAM files, downsampling is applied in 0.1 increments until the coverage would reach around 20x. As a result, higher coverage ranges are slightly less represented than the 30x-20x range, but not by a substantial amount. There are two main purposes of this - the first is to allow DeepVariant to perform well across many different coverages. The second is to ensure that there are many hard examples to learn from. Our strategy in downsampling is not fixed - for example, as we add more training data in the future, we may decide to have fewer downsample increments to generally keep the same range of examples. The coverage range has also evolved over time, for example in v0.7, the range was roughly 60x-30x. Extending the range to 20x caused a very small decline in accuracy at 50x (and also therefore the case study), but resulted in more substantial gains in the 20x-30x range. I would stress that there isn't one correct downsampling strategy, as long as it represents a diversity of coverages and helps create hard examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:577,usability,learn,learn,577,"Hi @anands-repo . With respect to your second point - The starting training data begins from various coverages, ranging roughly from 27x-60x. From the starting coverage of the BAM files, downsampling is applied in 0.1 increments until the coverage would reach around 20x. As a result, higher coverage ranges are slightly less represented than the 30x-20x range, but not by a substantial amount. There are two main purposes of this - the first is to allow DeepVariant to perform well across many different coverages. The second is to ensure that there are many hard examples to learn from. Our strategy in downsampling is not fixed - for example, as we add more training data in the future, we may decide to have fewer downsample increments to generally keep the same range of examples. The coverage range has also evolved over time, for example in v0.7, the range was roughly 60x-30x. Extending the range to 20x caused a very small decline in accuracy at 50x (and also therefore the case study), but resulted in more substantial gains in the 20x-30x range. I would stress that there isn't one correct downsampling strategy, as long as it represents a diversity of coverages and helps create hard examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:1178,usability,help,helps,1178,"Hi @anands-repo . With respect to your second point - The starting training data begins from various coverages, ranging roughly from 27x-60x. From the starting coverage of the BAM files, downsampling is applied in 0.1 increments until the coverage would reach around 20x. As a result, higher coverage ranges are slightly less represented than the 30x-20x range, but not by a substantial amount. There are two main purposes of this - the first is to allow DeepVariant to perform well across many different coverages. The second is to ensure that there are many hard examples to learn from. Our strategy in downsampling is not fixed - for example, as we add more training data in the future, we may decide to have fewer downsample increments to generally keep the same range of examples. The coverage range has also evolved over time, for example in v0.7, the range was roughly 60x-30x. Extending the range to 20x caused a very small decline in accuracy at 50x (and also therefore the case study), but resulted in more substantial gains in the 20x-30x range. I would stress that there isn't one correct downsampling strategy, as long as it represents a diversity of coverages and helps create hard examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:65,energy efficiency,Current,Current,65,"Thanks @sidharthgoel @AndrewCarroll ! Just one more question ... Current subsampling is static in the sense, the training loops see the same images every epoch. Just wanted to ask, did you consider doing a dynamic type of random subsampling, such that reads are selected just before entering the DNN from a fixed make_examples dump?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:73,integrability,sub,subsampling,73,"Thanks @sidharthgoel @AndrewCarroll ! Just one more question ... Current subsampling is static in the sense, the training loops see the same images every epoch. Just wanted to ask, did you consider doing a dynamic type of random subsampling, such that reads are selected just before entering the DNN from a fixed make_examples dump?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:229,integrability,sub,subsampling,229,"Thanks @sidharthgoel @AndrewCarroll ! Just one more question ... Current subsampling is static in the sense, the training loops see the same images every epoch. Just wanted to ask, did you consider doing a dynamic type of random subsampling, such that reads are selected just before entering the DNN from a fixed make_examples dump?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:91,energy efficiency,reduc,reduces,91,"Hi @anands-repo . You are correct, subsampling is static. A nice effect of this is that it reduces the complexity in terms of training reproducibility. We have not deeply investigated whether dynamic resampling (making a different image per epoch) would benefit training. It's an interesting question. It could potentially reduce overfitting that might occur at the read level and therefore allow training to progress through more epochs before a model is selected. . I think it is unlikely that this would improve the current production training setup, but it is not impossible. For the WGS training curves, there is little overfitting apparent in training graphs over a large number of epochs. For the WES training curves, some overfitting is apparent, but we suspect this is less due to signal from the read level and more due to the smaller number of regions represented in the exome. This is one reason that we currently train the exome model by warmstarting from the WGS model. It is probably worth us taking a look at some point, but likely isn't the lowest hanging fruit for us to improve performance. Thank you for the suggestion and discussion.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:323,energy efficiency,reduc,reduce,323,"Hi @anands-repo . You are correct, subsampling is static. A nice effect of this is that it reduces the complexity in terms of training reproducibility. We have not deeply investigated whether dynamic resampling (making a different image per epoch) would benefit training. It's an interesting question. It could potentially reduce overfitting that might occur at the read level and therefore allow training to progress through more epochs before a model is selected. . I think it is unlikely that this would improve the current production training setup, but it is not impossible. For the WGS training curves, there is little overfitting apparent in training graphs over a large number of epochs. For the WES training curves, some overfitting is apparent, but we suspect this is less due to signal from the read level and more due to the smaller number of regions represented in the exome. This is one reason that we currently train the exome model by warmstarting from the WGS model. It is probably worth us taking a look at some point, but likely isn't the lowest hanging fruit for us to improve performance. Thank you for the suggestion and discussion.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:447,energy efficiency,model,model,447,"Hi @anands-repo . You are correct, subsampling is static. A nice effect of this is that it reduces the complexity in terms of training reproducibility. We have not deeply investigated whether dynamic resampling (making a different image per epoch) would benefit training. It's an interesting question. It could potentially reduce overfitting that might occur at the read level and therefore allow training to progress through more epochs before a model is selected. . I think it is unlikely that this would improve the current production training setup, but it is not impossible. For the WGS training curves, there is little overfitting apparent in training graphs over a large number of epochs. For the WES training curves, some overfitting is apparent, but we suspect this is less due to signal from the read level and more due to the smaller number of regions represented in the exome. This is one reason that we currently train the exome model by warmstarting from the WGS model. It is probably worth us taking a look at some point, but likely isn't the lowest hanging fruit for us to improve performance. Thank you for the suggestion and discussion.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:519,energy efficiency,current,current,519,"Hi @anands-repo . You are correct, subsampling is static. A nice effect of this is that it reduces the complexity in terms of training reproducibility. We have not deeply investigated whether dynamic resampling (making a different image per epoch) would benefit training. It's an interesting question. It could potentially reduce overfitting that might occur at the read level and therefore allow training to progress through more epochs before a model is selected. . I think it is unlikely that this would improve the current production training setup, but it is not impossible. For the WGS training curves, there is little overfitting apparent in training graphs over a large number of epochs. For the WES training curves, some overfitting is apparent, but we suspect this is less due to signal from the read level and more due to the smaller number of regions represented in the exome. This is one reason that we currently train the exome model by warmstarting from the WGS model. It is probably worth us taking a look at some point, but likely isn't the lowest hanging fruit for us to improve performance. Thank you for the suggestion and discussion.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:916,energy efficiency,current,currently,916,"Hi @anands-repo . You are correct, subsampling is static. A nice effect of this is that it reduces the complexity in terms of training reproducibility. We have not deeply investigated whether dynamic resampling (making a different image per epoch) would benefit training. It's an interesting question. It could potentially reduce overfitting that might occur at the read level and therefore allow training to progress through more epochs before a model is selected. . I think it is unlikely that this would improve the current production training setup, but it is not impossible. For the WGS training curves, there is little overfitting apparent in training graphs over a large number of epochs. For the WES training curves, some overfitting is apparent, but we suspect this is less due to signal from the read level and more due to the smaller number of regions represented in the exome. This is one reason that we currently train the exome model by warmstarting from the WGS model. It is probably worth us taking a look at some point, but likely isn't the lowest hanging fruit for us to improve performance. Thank you for the suggestion and discussion.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:942,energy efficiency,model,model,942,"Hi @anands-repo . You are correct, subsampling is static. A nice effect of this is that it reduces the complexity in terms of training reproducibility. We have not deeply investigated whether dynamic resampling (making a different image per epoch) would benefit training. It's an interesting question. It could potentially reduce overfitting that might occur at the read level and therefore allow training to progress through more epochs before a model is selected. . I think it is unlikely that this would improve the current production training setup, but it is not impossible. For the WGS training curves, there is little overfitting apparent in training graphs over a large number of epochs. For the WES training curves, some overfitting is apparent, but we suspect this is less due to signal from the read level and more due to the smaller number of regions represented in the exome. This is one reason that we currently train the exome model by warmstarting from the WGS model. It is probably worth us taking a look at some point, but likely isn't the lowest hanging fruit for us to improve performance. Thank you for the suggestion and discussion.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:977,energy efficiency,model,model,977,"Hi @anands-repo . You are correct, subsampling is static. A nice effect of this is that it reduces the complexity in terms of training reproducibility. We have not deeply investigated whether dynamic resampling (making a different image per epoch) would benefit training. It's an interesting question. It could potentially reduce overfitting that might occur at the read level and therefore allow training to progress through more epochs before a model is selected. . I think it is unlikely that this would improve the current production training setup, but it is not impossible. For the WGS training curves, there is little overfitting apparent in training graphs over a large number of epochs. For the WES training curves, some overfitting is apparent, but we suspect this is less due to signal from the read level and more due to the smaller number of regions represented in the exome. This is one reason that we currently train the exome model by warmstarting from the WGS model. It is probably worth us taking a look at some point, but likely isn't the lowest hanging fruit for us to improve performance. Thank you for the suggestion and discussion.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:35,integrability,sub,subsampling,35,"Hi @anands-repo . You are correct, subsampling is static. A nice effect of this is that it reduces the complexity in terms of training reproducibility. We have not deeply investigated whether dynamic resampling (making a different image per epoch) would benefit training. It's an interesting question. It could potentially reduce overfitting that might occur at the read level and therefore allow training to progress through more epochs before a model is selected. . I think it is unlikely that this would improve the current production training setup, but it is not impossible. For the WGS training curves, there is little overfitting apparent in training graphs over a large number of epochs. For the WES training curves, some overfitting is apparent, but we suspect this is less due to signal from the read level and more due to the smaller number of regions represented in the exome. This is one reason that we currently train the exome model by warmstarting from the WGS model. It is probably worth us taking a look at some point, but likely isn't the lowest hanging fruit for us to improve performance. Thank you for the suggestion and discussion.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:1089,performance,improve perform,improve performance,1089,"Hi @anands-repo . You are correct, subsampling is static. A nice effect of this is that it reduces the complexity in terms of training reproducibility. We have not deeply investigated whether dynamic resampling (making a different image per epoch) would benefit training. It's an interesting question. It could potentially reduce overfitting that might occur at the read level and therefore allow training to progress through more epochs before a model is selected. . I think it is unlikely that this would improve the current production training setup, but it is not impossible. For the WGS training curves, there is little overfitting apparent in training graphs over a large number of epochs. For the WES training curves, some overfitting is apparent, but we suspect this is less due to signal from the read level and more due to the smaller number of regions represented in the exome. This is one reason that we currently train the exome model by warmstarting from the WGS model. It is probably worth us taking a look at some point, but likely isn't the lowest hanging fruit for us to improve performance. Thank you for the suggestion and discussion.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:103,safety,compl,complexity,103,"Hi @anands-repo . You are correct, subsampling is static. A nice effect of this is that it reduces the complexity in terms of training reproducibility. We have not deeply investigated whether dynamic resampling (making a different image per epoch) would benefit training. It's an interesting question. It could potentially reduce overfitting that might occur at the read level and therefore allow training to progress through more epochs before a model is selected. . I think it is unlikely that this would improve the current production training setup, but it is not impossible. For the WGS training curves, there is little overfitting apparent in training graphs over a large number of epochs. For the WES training curves, some overfitting is apparent, but we suspect this is less due to signal from the read level and more due to the smaller number of regions represented in the exome. This is one reason that we currently train the exome model by warmstarting from the WGS model. It is probably worth us taking a look at some point, but likely isn't the lowest hanging fruit for us to improve performance. Thank you for the suggestion and discussion.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:103,security,compl,complexity,103,"Hi @anands-repo . You are correct, subsampling is static. A nice effect of this is that it reduces the complexity in terms of training reproducibility. We have not deeply investigated whether dynamic resampling (making a different image per epoch) would benefit training. It's an interesting question. It could potentially reduce overfitting that might occur at the read level and therefore allow training to progress through more epochs before a model is selected. . I think it is unlikely that this would improve the current production training setup, but it is not impossible. For the WGS training curves, there is little overfitting apparent in training graphs over a large number of epochs. For the WES training curves, some overfitting is apparent, but we suspect this is less due to signal from the read level and more due to the smaller number of regions represented in the exome. This is one reason that we currently train the exome model by warmstarting from the WGS model. It is probably worth us taking a look at some point, but likely isn't the lowest hanging fruit for us to improve performance. Thank you for the suggestion and discussion.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:447,security,model,model,447,"Hi @anands-repo . You are correct, subsampling is static. A nice effect of this is that it reduces the complexity in terms of training reproducibility. We have not deeply investigated whether dynamic resampling (making a different image per epoch) would benefit training. It's an interesting question. It could potentially reduce overfitting that might occur at the read level and therefore allow training to progress through more epochs before a model is selected. . I think it is unlikely that this would improve the current production training setup, but it is not impossible. For the WGS training curves, there is little overfitting apparent in training graphs over a large number of epochs. For the WES training curves, some overfitting is apparent, but we suspect this is less due to signal from the read level and more due to the smaller number of regions represented in the exome. This is one reason that we currently train the exome model by warmstarting from the WGS model. It is probably worth us taking a look at some point, but likely isn't the lowest hanging fruit for us to improve performance. Thank you for the suggestion and discussion.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:790,security,sign,signal,790,"Hi @anands-repo . You are correct, subsampling is static. A nice effect of this is that it reduces the complexity in terms of training reproducibility. We have not deeply investigated whether dynamic resampling (making a different image per epoch) would benefit training. It's an interesting question. It could potentially reduce overfitting that might occur at the read level and therefore allow training to progress through more epochs before a model is selected. . I think it is unlikely that this would improve the current production training setup, but it is not impossible. For the WGS training curves, there is little overfitting apparent in training graphs over a large number of epochs. For the WES training curves, some overfitting is apparent, but we suspect this is less due to signal from the read level and more due to the smaller number of regions represented in the exome. This is one reason that we currently train the exome model by warmstarting from the WGS model. It is probably worth us taking a look at some point, but likely isn't the lowest hanging fruit for us to improve performance. Thank you for the suggestion and discussion.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:942,security,model,model,942,"Hi @anands-repo . You are correct, subsampling is static. A nice effect of this is that it reduces the complexity in terms of training reproducibility. We have not deeply investigated whether dynamic resampling (making a different image per epoch) would benefit training. It's an interesting question. It could potentially reduce overfitting that might occur at the read level and therefore allow training to progress through more epochs before a model is selected. . I think it is unlikely that this would improve the current production training setup, but it is not impossible. For the WGS training curves, there is little overfitting apparent in training graphs over a large number of epochs. For the WES training curves, some overfitting is apparent, but we suspect this is less due to signal from the read level and more due to the smaller number of regions represented in the exome. This is one reason that we currently train the exome model by warmstarting from the WGS model. It is probably worth us taking a look at some point, but likely isn't the lowest hanging fruit for us to improve performance. Thank you for the suggestion and discussion.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:977,security,model,model,977,"Hi @anands-repo . You are correct, subsampling is static. A nice effect of this is that it reduces the complexity in terms of training reproducibility. We have not deeply investigated whether dynamic resampling (making a different image per epoch) would benefit training. It's an interesting question. It could potentially reduce overfitting that might occur at the read level and therefore allow training to progress through more epochs before a model is selected. . I think it is unlikely that this would improve the current production training setup, but it is not impossible. For the WGS training curves, there is little overfitting apparent in training graphs over a large number of epochs. For the WES training curves, some overfitting is apparent, but we suspect this is less due to signal from the read level and more due to the smaller number of regions represented in the exome. This is one reason that we currently train the exome model by warmstarting from the WGS model. It is probably worth us taking a look at some point, but likely isn't the lowest hanging fruit for us to improve performance. Thank you for the suggestion and discussion.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:409,usability,progress,progress,409,"Hi @anands-repo . You are correct, subsampling is static. A nice effect of this is that it reduces the complexity in terms of training reproducibility. We have not deeply investigated whether dynamic resampling (making a different image per epoch) would benefit training. It's an interesting question. It could potentially reduce overfitting that might occur at the read level and therefore allow training to progress through more epochs before a model is selected. . I think it is unlikely that this would improve the current production training setup, but it is not impossible. For the WGS training curves, there is little overfitting apparent in training graphs over a large number of epochs. For the WES training curves, some overfitting is apparent, but we suspect this is less due to signal from the read level and more due to the smaller number of regions represented in the exome. This is one reason that we currently train the exome model by warmstarting from the WGS model. It is probably worth us taking a look at some point, but likely isn't the lowest hanging fruit for us to improve performance. Thank you for the suggestion and discussion.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:1097,usability,perform,performance,1097,"Hi @anands-repo . You are correct, subsampling is static. A nice effect of this is that it reduces the complexity in terms of training reproducibility. We have not deeply investigated whether dynamic resampling (making a different image per epoch) would benefit training. It's an interesting question. It could potentially reduce overfitting that might occur at the read level and therefore allow training to progress through more epochs before a model is selected. . I think it is unlikely that this would improve the current production training setup, but it is not impossible. For the WGS training curves, there is little overfitting apparent in training graphs over a large number of epochs. For the WES training curves, some overfitting is apparent, but we suspect this is less due to signal from the read level and more due to the smaller number of regions represented in the exome. This is one reason that we currently train the exome model by warmstarting from the WGS model. It is probably worth us taking a look at some point, but likely isn't the lowest hanging fruit for us to improve performance. Thank you for the suggestion and discussion.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:828,deployability,continu,continue,828,"@AndrewCarroll Thanks for sharing your thoughts. I understand regarding the complexities involved, and that this may not be a low-hanging fruit. Also, bigger gains may be had from better data I imagine. While GIAB and Platinum Genomes are great, it would be great if the Syndip dataset would be pulled into a similar effort such as GIAB. Regarding dynamic subsampling, there may also be a need to correct for some effects such as re-thresholding with the 0.12 allele fraction cut-off after subsampling etc. The effect of realignment at a lower coverage (coverage after subsampling) may come into picture as well though may be not that much. Dynamic subsampling could result in a different input data statistic overall. May be your original assessment that static subsampling reduces complexity is a good enough argument to just continue with it. Thanks for the discussion!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:775,energy efficiency,reduc,reduces,775,"@AndrewCarroll Thanks for sharing your thoughts. I understand regarding the complexities involved, and that this may not be a low-hanging fruit. Also, bigger gains may be had from better data I imagine. While GIAB and Platinum Genomes are great, it would be great if the Syndip dataset would be pulled into a similar effort such as GIAB. Regarding dynamic subsampling, there may also be a need to correct for some effects such as re-thresholding with the 0.12 allele fraction cut-off after subsampling etc. The effect of realignment at a lower coverage (coverage after subsampling) may come into picture as well though may be not that much. Dynamic subsampling could result in a different input data statistic overall. May be your original assessment that static subsampling reduces complexity is a good enough argument to just continue with it. Thanks for the discussion!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:356,integrability,sub,subsampling,356,"@AndrewCarroll Thanks for sharing your thoughts. I understand regarding the complexities involved, and that this may not be a low-hanging fruit. Also, bigger gains may be had from better data I imagine. While GIAB and Platinum Genomes are great, it would be great if the Syndip dataset would be pulled into a similar effort such as GIAB. Regarding dynamic subsampling, there may also be a need to correct for some effects such as re-thresholding with the 0.12 allele fraction cut-off after subsampling etc. The effect of realignment at a lower coverage (coverage after subsampling) may come into picture as well though may be not that much. Dynamic subsampling could result in a different input data statistic overall. May be your original assessment that static subsampling reduces complexity is a good enough argument to just continue with it. Thanks for the discussion!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:490,integrability,sub,subsampling,490,"@AndrewCarroll Thanks for sharing your thoughts. I understand regarding the complexities involved, and that this may not be a low-hanging fruit. Also, bigger gains may be had from better data I imagine. While GIAB and Platinum Genomes are great, it would be great if the Syndip dataset would be pulled into a similar effort such as GIAB. Regarding dynamic subsampling, there may also be a need to correct for some effects such as re-thresholding with the 0.12 allele fraction cut-off after subsampling etc. The effect of realignment at a lower coverage (coverage after subsampling) may come into picture as well though may be not that much. Dynamic subsampling could result in a different input data statistic overall. May be your original assessment that static subsampling reduces complexity is a good enough argument to just continue with it. Thanks for the discussion!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:569,integrability,sub,subsampling,569,"@AndrewCarroll Thanks for sharing your thoughts. I understand regarding the complexities involved, and that this may not be a low-hanging fruit. Also, bigger gains may be had from better data I imagine. While GIAB and Platinum Genomes are great, it would be great if the Syndip dataset would be pulled into a similar effort such as GIAB. Regarding dynamic subsampling, there may also be a need to correct for some effects such as re-thresholding with the 0.12 allele fraction cut-off after subsampling etc. The effect of realignment at a lower coverage (coverage after subsampling) may come into picture as well though may be not that much. Dynamic subsampling could result in a different input data statistic overall. May be your original assessment that static subsampling reduces complexity is a good enough argument to just continue with it. Thanks for the discussion!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:649,integrability,sub,subsampling,649,"@AndrewCarroll Thanks for sharing your thoughts. I understand regarding the complexities involved, and that this may not be a low-hanging fruit. Also, bigger gains may be had from better data I imagine. While GIAB and Platinum Genomes are great, it would be great if the Syndip dataset would be pulled into a similar effort such as GIAB. Regarding dynamic subsampling, there may also be a need to correct for some effects such as re-thresholding with the 0.12 allele fraction cut-off after subsampling etc. The effect of realignment at a lower coverage (coverage after subsampling) may come into picture as well though may be not that much. Dynamic subsampling could result in a different input data statistic overall. May be your original assessment that static subsampling reduces complexity is a good enough argument to just continue with it. Thanks for the discussion!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:763,integrability,sub,subsampling,763,"@AndrewCarroll Thanks for sharing your thoughts. I understand regarding the complexities involved, and that this may not be a low-hanging fruit. Also, bigger gains may be had from better data I imagine. While GIAB and Platinum Genomes are great, it would be great if the Syndip dataset would be pulled into a similar effort such as GIAB. Regarding dynamic subsampling, there may also be a need to correct for some effects such as re-thresholding with the 0.12 allele fraction cut-off after subsampling etc. The effect of realignment at a lower coverage (coverage after subsampling) may come into picture as well though may be not that much. Dynamic subsampling could result in a different input data statistic overall. May be your original assessment that static subsampling reduces complexity is a good enough argument to just continue with it. Thanks for the discussion!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:76,safety,compl,complexities,76,"@AndrewCarroll Thanks for sharing your thoughts. I understand regarding the complexities involved, and that this may not be a low-hanging fruit. Also, bigger gains may be had from better data I imagine. While GIAB and Platinum Genomes are great, it would be great if the Syndip dataset would be pulled into a similar effort such as GIAB. Regarding dynamic subsampling, there may also be a need to correct for some effects such as re-thresholding with the 0.12 allele fraction cut-off after subsampling etc. The effect of realignment at a lower coverage (coverage after subsampling) may come into picture as well though may be not that much. Dynamic subsampling could result in a different input data statistic overall. May be your original assessment that static subsampling reduces complexity is a good enough argument to just continue with it. Thanks for the discussion!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:689,safety,input,input,689,"@AndrewCarroll Thanks for sharing your thoughts. I understand regarding the complexities involved, and that this may not be a low-hanging fruit. Also, bigger gains may be had from better data I imagine. While GIAB and Platinum Genomes are great, it would be great if the Syndip dataset would be pulled into a similar effort such as GIAB. Regarding dynamic subsampling, there may also be a need to correct for some effects such as re-thresholding with the 0.12 allele fraction cut-off after subsampling etc. The effect of realignment at a lower coverage (coverage after subsampling) may come into picture as well though may be not that much. Dynamic subsampling could result in a different input data statistic overall. May be your original assessment that static subsampling reduces complexity is a good enough argument to just continue with it. Thanks for the discussion!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:783,safety,compl,complexity,783,"@AndrewCarroll Thanks for sharing your thoughts. I understand regarding the complexities involved, and that this may not be a low-hanging fruit. Also, bigger gains may be had from better data I imagine. While GIAB and Platinum Genomes are great, it would be great if the Syndip dataset would be pulled into a similar effort such as GIAB. Regarding dynamic subsampling, there may also be a need to correct for some effects such as re-thresholding with the 0.12 allele fraction cut-off after subsampling etc. The effect of realignment at a lower coverage (coverage after subsampling) may come into picture as well though may be not that much. Dynamic subsampling could result in a different input data statistic overall. May be your original assessment that static subsampling reduces complexity is a good enough argument to just continue with it. Thanks for the discussion!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:76,security,compl,complexities,76,"@AndrewCarroll Thanks for sharing your thoughts. I understand regarding the complexities involved, and that this may not be a low-hanging fruit. Also, bigger gains may be had from better data I imagine. While GIAB and Platinum Genomes are great, it would be great if the Syndip dataset would be pulled into a similar effort such as GIAB. Regarding dynamic subsampling, there may also be a need to correct for some effects such as re-thresholding with the 0.12 allele fraction cut-off after subsampling etc. The effect of realignment at a lower coverage (coverage after subsampling) may come into picture as well though may be not that much. Dynamic subsampling could result in a different input data statistic overall. May be your original assessment that static subsampling reduces complexity is a good enough argument to just continue with it. Thanks for the discussion!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:740,security,assess,assessment,740,"@AndrewCarroll Thanks for sharing your thoughts. I understand regarding the complexities involved, and that this may not be a low-hanging fruit. Also, bigger gains may be had from better data I imagine. While GIAB and Platinum Genomes are great, it would be great if the Syndip dataset would be pulled into a similar effort such as GIAB. Regarding dynamic subsampling, there may also be a need to correct for some effects such as re-thresholding with the 0.12 allele fraction cut-off after subsampling etc. The effect of realignment at a lower coverage (coverage after subsampling) may come into picture as well though may be not that much. Dynamic subsampling could result in a different input data statistic overall. May be your original assessment that static subsampling reduces complexity is a good enough argument to just continue with it. Thanks for the discussion!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:783,security,compl,complexity,783,"@AndrewCarroll Thanks for sharing your thoughts. I understand regarding the complexities involved, and that this may not be a low-hanging fruit. Also, bigger gains may be had from better data I imagine. While GIAB and Platinum Genomes are great, it would be great if the Syndip dataset would be pulled into a similar effort such as GIAB. Regarding dynamic subsampling, there may also be a need to correct for some effects such as re-thresholding with the 0.12 allele fraction cut-off after subsampling etc. The effect of realignment at a lower coverage (coverage after subsampling) may come into picture as well though may be not that much. Dynamic subsampling could result in a different input data statistic overall. May be your original assessment that static subsampling reduces complexity is a good enough argument to just continue with it. Thanks for the discussion!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:51,testability,understand,understand,51,"@AndrewCarroll Thanks for sharing your thoughts. I understand regarding the complexities involved, and that this may not be a low-hanging fruit. Also, bigger gains may be had from better data I imagine. While GIAB and Platinum Genomes are great, it would be great if the Syndip dataset would be pulled into a similar effort such as GIAB. Regarding dynamic subsampling, there may also be a need to correct for some effects such as re-thresholding with the 0.12 allele fraction cut-off after subsampling etc. The effect of realignment at a lower coverage (coverage after subsampling) may come into picture as well though may be not that much. Dynamic subsampling could result in a different input data statistic overall. May be your original assessment that static subsampling reduces complexity is a good enough argument to just continue with it. Thanks for the discussion!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:544,testability,coverag,coverage,544,"@AndrewCarroll Thanks for sharing your thoughts. I understand regarding the complexities involved, and that this may not be a low-hanging fruit. Also, bigger gains may be had from better data I imagine. While GIAB and Platinum Genomes are great, it would be great if the Syndip dataset would be pulled into a similar effort such as GIAB. Regarding dynamic subsampling, there may also be a need to correct for some effects such as re-thresholding with the 0.12 allele fraction cut-off after subsampling etc. The effect of realignment at a lower coverage (coverage after subsampling) may come into picture as well though may be not that much. Dynamic subsampling could result in a different input data statistic overall. May be your original assessment that static subsampling reduces complexity is a good enough argument to just continue with it. Thanks for the discussion!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:554,testability,coverag,coverage,554,"@AndrewCarroll Thanks for sharing your thoughts. I understand regarding the complexities involved, and that this may not be a low-hanging fruit. Also, bigger gains may be had from better data I imagine. While GIAB and Platinum Genomes are great, it would be great if the Syndip dataset would be pulled into a similar effort such as GIAB. Regarding dynamic subsampling, there may also be a need to correct for some effects such as re-thresholding with the 0.12 allele fraction cut-off after subsampling etc. The effect of realignment at a lower coverage (coverage after subsampling) may come into picture as well though may be not that much. Dynamic subsampling could result in a different input data statistic overall. May be your original assessment that static subsampling reduces complexity is a good enough argument to just continue with it. Thanks for the discussion!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/230:689,usability,input,input,689,"@AndrewCarroll Thanks for sharing your thoughts. I understand regarding the complexities involved, and that this may not be a low-hanging fruit. Also, bigger gains may be had from better data I imagine. While GIAB and Platinum Genomes are great, it would be great if the Syndip dataset would be pulled into a similar effort such as GIAB. Regarding dynamic subsampling, there may also be a need to correct for some effects such as re-thresholding with the 0.12 allele fraction cut-off after subsampling etc. The effect of realignment at a lower coverage (coverage after subsampling) may come into picture as well though may be not that much. Dynamic subsampling could result in a different input data statistic overall. May be your original assessment that static subsampling reduces complexity is a good enough argument to just continue with it. Thanks for the discussion!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/230
https://github.com/google/deepvariant/issues/231:170,availability,error,error,170,"Hi @mano2991 , Two questions:. (1) Can you tell me what environment (e.g., OS, version) you're running this on? . There are also a few unexpected warnings (like the ""GPG error"" ones) before the bazel error, which I don't see when I test in my run. (2). Can you try rerunning with:. `bash -x build-prereq.sh` which should give you a bit more context on what was executed around the error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:200,availability,error,error,200,"Hi @mano2991 , Two questions:. (1) Can you tell me what environment (e.g., OS, version) you're running this on? . There are also a few unexpected warnings (like the ""GPG error"" ones) before the bazel error, which I don't see when I test in my run. (2). Can you try rerunning with:. `bash -x build-prereq.sh` which should give you a bit more context on what was executed around the error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:381,availability,error,error,381,"Hi @mano2991 , Two questions:. (1) Can you tell me what environment (e.g., OS, version) you're running this on? . There are also a few unexpected warnings (like the ""GPG error"" ones) before the bazel error, which I don't see when I test in my run. (2). Can you try rerunning with:. `bash -x build-prereq.sh` which should give you a bit more context on what was executed around the error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:79,deployability,version,version,79,"Hi @mano2991 , Two questions:. (1) Can you tell me what environment (e.g., OS, version) you're running this on? . There are also a few unexpected warnings (like the ""GPG error"" ones) before the bazel error, which I don't see when I test in my run. (2). Can you try rerunning with:. `bash -x build-prereq.sh` which should give you a bit more context on what was executed around the error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:291,deployability,build,build-prereq,291,"Hi @mano2991 , Two questions:. (1) Can you tell me what environment (e.g., OS, version) you're running this on? . There are also a few unexpected warnings (like the ""GPG error"" ones) before the bazel error, which I don't see when I test in my run. (2). Can you try rerunning with:. `bash -x build-prereq.sh` which should give you a bit more context on what was executed around the error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:79,integrability,version,version,79,"Hi @mano2991 , Two questions:. (1) Can you tell me what environment (e.g., OS, version) you're running this on? . There are also a few unexpected warnings (like the ""GPG error"" ones) before the bazel error, which I don't see when I test in my run. (2). Can you try rerunning with:. `bash -x build-prereq.sh` which should give you a bit more context on what was executed around the error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:79,modifiability,version,version,79,"Hi @mano2991 , Two questions:. (1) Can you tell me what environment (e.g., OS, version) you're running this on? . There are also a few unexpected warnings (like the ""GPG error"" ones) before the bazel error, which I don't see when I test in my run. (2). Can you try rerunning with:. `bash -x build-prereq.sh` which should give you a bit more context on what was executed around the error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:170,performance,error,error,170,"Hi @mano2991 , Two questions:. (1) Can you tell me what environment (e.g., OS, version) you're running this on? . There are also a few unexpected warnings (like the ""GPG error"" ones) before the bazel error, which I don't see when I test in my run. (2). Can you try rerunning with:. `bash -x build-prereq.sh` which should give you a bit more context on what was executed around the error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:200,performance,error,error,200,"Hi @mano2991 , Two questions:. (1) Can you tell me what environment (e.g., OS, version) you're running this on? . There are also a few unexpected warnings (like the ""GPG error"" ones) before the bazel error, which I don't see when I test in my run. (2). Can you try rerunning with:. `bash -x build-prereq.sh` which should give you a bit more context on what was executed around the error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:381,performance,error,error,381,"Hi @mano2991 , Two questions:. (1) Can you tell me what environment (e.g., OS, version) you're running this on? . There are also a few unexpected warnings (like the ""GPG error"" ones) before the bazel error, which I don't see when I test in my run. (2). Can you try rerunning with:. `bash -x build-prereq.sh` which should give you a bit more context on what was executed around the error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:170,safety,error,error,170,"Hi @mano2991 , Two questions:. (1) Can you tell me what environment (e.g., OS, version) you're running this on? . There are also a few unexpected warnings (like the ""GPG error"" ones) before the bazel error, which I don't see when I test in my run. (2). Can you try rerunning with:. `bash -x build-prereq.sh` which should give you a bit more context on what was executed around the error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:200,safety,error,error,200,"Hi @mano2991 , Two questions:. (1) Can you tell me what environment (e.g., OS, version) you're running this on? . There are also a few unexpected warnings (like the ""GPG error"" ones) before the bazel error, which I don't see when I test in my run. (2). Can you try rerunning with:. `bash -x build-prereq.sh` which should give you a bit more context on what was executed around the error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:232,safety,test,test,232,"Hi @mano2991 , Two questions:. (1) Can you tell me what environment (e.g., OS, version) you're running this on? . There are also a few unexpected warnings (like the ""GPG error"" ones) before the bazel error, which I don't see when I test in my run. (2). Can you try rerunning with:. `bash -x build-prereq.sh` which should give you a bit more context on what was executed around the error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:381,safety,error,error,381,"Hi @mano2991 , Two questions:. (1) Can you tell me what environment (e.g., OS, version) you're running this on? . There are also a few unexpected warnings (like the ""GPG error"" ones) before the bazel error, which I don't see when I test in my run. (2). Can you try rerunning with:. `bash -x build-prereq.sh` which should give you a bit more context on what was executed around the error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:232,testability,test,test,232,"Hi @mano2991 , Two questions:. (1) Can you tell me what environment (e.g., OS, version) you're running this on? . There are also a few unexpected warnings (like the ""GPG error"" ones) before the bazel error, which I don't see when I test in my run. (2). Can you try rerunning with:. `bash -x build-prereq.sh` which should give you a bit more context on what was executed around the error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:341,testability,context,context,341,"Hi @mano2991 , Two questions:. (1) Can you tell me what environment (e.g., OS, version) you're running this on? . There are also a few unexpected warnings (like the ""GPG error"" ones) before the bazel error, which I don't see when I test in my run. (2). Can you try rerunning with:. `bash -x build-prereq.sh` which should give you a bit more context on what was executed around the error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:170,usability,error,error,170,"Hi @mano2991 , Two questions:. (1) Can you tell me what environment (e.g., OS, version) you're running this on? . There are also a few unexpected warnings (like the ""GPG error"" ones) before the bazel error, which I don't see when I test in my run. (2). Can you try rerunning with:. `bash -x build-prereq.sh` which should give you a bit more context on what was executed around the error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:200,usability,error,error,200,"Hi @mano2991 , Two questions:. (1) Can you tell me what environment (e.g., OS, version) you're running this on? . There are also a few unexpected warnings (like the ""GPG error"" ones) before the bazel error, which I don't see when I test in my run. (2). Can you try rerunning with:. `bash -x build-prereq.sh` which should give you a bit more context on what was executed around the error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:381,usability,error,error,381,"Hi @mano2991 , Two questions:. (1) Can you tell me what environment (e.g., OS, version) you're running this on? . There are also a few unexpected warnings (like the ""GPG error"" ones) before the bazel error, which I don't see when I test in my run. (2). Can you try rerunning with:. `bash -x build-prereq.sh` which should give you a bit more context on what was executed around the error?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:100,availability,error,error,100,"@mano2991 I'll close this issue for now, but feel free to reopen if you are still running into this error. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:100,performance,error,error,100,"@mano2991 I'll close this issue for now, but feel free to reopen if you are still running into this error. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:100,safety,error,error,100,"@mano2991 I'll close this issue for now, but feel free to reopen if you are still running into this error. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:15,usability,close,close,15,"@mano2991 I'll close this issue for now, but feel free to reopen if you are still running into this error. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/231:100,usability,error,error,100,"@mano2991 I'll close this issue for now, but feel free to reopen if you are still running into this error. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/231
https://github.com/google/deepvariant/issues/232:204,availability,error,errors,204,"I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). (2) Is this reliably reproducible on the same input? Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:431,availability,reliab,reliably,431,"I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). (2) Is this reliably reproducible on the same input? Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:543,availability,error,error,543,"I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). (2) Is this reliably reproducible on the same input? Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:294,deployability,fail,failed,294,"I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). (2) Is this reliably reproducible on the same input? Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:350,integrability,messag,message,350,"I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). (2) Is this reliably reproducible on the same input? Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:549,integrability,messag,messages,549,"I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). (2) Is this reliably reproducible on the same input? Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:350,interoperability,messag,message,350,"I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). (2) Is this reliably reproducible on the same input? Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:549,interoperability,messag,messages,549,"I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). (2) Is this reliably reproducible on the same input? Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:204,performance,error,errors,204,"I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). (2) Is this reliably reproducible on the same input? Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:543,performance,error,error,543,"I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). (2) Is this reliably reproducible on the same input? Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:294,reliability,fail,failed,294,"I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). (2) Is this reliably reproducible on the same input? Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:308,reliability,doe,doesn,308,"I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). (2) Is this reliably reproducible on the same input? Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:431,reliability,reliab,reliably,431,"I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). (2) Is this reliably reproducible on the same input? Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:170,safety,compl,completed,170,"I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). (2) Is this reliably reproducible on the same input? Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:204,safety,error,errors,204,"I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). (2) Is this reliably reproducible on the same input? Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:465,safety,input,input,465,"I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). (2) Is this reliably reproducible on the same input? Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:543,safety,error,error,543,"I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). (2) Is this reliably reproducible on the same input? Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:170,security,compl,completed,170,"I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). (2) Is this reliably reproducible on the same input? Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:38,usability,statu,status,38,"I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). (2) Is this reliably reproducible on the same input? Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:48,usability,statu,status,48,"I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). (2) Is this reliably reproducible on the same input? Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:204,usability,error,errors,204,"I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). (2) Is this reliably reproducible on the same input? Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:465,usability,input,input,465,"I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). (2) Is this reliably reproducible on the same input? Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:543,usability,error,error,543,"I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). (2) Is this reliably reproducible on the same input? Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:208,availability,error,errors,208,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:439,availability,reliab,reliably,439,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:557,availability,error,error,557,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:672,availability,reliab,reliably,672,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:803,availability,error,error,803,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:300,deployability,fail,failed,300,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1135,deployability,modul,module,1135,"k for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 20. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:724,energy efficiency,CPU,CPU,724,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:772,energy efficiency,CPU,CPU,772,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:356,integrability,messag,message,356,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:563,integrability,messag,messages,563,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1431,integrability,sub,subprocess,1431,"k for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 20. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1524,integrability,sub,subprocess,1524,"k for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 20. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1605,integrability,sub,subprocess,1605,"k for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 20. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1680,integrability,buffer,buffer,1680,"k for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 20. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:356,interoperability,messag,message,356,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:563,interoperability,messag,messages,563,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1135,modifiability,modul,module,1135,"k for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 20. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1195,modifiability,pac,packages,1195,"k for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 20. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1295,modifiability,pac,packages,1295,"k for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 20. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:208,performance,error,errors,208,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:557,performance,error,error,557,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:724,performance,CPU,CPU,724,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:772,performance,CPU,CPU,772,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:803,performance,error,error,803,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1645,performance,time,time,1645,"k for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 20. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1661,performance,parallel,parallel,1661,"k for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 20. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:300,reliability,fail,failed,300,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:314,reliability,doe,doesn,314,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:439,reliability,reliab,reliably,439,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:672,reliability,reliab,reliably,672,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:174,safety,compl,completed,174,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:208,safety,error,errors,208,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:473,safety,input,input,473,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:557,safety,error,error,557,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:708,safety,input,input,708,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:803,safety,error,error,803,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1135,safety,modul,module,1135,"k for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 20. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1791,safety,input,input,1791,"k for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 20. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:174,security,compl,completed,174,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1037,testability,Trace,Traceback,1037,"k for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 20. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:40,usability,statu,status,40,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:50,usability,statu,status,50,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:208,usability,error,errors,208,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:473,usability,input,input,473,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:557,usability,error,error,557,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:708,usability,input,input,708,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:803,usability,error,error,803,"> I tried to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1005,usability,user,user,1005,"ed to look for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit statu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1453,usability,command,command,1453,"k for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 20. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1636,usability,Command,Command,1636,"k for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 20. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:1791,usability,input,input,1791,"k for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 20. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:2002,usability,statu,status,2002,"k for the non-zero exit status 16 status, but wasn't quite able to figure out what it was. > Given that you said the same script was used the same script and completed on other things without errors, I have a few questions for you:. > (1) Is your machine somehow overloaded when this failed? (This doesn't make sense to have such a cryptic message... but just trying to figure out what might have happened.). > (2) Is this reliably reproducible on the same input? > . > Thanks for reporting. I'd like for DeepVariant to have more meaningful error messages in general. If I can figure out how to reproduce this, I'd like to improve it. Dear pichuan,. It is reliably reproducible with the same input (4x) (16x CPU, 30GB RAM). When I run on a server with 32x CPU and 60GB RAM I got similar error:. ```. I1030 20:48:33.115523 140410104575744 make_examples.py:1167] Found 487 candidate variants. I1030 20:48:33.116027 140410104575744 make_examples.py:1168] Created 499 examples. real	3m0.610s. user	74m46.176s. sys	3m15.360s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 63 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/home/dnanexus/ref.fa"" --reads ""/home/dnanexus/input.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@64.gz"" --regions ""/home/dnanexus/regions.bed"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@64.gz"" --task {}' returned non-zero exit status 20. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:86,availability,error,error,86,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:233,availability,error,error,233,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:265,availability,error,error,265,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:394,availability,error,error,394,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:708,availability,error,error,708,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:55,deployability,log,log,55,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:400,integrability,messag,message,400,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:509,integrability,wrap,wrapper,509,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:714,integrability,messag,message,714,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:168,interoperability,incompatib,incompatible,168,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:400,interoperability,messag,message,400,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:509,interoperability,wrapper,wrapper,509,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:714,interoperability,messag,message,714,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:86,performance,error,error,86,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:233,performance,error,error,233,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:265,performance,error,error,265,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:394,performance,error,error,394,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:708,performance,error,error,708,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:55,safety,log,log,55,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:86,safety,error,error,86,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:233,safety,error,error,233,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:265,safety,error,error,265,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:394,safety,error,error,394,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:708,safety,error,error,708,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:55,security,log,log,55,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:55,testability,log,log,55,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:72,usability,experien,experience,72,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:86,usability,error,error,86,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:233,usability,error,error,233,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:265,usability,error,error,265,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:280,usability,user,user-images,280,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:394,usability,error,error,394,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:708,usability,error,error,708,"Hi @bopohdr, if it's possible, can you send me to full log? In order to experience an error, I tried our example in Quick Start, but I deliberately make the FASTA file incompatible with the BAM file by removing the `chr` prefix. The error I got looks like this:. ![error](https://user-images.githubusercontent.com/471813/68056060-6f66df80-fcaf-11e9-875b-c56db1303c40.png). Note that the bottom error message is similar to yours, but it's not the most informative one, because it was just telling you that the wrapper script [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.8/scripts/run_deepvariant.py) is unable to run make_examples successfully. I'm hoping that somewhere above this last error message, you might be able to see more what have gone wrong. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:9,deployability,log,logs,9,"The full logs are attached for exit status 16 and 20: . [Logs_deepvariant.txt](https://github.com/google/deepvariant/files/3801760/Logs_deepvariant.txt). I have found, that the Deepvariant works fine for the same .bam file, but with another target region .bed file (both are attached). Again, the target file that does not work for some samples, works fine for other samples. [Works_fine_Twist_Exome_Target.txt](https://github.com/google/deepvariant/files/3801765/Works_fine_Twist_Exome_Target.txt). [does_not_work_Trusight_one_bed.txt](https://github.com/google/deepvariant/files/3801766/does_not_work_Trusight_one_bed.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:314,reliability,doe,does,314,"The full logs are attached for exit status 16 and 20: . [Logs_deepvariant.txt](https://github.com/google/deepvariant/files/3801760/Logs_deepvariant.txt). I have found, that the Deepvariant works fine for the same .bam file, but with another target region .bed file (both are attached). Again, the target file that does not work for some samples, works fine for other samples. [Works_fine_Twist_Exome_Target.txt](https://github.com/google/deepvariant/files/3801765/Works_fine_Twist_Exome_Target.txt). [does_not_work_Trusight_one_bed.txt](https://github.com/google/deepvariant/files/3801766/does_not_work_Trusight_one_bed.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:9,safety,log,logs,9,"The full logs are attached for exit status 16 and 20: . [Logs_deepvariant.txt](https://github.com/google/deepvariant/files/3801760/Logs_deepvariant.txt). I have found, that the Deepvariant works fine for the same .bam file, but with another target region .bed file (both are attached). Again, the target file that does not work for some samples, works fine for other samples. [Works_fine_Twist_Exome_Target.txt](https://github.com/google/deepvariant/files/3801765/Works_fine_Twist_Exome_Target.txt). [does_not_work_Trusight_one_bed.txt](https://github.com/google/deepvariant/files/3801766/does_not_work_Trusight_one_bed.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:9,security,log,logs,9,"The full logs are attached for exit status 16 and 20: . [Logs_deepvariant.txt](https://github.com/google/deepvariant/files/3801760/Logs_deepvariant.txt). I have found, that the Deepvariant works fine for the same .bam file, but with another target region .bed file (both are attached). Again, the target file that does not work for some samples, works fine for other samples. [Works_fine_Twist_Exome_Target.txt](https://github.com/google/deepvariant/files/3801765/Works_fine_Twist_Exome_Target.txt). [does_not_work_Trusight_one_bed.txt](https://github.com/google/deepvariant/files/3801766/does_not_work_Trusight_one_bed.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:9,testability,log,logs,9,"The full logs are attached for exit status 16 and 20: . [Logs_deepvariant.txt](https://github.com/google/deepvariant/files/3801760/Logs_deepvariant.txt). I have found, that the Deepvariant works fine for the same .bam file, but with another target region .bed file (both are attached). Again, the target file that does not work for some samples, works fine for other samples. [Works_fine_Twist_Exome_Target.txt](https://github.com/google/deepvariant/files/3801765/Works_fine_Twist_Exome_Target.txt). [does_not_work_Trusight_one_bed.txt](https://github.com/google/deepvariant/files/3801766/does_not_work_Trusight_one_bed.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:36,usability,statu,status,36,"The full logs are attached for exit status 16 and 20: . [Logs_deepvariant.txt](https://github.com/google/deepvariant/files/3801760/Logs_deepvariant.txt). I have found, that the Deepvariant works fine for the same .bam file, but with another target region .bed file (both are attached). Again, the target file that does not work for some samples, works fine for other samples. [Works_fine_Twist_Exome_Target.txt](https://github.com/google/deepvariant/files/3801765/Works_fine_Twist_Exome_Target.txt). [does_not_work_Trusight_one_bed.txt](https://github.com/google/deepvariant/files/3801766/does_not_work_Trusight_one_bed.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:54,availability,error,error,54,"Hi @bopohdr . Thank you, the log is helpful. From the error, specifically this line:. ```. ValueError: Failed precondition: Cannot query without an index. ```. It looks like maybe your BAM file doesn't have a corresponding *.bai file. Can you double check that your input BAM file has a correct *.bai file associated with it? Usually, if you have a BAM file named `foo.bam`, there should be a corresponding `foo.bam.bai` or `foo.bai` in the same directory. If it doesn't exist, please run:. `samtools index foo.bam` to generate an index file before you proceed. Let me know if this resolves your issue. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:29,deployability,log,log,29,"Hi @bopohdr . Thank you, the log is helpful. From the error, specifically this line:. ```. ValueError: Failed precondition: Cannot query without an index. ```. It looks like maybe your BAM file doesn't have a corresponding *.bai file. Can you double check that your input BAM file has a correct *.bai file associated with it? Usually, if you have a BAM file named `foo.bam`, there should be a corresponding `foo.bam.bai` or `foo.bai` in the same directory. If it doesn't exist, please run:. `samtools index foo.bam` to generate an index file before you proceed. Let me know if this resolves your issue. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:103,deployability,Fail,Failed,103,"Hi @bopohdr . Thank you, the log is helpful. From the error, specifically this line:. ```. ValueError: Failed precondition: Cannot query without an index. ```. It looks like maybe your BAM file doesn't have a corresponding *.bai file. Can you double check that your input BAM file has a correct *.bai file associated with it? Usually, if you have a BAM file named `foo.bam`, there should be a corresponding `foo.bam.bai` or `foo.bai` in the same directory. If it doesn't exist, please run:. `samtools index foo.bam` to generate an index file before you proceed. Let me know if this resolves your issue. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:61,interoperability,specif,specifically,61,"Hi @bopohdr . Thank you, the log is helpful. From the error, specifically this line:. ```. ValueError: Failed precondition: Cannot query without an index. ```. It looks like maybe your BAM file doesn't have a corresponding *.bai file. Can you double check that your input BAM file has a correct *.bai file associated with it? Usually, if you have a BAM file named `foo.bam`, there should be a corresponding `foo.bam.bai` or `foo.bai` in the same directory. If it doesn't exist, please run:. `samtools index foo.bam` to generate an index file before you proceed. Let me know if this resolves your issue. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:54,performance,error,error,54,"Hi @bopohdr . Thank you, the log is helpful. From the error, specifically this line:. ```. ValueError: Failed precondition: Cannot query without an index. ```. It looks like maybe your BAM file doesn't have a corresponding *.bai file. Can you double check that your input BAM file has a correct *.bai file associated with it? Usually, if you have a BAM file named `foo.bam`, there should be a corresponding `foo.bam.bai` or `foo.bai` in the same directory. If it doesn't exist, please run:. `samtools index foo.bam` to generate an index file before you proceed. Let me know if this resolves your issue. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:103,reliability,Fail,Failed,103,"Hi @bopohdr . Thank you, the log is helpful. From the error, specifically this line:. ```. ValueError: Failed precondition: Cannot query without an index. ```. It looks like maybe your BAM file doesn't have a corresponding *.bai file. Can you double check that your input BAM file has a correct *.bai file associated with it? Usually, if you have a BAM file named `foo.bam`, there should be a corresponding `foo.bam.bai` or `foo.bai` in the same directory. If it doesn't exist, please run:. `samtools index foo.bam` to generate an index file before you proceed. Let me know if this resolves your issue. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:194,reliability,doe,doesn,194,"Hi @bopohdr . Thank you, the log is helpful. From the error, specifically this line:. ```. ValueError: Failed precondition: Cannot query without an index. ```. It looks like maybe your BAM file doesn't have a corresponding *.bai file. Can you double check that your input BAM file has a correct *.bai file associated with it? Usually, if you have a BAM file named `foo.bam`, there should be a corresponding `foo.bam.bai` or `foo.bai` in the same directory. If it doesn't exist, please run:. `samtools index foo.bam` to generate an index file before you proceed. Let me know if this resolves your issue. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:463,reliability,doe,doesn,463,"Hi @bopohdr . Thank you, the log is helpful. From the error, specifically this line:. ```. ValueError: Failed precondition: Cannot query without an index. ```. It looks like maybe your BAM file doesn't have a corresponding *.bai file. Can you double check that your input BAM file has a correct *.bai file associated with it? Usually, if you have a BAM file named `foo.bam`, there should be a corresponding `foo.bam.bai` or `foo.bai` in the same directory. If it doesn't exist, please run:. `samtools index foo.bam` to generate an index file before you proceed. Let me know if this resolves your issue. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:29,safety,log,log,29,"Hi @bopohdr . Thank you, the log is helpful. From the error, specifically this line:. ```. ValueError: Failed precondition: Cannot query without an index. ```. It looks like maybe your BAM file doesn't have a corresponding *.bai file. Can you double check that your input BAM file has a correct *.bai file associated with it? Usually, if you have a BAM file named `foo.bam`, there should be a corresponding `foo.bam.bai` or `foo.bai` in the same directory. If it doesn't exist, please run:. `samtools index foo.bam` to generate an index file before you proceed. Let me know if this resolves your issue. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:54,safety,error,error,54,"Hi @bopohdr . Thank you, the log is helpful. From the error, specifically this line:. ```. ValueError: Failed precondition: Cannot query without an index. ```. It looks like maybe your BAM file doesn't have a corresponding *.bai file. Can you double check that your input BAM file has a correct *.bai file associated with it? Usually, if you have a BAM file named `foo.bam`, there should be a corresponding `foo.bam.bai` or `foo.bai` in the same directory. If it doesn't exist, please run:. `samtools index foo.bam` to generate an index file before you proceed. Let me know if this resolves your issue. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:266,safety,input,input,266,"Hi @bopohdr . Thank you, the log is helpful. From the error, specifically this line:. ```. ValueError: Failed precondition: Cannot query without an index. ```. It looks like maybe your BAM file doesn't have a corresponding *.bai file. Can you double check that your input BAM file has a correct *.bai file associated with it? Usually, if you have a BAM file named `foo.bam`, there should be a corresponding `foo.bam.bai` or `foo.bai` in the same directory. If it doesn't exist, please run:. `samtools index foo.bam` to generate an index file before you proceed. Let me know if this resolves your issue. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:29,security,log,log,29,"Hi @bopohdr . Thank you, the log is helpful. From the error, specifically this line:. ```. ValueError: Failed precondition: Cannot query without an index. ```. It looks like maybe your BAM file doesn't have a corresponding *.bai file. Can you double check that your input BAM file has a correct *.bai file associated with it? Usually, if you have a BAM file named `foo.bam`, there should be a corresponding `foo.bam.bai` or `foo.bai` in the same directory. If it doesn't exist, please run:. `samtools index foo.bam` to generate an index file before you proceed. Let me know if this resolves your issue. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:29,testability,log,log,29,"Hi @bopohdr . Thank you, the log is helpful. From the error, specifically this line:. ```. ValueError: Failed precondition: Cannot query without an index. ```. It looks like maybe your BAM file doesn't have a corresponding *.bai file. Can you double check that your input BAM file has a correct *.bai file associated with it? Usually, if you have a BAM file named `foo.bam`, there should be a corresponding `foo.bam.bai` or `foo.bai` in the same directory. If it doesn't exist, please run:. `samtools index foo.bam` to generate an index file before you proceed. Let me know if this resolves your issue. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:36,usability,help,helpful,36,"Hi @bopohdr . Thank you, the log is helpful. From the error, specifically this line:. ```. ValueError: Failed precondition: Cannot query without an index. ```. It looks like maybe your BAM file doesn't have a corresponding *.bai file. Can you double check that your input BAM file has a correct *.bai file associated with it? Usually, if you have a BAM file named `foo.bam`, there should be a corresponding `foo.bam.bai` or `foo.bai` in the same directory. If it doesn't exist, please run:. `samtools index foo.bam` to generate an index file before you proceed. Let me know if this resolves your issue. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:54,usability,error,error,54,"Hi @bopohdr . Thank you, the log is helpful. From the error, specifically this line:. ```. ValueError: Failed precondition: Cannot query without an index. ```. It looks like maybe your BAM file doesn't have a corresponding *.bai file. Can you double check that your input BAM file has a correct *.bai file associated with it? Usually, if you have a BAM file named `foo.bam`, there should be a corresponding `foo.bam.bai` or `foo.bai` in the same directory. If it doesn't exist, please run:. `samtools index foo.bam` to generate an index file before you proceed. Let me know if this resolves your issue. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:266,usability,input,input,266,"Hi @bopohdr . Thank you, the log is helpful. From the error, specifically this line:. ```. ValueError: Failed precondition: Cannot query without an index. ```. It looks like maybe your BAM file doesn't have a corresponding *.bai file. Can you double check that your input BAM file has a correct *.bai file associated with it? Usually, if you have a BAM file named `foo.bam`, there should be a corresponding `foo.bam.bai` or `foo.bai` in the same directory. If it doesn't exist, please run:. `samtools index foo.bam` to generate an index file before you proceed. Let me know if this resolves your issue. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:224,availability,error,error,224,"Hi @pichuan ,. You are right, the problem is with the index file. . samtools index is done for all samples before running deepvariant , however for some of the larger .bam files it did not produced index files and therefore error in deepvariant. . Thank you !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:224,performance,error,error,224,"Hi @pichuan ,. You are right, the problem is with the index file. . samtools index is done for all samples before running deepvariant , however for some of the larger .bam files it did not produced index files and therefore error in deepvariant. . Thank you !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:224,safety,error,error,224,"Hi @pichuan ,. You are right, the problem is with the index file. . samtools index is done for all samples before running deepvariant , however for some of the larger .bam files it did not produced index files and therefore error in deepvariant. . Thank you !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:224,usability,error,error,224,"Hi @pichuan ,. You are right, the problem is with the index file. . samtools index is done for all samples before running deepvariant , however for some of the larger .bam files it did not produced index files and therefore error in deepvariant. . Thank you !",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:127,usability,user,users,127,I'm glad to hear this is resolved. Thanks for reporting the issue. I'll think about how to make this a bit more obvious to the users in the future.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:190,availability,error,errors,190,"Hi @sclan . to give you an update, I made an internal fix to make sure [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py) can output more clear errors when they occur. The new code is not on GitHub yet, but will come out in the next release. Specifically, I changed the main function to be: . ```. def main(_):. check_or_create_intermediate_results_dir(FLAGS.intermediate_results_dir). check_flags(). commands = create_all_commands(). for command in commands:. print('\n***** Running the command:*****\n{}\n'.format(command)). try:. subprocess.check_call(command, shell=True, executable='/bin/bash'). except subprocess.CalledProcessError as e:. logging.info(e.output). raise. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:27,deployability,updat,update,27,"Hi @sclan . to give you an update, I made an internal fix to make sure [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py) can output more clear errors when they occur. The new code is not on GitHub yet, but will come out in the next release. Specifically, I changed the main function to be: . ```. def main(_):. check_or_create_intermediate_results_dir(FLAGS.intermediate_results_dir). check_flags(). commands = create_all_commands(). for command in commands:. print('\n***** Running the command:*****\n{}\n'.format(command)). try:. subprocess.check_call(command, shell=True, executable='/bin/bash'). except subprocess.CalledProcessError as e:. logging.info(e.output). raise. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:279,deployability,releas,release,279,"Hi @sclan . to give you an update, I made an internal fix to make sure [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py) can output more clear errors when they occur. The new code is not on GitHub yet, but will come out in the next release. Specifically, I changed the main function to be: . ```. def main(_):. check_or_create_intermediate_results_dir(FLAGS.intermediate_results_dir). check_flags(). commands = create_all_commands(). for command in commands:. print('\n***** Running the command:*****\n{}\n'.format(command)). try:. subprocess.check_call(command, shell=True, executable='/bin/bash'). except subprocess.CalledProcessError as e:. logging.info(e.output). raise. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:691,deployability,log,logging,691,"Hi @sclan . to give you an update, I made an internal fix to make sure [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py) can output more clear errors when they occur. The new code is not on GitHub yet, but will come out in the next release. Specifically, I changed the main function to be: . ```. def main(_):. check_or_create_intermediate_results_dir(FLAGS.intermediate_results_dir). check_flags(). commands = create_all_commands(). for command in commands:. print('\n***** Running the command:*****\n{}\n'.format(command)). try:. subprocess.check_call(command, shell=True, executable='/bin/bash'). except subprocess.CalledProcessError as e:. logging.info(e.output). raise. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:579,integrability,sub,subprocess,579,"Hi @sclan . to give you an update, I made an internal fix to make sure [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py) can output more clear errors when they occur. The new code is not on GitHub yet, but will come out in the next release. Specifically, I changed the main function to be: . ```. def main(_):. check_or_create_intermediate_results_dir(FLAGS.intermediate_results_dir). check_flags(). commands = create_all_commands(). for command in commands:. print('\n***** Running the command:*****\n{}\n'.format(command)). try:. subprocess.check_call(command, shell=True, executable='/bin/bash'). except subprocess.CalledProcessError as e:. logging.info(e.output). raise. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:654,integrability,sub,subprocess,654,"Hi @sclan . to give you an update, I made an internal fix to make sure [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py) can output more clear errors when they occur. The new code is not on GitHub yet, but will come out in the next release. Specifically, I changed the main function to be: . ```. def main(_):. check_or_create_intermediate_results_dir(FLAGS.intermediate_results_dir). check_flags(). commands = create_all_commands(). for command in commands:. print('\n***** Running the command:*****\n{}\n'.format(command)). try:. subprocess.check_call(command, shell=True, executable='/bin/bash'). except subprocess.CalledProcessError as e:. logging.info(e.output). raise. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:288,interoperability,Specif,Specifically,288,"Hi @sclan . to give you an update, I made an internal fix to make sure [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py) can output more clear errors when they occur. The new code is not on GitHub yet, but will come out in the next release. Specifically, I changed the main function to be: . ```. def main(_):. check_or_create_intermediate_results_dir(FLAGS.intermediate_results_dir). check_flags(). commands = create_all_commands(). for command in commands:. print('\n***** Running the command:*****\n{}\n'.format(command)). try:. subprocess.check_call(command, shell=True, executable='/bin/bash'). except subprocess.CalledProcessError as e:. logging.info(e.output). raise. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:555,interoperability,format,format,555,"Hi @sclan . to give you an update, I made an internal fix to make sure [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py) can output more clear errors when they occur. The new code is not on GitHub yet, but will come out in the next release. Specifically, I changed the main function to be: . ```. def main(_):. check_or_create_intermediate_results_dir(FLAGS.intermediate_results_dir). check_flags(). commands = create_all_commands(). for command in commands:. print('\n***** Running the command:*****\n{}\n'.format(command)). try:. subprocess.check_call(command, shell=True, executable='/bin/bash'). except subprocess.CalledProcessError as e:. logging.info(e.output). raise. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:190,performance,error,errors,190,"Hi @sclan . to give you an update, I made an internal fix to make sure [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py) can output more clear errors when they occur. The new code is not on GitHub yet, but will come out in the next release. Specifically, I changed the main function to be: . ```. def main(_):. check_or_create_intermediate_results_dir(FLAGS.intermediate_results_dir). check_flags(). commands = create_all_commands(). for command in commands:. print('\n***** Running the command:*****\n{}\n'.format(command)). try:. subprocess.check_call(command, shell=True, executable='/bin/bash'). except subprocess.CalledProcessError as e:. logging.info(e.output). raise. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:27,safety,updat,update,27,"Hi @sclan . to give you an update, I made an internal fix to make sure [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py) can output more clear errors when they occur. The new code is not on GitHub yet, but will come out in the next release. Specifically, I changed the main function to be: . ```. def main(_):. check_or_create_intermediate_results_dir(FLAGS.intermediate_results_dir). check_flags(). commands = create_all_commands(). for command in commands:. print('\n***** Running the command:*****\n{}\n'.format(command)). try:. subprocess.check_call(command, shell=True, executable='/bin/bash'). except subprocess.CalledProcessError as e:. logging.info(e.output). raise. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:190,safety,error,errors,190,"Hi @sclan . to give you an update, I made an internal fix to make sure [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py) can output more clear errors when they occur. The new code is not on GitHub yet, but will come out in the next release. Specifically, I changed the main function to be: . ```. def main(_):. check_or_create_intermediate_results_dir(FLAGS.intermediate_results_dir). check_flags(). commands = create_all_commands(). for command in commands:. print('\n***** Running the command:*****\n{}\n'.format(command)). try:. subprocess.check_call(command, shell=True, executable='/bin/bash'). except subprocess.CalledProcessError as e:. logging.info(e.output). raise. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:647,safety,except,except,647,"Hi @sclan . to give you an update, I made an internal fix to make sure [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py) can output more clear errors when they occur. The new code is not on GitHub yet, but will come out in the next release. Specifically, I changed the main function to be: . ```. def main(_):. check_or_create_intermediate_results_dir(FLAGS.intermediate_results_dir). check_flags(). commands = create_all_commands(). for command in commands:. print('\n***** Running the command:*****\n{}\n'.format(command)). try:. subprocess.check_call(command, shell=True, executable='/bin/bash'). except subprocess.CalledProcessError as e:. logging.info(e.output). raise. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:691,safety,log,logging,691,"Hi @sclan . to give you an update, I made an internal fix to make sure [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py) can output more clear errors when they occur. The new code is not on GitHub yet, but will come out in the next release. Specifically, I changed the main function to be: . ```. def main(_):. check_or_create_intermediate_results_dir(FLAGS.intermediate_results_dir). check_flags(). commands = create_all_commands(). for command in commands:. print('\n***** Running the command:*****\n{}\n'.format(command)). try:. subprocess.check_call(command, shell=True, executable='/bin/bash'). except subprocess.CalledProcessError as e:. logging.info(e.output). raise. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:27,security,updat,update,27,"Hi @sclan . to give you an update, I made an internal fix to make sure [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py) can output more clear errors when they occur. The new code is not on GitHub yet, but will come out in the next release. Specifically, I changed the main function to be: . ```. def main(_):. check_or_create_intermediate_results_dir(FLAGS.intermediate_results_dir). check_flags(). commands = create_all_commands(). for command in commands:. print('\n***** Running the command:*****\n{}\n'.format(command)). try:. subprocess.check_call(command, shell=True, executable='/bin/bash'). except subprocess.CalledProcessError as e:. logging.info(e.output). raise. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:691,security,log,logging,691,"Hi @sclan . to give you an update, I made an internal fix to make sure [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py) can output more clear errors when they occur. The new code is not on GitHub yet, but will come out in the next release. Specifically, I changed the main function to be: . ```. def main(_):. check_or_create_intermediate_results_dir(FLAGS.intermediate_results_dir). check_flags(). commands = create_all_commands(). for command in commands:. print('\n***** Running the command:*****\n{}\n'.format(command)). try:. subprocess.check_call(command, shell=True, executable='/bin/bash'). except subprocess.CalledProcessError as e:. logging.info(e.output). raise. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:691,testability,log,logging,691,"Hi @sclan . to give you an update, I made an internal fix to make sure [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py) can output more clear errors when they occur. The new code is not on GitHub yet, but will come out in the next release. Specifically, I changed the main function to be: . ```. def main(_):. check_or_create_intermediate_results_dir(FLAGS.intermediate_results_dir). check_flags(). commands = create_all_commands(). for command in commands:. print('\n***** Running the command:*****\n{}\n'.format(command)). try:. subprocess.check_call(command, shell=True, executable='/bin/bash'). except subprocess.CalledProcessError as e:. logging.info(e.output). raise. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:184,usability,clear,clear,184,"Hi @sclan . to give you an update, I made an internal fix to make sure [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py) can output more clear errors when they occur. The new code is not on GitHub yet, but will come out in the next release. Specifically, I changed the main function to be: . ```. def main(_):. check_or_create_intermediate_results_dir(FLAGS.intermediate_results_dir). check_flags(). commands = create_all_commands(). for command in commands:. print('\n***** Running the command:*****\n{}\n'.format(command)). try:. subprocess.check_call(command, shell=True, executable='/bin/bash'). except subprocess.CalledProcessError as e:. logging.info(e.output). raise. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:190,usability,error,errors,190,"Hi @sclan . to give you an update, I made an internal fix to make sure [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py) can output more clear errors when they occur. The new code is not on GitHub yet, but will come out in the next release. Specifically, I changed the main function to be: . ```. def main(_):. check_or_create_intermediate_results_dir(FLAGS.intermediate_results_dir). check_flags(). commands = create_all_commands(). for command in commands:. print('\n***** Running the command:*****\n{}\n'.format(command)). try:. subprocess.check_call(command, shell=True, executable='/bin/bash'). except subprocess.CalledProcessError as e:. logging.info(e.output). raise. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:447,usability,command,commands,447,"Hi @sclan . to give you an update, I made an internal fix to make sure [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py) can output more clear errors when they occur. The new code is not on GitHub yet, but will come out in the next release. Specifically, I changed the main function to be: . ```. def main(_):. check_or_create_intermediate_results_dir(FLAGS.intermediate_results_dir). check_flags(). commands = create_all_commands(). for command in commands:. print('\n***** Running the command:*****\n{}\n'.format(command)). try:. subprocess.check_call(command, shell=True, executable='/bin/bash'). except subprocess.CalledProcessError as e:. logging.info(e.output). raise. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:485,usability,command,command,485,"Hi @sclan . to give you an update, I made an internal fix to make sure [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py) can output more clear errors when they occur. The new code is not on GitHub yet, but will come out in the next release. Specifically, I changed the main function to be: . ```. def main(_):. check_or_create_intermediate_results_dir(FLAGS.intermediate_results_dir). check_flags(). commands = create_all_commands(). for command in commands:. print('\n***** Running the command:*****\n{}\n'.format(command)). try:. subprocess.check_call(command, shell=True, executable='/bin/bash'). except subprocess.CalledProcessError as e:. logging.info(e.output). raise. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:496,usability,command,commands,496,"Hi @sclan . to give you an update, I made an internal fix to make sure [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py) can output more clear errors when they occur. The new code is not on GitHub yet, but will come out in the next release. Specifically, I changed the main function to be: . ```. def main(_):. check_or_create_intermediate_results_dir(FLAGS.intermediate_results_dir). check_flags(). commands = create_all_commands(). for command in commands:. print('\n***** Running the command:*****\n{}\n'.format(command)). try:. subprocess.check_call(command, shell=True, executable='/bin/bash'). except subprocess.CalledProcessError as e:. logging.info(e.output). raise. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:534,usability,command,command,534,"Hi @sclan . to give you an update, I made an internal fix to make sure [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py) can output more clear errors when they occur. The new code is not on GitHub yet, but will come out in the next release. Specifically, I changed the main function to be: . ```. def main(_):. check_or_create_intermediate_results_dir(FLAGS.intermediate_results_dir). check_flags(). commands = create_all_commands(). for command in commands:. print('\n***** Running the command:*****\n{}\n'.format(command)). try:. subprocess.check_call(command, shell=True, executable='/bin/bash'). except subprocess.CalledProcessError as e:. logging.info(e.output). raise. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:562,usability,command,command,562,"Hi @sclan . to give you an update, I made an internal fix to make sure [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py) can output more clear errors when they occur. The new code is not on GitHub yet, but will come out in the next release. Specifically, I changed the main function to be: . ```. def main(_):. check_or_create_intermediate_results_dir(FLAGS.intermediate_results_dir). check_flags(). commands = create_all_commands(). for command in commands:. print('\n***** Running the command:*****\n{}\n'.format(command)). try:. subprocess.check_call(command, shell=True, executable='/bin/bash'). except subprocess.CalledProcessError as e:. logging.info(e.output). raise. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/232:601,usability,command,command,601,"Hi @sclan . to give you an update, I made an internal fix to make sure [run_deepvariant.py](https://github.com/google/deepvariant/blob/r0.9/scripts/run_deepvariant.py) can output more clear errors when they occur. The new code is not on GitHub yet, but will come out in the next release. Specifically, I changed the main function to be: . ```. def main(_):. check_or_create_intermediate_results_dir(FLAGS.intermediate_results_dir). check_flags(). commands = create_all_commands(). for command in commands:. print('\n***** Running the command:*****\n{}\n'.format(command)). try:. subprocess.check_call(command, shell=True, executable='/bin/bash'). except subprocess.CalledProcessError as e:. logging.info(e.output). raise. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/232
https://github.com/google/deepvariant/issues/233:1226,deployability,updat,updated,1226,"Hi @ydLiu-HIT . Thank you for your question. The answer to this is complicated. It looks like the region that these elements is in is a LINE element - long regions with multiple copies through the genome that have high sequence similarity to each other. Because of the high sequence similarity, reads to line elements can map to other parts of the genome, and they are generally very difficult regions to call correctly. We've seen the behavior in DeepVariant not calling variants that are near other variants and in regions with two (or more) variant-rich haplotypes. We think that one of the reasons for this is that DeepVariant has learned that these regions represent uncaptured segmental duplication and LINE elements, which are often labelled as not variant in the more comprehensive genome in a bottle truth set. . Whether these positions represent true variants at that position, or sequences from a similar LINE element elsewhere is difficult to say. Since this is HG002, if this is within the confident regions, you can see whether Genome in a Bottle indicates them to be true variants. However, Genome in a Bottle has some more recent corrections to variants in/near LINE elements, so it may be better to check the updated (though still beta) [truth set](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_v4beta_SmallVariantDraftBenchmark_07192019/). DeepVariant will output every candidate considered, so if you want to find positions that are called in this way, looking for 0/0 or ./. calls with more than 35% ALT support and within 100bp of 2 or more candidate variants may be able to pull out many of these examples. . The other option to pull out examples like this would be to intersect with a LINE element annotation track from UCSC. Please let us know if there is something unclear about this answer. This is a rather complicated concept and explanation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/233
https://github.com/google/deepvariant/issues/233:67,safety,compl,complicated,67,"Hi @ydLiu-HIT . Thank you for your question. The answer to this is complicated. It looks like the region that these elements is in is a LINE element - long regions with multiple copies through the genome that have high sequence similarity to each other. Because of the high sequence similarity, reads to line elements can map to other parts of the genome, and they are generally very difficult regions to call correctly. We've seen the behavior in DeepVariant not calling variants that are near other variants and in regions with two (or more) variant-rich haplotypes. We think that one of the reasons for this is that DeepVariant has learned that these regions represent uncaptured segmental duplication and LINE elements, which are often labelled as not variant in the more comprehensive genome in a bottle truth set. . Whether these positions represent true variants at that position, or sequences from a similar LINE element elsewhere is difficult to say. Since this is HG002, if this is within the confident regions, you can see whether Genome in a Bottle indicates them to be true variants. However, Genome in a Bottle has some more recent corrections to variants in/near LINE elements, so it may be better to check the updated (though still beta) [truth set](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_v4beta_SmallVariantDraftBenchmark_07192019/). DeepVariant will output every candidate considered, so if you want to find positions that are called in this way, looking for 0/0 or ./. calls with more than 35% ALT support and within 100bp of 2 or more candidate variants may be able to pull out many of these examples. . The other option to pull out examples like this would be to intersect with a LINE element annotation track from UCSC. Please let us know if there is something unclear about this answer. This is a rather complicated concept and explanation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/233
https://github.com/google/deepvariant/issues/233:1226,safety,updat,updated,1226,"Hi @ydLiu-HIT . Thank you for your question. The answer to this is complicated. It looks like the region that these elements is in is a LINE element - long regions with multiple copies through the genome that have high sequence similarity to each other. Because of the high sequence similarity, reads to line elements can map to other parts of the genome, and they are generally very difficult regions to call correctly. We've seen the behavior in DeepVariant not calling variants that are near other variants and in regions with two (or more) variant-rich haplotypes. We think that one of the reasons for this is that DeepVariant has learned that these regions represent uncaptured segmental duplication and LINE elements, which are often labelled as not variant in the more comprehensive genome in a bottle truth set. . Whether these positions represent true variants at that position, or sequences from a similar LINE element elsewhere is difficult to say. Since this is HG002, if this is within the confident regions, you can see whether Genome in a Bottle indicates them to be true variants. However, Genome in a Bottle has some more recent corrections to variants in/near LINE elements, so it may be better to check the updated (though still beta) [truth set](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_v4beta_SmallVariantDraftBenchmark_07192019/). DeepVariant will output every candidate considered, so if you want to find positions that are called in this way, looking for 0/0 or ./. calls with more than 35% ALT support and within 100bp of 2 or more candidate variants may be able to pull out many of these examples. . The other option to pull out examples like this would be to intersect with a LINE element annotation track from UCSC. Please let us know if there is something unclear about this answer. This is a rather complicated concept and explanation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/233
https://github.com/google/deepvariant/issues/233:1864,safety,compl,complicated,1864,"Hi @ydLiu-HIT . Thank you for your question. The answer to this is complicated. It looks like the region that these elements is in is a LINE element - long regions with multiple copies through the genome that have high sequence similarity to each other. Because of the high sequence similarity, reads to line elements can map to other parts of the genome, and they are generally very difficult regions to call correctly. We've seen the behavior in DeepVariant not calling variants that are near other variants and in regions with two (or more) variant-rich haplotypes. We think that one of the reasons for this is that DeepVariant has learned that these regions represent uncaptured segmental duplication and LINE elements, which are often labelled as not variant in the more comprehensive genome in a bottle truth set. . Whether these positions represent true variants at that position, or sequences from a similar LINE element elsewhere is difficult to say. Since this is HG002, if this is within the confident regions, you can see whether Genome in a Bottle indicates them to be true variants. However, Genome in a Bottle has some more recent corrections to variants in/near LINE elements, so it may be better to check the updated (though still beta) [truth set](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_v4beta_SmallVariantDraftBenchmark_07192019/). DeepVariant will output every candidate considered, so if you want to find positions that are called in this way, looking for 0/0 or ./. calls with more than 35% ALT support and within 100bp of 2 or more candidate variants may be able to pull out many of these examples. . The other option to pull out examples like this would be to intersect with a LINE element annotation track from UCSC. Please let us know if there is something unclear about this answer. This is a rather complicated concept and explanation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/233
https://github.com/google/deepvariant/issues/233:67,security,compl,complicated,67,"Hi @ydLiu-HIT . Thank you for your question. The answer to this is complicated. It looks like the region that these elements is in is a LINE element - long regions with multiple copies through the genome that have high sequence similarity to each other. Because of the high sequence similarity, reads to line elements can map to other parts of the genome, and they are generally very difficult regions to call correctly. We've seen the behavior in DeepVariant not calling variants that are near other variants and in regions with two (or more) variant-rich haplotypes. We think that one of the reasons for this is that DeepVariant has learned that these regions represent uncaptured segmental duplication and LINE elements, which are often labelled as not variant in the more comprehensive genome in a bottle truth set. . Whether these positions represent true variants at that position, or sequences from a similar LINE element elsewhere is difficult to say. Since this is HG002, if this is within the confident regions, you can see whether Genome in a Bottle indicates them to be true variants. However, Genome in a Bottle has some more recent corrections to variants in/near LINE elements, so it may be better to check the updated (though still beta) [truth set](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_v4beta_SmallVariantDraftBenchmark_07192019/). DeepVariant will output every candidate considered, so if you want to find positions that are called in this way, looking for 0/0 or ./. calls with more than 35% ALT support and within 100bp of 2 or more candidate variants may be able to pull out many of these examples. . The other option to pull out examples like this would be to intersect with a LINE element annotation track from UCSC. Please let us know if there is something unclear about this answer. This is a rather complicated concept and explanation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/233
https://github.com/google/deepvariant/issues/233:1226,security,updat,updated,1226,"Hi @ydLiu-HIT . Thank you for your question. The answer to this is complicated. It looks like the region that these elements is in is a LINE element - long regions with multiple copies through the genome that have high sequence similarity to each other. Because of the high sequence similarity, reads to line elements can map to other parts of the genome, and they are generally very difficult regions to call correctly. We've seen the behavior in DeepVariant not calling variants that are near other variants and in regions with two (or more) variant-rich haplotypes. We think that one of the reasons for this is that DeepVariant has learned that these regions represent uncaptured segmental duplication and LINE elements, which are often labelled as not variant in the more comprehensive genome in a bottle truth set. . Whether these positions represent true variants at that position, or sequences from a similar LINE element elsewhere is difficult to say. Since this is HG002, if this is within the confident regions, you can see whether Genome in a Bottle indicates them to be true variants. However, Genome in a Bottle has some more recent corrections to variants in/near LINE elements, so it may be better to check the updated (though still beta) [truth set](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_v4beta_SmallVariantDraftBenchmark_07192019/). DeepVariant will output every candidate considered, so if you want to find positions that are called in this way, looking for 0/0 or ./. calls with more than 35% ALT support and within 100bp of 2 or more candidate variants may be able to pull out many of these examples. . The other option to pull out examples like this would be to intersect with a LINE element annotation track from UCSC. Please let us know if there is something unclear about this answer. This is a rather complicated concept and explanation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/233
https://github.com/google/deepvariant/issues/233:1864,security,compl,complicated,1864,"Hi @ydLiu-HIT . Thank you for your question. The answer to this is complicated. It looks like the region that these elements is in is a LINE element - long regions with multiple copies through the genome that have high sequence similarity to each other. Because of the high sequence similarity, reads to line elements can map to other parts of the genome, and they are generally very difficult regions to call correctly. We've seen the behavior in DeepVariant not calling variants that are near other variants and in regions with two (or more) variant-rich haplotypes. We think that one of the reasons for this is that DeepVariant has learned that these regions represent uncaptured segmental duplication and LINE elements, which are often labelled as not variant in the more comprehensive genome in a bottle truth set. . Whether these positions represent true variants at that position, or sequences from a similar LINE element elsewhere is difficult to say. Since this is HG002, if this is within the confident regions, you can see whether Genome in a Bottle indicates them to be true variants. However, Genome in a Bottle has some more recent corrections to variants in/near LINE elements, so it may be better to check the updated (though still beta) [truth set](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_v4beta_SmallVariantDraftBenchmark_07192019/). DeepVariant will output every candidate considered, so if you want to find positions that are called in this way, looking for 0/0 or ./. calls with more than 35% ALT support and within 100bp of 2 or more candidate variants may be able to pull out many of these examples. . The other option to pull out examples like this would be to intersect with a LINE element annotation track from UCSC. Please let us know if there is something unclear about this answer. This is a rather complicated concept and explanation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/233
https://github.com/google/deepvariant/issues/233:1276,testability,trace,trace,1276,"Hi @ydLiu-HIT . Thank you for your question. The answer to this is complicated. It looks like the region that these elements is in is a LINE element - long regions with multiple copies through the genome that have high sequence similarity to each other. Because of the high sequence similarity, reads to line elements can map to other parts of the genome, and they are generally very difficult regions to call correctly. We've seen the behavior in DeepVariant not calling variants that are near other variants and in regions with two (or more) variant-rich haplotypes. We think that one of the reasons for this is that DeepVariant has learned that these regions represent uncaptured segmental duplication and LINE elements, which are often labelled as not variant in the more comprehensive genome in a bottle truth set. . Whether these positions represent true variants at that position, or sequences from a similar LINE element elsewhere is difficult to say. Since this is HG002, if this is within the confident regions, you can see whether Genome in a Bottle indicates them to be true variants. However, Genome in a Bottle has some more recent corrections to variants in/near LINE elements, so it may be better to check the updated (though still beta) [truth set](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_v4beta_SmallVariantDraftBenchmark_07192019/). DeepVariant will output every candidate considered, so if you want to find positions that are called in this way, looking for 0/0 or ./. calls with more than 35% ALT support and within 100bp of 2 or more candidate variants may be able to pull out many of these examples. . The other option to pull out examples like this would be to intersect with a LINE element annotation track from UCSC. Please let us know if there is something unclear about this answer. This is a rather complicated concept and explanation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/233
https://github.com/google/deepvariant/issues/233:436,usability,behavi,behavior,436,"Hi @ydLiu-HIT . Thank you for your question. The answer to this is complicated. It looks like the region that these elements is in is a LINE element - long regions with multiple copies through the genome that have high sequence similarity to each other. Because of the high sequence similarity, reads to line elements can map to other parts of the genome, and they are generally very difficult regions to call correctly. We've seen the behavior in DeepVariant not calling variants that are near other variants and in regions with two (or more) variant-rich haplotypes. We think that one of the reasons for this is that DeepVariant has learned that these regions represent uncaptured segmental duplication and LINE elements, which are often labelled as not variant in the more comprehensive genome in a bottle truth set. . Whether these positions represent true variants at that position, or sequences from a similar LINE element elsewhere is difficult to say. Since this is HG002, if this is within the confident regions, you can see whether Genome in a Bottle indicates them to be true variants. However, Genome in a Bottle has some more recent corrections to variants in/near LINE elements, so it may be better to check the updated (though still beta) [truth set](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_v4beta_SmallVariantDraftBenchmark_07192019/). DeepVariant will output every candidate considered, so if you want to find positions that are called in this way, looking for 0/0 or ./. calls with more than 35% ALT support and within 100bp of 2 or more candidate variants may be able to pull out many of these examples. . The other option to pull out examples like this would be to intersect with a LINE element annotation track from UCSC. Please let us know if there is something unclear about this answer. This is a rather complicated concept and explanation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/233
https://github.com/google/deepvariant/issues/233:635,usability,learn,learned,635,"Hi @ydLiu-HIT . Thank you for your question. The answer to this is complicated. It looks like the region that these elements is in is a LINE element - long regions with multiple copies through the genome that have high sequence similarity to each other. Because of the high sequence similarity, reads to line elements can map to other parts of the genome, and they are generally very difficult regions to call correctly. We've seen the behavior in DeepVariant not calling variants that are near other variants and in regions with two (or more) variant-rich haplotypes. We think that one of the reasons for this is that DeepVariant has learned that these regions represent uncaptured segmental duplication and LINE elements, which are often labelled as not variant in the more comprehensive genome in a bottle truth set. . Whether these positions represent true variants at that position, or sequences from a similar LINE element elsewhere is difficult to say. Since this is HG002, if this is within the confident regions, you can see whether Genome in a Bottle indicates them to be true variants. However, Genome in a Bottle has some more recent corrections to variants in/near LINE elements, so it may be better to check the updated (though still beta) [truth set](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_v4beta_SmallVariantDraftBenchmark_07192019/). DeepVariant will output every candidate considered, so if you want to find positions that are called in this way, looking for 0/0 or ./. calls with more than 35% ALT support and within 100bp of 2 or more candidate variants may be able to pull out many of these examples. . The other option to pull out examples like this would be to intersect with a LINE element annotation track from UCSC. Please let us know if there is something unclear about this answer. This is a rather complicated concept and explanation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/233
https://github.com/google/deepvariant/issues/233:1061,usability,indicat,indicates,1061,"Hi @ydLiu-HIT . Thank you for your question. The answer to this is complicated. It looks like the region that these elements is in is a LINE element - long regions with multiple copies through the genome that have high sequence similarity to each other. Because of the high sequence similarity, reads to line elements can map to other parts of the genome, and they are generally very difficult regions to call correctly. We've seen the behavior in DeepVariant not calling variants that are near other variants and in regions with two (or more) variant-rich haplotypes. We think that one of the reasons for this is that DeepVariant has learned that these regions represent uncaptured segmental duplication and LINE elements, which are often labelled as not variant in the more comprehensive genome in a bottle truth set. . Whether these positions represent true variants at that position, or sequences from a similar LINE element elsewhere is difficult to say. Since this is HG002, if this is within the confident regions, you can see whether Genome in a Bottle indicates them to be true variants. However, Genome in a Bottle has some more recent corrections to variants in/near LINE elements, so it may be better to check the updated (though still beta) [truth set](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_v4beta_SmallVariantDraftBenchmark_07192019/). DeepVariant will output every candidate considered, so if you want to find positions that are called in this way, looking for 0/0 or ./. calls with more than 35% ALT support and within 100bp of 2 or more candidate variants may be able to pull out many of these examples. . The other option to pull out examples like this would be to intersect with a LINE element annotation track from UCSC. Please let us know if there is something unclear about this answer. This is a rather complicated concept and explanation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/233
https://github.com/google/deepvariant/issues/233:1554,usability,support,support,1554,"Hi @ydLiu-HIT . Thank you for your question. The answer to this is complicated. It looks like the region that these elements is in is a LINE element - long regions with multiple copies through the genome that have high sequence similarity to each other. Because of the high sequence similarity, reads to line elements can map to other parts of the genome, and they are generally very difficult regions to call correctly. We've seen the behavior in DeepVariant not calling variants that are near other variants and in regions with two (or more) variant-rich haplotypes. We think that one of the reasons for this is that DeepVariant has learned that these regions represent uncaptured segmental duplication and LINE elements, which are often labelled as not variant in the more comprehensive genome in a bottle truth set. . Whether these positions represent true variants at that position, or sequences from a similar LINE element elsewhere is difficult to say. Since this is HG002, if this is within the confident regions, you can see whether Genome in a Bottle indicates them to be true variants. However, Genome in a Bottle has some more recent corrections to variants in/near LINE elements, so it may be better to check the updated (though still beta) [truth set](ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_v4beta_SmallVariantDraftBenchmark_07192019/). DeepVariant will output every candidate considered, so if you want to find positions that are called in this way, looking for 0/0 or ./. calls with more than 35% ALT support and within 100bp of 2 or more candidate variants may be able to pull out many of these examples. . The other option to pull out examples like this would be to intersect with a LINE element annotation track from UCSC. Please let us know if there is something unclear about this answer. This is a rather complicated concept and explanation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/233
https://github.com/google/deepvariant/issues/235:352,deployability,version,version,352,"Thank you for your patience! We have fixed the issue and refreshed the 0.9.0 Docker images. Please try it again and let us know if it works for you. If you did `docker pull` before and have a local copy, you will just need to run `sudo docker pull google/deepvariant:0.9.0` to refresh your local copy, otherwise `sudo docker run` should use the latest version automatically. Thanks for alerting us to this issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:360,deployability,automat,automatically,360,"Thank you for your patience! We have fixed the issue and refreshed the 0.9.0 Docker images. Please try it again and let us know if it works for you. If you did `docker pull` before and have a local copy, you will just need to run `sudo docker pull google/deepvariant:0.9.0` to refresh your local copy, otherwise `sudo docker run` should use the latest version automatically. Thanks for alerting us to this issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:352,integrability,version,version,352,"Thank you for your patience! We have fixed the issue and refreshed the 0.9.0 Docker images. Please try it again and let us know if it works for you. If you did `docker pull` before and have a local copy, you will just need to run `sudo docker pull google/deepvariant:0.9.0` to refresh your local copy, otherwise `sudo docker run` should use the latest version automatically. Thanks for alerting us to this issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:352,modifiability,version,version,352,"Thank you for your patience! We have fixed the issue and refreshed the 0.9.0 Docker images. Please try it again and let us know if it works for you. If you did `docker pull` before and have a local copy, you will just need to run `sudo docker pull google/deepvariant:0.9.0` to refresh your local copy, otherwise `sudo docker run` should use the latest version automatically. Thanks for alerting us to this issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:386,reliability,alert,alerting,386,"Thank you for your patience! We have fixed the issue and refreshed the 0.9.0 Docker images. Please try it again and let us know if it works for you. If you did `docker pull` before and have a local copy, you will just need to run `sudo docker pull google/deepvariant:0.9.0` to refresh your local copy, otherwise `sudo docker run` should use the latest version automatically. Thanks for alerting us to this issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:386,safety,aler,alerting,386,"Thank you for your patience! We have fixed the issue and refreshed the 0.9.0 Docker images. Please try it again and let us know if it works for you. If you did `docker pull` before and have a local copy, you will just need to run `sudo docker pull google/deepvariant:0.9.0` to refresh your local copy, otherwise `sudo docker run` should use the latest version automatically. Thanks for alerting us to this issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:360,testability,automat,automatically,360,"Thank you for your patience! We have fixed the issue and refreshed the 0.9.0 Docker images. Please try it again and let us know if it works for you. If you did `docker pull` before and have a local copy, you will just need to run `sudo docker pull google/deepvariant:0.9.0` to refresh your local copy, otherwise `sudo docker run` should use the latest version automatically. Thanks for alerting us to this issue!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:66,deployability,updat,updated,66,"I'm going to close this issue, but please let us know whether the updated Docker image works for you. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:66,safety,updat,updated,66,"I'm going to close this issue, but please let us know whether the updated Docker image works for you. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:66,security,updat,updated,66,"I'm going to close this issue, but please let us know whether the updated Docker image works for you. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:13,usability,close,close,13,"I'm going to close this issue, but please let us know whether the updated Docker image works for you. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:15,deployability,updat,updated,15,"Hi Maria,. The updated Docker image made the module work perfectly. I appreciate the quick fix and response. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:45,deployability,modul,module,45,"Hi Maria,. The updated Docker image made the module work perfectly. I appreciate the quick fix and response. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:45,modifiability,modul,module,45,"Hi Maria,. The updated Docker image made the module work perfectly. I appreciate the quick fix and response. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:15,safety,updat,updated,15,"Hi Maria,. The updated Docker image made the module work perfectly. I appreciate the quick fix and response. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:45,safety,modul,module,45,"Hi Maria,. The updated Docker image made the module work perfectly. I appreciate the quick fix and response. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/235:15,security,updat,updated,15,"Hi Maria,. The updated Docker image made the module work perfectly. I appreciate the quick fix and response. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/235
https://github.com/google/deepvariant/issues/236:217,availability,error,error,217,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:520,availability,avail,available,520,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:1008,availability,error,error,1008,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:86,deployability,build,building,86,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:106,deployability,version,version,106,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:119,deployability,version,version,119,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:287,deployability,version,version,287,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:318,deployability,build,build,318,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:351,deployability,build,build,351,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:464,deployability,build,build,464,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:508,deployability,modul,modules,508,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:588,deployability,Releas,Release,588,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:672,deployability,build,build,672,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:785,deployability,build,build,785,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:827,deployability,build,build,827,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:884,deployability,build,build,884,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:913,deployability,build,build,913,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:936,deployability,build,build-prereq,936,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:1032,deployability,version,version,1032,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:1063,deployability,build,build,1063,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:1090,deployability,version,version,1090,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:106,integrability,version,version,106,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:119,integrability,version,version,119,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:287,integrability,version,version,287,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:1032,integrability,version,version,1032,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:1090,integrability,version,version,1090,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:531,interoperability,Distribut,Distributor,531,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:106,modifiability,version,version,106,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:119,modifiability,version,version,119,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:287,modifiability,version,version,287,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:508,modifiability,modul,modules,508,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:1032,modifiability,version,version,1032,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:1090,modifiability,version,version,1090,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:217,performance,error,error,217,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:1008,performance,error,error,1008,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:520,reliability,availab,available,520,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:217,safety,error,error,217,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:508,safety,modul,modules,508,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:520,safety,avail,available,520,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:987,safety,compl,completed,987,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:1008,safety,error,error,1008,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:520,security,availab,available,520,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:987,security,compl,completed,987,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:217,usability,error,error,217,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:233,usability,help,help,233,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:739,usability,Confirm,Confirmed,739,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:1008,usability,error,error,1008,"Thank you for reporting the issue. Can you tell us more about what environment you're building it in? (OS version, gcc version). I tried build_and_test.sh just now, and didn't see any issue. I'd like to reproduce the error so we can help fix it for your setting. For example, here is my version:. ```. pichuan@pichuan-build:~$ uname -a. Linux pichuan-build 4.15.0-1049-gcp #52-Ubuntu SMP Fri Nov 8 10:30:54 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. pichuan@pichuan-build:~/deepvariant$ lsb_release -a. No LSB modules are available. Distributor ID: Ubuntu. Description: Ubuntu 16.04.6 LTS. Release: 16.04. Codename: xenial. ```. Then I clone our repo:. ```. pichuan@pichuan-build:~$ git clone https://github.com/google/deepvariant.git. ```. Confirmed it's on r0.9:. ```. pichuan@pichuan-build:~$ cd deepvariant/. pichuan@pichuan-build:~/deepvariant$ git branch. * r0.9. ```. And then I build:. ```. pichuan@pichuan-build:~/deepvariant$ ./build-prereq.sh && ./build_and_test.sh . ```. This completed without an error. I checked my gcc version:. ```. pichuan@pichuan-build:~/deepvariant$ gcc --version. gcc (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609. Copyright (C) 2015 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:281,availability,avail,available,281,"Thank you for answer. We are using Ubuntu 14.04 for our images (yes, still). ```. # uname -a. Linux 417d805a5037 3.10.0-1062.4.1.el7.x86_64 #1 SMP Fri Oct 18 17:15:30 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. ```. ```. root@417d805a5037:/outputs# lsb_release -a. No LSB modules are available. . Distributor ID: Ubuntu . Description: Ubuntu 14.04.6 LTS . Release: 14.04 . Codename: trusty . ```. ```. root@417d805a5037:/outputs# gcc --version . gcc (Ubuntu 4.8.4-2ubuntu1~14.04.4) 4.8.4 . Copyright (C) 2013 Free Software Foundation, Inc. . This is free software; see the source for copying conditions. There is NO . warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```. Maybe we need newer `gcc`? And we don't clone repos - we download release archives.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:753,availability,down,download,753,"Thank you for answer. We are using Ubuntu 14.04 for our images (yes, still). ```. # uname -a. Linux 417d805a5037 3.10.0-1062.4.1.el7.x86_64 #1 SMP Fri Oct 18 17:15:30 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. ```. ```. root@417d805a5037:/outputs# lsb_release -a. No LSB modules are available. . Distributor ID: Ubuntu . Description: Ubuntu 14.04.6 LTS . Release: 14.04 . Codename: trusty . ```. ```. root@417d805a5037:/outputs# gcc --version . gcc (Ubuntu 4.8.4-2ubuntu1~14.04.4) 4.8.4 . Copyright (C) 2013 Free Software Foundation, Inc. . This is free software; see the source for copying conditions. There is NO . warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```. Maybe we need newer `gcc`? And we don't clone repos - we download release archives.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:269,deployability,modul,modules,269,"Thank you for answer. We are using Ubuntu 14.04 for our images (yes, still). ```. # uname -a. Linux 417d805a5037 3.10.0-1062.4.1.el7.x86_64 #1 SMP Fri Oct 18 17:15:30 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. ```. ```. root@417d805a5037:/outputs# lsb_release -a. No LSB modules are available. . Distributor ID: Ubuntu . Description: Ubuntu 14.04.6 LTS . Release: 14.04 . Codename: trusty . ```. ```. root@417d805a5037:/outputs# gcc --version . gcc (Ubuntu 4.8.4-2ubuntu1~14.04.4) 4.8.4 . Copyright (C) 2013 Free Software Foundation, Inc. . This is free software; see the source for copying conditions. There is NO . warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```. Maybe we need newer `gcc`? And we don't clone repos - we download release archives.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:353,deployability,Releas,Release,353,"Thank you for answer. We are using Ubuntu 14.04 for our images (yes, still). ```. # uname -a. Linux 417d805a5037 3.10.0-1062.4.1.el7.x86_64 #1 SMP Fri Oct 18 17:15:30 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. ```. ```. root@417d805a5037:/outputs# lsb_release -a. No LSB modules are available. . Distributor ID: Ubuntu . Description: Ubuntu 14.04.6 LTS . Release: 14.04 . Codename: trusty . ```. ```. root@417d805a5037:/outputs# gcc --version . gcc (Ubuntu 4.8.4-2ubuntu1~14.04.4) 4.8.4 . Copyright (C) 2013 Free Software Foundation, Inc. . This is free software; see the source for copying conditions. There is NO . warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```. Maybe we need newer `gcc`? And we don't clone repos - we download release archives.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:433,deployability,version,version,433,"Thank you for answer. We are using Ubuntu 14.04 for our images (yes, still). ```. # uname -a. Linux 417d805a5037 3.10.0-1062.4.1.el7.x86_64 #1 SMP Fri Oct 18 17:15:30 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. ```. ```. root@417d805a5037:/outputs# lsb_release -a. No LSB modules are available. . Distributor ID: Ubuntu . Description: Ubuntu 14.04.6 LTS . Release: 14.04 . Codename: trusty . ```. ```. root@417d805a5037:/outputs# gcc --version . gcc (Ubuntu 4.8.4-2ubuntu1~14.04.4) 4.8.4 . Copyright (C) 2013 Free Software Foundation, Inc. . This is free software; see the source for copying conditions. There is NO . warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```. Maybe we need newer `gcc`? And we don't clone repos - we download release archives.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:762,deployability,releas,release,762,"Thank you for answer. We are using Ubuntu 14.04 for our images (yes, still). ```. # uname -a. Linux 417d805a5037 3.10.0-1062.4.1.el7.x86_64 #1 SMP Fri Oct 18 17:15:30 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. ```. ```. root@417d805a5037:/outputs# lsb_release -a. No LSB modules are available. . Distributor ID: Ubuntu . Description: Ubuntu 14.04.6 LTS . Release: 14.04 . Codename: trusty . ```. ```. root@417d805a5037:/outputs# gcc --version . gcc (Ubuntu 4.8.4-2ubuntu1~14.04.4) 4.8.4 . Copyright (C) 2013 Free Software Foundation, Inc. . This is free software; see the source for copying conditions. There is NO . warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```. Maybe we need newer `gcc`? And we don't clone repos - we download release archives.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:433,integrability,version,version,433,"Thank you for answer. We are using Ubuntu 14.04 for our images (yes, still). ```. # uname -a. Linux 417d805a5037 3.10.0-1062.4.1.el7.x86_64 #1 SMP Fri Oct 18 17:15:30 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. ```. ```. root@417d805a5037:/outputs# lsb_release -a. No LSB modules are available. . Distributor ID: Ubuntu . Description: Ubuntu 14.04.6 LTS . Release: 14.04 . Codename: trusty . ```. ```. root@417d805a5037:/outputs# gcc --version . gcc (Ubuntu 4.8.4-2ubuntu1~14.04.4) 4.8.4 . Copyright (C) 2013 Free Software Foundation, Inc. . This is free software; see the source for copying conditions. There is NO . warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```. Maybe we need newer `gcc`? And we don't clone repos - we download release archives.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:294,interoperability,Distribut,Distributor,294,"Thank you for answer. We are using Ubuntu 14.04 for our images (yes, still). ```. # uname -a. Linux 417d805a5037 3.10.0-1062.4.1.el7.x86_64 #1 SMP Fri Oct 18 17:15:30 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. ```. ```. root@417d805a5037:/outputs# lsb_release -a. No LSB modules are available. . Distributor ID: Ubuntu . Description: Ubuntu 14.04.6 LTS . Release: 14.04 . Codename: trusty . ```. ```. root@417d805a5037:/outputs# gcc --version . gcc (Ubuntu 4.8.4-2ubuntu1~14.04.4) 4.8.4 . Copyright (C) 2013 Free Software Foundation, Inc. . This is free software; see the source for copying conditions. There is NO . warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```. Maybe we need newer `gcc`? And we don't clone repos - we download release archives.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:269,modifiability,modul,modules,269,"Thank you for answer. We are using Ubuntu 14.04 for our images (yes, still). ```. # uname -a. Linux 417d805a5037 3.10.0-1062.4.1.el7.x86_64 #1 SMP Fri Oct 18 17:15:30 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. ```. ```. root@417d805a5037:/outputs# lsb_release -a. No LSB modules are available. . Distributor ID: Ubuntu . Description: Ubuntu 14.04.6 LTS . Release: 14.04 . Codename: trusty . ```. ```. root@417d805a5037:/outputs# gcc --version . gcc (Ubuntu 4.8.4-2ubuntu1~14.04.4) 4.8.4 . Copyright (C) 2013 Free Software Foundation, Inc. . This is free software; see the source for copying conditions. There is NO . warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```. Maybe we need newer `gcc`? And we don't clone repos - we download release archives.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:433,modifiability,version,version,433,"Thank you for answer. We are using Ubuntu 14.04 for our images (yes, still). ```. # uname -a. Linux 417d805a5037 3.10.0-1062.4.1.el7.x86_64 #1 SMP Fri Oct 18 17:15:30 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. ```. ```. root@417d805a5037:/outputs# lsb_release -a. No LSB modules are available. . Distributor ID: Ubuntu . Description: Ubuntu 14.04.6 LTS . Release: 14.04 . Codename: trusty . ```. ```. root@417d805a5037:/outputs# gcc --version . gcc (Ubuntu 4.8.4-2ubuntu1~14.04.4) 4.8.4 . Copyright (C) 2013 Free Software Foundation, Inc. . This is free software; see the source for copying conditions. There is NO . warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```. Maybe we need newer `gcc`? And we don't clone repos - we download release archives.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:281,reliability,availab,available,281,"Thank you for answer. We are using Ubuntu 14.04 for our images (yes, still). ```. # uname -a. Linux 417d805a5037 3.10.0-1062.4.1.el7.x86_64 #1 SMP Fri Oct 18 17:15:30 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. ```. ```. root@417d805a5037:/outputs# lsb_release -a. No LSB modules are available. . Distributor ID: Ubuntu . Description: Ubuntu 14.04.6 LTS . Release: 14.04 . Codename: trusty . ```. ```. root@417d805a5037:/outputs# gcc --version . gcc (Ubuntu 4.8.4-2ubuntu1~14.04.4) 4.8.4 . Copyright (C) 2013 Free Software Foundation, Inc. . This is free software; see the source for copying conditions. There is NO . warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```. Maybe we need newer `gcc`? And we don't clone repos - we download release archives.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:269,safety,modul,modules,269,"Thank you for answer. We are using Ubuntu 14.04 for our images (yes, still). ```. # uname -a. Linux 417d805a5037 3.10.0-1062.4.1.el7.x86_64 #1 SMP Fri Oct 18 17:15:30 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. ```. ```. root@417d805a5037:/outputs# lsb_release -a. No LSB modules are available. . Distributor ID: Ubuntu . Description: Ubuntu 14.04.6 LTS . Release: 14.04 . Codename: trusty . ```. ```. root@417d805a5037:/outputs# gcc --version . gcc (Ubuntu 4.8.4-2ubuntu1~14.04.4) 4.8.4 . Copyright (C) 2013 Free Software Foundation, Inc. . This is free software; see the source for copying conditions. There is NO . warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```. Maybe we need newer `gcc`? And we don't clone repos - we download release archives.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:281,safety,avail,available,281,"Thank you for answer. We are using Ubuntu 14.04 for our images (yes, still). ```. # uname -a. Linux 417d805a5037 3.10.0-1062.4.1.el7.x86_64 #1 SMP Fri Oct 18 17:15:30 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. ```. ```. root@417d805a5037:/outputs# lsb_release -a. No LSB modules are available. . Distributor ID: Ubuntu . Description: Ubuntu 14.04.6 LTS . Release: 14.04 . Codename: trusty . ```. ```. root@417d805a5037:/outputs# gcc --version . gcc (Ubuntu 4.8.4-2ubuntu1~14.04.4) 4.8.4 . Copyright (C) 2013 Free Software Foundation, Inc. . This is free software; see the source for copying conditions. There is NO . warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```. Maybe we need newer `gcc`? And we don't clone repos - we download release archives.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:281,security,availab,available,281,"Thank you for answer. We are using Ubuntu 14.04 for our images (yes, still). ```. # uname -a. Linux 417d805a5037 3.10.0-1062.4.1.el7.x86_64 #1 SMP Fri Oct 18 17:15:30 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. ```. ```. root@417d805a5037:/outputs# lsb_release -a. No LSB modules are available. . Distributor ID: Ubuntu . Description: Ubuntu 14.04.6 LTS . Release: 14.04 . Codename: trusty . ```. ```. root@417d805a5037:/outputs# gcc --version . gcc (Ubuntu 4.8.4-2ubuntu1~14.04.4) 4.8.4 . Copyright (C) 2013 Free Software Foundation, Inc. . This is free software; see the source for copying conditions. There is NO . warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```. Maybe we need newer `gcc`? And we don't clone repos - we download release archives.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:380,security,trust,trusty,380,"Thank you for answer. We are using Ubuntu 14.04 for our images (yes, still). ```. # uname -a. Linux 417d805a5037 3.10.0-1062.4.1.el7.x86_64 #1 SMP Fri Oct 18 17:15:30 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux. ```. ```. root@417d805a5037:/outputs# lsb_release -a. No LSB modules are available. . Distributor ID: Ubuntu . Description: Ubuntu 14.04.6 LTS . Release: 14.04 . Codename: trusty . ```. ```. root@417d805a5037:/outputs# gcc --version . gcc (Ubuntu 4.8.4-2ubuntu1~14.04.4) 4.8.4 . Copyright (C) 2013 Free Software Foundation, Inc. . This is free software; see the source for copying conditions. There is NO . warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. ```. Maybe we need newer `gcc`? And we don't clone repos - we download release archives.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:88,deployability,build,building,88,"@Stikus Hi, I was able to reproduce the issue on Ubuntu 14. We don't officially support building on Ubuntu 14, but I'll give it a try and see if I'm able to get it to work. I can give an update later. One question for you - Can you tell us the reason why you're not using our Docker image, and instead building your own binaries? It'll be useful for us to understand what our users need so we can prioritize the right things. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:187,deployability,updat,update,187,"@Stikus Hi, I was able to reproduce the issue on Ubuntu 14. We don't officially support building on Ubuntu 14, but I'll give it a try and see if I'm able to get it to work. I can give an update later. One question for you - Can you tell us the reason why you're not using our Docker image, and instead building your own binaries? It'll be useful for us to understand what our users need so we can prioritize the right things. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:302,deployability,build,building,302,"@Stikus Hi, I was able to reproduce the issue on Ubuntu 14. We don't officially support building on Ubuntu 14, but I'll give it a try and see if I'm able to get it to work. I can give an update later. One question for you - Can you tell us the reason why you're not using our Docker image, and instead building your own binaries? It'll be useful for us to understand what our users need so we can prioritize the right things. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:187,safety,updat,update,187,"@Stikus Hi, I was able to reproduce the issue on Ubuntu 14. We don't officially support building on Ubuntu 14, but I'll give it a try and see if I'm able to get it to work. I can give an update later. One question for you - Can you tell us the reason why you're not using our Docker image, and instead building your own binaries? It'll be useful for us to understand what our users need so we can prioritize the right things. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:187,security,updat,update,187,"@Stikus Hi, I was able to reproduce the issue on Ubuntu 14. We don't officially support building on Ubuntu 14, but I'll give it a try and see if I'm able to get it to work. I can give an update later. One question for you - Can you tell us the reason why you're not using our Docker image, and instead building your own binaries? It'll be useful for us to understand what our users need so we can prioritize the right things. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:356,testability,understand,understand,356,"@Stikus Hi, I was able to reproduce the issue on Ubuntu 14. We don't officially support building on Ubuntu 14, but I'll give it a try and see if I'm able to get it to work. I can give an update later. One question for you - Can you tell us the reason why you're not using our Docker image, and instead building your own binaries? It'll be useful for us to understand what our users need so we can prioritize the right things. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:80,usability,support,support,80,"@Stikus Hi, I was able to reproduce the issue on Ubuntu 14. We don't officially support building on Ubuntu 14, but I'll give it a try and see if I'm able to get it to work. I can give an update later. One question for you - Can you tell us the reason why you're not using our Docker image, and instead building your own binaries? It'll be useful for us to understand what our users need so we can prioritize the right things. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:376,usability,user,users,376,"@Stikus Hi, I was able to reproduce the issue on Ubuntu 14. We don't officially support building on Ubuntu 14, but I'll give it a try and see if I'm able to get it to work. I can give an update later. One question for you - Can you tell us the reason why you're not using our Docker image, and instead building your own binaries? It'll be useful for us to understand what our users need so we can prioritize the right things. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:102,deployability,build,build,102,"Hi @Stikus , . actually , it seems like simply removing the line. ```. #include <optional>. ```. will build. From the code, we're using ""optional"" from tensorflow::gtl::optional. So we don't really need the #include here. I have confirmed that removing this line builds on Ubuntu14.04. Please give that a try. If it doesn't work, let me know. I will make an internal fix, which will come out in the next release. For now, please make a local edit before you build.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:263,deployability,build,builds,263,"Hi @Stikus , . actually , it seems like simply removing the line. ```. #include <optional>. ```. will build. From the code, we're using ""optional"" from tensorflow::gtl::optional. So we don't really need the #include here. I have confirmed that removing this line builds on Ubuntu14.04. Please give that a try. If it doesn't work, let me know. I will make an internal fix, which will come out in the next release. For now, please make a local edit before you build.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:404,deployability,releas,release,404,"Hi @Stikus , . actually , it seems like simply removing the line. ```. #include <optional>. ```. will build. From the code, we're using ""optional"" from tensorflow::gtl::optional. So we don't really need the #include here. I have confirmed that removing this line builds on Ubuntu14.04. Please give that a try. If it doesn't work, let me know. I will make an internal fix, which will come out in the next release. For now, please make a local edit before you build.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:458,deployability,build,build,458,"Hi @Stikus , . actually , it seems like simply removing the line. ```. #include <optional>. ```. will build. From the code, we're using ""optional"" from tensorflow::gtl::optional. So we don't really need the #include here. I have confirmed that removing this line builds on Ubuntu14.04. Please give that a try. If it doesn't work, let me know. I will make an internal fix, which will come out in the next release. For now, please make a local edit before you build.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:316,reliability,doe,doesn,316,"Hi @Stikus , . actually , it seems like simply removing the line. ```. #include <optional>. ```. will build. From the code, we're using ""optional"" from tensorflow::gtl::optional. So we don't really need the #include here. I have confirmed that removing this line builds on Ubuntu14.04. Please give that a try. If it doesn't work, let me know. I will make an internal fix, which will come out in the next release. For now, please make a local edit before you build.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:40,testability,simpl,simply,40,"Hi @Stikus , . actually , it seems like simply removing the line. ```. #include <optional>. ```. will build. From the code, we're using ""optional"" from tensorflow::gtl::optional. So we don't really need the #include here. I have confirmed that removing this line builds on Ubuntu14.04. Please give that a try. If it doesn't work, let me know. I will make an internal fix, which will come out in the next release. For now, please make a local edit before you build.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:40,usability,simpl,simply,40,"Hi @Stikus , . actually , it seems like simply removing the line. ```. #include <optional>. ```. will build. From the code, we're using ""optional"" from tensorflow::gtl::optional. So we don't really need the #include here. I have confirmed that removing this line builds on Ubuntu14.04. Please give that a try. If it doesn't work, let me know. I will make an internal fix, which will come out in the next release. For now, please make a local edit before you build.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:229,usability,confirm,confirmed,229,"Hi @Stikus , . actually , it seems like simply removing the line. ```. #include <optional>. ```. will build. From the code, we're using ""optional"" from tensorflow::gtl::optional. So we don't really need the #include here. I have confirmed that removing this line builds on Ubuntu14.04. Please give that a try. If it doesn't work, let me know. I will make an internal fix, which will come out in the next release. For now, please make a local edit before you build.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:103,deployability,build,building,103,"> One question for you - Can you tell us the reason why you're not using our Docker image, and instead building your own binaries? It'll be useful for us to understand what our users need so we can prioritize the right things. Thank you! We are always creating our own images because we have a lot of preinstalled soft in them and all them start from same instructions. And for full understanding of external programs too. Thanks for proposal, I'll try to build v0.9.0 without `#include <optional>` and report here.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:456,deployability,build,build,456,"> One question for you - Can you tell us the reason why you're not using our Docker image, and instead building your own binaries? It'll be useful for us to understand what our users need so we can prioritize the right things. Thank you! We are always creating our own images because we have a lot of preinstalled soft in them and all them start from same instructions. And for full understanding of external programs too. Thanks for proposal, I'll try to build v0.9.0 without `#include <optional>` and report here.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:157,testability,understand,understand,157,"> One question for you - Can you tell us the reason why you're not using our Docker image, and instead building your own binaries? It'll be useful for us to understand what our users need so we can prioritize the right things. Thank you! We are always creating our own images because we have a lot of preinstalled soft in them and all them start from same instructions. And for full understanding of external programs too. Thanks for proposal, I'll try to build v0.9.0 without `#include <optional>` and report here.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:383,testability,understand,understanding,383,"> One question for you - Can you tell us the reason why you're not using our Docker image, and instead building your own binaries? It'll be useful for us to understand what our users need so we can prioritize the right things. Thank you! We are always creating our own images because we have a lot of preinstalled soft in them and all them start from same instructions. And for full understanding of external programs too. Thanks for proposal, I'll try to build v0.9.0 without `#include <optional>` and report here.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:177,usability,user,users,177,"> One question for you - Can you tell us the reason why you're not using our Docker image, and instead building your own binaries? It'll be useful for us to understand what our users need so we can prioritize the right things. Thank you! We are always creating our own images because we have a lot of preinstalled soft in them and all them start from same instructions. And for full understanding of external programs too. Thanks for proposal, I'll try to build v0.9.0 without `#include <optional>` and report here.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:36,deployability,build,build,36,"Thank you for help, with your tweak build and tests passed. But I get different results on test data - described [here](https://github.com/google/deepvariant/issues/239#issuecomment-558061938).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:46,safety,test,tests,46,"Thank you for help, with your tweak build and tests passed. But I get different results on test data - described [here](https://github.com/google/deepvariant/issues/239#issuecomment-558061938).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:91,safety,test,test,91,"Thank you for help, with your tweak build and tests passed. But I get different results on test data - described [here](https://github.com/google/deepvariant/issues/239#issuecomment-558061938).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:46,testability,test,tests,46,"Thank you for help, with your tweak build and tests passed. But I get different results on test data - described [here](https://github.com/google/deepvariant/issues/239#issuecomment-558061938).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:91,testability,test,test,91,"Thank you for help, with your tweak build and tests passed. But I get different results on test data - described [here](https://github.com/google/deepvariant/issues/239#issuecomment-558061938).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/236:14,usability,help,help,14,"Thank you for help, with your tweak build and tests passed. But I get different results on test data - described [here](https://github.com/google/deepvariant/issues/239#issuecomment-558061938).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/236
https://github.com/google/deepvariant/issues/237:175,security,expir,expired,175,"Hi Xiaoledeng,. Thanks for bringing this to our attention. I am attaching the capture regions BED file to this issue. I will also edit the earlier comments to correct for the expired link. [agilent_sureselect_human_all_exon_v5_b37_targets.bed.gz](https://github.com/google/deepvariant/files/3875975/agilent_sureselect_human_all_exon_v5_b37_targets.bed.gz). Thank you",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/237
https://github.com/google/deepvariant/issues/238:57,deployability,observ,observation,57,"Hi @segoerge . Thank you for your question. It is a good observation that better support for MNP would be helpful. We have discussed this internally to a limited extent, but have not yet mapped out what would be involved to make the change. I couldn't give a timeframe for this yet (or give an indication as to whether this could be something in the next release). Your feedback is appreciated, as it helps us understand the needs of the user community. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:355,deployability,releas,release,355,"Hi @segoerge . Thank you for your question. It is a good observation that better support for MNP would be helpful. We have discussed this internally to a limited extent, but have not yet mapped out what would be involved to make the change. I couldn't give a timeframe for this yet (or give an indication as to whether this could be something in the next release). Your feedback is appreciated, as it helps us understand the needs of the user community. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:162,modifiability,exten,extent,162,"Hi @segoerge . Thank you for your question. It is a good observation that better support for MNP would be helpful. We have discussed this internally to a limited extent, but have not yet mapped out what would be involved to make the change. I couldn't give a timeframe for this yet (or give an indication as to whether this could be something in the next release). Your feedback is appreciated, as it helps us understand the needs of the user community. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:259,performance,time,timeframe,259,"Hi @segoerge . Thank you for your question. It is a good observation that better support for MNP would be helpful. We have discussed this internally to a limited extent, but have not yet mapped out what would be involved to make the change. I couldn't give a timeframe for this yet (or give an indication as to whether this could be something in the next release). Your feedback is appreciated, as it helps us understand the needs of the user community. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:57,testability,observ,observation,57,"Hi @segoerge . Thank you for your question. It is a good observation that better support for MNP would be helpful. We have discussed this internally to a limited extent, but have not yet mapped out what would be involved to make the change. I couldn't give a timeframe for this yet (or give an indication as to whether this could be something in the next release). Your feedback is appreciated, as it helps us understand the needs of the user community. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:410,testability,understand,understand,410,"Hi @segoerge . Thank you for your question. It is a good observation that better support for MNP would be helpful. We have discussed this internally to a limited extent, but have not yet mapped out what would be involved to make the change. I couldn't give a timeframe for this yet (or give an indication as to whether this could be something in the next release). Your feedback is appreciated, as it helps us understand the needs of the user community. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:81,usability,support,support,81,"Hi @segoerge . Thank you for your question. It is a good observation that better support for MNP would be helpful. We have discussed this internally to a limited extent, but have not yet mapped out what would be involved to make the change. I couldn't give a timeframe for this yet (or give an indication as to whether this could be something in the next release). Your feedback is appreciated, as it helps us understand the needs of the user community. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:106,usability,help,helpful,106,"Hi @segoerge . Thank you for your question. It is a good observation that better support for MNP would be helpful. We have discussed this internally to a limited extent, but have not yet mapped out what would be involved to make the change. I couldn't give a timeframe for this yet (or give an indication as to whether this could be something in the next release). Your feedback is appreciated, as it helps us understand the needs of the user community. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:294,usability,indicat,indication,294,"Hi @segoerge . Thank you for your question. It is a good observation that better support for MNP would be helpful. We have discussed this internally to a limited extent, but have not yet mapped out what would be involved to make the change. I couldn't give a timeframe for this yet (or give an indication as to whether this could be something in the next release). Your feedback is appreciated, as it helps us understand the needs of the user community. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:370,usability,feedback,feedback,370,"Hi @segoerge . Thank you for your question. It is a good observation that better support for MNP would be helpful. We have discussed this internally to a limited extent, but have not yet mapped out what would be involved to make the change. I couldn't give a timeframe for this yet (or give an indication as to whether this could be something in the next release). Your feedback is appreciated, as it helps us understand the needs of the user community. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:401,usability,help,helps,401,"Hi @segoerge . Thank you for your question. It is a good observation that better support for MNP would be helpful. We have discussed this internally to a limited extent, but have not yet mapped out what would be involved to make the change. I couldn't give a timeframe for this yet (or give an indication as to whether this could be something in the next release). Your feedback is appreciated, as it helps us understand the needs of the user community. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:438,usability,user,user,438,"Hi @segoerge . Thank you for your question. It is a good observation that better support for MNP would be helpful. We have discussed this internally to a limited extent, but have not yet mapped out what would be involved to make the change. I couldn't give a timeframe for this yet (or give an indication as to whether this could be something in the next release). Your feedback is appreciated, as it helps us understand the needs of the user community. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:342,availability,down,downstream,342,"HI! any update on this topic? We called multiple genomes recently and found a first example of 4 adjacent base substitution AACT => GGTC being called 4 separate SNVs. The support information is very similar for the 4 calls and I wonder why deepvariant did not call them as one single MNP. This makes that the annotation and effect prediction downstream are wrong. Thanks for your support. ![failed_MNP-call](https://github.com/google/deepvariant/assets/858516/a02c3b5a-0362-4030-be8a-8b3c49129a8f). here is the extract of the gVCF at that location for one sample. ```. chrNN 51225801 . T <*> 0 . END=51225807 GT:GQ:MIN_DP:PL 0/0:50:27:0,81,809. chrNN 51225808 . A G,<*> 30.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:30:26:17,9,0:0.346154,0:30,0,37,990,990,990. chrNN 51225809 . A G,<*> 31.8 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:26:17,9,0:0.346154,0:31,0,38,990,990,990. chrNN 51225810 . C T,<*> 31.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:26:17,9,0:0.346154,0:31,0,39,990,990,990. chrNN 51225811 . T C,<*> 32.2 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:28:17,9,0:0.321429,0:32,0,37,990,990,990. chrNN 51225812 . C <*> 0 . END=51225881 GT:GQ:MIN_DP:PL 0/0:48:26:0,87,869. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:8,deployability,updat,update,8,"HI! any update on this topic? We called multiple genomes recently and found a first example of 4 adjacent base substitution AACT => GGTC being called 4 separate SNVs. The support information is very similar for the 4 calls and I wonder why deepvariant did not call them as one single MNP. This makes that the annotation and effect prediction downstream are wrong. Thanks for your support. ![failed_MNP-call](https://github.com/google/deepvariant/assets/858516/a02c3b5a-0362-4030-be8a-8b3c49129a8f). here is the extract of the gVCF at that location for one sample. ```. chrNN 51225801 . T <*> 0 . END=51225807 GT:GQ:MIN_DP:PL 0/0:50:27:0,81,809. chrNN 51225808 . A G,<*> 30.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:30:26:17,9,0:0.346154,0:30,0,37,990,990,990. chrNN 51225809 . A G,<*> 31.8 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:26:17,9,0:0.346154,0:31,0,38,990,990,990. chrNN 51225810 . C T,<*> 31.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:26:17,9,0:0.346154,0:31,0,39,990,990,990. chrNN 51225811 . T C,<*> 32.2 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:28:17,9,0:0.321429,0:32,0,37,990,990,990. chrNN 51225812 . C <*> 0 . END=51225881 GT:GQ:MIN_DP:PL 0/0:48:26:0,87,869. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:331,energy efficiency,predict,prediction,331,"HI! any update on this topic? We called multiple genomes recently and found a first example of 4 adjacent base substitution AACT => GGTC being called 4 separate SNVs. The support information is very similar for the 4 calls and I wonder why deepvariant did not call them as one single MNP. This makes that the annotation and effect prediction downstream are wrong. Thanks for your support. ![failed_MNP-call](https://github.com/google/deepvariant/assets/858516/a02c3b5a-0362-4030-be8a-8b3c49129a8f). here is the extract of the gVCF at that location for one sample. ```. chrNN 51225801 . T <*> 0 . END=51225807 GT:GQ:MIN_DP:PL 0/0:50:27:0,81,809. chrNN 51225808 . A G,<*> 30.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:30:26:17,9,0:0.346154,0:30,0,37,990,990,990. chrNN 51225809 . A G,<*> 31.8 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:26:17,9,0:0.346154,0:31,0,38,990,990,990. chrNN 51225810 . C T,<*> 31.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:26:17,9,0:0.346154,0:31,0,39,990,990,990. chrNN 51225811 . T C,<*> 32.2 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:28:17,9,0:0.321429,0:32,0,37,990,990,990. chrNN 51225812 . C <*> 0 . END=51225881 GT:GQ:MIN_DP:PL 0/0:48:26:0,87,869. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:23,integrability,topic,topic,23,"HI! any update on this topic? We called multiple genomes recently and found a first example of 4 adjacent base substitution AACT => GGTC being called 4 separate SNVs. The support information is very similar for the 4 calls and I wonder why deepvariant did not call them as one single MNP. This makes that the annotation and effect prediction downstream are wrong. Thanks for your support. ![failed_MNP-call](https://github.com/google/deepvariant/assets/858516/a02c3b5a-0362-4030-be8a-8b3c49129a8f). here is the extract of the gVCF at that location for one sample. ```. chrNN 51225801 . T <*> 0 . END=51225807 GT:GQ:MIN_DP:PL 0/0:50:27:0,81,809. chrNN 51225808 . A G,<*> 30.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:30:26:17,9,0:0.346154,0:30,0,37,990,990,990. chrNN 51225809 . A G,<*> 31.8 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:26:17,9,0:0.346154,0:31,0,38,990,990,990. chrNN 51225810 . C T,<*> 31.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:26:17,9,0:0.346154,0:31,0,39,990,990,990. chrNN 51225811 . T C,<*> 32.2 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:28:17,9,0:0.321429,0:32,0,37,990,990,990. chrNN 51225812 . C <*> 0 . END=51225881 GT:GQ:MIN_DP:PL 0/0:48:26:0,87,869. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:111,integrability,sub,substitution,111,"HI! any update on this topic? We called multiple genomes recently and found a first example of 4 adjacent base substitution AACT => GGTC being called 4 separate SNVs. The support information is very similar for the 4 calls and I wonder why deepvariant did not call them as one single MNP. This makes that the annotation and effect prediction downstream are wrong. Thanks for your support. ![failed_MNP-call](https://github.com/google/deepvariant/assets/858516/a02c3b5a-0362-4030-be8a-8b3c49129a8f). here is the extract of the gVCF at that location for one sample. ```. chrNN 51225801 . T <*> 0 . END=51225807 GT:GQ:MIN_DP:PL 0/0:50:27:0,81,809. chrNN 51225808 . A G,<*> 30.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:30:26:17,9,0:0.346154,0:30,0,37,990,990,990. chrNN 51225809 . A G,<*> 31.8 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:26:17,9,0:0.346154,0:31,0,38,990,990,990. chrNN 51225810 . C T,<*> 31.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:26:17,9,0:0.346154,0:31,0,39,990,990,990. chrNN 51225811 . T C,<*> 32.2 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:28:17,9,0:0.321429,0:32,0,37,990,990,990. chrNN 51225812 . C <*> 0 . END=51225881 GT:GQ:MIN_DP:PL 0/0:48:26:0,87,869. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:8,safety,updat,update,8,"HI! any update on this topic? We called multiple genomes recently and found a first example of 4 adjacent base substitution AACT => GGTC being called 4 separate SNVs. The support information is very similar for the 4 calls and I wonder why deepvariant did not call them as one single MNP. This makes that the annotation and effect prediction downstream are wrong. Thanks for your support. ![failed_MNP-call](https://github.com/google/deepvariant/assets/858516/a02c3b5a-0362-4030-be8a-8b3c49129a8f). here is the extract of the gVCF at that location for one sample. ```. chrNN 51225801 . T <*> 0 . END=51225807 GT:GQ:MIN_DP:PL 0/0:50:27:0,81,809. chrNN 51225808 . A G,<*> 30.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:30:26:17,9,0:0.346154,0:30,0,37,990,990,990. chrNN 51225809 . A G,<*> 31.8 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:26:17,9,0:0.346154,0:31,0,38,990,990,990. chrNN 51225810 . C T,<*> 31.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:26:17,9,0:0.346154,0:31,0,39,990,990,990. chrNN 51225811 . T C,<*> 32.2 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:28:17,9,0:0.321429,0:32,0,37,990,990,990. chrNN 51225812 . C <*> 0 . END=51225881 GT:GQ:MIN_DP:PL 0/0:48:26:0,87,869. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:331,safety,predict,prediction,331,"HI! any update on this topic? We called multiple genomes recently and found a first example of 4 adjacent base substitution AACT => GGTC being called 4 separate SNVs. The support information is very similar for the 4 calls and I wonder why deepvariant did not call them as one single MNP. This makes that the annotation and effect prediction downstream are wrong. Thanks for your support. ![failed_MNP-call](https://github.com/google/deepvariant/assets/858516/a02c3b5a-0362-4030-be8a-8b3c49129a8f). here is the extract of the gVCF at that location for one sample. ```. chrNN 51225801 . T <*> 0 . END=51225807 GT:GQ:MIN_DP:PL 0/0:50:27:0,81,809. chrNN 51225808 . A G,<*> 30.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:30:26:17,9,0:0.346154,0:30,0,37,990,990,990. chrNN 51225809 . A G,<*> 31.8 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:26:17,9,0:0.346154,0:31,0,38,990,990,990. chrNN 51225810 . C T,<*> 31.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:26:17,9,0:0.346154,0:31,0,39,990,990,990. chrNN 51225811 . T C,<*> 32.2 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:28:17,9,0:0.321429,0:32,0,37,990,990,990. chrNN 51225812 . C <*> 0 . END=51225881 GT:GQ:MIN_DP:PL 0/0:48:26:0,87,869. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:8,security,updat,update,8,"HI! any update on this topic? We called multiple genomes recently and found a first example of 4 adjacent base substitution AACT => GGTC being called 4 separate SNVs. The support information is very similar for the 4 calls and I wonder why deepvariant did not call them as one single MNP. This makes that the annotation and effect prediction downstream are wrong. Thanks for your support. ![failed_MNP-call](https://github.com/google/deepvariant/assets/858516/a02c3b5a-0362-4030-be8a-8b3c49129a8f). here is the extract of the gVCF at that location for one sample. ```. chrNN 51225801 . T <*> 0 . END=51225807 GT:GQ:MIN_DP:PL 0/0:50:27:0,81,809. chrNN 51225808 . A G,<*> 30.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:30:26:17,9,0:0.346154,0:30,0,37,990,990,990. chrNN 51225809 . A G,<*> 31.8 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:26:17,9,0:0.346154,0:31,0,38,990,990,990. chrNN 51225810 . C T,<*> 31.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:26:17,9,0:0.346154,0:31,0,39,990,990,990. chrNN 51225811 . T C,<*> 32.2 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:28:17,9,0:0.321429,0:32,0,37,990,990,990. chrNN 51225812 . C <*> 0 . END=51225881 GT:GQ:MIN_DP:PL 0/0:48:26:0,87,869. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:171,usability,support,support,171,"HI! any update on this topic? We called multiple genomes recently and found a first example of 4 adjacent base substitution AACT => GGTC being called 4 separate SNVs. The support information is very similar for the 4 calls and I wonder why deepvariant did not call them as one single MNP. This makes that the annotation and effect prediction downstream are wrong. Thanks for your support. ![failed_MNP-call](https://github.com/google/deepvariant/assets/858516/a02c3b5a-0362-4030-be8a-8b3c49129a8f). here is the extract of the gVCF at that location for one sample. ```. chrNN 51225801 . T <*> 0 . END=51225807 GT:GQ:MIN_DP:PL 0/0:50:27:0,81,809. chrNN 51225808 . A G,<*> 30.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:30:26:17,9,0:0.346154,0:30,0,37,990,990,990. chrNN 51225809 . A G,<*> 31.8 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:26:17,9,0:0.346154,0:31,0,38,990,990,990. chrNN 51225810 . C T,<*> 31.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:26:17,9,0:0.346154,0:31,0,39,990,990,990. chrNN 51225811 . T C,<*> 32.2 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:28:17,9,0:0.321429,0:32,0,37,990,990,990. chrNN 51225812 . C <*> 0 . END=51225881 GT:GQ:MIN_DP:PL 0/0:48:26:0,87,869. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:380,usability,support,support,380,"HI! any update on this topic? We called multiple genomes recently and found a first example of 4 adjacent base substitution AACT => GGTC being called 4 separate SNVs. The support information is very similar for the 4 calls and I wonder why deepvariant did not call them as one single MNP. This makes that the annotation and effect prediction downstream are wrong. Thanks for your support. ![failed_MNP-call](https://github.com/google/deepvariant/assets/858516/a02c3b5a-0362-4030-be8a-8b3c49129a8f). here is the extract of the gVCF at that location for one sample. ```. chrNN 51225801 . T <*> 0 . END=51225807 GT:GQ:MIN_DP:PL 0/0:50:27:0,81,809. chrNN 51225808 . A G,<*> 30.5 PASS . GT:GQ:DP:AD:VAF:PL 0/1:30:26:17,9,0:0.346154,0:30,0,37,990,990,990. chrNN 51225809 . A G,<*> 31.8 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:26:17,9,0:0.346154,0:31,0,38,990,990,990. chrNN 51225810 . C T,<*> 31.6 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:26:17,9,0:0.346154,0:31,0,39,990,990,990. chrNN 51225811 . T C,<*> 32.2 PASS . GT:GQ:DP:AD:VAF:PL 0/1:31:28:17,9,0:0.321429,0:32,0,37,990,990,990. chrNN 51225812 . C <*> 0 . END=51225881 GT:GQ:MIN_DP:PL 0/0:48:26:0,87,869. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:0,security,ident,identical,0,identical issue as in https://github.com/google/deepvariant/issues/520.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:202,usability,help,help,202,"Hi Stephane,. In the meantime would running `freebayes` (alongside DeepVariant) to generate MNPs using your DeepVariant realigned BAMs, and then `bcftools merge` the results from the two VCFs (FB + DV) help out? ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:100,deployability,updat,update,100,"Hi @splaisan . We are currently working on a more complete approach for MNPs, but we don't have any update at this time and it won't be in the very next release. Hopefully sometime after that we will have results for MNPs, but I can't give a specific timeline.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:153,deployability,releas,release,153,"Hi @splaisan . We are currently working on a more complete approach for MNPs, but we don't have any update at this time and it won't be in the very next release. Hopefully sometime after that we will have results for MNPs, but I can't give a specific timeline.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:22,energy efficiency,current,currently,22,"Hi @splaisan . We are currently working on a more complete approach for MNPs, but we don't have any update at this time and it won't be in the very next release. Hopefully sometime after that we will have results for MNPs, but I can't give a specific timeline.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:242,interoperability,specif,specific,242,"Hi @splaisan . We are currently working on a more complete approach for MNPs, but we don't have any update at this time and it won't be in the very next release. Hopefully sometime after that we will have results for MNPs, but I can't give a specific timeline.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:115,performance,time,time,115,"Hi @splaisan . We are currently working on a more complete approach for MNPs, but we don't have any update at this time and it won't be in the very next release. Hopefully sometime after that we will have results for MNPs, but I can't give a specific timeline.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:251,performance,time,timeline,251,"Hi @splaisan . We are currently working on a more complete approach for MNPs, but we don't have any update at this time and it won't be in the very next release. Hopefully sometime after that we will have results for MNPs, but I can't give a specific timeline.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:50,safety,compl,complete,50,"Hi @splaisan . We are currently working on a more complete approach for MNPs, but we don't have any update at this time and it won't be in the very next release. Hopefully sometime after that we will have results for MNPs, but I can't give a specific timeline.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:100,safety,updat,update,100,"Hi @splaisan . We are currently working on a more complete approach for MNPs, but we don't have any update at this time and it won't be in the very next release. Hopefully sometime after that we will have results for MNPs, but I can't give a specific timeline.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:50,security,compl,complete,50,"Hi @splaisan . We are currently working on a more complete approach for MNPs, but we don't have any update at this time and it won't be in the very next release. Hopefully sometime after that we will have results for MNPs, but I can't give a specific timeline.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:100,security,updat,update,100,"Hi @splaisan . We are currently working on a more complete approach for MNPs, but we don't have any update at this time and it won't be in the very next release. Hopefully sometime after that we will have results for MNPs, but I can't give a specific timeline.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:253,availability,servic,service,253,"Thanks both for your answers,. @pgrosu this is hardly a solution as the calling took now more than a week on 88 threads plus merging the calls will lead to overlaps and discordances difficult to resolve without manual inspection (which I cannot do as a service) and also as I am going through gVCF and GLnexus merging which is not that well supported for freebayes in my experience (I might have overlooked though). @AndrewCarroll this is great, it will surely be appreciated by the community as this issue has been raised by several already and is annoying in a clinical setting. Please make sure to advertise it when it comes out so that we can try it. Cheers",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:253,deployability,servic,service,253,"Thanks both for your answers,. @pgrosu this is hardly a solution as the calling took now more than a week on 88 threads plus merging the calls will lead to overlaps and discordances difficult to resolve without manual inspection (which I cannot do as a service) and also as I am going through gVCF and GLnexus merging which is not that well supported for freebayes in my experience (I might have overlooked though). @AndrewCarroll this is great, it will surely be appreciated by the community as this issue has been raised by several already and is annoying in a clinical setting. Please make sure to advertise it when it comes out so that we can try it. Cheers",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:253,integrability,servic,service,253,"Thanks both for your answers,. @pgrosu this is hardly a solution as the calling took now more than a week on 88 threads plus merging the calls will lead to overlaps and discordances difficult to resolve without manual inspection (which I cannot do as a service) and also as I am going through gVCF and GLnexus merging which is not that well supported for freebayes in my experience (I might have overlooked though). @AndrewCarroll this is great, it will surely be appreciated by the community as this issue has been raised by several already and is annoying in a clinical setting. Please make sure to advertise it when it comes out so that we can try it. Cheers",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:253,modifiability,servic,service,253,"Thanks both for your answers,. @pgrosu this is hardly a solution as the calling took now more than a week on 88 threads plus merging the calls will lead to overlaps and discordances difficult to resolve without manual inspection (which I cannot do as a service) and also as I am going through gVCF and GLnexus merging which is not that well supported for freebayes in my experience (I might have overlooked though). @AndrewCarroll this is great, it will surely be appreciated by the community as this issue has been raised by several already and is annoying in a clinical setting. Please make sure to advertise it when it comes out so that we can try it. Cheers",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:341,usability,support,supported,341,"Thanks both for your answers,. @pgrosu this is hardly a solution as the calling took now more than a week on 88 threads plus merging the calls will lead to overlaps and discordances difficult to resolve without manual inspection (which I cannot do as a service) and also as I am going through gVCF and GLnexus merging which is not that well supported for freebayes in my experience (I might have overlooked though). @AndrewCarroll this is great, it will surely be appreciated by the community as this issue has been raised by several already and is annoying in a clinical setting. Please make sure to advertise it when it comes out so that we can try it. Cheers",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:371,usability,experien,experience,371,"Thanks both for your answers,. @pgrosu this is hardly a solution as the calling took now more than a week on 88 threads plus merging the calls will lead to overlaps and discordances difficult to resolve without manual inspection (which I cannot do as a service) and also as I am going through gVCF and GLnexus merging which is not that well supported for freebayes in my experience (I might have overlooked though). @AndrewCarroll this is great, it will surely be appreciated by the community as this issue has been raised by several already and is annoying in a clinical setting. Please make sure to advertise it when it comes out so that we can try it. Cheers",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:116,deployability,observ,observe,116,"Hi @splaisan,. That is a very complex experimental setup. I initially proposed freebayes + DV in order to merge and observe them together, for making proper selection in study-specific regions as a follow-up among the two results. Of course it would easier to write a program to compare between the two, filtered on thresholds appropriate to your design. In any case, even though [freebayes has gVCF output](https://github.com/freebayes/freebayes/blob/master/README.md#usage), let's ignore that for now and look closer at the GLnexus algorithm - as it gives nice insights about how variants are processed from gVCF files. Thus when it generates the pVCF, unified variant sites are collected from variants spanning overlapping regions. Since it performs $`\arg \max_{g} Pr(Genotype = g) Pr(Data | Genotype = g)`$, having multiple possible MNPs in the unified site (across gVCFs) dilutes the probability of each genotype, and thus having them as individual SNPs ensures the GQ and PL are maximally contributed to for each base. This is also because for such unified sites, it considers all discovered QC-filtered alleles greedily in descending order of frequency, and might be exacerbated with rare alleles when calling sites. Therefore given the above, utilizing the combined output of the VCF for post-processing into MNPs might be optimal. Ideally, having phasing information would also provide more confidence in the quality of MNPs from combined adjacent SNPs belonging to a haplotype. If possible, limiting via a BED file to regions that are more relevant for your study - especially under heavy multi-threaded conditions - might shorted the analysis time. With many threads you might be thrashing, thus limiting your performance by spending more time context-switching. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:1151,energy efficiency,frequenc,frequency,1151,"Hi @splaisan,. That is a very complex experimental setup. I initially proposed freebayes + DV in order to merge and observe them together, for making proper selection in study-specific regions as a follow-up among the two results. Of course it would easier to write a program to compare between the two, filtered on thresholds appropriate to your design. In any case, even though [freebayes has gVCF output](https://github.com/freebayes/freebayes/blob/master/README.md#usage), let's ignore that for now and look closer at the GLnexus algorithm - as it gives nice insights about how variants are processed from gVCF files. Thus when it generates the pVCF, unified variant sites are collected from variants spanning overlapping regions. Since it performs $`\arg \max_{g} Pr(Genotype = g) Pr(Data | Genotype = g)`$, having multiple possible MNPs in the unified site (across gVCFs) dilutes the probability of each genotype, and thus having them as individual SNPs ensures the GQ and PL are maximally contributed to for each base. This is also because for such unified sites, it considers all discovered QC-filtered alleles greedily in descending order of frequency, and might be exacerbated with rare alleles when calling sites. Therefore given the above, utilizing the combined output of the VCF for post-processing into MNPs might be optimal. Ideally, having phasing information would also provide more confidence in the quality of MNPs from combined adjacent SNPs belonging to a haplotype. If possible, limiting via a BED file to regions that are more relevant for your study - especially under heavy multi-threaded conditions - might shorted the analysis time. With many threads you might be thrashing, thus limiting your performance by spending more time context-switching. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:1332,energy efficiency,optim,optimal,1332,"Hi @splaisan,. That is a very complex experimental setup. I initially proposed freebayes + DV in order to merge and observe them together, for making proper selection in study-specific regions as a follow-up among the two results. Of course it would easier to write a program to compare between the two, filtered on thresholds appropriate to your design. In any case, even though [freebayes has gVCF output](https://github.com/freebayes/freebayes/blob/master/README.md#usage), let's ignore that for now and look closer at the GLnexus algorithm - as it gives nice insights about how variants are processed from gVCF files. Thus when it generates the pVCF, unified variant sites are collected from variants spanning overlapping regions. Since it performs $`\arg \max_{g} Pr(Genotype = g) Pr(Data | Genotype = g)`$, having multiple possible MNPs in the unified site (across gVCFs) dilutes the probability of each genotype, and thus having them as individual SNPs ensures the GQ and PL are maximally contributed to for each base. This is also because for such unified sites, it considers all discovered QC-filtered alleles greedily in descending order of frequency, and might be exacerbated with rare alleles when calling sites. Therefore given the above, utilizing the combined output of the VCF for post-processing into MNPs might be optimal. Ideally, having phasing information would also provide more confidence in the quality of MNPs from combined adjacent SNPs belonging to a haplotype. If possible, limiting via a BED file to regions that are more relevant for your study - especially under heavy multi-threaded conditions - might shorted the analysis time. With many threads you might be thrashing, thus limiting your performance by spending more time context-switching. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:304,integrability,filter,filtered,304,"Hi @splaisan,. That is a very complex experimental setup. I initially proposed freebayes + DV in order to merge and observe them together, for making proper selection in study-specific regions as a follow-up among the two results. Of course it would easier to write a program to compare between the two, filtered on thresholds appropriate to your design. In any case, even though [freebayes has gVCF output](https://github.com/freebayes/freebayes/blob/master/README.md#usage), let's ignore that for now and look closer at the GLnexus algorithm - as it gives nice insights about how variants are processed from gVCF files. Thus when it generates the pVCF, unified variant sites are collected from variants spanning overlapping regions. Since it performs $`\arg \max_{g} Pr(Genotype = g) Pr(Data | Genotype = g)`$, having multiple possible MNPs in the unified site (across gVCFs) dilutes the probability of each genotype, and thus having them as individual SNPs ensures the GQ and PL are maximally contributed to for each base. This is also because for such unified sites, it considers all discovered QC-filtered alleles greedily in descending order of frequency, and might be exacerbated with rare alleles when calling sites. Therefore given the above, utilizing the combined output of the VCF for post-processing into MNPs might be optimal. Ideally, having phasing information would also provide more confidence in the quality of MNPs from combined adjacent SNPs belonging to a haplotype. If possible, limiting via a BED file to regions that are more relevant for your study - especially under heavy multi-threaded conditions - might shorted the analysis time. With many threads you might be thrashing, thus limiting your performance by spending more time context-switching. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:1088,integrability,discover,discovered,1088,"Hi @splaisan,. That is a very complex experimental setup. I initially proposed freebayes + DV in order to merge and observe them together, for making proper selection in study-specific regions as a follow-up among the two results. Of course it would easier to write a program to compare between the two, filtered on thresholds appropriate to your design. In any case, even though [freebayes has gVCF output](https://github.com/freebayes/freebayes/blob/master/README.md#usage), let's ignore that for now and look closer at the GLnexus algorithm - as it gives nice insights about how variants are processed from gVCF files. Thus when it generates the pVCF, unified variant sites are collected from variants spanning overlapping regions. Since it performs $`\arg \max_{g} Pr(Genotype = g) Pr(Data | Genotype = g)`$, having multiple possible MNPs in the unified site (across gVCFs) dilutes the probability of each genotype, and thus having them as individual SNPs ensures the GQ and PL are maximally contributed to for each base. This is also because for such unified sites, it considers all discovered QC-filtered alleles greedily in descending order of frequency, and might be exacerbated with rare alleles when calling sites. Therefore given the above, utilizing the combined output of the VCF for post-processing into MNPs might be optimal. Ideally, having phasing information would also provide more confidence in the quality of MNPs from combined adjacent SNPs belonging to a haplotype. If possible, limiting via a BED file to regions that are more relevant for your study - especially under heavy multi-threaded conditions - might shorted the analysis time. With many threads you might be thrashing, thus limiting your performance by spending more time context-switching. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:1102,integrability,filter,filtered,1102,"Hi @splaisan,. That is a very complex experimental setup. I initially proposed freebayes + DV in order to merge and observe them together, for making proper selection in study-specific regions as a follow-up among the two results. Of course it would easier to write a program to compare between the two, filtered on thresholds appropriate to your design. In any case, even though [freebayes has gVCF output](https://github.com/freebayes/freebayes/blob/master/README.md#usage), let's ignore that for now and look closer at the GLnexus algorithm - as it gives nice insights about how variants are processed from gVCF files. Thus when it generates the pVCF, unified variant sites are collected from variants spanning overlapping regions. Since it performs $`\arg \max_{g} Pr(Genotype = g) Pr(Data | Genotype = g)`$, having multiple possible MNPs in the unified site (across gVCFs) dilutes the probability of each genotype, and thus having them as individual SNPs ensures the GQ and PL are maximally contributed to for each base. This is also because for such unified sites, it considers all discovered QC-filtered alleles greedily in descending order of frequency, and might be exacerbated with rare alleles when calling sites. Therefore given the above, utilizing the combined output of the VCF for post-processing into MNPs might be optimal. Ideally, having phasing information would also provide more confidence in the quality of MNPs from combined adjacent SNPs belonging to a haplotype. If possible, limiting via a BED file to regions that are more relevant for your study - especially under heavy multi-threaded conditions - might shorted the analysis time. With many threads you might be thrashing, thus limiting your performance by spending more time context-switching. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:176,interoperability,specif,specific,176,"Hi @splaisan,. That is a very complex experimental setup. I initially proposed freebayes + DV in order to merge and observe them together, for making proper selection in study-specific regions as a follow-up among the two results. Of course it would easier to write a program to compare between the two, filtered on thresholds appropriate to your design. In any case, even though [freebayes has gVCF output](https://github.com/freebayes/freebayes/blob/master/README.md#usage), let's ignore that for now and look closer at the GLnexus algorithm - as it gives nice insights about how variants are processed from gVCF files. Thus when it generates the pVCF, unified variant sites are collected from variants spanning overlapping regions. Since it performs $`\arg \max_{g} Pr(Genotype = g) Pr(Data | Genotype = g)`$, having multiple possible MNPs in the unified site (across gVCFs) dilutes the probability of each genotype, and thus having them as individual SNPs ensures the GQ and PL are maximally contributed to for each base. This is also because for such unified sites, it considers all discovered QC-filtered alleles greedily in descending order of frequency, and might be exacerbated with rare alleles when calling sites. Therefore given the above, utilizing the combined output of the VCF for post-processing into MNPs might be optimal. Ideally, having phasing information would also provide more confidence in the quality of MNPs from combined adjacent SNPs belonging to a haplotype. If possible, limiting via a BED file to regions that are more relevant for your study - especially under heavy multi-threaded conditions - might shorted the analysis time. With many threads you might be thrashing, thus limiting your performance by spending more time context-switching. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:1088,interoperability,discover,discovered,1088,"Hi @splaisan,. That is a very complex experimental setup. I initially proposed freebayes + DV in order to merge and observe them together, for making proper selection in study-specific regions as a follow-up among the two results. Of course it would easier to write a program to compare between the two, filtered on thresholds appropriate to your design. In any case, even though [freebayes has gVCF output](https://github.com/freebayes/freebayes/blob/master/README.md#usage), let's ignore that for now and look closer at the GLnexus algorithm - as it gives nice insights about how variants are processed from gVCF files. Thus when it generates the pVCF, unified variant sites are collected from variants spanning overlapping regions. Since it performs $`\arg \max_{g} Pr(Genotype = g) Pr(Data | Genotype = g)`$, having multiple possible MNPs in the unified site (across gVCFs) dilutes the probability of each genotype, and thus having them as individual SNPs ensures the GQ and PL are maximally contributed to for each base. This is also because for such unified sites, it considers all discovered QC-filtered alleles greedily in descending order of frequency, and might be exacerbated with rare alleles when calling sites. Therefore given the above, utilizing the combined output of the VCF for post-processing into MNPs might be optimal. Ideally, having phasing information would also provide more confidence in the quality of MNPs from combined adjacent SNPs belonging to a haplotype. If possible, limiting via a BED file to regions that are more relevant for your study - especially under heavy multi-threaded conditions - might shorted the analysis time. With many threads you might be thrashing, thus limiting your performance by spending more time context-switching. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:744,performance,perform,performs,744,"Hi @splaisan,. That is a very complex experimental setup. I initially proposed freebayes + DV in order to merge and observe them together, for making proper selection in study-specific regions as a follow-up among the two results. Of course it would easier to write a program to compare between the two, filtered on thresholds appropriate to your design. In any case, even though [freebayes has gVCF output](https://github.com/freebayes/freebayes/blob/master/README.md#usage), let's ignore that for now and look closer at the GLnexus algorithm - as it gives nice insights about how variants are processed from gVCF files. Thus when it generates the pVCF, unified variant sites are collected from variants spanning overlapping regions. Since it performs $`\arg \max_{g} Pr(Genotype = g) Pr(Data | Genotype = g)`$, having multiple possible MNPs in the unified site (across gVCFs) dilutes the probability of each genotype, and thus having them as individual SNPs ensures the GQ and PL are maximally contributed to for each base. This is also because for such unified sites, it considers all discovered QC-filtered alleles greedily in descending order of frequency, and might be exacerbated with rare alleles when calling sites. Therefore given the above, utilizing the combined output of the VCF for post-processing into MNPs might be optimal. Ideally, having phasing information would also provide more confidence in the quality of MNPs from combined adjacent SNPs belonging to a haplotype. If possible, limiting via a BED file to regions that are more relevant for your study - especially under heavy multi-threaded conditions - might shorted the analysis time. With many threads you might be thrashing, thus limiting your performance by spending more time context-switching. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:1600,performance,multi-thread,multi-threaded,1600,"Hi @splaisan,. That is a very complex experimental setup. I initially proposed freebayes + DV in order to merge and observe them together, for making proper selection in study-specific regions as a follow-up among the two results. Of course it would easier to write a program to compare between the two, filtered on thresholds appropriate to your design. In any case, even though [freebayes has gVCF output](https://github.com/freebayes/freebayes/blob/master/README.md#usage), let's ignore that for now and look closer at the GLnexus algorithm - as it gives nice insights about how variants are processed from gVCF files. Thus when it generates the pVCF, unified variant sites are collected from variants spanning overlapping regions. Since it performs $`\arg \max_{g} Pr(Genotype = g) Pr(Data | Genotype = g)`$, having multiple possible MNPs in the unified site (across gVCFs) dilutes the probability of each genotype, and thus having them as individual SNPs ensures the GQ and PL are maximally contributed to for each base. This is also because for such unified sites, it considers all discovered QC-filtered alleles greedily in descending order of frequency, and might be exacerbated with rare alleles when calling sites. Therefore given the above, utilizing the combined output of the VCF for post-processing into MNPs might be optimal. Ideally, having phasing information would also provide more confidence in the quality of MNPs from combined adjacent SNPs belonging to a haplotype. If possible, limiting via a BED file to regions that are more relevant for your study - especially under heavy multi-threaded conditions - might shorted the analysis time. With many threads you might be thrashing, thus limiting your performance by spending more time context-switching. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:1655,performance,time,time,1655,"Hi @splaisan,. That is a very complex experimental setup. I initially proposed freebayes + DV in order to merge and observe them together, for making proper selection in study-specific regions as a follow-up among the two results. Of course it would easier to write a program to compare between the two, filtered on thresholds appropriate to your design. In any case, even though [freebayes has gVCF output](https://github.com/freebayes/freebayes/blob/master/README.md#usage), let's ignore that for now and look closer at the GLnexus algorithm - as it gives nice insights about how variants are processed from gVCF files. Thus when it generates the pVCF, unified variant sites are collected from variants spanning overlapping regions. Since it performs $`\arg \max_{g} Pr(Genotype = g) Pr(Data | Genotype = g)`$, having multiple possible MNPs in the unified site (across gVCFs) dilutes the probability of each genotype, and thus having them as individual SNPs ensures the GQ and PL are maximally contributed to for each base. This is also because for such unified sites, it considers all discovered QC-filtered alleles greedily in descending order of frequency, and might be exacerbated with rare alleles when calling sites. Therefore given the above, utilizing the combined output of the VCF for post-processing into MNPs might be optimal. Ideally, having phasing information would also provide more confidence in the quality of MNPs from combined adjacent SNPs belonging to a haplotype. If possible, limiting via a BED file to regions that are more relevant for your study - especially under heavy multi-threaded conditions - might shorted the analysis time. With many threads you might be thrashing, thus limiting your performance by spending more time context-switching. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:1722,performance,perform,performance,1722,"Hi @splaisan,. That is a very complex experimental setup. I initially proposed freebayes + DV in order to merge and observe them together, for making proper selection in study-specific regions as a follow-up among the two results. Of course it would easier to write a program to compare between the two, filtered on thresholds appropriate to your design. In any case, even though [freebayes has gVCF output](https://github.com/freebayes/freebayes/blob/master/README.md#usage), let's ignore that for now and look closer at the GLnexus algorithm - as it gives nice insights about how variants are processed from gVCF files. Thus when it generates the pVCF, unified variant sites are collected from variants spanning overlapping regions. Since it performs $`\arg \max_{g} Pr(Genotype = g) Pr(Data | Genotype = g)`$, having multiple possible MNPs in the unified site (across gVCFs) dilutes the probability of each genotype, and thus having them as individual SNPs ensures the GQ and PL are maximally contributed to for each base. This is also because for such unified sites, it considers all discovered QC-filtered alleles greedily in descending order of frequency, and might be exacerbated with rare alleles when calling sites. Therefore given the above, utilizing the combined output of the VCF for post-processing into MNPs might be optimal. Ideally, having phasing information would also provide more confidence in the quality of MNPs from combined adjacent SNPs belonging to a haplotype. If possible, limiting via a BED file to regions that are more relevant for your study - especially under heavy multi-threaded conditions - might shorted the analysis time. With many threads you might be thrashing, thus limiting your performance by spending more time context-switching. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:1751,performance,time,time,1751,"Hi @splaisan,. That is a very complex experimental setup. I initially proposed freebayes + DV in order to merge and observe them together, for making proper selection in study-specific regions as a follow-up among the two results. Of course it would easier to write a program to compare between the two, filtered on thresholds appropriate to your design. In any case, even though [freebayes has gVCF output](https://github.com/freebayes/freebayes/blob/master/README.md#usage), let's ignore that for now and look closer at the GLnexus algorithm - as it gives nice insights about how variants are processed from gVCF files. Thus when it generates the pVCF, unified variant sites are collected from variants spanning overlapping regions. Since it performs $`\arg \max_{g} Pr(Genotype = g) Pr(Data | Genotype = g)`$, having multiple possible MNPs in the unified site (across gVCFs) dilutes the probability of each genotype, and thus having them as individual SNPs ensures the GQ and PL are maximally contributed to for each base. This is also because for such unified sites, it considers all discovered QC-filtered alleles greedily in descending order of frequency, and might be exacerbated with rare alleles when calling sites. Therefore given the above, utilizing the combined output of the VCF for post-processing into MNPs might be optimal. Ideally, having phasing information would also provide more confidence in the quality of MNPs from combined adjacent SNPs belonging to a haplotype. If possible, limiting via a BED file to regions that are more relevant for your study - especially under heavy multi-threaded conditions - might shorted the analysis time. With many threads you might be thrashing, thus limiting your performance by spending more time context-switching. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:30,safety,compl,complex,30,"Hi @splaisan,. That is a very complex experimental setup. I initially proposed freebayes + DV in order to merge and observe them together, for making proper selection in study-specific regions as a follow-up among the two results. Of course it would easier to write a program to compare between the two, filtered on thresholds appropriate to your design. In any case, even though [freebayes has gVCF output](https://github.com/freebayes/freebayes/blob/master/README.md#usage), let's ignore that for now and look closer at the GLnexus algorithm - as it gives nice insights about how variants are processed from gVCF files. Thus when it generates the pVCF, unified variant sites are collected from variants spanning overlapping regions. Since it performs $`\arg \max_{g} Pr(Genotype = g) Pr(Data | Genotype = g)`$, having multiple possible MNPs in the unified site (across gVCFs) dilutes the probability of each genotype, and thus having them as individual SNPs ensures the GQ and PL are maximally contributed to for each base. This is also because for such unified sites, it considers all discovered QC-filtered alleles greedily in descending order of frequency, and might be exacerbated with rare alleles when calling sites. Therefore given the above, utilizing the combined output of the VCF for post-processing into MNPs might be optimal. Ideally, having phasing information would also provide more confidence in the quality of MNPs from combined adjacent SNPs belonging to a haplotype. If possible, limiting via a BED file to regions that are more relevant for your study - especially under heavy multi-threaded conditions - might shorted the analysis time. With many threads you might be thrashing, thus limiting your performance by spending more time context-switching. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:30,security,compl,complex,30,"Hi @splaisan,. That is a very complex experimental setup. I initially proposed freebayes + DV in order to merge and observe them together, for making proper selection in study-specific regions as a follow-up among the two results. Of course it would easier to write a program to compare between the two, filtered on thresholds appropriate to your design. In any case, even though [freebayes has gVCF output](https://github.com/freebayes/freebayes/blob/master/README.md#usage), let's ignore that for now and look closer at the GLnexus algorithm - as it gives nice insights about how variants are processed from gVCF files. Thus when it generates the pVCF, unified variant sites are collected from variants spanning overlapping regions. Since it performs $`\arg \max_{g} Pr(Genotype = g) Pr(Data | Genotype = g)`$, having multiple possible MNPs in the unified site (across gVCFs) dilutes the probability of each genotype, and thus having them as individual SNPs ensures the GQ and PL are maximally contributed to for each base. This is also because for such unified sites, it considers all discovered QC-filtered alleles greedily in descending order of frequency, and might be exacerbated with rare alleles when calling sites. Therefore given the above, utilizing the combined output of the VCF for post-processing into MNPs might be optimal. Ideally, having phasing information would also provide more confidence in the quality of MNPs from combined adjacent SNPs belonging to a haplotype. If possible, limiting via a BED file to regions that are more relevant for your study - especially under heavy multi-threaded conditions - might shorted the analysis time. With many threads you might be thrashing, thus limiting your performance by spending more time context-switching. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:116,testability,observ,observe,116,"Hi @splaisan,. That is a very complex experimental setup. I initially proposed freebayes + DV in order to merge and observe them together, for making proper selection in study-specific regions as a follow-up among the two results. Of course it would easier to write a program to compare between the two, filtered on thresholds appropriate to your design. In any case, even though [freebayes has gVCF output](https://github.com/freebayes/freebayes/blob/master/README.md#usage), let's ignore that for now and look closer at the GLnexus algorithm - as it gives nice insights about how variants are processed from gVCF files. Thus when it generates the pVCF, unified variant sites are collected from variants spanning overlapping regions. Since it performs $`\arg \max_{g} Pr(Genotype = g) Pr(Data | Genotype = g)`$, having multiple possible MNPs in the unified site (across gVCFs) dilutes the probability of each genotype, and thus having them as individual SNPs ensures the GQ and PL are maximally contributed to for each base. This is also because for such unified sites, it considers all discovered QC-filtered alleles greedily in descending order of frequency, and might be exacerbated with rare alleles when calling sites. Therefore given the above, utilizing the combined output of the VCF for post-processing into MNPs might be optimal. Ideally, having phasing information would also provide more confidence in the quality of MNPs from combined adjacent SNPs belonging to a haplotype. If possible, limiting via a BED file to regions that are more relevant for your study - especially under heavy multi-threaded conditions - might shorted the analysis time. With many threads you might be thrashing, thus limiting your performance by spending more time context-switching. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:1756,testability,context,context-switching,1756,"Hi @splaisan,. That is a very complex experimental setup. I initially proposed freebayes + DV in order to merge and observe them together, for making proper selection in study-specific regions as a follow-up among the two results. Of course it would easier to write a program to compare between the two, filtered on thresholds appropriate to your design. In any case, even though [freebayes has gVCF output](https://github.com/freebayes/freebayes/blob/master/README.md#usage), let's ignore that for now and look closer at the GLnexus algorithm - as it gives nice insights about how variants are processed from gVCF files. Thus when it generates the pVCF, unified variant sites are collected from variants spanning overlapping regions. Since it performs $`\arg \max_{g} Pr(Genotype = g) Pr(Data | Genotype = g)`$, having multiple possible MNPs in the unified site (across gVCFs) dilutes the probability of each genotype, and thus having them as individual SNPs ensures the GQ and PL are maximally contributed to for each base. This is also because for such unified sites, it considers all discovered QC-filtered alleles greedily in descending order of frequency, and might be exacerbated with rare alleles when calling sites. Therefore given the above, utilizing the combined output of the VCF for post-processing into MNPs might be optimal. Ideally, having phasing information would also provide more confidence in the quality of MNPs from combined adjacent SNPs belonging to a haplotype. If possible, limiting via a BED file to regions that are more relevant for your study - especially under heavy multi-threaded conditions - might shorted the analysis time. With many threads you might be thrashing, thus limiting your performance by spending more time context-switching. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:512,usability,close,closer,512,"Hi @splaisan,. That is a very complex experimental setup. I initially proposed freebayes + DV in order to merge and observe them together, for making proper selection in study-specific regions as a follow-up among the two results. Of course it would easier to write a program to compare between the two, filtered on thresholds appropriate to your design. In any case, even though [freebayes has gVCF output](https://github.com/freebayes/freebayes/blob/master/README.md#usage), let's ignore that for now and look closer at the GLnexus algorithm - as it gives nice insights about how variants are processed from gVCF files. Thus when it generates the pVCF, unified variant sites are collected from variants spanning overlapping regions. Since it performs $`\arg \max_{g} Pr(Genotype = g) Pr(Data | Genotype = g)`$, having multiple possible MNPs in the unified site (across gVCFs) dilutes the probability of each genotype, and thus having them as individual SNPs ensures the GQ and PL are maximally contributed to for each base. This is also because for such unified sites, it considers all discovered QC-filtered alleles greedily in descending order of frequency, and might be exacerbated with rare alleles when calling sites. Therefore given the above, utilizing the combined output of the VCF for post-processing into MNPs might be optimal. Ideally, having phasing information would also provide more confidence in the quality of MNPs from combined adjacent SNPs belonging to a haplotype. If possible, limiting via a BED file to regions that are more relevant for your study - especially under heavy multi-threaded conditions - might shorted the analysis time. With many threads you might be thrashing, thus limiting your performance by spending more time context-switching. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:744,usability,perform,performs,744,"Hi @splaisan,. That is a very complex experimental setup. I initially proposed freebayes + DV in order to merge and observe them together, for making proper selection in study-specific regions as a follow-up among the two results. Of course it would easier to write a program to compare between the two, filtered on thresholds appropriate to your design. In any case, even though [freebayes has gVCF output](https://github.com/freebayes/freebayes/blob/master/README.md#usage), let's ignore that for now and look closer at the GLnexus algorithm - as it gives nice insights about how variants are processed from gVCF files. Thus when it generates the pVCF, unified variant sites are collected from variants spanning overlapping regions. Since it performs $`\arg \max_{g} Pr(Genotype = g) Pr(Data | Genotype = g)`$, having multiple possible MNPs in the unified site (across gVCFs) dilutes the probability of each genotype, and thus having them as individual SNPs ensures the GQ and PL are maximally contributed to for each base. This is also because for such unified sites, it considers all discovered QC-filtered alleles greedily in descending order of frequency, and might be exacerbated with rare alleles when calling sites. Therefore given the above, utilizing the combined output of the VCF for post-processing into MNPs might be optimal. Ideally, having phasing information would also provide more confidence in the quality of MNPs from combined adjacent SNPs belonging to a haplotype. If possible, limiting via a BED file to regions that are more relevant for your study - especially under heavy multi-threaded conditions - might shorted the analysis time. With many threads you might be thrashing, thus limiting your performance by spending more time context-switching. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:1088,usability,discov,discovered,1088,"Hi @splaisan,. That is a very complex experimental setup. I initially proposed freebayes + DV in order to merge and observe them together, for making proper selection in study-specific regions as a follow-up among the two results. Of course it would easier to write a program to compare between the two, filtered on thresholds appropriate to your design. In any case, even though [freebayes has gVCF output](https://github.com/freebayes/freebayes/blob/master/README.md#usage), let's ignore that for now and look closer at the GLnexus algorithm - as it gives nice insights about how variants are processed from gVCF files. Thus when it generates the pVCF, unified variant sites are collected from variants spanning overlapping regions. Since it performs $`\arg \max_{g} Pr(Genotype = g) Pr(Data | Genotype = g)`$, having multiple possible MNPs in the unified site (across gVCFs) dilutes the probability of each genotype, and thus having them as individual SNPs ensures the GQ and PL are maximally contributed to for each base. This is also because for such unified sites, it considers all discovered QC-filtered alleles greedily in descending order of frequency, and might be exacerbated with rare alleles when calling sites. Therefore given the above, utilizing the combined output of the VCF for post-processing into MNPs might be optimal. Ideally, having phasing information would also provide more confidence in the quality of MNPs from combined adjacent SNPs belonging to a haplotype. If possible, limiting via a BED file to regions that are more relevant for your study - especially under heavy multi-threaded conditions - might shorted the analysis time. With many threads you might be thrashing, thus limiting your performance by spending more time context-switching. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:1722,usability,perform,performance,1722,"Hi @splaisan,. That is a very complex experimental setup. I initially proposed freebayes + DV in order to merge and observe them together, for making proper selection in study-specific regions as a follow-up among the two results. Of course it would easier to write a program to compare between the two, filtered on thresholds appropriate to your design. In any case, even though [freebayes has gVCF output](https://github.com/freebayes/freebayes/blob/master/README.md#usage), let's ignore that for now and look closer at the GLnexus algorithm - as it gives nice insights about how variants are processed from gVCF files. Thus when it generates the pVCF, unified variant sites are collected from variants spanning overlapping regions. Since it performs $`\arg \max_{g} Pr(Genotype = g) Pr(Data | Genotype = g)`$, having multiple possible MNPs in the unified site (across gVCFs) dilutes the probability of each genotype, and thus having them as individual SNPs ensures the GQ and PL are maximally contributed to for each base. This is also because for such unified sites, it considers all discovered QC-filtered alleles greedily in descending order of frequency, and might be exacerbated with rare alleles when calling sites. Therefore given the above, utilizing the combined output of the VCF for post-processing into MNPs might be optimal. Ideally, having phasing information would also provide more confidence in the quality of MNPs from combined adjacent SNPs belonging to a haplotype. If possible, limiting via a BED file to regions that are more relevant for your study - especially under heavy multi-threaded conditions - might shorted the analysis time. With many threads you might be thrashing, thus limiting your performance by spending more time context-switching. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/238:1783,usability,help,helps,1783,"Hi @splaisan,. That is a very complex experimental setup. I initially proposed freebayes + DV in order to merge and observe them together, for making proper selection in study-specific regions as a follow-up among the two results. Of course it would easier to write a program to compare between the two, filtered on thresholds appropriate to your design. In any case, even though [freebayes has gVCF output](https://github.com/freebayes/freebayes/blob/master/README.md#usage), let's ignore that for now and look closer at the GLnexus algorithm - as it gives nice insights about how variants are processed from gVCF files. Thus when it generates the pVCF, unified variant sites are collected from variants spanning overlapping regions. Since it performs $`\arg \max_{g} Pr(Genotype = g) Pr(Data | Genotype = g)`$, having multiple possible MNPs in the unified site (across gVCFs) dilutes the probability of each genotype, and thus having them as individual SNPs ensures the GQ and PL are maximally contributed to for each base. This is also because for such unified sites, it considers all discovered QC-filtered alleles greedily in descending order of frequency, and might be exacerbated with rare alleles when calling sites. Therefore given the above, utilizing the combined output of the VCF for post-processing into MNPs might be optimal. Ideally, having phasing information would also provide more confidence in the quality of MNPs from combined adjacent SNPs belonging to a haplotype. If possible, limiting via a BED file to regions that are more relevant for your study - especially under heavy multi-threaded conditions - might shorted the analysis time. With many threads you might be thrashing, thus limiting your performance by spending more time context-switching. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/238
https://github.com/google/deepvariant/issues/239:6,deployability,updat,updating,6,"After updating to v0.9.0 we have different results:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:760,deployability,observ,observed,760,"After updating to v0.9.0 we have different results:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:1012,deployability,scale,scaled,1012,"to v0.9.0 we have different results:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001474	.	C	T	45.2	",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24600,deployability,observ,observed,24600,".448276:45,0,57. chr20	10099565	.	C	T	42.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:42:56:33,23:0.410714:42,0,52. chr20	10099755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>Our test VCF (DeepVariant v0.9.0)</summary>. . ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	39.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:44:0,44:1:39,43,0. chr20	10000117	.	C	T	26.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:55:25,30:0.545455:26,0,41. chr20	10000211	.	C	T	39.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:59:30,29:0.491525:39,0,54. chr20	10000439	.	T	G	29.9	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:30:72:0,72:1:29,42,0. chr20	10000598	.	T	A	45.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:44:46:0,46:1:45,51,0. chr20	10000694	.	G	A	38	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:38:48:26,22:0.458333:37,0,53. chr20	10000758	.	T	A	44.5	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:43:56:0,56:1:44,48,0. chr20	10001019	.	T	G	7.1	PASS",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24852,deployability,scale,scaled,24852,":0.415094:29,0,50. ```. </details>. <details>. <summary>Our test VCF (DeepVariant v0.9.0)</summary>. . ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	39.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:44:0,44:1:39,43,0. chr20	10000117	.	C	T	26.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:55:25,30:0.545455:26,0,41. chr20	10000211	.	C	T	39.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:59:30,29:0.491525:39,0,54. chr20	10000439	.	T	G	29.9	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:30:72:0,72:1:29,42,0. chr20	10000598	.	T	A	45.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:44:46:0,46:1:45,51,0. chr20	10000694	.	G	A	38	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:38:48:26,22:0.458333:37,0,53. chr20	10000758	.	T	A	44.5	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:43:56:0,56:1:44,48,0. chr20	10001019	.	T	G	7.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:7:44:31,13:0.295455:6,0,34. chr20	10001298	.	T	A	43.3	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:43:0,43:1:43,45,0. chr20	10001436	.	A	AAGGCT	27.3	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:27:39:2,35:0.897436:27,46,0. chr20	10001474	.	C	T	38.2	PAS",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:243,energy efficiency,model,model,243,"After updating to v0.9.0 we have different results:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:1012,energy efficiency,scale,scaled,1012,"to v0.9.0 we have different results:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001474	.	C	T	45.2	",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24083,energy efficiency,model,model,24083,"94737:0,15,48. chr20	10099111	.	T	TTTTGTTTG	1.9	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:49:33,15:0.306122:0,2,35. chr20	10099140	.	G	T	0.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:16:52:28,24:0.461538:0,15,46. chr20	10099190	.	G	T	9.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:9:47:20,27:0.574468:8,0,42. chr20	10099220	.	A	G	37.3	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:37:40:21,19:0.475:37,0,51. chr20	10099250	.	G	A	32.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:32:39:21,18:0.461538:32,0,46. chr20	10099535	.	G	A	45.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:46:58:32,26:0.448276:45,0,57. chr20	10099565	.	C	T	42.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:42:56:33,23:0.410714:42,0,52. chr20	10099755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>Our test VCF (DeepVariant v0.9.0)</summary>. . ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	39.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:44:0,44:1:39,43,0. c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24852,energy efficiency,scale,scaled,24852,":0.415094:29,0,50. ```. </details>. <details>. <summary>Our test VCF (DeepVariant v0.9.0)</summary>. . ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	39.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:44:0,44:1:39,43,0. chr20	10000117	.	C	T	26.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:55:25,30:0.545455:26,0,41. chr20	10000211	.	C	T	39.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:59:30,29:0.491525:39,0,54. chr20	10000439	.	T	G	29.9	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:30:72:0,72:1:29,42,0. chr20	10000598	.	T	A	45.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:44:46:0,46:1:45,51,0. chr20	10000694	.	G	A	38	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:38:48:26,22:0.458333:37,0,53. chr20	10000758	.	T	A	44.5	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:43:56:0,56:1:44,48,0. chr20	10001019	.	T	G	7.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:7:44:31,13:0.295455:6,0,34. chr20	10001298	.	T	A	43.3	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:43:0,43:1:43,45,0. chr20	10001436	.	A	AAGGCT	27.3	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:27:39:2,35:0.897436:27,46,0. chr20	10001474	.	C	T	38.2	PAS",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:147,integrability,FILTER,FILTER,147,"After updating to v0.9.0 we have different results:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:180,integrability,filter,filters,180,"After updating to v0.9.0 we have different results:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:200,integrability,FILTER,FILTER,200,"After updating to v0.9.0 we have different results:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:285,integrability,FILTER,FILTER,285,"After updating to v0.9.0 we have different results:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:1138,integrability,FILTER,FILTER,1138,".2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001474	.	C	T	45.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:44:36:0,36:1:45,50,0. chr20	10001617	.	C	A	30.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:31:43:23,20:0.4651",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:23987,integrability,FILTER,FILTER,23987,"8,14:0.333333:0,28,55. chr20	10099079	.	C	T	0.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:16:38:23,15:0.394737:0,15,48. chr20	10099111	.	T	TTTTGTTTG	1.9	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:49:33,15:0.306122:0,2,35. chr20	10099140	.	G	T	0.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:16:52:28,24:0.461538:0,15,46. chr20	10099190	.	G	T	9.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:9:47:20,27:0.574468:8,0,42. chr20	10099220	.	A	G	37.3	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:37:40:21,19:0.475:37,0,51. chr20	10099250	.	G	A	32.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:32:39:21,18:0.461538:32,0,46. chr20	10099535	.	G	A	45.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:46:58:32,26:0.448276:45,0,57. chr20	10099565	.	C	T	42.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:42:56:33,23:0.410714:42,0,52. chr20	10099755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>Our test VCF (DeepVariant v0.9.0)</summary>. . ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24020,integrability,filter,filters,24020,"079	.	C	T	0.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:16:38:23,15:0.394737:0,15,48. chr20	10099111	.	T	TTTTGTTTG	1.9	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:49:33,15:0.306122:0,2,35. chr20	10099140	.	G	T	0.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:16:52:28,24:0.461538:0,15,46. chr20	10099190	.	G	T	9.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:9:47:20,27:0.574468:8,0,42. chr20	10099220	.	A	G	37.3	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:37:40:21,19:0.475:37,0,51. chr20	10099250	.	G	A	32.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:32:39:21,18:0.461538:32,0,46. chr20	10099535	.	G	A	45.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:46:58:32,26:0.448276:45,0,57. chr20	10099565	.	C	T	42.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:42:56:33,23:0.410714:42,0,52. chr20	10099755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>Our test VCF (DeepVariant v0.9.0)</summary>. . ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24040,integrability,FILTER,FILTER,24040,"ll	.	GT:GQ:DP:AD:VAF:PL	./.:16:38:23,15:0.394737:0,15,48. chr20	10099111	.	T	TTTTGTTTG	1.9	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:49:33,15:0.306122:0,2,35. chr20	10099140	.	G	T	0.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:16:52:28,24:0.461538:0,15,46. chr20	10099190	.	G	T	9.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:9:47:20,27:0.574468:8,0,42. chr20	10099220	.	A	G	37.3	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:37:40:21,19:0.475:37,0,51. chr20	10099250	.	G	A	32.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:32:39:21,18:0.461538:32,0,46. chr20	10099535	.	G	A	45.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:46:58:32,26:0.448276:45,0,57. chr20	10099565	.	C	T	42.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:42:56:33,23:0.410714:42,0,52. chr20	10099755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>Our test VCF (DeepVariant v0.9.0)</summary>. . ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	39.7	PASS	.	GT:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24125,integrability,FILTER,FILTER,24125,"G	1.9	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:49:33,15:0.306122:0,2,35. chr20	10099140	.	G	T	0.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:16:52:28,24:0.461538:0,15,46. chr20	10099190	.	G	T	9.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:9:47:20,27:0.574468:8,0,42. chr20	10099220	.	A	G	37.3	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:37:40:21,19:0.475:37,0,51. chr20	10099250	.	G	A	32.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:32:39:21,18:0.461538:32,0,46. chr20	10099535	.	G	A	45.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:46:58:32,26:0.448276:45,0,57. chr20	10099565	.	C	T	42.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:42:56:33,23:0.410714:42,0,52. chr20	10099755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>Our test VCF (DeepVariant v0.9.0)</summary>. . ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	39.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:44:0,44:1:39,43,0. chr20	10000117	.	C	T	26.1	PASS	.	GT:GQ:DP:A",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24978,integrability,FILTER,FILTER,24978,".2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	39.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:44:0,44:1:39,43,0. chr20	10000117	.	C	T	26.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:55:25,30:0.545455:26,0,41. chr20	10000211	.	C	T	39.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:59:30,29:0.491525:39,0,54. chr20	10000439	.	T	G	29.9	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:30:72:0,72:1:29,42,0. chr20	10000598	.	T	A	45.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:44:46:0,46:1:45,51,0. chr20	10000694	.	G	A	38	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:38:48:26,22:0.458333:37,0,53. chr20	10000758	.	T	A	44.5	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:43:56:0,56:1:44,48,0. chr20	10001019	.	T	G	7.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:7:44:31,13:0.295455:6,0,34. chr20	10001298	.	T	A	43.3	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:43:0,43:1:43,45,0. chr20	10001436	.	A	AAGGCT	27.3	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:27:39:2,35:0.897436:27,46,0. chr20	10001474	.	C	T	38.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:36:0,36:1:38,50,0. chr20	10001617	.	C	A	38.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:43:23,20:0.465116:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:48493,integrability,Filter,Filter,48493,"	./.:3:26:18,8:0.307692:0,0,35. chr20	10099029	.	T	C	0.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:16:36:20,16:0.444444:0,15,44. chr20	10099034	.	C	A	0	RefCall	.	GT:GQ:DP:AD:VAF:PL	0/0:22:35:20,15:0.428571:0,21,42. chr20	10099044	.	A	C	0.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:15:38:25,13:0.342105:0,15,42. chr20	10099046	.	T	C	0	RefCall	.	GT:GQ:DP:AD:VAF:PL	0/0:30:39:26,13:0.333333:0,30,49. chr20	10099055	.	T	C	0	RefCall	.	GT:GQ:DP:AD:VAF:PL	0/0:45:42:28,14:0.333333:0,45,57. chr20	10099079	.	C	T	0	RefCall	.	GT:GQ:DP:AD:VAF:PL	0/0:34:38:23,15:0.394737:0,34,54. chr20	10099111	.	T	TTTTGTTTG	2.9	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:3:49:33,15:0.306122:0,0,36. chr20	10099140	.	G	T	0.8	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:8:52:28,24:0.461538:0,6,46. chr20	10099190	.	G	T	10	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:10:47:20,27:0.574468:9,0,47. chr20	10099220	.	A	G	44.3	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:44:40:21,19:0.475:44,0,61. chr20	10099250	.	G	A	39.3	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:39:21,18:0.461538:39,0,59. chr20	10099535	.	G	A	45.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:46:58:32,26:0.448276:45,0,61. chr20	10099565	.	C	T	37.6	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:38:56:33,23:0.410714:37,0,56. chr20	10099755	.	C	T	30.6	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:31:50:25,25:0.5:30,0,53. chr20	10099832	.	A	G	27.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:27:53:31,22:0.415094:27,0,46. ```. </details>. hap.py report for v0.9.0 data:. ```. Type Filter TRUTH.TOTAL TRUTH.TP TRUTH.FN QUERY.TOTAL QUERY.FP QUERY.UNK FP.gt METRIC.Recall METRIC.Precision METRIC.Frac_NA METRIC.F1_Score TRUTH.TOTAL.TiTv_ratio QUERY.TOTAL.TiTv_ratio TRUTH.TOTAL.het_hom_ratio QUERY.TOTAL.het_hom_ratio. INDEL ALL 4 4 0 49 0 45 0 1.0 1.0 0.918367 1.0 0.333333333333 1.28571428571. INDEL PASS 4 4 0 49 0 45 0 1.0 1.0 0.918367 1.0 0.333333333333 1.28571428571. SNP ALL 45 45 0 188 0 143 0 1.0 1.0 0.760638 1.0 1.14285714286 1.98412698413 0.363636363636 1.35. SNP PASS 45 45 0 188 0 143 0 1.0 1.0 0.760638 1.0 1.14285714286 1.98412698413 0.363636363636 1.35. ```. Is it expected difference?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:486,interoperability,FORMAT,FORMAT,486,"After updating to v0.9.0 we have different results:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:548,interoperability,FORMAT,FORMAT,548,"After updating to v0.9.0 we have different results:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:631,interoperability,FORMAT,FORMAT,631,"After updating to v0.9.0 we have different results:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:696,interoperability,FORMAT,FORMAT,696,"After updating to v0.9.0 we have different results:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:797,interoperability,FORMAT,FORMAT,797,"After updating to v0.9.0 we have different results:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:878,interoperability,FORMAT,FORMAT,878,"After updating to v0.9.0 we have different results:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:957,interoperability,FORMAT,FORMAT,957,"After updating to v0.9.0 we have different results:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:1150,interoperability,FORMAT,FORMAT,1150,"=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001474	.	C	T	45.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:44:36:0,36:1:45,50,0. chr20	10001617	.	C	A	30.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:31:43:23,20:0.465116:30,0,57. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24326,interoperability,FORMAT,FORMAT,24326,"F:PL	0/1:9:47:20,27:0.574468:8,0,42. chr20	10099220	.	A	G	37.3	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:37:40:21,19:0.475:37,0,51. chr20	10099250	.	G	A	32.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:32:39:21,18:0.461538:32,0,46. chr20	10099535	.	G	A	45.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:46:58:32,26:0.448276:45,0,57. chr20	10099565	.	C	T	42.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:42:56:33,23:0.410714:42,0,52. chr20	10099755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>Our test VCF (DeepVariant v0.9.0)</summary>. . ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	39.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:44:0,44:1:39,43,0. chr20	10000117	.	C	T	26.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:55:25,30:0.545455:26,0,41. chr20	10000211	.	C	T	39.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:59:30,29:0.491525:39,0,54. chr20	10000439	.	T	G	29.9	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:30:72:0,72:1:29,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24388,interoperability,FORMAT,FORMAT,24388,"	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:37:40:21,19:0.475:37,0,51. chr20	10099250	.	G	A	32.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:32:39:21,18:0.461538:32,0,46. chr20	10099535	.	G	A	45.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:46:58:32,26:0.448276:45,0,57. chr20	10099565	.	C	T	42.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:42:56:33,23:0.410714:42,0,52. chr20	10099755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>Our test VCF (DeepVariant v0.9.0)</summary>. . ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	39.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:44:0,44:1:39,43,0. chr20	10000117	.	C	T	26.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:55:25,30:0.545455:26,0,41. chr20	10000211	.	C	T	39.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:59:30,29:0.491525:39,0,54. chr20	10000439	.	T	G	29.9	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:30:72:0,72:1:29,42,0. chr20	10000598	.	T	A	45.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24471,interoperability,FORMAT,FORMAT,24471,"	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:32:39:21,18:0.461538:32,0,46. chr20	10099535	.	G	A	45.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:46:58:32,26:0.448276:45,0,57. chr20	10099565	.	C	T	42.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:42:56:33,23:0.410714:42,0,52. chr20	10099755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>Our test VCF (DeepVariant v0.9.0)</summary>. . ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	39.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:44:0,44:1:39,43,0. chr20	10000117	.	C	T	26.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:55:25,30:0.545455:26,0,41. chr20	10000211	.	C	T	39.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:59:30,29:0.491525:39,0,54. chr20	10000439	.	T	G	29.9	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:30:72:0,72:1:29,42,0. chr20	10000598	.	T	A	45.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:44:46:0,46:1:45,51,0. chr20	10000694	.	G	A	38	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:38:48:2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24536,interoperability,FORMAT,FORMAT,24536,"0	10099535	.	G	A	45.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:46:58:32,26:0.448276:45,0,57. chr20	10099565	.	C	T	42.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:42:56:33,23:0.410714:42,0,52. chr20	10099755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>Our test VCF (DeepVariant v0.9.0)</summary>. . ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	39.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:44:0,44:1:39,43,0. chr20	10000117	.	C	T	26.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:55:25,30:0.545455:26,0,41. chr20	10000211	.	C	T	39.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:59:30,29:0.491525:39,0,54. chr20	10000439	.	T	G	29.9	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:30:72:0,72:1:29,42,0. chr20	10000598	.	T	A	45.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:44:46:0,46:1:45,51,0. chr20	10000694	.	G	A	38	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:38:48:26,22:0.458333:37,0,53. chr20	10000758	.	T	A	44.5	PASS	.	GT:GQ:DP:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24637,interoperability,FORMAT,FORMAT,24637,"T	42.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:42:56:33,23:0.410714:42,0,52. chr20	10099755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>Our test VCF (DeepVariant v0.9.0)</summary>. . ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	39.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:44:0,44:1:39,43,0. chr20	10000117	.	C	T	26.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:55:25,30:0.545455:26,0,41. chr20	10000211	.	C	T	39.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:59:30,29:0.491525:39,0,54. chr20	10000439	.	T	G	29.9	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:30:72:0,72:1:29,42,0. chr20	10000598	.	T	A	45.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:44:46:0,46:1:45,51,0. chr20	10000694	.	G	A	38	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:38:48:26,22:0.458333:37,0,53. chr20	10000758	.	T	A	44.5	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:43:56:0,56:1:44,48,0. chr20	10001019	.	T	G	7.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:7:44:31,13",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24718,interoperability,FORMAT,FORMAT,24718,"	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>Our test VCF (DeepVariant v0.9.0)</summary>. . ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	39.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:44:0,44:1:39,43,0. chr20	10000117	.	C	T	26.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:55:25,30:0.545455:26,0,41. chr20	10000211	.	C	T	39.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:59:30,29:0.491525:39,0,54. chr20	10000439	.	T	G	29.9	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:30:72:0,72:1:29,42,0. chr20	10000598	.	T	A	45.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:44:46:0,46:1:45,51,0. chr20	10000694	.	G	A	38	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:38:48:26,22:0.458333:37,0,53. chr20	10000758	.	T	A	44.5	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:43:56:0,56:1:44,48,0. chr20	10001019	.	T	G	7.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:7:44:31,13:0.295455:6,0,34. chr20	10001298	.	T	A	43.3	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:43:0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24797,interoperability,FORMAT,FORMAT,24797,"32	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>Our test VCF (DeepVariant v0.9.0)</summary>. . ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	39.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:44:0,44:1:39,43,0. chr20	10000117	.	C	T	26.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:55:25,30:0.545455:26,0,41. chr20	10000211	.	C	T	39.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:59:30,29:0.491525:39,0,54. chr20	10000439	.	T	G	29.9	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:30:72:0,72:1:29,42,0. chr20	10000598	.	T	A	45.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:44:46:0,46:1:45,51,0. chr20	10000694	.	G	A	38	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:38:48:26,22:0.458333:37,0,53. chr20	10000758	.	T	A	44.5	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:43:56:0,56:1:44,48,0. chr20	10001019	.	T	G	7.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:7:44:31,13:0.295455:6,0,34. chr20	10001298	.	T	A	43.3	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:43:0,43:1:43,45,0. chr20	10001436	.	A	AAGGCT	27.3	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:27:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24990,interoperability,FORMAT,FORMAT,24990,"=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	39.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:44:0,44:1:39,43,0. chr20	10000117	.	C	T	26.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:55:25,30:0.545455:26,0,41. chr20	10000211	.	C	T	39.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:59:30,29:0.491525:39,0,54. chr20	10000439	.	T	G	29.9	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:30:72:0,72:1:29,42,0. chr20	10000598	.	T	A	45.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:44:46:0,46:1:45,51,0. chr20	10000694	.	G	A	38	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:38:48:26,22:0.458333:37,0,53. chr20	10000758	.	T	A	44.5	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:43:56:0,56:1:44,48,0. chr20	10001019	.	T	G	7.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:7:44:31,13:0.295455:6,0,34. chr20	10001298	.	T	A	43.3	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:43:0,43:1:43,45,0. chr20	10001436	.	A	AAGGCT	27.3	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:27:39:2,35:0.897436:27,46,0. chr20	10001474	.	C	T	38.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:36:0,36:1:38,50,0. chr20	10001617	.	C	A	38.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:43:23,20:0.465116:38,0,59. chr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:1012,modifiability,scal,scaled,1012,"to v0.9.0 we have different results:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001474	.	C	T	45.2	",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24852,modifiability,scal,scaled,24852,":0.415094:29,0,50. ```. </details>. <details>. <summary>Our test VCF (DeepVariant v0.9.0)</summary>. . ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	39.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:44:0,44:1:39,43,0. chr20	10000117	.	C	T	26.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:55:25,30:0.545455:26,0,41. chr20	10000211	.	C	T	39.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:59:30,29:0.491525:39,0,54. chr20	10000439	.	T	G	29.9	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:30:72:0,72:1:29,42,0. chr20	10000598	.	T	A	45.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:44:46:0,46:1:45,51,0. chr20	10000694	.	G	A	38	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:38:48:26,22:0.458333:37,0,53. chr20	10000758	.	T	A	44.5	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:43:56:0,56:1:44,48,0. chr20	10001019	.	T	G	7.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:7:44:31,13:0.295455:6,0,34. chr20	10001298	.	T	A	43.3	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:43:0,43:1:43,45,0. chr20	10001436	.	A	AAGGCT	27.3	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:27:39:2,35:0.897436:27,46,0. chr20	10001474	.	C	T	38.2	PAS",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:1012,performance,scale,scaled,1012,"to v0.9.0 we have different results:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001474	.	C	T	45.2	",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24852,performance,scale,scaled,24852,":0.415094:29,0,50. ```. </details>. <details>. <summary>Our test VCF (DeepVariant v0.9.0)</summary>. . ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	39.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:44:0,44:1:39,43,0. chr20	10000117	.	C	T	26.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:55:25,30:0.545455:26,0,41. chr20	10000211	.	C	T	39.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:59:30,29:0.491525:39,0,54. chr20	10000439	.	T	G	29.9	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:30:72:0,72:1:29,42,0. chr20	10000598	.	T	A	45.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:44:46:0,46:1:45,51,0. chr20	10000694	.	G	A	38	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:38:48:26,22:0.458333:37,0,53. chr20	10000758	.	T	A	44.5	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:43:56:0,56:1:44,48,0. chr20	10001019	.	T	G	7.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:7:44:31,13:0.295455:6,0,34. chr20	10001298	.	T	A	43.3	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:43:0,43:1:43,45,0. chr20	10001436	.	A	AAGGCT	27.3	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:27:39:2,35:0.897436:27,46,0. chr20	10001474	.	C	T	38.2	PAS",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:6,safety,updat,updating,6,"After updating to v0.9.0 we have different results:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:77,safety,test,test,77,"After updating to v0.9.0 we have different results:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:23915,safety,test,test,23915,"3:0,3,33. chr20	10099055	.	T	C	0	RefCall	.	GT:GQ:DP:AD:VAF:PL	0/0:28:42:28,14:0.333333:0,28,55. chr20	10099079	.	C	T	0.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:16:38:23,15:0.394737:0,15,48. chr20	10099111	.	T	TTTTGTTTG	1.9	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:49:33,15:0.306122:0,2,35. chr20	10099140	.	G	T	0.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:16:52:28,24:0.461538:0,15,46. chr20	10099190	.	G	T	9.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:9:47:20,27:0.574468:8,0,42. chr20	10099220	.	A	G	37.3	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:37:40:21,19:0.475:37,0,51. chr20	10099250	.	G	A	32.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:32:39:21,18:0.461538:32,0,46. chr20	10099535	.	G	A	45.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:46:58:32,26:0.448276:45,0,57. chr20	10099565	.	C	T	42.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:42:56:33,23:0.410714:42,0,52. chr20	10099755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>Our test VCF (DeepVariant v0.9.0)</summary>. . ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:6,security,updat,updating,6,"After updating to v0.9.0 we have different results:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:243,security,model,model,243,"After updating to v0.9.0 we have different results:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24083,security,model,model,24083,"94737:0,15,48. chr20	10099111	.	T	TTTTGTTTG	1.9	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:49:33,15:0.306122:0,2,35. chr20	10099140	.	G	T	0.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:16:52:28,24:0.461538:0,15,46. chr20	10099190	.	G	T	9.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:9:47:20,27:0.574468:8,0,42. chr20	10099220	.	A	G	37.3	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:37:40:21,19:0.475:37,0,51. chr20	10099250	.	G	A	32.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:32:39:21,18:0.461538:32,0,46. chr20	10099535	.	G	A	45.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:46:58:32,26:0.448276:45,0,57. chr20	10099565	.	C	T	42.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:42:56:33,23:0.410714:42,0,52. chr20	10099755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>Our test VCF (DeepVariant v0.9.0)</summary>. . ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	39.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:44:0,44:1:39,43,0. c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:77,testability,test,test,77,"After updating to v0.9.0 we have different results:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:760,testability,observ,observed,760,"After updating to v0.9.0 we have different results:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:23915,testability,test,test,23915,"3:0,3,33. chr20	10099055	.	T	C	0	RefCall	.	GT:GQ:DP:AD:VAF:PL	0/0:28:42:28,14:0.333333:0,28,55. chr20	10099079	.	C	T	0.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:16:38:23,15:0.394737:0,15,48. chr20	10099111	.	T	TTTTGTTTG	1.9	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:49:33,15:0.306122:0,2,35. chr20	10099140	.	G	T	0.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:16:52:28,24:0.461538:0,15,46. chr20	10099190	.	G	T	9.4	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:9:47:20,27:0.574468:8,0,42. chr20	10099220	.	A	G	37.3	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:37:40:21,19:0.475:37,0,51. chr20	10099250	.	G	A	32.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:32:39:21,18:0.461538:32,0,46. chr20	10099535	.	G	A	45.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:46:58:32,26:0.448276:45,0,57. chr20	10099565	.	C	T	42.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:42:56:33,23:0.410714:42,0,52. chr20	10099755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>Our test VCF (DeepVariant v0.9.0)</summary>. . ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24600,testability,observ,observed,24600,".448276:45,0,57. chr20	10099565	.	C	T	42.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:42:56:33,23:0.410714:42,0,52. chr20	10099755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>Our test VCF (DeepVariant v0.9.0)</summary>. . ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	39.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:44:0,44:1:39,43,0. chr20	10000117	.	C	T	26.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:55:25,30:0.545455:26,0,41. chr20	10000211	.	C	T	39.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:59:30,29:0.491525:39,0,54. chr20	10000439	.	T	G	29.9	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:30:72:0,72:1:29,42,0. chr20	10000598	.	T	A	45.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:44:46:0,46:1:45,51,0. chr20	10000694	.	G	A	38	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:38:48:26,22:0.458333:37,0,53. chr20	10000758	.	T	A	44.5	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:43:56:0,56:1:44,48,0. chr20	10001019	.	T	G	7.1	PASS",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:749,usability,Minim,Minimum,749,"After updating to v0.9.0 we have different results:. <details>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:1055,usability,close,closest,1055,"ls>. <summary>Our test VCF (DeepVariant v0.8.0)</summary>. ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	44.4	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:44:0,44:1:44,44,0. chr20	10000117	.	C	T	36.9	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:55:25,30:0.545455:36,0,37. chr20	10000211	.	C	T	34.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:34:59:30,29:0.491525:34,0,51. chr20	10000439	.	T	G	40	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:39:72:0,72:1:40,45,0. chr20	10000598	.	T	A	62.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:54:46:0,46:1:62,55,0. chr20	10000694	.	G	A	35.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:35:48:26,22:0.458333:35,0,47. chr20	10000758	.	T	A	69.1	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:56:56:0,56:1:69,55,0. chr20	10001019	.	T	G	2.1	RefCall	.	GT:GQ:DP:AD:VAF:PL	./.:4:44:31,13:0.295455:0,2,34. chr20	10001298	.	T	A	54.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:49:43:0,43:1:54,50,0. chr20	10001436	.	A	AAGGCT	38.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:39:2,35:0.897436:38,47,0. chr20	10001474	.	C	T	45.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:44:36:0,36:1:4",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24589,usability,Minim,Minimum,24589,":58:32,26:0.448276:45,0,57. chr20	10099565	.	C	T	42.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:42:56:33,23:0.410714:42,0,52. chr20	10099755	.	C	T	24.8	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:25:50:25,25:0.5:24,0,47. chr20	10099832	.	A	G	29.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:29:53:31,22:0.415094:29,0,50. ```. </details>. <details>. <summary>Our test VCF (DeepVariant v0.9.0)</summary>. . ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	39.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:44:0,44:1:39,43,0. chr20	10000117	.	C	T	26.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:55:25,30:0.545455:26,0,41. chr20	10000211	.	C	T	39.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:59:30,29:0.491525:39,0,54. chr20	10000439	.	T	G	29.9	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:30:72:0,72:1:29,42,0. chr20	10000598	.	T	A	45.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:44:46:0,46:1:45,51,0. chr20	10000694	.	G	A	38	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:38:48:26,22:0.458333:37,0,53. chr20	10000758	.	T	A	44.5	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:43:56:0,56:1:44,48,0. chr20	10001019	.	T",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:24895,usability,close,closest,24895,">. <summary>Our test VCF (DeepVariant v0.9.0)</summary>. . ```. ##fileformat=VCFv4.2. ##FILTER=<ID=PASS,Description=""All filters passed"">. ##FILTER=<ID=RefCall,Description=""Genotyping model thinks this site is reference."">. ##FILTER=<ID=LowQual,Description=""Confidence in this variant being real is below calling threshold."">. ##INFO=<ID=END,Number=1,Type=Integer,Description=""End position (for use with symbolic alleles)"">. ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">. ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Conditional genotype quality"">. ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Read depth"">. ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block."">. ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Read depth for each allele"">. ##FORMAT=<ID=VAF,Number=A,Type=Float,Description=""Variant allele fractions."">. ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Phred-scaled genotype likelihoods rounded to the closest integer"">. ##contig=<ID=chr20,length=63025520>. #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	NA12878. chr20	9999996	.	A	ACT	39.7	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:44:0,44:1:39,43,0. chr20	10000117	.	C	T	26.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:26:55:25,30:0.545455:26,0,41. chr20	10000211	.	C	T	39.2	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:39:59:30,29:0.491525:39,0,54. chr20	10000439	.	T	G	29.9	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:30:72:0,72:1:29,42,0. chr20	10000598	.	T	A	45.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:44:46:0,46:1:45,51,0. chr20	10000694	.	G	A	38	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:38:48:26,22:0.458333:37,0,53. chr20	10000758	.	T	A	44.5	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:43:56:0,56:1:44,48,0. chr20	10001019	.	T	G	7.1	PASS	.	GT:GQ:DP:AD:VAF:PL	0/1:7:44:31,13:0.295455:6,0,34. chr20	10001298	.	T	A	43.3	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:41:43:0,43:1:43,45,0. chr20	10001436	.	A	AAGGCT	27.3	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:27:39:2,35:0.897436:27,46,0. chr20	10001474	.	C	T	38.2	PASS	.	GT:GQ:DP:AD:VAF:PL	1/1:38:36:0,36:1:38,5",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:115,deployability,version,version,115,"Looks like I forgot to submit calling regions, now we have much less query records. I assume one FN call at v0.8.0 version is expected, because it was in v0.8.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) and it wasn't in v0.9.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md). Am I correct?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:23,integrability,sub,submit,23,"Looks like I forgot to submit calling regions, now we have much less query records. I assume one FN call at v0.8.0 version is expected, because it was in v0.8.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) and it wasn't in v0.9.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md). Am I correct?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:115,integrability,version,version,115,"Looks like I forgot to submit calling regions, now we have much less query records. I assume one FN call at v0.8.0 version is expected, because it was in v0.8.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) and it wasn't in v0.9.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md). Am I correct?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:115,modifiability,version,version,115,"Looks like I forgot to submit calling regions, now we have much less query records. I assume one FN call at v0.8.0 version is expected, because it was in v0.8.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) and it wasn't in v0.9.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md). Am I correct?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:119,deployability,version,version,119,"> Looks like I forgot to submit calling regions, now we have much less query records. > I assume one FN call at v0.8.0 version is expected, because it was in v0.8.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) and it wasn't in v0.9.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md). Hi @Stikus , you closed this issue so I'm not sure if you still have this question. In 0.8.0 and 0.9.0, the code and models have changed. If following v0.9.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md), I would expect you to get 0 FN calls. But yes, if you're running with v0.8.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), I would expect 1 FN call. Feel free to open another issue (or reopen this issue) if you still have questions. Thanks! > Am I correct?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:527,energy efficiency,model,models,527,"> Looks like I forgot to submit calling regions, now we have much less query records. > I assume one FN call at v0.8.0 version is expected, because it was in v0.8.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) and it wasn't in v0.9.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md). Hi @Stikus , you closed this issue so I'm not sure if you still have this question. In 0.8.0 and 0.9.0, the code and models have changed. If following v0.9.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md), I would expect you to get 0 FN calls. But yes, if you're running with v0.8.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), I would expect 1 FN call. Feel free to open another issue (or reopen this issue) if you still have questions. Thanks! > Am I correct?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:25,integrability,sub,submit,25,"> Looks like I forgot to submit calling regions, now we have much less query records. > I assume one FN call at v0.8.0 version is expected, because it was in v0.8.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) and it wasn't in v0.9.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md). Hi @Stikus , you closed this issue so I'm not sure if you still have this question. In 0.8.0 and 0.9.0, the code and models have changed. If following v0.9.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md), I would expect you to get 0 FN calls. But yes, if you're running with v0.8.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), I would expect 1 FN call. Feel free to open another issue (or reopen this issue) if you still have questions. Thanks! > Am I correct?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:119,integrability,version,version,119,"> Looks like I forgot to submit calling regions, now we have much less query records. > I assume one FN call at v0.8.0 version is expected, because it was in v0.8.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) and it wasn't in v0.9.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md). Hi @Stikus , you closed this issue so I'm not sure if you still have this question. In 0.8.0 and 0.9.0, the code and models have changed. If following v0.9.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md), I would expect you to get 0 FN calls. But yes, if you're running with v0.8.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), I would expect 1 FN call. Feel free to open another issue (or reopen this issue) if you still have questions. Thanks! > Am I correct?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:119,modifiability,version,version,119,"> Looks like I forgot to submit calling regions, now we have much less query records. > I assume one FN call at v0.8.0 version is expected, because it was in v0.8.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) and it wasn't in v0.9.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md). Hi @Stikus , you closed this issue so I'm not sure if you still have this question. In 0.8.0 and 0.9.0, the code and models have changed. If following v0.9.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md), I would expect you to get 0 FN calls. But yes, if you're running with v0.8.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), I would expect 1 FN call. Feel free to open another issue (or reopen this issue) if you still have questions. Thanks! > Am I correct?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:527,security,model,models,527,"> Looks like I forgot to submit calling regions, now we have much less query records. > I assume one FN call at v0.8.0 version is expected, because it was in v0.8.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) and it wasn't in v0.9.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md). Hi @Stikus , you closed this issue so I'm not sure if you still have this question. In 0.8.0 and 0.9.0, the code and models have changed. If following v0.9.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md), I would expect you to get 0 FN calls. But yes, if you're running with v0.8.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), I would expect 1 FN call. Feel free to open another issue (or reopen this issue) if you still have questions. Thanks! > Am I correct?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/239:427,usability,close,closed,427,"> Looks like I forgot to submit calling regions, now we have much less query records. > I assume one FN call at v0.8.0 version is expected, because it was in v0.8.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) and it wasn't in v0.9.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md). Hi @Stikus , you closed this issue so I'm not sure if you still have this question. In 0.8.0 and 0.9.0, the code and models have changed. If following v0.9.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-quick-start.md), I would expect you to get 0 FN calls. But yes, if you're running with v0.8.0 [deepvariant-quick-start.md](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), I would expect 1 FN call. Feel free to open another issue (or reopen this issue) if you still have questions. Thanks! > Am I correct?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/239
https://github.com/google/deepvariant/issues/240:165,energy efficiency,GPU,GPU,165,"Hi @aardes, we have reported [this runtime](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-case-study.md#runtime) for running DeepVariant WGS on a GPU. The specs for that GPU are listed at the bottom of the [page](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-details.md#command-for-a-gpu-machine-on-google-cloud-platform). I'm not sure how your specific GPU type would perform, but those numbers should give you a point of comparison.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/240
https://github.com/google/deepvariant/issues/240:189,energy efficiency,GPU,GPU,189,"Hi @aardes, we have reported [this runtime](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-case-study.md#runtime) for running DeepVariant WGS on a GPU. The specs for that GPU are listed at the bottom of the [page](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-details.md#command-for-a-gpu-machine-on-google-cloud-platform). I'm not sure how your specific GPU type would perform, but those numbers should give you a point of comparison.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/240
https://github.com/google/deepvariant/issues/240:322,energy efficiency,gpu,gpu-machine-on-google-cloud-platform,322,"Hi @aardes, we have reported [this runtime](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-case-study.md#runtime) for running DeepVariant WGS on a GPU. The specs for that GPU are listed at the bottom of the [page](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-details.md#command-for-a-gpu-machine-on-google-cloud-platform). I'm not sure how your specific GPU type would perform, but those numbers should give you a point of comparison.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/240
https://github.com/google/deepvariant/issues/240:392,energy efficiency,GPU,GPU,392,"Hi @aardes, we have reported [this runtime](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-case-study.md#runtime) for running DeepVariant WGS on a GPU. The specs for that GPU are listed at the bottom of the [page](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-details.md#command-for-a-gpu-machine-on-google-cloud-platform). I'm not sure how your specific GPU type would perform, but those numbers should give you a point of comparison.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/240
https://github.com/google/deepvariant/issues/240:350,interoperability,platform,platform,350,"Hi @aardes, we have reported [this runtime](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-case-study.md#runtime) for running DeepVariant WGS on a GPU. The specs for that GPU are listed at the bottom of the [page](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-details.md#command-for-a-gpu-machine-on-google-cloud-platform). I'm not sure how your specific GPU type would perform, but those numbers should give you a point of comparison.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/240
https://github.com/google/deepvariant/issues/240:383,interoperability,specif,specific,383,"Hi @aardes, we have reported [this runtime](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-case-study.md#runtime) for running DeepVariant WGS on a GPU. The specs for that GPU are listed at the bottom of the [page](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-details.md#command-for-a-gpu-machine-on-google-cloud-platform). I'm not sure how your specific GPU type would perform, but those numbers should give you a point of comparison.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/240
https://github.com/google/deepvariant/issues/240:165,performance,GPU,GPU,165,"Hi @aardes, we have reported [this runtime](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-case-study.md#runtime) for running DeepVariant WGS on a GPU. The specs for that GPU are listed at the bottom of the [page](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-details.md#command-for-a-gpu-machine-on-google-cloud-platform). I'm not sure how your specific GPU type would perform, but those numbers should give you a point of comparison.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/240
https://github.com/google/deepvariant/issues/240:189,performance,GPU,GPU,189,"Hi @aardes, we have reported [this runtime](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-case-study.md#runtime) for running DeepVariant WGS on a GPU. The specs for that GPU are listed at the bottom of the [page](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-details.md#command-for-a-gpu-machine-on-google-cloud-platform). I'm not sure how your specific GPU type would perform, but those numbers should give you a point of comparison.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/240
https://github.com/google/deepvariant/issues/240:322,performance,gpu,gpu-machine-on-google-cloud-platform,322,"Hi @aardes, we have reported [this runtime](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-case-study.md#runtime) for running DeepVariant WGS on a GPU. The specs for that GPU are listed at the bottom of the [page](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-details.md#command-for-a-gpu-machine-on-google-cloud-platform). I'm not sure how your specific GPU type would perform, but those numbers should give you a point of comparison.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/240
https://github.com/google/deepvariant/issues/240:392,performance,GPU,GPU,392,"Hi @aardes, we have reported [this runtime](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-case-study.md#runtime) for running DeepVariant WGS on a GPU. The specs for that GPU are listed at the bottom of the [page](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-details.md#command-for-a-gpu-machine-on-google-cloud-platform). I'm not sure how your specific GPU type would perform, but those numbers should give you a point of comparison.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/240
https://github.com/google/deepvariant/issues/240:407,performance,perform,perform,407,"Hi @aardes, we have reported [this runtime](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-case-study.md#runtime) for running DeepVariant WGS on a GPU. The specs for that GPU are listed at the bottom of the [page](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-details.md#command-for-a-gpu-machine-on-google-cloud-platform). I'm not sure how your specific GPU type would perform, but those numbers should give you a point of comparison.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/240
https://github.com/google/deepvariant/issues/240:308,usability,command,command-for-a-gpu-machine-on-google-cloud-platform,308,"Hi @aardes, we have reported [this runtime](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-case-study.md#runtime) for running DeepVariant WGS on a GPU. The specs for that GPU are listed at the bottom of the [page](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-details.md#command-for-a-gpu-machine-on-google-cloud-platform). I'm not sure how your specific GPU type would perform, but those numbers should give you a point of comparison.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/240
https://github.com/google/deepvariant/issues/240:407,usability,perform,perform,407,"Hi @aardes, we have reported [this runtime](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-case-study.md#runtime) for running DeepVariant WGS on a GPU. The specs for that GPU are listed at the bottom of the [page](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-details.md#command-for-a-gpu-machine-on-google-cloud-platform). I'm not sure how your specific GPU type would perform, but those numbers should give you a point of comparison.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/240
https://github.com/google/deepvariant/issues/241:56,deployability,version,version,56,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:346,deployability,releas,releasing,346,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:477,deployability,infrastructur,infrastructure,477,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:639,deployability,resourc,resource,639,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:540,energy efficiency,model,model,540,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:584,energy efficiency,model,models,584,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:639,energy efficiency,resourc,resource,639,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:880,energy efficiency,model,models,880,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:982,energy efficiency,GPU,GPUs,982,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:56,integrability,version,version,56,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:56,modifiability,version,version,56,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:577,modifiability,Pac,PacBio,577,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:119,performance,perform,performs,119,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:258,performance,perform,performance,258,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:364,performance,time,time,364,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:639,performance,resourc,resource,639,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:982,performance,GPU,GPUs,982,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:1048,performance,time,time,1048,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:1563,reliability,doe,does,1563,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:639,safety,resourc,resource,639,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:540,security,model,model,540,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:584,security,model,models,584,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:880,security,model,models,880,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:136,testability,simul,simulated,136,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:639,testability,resourc,resource,639,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:119,usability,perform,performs,119,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:218,usability,feedback,feedback,218,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:258,usability,perform,performance,258,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:966,usability,workflow,workflows,966,"Hi @mikael-christensen . For somatic calling, we have a version of DeepVariant designed to call somatic variants. This performs well in simulated benchmarks and in benchmarks with COLO829. However, we want to get more feedback from external groups about its performance across real data for more cancer types before we feel comfortable generally releasing it. The time to train DeepVariant internally is a function of the amount and prioritization of training jobs on internal infrastructure. Generally it takes a few days to train the WGS model and is shorter for the WES and PacBio models. Training uses TPUs. I am not sure of the exact resource requirements in the production runs. However, external groups who have successfully trained DeepVariant have generally done so with much less data than what we train for in production, and often warmstart from one of our production models and re-train for their data. External groups have shown improvements for their workflows using GPUs and (I believe) on the order of a day or less of re-training time. The candidates created by the very sensitive caller are not genotyped, so comparing accuracy of the sensitive caller in the same way isn't quite possible. DeepVariant's VCF output will write every position which it generated a candidate for. For a 50x PCR-Free Illumina HG002 run, DeepVariant produced:. 0/0 calls - 934,097 . ./. calls - 150,238. 0/1 calls - 2,793,521. 1/1 calls - 1,851,566. 1/2 calls - 78,194. This means that for about 19% of the positions which the sensitive caller proposes, DeepVariant does not believe there is sufficient evidence for a variant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:45,usability,help,helpful,45,"Thank you for the speedy reply! This is very helpful - Best, Mikael.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:170,reliability,pra,practice,170,You! You should also evaluate in on blood liquid biopsy samples! Having a tool that can call accurate variants in these samples would be extremely useful in the clinical practice.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:74,usability,tool,tool,74,You! You should also evaluate in on blood liquid biopsy samples! Having a tool that can call accurate variants in these samples would be extremely useful in the clinical practice.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:82,modifiability,Pac,PacBio,82,I am also waiting for somatic variant calling using deepvariant on both Hiseq and PacBio reads!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/241:97,testability,simul,simulated,97,"@AndrewCarroll , what data was used for training the somatic caller? And how do you generate the simulated benchmarks? Could you point me to more information on this?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/241
https://github.com/google/deepvariant/issues/242:99,deployability,releas,release,99,Thanks @ptrebert . I added this as a future improvement that we'll work on and include in the next release. I'll leave this open.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/242
https://github.com/google/deepvariant/issues/242:76,deployability,version,version,76,"Hi @ptrebert . Thanks for the suggestion. I have fixed this in our internal version, and the fix will come out in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/242
https://github.com/google/deepvariant/issues/242:123,deployability,releas,release,123,"Hi @ptrebert . Thanks for the suggestion. I have fixed this in our internal version, and the fix will come out in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/242
https://github.com/google/deepvariant/issues/242:76,integrability,version,version,76,"Hi @ptrebert . Thanks for the suggestion. I have fixed this in our internal version, and the fix will come out in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/242
https://github.com/google/deepvariant/issues/242:76,modifiability,version,version,76,"Hi @ptrebert . Thanks for the suggestion. I have fixed this in our internal version, and the fix will come out in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/242
https://github.com/google/deepvariant/issues/243:3246,availability,error,errors,3246,"do docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0.9/scripts/install_nvidia_docker.sh. and. https://github.com/google/deepvariant/blob/r0.9/scripts/install_singularity.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:197,deployability,releas,release,197,"Hi @jguhlin ,. thanks for the feedback, and for letting us know that our users are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSIO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:304,deployability,build,building,304,"Hi @jguhlin ,. thanks for the feedback, and for letting us know that our users are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSIO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:876,deployability,version,version,876,"Hi @jguhlin ,. thanks for the feedback, and for letting us know that our users are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSIO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1022,deployability,build,building,1022,"the feedback, and for letting us know that our users are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvarian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1136,deployability,instal,install,1136," hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1293,deployability,VERSION,VERSION,1293,"nsider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1320,deployability,updat,update,1320,"mg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-g",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1343,deployability,instal,install,1343,"bute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1403,deployability,VERSION,VERSION,1403,"ps://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag go",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1450,deployability,VERSION,VERSION,1450,"ssuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1657,deployability,build,build,1657,"ariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1677,deployability,VERSION,VERSION,1677,"ages/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSIO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1994,deployability,VERSION,VERSION,1994," # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2308,deployability,VERSION,VERSION,2308," apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2372,deployability,VERSION,VERSION,2372," pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2426,deployability,VERSION,VERSION,2426,"oogle/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0.9/scripts/install_nvidia_docker.sh. and. https://gith",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2655,deployability,build,build,2655,"do docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0.9/scripts/install_nvidia_docker.sh. and. https://github.com/google/deepvariant/blob/r0.9/scripts/install_singularity.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2675,deployability,VERSION,VERSION,2675,"do docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0.9/scripts/install_nvidia_docker.sh. and. https://github.com/google/deepvariant/blob/r0.9/scripts/install_singularity.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2888,deployability,VERSION,VERSION,2888,"do docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0.9/scripts/install_nvidia_docker.sh. and. https://github.com/google/deepvariant/blob/r0.9/scripts/install_singularity.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:3200,deployability,version,versions,3200,"do docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0.9/scripts/install_nvidia_docker.sh. and. https://github.com/google/deepvariant/blob/r0.9/scripts/install_singularity.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:3267,deployability,instal,installing,3267,"do docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0.9/scripts/install_nvidia_docker.sh. and. https://github.com/google/deepvariant/blob/r0.9/scripts/install_singularity.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:640,energy efficiency,gpu,gpu,640,"Hi @jguhlin ,. thanks for the feedback, and for letting us know that our users are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSIO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:774,energy efficiency,cloud,cloud,774,"Hi @jguhlin ,. thanks for the feedback, and for letting us know that our users are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSIO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:864,energy efficiency,CPU,CPU,864,"Hi @jguhlin ,. thanks for the feedback, and for letting us know that our users are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSIO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:872,energy efficiency,GPU,GPU,872,"Hi @jguhlin ,. thanks for the feedback, and for letting us know that our users are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSIO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:961,energy efficiency,gpu,gpu,961,"Hi @jguhlin ,. thanks for the feedback, and for letting us know that our users are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSIO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1066,energy efficiency,CPU,CPU,1066," our users are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1074,energy efficiency,GPU,GPU,1074,"rs are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1277,energy efficiency,CPU,CPU,1277,"he future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2292,energy efficiency,GPU,GPU,2292,"ERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker an",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2322,energy efficiency,gpu,gpu,2322,"te && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also re",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:3188,energy efficiency,CPU,CPU,3188,"do docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0.9/scripts/install_nvidia_docker.sh. and. https://github.com/google/deepvariant/blob/r0.9/scripts/install_singularity.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:3196,energy efficiency,GPU,GPU,3196,"do docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0.9/scripts/install_nvidia_docker.sh. and. https://github.com/google/deepvariant/blob/r0.9/scripts/install_singularity.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:876,integrability,version,version,876,"Hi @jguhlin ,. thanks for the feedback, and for letting us know that our users are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSIO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1293,integrability,VERSION,VERSION,1293,"nsider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1403,integrability,VERSION,VERSION,1403,"ps://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag go",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1450,integrability,VERSION,VERSION,1450,"ssuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1677,integrability,VERSION,VERSION,1677,"ages/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSIO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1994,integrability,VERSION,VERSION,1994," # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2308,integrability,VERSION,VERSION,2308," apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2372,integrability,VERSION,VERSION,2372," pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2426,integrability,VERSION,VERSION,2426,"oogle/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0.9/scripts/install_nvidia_docker.sh. and. https://gith",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2675,integrability,VERSION,VERSION,2675,"do docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0.9/scripts/install_nvidia_docker.sh. and. https://github.com/google/deepvariant/blob/r0.9/scripts/install_singularity.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2888,integrability,VERSION,VERSION,2888,"do docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0.9/scripts/install_nvidia_docker.sh. and. https://github.com/google/deepvariant/blob/r0.9/scripts/install_singularity.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:3200,integrability,version,versions,3200,"do docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0.9/scripts/install_nvidia_docker.sh. and. https://github.com/google/deepvariant/blob/r0.9/scripts/install_singularity.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:341,interoperability,distribut,distribute,341,"Hi @jguhlin ,. thanks for the feedback, and for letting us know that our users are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSIO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:525,interoperability,convers,conversion,525,"Hi @jguhlin ,. thanks for the feedback, and for letting us know that our users are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSIO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1550,interoperability,registr,registry,1550,"output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1559,interoperability,registr,registry,1559,"simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2537,interoperability,registr,registry,2537,"do docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0.9/scripts/install_nvidia_docker.sh. and. https://github.com/google/deepvariant/blob/r0.9/scripts/install_singularity.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2546,interoperability,registr,registry,2546,"do docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0.9/scripts/install_nvidia_docker.sh. and. https://github.com/google/deepvariant/blob/r0.9/scripts/install_singularity.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:876,modifiability,version,version,876,"Hi @jguhlin ,. thanks for the feedback, and for letting us know that our users are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSIO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1293,modifiability,VERSION,VERSION,1293,"nsider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1403,modifiability,VERSION,VERSION,1403,"ps://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag go",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1450,modifiability,VERSION,VERSION,1450,"ssuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1677,modifiability,VERSION,VERSION,1677,"ages/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSIO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1994,modifiability,VERSION,VERSION,1994," # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2308,modifiability,VERSION,VERSION,2308," apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2372,modifiability,VERSION,VERSION,2372," pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2426,modifiability,VERSION,VERSION,2426,"oogle/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0.9/scripts/install_nvidia_docker.sh. and. https://gith",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2675,modifiability,VERSION,VERSION,2675,"do docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0.9/scripts/install_nvidia_docker.sh. and. https://github.com/google/deepvariant/blob/r0.9/scripts/install_singularity.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2888,modifiability,VERSION,VERSION,2888,"do docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0.9/scripts/install_nvidia_docker.sh. and. https://github.com/google/deepvariant/blob/r0.9/scripts/install_singularity.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:3200,modifiability,version,versions,3200,"do docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0.9/scripts/install_nvidia_docker.sh. and. https://github.com/google/deepvariant/blob/r0.9/scripts/install_singularity.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:640,performance,gpu,gpu,640,"Hi @jguhlin ,. thanks for the feedback, and for letting us know that our users are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSIO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:864,performance,CPU,CPU,864,"Hi @jguhlin ,. thanks for the feedback, and for letting us know that our users are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSIO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:872,performance,GPU,GPU,872,"Hi @jguhlin ,. thanks for the feedback, and for letting us know that our users are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSIO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:961,performance,gpu,gpu,961,"Hi @jguhlin ,. thanks for the feedback, and for letting us know that our users are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSIO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1066,performance,CPU,CPU,1066," our users are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1074,performance,GPU,GPU,1074,"rs are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1277,performance,CPU,CPU,1277,"he future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2292,performance,GPU,GPU,2292,"ERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker an",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2322,performance,gpu,gpu,2322,"te && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also re",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:3188,performance,CPU,CPU,3188,"do docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0.9/scripts/install_nvidia_docker.sh. and. https://github.com/google/deepvariant/blob/r0.9/scripts/install_singularity.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:3196,performance,GPU,GPU,3196,"do docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0.9/scripts/install_nvidia_docker.sh. and. https://github.com/google/deepvariant/blob/r0.9/scripts/install_singularity.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:3246,performance,error,errors,3246,"do docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0.9/scripts/install_nvidia_docker.sh. and. https://github.com/google/deepvariant/blob/r0.9/scripts/install_singularity.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:854,safety,test,test,854,"Hi @jguhlin ,. thanks for the feedback, and for letting us know that our users are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSIO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1320,safety,updat,update,1320,"mg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-g",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:3246,safety,error,errors,3246,"do docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0.9/scripts/install_nvidia_docker.sh. and. https://github.com/google/deepvariant/blob/r0.9/scripts/install_singularity.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:252,security,control,control,252,"Hi @jguhlin ,. thanks for the feedback, and for letting us know that our users are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSIO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1313,security,apt,apt,1313,"ese *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1320,security,updat,update,1320,"mg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-g",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1335,security,apt,apt-get,1335,"t distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:252,testability,control,control,252,"Hi @jguhlin ,. thanks for the feedback, and for letting us know that our users are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSIO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:854,testability,test,test,854,"Hi @jguhlin ,. thanks for the feedback, and for letting us know that our users are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSIO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:2106,testability,unit,unittest,2106,"ularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,00",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:3000,testability,unit,unittest,3000,"do docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0.9/scripts/install_nvidia_docker.sh. and. https://github.com/google/deepvariant/blob/r0.9/scripts/install_singularity.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:30,usability,feedback,feedback,30,"Hi @jguhlin ,. thanks for the feedback, and for letting us know that our users are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSIO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:73,usability,user,users,73,"Hi @jguhlin ,. thanks for the feedback, and for letting us know that our users are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSIO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:386,usability,document,documented,386,"Hi @jguhlin ,. thanks for the feedback, and for letting us know that our users are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSIO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:497,usability,command,commands,497,"Hi @jguhlin ,. thanks for the feedback, and for letting us know that our users are still interested in Singularity images. I have been a bit hesitated to make Singularity images part of our formal release process, mostly because the additional quality control burden. . But, in the future we'll consider building these *.simg files and just distribute them. The steps below I used were documented here:. https://github.com/google/deepvariant/issues/132#issuecomment-482430728. I have the detailed commands that I used for my conversion, and I copied the output *.simg files here:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Or you can find them in the browser here:. https://console.cloud.google.com/storage/browser/deepvariant/singularity_images/. I was able to test both CPU and GPU version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSIO",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1871,usability,command,command,1871," version on the Quick Start data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1897,usability,command,command,1897,"t data (see below). Can you see if if my `deepvariant-0.9.0-gpu.simg` file works for you? ------. # @pichuan 's notes on building DeepVariant Singularity images for CPU and GPU (v0.9.0). If you don't have singularity on your computer, install it first:. https://sylabs.io/docs/. Once you do, you can pull the DeepVariant Docker image and convert it to a Singularity image. ## CPU image. ```. VERSION=0.9.0. sudo apt -y update && sudo apt-get install -y docker.io. sudo docker pull google/deepvariant:${VERSION}. sudo docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant:latest. sudo docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:3246,usability,error,errors,3246,"do docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo docker push localhost:5000/deepvariant:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant:latest. ```. To run [Quick Start](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md), instead of using the docker command, you can use this command instead:. ```. singularity -s exec -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. ## GPU image. ```. VERSION=0.9.0-gpu. sudo nvidia-docker pull google/deepvariant:${VERSION}. sudo nvidia-docker tag google/deepvariant:${VERSION} localhost:5000/deepvariant_gpu:latest. sudo nvidia-docker run -d -p 5000:5000 --restart=always --name registry registry:2. sudo nvidia-docker push localhost:5000/deepvariant_gpu:latest. SINGULARITY_NOHTTPS=1 singularity build deepvariant-${VERSION}.simg docker://localhost:5000/deepvariant_gpu:latest. ```. Running through Quick Start just to make sure nothing wrong:. ```. singularity -s exec --nv -B /usr/lib/locale/:/usr/lib/locale/ \. deepvariant-${VERSION}.simg \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=${INPUT_DIR}/ucsc.hg19.chr20.unittest.fasta \. --reads=${INPUT_DIR}/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=output.vcf.gz \. --output_gvcf=output.g.vcf.gz . ```. Both CPU and GPU versions finished on Quick Start data without errors. ## Misc. For installing nvidia-docker and singularity, you can also refer to https://github.com/google/deepvariant/blob/r0.9/scripts/install_nvidia_docker.sh. and. https://github.com/google/deepvariant/blob/r0.9/scripts/install_singularity.sh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:352,availability,error,errors,352,"I strongly concur. Singularity images would be nice. Using Docker has already given me multiple diseases. It's such a hassle and from what other colleagues tell me, I am not the only one. . Note that there is nothing wrong with the deepvariant image, it's the Docker process that can cause many problems running, pulling images, restarting, generating errors, etc ... . Like this issue, unresolved since 2017: . https://github.com/docker/for-win/issues/813. Dark Souls bosses are easier to take down than pulling a docker image on some systems. . So to be clear again, nothing wrong at all with deepvariant, which I love more and more btw, but having something else than Docker would be indeed really great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:495,availability,down,down,495,"I strongly concur. Singularity images would be nice. Using Docker has already given me multiple diseases. It's such a hassle and from what other colleagues tell me, I am not the only one. . Note that there is nothing wrong with the deepvariant image, it's the Docker process that can cause many problems running, pulling images, restarting, generating errors, etc ... . Like this issue, unresolved since 2017: . https://github.com/docker/for-win/issues/813. Dark Souls bosses are easier to take down than pulling a docker image on some systems. . So to be clear again, nothing wrong at all with deepvariant, which I love more and more btw, but having something else than Docker would be indeed really great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:352,performance,error,errors,352,"I strongly concur. Singularity images would be nice. Using Docker has already given me multiple diseases. It's such a hassle and from what other colleagues tell me, I am not the only one. . Note that there is nothing wrong with the deepvariant image, it's the Docker process that can cause many problems running, pulling images, restarting, generating errors, etc ... . Like this issue, unresolved since 2017: . https://github.com/docker/for-win/issues/813. Dark Souls bosses are easier to take down than pulling a docker image on some systems. . So to be clear again, nothing wrong at all with deepvariant, which I love more and more btw, but having something else than Docker would be indeed really great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:352,safety,error,errors,352,"I strongly concur. Singularity images would be nice. Using Docker has already given me multiple diseases. It's such a hassle and from what other colleagues tell me, I am not the only one. . Note that there is nothing wrong with the deepvariant image, it's the Docker process that can cause many problems running, pulling images, restarting, generating errors, etc ... . Like this issue, unresolved since 2017: . https://github.com/docker/for-win/issues/813. Dark Souls bosses are easier to take down than pulling a docker image on some systems. . So to be clear again, nothing wrong at all with deepvariant, which I love more and more btw, but having something else than Docker would be indeed really great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:352,usability,error,errors,352,"I strongly concur. Singularity images would be nice. Using Docker has already given me multiple diseases. It's such a hassle and from what other colleagues tell me, I am not the only one. . Note that there is nothing wrong with the deepvariant image, it's the Docker process that can cause many problems running, pulling images, restarting, generating errors, etc ... . Like this issue, unresolved since 2017: . https://github.com/docker/for-win/issues/813. Dark Souls bosses are easier to take down than pulling a docker image on some systems. . So to be clear again, nothing wrong at all with deepvariant, which I love more and more btw, but having something else than Docker would be indeed really great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:556,usability,clear,clear,556,"I strongly concur. Singularity images would be nice. Using Docker has already given me multiple diseases. It's such a hassle and from what other colleagues tell me, I am not the only one. . Note that there is nothing wrong with the deepvariant image, it's the Docker process that can cause many problems running, pulling images, restarting, generating errors, etc ... . Like this issue, unresolved since 2017: . https://github.com/docker/for-win/issues/813. Dark Souls bosses are easier to take down than pulling a docker image on some systems. . So to be clear again, nothing wrong at all with deepvariant, which I love more and more btw, but having something else than Docker would be indeed really great.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:159,energy efficiency,gpu,gpu,159,"Hi @aderzelle . thanks for your feedback. If you have a chance to try out the two images I shared:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Please let me know whether they work for you or not. If you see any issues, please let us know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:91,interoperability,share,shared,91,"Hi @aderzelle . thanks for your feedback. If you have a chance to try out the two images I shared:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Please let me know whether they work for you or not. If you see any issues, please let us know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:159,performance,gpu,gpu,159,"Hi @aderzelle . thanks for your feedback. If you have a chance to try out the two images I shared:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Please let me know whether they work for you or not. If you see any issues, please let us know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:32,usability,feedback,feedback,32,"Hi @aderzelle . thanks for your feedback. If you have a chance to try out the two images I shared:. ```. gs://deepvariant/singularity_images/deepvariant-0.9.0-gpu.simg. gs://deepvariant/singularity_images/deepvariant-0.9.0.simg. ```. Please let me know whether they work for you or not. If you see any issues, please let us know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:44,deployability,contain,container,44,"Hi @pichuan. It looks like this singularity container works well, thanks. A singularity container would be great, although possibly figuring out what's wrong with the docker conversion might be the way to go (it could be something on my end as well). Docker is being phased out at some research institutions due to its reliance on the root user, so singularity is where we are at. But the conversion usually just works. Now to figure why training with deepvariant is only producing refcalls.....",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:88,deployability,contain,container,88,"Hi @pichuan. It looks like this singularity container works well, thanks. A singularity container would be great, although possibly figuring out what's wrong with the docker conversion might be the way to go (it could be something on my end as well). Docker is being phased out at some research institutions due to its reliance on the root user, so singularity is where we are at. But the conversion usually just works. Now to figure why training with deepvariant is only producing refcalls.....",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:174,interoperability,convers,conversion,174,"Hi @pichuan. It looks like this singularity container works well, thanks. A singularity container would be great, although possibly figuring out what's wrong with the docker conversion might be the way to go (it could be something on my end as well). Docker is being phased out at some research institutions due to its reliance on the root user, so singularity is where we are at. But the conversion usually just works. Now to figure why training with deepvariant is only producing refcalls.....",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:389,interoperability,convers,conversion,389,"Hi @pichuan. It looks like this singularity container works well, thanks. A singularity container would be great, although possibly figuring out what's wrong with the docker conversion might be the way to go (it could be something on my end as well). Docker is being phased out at some research institutions due to its reliance on the root user, so singularity is where we are at. But the conversion usually just works. Now to figure why training with deepvariant is only producing refcalls.....",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:340,usability,user,user,340,"Hi @pichuan. It looks like this singularity container works well, thanks. A singularity container would be great, although possibly figuring out what's wrong with the docker conversion might be the way to go (it could be something on my end as well). Docker is being phased out at some research institutions due to its reliance on the root user, so singularity is where we are at. But the conversion usually just works. Now to figure why training with deepvariant is only producing refcalls.....",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:30,deployability,releas,release,30,Thanks @jguhlin . In the next release we'll plan to include the converted version in the same GCS bucket.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:74,deployability,version,version,74,Thanks @jguhlin . In the next release we'll plan to include the converted version in the same GCS bucket.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:74,integrability,version,version,74,Thanks @jguhlin . In the next release we'll plan to include the converted version in the same GCS bucket.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:74,modifiability,version,version,74,Thanks @jguhlin . In the next release we'll plan to include the converted version in the same GCS bucket.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:44,testability,plan,plan,44,Thanks @jguhlin . In the next release we'll plan to include the converted version in the same GCS bucket.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:91,availability,cluster,cluster,91,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:163,availability,error,errors,163,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:91,deployability,cluster,cluster,91,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1038,deployability,log,login,1038,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1311,deployability,modul,module,1311,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1359,deployability,modul,module,1359,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1433,deployability,fail,failed,1433,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1481,deployability,fail,failed,1481,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1579,deployability,fail,failed,1579,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1024,energy efficiency,Power,Power,1024,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1410,energy efficiency,core,core,1410,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1470,energy efficiency,core,core,1470,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1551,energy efficiency,core,core,1551,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:395,integrability,buffer,buffer,395,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:948,integrability,pub,publication,948,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1311,modifiability,modul,module,1311,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1359,modifiability,modul,module,1359,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:163,performance,error,errors,163,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:361,performance,time,time,361,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:376,performance,parallel,parallel,376,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:919,performance,Parallel,Parallel,919,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:996,performance,Parallel,Parallel,996,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1210,performance,Parallel,Parallel,1210,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1273,performance,parallel,parallel,1273,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1433,reliability,fail,failed,1433,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1481,reliability,fail,failed,1481,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1579,reliability,fail,failed,1579,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:64,safety,test,tested,64,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:106,safety,test,test,106,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:163,safety,error,errors,163,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:481,safety,test,test,481,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:503,safety,test,testdata,503,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:575,safety,test,test,575,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:597,safety,test,testdata,597,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1038,safety,log,login,1038,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1311,safety,modul,module,1311,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1359,safety,modul,module,1359,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1011,security,Command-Lin,Command-Line,1011,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1038,security,log,login,1038,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:64,testability,test,tested,64,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:106,testability,test,test,106,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:481,testability,test,test,481,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:503,testability,test,testdata,503,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:528,testability,unit,unittest,528,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:575,testability,test,test,575,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:597,testability,test,testdata,597,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1038,testability,log,login,1038,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:163,usability,error,errors,163,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:308,usability,help,help,308,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:346,usability,command,command,346,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1011,usability,Command,Command-Line,1011,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1030,usability,Tool,Tool,1030,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1092,usability,help,helps,1092,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:1639,usability,user,user,1639,"Hi @pichuan,. Thank you for posting these Singularity images. I tested them on a computing cluster on the test data, following the instructions above and ran into errors similar to those posted in another issue, below. I'm wondering if you have any suggestions for workarounds? Thank you in advance for your help! . Best,. ```. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/ucsc.hg19.chr20.unittest.fasta"" --reads ""/labs/jandr/walter/tb/test/deepV/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. Academic tradition requires you to cite works you base your article on. When using programs that use GNU Parallel to process data for publication. please cite:. O. Tange (2011): GNU Parallel - The Command-Line Power Tool,. ;login: The USENIX Magazine, February 2011:42-47. This helps funding further development; AND IT WON'T COST YOU A CENT. If you pay 10000 EUR you should feel free to use GNU Parallel without citing. To silence this citation notice: run 'parallel --citation'. ImportError: No module named _multiarray_umath. ImportError: No module named _multiarray_umath. ImportError: numpy.core._multiarray_umath failed to import. ImportError: numpy.core.umath failed to import. 2020-01-28 19:06:29.164168: F tensorflow/python/lib/core/bfloat16.cc:675] Check failed: PyBfloat16_Type.tp_base != nullptr . real	0m4.153s. user	0m0.699s. sys	0m1.614s. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:8,testability,plan,plan,8,"FYI:. I plan to remove the gs://deepvariant/singularity_images directory , and suggest our users to directly pull from our Docker image instead. Example:. ```. BIN_VERSION=""1.0.0"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/243:91,usability,user,users,91,"FYI:. I plan to remove the gs://deepvariant/singularity_images directory , and suggest our users to directly pull from our Docker image instead. Example:. ```. BIN_VERSION=""1.0.0"". singularity pull docker://google/deepvariant:""${BIN_VERSION}"". ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/243
https://github.com/google/deepvariant/issues/247:658,availability,down,downstream,658,"This question is complex enough that it cuts to some of the fundamental issues of VCF. I expect that across the community, opinions will differ as to whether this represents troubling inconsistency as opposed to a strange edge case. The heart of this question is whether people will tend to interpret a 0/1 as ""I have evidence for a reference allele and evidence for the 1st alternate allele"" or as ""I have evidence for one copy of the ALT allele but for one non-REF position"". This could be fully expressed with REF: CATTA || ALT: C, CAGTA || GT: 1/2. I expect that the majority of programs don't do this sort of normalization, and I expect the majority of downstream tools operate in a way that doesn't assume that the two lines you post introduce inconsistency (that is most probably assume ""REF"" more like ""Evidence for at least one copy that is non-ALT, other lines may clarify if an additional non-REF allele is present). However, if you want to dig into this question further, I would encourage you to ask on one of the GA4GH forums about variant representations. I don't consider myself knowledgable enough to give definitive statements on edge cases like this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:675,availability,operat,operate,675,"This question is complex enough that it cuts to some of the fundamental issues of VCF. I expect that across the community, opinions will differ as to whether this represents troubling inconsistency as opposed to a strange edge case. The heart of this question is whether people will tend to interpret a 0/1 as ""I have evidence for a reference allele and evidence for the 1st alternate allele"" or as ""I have evidence for one copy of the ALT allele but for one non-REF position"". This could be fully expressed with REF: CATTA || ALT: C, CAGTA || GT: 1/2. I expect that the majority of programs don't do this sort of normalization, and I expect the majority of downstream tools operate in a way that doesn't assume that the two lines you post introduce inconsistency (that is most probably assume ""REF"" more like ""Evidence for at least one copy that is non-ALT, other lines may clarify if an additional non-REF allele is present). However, if you want to dig into this question further, I would encourage you to ask on one of the GA4GH forums about variant representations. I don't consider myself knowledgable enough to give definitive statements on edge cases like this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:1134,availability,state,statements,1134,"This question is complex enough that it cuts to some of the fundamental issues of VCF. I expect that across the community, opinions will differ as to whether this represents troubling inconsistency as opposed to a strange edge case. The heart of this question is whether people will tend to interpret a 0/1 as ""I have evidence for a reference allele and evidence for the 1st alternate allele"" or as ""I have evidence for one copy of the ALT allele but for one non-REF position"". This could be fully expressed with REF: CATTA || ALT: C, CAGTA || GT: 1/2. I expect that the majority of programs don't do this sort of normalization, and I expect the majority of downstream tools operate in a way that doesn't assume that the two lines you post introduce inconsistency (that is most probably assume ""REF"" more like ""Evidence for at least one copy that is non-ALT, other lines may clarify if an additional non-REF allele is present). However, if you want to dig into this question further, I would encourage you to ask on one of the GA4GH forums about variant representations. I don't consider myself knowledgable enough to give definitive statements on edge cases like this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:1134,integrability,state,statements,1134,"This question is complex enough that it cuts to some of the fundamental issues of VCF. I expect that across the community, opinions will differ as to whether this represents troubling inconsistency as opposed to a strange edge case. The heart of this question is whether people will tend to interpret a 0/1 as ""I have evidence for a reference allele and evidence for the 1st alternate allele"" or as ""I have evidence for one copy of the ALT allele but for one non-REF position"". This could be fully expressed with REF: CATTA || ALT: C, CAGTA || GT: 1/2. I expect that the majority of programs don't do this sort of normalization, and I expect the majority of downstream tools operate in a way that doesn't assume that the two lines you post introduce inconsistency (that is most probably assume ""REF"" more like ""Evidence for at least one copy that is non-ALT, other lines may clarify if an additional non-REF allele is present). However, if you want to dig into this question further, I would encourage you to ask on one of the GA4GH forums about variant representations. I don't consider myself knowledgable enough to give definitive statements on edge cases like this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:697,reliability,doe,doesn,697,"This question is complex enough that it cuts to some of the fundamental issues of VCF. I expect that across the community, opinions will differ as to whether this represents troubling inconsistency as opposed to a strange edge case. The heart of this question is whether people will tend to interpret a 0/1 as ""I have evidence for a reference allele and evidence for the 1st alternate allele"" or as ""I have evidence for one copy of the ALT allele but for one non-REF position"". This could be fully expressed with REF: CATTA || ALT: C, CAGTA || GT: 1/2. I expect that the majority of programs don't do this sort of normalization, and I expect the majority of downstream tools operate in a way that doesn't assume that the two lines you post introduce inconsistency (that is most probably assume ""REF"" more like ""Evidence for at least one copy that is non-ALT, other lines may clarify if an additional non-REF allele is present). However, if you want to dig into this question further, I would encourage you to ask on one of the GA4GH forums about variant representations. I don't consider myself knowledgable enough to give definitive statements on edge cases like this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:17,safety,compl,complex,17,"This question is complex enough that it cuts to some of the fundamental issues of VCF. I expect that across the community, opinions will differ as to whether this represents troubling inconsistency as opposed to a strange edge case. The heart of this question is whether people will tend to interpret a 0/1 as ""I have evidence for a reference allele and evidence for the 1st alternate allele"" or as ""I have evidence for one copy of the ALT allele but for one non-REF position"". This could be fully expressed with REF: CATTA || ALT: C, CAGTA || GT: 1/2. I expect that the majority of programs don't do this sort of normalization, and I expect the majority of downstream tools operate in a way that doesn't assume that the two lines you post introduce inconsistency (that is most probably assume ""REF"" more like ""Evidence for at least one copy that is non-ALT, other lines may clarify if an additional non-REF allele is present). However, if you want to dig into this question further, I would encourage you to ask on one of the GA4GH forums about variant representations. I don't consider myself knowledgable enough to give definitive statements on edge cases like this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:17,security,compl,complex,17,"This question is complex enough that it cuts to some of the fundamental issues of VCF. I expect that across the community, opinions will differ as to whether this represents troubling inconsistency as opposed to a strange edge case. The heart of this question is whether people will tend to interpret a 0/1 as ""I have evidence for a reference allele and evidence for the 1st alternate allele"" or as ""I have evidence for one copy of the ALT allele but for one non-REF position"". This could be fully expressed with REF: CATTA || ALT: C, CAGTA || GT: 1/2. I expect that the majority of programs don't do this sort of normalization, and I expect the majority of downstream tools operate in a way that doesn't assume that the two lines you post introduce inconsistency (that is most probably assume ""REF"" more like ""Evidence for at least one copy that is non-ALT, other lines may clarify if an additional non-REF allele is present). However, if you want to dig into this question further, I would encourage you to ask on one of the GA4GH forums about variant representations. I don't consider myself knowledgable enough to give definitive statements on edge cases like this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:669,usability,tool,tools,669,"This question is complex enough that it cuts to some of the fundamental issues of VCF. I expect that across the community, opinions will differ as to whether this represents troubling inconsistency as opposed to a strange edge case. The heart of this question is whether people will tend to interpret a 0/1 as ""I have evidence for a reference allele and evidence for the 1st alternate allele"" or as ""I have evidence for one copy of the ALT allele but for one non-REF position"". This could be fully expressed with REF: CATTA || ALT: C, CAGTA || GT: 1/2. I expect that the majority of programs don't do this sort of normalization, and I expect the majority of downstream tools operate in a way that doesn't assume that the two lines you post introduce inconsistency (that is most probably assume ""REF"" more like ""Evidence for at least one copy that is non-ALT, other lines may clarify if an additional non-REF allele is present). However, if you want to dig into this question further, I would encourage you to ask on one of the GA4GH forums about variant representations. I don't consider myself knowledgable enough to give definitive statements on edge cases like this.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:176,availability,down,downstream,176,"I guess the core question for the variant caller is, (whether or not fully normalized as you have written) whether the raw calls can be interpreted without contradictions by a downstream method (notwithstanding the VCF standard). Considering GT=0 to be ""non-ALT"" instead of ""REF allele"" for such call clusters does seem to work in these cases (though I am not aware of a standardization of such an interpretation). The code I have referenced from DeepVariant above seems to try to filter out cases that do not make sense for such clusters of calls, so a downstream method that assumes GT=0 to imply ""non-ALT"" might work smoothly almost all the time (except perhaps when the algorithm aborts). I also didn't have an idea as to whether, as a method developer, you considered these to be corner cases, and your comment above has provided an answer to that. I myself do not have any measurements on how prevalent these types of cases are, but I encountered some of these cases recently. I will make another post here if I learn anything further about this, but I understand the point-of-view behind the original piece of code that I posted. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:301,availability,cluster,clusters,301,"I guess the core question for the variant caller is, (whether or not fully normalized as you have written) whether the raw calls can be interpreted without contradictions by a downstream method (notwithstanding the VCF standard). Considering GT=0 to be ""non-ALT"" instead of ""REF allele"" for such call clusters does seem to work in these cases (though I am not aware of a standardization of such an interpretation). The code I have referenced from DeepVariant above seems to try to filter out cases that do not make sense for such clusters of calls, so a downstream method that assumes GT=0 to imply ""non-ALT"" might work smoothly almost all the time (except perhaps when the algorithm aborts). I also didn't have an idea as to whether, as a method developer, you considered these to be corner cases, and your comment above has provided an answer to that. I myself do not have any measurements on how prevalent these types of cases are, but I encountered some of these cases recently. I will make another post here if I learn anything further about this, but I understand the point-of-view behind the original piece of code that I posted. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:530,availability,cluster,clusters,530,"I guess the core question for the variant caller is, (whether or not fully normalized as you have written) whether the raw calls can be interpreted without contradictions by a downstream method (notwithstanding the VCF standard). Considering GT=0 to be ""non-ALT"" instead of ""REF allele"" for such call clusters does seem to work in these cases (though I am not aware of a standardization of such an interpretation). The code I have referenced from DeepVariant above seems to try to filter out cases that do not make sense for such clusters of calls, so a downstream method that assumes GT=0 to imply ""non-ALT"" might work smoothly almost all the time (except perhaps when the algorithm aborts). I also didn't have an idea as to whether, as a method developer, you considered these to be corner cases, and your comment above has provided an answer to that. I myself do not have any measurements on how prevalent these types of cases are, but I encountered some of these cases recently. I will make another post here if I learn anything further about this, but I understand the point-of-view behind the original piece of code that I posted. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:554,availability,down,downstream,554,"I guess the core question for the variant caller is, (whether or not fully normalized as you have written) whether the raw calls can be interpreted without contradictions by a downstream method (notwithstanding the VCF standard). Considering GT=0 to be ""non-ALT"" instead of ""REF allele"" for such call clusters does seem to work in these cases (though I am not aware of a standardization of such an interpretation). The code I have referenced from DeepVariant above seems to try to filter out cases that do not make sense for such clusters of calls, so a downstream method that assumes GT=0 to imply ""non-ALT"" might work smoothly almost all the time (except perhaps when the algorithm aborts). I also didn't have an idea as to whether, as a method developer, you considered these to be corner cases, and your comment above has provided an answer to that. I myself do not have any measurements on how prevalent these types of cases are, but I encountered some of these cases recently. I will make another post here if I learn anything further about this, but I understand the point-of-view behind the original piece of code that I posted. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:301,deployability,cluster,clusters,301,"I guess the core question for the variant caller is, (whether or not fully normalized as you have written) whether the raw calls can be interpreted without contradictions by a downstream method (notwithstanding the VCF standard). Considering GT=0 to be ""non-ALT"" instead of ""REF allele"" for such call clusters does seem to work in these cases (though I am not aware of a standardization of such an interpretation). The code I have referenced from DeepVariant above seems to try to filter out cases that do not make sense for such clusters of calls, so a downstream method that assumes GT=0 to imply ""non-ALT"" might work smoothly almost all the time (except perhaps when the algorithm aborts). I also didn't have an idea as to whether, as a method developer, you considered these to be corner cases, and your comment above has provided an answer to that. I myself do not have any measurements on how prevalent these types of cases are, but I encountered some of these cases recently. I will make another post here if I learn anything further about this, but I understand the point-of-view behind the original piece of code that I posted. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:530,deployability,cluster,clusters,530,"I guess the core question for the variant caller is, (whether or not fully normalized as you have written) whether the raw calls can be interpreted without contradictions by a downstream method (notwithstanding the VCF standard). Considering GT=0 to be ""non-ALT"" instead of ""REF allele"" for such call clusters does seem to work in these cases (though I am not aware of a standardization of such an interpretation). The code I have referenced from DeepVariant above seems to try to filter out cases that do not make sense for such clusters of calls, so a downstream method that assumes GT=0 to imply ""non-ALT"" might work smoothly almost all the time (except perhaps when the algorithm aborts). I also didn't have an idea as to whether, as a method developer, you considered these to be corner cases, and your comment above has provided an answer to that. I myself do not have any measurements on how prevalent these types of cases are, but I encountered some of these cases recently. I will make another post here if I learn anything further about this, but I understand the point-of-view behind the original piece of code that I posted. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:12,energy efficiency,core,core,12,"I guess the core question for the variant caller is, (whether or not fully normalized as you have written) whether the raw calls can be interpreted without contradictions by a downstream method (notwithstanding the VCF standard). Considering GT=0 to be ""non-ALT"" instead of ""REF allele"" for such call clusters does seem to work in these cases (though I am not aware of a standardization of such an interpretation). The code I have referenced from DeepVariant above seems to try to filter out cases that do not make sense for such clusters of calls, so a downstream method that assumes GT=0 to imply ""non-ALT"" might work smoothly almost all the time (except perhaps when the algorithm aborts). I also didn't have an idea as to whether, as a method developer, you considered these to be corner cases, and your comment above has provided an answer to that. I myself do not have any measurements on how prevalent these types of cases are, but I encountered some of these cases recently. I will make another post here if I learn anything further about this, but I understand the point-of-view behind the original piece of code that I posted. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:879,energy efficiency,measur,measurements,879,"I guess the core question for the variant caller is, (whether or not fully normalized as you have written) whether the raw calls can be interpreted without contradictions by a downstream method (notwithstanding the VCF standard). Considering GT=0 to be ""non-ALT"" instead of ""REF allele"" for such call clusters does seem to work in these cases (though I am not aware of a standardization of such an interpretation). The code I have referenced from DeepVariant above seems to try to filter out cases that do not make sense for such clusters of calls, so a downstream method that assumes GT=0 to imply ""non-ALT"" might work smoothly almost all the time (except perhaps when the algorithm aborts). I also didn't have an idea as to whether, as a method developer, you considered these to be corner cases, and your comment above has provided an answer to that. I myself do not have any measurements on how prevalent these types of cases are, but I encountered some of these cases recently. I will make another post here if I learn anything further about this, but I understand the point-of-view behind the original piece of code that I posted. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:371,integrability,standardiz,standardization,371,"I guess the core question for the variant caller is, (whether or not fully normalized as you have written) whether the raw calls can be interpreted without contradictions by a downstream method (notwithstanding the VCF standard). Considering GT=0 to be ""non-ALT"" instead of ""REF allele"" for such call clusters does seem to work in these cases (though I am not aware of a standardization of such an interpretation). The code I have referenced from DeepVariant above seems to try to filter out cases that do not make sense for such clusters of calls, so a downstream method that assumes GT=0 to imply ""non-ALT"" might work smoothly almost all the time (except perhaps when the algorithm aborts). I also didn't have an idea as to whether, as a method developer, you considered these to be corner cases, and your comment above has provided an answer to that. I myself do not have any measurements on how prevalent these types of cases are, but I encountered some of these cases recently. I will make another post here if I learn anything further about this, but I understand the point-of-view behind the original piece of code that I posted. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:481,integrability,filter,filter,481,"I guess the core question for the variant caller is, (whether or not fully normalized as you have written) whether the raw calls can be interpreted without contradictions by a downstream method (notwithstanding the VCF standard). Considering GT=0 to be ""non-ALT"" instead of ""REF allele"" for such call clusters does seem to work in these cases (though I am not aware of a standardization of such an interpretation). The code I have referenced from DeepVariant above seems to try to filter out cases that do not make sense for such clusters of calls, so a downstream method that assumes GT=0 to imply ""non-ALT"" might work smoothly almost all the time (except perhaps when the algorithm aborts). I also didn't have an idea as to whether, as a method developer, you considered these to be corner cases, and your comment above has provided an answer to that. I myself do not have any measurements on how prevalent these types of cases are, but I encountered some of these cases recently. I will make another post here if I learn anything further about this, but I understand the point-of-view behind the original piece of code that I posted. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:219,interoperability,standard,standard,219,"I guess the core question for the variant caller is, (whether or not fully normalized as you have written) whether the raw calls can be interpreted without contradictions by a downstream method (notwithstanding the VCF standard). Considering GT=0 to be ""non-ALT"" instead of ""REF allele"" for such call clusters does seem to work in these cases (though I am not aware of a standardization of such an interpretation). The code I have referenced from DeepVariant above seems to try to filter out cases that do not make sense for such clusters of calls, so a downstream method that assumes GT=0 to imply ""non-ALT"" might work smoothly almost all the time (except perhaps when the algorithm aborts). I also didn't have an idea as to whether, as a method developer, you considered these to be corner cases, and your comment above has provided an answer to that. I myself do not have any measurements on how prevalent these types of cases are, but I encountered some of these cases recently. I will make another post here if I learn anything further about this, but I understand the point-of-view behind the original piece of code that I posted. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:371,interoperability,standard,standardization,371,"I guess the core question for the variant caller is, (whether or not fully normalized as you have written) whether the raw calls can be interpreted without contradictions by a downstream method (notwithstanding the VCF standard). Considering GT=0 to be ""non-ALT"" instead of ""REF allele"" for such call clusters does seem to work in these cases (though I am not aware of a standardization of such an interpretation). The code I have referenced from DeepVariant above seems to try to filter out cases that do not make sense for such clusters of calls, so a downstream method that assumes GT=0 to imply ""non-ALT"" might work smoothly almost all the time (except perhaps when the algorithm aborts). I also didn't have an idea as to whether, as a method developer, you considered these to be corner cases, and your comment above has provided an answer to that. I myself do not have any measurements on how prevalent these types of cases are, but I encountered some of these cases recently. I will make another post here if I learn anything further about this, but I understand the point-of-view behind the original piece of code that I posted. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:644,performance,time,time,644,"I guess the core question for the variant caller is, (whether or not fully normalized as you have written) whether the raw calls can be interpreted without contradictions by a downstream method (notwithstanding the VCF standard). Considering GT=0 to be ""non-ALT"" instead of ""REF allele"" for such call clusters does seem to work in these cases (though I am not aware of a standardization of such an interpretation). The code I have referenced from DeepVariant above seems to try to filter out cases that do not make sense for such clusters of calls, so a downstream method that assumes GT=0 to imply ""non-ALT"" might work smoothly almost all the time (except perhaps when the algorithm aborts). I also didn't have an idea as to whether, as a method developer, you considered these to be corner cases, and your comment above has provided an answer to that. I myself do not have any measurements on how prevalent these types of cases are, but I encountered some of these cases recently. I will make another post here if I learn anything further about this, but I understand the point-of-view behind the original piece of code that I posted. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:310,reliability,doe,does,310,"I guess the core question for the variant caller is, (whether or not fully normalized as you have written) whether the raw calls can be interpreted without contradictions by a downstream method (notwithstanding the VCF standard). Considering GT=0 to be ""non-ALT"" instead of ""REF allele"" for such call clusters does seem to work in these cases (though I am not aware of a standardization of such an interpretation). The code I have referenced from DeepVariant above seems to try to filter out cases that do not make sense for such clusters of calls, so a downstream method that assumes GT=0 to imply ""non-ALT"" might work smoothly almost all the time (except perhaps when the algorithm aborts). I also didn't have an idea as to whether, as a method developer, you considered these to be corner cases, and your comment above has provided an answer to that. I myself do not have any measurements on how prevalent these types of cases are, but I encountered some of these cases recently. I will make another post here if I learn anything further about this, but I understand the point-of-view behind the original piece of code that I posted. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:650,safety,except,except,650,"I guess the core question for the variant caller is, (whether or not fully normalized as you have written) whether the raw calls can be interpreted without contradictions by a downstream method (notwithstanding the VCF standard). Considering GT=0 to be ""non-ALT"" instead of ""REF allele"" for such call clusters does seem to work in these cases (though I am not aware of a standardization of such an interpretation). The code I have referenced from DeepVariant above seems to try to filter out cases that do not make sense for such clusters of calls, so a downstream method that assumes GT=0 to imply ""non-ALT"" might work smoothly almost all the time (except perhaps when the algorithm aborts). I also didn't have an idea as to whether, as a method developer, you considered these to be corner cases, and your comment above has provided an answer to that. I myself do not have any measurements on how prevalent these types of cases are, but I encountered some of these cases recently. I will make another post here if I learn anything further about this, but I understand the point-of-view behind the original piece of code that I posted. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:1059,testability,understand,understand,1059,"I guess the core question for the variant caller is, (whether or not fully normalized as you have written) whether the raw calls can be interpreted without contradictions by a downstream method (notwithstanding the VCF standard). Considering GT=0 to be ""non-ALT"" instead of ""REF allele"" for such call clusters does seem to work in these cases (though I am not aware of a standardization of such an interpretation). The code I have referenced from DeepVariant above seems to try to filter out cases that do not make sense for such clusters of calls, so a downstream method that assumes GT=0 to imply ""non-ALT"" might work smoothly almost all the time (except perhaps when the algorithm aborts). I also didn't have an idea as to whether, as a method developer, you considered these to be corner cases, and your comment above has provided an answer to that. I myself do not have any measurements on how prevalent these types of cases are, but I encountered some of these cases recently. I will make another post here if I learn anything further about this, but I understand the point-of-view behind the original piece of code that I posted. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:1018,usability,learn,learn,1018,"I guess the core question for the variant caller is, (whether or not fully normalized as you have written) whether the raw calls can be interpreted without contradictions by a downstream method (notwithstanding the VCF standard). Considering GT=0 to be ""non-ALT"" instead of ""REF allele"" for such call clusters does seem to work in these cases (though I am not aware of a standardization of such an interpretation). The code I have referenced from DeepVariant above seems to try to filter out cases that do not make sense for such clusters of calls, so a downstream method that assumes GT=0 to imply ""non-ALT"" might work smoothly almost all the time (except perhaps when the algorithm aborts). I also didn't have an idea as to whether, as a method developer, you considered these to be corner cases, and your comment above has provided an answer to that. I myself do not have any measurements on how prevalent these types of cases are, but I encountered some of these cases recently. I will make another post here if I learn anything further about this, but I understand the point-of-view behind the original piece of code that I posted. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:851,availability,sli,slightly,851,"Hi @anands-repo,. Thanks for the question. You are correct that in these cases we are semantically treating GT=0 to be ""non-ALT""; the goal of the haplotypes.py library is to try to resolve cases where the raw calls indicate more than two alternate alleles at a single base pair. This can occur because DeepVariant processes each candidate variant independently, and sometimes candidates overlap the same stretch of the reference genome. As you observed in the code, the haplotypes.py library is even still just a ""best effort"" and there are cases where > 2 alternate alleles will still be emitted by the algorithm. Regarding your prevalence comment, empirically on the Genome in a Bottle HG002 sample we observed this library reduce the number of regions with > 2 alternate alleles from ~3000 to ~300 when it was first introduced. (The numbers may be slightly different now due to subsequent improvements in variant discovery and calling). regards,. Cory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:444,deployability,observ,observed,444,"Hi @anands-repo,. Thanks for the question. You are correct that in these cases we are semantically treating GT=0 to be ""non-ALT""; the goal of the haplotypes.py library is to try to resolve cases where the raw calls indicate more than two alternate alleles at a single base pair. This can occur because DeepVariant processes each candidate variant independently, and sometimes candidates overlap the same stretch of the reference genome. As you observed in the code, the haplotypes.py library is even still just a ""best effort"" and there are cases where > 2 alternate alleles will still be emitted by the algorithm. Regarding your prevalence comment, empirically on the Genome in a Bottle HG002 sample we observed this library reduce the number of regions with > 2 alternate alleles from ~3000 to ~300 when it was first introduced. (The numbers may be slightly different now due to subsequent improvements in variant discovery and calling). regards,. Cory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:704,deployability,observ,observed,704,"Hi @anands-repo,. Thanks for the question. You are correct that in these cases we are semantically treating GT=0 to be ""non-ALT""; the goal of the haplotypes.py library is to try to resolve cases where the raw calls indicate more than two alternate alleles at a single base pair. This can occur because DeepVariant processes each candidate variant independently, and sometimes candidates overlap the same stretch of the reference genome. As you observed in the code, the haplotypes.py library is even still just a ""best effort"" and there are cases where > 2 alternate alleles will still be emitted by the algorithm. Regarding your prevalence comment, empirically on the Genome in a Bottle HG002 sample we observed this library reduce the number of regions with > 2 alternate alleles from ~3000 to ~300 when it was first introduced. (The numbers may be slightly different now due to subsequent improvements in variant discovery and calling). regards,. Cory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:726,energy efficiency,reduc,reduce,726,"Hi @anands-repo,. Thanks for the question. You are correct that in these cases we are semantically treating GT=0 to be ""non-ALT""; the goal of the haplotypes.py library is to try to resolve cases where the raw calls indicate more than two alternate alleles at a single base pair. This can occur because DeepVariant processes each candidate variant independently, and sometimes candidates overlap the same stretch of the reference genome. As you observed in the code, the haplotypes.py library is even still just a ""best effort"" and there are cases where > 2 alternate alleles will still be emitted by the algorithm. Regarding your prevalence comment, empirically on the Genome in a Bottle HG002 sample we observed this library reduce the number of regions with > 2 alternate alleles from ~3000 to ~300 when it was first introduced. (The numbers may be slightly different now due to subsequent improvements in variant discovery and calling). regards,. Cory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:881,integrability,sub,subsequent,881,"Hi @anands-repo,. Thanks for the question. You are correct that in these cases we are semantically treating GT=0 to be ""non-ALT""; the goal of the haplotypes.py library is to try to resolve cases where the raw calls indicate more than two alternate alleles at a single base pair. This can occur because DeepVariant processes each candidate variant independently, and sometimes candidates overlap the same stretch of the reference genome. As you observed in the code, the haplotypes.py library is even still just a ""best effort"" and there are cases where > 2 alternate alleles will still be emitted by the algorithm. Regarding your prevalence comment, empirically on the Genome in a Bottle HG002 sample we observed this library reduce the number of regions with > 2 alternate alleles from ~3000 to ~300 when it was first introduced. (The numbers may be slightly different now due to subsequent improvements in variant discovery and calling). regards,. Cory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:916,integrability,discover,discovery,916,"Hi @anands-repo,. Thanks for the question. You are correct that in these cases we are semantically treating GT=0 to be ""non-ALT""; the goal of the haplotypes.py library is to try to resolve cases where the raw calls indicate more than two alternate alleles at a single base pair. This can occur because DeepVariant processes each candidate variant independently, and sometimes candidates overlap the same stretch of the reference genome. As you observed in the code, the haplotypes.py library is even still just a ""best effort"" and there are cases where > 2 alternate alleles will still be emitted by the algorithm. Regarding your prevalence comment, empirically on the Genome in a Bottle HG002 sample we observed this library reduce the number of regions with > 2 alternate alleles from ~3000 to ~300 when it was first introduced. (The numbers may be slightly different now due to subsequent improvements in variant discovery and calling). regards,. Cory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:86,interoperability,semant,semantically,86,"Hi @anands-repo,. Thanks for the question. You are correct that in these cases we are semantically treating GT=0 to be ""non-ALT""; the goal of the haplotypes.py library is to try to resolve cases where the raw calls indicate more than two alternate alleles at a single base pair. This can occur because DeepVariant processes each candidate variant independently, and sometimes candidates overlap the same stretch of the reference genome. As you observed in the code, the haplotypes.py library is even still just a ""best effort"" and there are cases where > 2 alternate alleles will still be emitted by the algorithm. Regarding your prevalence comment, empirically on the Genome in a Bottle HG002 sample we observed this library reduce the number of regions with > 2 alternate alleles from ~3000 to ~300 when it was first introduced. (The numbers may be slightly different now due to subsequent improvements in variant discovery and calling). regards,. Cory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:916,interoperability,discover,discovery,916,"Hi @anands-repo,. Thanks for the question. You are correct that in these cases we are semantically treating GT=0 to be ""non-ALT""; the goal of the haplotypes.py library is to try to resolve cases where the raw calls indicate more than two alternate alleles at a single base pair. This can occur because DeepVariant processes each candidate variant independently, and sometimes candidates overlap the same stretch of the reference genome. As you observed in the code, the haplotypes.py library is even still just a ""best effort"" and there are cases where > 2 alternate alleles will still be emitted by the algorithm. Regarding your prevalence comment, empirically on the Genome in a Bottle HG002 sample we observed this library reduce the number of regions with > 2 alternate alleles from ~3000 to ~300 when it was first introduced. (The numbers may be slightly different now due to subsequent improvements in variant discovery and calling). regards,. Cory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:851,reliability,sli,slightly,851,"Hi @anands-repo,. Thanks for the question. You are correct that in these cases we are semantically treating GT=0 to be ""non-ALT""; the goal of the haplotypes.py library is to try to resolve cases where the raw calls indicate more than two alternate alleles at a single base pair. This can occur because DeepVariant processes each candidate variant independently, and sometimes candidates overlap the same stretch of the reference genome. As you observed in the code, the haplotypes.py library is even still just a ""best effort"" and there are cases where > 2 alternate alleles will still be emitted by the algorithm. Regarding your prevalence comment, empirically on the Genome in a Bottle HG002 sample we observed this library reduce the number of regions with > 2 alternate alleles from ~3000 to ~300 when it was first introduced. (The numbers may be slightly different now due to subsequent improvements in variant discovery and calling). regards,. Cory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:444,testability,observ,observed,444,"Hi @anands-repo,. Thanks for the question. You are correct that in these cases we are semantically treating GT=0 to be ""non-ALT""; the goal of the haplotypes.py library is to try to resolve cases where the raw calls indicate more than two alternate alleles at a single base pair. This can occur because DeepVariant processes each candidate variant independently, and sometimes candidates overlap the same stretch of the reference genome. As you observed in the code, the haplotypes.py library is even still just a ""best effort"" and there are cases where > 2 alternate alleles will still be emitted by the algorithm. Regarding your prevalence comment, empirically on the Genome in a Bottle HG002 sample we observed this library reduce the number of regions with > 2 alternate alleles from ~3000 to ~300 when it was first introduced. (The numbers may be slightly different now due to subsequent improvements in variant discovery and calling). regards,. Cory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:704,testability,observ,observed,704,"Hi @anands-repo,. Thanks for the question. You are correct that in these cases we are semantically treating GT=0 to be ""non-ALT""; the goal of the haplotypes.py library is to try to resolve cases where the raw calls indicate more than two alternate alleles at a single base pair. This can occur because DeepVariant processes each candidate variant independently, and sometimes candidates overlap the same stretch of the reference genome. As you observed in the code, the haplotypes.py library is even still just a ""best effort"" and there are cases where > 2 alternate alleles will still be emitted by the algorithm. Regarding your prevalence comment, empirically on the Genome in a Bottle HG002 sample we observed this library reduce the number of regions with > 2 alternate alleles from ~3000 to ~300 when it was first introduced. (The numbers may be slightly different now due to subsequent improvements in variant discovery and calling). regards,. Cory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:215,usability,indicat,indicate,215,"Hi @anands-repo,. Thanks for the question. You are correct that in these cases we are semantically treating GT=0 to be ""non-ALT""; the goal of the haplotypes.py library is to try to resolve cases where the raw calls indicate more than two alternate alleles at a single base pair. This can occur because DeepVariant processes each candidate variant independently, and sometimes candidates overlap the same stretch of the reference genome. As you observed in the code, the haplotypes.py library is even still just a ""best effort"" and there are cases where > 2 alternate alleles will still be emitted by the algorithm. Regarding your prevalence comment, empirically on the Genome in a Bottle HG002 sample we observed this library reduce the number of regions with > 2 alternate alleles from ~3000 to ~300 when it was first introduced. (The numbers may be slightly different now due to subsequent improvements in variant discovery and calling). regards,. Cory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:916,usability,discov,discovery,916,"Hi @anands-repo,. Thanks for the question. You are correct that in these cases we are semantically treating GT=0 to be ""non-ALT""; the goal of the haplotypes.py library is to try to resolve cases where the raw calls indicate more than two alternate alleles at a single base pair. This can occur because DeepVariant processes each candidate variant independently, and sometimes candidates overlap the same stretch of the reference genome. As you observed in the code, the haplotypes.py library is even still just a ""best effort"" and there are cases where > 2 alternate alleles will still be emitted by the algorithm. Regarding your prevalence comment, empirically on the Genome in a Bottle HG002 sample we observed this library reduce the number of regions with > 2 alternate alleles from ~3000 to ~300 when it was first introduced. (The numbers may be slightly different now due to subsequent improvements in variant discovery and calling). regards,. Cory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:115,energy efficiency,predict,predicted,115,"@cmclean Thanks for the additional explanation. So the cases to be filtered out are those with more than 2 alleles predicted per reference position. Also, 300 out of millions of variants does seem to indicate that these cases are really rare after the use of this functionality. @AndrewCarroll @cmclean Thank you for your patience and the helpful explanations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:67,integrability,filter,filtered,67,"@cmclean Thanks for the additional explanation. So the cases to be filtered out are those with more than 2 alleles predicted per reference position. Also, 300 out of millions of variants does seem to indicate that these cases are really rare after the use of this functionality. @AndrewCarroll @cmclean Thank you for your patience and the helpful explanations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:187,reliability,doe,does,187,"@cmclean Thanks for the additional explanation. So the cases to be filtered out are those with more than 2 alleles predicted per reference position. Also, 300 out of millions of variants does seem to indicate that these cases are really rare after the use of this functionality. @AndrewCarroll @cmclean Thank you for your patience and the helpful explanations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:115,safety,predict,predicted,115,"@cmclean Thanks for the additional explanation. So the cases to be filtered out are those with more than 2 alleles predicted per reference position. Also, 300 out of millions of variants does seem to indicate that these cases are really rare after the use of this functionality. @AndrewCarroll @cmclean Thank you for your patience and the helpful explanations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:200,usability,indicat,indicate,200,"@cmclean Thanks for the additional explanation. So the cases to be filtered out are those with more than 2 alleles predicted per reference position. Also, 300 out of millions of variants does seem to indicate that these cases are really rare after the use of this functionality. @AndrewCarroll @cmclean Thank you for your patience and the helpful explanations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/247:339,usability,help,helpful,339,"@cmclean Thanks for the additional explanation. So the cases to be filtered out are those with more than 2 alleles predicted per reference position. Also, 300 out of millions of variants does seem to indicate that these cases are really rare after the use of this functionality. @AndrewCarroll @cmclean Thank you for your patience and the helpful explanations.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/247
https://github.com/google/deepvariant/issues/248:217,deployability,version,version,217,"if you run:. cat /proc/cpuinfo | grep avx. do you see anything? As if not, then your machine/CPU doesn't have avx instructions so that image won't work and as per the home page you'll have to compile or use a non-avx version yourself. If you DO have the right instructions you'll see something like this:```. (bioinfo) [root@virtbio deepvariant_tmp_output]# cat /proc/cpuinfo | grep avx. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology cpuid tsc_known_freq pni pclmulqdq ssse3 cx16 pcid sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx hypervisor lahf_lm cpuid_fault ibrs ibpb stibp tsc_adjust xsaveopt arat umip md_clear arch_capabilities```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:431,deployability,api,apic,431,"if you run:. cat /proc/cpuinfo | grep avx. do you see anything? As if not, then your machine/CPU doesn't have avx instructions so that image won't work and as per the home page you'll have to compile or use a non-avx version yourself. If you DO have the right instructions you'll see something like this:```. (bioinfo) [root@virtbio deepvariant_tmp_output]# cat /proc/cpuinfo | grep avx. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology cpuid tsc_known_freq pni pclmulqdq ssse3 cx16 pcid sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx hypervisor lahf_lm cpuid_fault ibrs ibpb stibp tsc_adjust xsaveopt arat umip md_clear arch_capabilities```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:23,energy efficiency,cpu,cpuinfo,23,"if you run:. cat /proc/cpuinfo | grep avx. do you see anything? As if not, then your machine/CPU doesn't have avx instructions so that image won't work and as per the home page you'll have to compile or use a non-avx version yourself. If you DO have the right instructions you'll see something like this:```. (bioinfo) [root@virtbio deepvariant_tmp_output]# cat /proc/cpuinfo | grep avx. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology cpuid tsc_known_freq pni pclmulqdq ssse3 cx16 pcid sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx hypervisor lahf_lm cpuid_fault ibrs ibpb stibp tsc_adjust xsaveopt arat umip md_clear arch_capabilities```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:93,energy efficiency,CPU,CPU,93,"if you run:. cat /proc/cpuinfo | grep avx. do you see anything? As if not, then your machine/CPU doesn't have avx instructions so that image won't work and as per the home page you'll have to compile or use a non-avx version yourself. If you DO have the right instructions you'll see something like this:```. (bioinfo) [root@virtbio deepvariant_tmp_output]# cat /proc/cpuinfo | grep avx. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology cpuid tsc_known_freq pni pclmulqdq ssse3 cx16 pcid sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx hypervisor lahf_lm cpuid_fault ibrs ibpb stibp tsc_adjust xsaveopt arat umip md_clear arch_capabilities```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:368,energy efficiency,cpu,cpuinfo,368,"if you run:. cat /proc/cpuinfo | grep avx. do you see anything? As if not, then your machine/CPU doesn't have avx instructions so that image won't work and as per the home page you'll have to compile or use a non-avx version yourself. If you DO have the right instructions you'll see something like this:```. (bioinfo) [root@virtbio deepvariant_tmp_output]# cat /proc/cpuinfo | grep avx. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology cpuid tsc_known_freq pni pclmulqdq ssse3 cx16 pcid sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx hypervisor lahf_lm cpuid_fault ibrs ibpb stibp tsc_adjust xsaveopt arat umip md_clear arch_capabilities```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:579,energy efficiency,cpu,cpuid,579,"if you run:. cat /proc/cpuinfo | grep avx. do you see anything? As if not, then your machine/CPU doesn't have avx instructions so that image won't work and as per the home page you'll have to compile or use a non-avx version yourself. If you DO have the right instructions you'll see something like this:```. (bioinfo) [root@virtbio deepvariant_tmp_output]# cat /proc/cpuinfo | grep avx. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology cpuid tsc_known_freq pni pclmulqdq ssse3 cx16 pcid sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx hypervisor lahf_lm cpuid_fault ibrs ibpb stibp tsc_adjust xsaveopt arat umip md_clear arch_capabilities```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:217,integrability,version,version,217,"if you run:. cat /proc/cpuinfo | grep avx. do you see anything? As if not, then your machine/CPU doesn't have avx instructions so that image won't work and as per the home page you'll have to compile or use a non-avx version yourself. If you DO have the right instructions you'll see something like this:```. (bioinfo) [root@virtbio deepvariant_tmp_output]# cat /proc/cpuinfo | grep avx. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology cpuid tsc_known_freq pni pclmulqdq ssse3 cx16 pcid sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx hypervisor lahf_lm cpuid_fault ibrs ibpb stibp tsc_adjust xsaveopt arat umip md_clear arch_capabilities```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:431,integrability,api,apic,431,"if you run:. cat /proc/cpuinfo | grep avx. do you see anything? As if not, then your machine/CPU doesn't have avx instructions so that image won't work and as per the home page you'll have to compile or use a non-avx version yourself. If you DO have the right instructions you'll see something like this:```. (bioinfo) [root@virtbio deepvariant_tmp_output]# cat /proc/cpuinfo | grep avx. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology cpuid tsc_known_freq pni pclmulqdq ssse3 cx16 pcid sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx hypervisor lahf_lm cpuid_fault ibrs ibpb stibp tsc_adjust xsaveopt arat umip md_clear arch_capabilities```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:431,interoperability,api,apic,431,"if you run:. cat /proc/cpuinfo | grep avx. do you see anything? As if not, then your machine/CPU doesn't have avx instructions so that image won't work and as per the home page you'll have to compile or use a non-avx version yourself. If you DO have the right instructions you'll see something like this:```. (bioinfo) [root@virtbio deepvariant_tmp_output]# cat /proc/cpuinfo | grep avx. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology cpuid tsc_known_freq pni pclmulqdq ssse3 cx16 pcid sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx hypervisor lahf_lm cpuid_fault ibrs ibpb stibp tsc_adjust xsaveopt arat umip md_clear arch_capabilities```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:217,modifiability,version,version,217,"if you run:. cat /proc/cpuinfo | grep avx. do you see anything? As if not, then your machine/CPU doesn't have avx instructions so that image won't work and as per the home page you'll have to compile or use a non-avx version yourself. If you DO have the right instructions you'll see something like this:```. (bioinfo) [root@virtbio deepvariant_tmp_output]# cat /proc/cpuinfo | grep avx. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology cpuid tsc_known_freq pni pclmulqdq ssse3 cx16 pcid sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx hypervisor lahf_lm cpuid_fault ibrs ibpb stibp tsc_adjust xsaveopt arat umip md_clear arch_capabilities```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:23,performance,cpu,cpuinfo,23,"if you run:. cat /proc/cpuinfo | grep avx. do you see anything? As if not, then your machine/CPU doesn't have avx instructions so that image won't work and as per the home page you'll have to compile or use a non-avx version yourself. If you DO have the right instructions you'll see something like this:```. (bioinfo) [root@virtbio deepvariant_tmp_output]# cat /proc/cpuinfo | grep avx. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology cpuid tsc_known_freq pni pclmulqdq ssse3 cx16 pcid sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx hypervisor lahf_lm cpuid_fault ibrs ibpb stibp tsc_adjust xsaveopt arat umip md_clear arch_capabilities```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:93,performance,CPU,CPU,93,"if you run:. cat /proc/cpuinfo | grep avx. do you see anything? As if not, then your machine/CPU doesn't have avx instructions so that image won't work and as per the home page you'll have to compile or use a non-avx version yourself. If you DO have the right instructions you'll see something like this:```. (bioinfo) [root@virtbio deepvariant_tmp_output]# cat /proc/cpuinfo | grep avx. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology cpuid tsc_known_freq pni pclmulqdq ssse3 cx16 pcid sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx hypervisor lahf_lm cpuid_fault ibrs ibpb stibp tsc_adjust xsaveopt arat umip md_clear arch_capabilities```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:368,performance,cpu,cpuinfo,368,"if you run:. cat /proc/cpuinfo | grep avx. do you see anything? As if not, then your machine/CPU doesn't have avx instructions so that image won't work and as per the home page you'll have to compile or use a non-avx version yourself. If you DO have the right instructions you'll see something like this:```. (bioinfo) [root@virtbio deepvariant_tmp_output]# cat /proc/cpuinfo | grep avx. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology cpuid tsc_known_freq pni pclmulqdq ssse3 cx16 pcid sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx hypervisor lahf_lm cpuid_fault ibrs ibpb stibp tsc_adjust xsaveopt arat umip md_clear arch_capabilities```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:579,performance,cpu,cpuid,579,"if you run:. cat /proc/cpuinfo | grep avx. do you see anything? As if not, then your machine/CPU doesn't have avx instructions so that image won't work and as per the home page you'll have to compile or use a non-avx version yourself. If you DO have the right instructions you'll see something like this:```. (bioinfo) [root@virtbio deepvariant_tmp_output]# cat /proc/cpuinfo | grep avx. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology cpuid tsc_known_freq pni pclmulqdq ssse3 cx16 pcid sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx hypervisor lahf_lm cpuid_fault ibrs ibpb stibp tsc_adjust xsaveopt arat umip md_clear arch_capabilities```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:97,reliability,doe,doesn,97,"if you run:. cat /proc/cpuinfo | grep avx. do you see anything? As if not, then your machine/CPU doesn't have avx instructions so that image won't work and as per the home page you'll have to compile or use a non-avx version yourself. If you DO have the right instructions you'll see something like this:```. (bioinfo) [root@virtbio deepvariant_tmp_output]# cat /proc/cpuinfo | grep avx. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology cpuid tsc_known_freq pni pclmulqdq ssse3 cx16 pcid sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx hypervisor lahf_lm cpuid_fault ibrs ibpb stibp tsc_adjust xsaveopt arat umip md_clear arch_capabilities```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:519,reliability,rdt,rdtscp,519,"if you run:. cat /proc/cpuinfo | grep avx. do you see anything? As if not, then your machine/CPU doesn't have avx instructions so that image won't work and as per the home page you'll have to compile or use a non-avx version yourself. If you DO have the right instructions you'll see something like this:```. (bioinfo) [root@virtbio deepvariant_tmp_output]# cat /proc/cpuinfo | grep avx. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology cpuid tsc_known_freq pni pclmulqdq ssse3 cx16 pcid sse4_1 sse4_2 x2apic popcnt tsc_deadline_timer aes xsave avx hypervisor lahf_lm cpuid_fault ibrs ibpb stibp tsc_adjust xsaveopt arat umip md_clear arch_capabilities```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:27,reliability,doe,does,27,Thanks rssfed23. my server does not have the avx instruction. I might be nice to add this to to the quick start documentation. Andy,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:112,usability,document,documentation,112,Thanks rssfed23. my server does not have the avx instruction. I might be nice to add this to to the quick start documentation. Andy,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:87,usability,document,documentation,87,Thank you for the comment! We will look into it and see how we can improve quick start documentation.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:8,deployability,updat,updated,8,"We have updated the documentation to mention that AVX instructions are needed. These changes will come out with the next release. Thank you for the feedback! Edit: we specifically mention this requirement again in the quickstart documentation, in addition to the page linked below by @pgrosu. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:121,deployability,releas,release,121,"We have updated the documentation to mention that AVX instructions are needed. These changes will come out with the next release. Thank you for the feedback! Edit: we specifically mention this requirement again in the quickstart documentation, in addition to the page linked below by @pgrosu. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:167,interoperability,specif,specifically,167,"We have updated the documentation to mention that AVX instructions are needed. These changes will come out with the next release. Thank you for the feedback! Edit: we specifically mention this requirement again in the quickstart documentation, in addition to the page linked below by @pgrosu. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:8,safety,updat,updated,8,"We have updated the documentation to mention that AVX instructions are needed. These changes will come out with the next release. Thank you for the feedback! Edit: we specifically mention this requirement again in the quickstart documentation, in addition to the page linked below by @pgrosu. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:8,security,updat,updated,8,"We have updated the documentation to mention that AVX instructions are needed. These changes will come out with the next release. Thank you for the feedback! Edit: we specifically mention this requirement again in the quickstart documentation, in addition to the page linked below by @pgrosu. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:20,usability,document,documentation,20,"We have updated the documentation to mention that AVX instructions are needed. These changes will come out with the next release. Thank you for the feedback! Edit: we specifically mention this requirement again in the quickstart documentation, in addition to the page linked below by @pgrosu. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:148,usability,feedback,feedback,148,"We have updated the documentation to mention that AVX instructions are needed. These changes will come out with the next release. Thank you for the feedback! Edit: we specifically mention this requirement again in the quickstart documentation, in addition to the page linked below by @pgrosu. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/248:229,usability,document,documentation,229,"We have updated the documentation to mention that AVX instructions are needed. These changes will come out with the next release. Thank you for the feedback! Edit: we specifically mention this requirement again in the quickstart documentation, in addition to the page linked below by @pgrosu. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/248
https://github.com/google/deepvariant/issues/249:145,availability,failur,failure,145,"Hi se2cheeese,. It looks like one of the shards failed during make_examples stage. In order to diagnose the problem we need to see logs with the failure. You may run it without shards (remove --num_shards flag). It should be pretty fast for 100K bases. . Then attach the entire output so that we could look at it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:48,deployability,fail,failed,48,"Hi se2cheeese,. It looks like one of the shards failed during make_examples stage. In order to diagnose the problem we need to see logs with the failure. You may run it without shards (remove --num_shards flag). It should be pretty fast for 100K bases. . Then attach the entire output so that we could look at it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:76,deployability,stage,stage,76,"Hi se2cheeese,. It looks like one of the shards failed during make_examples stage. In order to diagnose the problem we need to see logs with the failure. You may run it without shards (remove --num_shards flag). It should be pretty fast for 100K bases. . Then attach the entire output so that we could look at it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:131,deployability,log,logs,131,"Hi se2cheeese,. It looks like one of the shards failed during make_examples stage. In order to diagnose the problem we need to see logs with the failure. You may run it without shards (remove --num_shards flag). It should be pretty fast for 100K bases. . Then attach the entire output so that we could look at it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:145,deployability,fail,failure,145,"Hi se2cheeese,. It looks like one of the shards failed during make_examples stage. In order to diagnose the problem we need to see logs with the failure. You may run it without shards (remove --num_shards flag). It should be pretty fast for 100K bases. . Then attach the entire output so that we could look at it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:145,performance,failur,failure,145,"Hi se2cheeese,. It looks like one of the shards failed during make_examples stage. In order to diagnose the problem we need to see logs with the failure. You may run it without shards (remove --num_shards flag). It should be pretty fast for 100K bases. . Then attach the entire output so that we could look at it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:48,reliability,fail,failed,48,"Hi se2cheeese,. It looks like one of the shards failed during make_examples stage. In order to diagnose the problem we need to see logs with the failure. You may run it without shards (remove --num_shards flag). It should be pretty fast for 100K bases. . Then attach the entire output so that we could look at it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:95,reliability,diagno,diagnose,95,"Hi se2cheeese,. It looks like one of the shards failed during make_examples stage. In order to diagnose the problem we need to see logs with the failure. You may run it without shards (remove --num_shards flag). It should be pretty fast for 100K bases. . Then attach the entire output so that we could look at it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:145,reliability,fail,failure,145,"Hi se2cheeese,. It looks like one of the shards failed during make_examples stage. In order to diagnose the problem we need to see logs with the failure. You may run it without shards (remove --num_shards flag). It should be pretty fast for 100K bases. . Then attach the entire output so that we could look at it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:131,safety,log,logs,131,"Hi se2cheeese,. It looks like one of the shards failed during make_examples stage. In order to diagnose the problem we need to see logs with the failure. You may run it without shards (remove --num_shards flag). It should be pretty fast for 100K bases. . Then attach the entire output so that we could look at it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:131,security,log,logs,131,"Hi se2cheeese,. It looks like one of the shards failed during make_examples stage. In order to diagnose the problem we need to see logs with the failure. You may run it without shards (remove --num_shards flag). It should be pretty fast for 100K bases. . Then attach the entire output so that we could look at it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:95,testability,diagno,diagnose,95,"Hi se2cheeese,. It looks like one of the shards failed during make_examples stage. In order to diagnose the problem we need to see logs with the failure. You may run it without shards (remove --num_shards flag). It should be pretty fast for 100K bases. . Then attach the entire output so that we could look at it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:131,testability,log,logs,131,"Hi se2cheeese,. It looks like one of the shards failed during make_examples stage. In order to diagnose the problem we need to see logs with the failure. You may run it without shards (remove --num_shards flag). It should be pretty fast for 100K bases. . Then attach the entire output so that we could look at it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2987,availability,checkpoint,checkpoint,2987,"you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:07:00.397901: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:07:01.327224 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using conf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3282,availability,servic,service,3282,"3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protoc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3290,availability,servic,service,3290,"bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': Non",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3310,availability,servic,service,3310,"amReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoint",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3433,availability,servic,service,3433,"er. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3441,availability,servic,service,3441,"3 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4207,availability,Cluster,ClusterSpec,4207,"2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528713 140638419556096 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 13:07:08.533111 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 13:07:08.550576 140638419556096 data_providers.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6382,availability,operat,operator,6382,_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/m,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6989,availability,Restor,Restoring,6989,"nd will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. ti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:7343,availability,Restor,Restoring,7343,"updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". 2019-12-13 13:07:22.565874: I deepvariant/postprocess_v",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:29924,availability,error,error,29924,"93887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 1. ```. The same error develops with your WES-case-study sample file/script. It would be great to solve this problem. . Thank you in advance. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3282,deployability,servic,service,3282,"3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protoc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3290,deployability,servic,service,3290,"bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': Non",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3310,deployability,servic,service,3310,"amReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoint",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3433,deployability,servic,service,3433,"er. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3441,deployability,servic,service,3441,"3 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4207,deployability,Cluster,ClusterSpec,4207,"2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528713 140638419556096 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 13:07:08.533111 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 13:07:08.550576 140638419556096 data_providers.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5078,deployability,version,version,5078,"_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528713 140638419556096 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 13:07:08.533111 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 13:07:08.550576 140638419556096 data_providers.py:367] self.input_read_threads=8. W1213 13:07:08.550924 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5104,deployability,updat,updating,5104,"rain_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528713 140638419556096 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 13:07:08.533111 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 13:07:08.550576 140638419556096 data_providers.py:367] self.input_read_threads=8. W1213 13:07:08.550924 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5135,deployability,automat,automatically,5135,"': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528713 140638419556096 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 13:07:08.533111 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 13:07:08.550576 140638419556096 data_providers.py:367] self.input_read_threads=8. W1213 13:07:08.550924 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] F",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5528,deployability,version,version,5528,"replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528713 140638419556096 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 13:07:08.533111 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 13:07:08.550576 140638419556096 data_providers.py:367] self.input_read_threads=8. W1213 13:07:08.550924 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 moni",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5554,deployability,updat,updating,5554,"0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528713 140638419556096 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 13:07:08.533111 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 13:07:08.550576 140638419556096 data_providers.py:367] self.input_read_threads=8. W1213 13:07:08.550924 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Grap",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6025,deployability,version,version,6025,s) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 13:07:08.550576 140638419556096 data_providers.py:367] self.input_read_threads=8. W1213 13:07:08.550924 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/we,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6051,deployability,updat,updating,6051,be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 13:07:08.550576 140638419556096 data_providers.py:367] self.input_read_threads=8. W1213 13:07:08.550924 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6322,deployability,version,version,6322,iles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 14063841955609,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6348,deployability,updat,updating,6348,oogle_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6839,deployability,version,version,6839," /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6865,deployability,updat,updating,6865,"l/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6894,deployability,API,APIs,6894,"ariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, pleas",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:7633,deployability,modul,module,7633,"m /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". 2019-12-13 13:07:22.565874: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. 2019-12-13 13:07:22.566377: I deepvariant/postprocess_variants.cc:97] Done reading: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. #entries in single_site_calls = 28. 2019-12-13 13:07:2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:7849,deployability,depend,depend,7849,"ructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". 2019-12-13 13:07:22.565874: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. 2019-12-13 13:07:22.566377: I deepvariant/postprocess_variants.cc:97] Done reading: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. #entries in single_site_calls = 28. 2019-12-13 13:07:22.566443: I deepvariant/postprocess_variants.cc:101] Total #entries in single_site_calls = 28. 2019-12-13 13:07:22.566459: I deepvariant/postprocess_variants.cc:103] Start SortSingleSiteCalls. 2019-12-13 13:07:22.566",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:29041,deployability,modul,module,29041,"40405993887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 1. ```. The same error develops with your WES-case-study sample file/script. It would be great to solve this problem. . Thank you in adva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3004,energy efficiency,model,models,3004,"RAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:07:00.397901: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:07:01.327224 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_che",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3015,energy efficiency,model,model,3015,"note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:07:00.397901: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:07:01.327224 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_se",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3153,energy efficiency,core,core,3153,"er.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:07:01.327224 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3198,energy efficiency,CPU,CPU,3198,"17728. I1213 13:07:01.327224 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.serv",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3202,energy efficiency,Frequenc,Frequency,3202,"I1213 13:07:01.327224 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3551,energy efficiency,core,core,3551,"I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3750,energy efficiency,model,modeling,3750,". sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528713 140638419556096 call_variants.py:381] Writing",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3780,energy efficiency,model,model,3780," the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528713 140638419556096 call_variants.py:381] Writing calls to /tmp/deepvariant_tm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3848,energy efficiency,estimat,estimator,3848,"""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528713 140638419556096 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 13:07:08.533111 14063",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3893,energy efficiency,model,model,3893,"output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528713 140638419556096 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 13:07:08.533111 140638419556096 deprecation.py:323] From /usr/lo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3964,energy efficiency,estimat,estimator,3964,".tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528713 140638419556096 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 13:07:08.533111 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_librar",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5744,energy efficiency,estimat,estimator,5744,iting calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 13:07:08.533111 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 13:07:08.550576 140638419556096 data_providers.py:367] self.input_read_threads=8. W1213 13:07:08.550924 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensor,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5915,energy efficiency,model,modeling,5915,packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 13:07:08.550576 140638419556096 data_providers.py:367] self.input_read_threads=8. W1213 13:07:08.550924 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files w,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6217,energy efficiency,model,modeling,6217,self.input_read_threads=8. W1213 13:07:08.550924 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I12,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6448,energy efficiency,estimat,estimator,6448,a.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:3,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:7020,energy efficiency,model,models,7020,"e version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postp",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:7031,energy efficiency,model,model,7031,"Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_vari",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:7256,energy efficiency,model,modeling,7256,"n.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --gvcf_ou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:7374,energy efficiency,model,models,7374,"r of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". 2019-12-13 13:07:22.565874: I deepvariant/postprocess_variants.cc:88] Read from: /tm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:7385,energy efficiency,model,model,7385,"or or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". 2019-12-13 13:07:22.565874: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/deepvaria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:557,integrability,buffer,buffer,557,"Thank you akolesikov, . Yes, it works without num_shards flag. . Here is the output. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:07:00.156721 139885760198400 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:07:00.265611 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.277568 139885760198400 make_examples.py:1324] Preparing inputs. I1213 13:07:00.354827 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.377454 139885760198400 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:07:00.383280 139885760198400 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00001.gz. I1213 13:07:00.383569 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3282,integrability,servic,service,3282,"3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protoc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3290,integrability,servic,service,3290,"bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': Non",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3310,integrability,servic,service,3310,"amReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoint",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3433,integrability,servic,service,3433,"er. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3441,integrability,servic,service,3441,"3 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5078,integrability,version,version,5078,"_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528713 140638419556096 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 13:07:08.533111 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 13:07:08.550576 140638419556096 data_providers.py:367] self.input_read_threads=8. W1213 13:07:08.550924 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5528,integrability,version,version,5528,"replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528713 140638419556096 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 13:07:08.533111 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 13:07:08.550576 140638419556096 data_providers.py:367] self.input_read_threads=8. W1213 13:07:08.550924 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 moni",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6025,integrability,version,version,6025,s) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 13:07:08.550576 140638419556096 data_providers.py:367] self.input_read_threads=8. W1213 13:07:08.550924 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/we,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6322,integrability,version,version,6322,iles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 14063841955609,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6839,integrability,version,version,6839," /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6894,integrability,API,APIs,6894,"ariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, pleas",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:7483,integrability,batch,batches,7483,"n. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". 2019-12-13 13:07:22.565874: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. 2019-12-13 13:07:22.566377: I deepvariant/postproce",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:7849,integrability,depend,depend,7849,"ructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". 2019-12-13 13:07:22.565874: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. 2019-12-13 13:07:22.566377: I deepvariant/postprocess_variants.cc:97] Done reading: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. #entries in single_site_calls = 28. 2019-12-13 13:07:22.566443: I deepvariant/postprocess_variants.cc:101] Total #entries in single_site_calls = 28. 2019-12-13 13:07:22.566459: I deepvariant/postprocess_variants.cc:103] Start SortSingleSiteCalls. 2019-12-13 13:07:22.566",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:9104,integrability,Transform,Transforming,9104,"iants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". 2019-12-13 13:07:22.565874: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. 2019-12-13 13:07:22.566377: I deepvariant/postprocess_variants.cc:97] Done reading: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. #entries in single_site_calls = 28. 2019-12-13 13:07:22.566443: I deepvariant/postprocess_variants.cc:101] Total #entries in single_site_calls = 28. 2019-12-13 13:07:22.566459: I deepvariant/postprocess_variants.cc:103] Start SortSingleSiteCalls. 2019-12-13 13:07:22.566492: I deepvariant/postprocess_variants.cc:105] Done SortSingleSiteCalls. I1213 13:07:22.566857 139950873712384 postprocess_variants.py:972] CVO sorting took 1.82509422302e-05 minutes. I1213 13:07:22.567840 139950873712384 postprocess_variants.py:974] Transforming call_variants_output to variants. I1213 13:07:22.568222 139950873712384 postprocess_variants.py:1000] Merging and writing variants to VCF and gVCF. I1213 13:07:22.570799 139950873712384 genomics_writer.py:172] Writing /output/output.vcf.gz with NativeVcfWriter. I1213 13:07:22.573292 139950873712384 genomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. I1213 13:07:22.661263 139950873712384 postprocess_variants.py:1020] Finished writing VCF and gVCF in 0.00155058304469 minutes. I1213 13:07:22.678944 139950873712384 genomics_reader.py:223] Reading /output/output.vcf.gz with NativeVcfReader. real	0m2.697s. user	0m2.250s. sys	0m1.410s. ```. When it didn't work with num_shards flag, the entire output was like this. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --read",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:10351,integrability,buffer,buffer,10351,"gz with NativeVcfWriter. I1213 13:07:22.573292 139950873712384 genomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. I1213 13:07:22.661263 139950873712384 postprocess_variants.py:1020] Finished writing VCF and gVCF in 0.00155058304469 minutes. I1213 13:07:22.678944 139950873712384 genomics_reader.py:223] Reading /output/output.vcf.gz with NativeVcfReader. real	0m2.697s. user	0m2.250s. sys	0m1.410s. ```. When it didn't work with num_shards flag, the entire output was like this. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=10. ***** Running the command:*****. time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:11:54.227790 140490637805312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379641 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392796 140490637805312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.896145 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.944020 140490637805312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:29337,integrability,sub,subprocess,29337,"93887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 1. ```. The same error develops with your WES-case-study sample file/script. It would be great to solve this problem. . Thank you in advance. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:29430,integrability,sub,subprocess,29430,"93887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 1. ```. The same error develops with your WES-case-study sample file/script. It would be great to solve this problem. . Thank you in advance. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:29511,integrability,sub,subprocess,29511,"93887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 1. ```. The same error develops with your WES-case-study sample file/script. It would be great to solve this problem. . Thank you in advance. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:29585,integrability,buffer,buffer,29585,"93887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 1. ```. The same error develops with your WES-case-study sample file/script. It would be great to solve this problem. . Thank you in advance. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3158,interoperability,platform,platform,3158,"60] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:07:01.327224 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3354,interoperability,platform,platform,3354,"400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_ho",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6880,interoperability,standard,standard,6880,"google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6894,interoperability,API,APIs,6894,"ariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, pleas",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:9104,interoperability,Transform,Transforming,9104,"iants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". 2019-12-13 13:07:22.565874: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. 2019-12-13 13:07:22.566377: I deepvariant/postprocess_variants.cc:97] Done reading: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. #entries in single_site_calls = 28. 2019-12-13 13:07:22.566443: I deepvariant/postprocess_variants.cc:101] Total #entries in single_site_calls = 28. 2019-12-13 13:07:22.566459: I deepvariant/postprocess_variants.cc:103] Start SortSingleSiteCalls. 2019-12-13 13:07:22.566492: I deepvariant/postprocess_variants.cc:105] Done SortSingleSiteCalls. I1213 13:07:22.566857 139950873712384 postprocess_variants.py:972] CVO sorting took 1.82509422302e-05 minutes. I1213 13:07:22.567840 139950873712384 postprocess_variants.py:974] Transforming call_variants_output to variants. I1213 13:07:22.568222 139950873712384 postprocess_variants.py:1000] Merging and writing variants to VCF and gVCF. I1213 13:07:22.570799 139950873712384 genomics_writer.py:172] Writing /output/output.vcf.gz with NativeVcfWriter. I1213 13:07:22.573292 139950873712384 genomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. I1213 13:07:22.661263 139950873712384 postprocess_variants.py:1020] Finished writing VCF and gVCF in 0.00155058304469 minutes. I1213 13:07:22.678944 139950873712384 genomics_reader.py:223] Reading /output/output.vcf.gz with NativeVcfReader. real	0m2.697s. user	0m2.250s. sys	0m1.410s. ```. When it didn't work with num_shards flag, the entire output was like this. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --read",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2036,modifiability,deco,decode,2036,"1 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.277568 139885760198400 make_examples.py:1324] Preparing inputs. I1213 13:07:00.354827 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.377454 139885760198400 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:07:00.383280 139885760198400 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00001.gz. I1213 13:07:00.383569 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:07:00.397901: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:07:01.327224 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3282,modifiability,servic,service,3282,"3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protoc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3290,modifiability,servic,service,3290,"bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': Non",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3310,modifiability,servic,service,3310,"amReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoint",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3433,modifiability,servic,service,3433,"er. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3441,modifiability,servic,service,3441,"3 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3798,modifiability,paramet,parameters,3798,"time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528713 140638419556096 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_varian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4919,modifiability,pac,packages,4919,"5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528713 140638419556096 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 13:07:08.533111 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 13:07:08.550576 140638419556096 data_providers.py:367] self.input_read_threads=8. W1213 13:07:08.550924 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5078,modifiability,version,version,5078,"_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528713 140638419556096 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 13:07:08.533111 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 13:07:08.550576 140638419556096 data_providers.py:367] self.input_read_threads=8. W1213 13:07:08.550924 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5528,modifiability,version,version,5528,"replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528713 140638419556096 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 13:07:08.533111 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 13:07:08.550576 140638419556096 data_providers.py:367] self.input_read_threads=8. W1213 13:07:08.550924 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 moni",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6025,modifiability,version,version,6025,s) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 13:07:08.550576 140638419556096 data_providers.py:367] self.input_read_threads=8. W1213 13:07:08.550924 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/we,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6322,modifiability,version,version,6322,iles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 14063841955609,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6668,modifiability,pac,packages,6668,y:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFl,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6839,modifiability,version,version,6839," /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6999,modifiability,paramet,parameters,6999," removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/de",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:7353,modifiability,paramet,parameters,7353," Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". 2019-12-13 13:07:22.565874: I deepvariant/postprocess_variants.cc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:7633,modifiability,modul,module,7633,"m /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". 2019-12-13 13:07:22.565874: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. 2019-12-13 13:07:22.566377: I deepvariant/postprocess_variants.cc:97] Done reading: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. #entries in single_site_calls = 28. 2019-12-13 13:07:2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:7849,modifiability,depend,depend,7849,"ructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". 2019-12-13 13:07:22.565874: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. 2019-12-13 13:07:22.566377: I deepvariant/postprocess_variants.cc:97] Done reading: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. #entries in single_site_calls = 28. 2019-12-13 13:07:22.566443: I deepvariant/postprocess_variants.cc:101] Total #entries in single_site_calls = 28. 2019-12-13 13:07:22.566459: I deepvariant/postprocess_variants.cc:103] Start SortSingleSiteCalls. 2019-12-13 13:07:22.566",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:11832,modifiability,deco,decode,11832,"1 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392796 140490637805312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.896145 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.944020 140490637805312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.960778 140490637805312 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00010.gz. I1213 13:11:54.961548 140490637805312 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00010.gz. I1213 13:11:55.068834 140490637805312 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.109412: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.427617 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700349 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.598862 140490637805312 make_examples.py:1363] Task 0: 0 candidates (0 examples) [17.64s elapsed]. I1213 13:12:13.068409 140490637805312 make_examples.py:1380] Found 1 candidate variants. I1213 13:12:13.223464 140490637805312 make_examples.py:1381] Created 1 examples. I1213 13:11:54.226648 140402484717312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.767545 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.788374 1404",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:13709,modifiability,deco,decode,13709,"5 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.788374 140402484717312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.979619 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:55.010253 140402484717312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:55.017723 140402484717312 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00001-of-00010.gz. I1213 13:11:55.018065 140402484717312 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00001-of-00010.gz. I1213 13:11:55.107007 140402484717312 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.127048: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.412683 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.702708 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.676522 140402484717312 make_examples.py:1363] Task 1: 4 candidates (4 examples) [17.66s elapsed]. I1213 13:12:13.028630 140402484717312 make_examples.py:1380] Found 7 candidate variants. I1213 13:12:13.211899 140402484717312 make_examples.py:1381] Created 7 examples. I1213 13:11:54.225912 139798917543680 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.380671 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.394714 1397",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:15586,modifiability,deco,decode,15586,"1 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.394714 139798917543680 make_examples.py:1324] Preparing inputs. I1213 13:11:54.895178 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.923032 139798917543680 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.930289 139798917543680 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00002-of-00010.gz. I1213 13:11:54.930751 139798917543680 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00002-of-00010.gz. I1213 13:11:54.940401 139798917543680 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943675: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.334026 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.708316 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.659555 139798917543680 make_examples.py:1363] Task 2: 3 candidates (3 examples) [17.73s elapsed]. I1213 13:12:13.045805 139798917543680 make_examples.py:1380] Found 7 candidate variants. I1213 13:12:13.209331 139798917543680 make_examples.py:1381] Created 7 examples. I1213 13:11:54.227793 140236020647680 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.403919 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.414350 1402",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:17463,modifiability,deco,decode,17463,"9 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.414350 140236020647680 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893651 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920942 140236020647680 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928174 140236020647680 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00003-of-00010.gz. I1213 13:11:54.928524 140236020647680 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00003-of-00010.gz. I1213 13:11:54.940502 140236020647680 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943561: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.417463 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.708851 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.610981 140236020647680 make_examples.py:1363] Task 3: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:13.094532 140236020647680 make_examples.py:1380] Found 1 candidate variants. I1213 13:12:13.241935 140236020647680 make_examples.py:1381] Created 1 examples. I1213 13:11:54.226402 140097611171584 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378241 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391170 1400",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:19340,modifiability,deco,decode,19340,"1 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391170 140097611171584 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893971 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921802 140097611171584 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928759 140097611171584 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00004-of-00010.gz. I1213 13:11:54.929138 140097611171584 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00004-of-00010.gz. I1213 13:11:54.940500 140097611171584 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943644: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.388587 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700193 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.595916 140097611171584 make_examples.py:1363] Task 4: 0 candidates (0 examples) [17.66s elapsed]. I1213 13:12:13.016803 140097611171584 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.202656 140097611171584 make_examples.py:1381] Created 3 examples. I1213 13:11:54.224806 139902364522240 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.382869 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.396718 1399",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:21217,modifiability,deco,decode,21217,"9 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.396718 139902364522240 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893652 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920939 139902364522240 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928069 139902364522240 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00005-of-00010.gz. I1213 13:11:54.928409 139902364522240 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00005-of-00010.gz. I1213 13:11:54.940448 139902364522240 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943632: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.312068 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.712960 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.605319 139902364522240 make_examples.py:1363] Task 5: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:12.983227 139902364522240 make_examples.py:1380] Found 0 candidate variants. I1213 13:12:13.147787 139902364522240 make_examples.py:1381] Created 0 examples. I1213 13:11:54.226497 140617939887872 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378638 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391983 1406",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:23094,modifiability,deco,decode,23094,"8 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391983 140617939887872 make_examples.py:1324] Preparing inputs. I1213 13:11:54.913211 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.939115 140617939887872 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.948522 140617939887872 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00006-of-00010.gz. I1213 13:11:54.949028 140617939887872 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00006-of-00010.gz. I1213 13:11:55.068927 140617939887872 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.127010: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.422019 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700212 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.628093 140617939887872 make_examples.py:1363] Task 6: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:13.083571 140617939887872 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.237519 140617939887872 make_examples.py:1381] Created 3 examples. I1213 13:11:54.227164 140331447654144 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379436 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392060 1403",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:24971,modifiability,deco,decode,24971,"6 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392060 140331447654144 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893769 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921667 140331447654144 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928567 140331447654144 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00007-of-00010.gz. I1213 13:11:54.928935 140331447654144 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00007-of-00010.gz. I1213 13:11:54.940444 140331447654144 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943589: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.413748 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700217 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.624783 140331447654144 make_examples.py:1363] Task 7: 0 candidates (0 examples) [17.69s elapsed]. I1213 13:12:13.050214 140331447654144 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.219461 140331447654144 make_examples.py:1381] Created 3 examples. I1213 13:11:54.225383 140460245006080 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378618 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392364 1404",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:26848,modifiability,deco,decode,26848,"8 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392364 140460245006080 make_examples.py:1324] Preparing inputs. I1213 13:11:54.905719 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.953198 140460245006080 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.963092 140460245006080 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00008-of-00010.gz. I1213 13:11:54.963464 140460245006080 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00008-of-00010.gz. I1213 13:11:55.068834 140460245006080 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.090168: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.314467 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700131 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.616221 140460245006080 make_examples.py:1363] Task 8: 0 candidates (0 examples) [17.65s elapsed]. I1213 13:12:13.152090 140460245006080 make_examples.py:1380] Found 2 candidate variants. I1213 13:12:13.250552 140460245006080 make_examples.py:1381] Created 2 examples. I1213 13:11:54.227202 140405993887488 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.386776 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.398395 1404",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:28725,modifiability,deco,decode,28725,"6 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.398395 140405993887488 make_examples.py:1324] Preparing inputs. I1213 13:11:54.894856 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.922434 140405993887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvaria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:29041,modifiability,modul,module,29041,"40405993887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 1. ```. The same error develops with your WES-case-study sample file/script. It would be great to solve this problem. . Thank you in adva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:29101,modifiability,pac,packages,29101,"93887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 1. ```. The same error develops with your WES-case-study sample file/script. It would be great to solve this problem. . Thank you in advance. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:29201,modifiability,pac,packages,29201,"93887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 1. ```. The same error develops with your WES-case-study sample file/script. It would be great to solve this problem. . Thank you in advance. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:523,performance,time,time,523,"Thank you akolesikov, . Yes, it works without num_shards flag. . Here is the output. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:07:00.156721 139885760198400 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:07:00.265611 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.277568 139885760198400 make_examples.py:1324] Preparing inputs. I1213 13:07:00.354827 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.377454 139885760198400 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:07:00.383280 139885760198400 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00001.gz. I1213 13:07:00.383569 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:538,performance,parallel,parallel,538,"Thank you akolesikov, . Yes, it works without num_shards flag. . Here is the output. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:07:00.156721 139885760198400 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:07:00.265611 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.277568 139885760198400 make_examples.py:1324] Preparing inputs. I1213 13:07:00.354827 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.377454 139885760198400 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:07:00.383280 139885760198400 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00001.gz. I1213 13:07:00.383569 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2803,performance,time,time,2803,"o /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:07:00.397901: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:07:01.327224 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random paramet",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3198,performance,CPU,CPU,3198,"17728. I1213 13:07:01.327224 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.serv",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3650,performance,Tune,Tune,3650,"07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3699,performance,perform,performance,3699,"reated 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:7483,performance,batch,batches,7483,"n. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". 2019-12-13 13:07:22.565874: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. 2019-12-13 13:07:22.566377: I deepvariant/postproce",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:7992,performance,time,time,7992,"ring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". 2019-12-13 13:07:22.565874: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. 2019-12-13 13:07:22.566377: I deepvariant/postprocess_variants.cc:97] Done reading: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. #entries in single_site_calls = 28. 2019-12-13 13:07:22.566443: I deepvariant/postprocess_variants.cc:101] Total #entries in single_site_calls = 28. 2019-12-13 13:07:22.566459: I deepvariant/postprocess_variants.cc:103] Start SortSingleSiteCalls. 2019-12-13 13:07:22.566492: I deepvariant/postprocess_variants.cc:105] Done SortSingleSiteCalls. I1213 13:07:22.566857 139950873712384 postprocess_variants.py:972] C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:10317,performance,time,time,10317,"py:172] Writing /output/output.vcf.gz with NativeVcfWriter. I1213 13:07:22.573292 139950873712384 genomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. I1213 13:07:22.661263 139950873712384 postprocess_variants.py:1020] Finished writing VCF and gVCF in 0.00155058304469 minutes. I1213 13:07:22.678944 139950873712384 genomics_reader.py:223] Reading /output/output.vcf.gz with NativeVcfReader. real	0m2.697s. user	0m2.250s. sys	0m1.410s. ```. When it didn't work with num_shards flag, the entire output was like this. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=10. ***** Running the command:*****. time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:11:54.227790 140490637805312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379641 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392796 140490637805312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.896145 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.944020 140490637805312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:10332,performance,parallel,parallel,10332,"output/output.vcf.gz with NativeVcfWriter. I1213 13:07:22.573292 139950873712384 genomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. I1213 13:07:22.661263 139950873712384 postprocess_variants.py:1020] Finished writing VCF and gVCF in 0.00155058304469 minutes. I1213 13:07:22.678944 139950873712384 genomics_reader.py:223] Reading /output/output.vcf.gz with NativeVcfReader. real	0m2.697s. user	0m2.250s. sys	0m1.410s. ```. When it didn't work with num_shards flag, the entire output was like this. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=10. ***** Running the command:*****. time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:11:54.227790 140490637805312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379641 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392796 140490637805312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.896145 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.944020 140490637805312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:29551,performance,time,time,29551,"93887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 1. ```. The same error develops with your WES-case-study sample file/script. It would be great to solve this problem. . Thank you in advance. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:29566,performance,parallel,parallel,29566,"93887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 1. ```. The same error develops with your WES-case-study sample file/script. It would be great to solve this problem. . Thank you in advance. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:29924,performance,error,error,29924,"93887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 1. ```. The same error develops with your WES-case-study sample file/script. It would be great to solve this problem. . Thank you in advance. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2987,reliability,checkpoint,checkpoint,2987,"you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:07:00.397901: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:07:01.327224 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using conf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6989,reliability,Restor,Restoring,6989,"nd will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. ti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:7343,reliability,Restor,Restoring,7343,"updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". 2019-12-13 13:07:22.565874: I deepvariant/postprocess_v",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:133,safety,input,input,133,"Thank you akolesikov, . Yes, it works without num_shards flag. . Here is the output. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:07:00.156721 139885760198400 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:07:00.265611 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.277568 139885760198400 make_examples.py:1324] Preparing inputs. I1213 13:07:00.354827 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.377454 139885760198400 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:07:00.383280 139885760198400 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00001.gz. I1213 13:07:00.383569 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:308,safety,input,input,308,"Thank you akolesikov, . Yes, it works without num_shards flag. . Here is the output. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:07:00.156721 139885760198400 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:07:00.265611 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.277568 139885760198400 make_examples.py:1324] Preparing inputs. I1213 13:07:00.354827 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.377454 139885760198400 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:07:00.383280 139885760198400 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00001.gz. I1213 13:07:00.383569 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:338,safety,input,input,338,"Thank you akolesikov, . Yes, it works without num_shards flag. . Here is the output. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:07:00.156721 139885760198400 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:07:00.265611 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.277568 139885760198400 make_examples.py:1324] Preparing inputs. I1213 13:07:00.354827 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.377454 139885760198400 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:07:00.383280 139885760198400 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00001.gz. I1213 13:07:00.383569 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:622,safety,input,input,622,"Thank you akolesikov, . Yes, it works without num_shards flag. . Here is the output. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:07:00.156721 139885760198400 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:07:00.265611 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.277568 139885760198400 make_examples.py:1324] Preparing inputs. I1213 13:07:00.354827 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.377454 139885760198400 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:07:00.383280 139885760198400 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00001.gz. I1213 13:07:00.383569 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:649,safety,input,input,649,"Thank you akolesikov, . Yes, it works without num_shards flag. . Here is the output. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:07:00.156721 139885760198400 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:07:00.265611 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.277568 139885760198400 make_examples.py:1324] Preparing inputs. I1213 13:07:00.354827 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.377454 139885760198400 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:07:00.383280 139885760198400 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00001.gz. I1213 13:07:00.383569 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:1090,safety,input,input,1090,"udo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:07:00.156721 139885760198400 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:07:00.265611 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.277568 139885760198400 make_examples.py:1324] Preparing inputs. I1213 13:07:00.354827 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.377454 139885760198400 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:07:00.383280 139885760198400 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00001.gz. I1213 13:07:00.383569 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:1207,safety,input,inputs,1207,"iant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:07:00.156721 139885760198400 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:07:00.265611 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.277568 139885760198400 make_examples.py:1324] Preparing inputs. I1213 13:07:00.354827 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.377454 139885760198400 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:07:00.383280 139885760198400 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00001.gz. I1213 13:07:00.383569 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:07:00.397901: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I12",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:1286,safety,input,input,1286,"pe=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:07:00.156721 139885760198400 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:07:00.265611 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.277568 139885760198400 make_examples.py:1324] Preparing inputs. I1213 13:07:00.354827 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.377454 139885760198400 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:07:00.383280 139885760198400 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00001.gz. I1213 13:07:00.383569 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:07:00.397901: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:07:01.327224 139885760198400 genomics_reader.py:223] Reading /input/HC3-B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2011,safety,input,input,2011,"ENT. I1213 13:07:00.265611 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.277568 139885760198400 make_examples.py:1324] Preparing inputs. I1213 13:07:00.354827 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.377454 139885760198400 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:07:00.383280 139885760198400 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00001.gz. I1213 13:07:00.383569 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:07:00.397901: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:07:01.327224 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2278,safety,input,input,2278,"ing /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.377454 139885760198400 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:07:00.383280 139885760198400 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00001.gz. I1213 13:07:00.383569 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:07:00.397901: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:07:01.327224 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2395,safety,input,input,2395,"n contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:07:00.383280 139885760198400 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00001.gz. I1213 13:07:00.383569 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:07:00.397901: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:07:01.327224 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5104,safety,updat,updating,5104,"rain_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528713 140638419556096 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 13:07:08.533111 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 13:07:08.550576 140638419556096 data_providers.py:367] self.input_read_threads=8. W1213 13:07:08.550924 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5554,safety,updat,updating,5554,"0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528713 140638419556096 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 13:07:08.533111 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 13:07:08.550576 140638419556096 data_providers.py:367] self.input_read_threads=8. W1213 13:07:08.550924 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Grap",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6051,safety,updat,updating,6051,be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 13:07:08.550576 140638419556096 data_providers.py:367] self.input_read_threads=8. W1213 13:07:08.550924 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6348,safety,updat,updating,6348,oogle_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6865,safety,updat,updating,6865,"l/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:7633,safety,modul,module,7633,"m /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". 2019-12-13 13:07:22.565874: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. 2019-12-13 13:07:22.566377: I deepvariant/postprocess_variants.cc:97] Done reading: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. #entries in single_site_calls = 28. 2019-12-13 13:07:2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:7849,safety,depend,depend,7849,"ructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". 2019-12-13 13:07:22.565874: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. 2019-12-13 13:07:22.566377: I deepvariant/postprocess_variants.cc:97] Done reading: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. #entries in single_site_calls = 28. 2019-12-13 13:07:22.566443: I deepvariant/postprocess_variants.cc:101] Total #entries in single_site_calls = 28. 2019-12-13 13:07:22.566459: I deepvariant/postprocess_variants.cc:103] Start SortSingleSiteCalls. 2019-12-13 13:07:22.566",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:8047,safety,input,input,8047,"3:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". 2019-12-13 13:07:22.565874: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. 2019-12-13 13:07:22.566377: I deepvariant/postprocess_variants.cc:97] Done reading: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. #entries in single_site_calls = 28. 2019-12-13 13:07:22.566443: I deepvariant/postprocess_variants.cc:101] Total #entries in single_site_calls = 28. 2019-12-13 13:07:22.566459: I deepvariant/postprocess_variants.cc:103] Start SortSingleSiteCalls. 2019-12-13 13:07:22.566492: I deepvariant/postprocess_variants.cc:105] Done SortSingleSiteCalls. I1213 13:07:22.566857 139950873712384 postprocess_variants.py:972] CVO sorting took 1.82509422302e-05 minutes. I1213 13:07:2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:9908,safety,input,input,9908,"ngleSiteCalls. I1213 13:07:22.566857 139950873712384 postprocess_variants.py:972] CVO sorting took 1.82509422302e-05 minutes. I1213 13:07:22.567840 139950873712384 postprocess_variants.py:974] Transforming call_variants_output to variants. I1213 13:07:22.568222 139950873712384 postprocess_variants.py:1000] Merging and writing variants to VCF and gVCF. I1213 13:07:22.570799 139950873712384 genomics_writer.py:172] Writing /output/output.vcf.gz with NativeVcfWriter. I1213 13:07:22.573292 139950873712384 genomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. I1213 13:07:22.661263 139950873712384 postprocess_variants.py:1020] Finished writing VCF and gVCF in 0.00155058304469 minutes. I1213 13:07:22.678944 139950873712384 genomics_reader.py:223] Reading /output/output.vcf.gz with NativeVcfReader. real	0m2.697s. user	0m2.250s. sys	0m1.410s. ```. When it didn't work with num_shards flag, the entire output was like this. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=10. ***** Running the command:*****. time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:11:54.227790 140490637805312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379641 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam w",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:10083,safety,input,input,10083,"_variants.py:974] Transforming call_variants_output to variants. I1213 13:07:22.568222 139950873712384 postprocess_variants.py:1000] Merging and writing variants to VCF and gVCF. I1213 13:07:22.570799 139950873712384 genomics_writer.py:172] Writing /output/output.vcf.gz with NativeVcfWriter. I1213 13:07:22.573292 139950873712384 genomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. I1213 13:07:22.661263 139950873712384 postprocess_variants.py:1020] Finished writing VCF and gVCF in 0.00155058304469 minutes. I1213 13:07:22.678944 139950873712384 genomics_reader.py:223] Reading /output/output.vcf.gz with NativeVcfReader. real	0m2.697s. user	0m2.250s. sys	0m1.410s. ```. When it didn't work with num_shards flag, the entire output was like this. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=10. ***** Running the command:*****. time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:11:54.227790 140490637805312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379641 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392796 140490637805312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.896145 140490637805312 genomics_reader.py:223] Reading /inpu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:10113,safety,input,input,10113," call_variants_output to variants. I1213 13:07:22.568222 139950873712384 postprocess_variants.py:1000] Merging and writing variants to VCF and gVCF. I1213 13:07:22.570799 139950873712384 genomics_writer.py:172] Writing /output/output.vcf.gz with NativeVcfWriter. I1213 13:07:22.573292 139950873712384 genomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. I1213 13:07:22.661263 139950873712384 postprocess_variants.py:1020] Finished writing VCF and gVCF in 0.00155058304469 minutes. I1213 13:07:22.678944 139950873712384 genomics_reader.py:223] Reading /output/output.vcf.gz with NativeVcfReader. real	0m2.697s. user	0m2.250s. sys	0m1.410s. ```. When it didn't work with num_shards flag, the entire output was like this. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=10. ***** Running the command:*****. time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:11:54.227790 140490637805312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379641 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392796 140490637805312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.896145 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with Nativ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:10416,safety,input,input,10416,"nomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. I1213 13:07:22.661263 139950873712384 postprocess_variants.py:1020] Finished writing VCF and gVCF in 0.00155058304469 minutes. I1213 13:07:22.678944 139950873712384 genomics_reader.py:223] Reading /output/output.vcf.gz with NativeVcfReader. real	0m2.697s. user	0m2.250s. sys	0m1.410s. ```. When it didn't work with num_shards flag, the entire output was like this. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=10. ***** Running the command:*****. time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:11:54.227790 140490637805312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379641 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392796 140490637805312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.896145 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.944020 140490637805312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.960778 140490637805312 make_examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:10443,safety,input,input,10443,"ng /output/output.g.vcf.gz with NativeVcfWriter. I1213 13:07:22.661263 139950873712384 postprocess_variants.py:1020] Finished writing VCF and gVCF in 0.00155058304469 minutes. I1213 13:07:22.678944 139950873712384 genomics_reader.py:223] Reading /output/output.vcf.gz with NativeVcfReader. real	0m2.697s. user	0m2.250s. sys	0m1.410s. ```. When it didn't work with num_shards flag, the entire output was like this. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=10. ***** Running the command:*****. time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:11:54.227790 140490637805312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379641 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392796 140490637805312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.896145 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.944020 140490637805312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.960778 140490637805312 make_examples.py:1330] Writing examples t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:10886,safety,input,input,10886,"v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=10. ***** Running the command:*****. time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:11:54.227790 140490637805312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379641 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392796 140490637805312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.896145 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.944020 140490637805312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.960778 140490637805312 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00010.gz. I1213 13:11:54.961548 140490637805312 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00010.gz. I1213 13:11:55.068834 140490637805312 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:11003,safety,input,inputs,11003," \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=10. ***** Running the command:*****. time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:11:54.227790 140490637805312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379641 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392796 140490637805312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.896145 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.944020 140490637805312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.960778 140490637805312 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00010.gz. I1213 13:11:54.961548 140490637805312 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00010.gz. I1213 13:11:55.068834 140490637805312 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.109412: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I12",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:11082,safety,input,input,11082,"put/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=10. ***** Running the command:*****. time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:11:54.227790 140490637805312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379641 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392796 140490637805312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.896145 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.944020 140490637805312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.960778 140490637805312 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00010.gz. I1213 13:11:54.961548 140490637805312 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00010.gz. I1213 13:11:55.068834 140490637805312 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.109412: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.427617 140490637805312 genomics_reader.py:223] Reading /input/HC3-B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:11807,safety,input,input,11807,"ENT. I1213 13:11:54.379641 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392796 140490637805312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.896145 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.944020 140490637805312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.960778 140490637805312 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00010.gz. I1213 13:11:54.961548 140490637805312 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00010.gz. I1213 13:11:55.068834 140490637805312 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.109412: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.427617 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700349 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.598862 140490637805312 make_examples.py:1363] Task 0: 0 candidates (0 examples) [17.64s elapsed]. I1213 13:12:13.068409 140490637805312 make_examples.py:1380] Found 1 candidate variants. I1213 13:12:13.223464 140490637805312 make_examples.py:1381] Created 1 examples. I1213 13:11:54.226648 140402484717312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.767545 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:12074,safety,input,input,12074,"ing /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.944020 140490637805312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.960778 140490637805312 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00010.gz. I1213 13:11:54.961548 140490637805312 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00010.gz. I1213 13:11:55.068834 140490637805312 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.109412: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.427617 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700349 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.598862 140490637805312 make_examples.py:1363] Task 0: 0 candidates (0 examples) [17.64s elapsed]. I1213 13:12:13.068409 140490637805312 make_examples.py:1380] Found 1 candidate variants. I1213 13:12:13.223464 140490637805312 make_examples.py:1381] Created 1 examples. I1213 13:11:54.226648 140402484717312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.767545 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.788374 140402484717312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.979619 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:55.010253 140402484717312 make_examples.py:1248] Common cont",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:12191,safety,input,input,12191,"n contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.960778 140490637805312 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00010.gz. I1213 13:11:54.961548 140490637805312 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00010.gz. I1213 13:11:55.068834 140490637805312 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.109412: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.427617 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700349 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.598862 140490637805312 make_examples.py:1363] Task 0: 0 candidates (0 examples) [17.64s elapsed]. I1213 13:12:13.068409 140490637805312 make_examples.py:1380] Found 1 candidate variants. I1213 13:12:13.223464 140490637805312 make_examples.py:1381] Created 1 examples. I1213 13:11:54.226648 140402484717312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.767545 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.788374 140402484717312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.979619 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:55.010253 140402484717312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:12763,safety,input,input,12763,"s default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.109412: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.427617 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700349 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.598862 140490637805312 make_examples.py:1363] Task 0: 0 candidates (0 examples) [17.64s elapsed]. I1213 13:12:13.068409 140490637805312 make_examples.py:1380] Found 1 candidate variants. I1213 13:12:13.223464 140490637805312 make_examples.py:1381] Created 1 examples. I1213 13:11:54.226648 140402484717312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.767545 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.788374 140402484717312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.979619 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:55.010253 140402484717312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:55.017723 140402484717312 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00001-of-00010.gz. I1213 13:11:55.018065 140402484717312 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00001-of-00010.gz. I1213 13:11:55.107007 140402484717312 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:12880,safety,input,inputs,12880,"--ref. 2019-12-13 13:11:55.109412: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.427617 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700349 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.598862 140490637805312 make_examples.py:1363] Task 0: 0 candidates (0 examples) [17.64s elapsed]. I1213 13:12:13.068409 140490637805312 make_examples.py:1380] Found 1 candidate variants. I1213 13:12:13.223464 140490637805312 make_examples.py:1381] Created 1 examples. I1213 13:11:54.226648 140402484717312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.767545 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.788374 140402484717312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.979619 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:55.010253 140402484717312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:55.017723 140402484717312 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00001-of-00010.gz. I1213 13:11:55.018065 140402484717312 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00001-of-00010.gz. I1213 13:11:55.107007 140402484717312 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.127048: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I12",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:12959,safety,input,input,12959,"Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.427617 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700349 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.598862 140490637805312 make_examples.py:1363] Task 0: 0 candidates (0 examples) [17.64s elapsed]. I1213 13:12:13.068409 140490637805312 make_examples.py:1380] Found 1 candidate variants. I1213 13:12:13.223464 140490637805312 make_examples.py:1381] Created 1 examples. I1213 13:11:54.226648 140402484717312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.767545 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.788374 140402484717312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.979619 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:55.010253 140402484717312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:55.017723 140402484717312 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00001-of-00010.gz. I1213 13:11:55.018065 140402484717312 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00001-of-00010.gz. I1213 13:11:55.107007 140402484717312 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.127048: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.412683 140402484717312 genomics_reader.py:223] Reading /input/HC3-B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:13684,safety,input,input,13684,"ENT. I1213 13:11:54.767545 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.788374 140402484717312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.979619 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:55.010253 140402484717312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:55.017723 140402484717312 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00001-of-00010.gz. I1213 13:11:55.018065 140402484717312 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00001-of-00010.gz. I1213 13:11:55.107007 140402484717312 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.127048: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.412683 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.702708 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.676522 140402484717312 make_examples.py:1363] Task 1: 4 candidates (4 examples) [17.66s elapsed]. I1213 13:12:13.028630 140402484717312 make_examples.py:1380] Found 7 candidate variants. I1213 13:12:13.211899 140402484717312 make_examples.py:1381] Created 7 examples. I1213 13:11:54.225912 139798917543680 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.380671 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:13951,safety,input,input,13951,"ing /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:55.010253 140402484717312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:55.017723 140402484717312 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00001-of-00010.gz. I1213 13:11:55.018065 140402484717312 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00001-of-00010.gz. I1213 13:11:55.107007 140402484717312 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.127048: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.412683 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.702708 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.676522 140402484717312 make_examples.py:1363] Task 1: 4 candidates (4 examples) [17.66s elapsed]. I1213 13:12:13.028630 140402484717312 make_examples.py:1380] Found 7 candidate variants. I1213 13:12:13.211899 140402484717312 make_examples.py:1381] Created 7 examples. I1213 13:11:54.225912 139798917543680 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.380671 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.394714 139798917543680 make_examples.py:1324] Preparing inputs. I1213 13:11:54.895178 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.923032 139798917543680 make_examples.py:1248] Common cont",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:14068,safety,input,input,14068,"n contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:55.017723 140402484717312 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00001-of-00010.gz. I1213 13:11:55.018065 140402484717312 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00001-of-00010.gz. I1213 13:11:55.107007 140402484717312 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.127048: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.412683 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.702708 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.676522 140402484717312 make_examples.py:1363] Task 1: 4 candidates (4 examples) [17.66s elapsed]. I1213 13:12:13.028630 140402484717312 make_examples.py:1380] Found 7 candidate variants. I1213 13:12:13.211899 140402484717312 make_examples.py:1381] Created 7 examples. I1213 13:11:54.225912 139798917543680 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.380671 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.394714 139798917543680 make_examples.py:1324] Preparing inputs. I1213 13:11:54.895178 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.923032 139798917543680 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:14640,safety,input,input,14640,"s default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.127048: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.412683 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.702708 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.676522 140402484717312 make_examples.py:1363] Task 1: 4 candidates (4 examples) [17.66s elapsed]. I1213 13:12:13.028630 140402484717312 make_examples.py:1380] Found 7 candidate variants. I1213 13:12:13.211899 140402484717312 make_examples.py:1381] Created 7 examples. I1213 13:11:54.225912 139798917543680 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.380671 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.394714 139798917543680 make_examples.py:1324] Preparing inputs. I1213 13:11:54.895178 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.923032 139798917543680 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.930289 139798917543680 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00002-of-00010.gz. I1213 13:11:54.930751 139798917543680 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00002-of-00010.gz. I1213 13:11:54.940401 139798917543680 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:14757,safety,input,inputs,14757,"--ref. 2019-12-13 13:11:55.127048: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.412683 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.702708 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.676522 140402484717312 make_examples.py:1363] Task 1: 4 candidates (4 examples) [17.66s elapsed]. I1213 13:12:13.028630 140402484717312 make_examples.py:1380] Found 7 candidate variants. I1213 13:12:13.211899 140402484717312 make_examples.py:1381] Created 7 examples. I1213 13:11:54.225912 139798917543680 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.380671 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.394714 139798917543680 make_examples.py:1324] Preparing inputs. I1213 13:11:54.895178 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.923032 139798917543680 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.930289 139798917543680 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00002-of-00010.gz. I1213 13:11:54.930751 139798917543680 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00002-of-00010.gz. I1213 13:11:54.940401 139798917543680 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943675: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I12",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:14836,safety,input,input,14836,"Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.412683 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.702708 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.676522 140402484717312 make_examples.py:1363] Task 1: 4 candidates (4 examples) [17.66s elapsed]. I1213 13:12:13.028630 140402484717312 make_examples.py:1380] Found 7 candidate variants. I1213 13:12:13.211899 140402484717312 make_examples.py:1381] Created 7 examples. I1213 13:11:54.225912 139798917543680 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.380671 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.394714 139798917543680 make_examples.py:1324] Preparing inputs. I1213 13:11:54.895178 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.923032 139798917543680 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.930289 139798917543680 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00002-of-00010.gz. I1213 13:11:54.930751 139798917543680 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00002-of-00010.gz. I1213 13:11:54.940401 139798917543680 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943675: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.334026 139798917543680 genomics_reader.py:223] Reading /input/HC3-B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:15561,safety,input,input,15561,"ENT. I1213 13:11:54.380671 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.394714 139798917543680 make_examples.py:1324] Preparing inputs. I1213 13:11:54.895178 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.923032 139798917543680 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.930289 139798917543680 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00002-of-00010.gz. I1213 13:11:54.930751 139798917543680 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00002-of-00010.gz. I1213 13:11:54.940401 139798917543680 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943675: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.334026 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.708316 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.659555 139798917543680 make_examples.py:1363] Task 2: 3 candidates (3 examples) [17.73s elapsed]. I1213 13:12:13.045805 139798917543680 make_examples.py:1380] Found 7 candidate variants. I1213 13:12:13.209331 139798917543680 make_examples.py:1381] Created 7 examples. I1213 13:11:54.227793 140236020647680 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.403919 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:15828,safety,input,input,15828,"ing /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.923032 139798917543680 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.930289 139798917543680 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00002-of-00010.gz. I1213 13:11:54.930751 139798917543680 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00002-of-00010.gz. I1213 13:11:54.940401 139798917543680 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943675: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.334026 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.708316 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.659555 139798917543680 make_examples.py:1363] Task 2: 3 candidates (3 examples) [17.73s elapsed]. I1213 13:12:13.045805 139798917543680 make_examples.py:1380] Found 7 candidate variants. I1213 13:12:13.209331 139798917543680 make_examples.py:1381] Created 7 examples. I1213 13:11:54.227793 140236020647680 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.403919 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.414350 140236020647680 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893651 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920942 140236020647680 make_examples.py:1248] Common cont",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:15945,safety,input,input,15945,"n contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.930289 139798917543680 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00002-of-00010.gz. I1213 13:11:54.930751 139798917543680 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00002-of-00010.gz. I1213 13:11:54.940401 139798917543680 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943675: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.334026 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.708316 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.659555 139798917543680 make_examples.py:1363] Task 2: 3 candidates (3 examples) [17.73s elapsed]. I1213 13:12:13.045805 139798917543680 make_examples.py:1380] Found 7 candidate variants. I1213 13:12:13.209331 139798917543680 make_examples.py:1381] Created 7 examples. I1213 13:11:54.227793 140236020647680 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.403919 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.414350 140236020647680 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893651 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920942 140236020647680 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:16517,safety,input,input,16517,"s default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943675: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.334026 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.708316 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.659555 139798917543680 make_examples.py:1363] Task 2: 3 candidates (3 examples) [17.73s elapsed]. I1213 13:12:13.045805 139798917543680 make_examples.py:1380] Found 7 candidate variants. I1213 13:12:13.209331 139798917543680 make_examples.py:1381] Created 7 examples. I1213 13:11:54.227793 140236020647680 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.403919 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.414350 140236020647680 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893651 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920942 140236020647680 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928174 140236020647680 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00003-of-00010.gz. I1213 13:11:54.928524 140236020647680 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00003-of-00010.gz. I1213 13:11:54.940502 140236020647680 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:16634,safety,input,inputs,16634,"--ref. 2019-12-13 13:11:54.943675: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.334026 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.708316 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.659555 139798917543680 make_examples.py:1363] Task 2: 3 candidates (3 examples) [17.73s elapsed]. I1213 13:12:13.045805 139798917543680 make_examples.py:1380] Found 7 candidate variants. I1213 13:12:13.209331 139798917543680 make_examples.py:1381] Created 7 examples. I1213 13:11:54.227793 140236020647680 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.403919 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.414350 140236020647680 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893651 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920942 140236020647680 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928174 140236020647680 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00003-of-00010.gz. I1213 13:11:54.928524 140236020647680 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00003-of-00010.gz. I1213 13:11:54.940502 140236020647680 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943561: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I12",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:16713,safety,input,input,16713,"Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.334026 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.708316 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.659555 139798917543680 make_examples.py:1363] Task 2: 3 candidates (3 examples) [17.73s elapsed]. I1213 13:12:13.045805 139798917543680 make_examples.py:1380] Found 7 candidate variants. I1213 13:12:13.209331 139798917543680 make_examples.py:1381] Created 7 examples. I1213 13:11:54.227793 140236020647680 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.403919 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.414350 140236020647680 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893651 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920942 140236020647680 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928174 140236020647680 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00003-of-00010.gz. I1213 13:11:54.928524 140236020647680 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00003-of-00010.gz. I1213 13:11:54.940502 140236020647680 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943561: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.417463 140236020647680 genomics_reader.py:223] Reading /input/HC3-B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:17438,safety,input,input,17438,"ENT. I1213 13:11:54.403919 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.414350 140236020647680 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893651 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920942 140236020647680 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928174 140236020647680 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00003-of-00010.gz. I1213 13:11:54.928524 140236020647680 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00003-of-00010.gz. I1213 13:11:54.940502 140236020647680 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943561: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.417463 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.708851 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.610981 140236020647680 make_examples.py:1363] Task 3: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:13.094532 140236020647680 make_examples.py:1380] Found 1 candidate variants. I1213 13:12:13.241935 140236020647680 make_examples.py:1381] Created 1 examples. I1213 13:11:54.226402 140097611171584 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378241 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:17705,safety,input,input,17705,"ing /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920942 140236020647680 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928174 140236020647680 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00003-of-00010.gz. I1213 13:11:54.928524 140236020647680 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00003-of-00010.gz. I1213 13:11:54.940502 140236020647680 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943561: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.417463 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.708851 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.610981 140236020647680 make_examples.py:1363] Task 3: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:13.094532 140236020647680 make_examples.py:1380] Found 1 candidate variants. I1213 13:12:13.241935 140236020647680 make_examples.py:1381] Created 1 examples. I1213 13:11:54.226402 140097611171584 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378241 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391170 140097611171584 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893971 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921802 140097611171584 make_examples.py:1248] Common cont",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:17822,safety,input,input,17822,"n contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928174 140236020647680 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00003-of-00010.gz. I1213 13:11:54.928524 140236020647680 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00003-of-00010.gz. I1213 13:11:54.940502 140236020647680 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943561: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.417463 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.708851 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.610981 140236020647680 make_examples.py:1363] Task 3: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:13.094532 140236020647680 make_examples.py:1380] Found 1 candidate variants. I1213 13:12:13.241935 140236020647680 make_examples.py:1381] Created 1 examples. I1213 13:11:54.226402 140097611171584 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378241 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391170 140097611171584 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893971 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921802 140097611171584 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:18394,safety,input,input,18394,"s default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943561: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.417463 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.708851 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.610981 140236020647680 make_examples.py:1363] Task 3: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:13.094532 140236020647680 make_examples.py:1380] Found 1 candidate variants. I1213 13:12:13.241935 140236020647680 make_examples.py:1381] Created 1 examples. I1213 13:11:54.226402 140097611171584 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378241 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391170 140097611171584 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893971 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921802 140097611171584 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928759 140097611171584 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00004-of-00010.gz. I1213 13:11:54.929138 140097611171584 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00004-of-00010.gz. I1213 13:11:54.940500 140097611171584 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:18511,safety,input,inputs,18511,"--ref. 2019-12-13 13:11:54.943561: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.417463 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.708851 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.610981 140236020647680 make_examples.py:1363] Task 3: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:13.094532 140236020647680 make_examples.py:1380] Found 1 candidate variants. I1213 13:12:13.241935 140236020647680 make_examples.py:1381] Created 1 examples. I1213 13:11:54.226402 140097611171584 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378241 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391170 140097611171584 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893971 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921802 140097611171584 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928759 140097611171584 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00004-of-00010.gz. I1213 13:11:54.929138 140097611171584 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00004-of-00010.gz. I1213 13:11:54.940500 140097611171584 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943644: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I12",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:18590,safety,input,input,18590,"Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.417463 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.708851 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.610981 140236020647680 make_examples.py:1363] Task 3: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:13.094532 140236020647680 make_examples.py:1380] Found 1 candidate variants. I1213 13:12:13.241935 140236020647680 make_examples.py:1381] Created 1 examples. I1213 13:11:54.226402 140097611171584 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378241 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391170 140097611171584 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893971 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921802 140097611171584 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928759 140097611171584 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00004-of-00010.gz. I1213 13:11:54.929138 140097611171584 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00004-of-00010.gz. I1213 13:11:54.940500 140097611171584 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943644: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.388587 140097611171584 genomics_reader.py:223] Reading /input/HC3-B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:19315,safety,input,input,19315,"ENT. I1213 13:11:54.378241 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391170 140097611171584 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893971 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921802 140097611171584 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928759 140097611171584 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00004-of-00010.gz. I1213 13:11:54.929138 140097611171584 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00004-of-00010.gz. I1213 13:11:54.940500 140097611171584 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943644: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.388587 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700193 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.595916 140097611171584 make_examples.py:1363] Task 4: 0 candidates (0 examples) [17.66s elapsed]. I1213 13:12:13.016803 140097611171584 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.202656 140097611171584 make_examples.py:1381] Created 3 examples. I1213 13:11:54.224806 139902364522240 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.382869 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:19582,safety,input,input,19582,"ing /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921802 140097611171584 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928759 140097611171584 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00004-of-00010.gz. I1213 13:11:54.929138 140097611171584 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00004-of-00010.gz. I1213 13:11:54.940500 140097611171584 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943644: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.388587 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700193 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.595916 140097611171584 make_examples.py:1363] Task 4: 0 candidates (0 examples) [17.66s elapsed]. I1213 13:12:13.016803 140097611171584 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.202656 140097611171584 make_examples.py:1381] Created 3 examples. I1213 13:11:54.224806 139902364522240 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.382869 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.396718 139902364522240 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893652 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920939 139902364522240 make_examples.py:1248] Common cont",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:19699,safety,input,input,19699,"n contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928759 140097611171584 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00004-of-00010.gz. I1213 13:11:54.929138 140097611171584 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00004-of-00010.gz. I1213 13:11:54.940500 140097611171584 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943644: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.388587 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700193 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.595916 140097611171584 make_examples.py:1363] Task 4: 0 candidates (0 examples) [17.66s elapsed]. I1213 13:12:13.016803 140097611171584 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.202656 140097611171584 make_examples.py:1381] Created 3 examples. I1213 13:11:54.224806 139902364522240 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.382869 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.396718 139902364522240 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893652 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920939 139902364522240 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:20271,safety,input,input,20271,"s default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943644: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.388587 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700193 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.595916 140097611171584 make_examples.py:1363] Task 4: 0 candidates (0 examples) [17.66s elapsed]. I1213 13:12:13.016803 140097611171584 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.202656 140097611171584 make_examples.py:1381] Created 3 examples. I1213 13:11:54.224806 139902364522240 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.382869 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.396718 139902364522240 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893652 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920939 139902364522240 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928069 139902364522240 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00005-of-00010.gz. I1213 13:11:54.928409 139902364522240 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00005-of-00010.gz. I1213 13:11:54.940448 139902364522240 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:20388,safety,input,inputs,20388,"--ref. 2019-12-13 13:11:54.943644: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.388587 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700193 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.595916 140097611171584 make_examples.py:1363] Task 4: 0 candidates (0 examples) [17.66s elapsed]. I1213 13:12:13.016803 140097611171584 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.202656 140097611171584 make_examples.py:1381] Created 3 examples. I1213 13:11:54.224806 139902364522240 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.382869 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.396718 139902364522240 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893652 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920939 139902364522240 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928069 139902364522240 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00005-of-00010.gz. I1213 13:11:54.928409 139902364522240 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00005-of-00010.gz. I1213 13:11:54.940448 139902364522240 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943632: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I12",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:20467,safety,input,input,20467,"Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.388587 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700193 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.595916 140097611171584 make_examples.py:1363] Task 4: 0 candidates (0 examples) [17.66s elapsed]. I1213 13:12:13.016803 140097611171584 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.202656 140097611171584 make_examples.py:1381] Created 3 examples. I1213 13:11:54.224806 139902364522240 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.382869 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.396718 139902364522240 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893652 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920939 139902364522240 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928069 139902364522240 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00005-of-00010.gz. I1213 13:11:54.928409 139902364522240 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00005-of-00010.gz. I1213 13:11:54.940448 139902364522240 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943632: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.312068 139902364522240 genomics_reader.py:223] Reading /input/HC3-B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:21192,safety,input,input,21192,"ENT. I1213 13:11:54.382869 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.396718 139902364522240 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893652 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920939 139902364522240 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928069 139902364522240 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00005-of-00010.gz. I1213 13:11:54.928409 139902364522240 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00005-of-00010.gz. I1213 13:11:54.940448 139902364522240 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943632: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.312068 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.712960 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.605319 139902364522240 make_examples.py:1363] Task 5: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:12.983227 139902364522240 make_examples.py:1380] Found 0 candidate variants. I1213 13:12:13.147787 139902364522240 make_examples.py:1381] Created 0 examples. I1213 13:11:54.226497 140617939887872 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378638 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:21459,safety,input,input,21459,"ing /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920939 139902364522240 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928069 139902364522240 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00005-of-00010.gz. I1213 13:11:54.928409 139902364522240 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00005-of-00010.gz. I1213 13:11:54.940448 139902364522240 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943632: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.312068 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.712960 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.605319 139902364522240 make_examples.py:1363] Task 5: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:12.983227 139902364522240 make_examples.py:1380] Found 0 candidate variants. I1213 13:12:13.147787 139902364522240 make_examples.py:1381] Created 0 examples. I1213 13:11:54.226497 140617939887872 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378638 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391983 140617939887872 make_examples.py:1324] Preparing inputs. I1213 13:11:54.913211 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.939115 140617939887872 make_examples.py:1248] Common cont",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:21576,safety,input,input,21576,"n contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928069 139902364522240 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00005-of-00010.gz. I1213 13:11:54.928409 139902364522240 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00005-of-00010.gz. I1213 13:11:54.940448 139902364522240 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943632: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.312068 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.712960 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.605319 139902364522240 make_examples.py:1363] Task 5: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:12.983227 139902364522240 make_examples.py:1380] Found 0 candidate variants. I1213 13:12:13.147787 139902364522240 make_examples.py:1381] Created 0 examples. I1213 13:11:54.226497 140617939887872 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378638 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391983 140617939887872 make_examples.py:1324] Preparing inputs. I1213 13:11:54.913211 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.939115 140617939887872 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:22148,safety,input,input,22148,"s default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943632: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.312068 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.712960 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.605319 139902364522240 make_examples.py:1363] Task 5: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:12.983227 139902364522240 make_examples.py:1380] Found 0 candidate variants. I1213 13:12:13.147787 139902364522240 make_examples.py:1381] Created 0 examples. I1213 13:11:54.226497 140617939887872 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378638 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391983 140617939887872 make_examples.py:1324] Preparing inputs. I1213 13:11:54.913211 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.939115 140617939887872 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.948522 140617939887872 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00006-of-00010.gz. I1213 13:11:54.949028 140617939887872 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00006-of-00010.gz. I1213 13:11:55.068927 140617939887872 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:22265,safety,input,inputs,22265,"--ref. 2019-12-13 13:11:54.943632: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.312068 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.712960 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.605319 139902364522240 make_examples.py:1363] Task 5: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:12.983227 139902364522240 make_examples.py:1380] Found 0 candidate variants. I1213 13:12:13.147787 139902364522240 make_examples.py:1381] Created 0 examples. I1213 13:11:54.226497 140617939887872 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378638 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391983 140617939887872 make_examples.py:1324] Preparing inputs. I1213 13:11:54.913211 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.939115 140617939887872 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.948522 140617939887872 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00006-of-00010.gz. I1213 13:11:54.949028 140617939887872 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00006-of-00010.gz. I1213 13:11:55.068927 140617939887872 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.127010: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I12",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:22344,safety,input,input,22344,"Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.312068 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.712960 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.605319 139902364522240 make_examples.py:1363] Task 5: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:12.983227 139902364522240 make_examples.py:1380] Found 0 candidate variants. I1213 13:12:13.147787 139902364522240 make_examples.py:1381] Created 0 examples. I1213 13:11:54.226497 140617939887872 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378638 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391983 140617939887872 make_examples.py:1324] Preparing inputs. I1213 13:11:54.913211 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.939115 140617939887872 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.948522 140617939887872 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00006-of-00010.gz. I1213 13:11:54.949028 140617939887872 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00006-of-00010.gz. I1213 13:11:55.068927 140617939887872 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.127010: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.422019 140617939887872 genomics_reader.py:223] Reading /input/HC3-B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:23069,safety,input,input,23069,"ENT. I1213 13:11:54.378638 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391983 140617939887872 make_examples.py:1324] Preparing inputs. I1213 13:11:54.913211 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.939115 140617939887872 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.948522 140617939887872 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00006-of-00010.gz. I1213 13:11:54.949028 140617939887872 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00006-of-00010.gz. I1213 13:11:55.068927 140617939887872 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.127010: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.422019 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700212 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.628093 140617939887872 make_examples.py:1363] Task 6: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:13.083571 140617939887872 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.237519 140617939887872 make_examples.py:1381] Created 3 examples. I1213 13:11:54.227164 140331447654144 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379436 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:23336,safety,input,input,23336,"ing /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.939115 140617939887872 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.948522 140617939887872 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00006-of-00010.gz. I1213 13:11:54.949028 140617939887872 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00006-of-00010.gz. I1213 13:11:55.068927 140617939887872 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.127010: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.422019 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700212 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.628093 140617939887872 make_examples.py:1363] Task 6: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:13.083571 140617939887872 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.237519 140617939887872 make_examples.py:1381] Created 3 examples. I1213 13:11:54.227164 140331447654144 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379436 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392060 140331447654144 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893769 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921667 140331447654144 make_examples.py:1248] Common cont",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:23453,safety,input,input,23453,"n contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.948522 140617939887872 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00006-of-00010.gz. I1213 13:11:54.949028 140617939887872 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00006-of-00010.gz. I1213 13:11:55.068927 140617939887872 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.127010: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.422019 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700212 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.628093 140617939887872 make_examples.py:1363] Task 6: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:13.083571 140617939887872 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.237519 140617939887872 make_examples.py:1381] Created 3 examples. I1213 13:11:54.227164 140331447654144 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379436 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392060 140331447654144 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893769 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921667 140331447654144 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:24025,safety,input,input,24025,"s default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.127010: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.422019 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700212 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.628093 140617939887872 make_examples.py:1363] Task 6: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:13.083571 140617939887872 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.237519 140617939887872 make_examples.py:1381] Created 3 examples. I1213 13:11:54.227164 140331447654144 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379436 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392060 140331447654144 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893769 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921667 140331447654144 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928567 140331447654144 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00007-of-00010.gz. I1213 13:11:54.928935 140331447654144 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00007-of-00010.gz. I1213 13:11:54.940444 140331447654144 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:24142,safety,input,inputs,24142,"--ref. 2019-12-13 13:11:55.127010: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.422019 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700212 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.628093 140617939887872 make_examples.py:1363] Task 6: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:13.083571 140617939887872 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.237519 140617939887872 make_examples.py:1381] Created 3 examples. I1213 13:11:54.227164 140331447654144 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379436 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392060 140331447654144 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893769 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921667 140331447654144 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928567 140331447654144 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00007-of-00010.gz. I1213 13:11:54.928935 140331447654144 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00007-of-00010.gz. I1213 13:11:54.940444 140331447654144 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943589: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I12",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:24221,safety,input,input,24221,"Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.422019 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700212 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.628093 140617939887872 make_examples.py:1363] Task 6: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:13.083571 140617939887872 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.237519 140617939887872 make_examples.py:1381] Created 3 examples. I1213 13:11:54.227164 140331447654144 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379436 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392060 140331447654144 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893769 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921667 140331447654144 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928567 140331447654144 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00007-of-00010.gz. I1213 13:11:54.928935 140331447654144 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00007-of-00010.gz. I1213 13:11:54.940444 140331447654144 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943589: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.413748 140331447654144 genomics_reader.py:223] Reading /input/HC3-B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:24946,safety,input,input,24946,"ENT. I1213 13:11:54.379436 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392060 140331447654144 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893769 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921667 140331447654144 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928567 140331447654144 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00007-of-00010.gz. I1213 13:11:54.928935 140331447654144 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00007-of-00010.gz. I1213 13:11:54.940444 140331447654144 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943589: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.413748 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700217 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.624783 140331447654144 make_examples.py:1363] Task 7: 0 candidates (0 examples) [17.69s elapsed]. I1213 13:12:13.050214 140331447654144 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.219461 140331447654144 make_examples.py:1381] Created 3 examples. I1213 13:11:54.225383 140460245006080 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378618 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:25213,safety,input,input,25213,"ing /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921667 140331447654144 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928567 140331447654144 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00007-of-00010.gz. I1213 13:11:54.928935 140331447654144 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00007-of-00010.gz. I1213 13:11:54.940444 140331447654144 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943589: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.413748 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700217 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.624783 140331447654144 make_examples.py:1363] Task 7: 0 candidates (0 examples) [17.69s elapsed]. I1213 13:12:13.050214 140331447654144 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.219461 140331447654144 make_examples.py:1381] Created 3 examples. I1213 13:11:54.225383 140460245006080 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378618 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392364 140460245006080 make_examples.py:1324] Preparing inputs. I1213 13:11:54.905719 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.953198 140460245006080 make_examples.py:1248] Common cont",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:25330,safety,input,input,25330,"n contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928567 140331447654144 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00007-of-00010.gz. I1213 13:11:54.928935 140331447654144 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00007-of-00010.gz. I1213 13:11:54.940444 140331447654144 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943589: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.413748 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700217 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.624783 140331447654144 make_examples.py:1363] Task 7: 0 candidates (0 examples) [17.69s elapsed]. I1213 13:12:13.050214 140331447654144 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.219461 140331447654144 make_examples.py:1381] Created 3 examples. I1213 13:11:54.225383 140460245006080 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378618 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392364 140460245006080 make_examples.py:1324] Preparing inputs. I1213 13:11:54.905719 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.953198 140460245006080 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:25902,safety,input,input,25902,"s default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943589: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.413748 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700217 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.624783 140331447654144 make_examples.py:1363] Task 7: 0 candidates (0 examples) [17.69s elapsed]. I1213 13:12:13.050214 140331447654144 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.219461 140331447654144 make_examples.py:1381] Created 3 examples. I1213 13:11:54.225383 140460245006080 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378618 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392364 140460245006080 make_examples.py:1324] Preparing inputs. I1213 13:11:54.905719 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.953198 140460245006080 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.963092 140460245006080 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00008-of-00010.gz. I1213 13:11:54.963464 140460245006080 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00008-of-00010.gz. I1213 13:11:55.068834 140460245006080 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:26019,safety,input,inputs,26019,"--ref. 2019-12-13 13:11:54.943589: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.413748 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700217 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.624783 140331447654144 make_examples.py:1363] Task 7: 0 candidates (0 examples) [17.69s elapsed]. I1213 13:12:13.050214 140331447654144 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.219461 140331447654144 make_examples.py:1381] Created 3 examples. I1213 13:11:54.225383 140460245006080 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378618 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392364 140460245006080 make_examples.py:1324] Preparing inputs. I1213 13:11:54.905719 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.953198 140460245006080 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.963092 140460245006080 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00008-of-00010.gz. I1213 13:11:54.963464 140460245006080 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00008-of-00010.gz. I1213 13:11:55.068834 140460245006080 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.090168: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I12",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:26098,safety,input,input,26098,"Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.413748 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700217 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.624783 140331447654144 make_examples.py:1363] Task 7: 0 candidates (0 examples) [17.69s elapsed]. I1213 13:12:13.050214 140331447654144 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.219461 140331447654144 make_examples.py:1381] Created 3 examples. I1213 13:11:54.225383 140460245006080 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378618 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392364 140460245006080 make_examples.py:1324] Preparing inputs. I1213 13:11:54.905719 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.953198 140460245006080 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.963092 140460245006080 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00008-of-00010.gz. I1213 13:11:54.963464 140460245006080 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00008-of-00010.gz. I1213 13:11:55.068834 140460245006080 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.090168: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.314467 140460245006080 genomics_reader.py:223] Reading /input/HC3-B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:26823,safety,input,input,26823,"ENT. I1213 13:11:54.378618 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392364 140460245006080 make_examples.py:1324] Preparing inputs. I1213 13:11:54.905719 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.953198 140460245006080 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.963092 140460245006080 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00008-of-00010.gz. I1213 13:11:54.963464 140460245006080 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00008-of-00010.gz. I1213 13:11:55.068834 140460245006080 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.090168: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.314467 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700131 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.616221 140460245006080 make_examples.py:1363] Task 8: 0 candidates (0 examples) [17.65s elapsed]. I1213 13:12:13.152090 140460245006080 make_examples.py:1380] Found 2 candidate variants. I1213 13:12:13.250552 140460245006080 make_examples.py:1381] Created 2 examples. I1213 13:11:54.227202 140405993887488 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.386776 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:27090,safety,input,input,27090,"ing /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.953198 140460245006080 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.963092 140460245006080 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00008-of-00010.gz. I1213 13:11:54.963464 140460245006080 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00008-of-00010.gz. I1213 13:11:55.068834 140460245006080 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.090168: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.314467 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700131 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.616221 140460245006080 make_examples.py:1363] Task 8: 0 candidates (0 examples) [17.65s elapsed]. I1213 13:12:13.152090 140460245006080 make_examples.py:1380] Found 2 candidate variants. I1213 13:12:13.250552 140460245006080 make_examples.py:1381] Created 2 examples. I1213 13:11:54.227202 140405993887488 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.386776 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.398395 140405993887488 make_examples.py:1324] Preparing inputs. I1213 13:11:54.894856 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.922434 140405993887488 make_examples.py:1248] Common cont",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:27207,safety,input,input,27207,"n contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.963092 140460245006080 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00008-of-00010.gz. I1213 13:11:54.963464 140460245006080 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00008-of-00010.gz. I1213 13:11:55.068834 140460245006080 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.090168: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.314467 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700131 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.616221 140460245006080 make_examples.py:1363] Task 8: 0 candidates (0 examples) [17.65s elapsed]. I1213 13:12:13.152090 140460245006080 make_examples.py:1380] Found 2 candidate variants. I1213 13:12:13.250552 140460245006080 make_examples.py:1381] Created 2 examples. I1213 13:11:54.227202 140405993887488 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.386776 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.398395 140405993887488 make_examples.py:1324] Preparing inputs. I1213 13:11:54.894856 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.922434 140405993887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:27779,safety,input,input,27779,"s default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.090168: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.314467 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700131 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.616221 140460245006080 make_examples.py:1363] Task 8: 0 candidates (0 examples) [17.65s elapsed]. I1213 13:12:13.152090 140460245006080 make_examples.py:1380] Found 2 candidate variants. I1213 13:12:13.250552 140460245006080 make_examples.py:1381] Created 2 examples. I1213 13:11:54.227202 140405993887488 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.386776 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.398395 140405993887488 make_examples.py:1324] Preparing inputs. I1213 13:11:54.894856 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.922434 140405993887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:27896,safety,input,inputs,27896,"--ref. 2019-12-13 13:11:55.090168: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.314467 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700131 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.616221 140460245006080 make_examples.py:1363] Task 8: 0 candidates (0 examples) [17.65s elapsed]. I1213 13:12:13.152090 140460245006080 make_examples.py:1380] Found 2 candidate variants. I1213 13:12:13.250552 140460245006080 make_examples.py:1381] Created 2 examples. I1213 13:11:54.227202 140405993887488 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.386776 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.398395 140405993887488 make_examples.py:1324] Preparing inputs. I1213 13:11:54.894856 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.922434 140405993887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. rea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:27975,safety,input,input,27975,"Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.314467 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700131 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.616221 140460245006080 make_examples.py:1363] Task 8: 0 candidates (0 examples) [17.65s elapsed]. I1213 13:12:13.152090 140460245006080 make_examples.py:1380] Found 2 candidate variants. I1213 13:12:13.250552 140460245006080 make_examples.py:1381] Created 2 examples. I1213 13:11:54.227202 140405993887488 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.386776 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.398395 140405993887488 make_examples.py:1324] Preparing inputs. I1213 13:11:54.894856 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.922434 140405993887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:28700,safety,input,input,28700,"ENT. I1213 13:11:54.386776 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.398395 140405993887488 make_examples.py:1324] Preparing inputs. I1213 13:11:54.894856 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.922434 140405993887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" -",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:29041,safety,modul,module,29041,"40405993887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 1. ```. The same error develops with your WES-case-study sample file/script. It would be great to solve this problem. . Thank you in adva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:29650,safety,input,input,29650,"93887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 1. ```. The same error develops with your WES-case-study sample file/script. It would be great to solve this problem. . Thank you in advance. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:29677,safety,input,input,29677,"93887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 1. ```. The same error develops with your WES-case-study sample file/script. It would be great to solve this problem. . Thank you in advance. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:29924,safety,error,error,29924,"93887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 1. ```. The same error develops with your WES-case-study sample file/script. It would be great to solve this problem. . Thank you in advance. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3004,security,model,models,3004,"RAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:07:00.397901: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:07:01.327224 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_che",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3015,security,model,model,3015,"note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:07:00.397901: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:07:01.327224 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_se",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3750,security,model,modeling,3750,". sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528713 140638419556096 call_variants.py:381] Writing",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3780,security,model,model,3780," the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528713 140638419556096 call_variants.py:381] Writing calls to /tmp/deepvariant_tm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3893,security,model,model,3893,"output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528713 140638419556096 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 13:07:08.533111 140638419556096 deprecation.py:323] From /usr/lo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5104,security,updat,updating,5104,"rain_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528713 140638419556096 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 13:07:08.533111 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 13:07:08.550576 140638419556096 data_providers.py:367] self.input_read_threads=8. W1213 13:07:08.550924 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5554,security,updat,updating,5554,"0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528713 140638419556096 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 13:07:08.533111 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 13:07:08.550576 140638419556096 data_providers.py:367] self.input_read_threads=8. W1213 13:07:08.550924 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Grap",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5915,security,model,modeling,5915,packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 13:07:08.550576 140638419556096 data_providers.py:367] self.input_read_threads=8. W1213 13:07:08.550924 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files w,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6051,security,updat,updating,6051,be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 13:07:08.550576 140638419556096 data_providers.py:367] self.input_read_threads=8. W1213 13:07:08.550924 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6217,security,model,modeling,6217,self.input_read_threads=8. W1213 13:07:08.550924 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I12,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6348,security,updat,updating,6348,oogle_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:6865,security,updat,updating,6865,"l/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functional",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:7020,security,model,models,7020,"e version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postp",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:7031,security,model,model,7031,"Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_vari",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:7256,security,model,modeling,7256,"n.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --gvcf_ou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:7374,security,model,models,7374,"r of operator or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". 2019-12-13 13:07:22.565874: I deepvariant/postprocess_variants.cc:88] Read from: /tm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:7385,security,model,model,7385,"or or tf.math.divide. I1213 13:07:11.932379 140638419556096 estimator.py:1113] Done calling model_fn. I1213 13:07:13.617564 140638419556096 monitored_session.py:222] Graph was finalized. W1213 13:07:13.618191 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". 2019-12-13 13:07:22.565874: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/deepvaria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5135,testability,automat,automatically,5135,"': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528713 140638419556096 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 13:07:08.533111 140638419556096 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 13:07:08.550576 140638419556096 data_providers.py:367] self.input_read_threads=8. W1213 13:07:08.550924 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 13:07:08.567331 140638419556096 data_providers.py:373] self.input_map_threads=48. I1213 13:07:08.591927 140638419556096 estimator.py:1111] Calling model_fn. W1213 13:07:08.592129 140638419556096 deprecation.py:323] From /tmp/Bazel.runfiles_nYYnpl/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 13:07:08.594911 140638419556096 deprecation.py:323] F",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:7849,testability,depend,depend,7849,"ructions for updating:. Use standard file APIs to check for files with this prefix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". 2019-12-13 13:07:22.565874: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. 2019-12-13 13:07:22.566377: I deepvariant/postprocess_variants.cc:97] Done reading: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. #entries in single_site_calls = 28. 2019-12-13 13:07:22.566443: I deepvariant/postprocess_variants.cc:101] Total #entries in single_site_calls = 28. 2019-12-13 13:07:22.566459: I deepvariant/postprocess_variants.cc:103] Start SortSingleSiteCalls. 2019-12-13 13:07:22.566",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:28943,testability,Trace,Traceback,28943,"cs_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.922434 140405993887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 1. ```. The same error develops with your",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:133,usability,input,input,133,"Thank you akolesikov, . Yes, it works without num_shards flag. . Here is the output. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:07:00.156721 139885760198400 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:07:00.265611 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.277568 139885760198400 make_examples.py:1324] Preparing inputs. I1213 13:07:00.354827 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.377454 139885760198400 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:07:00.383280 139885760198400 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00001.gz. I1213 13:07:00.383569 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:308,usability,input,input,308,"Thank you akolesikov, . Yes, it works without num_shards flag. . Here is the output. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:07:00.156721 139885760198400 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:07:00.265611 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.277568 139885760198400 make_examples.py:1324] Preparing inputs. I1213 13:07:00.354827 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.377454 139885760198400 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:07:00.383280 139885760198400 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00001.gz. I1213 13:07:00.383569 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:338,usability,input,input,338,"Thank you akolesikov, . Yes, it works without num_shards flag. . Here is the output. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:07:00.156721 139885760198400 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:07:00.265611 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.277568 139885760198400 make_examples.py:1324] Preparing inputs. I1213 13:07:00.354827 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.377454 139885760198400 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:07:00.383280 139885760198400 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00001.gz. I1213 13:07:00.383569 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:508,usability,command,command,508,"Thank you akolesikov, . Yes, it works without num_shards flag. . Here is the output. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:07:00.156721 139885760198400 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:07:00.265611 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.277568 139885760198400 make_examples.py:1324] Preparing inputs. I1213 13:07:00.354827 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.377454 139885760198400 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:07:00.383280 139885760198400 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00001.gz. I1213 13:07:00.383569 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:622,usability,input,input,622,"Thank you akolesikov, . Yes, it works without num_shards flag. . Here is the output. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:07:00.156721 139885760198400 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:07:00.265611 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.277568 139885760198400 make_examples.py:1324] Preparing inputs. I1213 13:07:00.354827 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.377454 139885760198400 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:07:00.383280 139885760198400 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00001.gz. I1213 13:07:00.383569 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:649,usability,input,input,649,"Thank you akolesikov, . Yes, it works without num_shards flag. . Here is the output. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:07:00.156721 139885760198400 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:07:00.265611 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.277568 139885760198400 make_examples.py:1324] Preparing inputs. I1213 13:07:00.354827 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.377454 139885760198400 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:07:00.383280 139885760198400 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00001.gz. I1213 13:07:00.383569 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:1090,usability,input,input,1090,"udo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:07:00.156721 139885760198400 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:07:00.265611 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.277568 139885760198400 make_examples.py:1324] Preparing inputs. I1213 13:07:00.354827 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.377454 139885760198400 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:07:00.383280 139885760198400 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00001.gz. I1213 13:07:00.383569 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:1207,usability,input,inputs,1207,"iant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:07:00.156721 139885760198400 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:07:00.265611 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.277568 139885760198400 make_examples.py:1324] Preparing inputs. I1213 13:07:00.354827 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.377454 139885760198400 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:07:00.383280 139885760198400 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00001.gz. I1213 13:07:00.383569 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:07:00.397901: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I12",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:1286,usability,input,input,1286,"pe=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:07:00.156721 139885760198400 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:07:00.265611 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.277568 139885760198400 make_examples.py:1324] Preparing inputs. I1213 13:07:00.354827 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.377454 139885760198400 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:07:00.383280 139885760198400 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00001.gz. I1213 13:07:00.383569 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:07:00.397901: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:07:01.327224 139885760198400 genomics_reader.py:223] Reading /input/HC3-B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2011,usability,input,input,2011,"ENT. I1213 13:07:00.265611 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.277568 139885760198400 make_examples.py:1324] Preparing inputs. I1213 13:07:00.354827 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.377454 139885760198400 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:07:00.383280 139885760198400 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00001.gz. I1213 13:07:00.383569 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:07:00.397901: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:07:01.327224 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2278,usability,input,input,2278,"ing /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:00.377454 139885760198400 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:07:00.383280 139885760198400 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00001.gz. I1213 13:07:00.383569 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:07:00.397901: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:07:01.327224 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2395,usability,input,input,2395,"n contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:07:00.383280 139885760198400 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00001.gz. I1213 13:07:00.383569 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:07:00.397901: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:07:01.327224 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2741,usability,user,user,2741," 139885760198400 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:07:00.397901: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:07:01.327224 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2788,usability,command,command,2788,"vcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00001.gz. I1213 13:07:00.394412 139885760198400 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:07:00.397901: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:07:01.327224 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:01.414663 139885760198400 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:07:02.310832 139885760198400 make_examples.py:1363] Task 0: 0 candidates (0 examples) [1.93s elapsed]. I1213 13:07:05.401592 139885760198400 make_examples.py:1380] Found 28 candidate variants. I1213 13:07:05.402002 139885760198400 make_examples.py:1381] Created 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with r",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3699,usability,perform,performance,3699,"reated 28 examples. real	0m10.204s. user	0m5.490s. sys	0m3.310s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 13:07:08.439639 140638419556096 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 13:07:08.488881: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 13:07:08.491470: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x58612b0 executing computations on platform Host. Devices:. 2019-12-13 13:07:08.491562: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 13:07:08.495160: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 13:07:08.525229 140638419556096 modeling.py:560] Initializing model with random parameters. W1213 13:07:08.527353 140638419556096 estimator.py:1760] Using temporary folder as model directory: /tmp/tmpr4M5u5. I1213 13:07:08.528274 140638419556096 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe88a5b6190>, '_model_dir': '/tmp/tmpr4M5u5', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 13:07:08.528",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:7929,usability,user,user,7929,"fix. I1213 13:07:13.621948 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". 2019-12-13 13:07:22.565874: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. 2019-12-13 13:07:22.566377: I deepvariant/postprocess_variants.cc:97] Done reading: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. #entries in single_site_calls = 28. 2019-12-13 13:07:22.566443: I deepvariant/postprocess_variants.cc:101] Total #entries in single_site_calls = 28. 2019-12-13 13:07:22.566459: I deepvariant/postprocess_variants.cc:103] Start SortSingleSiteCalls. 2019-12-13 13:07:22.566492: I deepvariant/postprocess_variants.cc:105] Done SortSingleSiteCalls. I1213",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:7977,usability,command,command,7977,"y:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". 2019-12-13 13:07:22.565874: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. 2019-12-13 13:07:22.566377: I deepvariant/postprocess_variants.cc:97] Done reading: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. #entries in single_site_calls = 28. 2019-12-13 13:07:22.566443: I deepvariant/postprocess_variants.cc:101] Total #entries in single_site_calls = 28. 2019-12-13 13:07:22.566459: I deepvariant/postprocess_variants.cc:103] Start SortSingleSiteCalls. 2019-12-13 13:07:22.566492: I deepvariant/postprocess_variants.cc:105] Done SortSingleSiteCalls. I1213 13:07:22.566857 139950873712384 postprocess_varia",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:8047,usability,input,input,8047,"3:07:15.663943 140638419556096 session_manager.py:491] Running local_init_op. I1213 13:07:15.711944 140638419556096 session_manager.py:493] Done running local_init_op. I1213 13:07:16.176234 140638419556096 modeling.py:410] Reloading EMA... I1213 13:07:16.177736 140638419556096 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 13:07:20.278557 140638419556096 call_variants.py:399] Processed 1 examples in 1 batches [1174.939 sec per 100]. I1213 13:07:20.328917 140638419556096 call_variants.py:401] Done evaluating variants. WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see:. * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md. * https://github.com/tensorflow/addons. If you depend on functionality not listed there, please file an issue. real	0m15.024s. user	0m13.890s. sys	0m3.410s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/genome.fa"" --infile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". 2019-12-13 13:07:22.565874: I deepvariant/postprocess_variants.cc:88] Read from: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. 2019-12-13 13:07:22.566377: I deepvariant/postprocess_variants.cc:97] Done reading: /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. #entries in single_site_calls = 28. 2019-12-13 13:07:22.566443: I deepvariant/postprocess_variants.cc:101] Total #entries in single_site_calls = 28. 2019-12-13 13:07:22.566459: I deepvariant/postprocess_variants.cc:103] Start SortSingleSiteCalls. 2019-12-13 13:07:22.566492: I deepvariant/postprocess_variants.cc:105] Done SortSingleSiteCalls. I1213 13:07:22.566857 139950873712384 postprocess_variants.py:972] CVO sorting took 1.82509422302e-05 minutes. I1213 13:07:2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:9751,usability,user,user,9751,"6459: I deepvariant/postprocess_variants.cc:103] Start SortSingleSiteCalls. 2019-12-13 13:07:22.566492: I deepvariant/postprocess_variants.cc:105] Done SortSingleSiteCalls. I1213 13:07:22.566857 139950873712384 postprocess_variants.py:972] CVO sorting took 1.82509422302e-05 minutes. I1213 13:07:22.567840 139950873712384 postprocess_variants.py:974] Transforming call_variants_output to variants. I1213 13:07:22.568222 139950873712384 postprocess_variants.py:1000] Merging and writing variants to VCF and gVCF. I1213 13:07:22.570799 139950873712384 genomics_writer.py:172] Writing /output/output.vcf.gz with NativeVcfWriter. I1213 13:07:22.573292 139950873712384 genomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. I1213 13:07:22.661263 139950873712384 postprocess_variants.py:1020] Finished writing VCF and gVCF in 0.00155058304469 minutes. I1213 13:07:22.678944 139950873712384 genomics_reader.py:223] Reading /output/output.vcf.gz with NativeVcfReader. real	0m2.697s. user	0m2.250s. sys	0m1.410s. ```. When it didn't work with num_shards flag, the entire output was like this. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=10. ***** Running the command:*****. time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:11:54.227790 140490637805312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:9908,usability,input,input,9908,"ngleSiteCalls. I1213 13:07:22.566857 139950873712384 postprocess_variants.py:972] CVO sorting took 1.82509422302e-05 minutes. I1213 13:07:22.567840 139950873712384 postprocess_variants.py:974] Transforming call_variants_output to variants. I1213 13:07:22.568222 139950873712384 postprocess_variants.py:1000] Merging and writing variants to VCF and gVCF. I1213 13:07:22.570799 139950873712384 genomics_writer.py:172] Writing /output/output.vcf.gz with NativeVcfWriter. I1213 13:07:22.573292 139950873712384 genomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. I1213 13:07:22.661263 139950873712384 postprocess_variants.py:1020] Finished writing VCF and gVCF in 0.00155058304469 minutes. I1213 13:07:22.678944 139950873712384 genomics_reader.py:223] Reading /output/output.vcf.gz with NativeVcfReader. real	0m2.697s. user	0m2.250s. sys	0m1.410s. ```. When it didn't work with num_shards flag, the entire output was like this. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=10. ***** Running the command:*****. time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:11:54.227790 140490637805312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379641 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam w",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:10083,usability,input,input,10083,"_variants.py:974] Transforming call_variants_output to variants. I1213 13:07:22.568222 139950873712384 postprocess_variants.py:1000] Merging and writing variants to VCF and gVCF. I1213 13:07:22.570799 139950873712384 genomics_writer.py:172] Writing /output/output.vcf.gz with NativeVcfWriter. I1213 13:07:22.573292 139950873712384 genomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. I1213 13:07:22.661263 139950873712384 postprocess_variants.py:1020] Finished writing VCF and gVCF in 0.00155058304469 minutes. I1213 13:07:22.678944 139950873712384 genomics_reader.py:223] Reading /output/output.vcf.gz with NativeVcfReader. real	0m2.697s. user	0m2.250s. sys	0m1.410s. ```. When it didn't work with num_shards flag, the entire output was like this. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=10. ***** Running the command:*****. time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:11:54.227790 140490637805312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379641 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392796 140490637805312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.896145 140490637805312 genomics_reader.py:223] Reading /inpu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:10113,usability,input,input,10113," call_variants_output to variants. I1213 13:07:22.568222 139950873712384 postprocess_variants.py:1000] Merging and writing variants to VCF and gVCF. I1213 13:07:22.570799 139950873712384 genomics_writer.py:172] Writing /output/output.vcf.gz with NativeVcfWriter. I1213 13:07:22.573292 139950873712384 genomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. I1213 13:07:22.661263 139950873712384 postprocess_variants.py:1020] Finished writing VCF and gVCF in 0.00155058304469 minutes. I1213 13:07:22.678944 139950873712384 genomics_reader.py:223] Reading /output/output.vcf.gz with NativeVcfReader. real	0m2.697s. user	0m2.250s. sys	0m1.410s. ```. When it didn't work with num_shards flag, the entire output was like this. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=10. ***** Running the command:*****. time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:11:54.227790 140490637805312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379641 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392796 140490637805312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.896145 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with Nativ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:10302,usability,command,command,10302,"omics_writer.py:172] Writing /output/output.vcf.gz with NativeVcfWriter. I1213 13:07:22.573292 139950873712384 genomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. I1213 13:07:22.661263 139950873712384 postprocess_variants.py:1020] Finished writing VCF and gVCF in 0.00155058304469 minutes. I1213 13:07:22.678944 139950873712384 genomics_reader.py:223] Reading /output/output.vcf.gz with NativeVcfReader. real	0m2.697s. user	0m2.250s. sys	0m1.410s. ```. When it didn't work with num_shards flag, the entire output was like this. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=10. ***** Running the command:*****. time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:11:54.227790 140490637805312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379641 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392796 140490637805312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.896145 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.944020 140490637805312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:10416,usability,input,input,10416,"nomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. I1213 13:07:22.661263 139950873712384 postprocess_variants.py:1020] Finished writing VCF and gVCF in 0.00155058304469 minutes. I1213 13:07:22.678944 139950873712384 genomics_reader.py:223] Reading /output/output.vcf.gz with NativeVcfReader. real	0m2.697s. user	0m2.250s. sys	0m1.410s. ```. When it didn't work with num_shards flag, the entire output was like this. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=10. ***** Running the command:*****. time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:11:54.227790 140490637805312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379641 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392796 140490637805312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.896145 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.944020 140490637805312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.960778 140490637805312 make_examples.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:10443,usability,input,input,10443,"ng /output/output.g.vcf.gz with NativeVcfWriter. I1213 13:07:22.661263 139950873712384 postprocess_variants.py:1020] Finished writing VCF and gVCF in 0.00155058304469 minutes. I1213 13:07:22.678944 139950873712384 genomics_reader.py:223] Reading /output/output.vcf.gz with NativeVcfReader. real	0m2.697s. user	0m2.250s. sys	0m1.410s. ```. When it didn't work with num_shards flag, the entire output was like this. ```. $ sudo docker run \. > -v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=10. ***** Running the command:*****. time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:11:54.227790 140490637805312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379641 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392796 140490637805312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.896145 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.944020 140490637805312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.960778 140490637805312 make_examples.py:1330] Writing examples t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:10886,usability,input,input,10886,"v ""${INPUT_DIR}"":""/input"" \. > -v ""${OUTPUT_DIR}:/output"" \. > gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=10. ***** Running the command:*****. time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:11:54.227790 140490637805312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379641 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392796 140490637805312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.896145 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.944020 140490637805312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.960778 140490637805312 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00010.gz. I1213 13:11:54.961548 140490637805312 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00010.gz. I1213 13:11:55.068834 140490637805312 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:11003,usability,input,inputs,11003," \. > /opt/deepvariant/bin/run_deepvariant \. > --model_type=WES \. > --ref=/input/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=10. ***** Running the command:*****. time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:11:54.227790 140490637805312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379641 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392796 140490637805312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.896145 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.944020 140490637805312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.960778 140490637805312 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00010.gz. I1213 13:11:54.961548 140490637805312 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00010.gz. I1213 13:11:55.068834 140490637805312 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.109412: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I12",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:11082,usability,input,input,11082,"put/genome.fa \. > --reads=/input/HC3-BC_RG_bwa.bam \. > --regions ""20:10,000,000-10,100,000"" \. > --output_vcf=/output/output.vcf.gz \. > --output_gvcf=/output/output.g.vcf.gz \. > --num_shards=10. ***** Running the command:*****. time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}. I1213 13:11:54.227790 140490637805312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379641 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392796 140490637805312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.896145 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.944020 140490637805312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.960778 140490637805312 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00010.gz. I1213 13:11:54.961548 140490637805312 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00010.gz. I1213 13:11:55.068834 140490637805312 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.109412: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.427617 140490637805312 genomics_reader.py:223] Reading /input/HC3-B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:11807,usability,input,input,11807,"ENT. I1213 13:11:54.379641 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392796 140490637805312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.896145 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.944020 140490637805312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.960778 140490637805312 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00010.gz. I1213 13:11:54.961548 140490637805312 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00010.gz. I1213 13:11:55.068834 140490637805312 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.109412: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.427617 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700349 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.598862 140490637805312 make_examples.py:1363] Task 0: 0 candidates (0 examples) [17.64s elapsed]. I1213 13:12:13.068409 140490637805312 make_examples.py:1380] Found 1 candidate variants. I1213 13:12:13.223464 140490637805312 make_examples.py:1381] Created 1 examples. I1213 13:11:54.226648 140402484717312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.767545 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:12074,usability,input,input,12074,"ing /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.944020 140490637805312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.960778 140490637805312 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00010.gz. I1213 13:11:54.961548 140490637805312 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00010.gz. I1213 13:11:55.068834 140490637805312 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.109412: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.427617 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700349 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.598862 140490637805312 make_examples.py:1363] Task 0: 0 candidates (0 examples) [17.64s elapsed]. I1213 13:12:13.068409 140490637805312 make_examples.py:1380] Found 1 candidate variants. I1213 13:12:13.223464 140490637805312 make_examples.py:1381] Created 1 examples. I1213 13:11:54.226648 140402484717312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.767545 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.788374 140402484717312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.979619 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:55.010253 140402484717312 make_examples.py:1248] Common cont",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:12191,usability,input,input,12191,"n contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.960778 140490637805312 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00000-of-00010.gz. I1213 13:11:54.961548 140490637805312 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00000-of-00010.gz. I1213 13:11:55.068834 140490637805312 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.109412: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.427617 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700349 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.598862 140490637805312 make_examples.py:1363] Task 0: 0 candidates (0 examples) [17.64s elapsed]. I1213 13:12:13.068409 140490637805312 make_examples.py:1380] Found 1 candidate variants. I1213 13:12:13.223464 140490637805312 make_examples.py:1381] Created 1 examples. I1213 13:11:54.226648 140402484717312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.767545 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.788374 140402484717312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.979619 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:55.010253 140402484717312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:12763,usability,input,input,12763,"s default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.109412: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.427617 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700349 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.598862 140490637805312 make_examples.py:1363] Task 0: 0 candidates (0 examples) [17.64s elapsed]. I1213 13:12:13.068409 140490637805312 make_examples.py:1380] Found 1 candidate variants. I1213 13:12:13.223464 140490637805312 make_examples.py:1381] Created 1 examples. I1213 13:11:54.226648 140402484717312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.767545 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.788374 140402484717312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.979619 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:55.010253 140402484717312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:55.017723 140402484717312 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00001-of-00010.gz. I1213 13:11:55.018065 140402484717312 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00001-of-00010.gz. I1213 13:11:55.107007 140402484717312 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:12880,usability,input,inputs,12880,"--ref. 2019-12-13 13:11:55.109412: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.427617 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700349 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.598862 140490637805312 make_examples.py:1363] Task 0: 0 candidates (0 examples) [17.64s elapsed]. I1213 13:12:13.068409 140490637805312 make_examples.py:1380] Found 1 candidate variants. I1213 13:12:13.223464 140490637805312 make_examples.py:1381] Created 1 examples. I1213 13:11:54.226648 140402484717312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.767545 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.788374 140402484717312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.979619 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:55.010253 140402484717312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:55.017723 140402484717312 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00001-of-00010.gz. I1213 13:11:55.018065 140402484717312 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00001-of-00010.gz. I1213 13:11:55.107007 140402484717312 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.127048: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I12",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:12959,usability,input,input,12959,"Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.427617 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700349 140490637805312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.598862 140490637805312 make_examples.py:1363] Task 0: 0 candidates (0 examples) [17.64s elapsed]. I1213 13:12:13.068409 140490637805312 make_examples.py:1380] Found 1 candidate variants. I1213 13:12:13.223464 140490637805312 make_examples.py:1381] Created 1 examples. I1213 13:11:54.226648 140402484717312 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.767545 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.788374 140402484717312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.979619 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:55.010253 140402484717312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:55.017723 140402484717312 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00001-of-00010.gz. I1213 13:11:55.018065 140402484717312 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00001-of-00010.gz. I1213 13:11:55.107007 140402484717312 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.127048: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.412683 140402484717312 genomics_reader.py:223] Reading /input/HC3-B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:13684,usability,input,input,13684,"ENT. I1213 13:11:54.767545 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.788374 140402484717312 make_examples.py:1324] Preparing inputs. I1213 13:11:54.979619 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:55.010253 140402484717312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:55.017723 140402484717312 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00001-of-00010.gz. I1213 13:11:55.018065 140402484717312 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00001-of-00010.gz. I1213 13:11:55.107007 140402484717312 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.127048: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.412683 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.702708 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.676522 140402484717312 make_examples.py:1363] Task 1: 4 candidates (4 examples) [17.66s elapsed]. I1213 13:12:13.028630 140402484717312 make_examples.py:1380] Found 7 candidate variants. I1213 13:12:13.211899 140402484717312 make_examples.py:1381] Created 7 examples. I1213 13:11:54.225912 139798917543680 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.380671 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:13951,usability,input,input,13951,"ing /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:55.010253 140402484717312 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:55.017723 140402484717312 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00001-of-00010.gz. I1213 13:11:55.018065 140402484717312 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00001-of-00010.gz. I1213 13:11:55.107007 140402484717312 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.127048: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.412683 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.702708 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.676522 140402484717312 make_examples.py:1363] Task 1: 4 candidates (4 examples) [17.66s elapsed]. I1213 13:12:13.028630 140402484717312 make_examples.py:1380] Found 7 candidate variants. I1213 13:12:13.211899 140402484717312 make_examples.py:1381] Created 7 examples. I1213 13:11:54.225912 139798917543680 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.380671 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.394714 139798917543680 make_examples.py:1324] Preparing inputs. I1213 13:11:54.895178 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.923032 139798917543680 make_examples.py:1248] Common cont",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:14068,usability,input,input,14068,"n contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:55.017723 140402484717312 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00001-of-00010.gz. I1213 13:11:55.018065 140402484717312 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00001-of-00010.gz. I1213 13:11:55.107007 140402484717312 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.127048: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.412683 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.702708 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.676522 140402484717312 make_examples.py:1363] Task 1: 4 candidates (4 examples) [17.66s elapsed]. I1213 13:12:13.028630 140402484717312 make_examples.py:1380] Found 7 candidate variants. I1213 13:12:13.211899 140402484717312 make_examples.py:1381] Created 7 examples. I1213 13:11:54.225912 139798917543680 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.380671 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.394714 139798917543680 make_examples.py:1324] Preparing inputs. I1213 13:11:54.895178 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.923032 139798917543680 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:14640,usability,input,input,14640,"s default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.127048: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.412683 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.702708 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.676522 140402484717312 make_examples.py:1363] Task 1: 4 candidates (4 examples) [17.66s elapsed]. I1213 13:12:13.028630 140402484717312 make_examples.py:1380] Found 7 candidate variants. I1213 13:12:13.211899 140402484717312 make_examples.py:1381] Created 7 examples. I1213 13:11:54.225912 139798917543680 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.380671 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.394714 139798917543680 make_examples.py:1324] Preparing inputs. I1213 13:11:54.895178 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.923032 139798917543680 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.930289 139798917543680 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00002-of-00010.gz. I1213 13:11:54.930751 139798917543680 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00002-of-00010.gz. I1213 13:11:54.940401 139798917543680 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:14757,usability,input,inputs,14757,"--ref. 2019-12-13 13:11:55.127048: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.412683 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.702708 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.676522 140402484717312 make_examples.py:1363] Task 1: 4 candidates (4 examples) [17.66s elapsed]. I1213 13:12:13.028630 140402484717312 make_examples.py:1380] Found 7 candidate variants. I1213 13:12:13.211899 140402484717312 make_examples.py:1381] Created 7 examples. I1213 13:11:54.225912 139798917543680 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.380671 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.394714 139798917543680 make_examples.py:1324] Preparing inputs. I1213 13:11:54.895178 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.923032 139798917543680 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.930289 139798917543680 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00002-of-00010.gz. I1213 13:11:54.930751 139798917543680 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00002-of-00010.gz. I1213 13:11:54.940401 139798917543680 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943675: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I12",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:14836,usability,input,input,14836,"Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.412683 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.702708 140402484717312 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.676522 140402484717312 make_examples.py:1363] Task 1: 4 candidates (4 examples) [17.66s elapsed]. I1213 13:12:13.028630 140402484717312 make_examples.py:1380] Found 7 candidate variants. I1213 13:12:13.211899 140402484717312 make_examples.py:1381] Created 7 examples. I1213 13:11:54.225912 139798917543680 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.380671 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.394714 139798917543680 make_examples.py:1324] Preparing inputs. I1213 13:11:54.895178 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.923032 139798917543680 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.930289 139798917543680 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00002-of-00010.gz. I1213 13:11:54.930751 139798917543680 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00002-of-00010.gz. I1213 13:11:54.940401 139798917543680 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943675: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.334026 139798917543680 genomics_reader.py:223] Reading /input/HC3-B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:15561,usability,input,input,15561,"ENT. I1213 13:11:54.380671 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.394714 139798917543680 make_examples.py:1324] Preparing inputs. I1213 13:11:54.895178 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.923032 139798917543680 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.930289 139798917543680 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00002-of-00010.gz. I1213 13:11:54.930751 139798917543680 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00002-of-00010.gz. I1213 13:11:54.940401 139798917543680 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943675: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.334026 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.708316 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.659555 139798917543680 make_examples.py:1363] Task 2: 3 candidates (3 examples) [17.73s elapsed]. I1213 13:12:13.045805 139798917543680 make_examples.py:1380] Found 7 candidate variants. I1213 13:12:13.209331 139798917543680 make_examples.py:1381] Created 7 examples. I1213 13:11:54.227793 140236020647680 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.403919 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:15828,usability,input,input,15828,"ing /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.923032 139798917543680 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.930289 139798917543680 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00002-of-00010.gz. I1213 13:11:54.930751 139798917543680 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00002-of-00010.gz. I1213 13:11:54.940401 139798917543680 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943675: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.334026 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.708316 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.659555 139798917543680 make_examples.py:1363] Task 2: 3 candidates (3 examples) [17.73s elapsed]. I1213 13:12:13.045805 139798917543680 make_examples.py:1380] Found 7 candidate variants. I1213 13:12:13.209331 139798917543680 make_examples.py:1381] Created 7 examples. I1213 13:11:54.227793 140236020647680 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.403919 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.414350 140236020647680 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893651 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920942 140236020647680 make_examples.py:1248] Common cont",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:15945,usability,input,input,15945,"n contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.930289 139798917543680 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00002-of-00010.gz. I1213 13:11:54.930751 139798917543680 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00002-of-00010.gz. I1213 13:11:54.940401 139798917543680 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943675: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.334026 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.708316 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.659555 139798917543680 make_examples.py:1363] Task 2: 3 candidates (3 examples) [17.73s elapsed]. I1213 13:12:13.045805 139798917543680 make_examples.py:1380] Found 7 candidate variants. I1213 13:12:13.209331 139798917543680 make_examples.py:1381] Created 7 examples. I1213 13:11:54.227793 140236020647680 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.403919 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.414350 140236020647680 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893651 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920942 140236020647680 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:16517,usability,input,input,16517,"s default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943675: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.334026 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.708316 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.659555 139798917543680 make_examples.py:1363] Task 2: 3 candidates (3 examples) [17.73s elapsed]. I1213 13:12:13.045805 139798917543680 make_examples.py:1380] Found 7 candidate variants. I1213 13:12:13.209331 139798917543680 make_examples.py:1381] Created 7 examples. I1213 13:11:54.227793 140236020647680 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.403919 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.414350 140236020647680 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893651 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920942 140236020647680 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928174 140236020647680 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00003-of-00010.gz. I1213 13:11:54.928524 140236020647680 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00003-of-00010.gz. I1213 13:11:54.940502 140236020647680 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:16634,usability,input,inputs,16634,"--ref. 2019-12-13 13:11:54.943675: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.334026 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.708316 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.659555 139798917543680 make_examples.py:1363] Task 2: 3 candidates (3 examples) [17.73s elapsed]. I1213 13:12:13.045805 139798917543680 make_examples.py:1380] Found 7 candidate variants. I1213 13:12:13.209331 139798917543680 make_examples.py:1381] Created 7 examples. I1213 13:11:54.227793 140236020647680 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.403919 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.414350 140236020647680 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893651 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920942 140236020647680 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928174 140236020647680 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00003-of-00010.gz. I1213 13:11:54.928524 140236020647680 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00003-of-00010.gz. I1213 13:11:54.940502 140236020647680 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943561: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I12",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:16713,usability,input,input,16713,"Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.334026 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.708316 139798917543680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.659555 139798917543680 make_examples.py:1363] Task 2: 3 candidates (3 examples) [17.73s elapsed]. I1213 13:12:13.045805 139798917543680 make_examples.py:1380] Found 7 candidate variants. I1213 13:12:13.209331 139798917543680 make_examples.py:1381] Created 7 examples. I1213 13:11:54.227793 140236020647680 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.403919 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.414350 140236020647680 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893651 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920942 140236020647680 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928174 140236020647680 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00003-of-00010.gz. I1213 13:11:54.928524 140236020647680 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00003-of-00010.gz. I1213 13:11:54.940502 140236020647680 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943561: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.417463 140236020647680 genomics_reader.py:223] Reading /input/HC3-B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:17438,usability,input,input,17438,"ENT. I1213 13:11:54.403919 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.414350 140236020647680 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893651 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920942 140236020647680 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928174 140236020647680 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00003-of-00010.gz. I1213 13:11:54.928524 140236020647680 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00003-of-00010.gz. I1213 13:11:54.940502 140236020647680 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943561: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.417463 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.708851 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.610981 140236020647680 make_examples.py:1363] Task 3: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:13.094532 140236020647680 make_examples.py:1380] Found 1 candidate variants. I1213 13:12:13.241935 140236020647680 make_examples.py:1381] Created 1 examples. I1213 13:11:54.226402 140097611171584 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378241 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:17705,usability,input,input,17705,"ing /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920942 140236020647680 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928174 140236020647680 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00003-of-00010.gz. I1213 13:11:54.928524 140236020647680 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00003-of-00010.gz. I1213 13:11:54.940502 140236020647680 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943561: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.417463 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.708851 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.610981 140236020647680 make_examples.py:1363] Task 3: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:13.094532 140236020647680 make_examples.py:1380] Found 1 candidate variants. I1213 13:12:13.241935 140236020647680 make_examples.py:1381] Created 1 examples. I1213 13:11:54.226402 140097611171584 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378241 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391170 140097611171584 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893971 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921802 140097611171584 make_examples.py:1248] Common cont",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:17822,usability,input,input,17822,"n contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928174 140236020647680 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00003-of-00010.gz. I1213 13:11:54.928524 140236020647680 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00003-of-00010.gz. I1213 13:11:54.940502 140236020647680 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943561: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.417463 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.708851 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.610981 140236020647680 make_examples.py:1363] Task 3: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:13.094532 140236020647680 make_examples.py:1380] Found 1 candidate variants. I1213 13:12:13.241935 140236020647680 make_examples.py:1381] Created 1 examples. I1213 13:11:54.226402 140097611171584 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378241 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391170 140097611171584 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893971 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921802 140097611171584 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:18394,usability,input,input,18394,"s default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943561: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.417463 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.708851 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.610981 140236020647680 make_examples.py:1363] Task 3: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:13.094532 140236020647680 make_examples.py:1380] Found 1 candidate variants. I1213 13:12:13.241935 140236020647680 make_examples.py:1381] Created 1 examples. I1213 13:11:54.226402 140097611171584 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378241 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391170 140097611171584 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893971 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921802 140097611171584 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928759 140097611171584 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00004-of-00010.gz. I1213 13:11:54.929138 140097611171584 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00004-of-00010.gz. I1213 13:11:54.940500 140097611171584 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:18511,usability,input,inputs,18511,"--ref. 2019-12-13 13:11:54.943561: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.417463 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.708851 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.610981 140236020647680 make_examples.py:1363] Task 3: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:13.094532 140236020647680 make_examples.py:1380] Found 1 candidate variants. I1213 13:12:13.241935 140236020647680 make_examples.py:1381] Created 1 examples. I1213 13:11:54.226402 140097611171584 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378241 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391170 140097611171584 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893971 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921802 140097611171584 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928759 140097611171584 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00004-of-00010.gz. I1213 13:11:54.929138 140097611171584 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00004-of-00010.gz. I1213 13:11:54.940500 140097611171584 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943644: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I12",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:18590,usability,input,input,18590,"Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.417463 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.708851 140236020647680 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.610981 140236020647680 make_examples.py:1363] Task 3: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:13.094532 140236020647680 make_examples.py:1380] Found 1 candidate variants. I1213 13:12:13.241935 140236020647680 make_examples.py:1381] Created 1 examples. I1213 13:11:54.226402 140097611171584 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378241 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391170 140097611171584 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893971 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921802 140097611171584 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928759 140097611171584 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00004-of-00010.gz. I1213 13:11:54.929138 140097611171584 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00004-of-00010.gz. I1213 13:11:54.940500 140097611171584 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943644: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.388587 140097611171584 genomics_reader.py:223] Reading /input/HC3-B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:19315,usability,input,input,19315,"ENT. I1213 13:11:54.378241 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391170 140097611171584 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893971 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921802 140097611171584 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928759 140097611171584 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00004-of-00010.gz. I1213 13:11:54.929138 140097611171584 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00004-of-00010.gz. I1213 13:11:54.940500 140097611171584 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943644: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.388587 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700193 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.595916 140097611171584 make_examples.py:1363] Task 4: 0 candidates (0 examples) [17.66s elapsed]. I1213 13:12:13.016803 140097611171584 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.202656 140097611171584 make_examples.py:1381] Created 3 examples. I1213 13:11:54.224806 139902364522240 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.382869 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:19582,usability,input,input,19582,"ing /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921802 140097611171584 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928759 140097611171584 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00004-of-00010.gz. I1213 13:11:54.929138 140097611171584 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00004-of-00010.gz. I1213 13:11:54.940500 140097611171584 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943644: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.388587 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700193 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.595916 140097611171584 make_examples.py:1363] Task 4: 0 candidates (0 examples) [17.66s elapsed]. I1213 13:12:13.016803 140097611171584 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.202656 140097611171584 make_examples.py:1381] Created 3 examples. I1213 13:11:54.224806 139902364522240 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.382869 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.396718 139902364522240 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893652 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920939 139902364522240 make_examples.py:1248] Common cont",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:19699,usability,input,input,19699,"n contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928759 140097611171584 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00004-of-00010.gz. I1213 13:11:54.929138 140097611171584 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00004-of-00010.gz. I1213 13:11:54.940500 140097611171584 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943644: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.388587 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700193 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.595916 140097611171584 make_examples.py:1363] Task 4: 0 candidates (0 examples) [17.66s elapsed]. I1213 13:12:13.016803 140097611171584 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.202656 140097611171584 make_examples.py:1381] Created 3 examples. I1213 13:11:54.224806 139902364522240 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.382869 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.396718 139902364522240 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893652 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920939 139902364522240 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:20271,usability,input,input,20271,"s default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943644: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.388587 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700193 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.595916 140097611171584 make_examples.py:1363] Task 4: 0 candidates (0 examples) [17.66s elapsed]. I1213 13:12:13.016803 140097611171584 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.202656 140097611171584 make_examples.py:1381] Created 3 examples. I1213 13:11:54.224806 139902364522240 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.382869 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.396718 139902364522240 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893652 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920939 139902364522240 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928069 139902364522240 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00005-of-00010.gz. I1213 13:11:54.928409 139902364522240 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00005-of-00010.gz. I1213 13:11:54.940448 139902364522240 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:20388,usability,input,inputs,20388,"--ref. 2019-12-13 13:11:54.943644: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.388587 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700193 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.595916 140097611171584 make_examples.py:1363] Task 4: 0 candidates (0 examples) [17.66s elapsed]. I1213 13:12:13.016803 140097611171584 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.202656 140097611171584 make_examples.py:1381] Created 3 examples. I1213 13:11:54.224806 139902364522240 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.382869 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.396718 139902364522240 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893652 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920939 139902364522240 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928069 139902364522240 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00005-of-00010.gz. I1213 13:11:54.928409 139902364522240 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00005-of-00010.gz. I1213 13:11:54.940448 139902364522240 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943632: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I12",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:20467,usability,input,input,20467,"Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.388587 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700193 140097611171584 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.595916 140097611171584 make_examples.py:1363] Task 4: 0 candidates (0 examples) [17.66s elapsed]. I1213 13:12:13.016803 140097611171584 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.202656 140097611171584 make_examples.py:1381] Created 3 examples. I1213 13:11:54.224806 139902364522240 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.382869 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.396718 139902364522240 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893652 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920939 139902364522240 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928069 139902364522240 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00005-of-00010.gz. I1213 13:11:54.928409 139902364522240 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00005-of-00010.gz. I1213 13:11:54.940448 139902364522240 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943632: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.312068 139902364522240 genomics_reader.py:223] Reading /input/HC3-B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:21192,usability,input,input,21192,"ENT. I1213 13:11:54.382869 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.396718 139902364522240 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893652 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920939 139902364522240 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928069 139902364522240 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00005-of-00010.gz. I1213 13:11:54.928409 139902364522240 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00005-of-00010.gz. I1213 13:11:54.940448 139902364522240 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943632: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.312068 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.712960 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.605319 139902364522240 make_examples.py:1363] Task 5: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:12.983227 139902364522240 make_examples.py:1380] Found 0 candidate variants. I1213 13:12:13.147787 139902364522240 make_examples.py:1381] Created 0 examples. I1213 13:11:54.226497 140617939887872 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378638 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:21459,usability,input,input,21459,"ing /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.920939 139902364522240 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928069 139902364522240 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00005-of-00010.gz. I1213 13:11:54.928409 139902364522240 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00005-of-00010.gz. I1213 13:11:54.940448 139902364522240 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943632: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.312068 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.712960 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.605319 139902364522240 make_examples.py:1363] Task 5: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:12.983227 139902364522240 make_examples.py:1380] Found 0 candidate variants. I1213 13:12:13.147787 139902364522240 make_examples.py:1381] Created 0 examples. I1213 13:11:54.226497 140617939887872 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378638 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391983 140617939887872 make_examples.py:1324] Preparing inputs. I1213 13:11:54.913211 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.939115 140617939887872 make_examples.py:1248] Common cont",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:21576,usability,input,input,21576,"n contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928069 139902364522240 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00005-of-00010.gz. I1213 13:11:54.928409 139902364522240 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00005-of-00010.gz. I1213 13:11:54.940448 139902364522240 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943632: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.312068 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.712960 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.605319 139902364522240 make_examples.py:1363] Task 5: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:12.983227 139902364522240 make_examples.py:1380] Found 0 candidate variants. I1213 13:12:13.147787 139902364522240 make_examples.py:1381] Created 0 examples. I1213 13:11:54.226497 140617939887872 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378638 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391983 140617939887872 make_examples.py:1324] Preparing inputs. I1213 13:11:54.913211 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.939115 140617939887872 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:22148,usability,input,input,22148,"s default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943632: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.312068 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.712960 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.605319 139902364522240 make_examples.py:1363] Task 5: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:12.983227 139902364522240 make_examples.py:1380] Found 0 candidate variants. I1213 13:12:13.147787 139902364522240 make_examples.py:1381] Created 0 examples. I1213 13:11:54.226497 140617939887872 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378638 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391983 140617939887872 make_examples.py:1324] Preparing inputs. I1213 13:11:54.913211 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.939115 140617939887872 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.948522 140617939887872 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00006-of-00010.gz. I1213 13:11:54.949028 140617939887872 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00006-of-00010.gz. I1213 13:11:55.068927 140617939887872 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:22265,usability,input,inputs,22265,"--ref. 2019-12-13 13:11:54.943632: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.312068 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.712960 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.605319 139902364522240 make_examples.py:1363] Task 5: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:12.983227 139902364522240 make_examples.py:1380] Found 0 candidate variants. I1213 13:12:13.147787 139902364522240 make_examples.py:1381] Created 0 examples. I1213 13:11:54.226497 140617939887872 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378638 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391983 140617939887872 make_examples.py:1324] Preparing inputs. I1213 13:11:54.913211 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.939115 140617939887872 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.948522 140617939887872 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00006-of-00010.gz. I1213 13:11:54.949028 140617939887872 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00006-of-00010.gz. I1213 13:11:55.068927 140617939887872 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.127010: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I12",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:22344,usability,input,input,22344,"Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.312068 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.712960 139902364522240 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.605319 139902364522240 make_examples.py:1363] Task 5: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:12.983227 139902364522240 make_examples.py:1380] Found 0 candidate variants. I1213 13:12:13.147787 139902364522240 make_examples.py:1381] Created 0 examples. I1213 13:11:54.226497 140617939887872 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378638 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391983 140617939887872 make_examples.py:1324] Preparing inputs. I1213 13:11:54.913211 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.939115 140617939887872 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.948522 140617939887872 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00006-of-00010.gz. I1213 13:11:54.949028 140617939887872 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00006-of-00010.gz. I1213 13:11:55.068927 140617939887872 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.127010: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.422019 140617939887872 genomics_reader.py:223] Reading /input/HC3-B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:23069,usability,input,input,23069,"ENT. I1213 13:11:54.378638 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.391983 140617939887872 make_examples.py:1324] Preparing inputs. I1213 13:11:54.913211 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.939115 140617939887872 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.948522 140617939887872 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00006-of-00010.gz. I1213 13:11:54.949028 140617939887872 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00006-of-00010.gz. I1213 13:11:55.068927 140617939887872 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.127010: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.422019 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700212 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.628093 140617939887872 make_examples.py:1363] Task 6: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:13.083571 140617939887872 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.237519 140617939887872 make_examples.py:1381] Created 3 examples. I1213 13:11:54.227164 140331447654144 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379436 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:23336,usability,input,input,23336,"ing /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.939115 140617939887872 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.948522 140617939887872 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00006-of-00010.gz. I1213 13:11:54.949028 140617939887872 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00006-of-00010.gz. I1213 13:11:55.068927 140617939887872 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.127010: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.422019 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700212 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.628093 140617939887872 make_examples.py:1363] Task 6: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:13.083571 140617939887872 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.237519 140617939887872 make_examples.py:1381] Created 3 examples. I1213 13:11:54.227164 140331447654144 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379436 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392060 140331447654144 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893769 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921667 140331447654144 make_examples.py:1248] Common cont",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:23453,usability,input,input,23453,"n contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.948522 140617939887872 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00006-of-00010.gz. I1213 13:11:54.949028 140617939887872 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00006-of-00010.gz. I1213 13:11:55.068927 140617939887872 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.127010: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.422019 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700212 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.628093 140617939887872 make_examples.py:1363] Task 6: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:13.083571 140617939887872 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.237519 140617939887872 make_examples.py:1381] Created 3 examples. I1213 13:11:54.227164 140331447654144 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379436 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392060 140331447654144 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893769 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921667 140331447654144 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:24025,usability,input,input,24025,"s default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.127010: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.422019 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700212 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.628093 140617939887872 make_examples.py:1363] Task 6: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:13.083571 140617939887872 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.237519 140617939887872 make_examples.py:1381] Created 3 examples. I1213 13:11:54.227164 140331447654144 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379436 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392060 140331447654144 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893769 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921667 140331447654144 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928567 140331447654144 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00007-of-00010.gz. I1213 13:11:54.928935 140331447654144 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00007-of-00010.gz. I1213 13:11:54.940444 140331447654144 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:24142,usability,input,inputs,24142,"--ref. 2019-12-13 13:11:55.127010: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.422019 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700212 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.628093 140617939887872 make_examples.py:1363] Task 6: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:13.083571 140617939887872 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.237519 140617939887872 make_examples.py:1381] Created 3 examples. I1213 13:11:54.227164 140331447654144 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379436 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392060 140331447654144 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893769 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921667 140331447654144 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928567 140331447654144 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00007-of-00010.gz. I1213 13:11:54.928935 140331447654144 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00007-of-00010.gz. I1213 13:11:54.940444 140331447654144 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943589: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I12",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:24221,usability,input,input,24221,"Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.422019 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700212 140617939887872 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.628093 140617939887872 make_examples.py:1363] Task 6: 0 candidates (0 examples) [17.68s elapsed]. I1213 13:12:13.083571 140617939887872 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.237519 140617939887872 make_examples.py:1381] Created 3 examples. I1213 13:11:54.227164 140331447654144 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.379436 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392060 140331447654144 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893769 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921667 140331447654144 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928567 140331447654144 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00007-of-00010.gz. I1213 13:11:54.928935 140331447654144 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00007-of-00010.gz. I1213 13:11:54.940444 140331447654144 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943589: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.413748 140331447654144 genomics_reader.py:223] Reading /input/HC3-B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:24946,usability,input,input,24946,"ENT. I1213 13:11:54.379436 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392060 140331447654144 make_examples.py:1324] Preparing inputs. I1213 13:11:54.893769 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921667 140331447654144 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928567 140331447654144 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00007-of-00010.gz. I1213 13:11:54.928935 140331447654144 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00007-of-00010.gz. I1213 13:11:54.940444 140331447654144 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943589: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.413748 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700217 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.624783 140331447654144 make_examples.py:1363] Task 7: 0 candidates (0 examples) [17.69s elapsed]. I1213 13:12:13.050214 140331447654144 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.219461 140331447654144 make_examples.py:1381] Created 3 examples. I1213 13:11:54.225383 140460245006080 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378618 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:25213,usability,input,input,25213,"ing /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.921667 140331447654144 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928567 140331447654144 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00007-of-00010.gz. I1213 13:11:54.928935 140331447654144 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00007-of-00010.gz. I1213 13:11:54.940444 140331447654144 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943589: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.413748 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700217 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.624783 140331447654144 make_examples.py:1363] Task 7: 0 candidates (0 examples) [17.69s elapsed]. I1213 13:12:13.050214 140331447654144 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.219461 140331447654144 make_examples.py:1381] Created 3 examples. I1213 13:11:54.225383 140460245006080 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378618 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392364 140460245006080 make_examples.py:1324] Preparing inputs. I1213 13:11:54.905719 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.953198 140460245006080 make_examples.py:1248] Common cont",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:25330,usability,input,input,25330,"n contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.928567 140331447654144 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00007-of-00010.gz. I1213 13:11:54.928935 140331447654144 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00007-of-00010.gz. I1213 13:11:54.940444 140331447654144 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943589: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.413748 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700217 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.624783 140331447654144 make_examples.py:1363] Task 7: 0 candidates (0 examples) [17.69s elapsed]. I1213 13:12:13.050214 140331447654144 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.219461 140331447654144 make_examples.py:1381] Created 3 examples. I1213 13:11:54.225383 140460245006080 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378618 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392364 140460245006080 make_examples.py:1324] Preparing inputs. I1213 13:11:54.905719 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.953198 140460245006080 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:25902,usability,input,input,25902,"s default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943589: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.413748 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700217 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.624783 140331447654144 make_examples.py:1363] Task 7: 0 candidates (0 examples) [17.69s elapsed]. I1213 13:12:13.050214 140331447654144 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.219461 140331447654144 make_examples.py:1381] Created 3 examples. I1213 13:11:54.225383 140460245006080 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378618 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392364 140460245006080 make_examples.py:1324] Preparing inputs. I1213 13:11:54.905719 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.953198 140460245006080 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.963092 140460245006080 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00008-of-00010.gz. I1213 13:11:54.963464 140460245006080 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00008-of-00010.gz. I1213 13:11:55.068834 140460245006080 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:26019,usability,input,inputs,26019,"--ref. 2019-12-13 13:11:54.943589: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.413748 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700217 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.624783 140331447654144 make_examples.py:1363] Task 7: 0 candidates (0 examples) [17.69s elapsed]. I1213 13:12:13.050214 140331447654144 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.219461 140331447654144 make_examples.py:1381] Created 3 examples. I1213 13:11:54.225383 140460245006080 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378618 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392364 140460245006080 make_examples.py:1324] Preparing inputs. I1213 13:11:54.905719 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.953198 140460245006080 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.963092 140460245006080 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00008-of-00010.gz. I1213 13:11:54.963464 140460245006080 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00008-of-00010.gz. I1213 13:11:55.068834 140460245006080 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.090168: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I12",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:26098,usability,input,input,26098,"Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.413748 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700217 140331447654144 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.624783 140331447654144 make_examples.py:1363] Task 7: 0 candidates (0 examples) [17.69s elapsed]. I1213 13:12:13.050214 140331447654144 make_examples.py:1380] Found 3 candidate variants. I1213 13:12:13.219461 140331447654144 make_examples.py:1381] Created 3 examples. I1213 13:11:54.225383 140460245006080 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.378618 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392364 140460245006080 make_examples.py:1324] Preparing inputs. I1213 13:11:54.905719 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.953198 140460245006080 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.963092 140460245006080 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00008-of-00010.gz. I1213 13:11:54.963464 140460245006080 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00008-of-00010.gz. I1213 13:11:55.068834 140460245006080 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.090168: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.314467 140460245006080 genomics_reader.py:223] Reading /input/HC3-B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:26823,usability,input,input,26823,"ENT. I1213 13:11:54.378618 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.392364 140460245006080 make_examples.py:1324] Preparing inputs. I1213 13:11:54.905719 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.953198 140460245006080 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.963092 140460245006080 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00008-of-00010.gz. I1213 13:11:54.963464 140460245006080 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00008-of-00010.gz. I1213 13:11:55.068834 140460245006080 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.090168: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.314467 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700131 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.616221 140460245006080 make_examples.py:1363] Task 8: 0 candidates (0 examples) [17.65s elapsed]. I1213 13:12:13.152090 140460245006080 make_examples.py:1380] Found 2 candidate variants. I1213 13:12:13.250552 140460245006080 make_examples.py:1381] Created 2 examples. I1213 13:11:54.227202 140405993887488 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.386776 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:27090,usability,input,input,27090,"ing /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.953198 140460245006080 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.963092 140460245006080 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00008-of-00010.gz. I1213 13:11:54.963464 140460245006080 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00008-of-00010.gz. I1213 13:11:55.068834 140460245006080 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.090168: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.314467 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700131 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.616221 140460245006080 make_examples.py:1363] Task 8: 0 candidates (0 examples) [17.65s elapsed]. I1213 13:12:13.152090 140460245006080 make_examples.py:1380] Found 2 candidate variants. I1213 13:12:13.250552 140460245006080 make_examples.py:1381] Created 2 examples. I1213 13:11:54.227202 140405993887488 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.386776 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.398395 140405993887488 make_examples.py:1324] Preparing inputs. I1213 13:11:54.894856 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.922434 140405993887488 make_examples.py:1248] Common cont",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:27207,usability,input,input,27207,"n contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.963092 140460245006080 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00008-of-00010.gz. I1213 13:11:54.963464 140460245006080 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00008-of-00010.gz. I1213 13:11:55.068834 140460245006080 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.090168: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.314467 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700131 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.616221 140460245006080 make_examples.py:1363] Task 8: 0 candidates (0 examples) [17.65s elapsed]. I1213 13:12:13.152090 140460245006080 make_examples.py:1380] Found 2 candidate variants. I1213 13:12:13.250552 140460245006080 make_examples.py:1381] Created 2 examples. I1213 13:11:54.227202 140405993887488 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.386776 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.398395 140405993887488 make_examples.py:1324] Preparing inputs. I1213 13:11:54.894856 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.922434 140405993887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17'",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:27779,usability,input,input,27779,"s default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:55.090168: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.314467 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700131 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.616221 140460245006080 make_examples.py:1363] Task 8: 0 candidates (0 examples) [17.65s elapsed]. I1213 13:12:13.152090 140460245006080 make_examples.py:1380] Found 2 candidate variants. I1213 13:12:13.250552 140460245006080 make_examples.py:1381] Created 2 examples. I1213 13:11:54.227202 140405993887488 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.386776 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.398395 140405993887488 make_examples.py:1324] Preparing inputs. I1213 13:11:54.894856 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.922434 140405993887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:27896,usability,input,inputs,27896,"--ref. 2019-12-13 13:11:55.090168: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.314467 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700131 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.616221 140460245006080 make_examples.py:1363] Task 8: 0 candidates (0 examples) [17.65s elapsed]. I1213 13:12:13.152090 140460245006080 make_examples.py:1380] Found 2 candidate variants. I1213 13:12:13.250552 140460245006080 make_examples.py:1381] Created 2 examples. I1213 13:11:54.227202 140405993887488 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.386776 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.398395 140405993887488 make_examples.py:1324] Preparing inputs. I1213 13:11:54.894856 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.922434 140405993887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. rea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:27975,usability,input,input,27975,"Setting HTS_OPT_BLOCK_SIZE to 134217728. I1213 13:12:03.314467 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:04.700131 140460245006080 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:12:12.616221 140460245006080 make_examples.py:1363] Task 8: 0 candidates (0 examples) [17.65s elapsed]. I1213 13:12:13.152090 140460245006080 make_examples.py:1380] Found 2 candidate variants. I1213 13:12:13.250552 140460245006080 make_examples.py:1381] Created 2 examples. I1213 13:11:54.227202 140405993887488 make_examples.py:377] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I1213 13:11:54.386776 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.398395 140405993887488 make_examples.py:1324] Preparing inputs. I1213 13:11:54.894856 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.922434 140405993887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:28700,usability,input,input,28700,"ENT. I1213 13:11:54.386776 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.398395 140405993887488 make_examples.py:1324] Preparing inputs. I1213 13:11:54.894856 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.922434 140405993887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" -",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:28912,usability,user,user,28912,"1:54.894856 140405993887488 genomics_reader.py:223] Reading /input/HC3-BC_RG_bwa.bam with NativeSamReader. I1213 13:11:54.922434 140405993887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 1. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:29359,usability,command,command,29359,"93887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 1. ```. The same error develops with your WES-case-study sample file/script. It would be great to solve this problem. . Thank you in advance. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:29542,usability,Command,Command,29542,"93887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 1. ```. The same error develops with your WES-case-study sample file/script. It would be great to solve this problem. . Thank you in advance. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:29650,usability,input,input,29650,"93887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 1. ```. The same error develops with your WES-case-study sample file/script. It would be great to solve this problem. . Thank you in advance. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:29677,usability,input,input,29677,"93887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 1. ```. The same error develops with your WES-case-study sample file/script. It would be great to solve this problem. . Thank you in advance. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:29900,usability,statu,status,29900,"93887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 1. ```. The same error develops with your WES-case-study sample file/script. It would be great to solve this problem. . Thank you in advance. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:29924,usability,error,error,29924,"93887488 make_examples.py:1248] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. I1213 13:11:54.929332 140405993887488 make_examples.py:1330] Writing examples to /tmp/deepvariant_tmp_output/make_examples.tfrecord-00009-of-00010.gz. I1213 13:11:54.929711 140405993887488 make_examples.py:1334] Writing gvcf records to /tmp/deepvariant_tmp_output/gvcf.tfrecord-00009-of-00010.gz. I1213 13:11:54.940470 140405993887488 make_examples.py:905] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2019-12-13 13:11:54.943603: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. real	0m33.273s. user	0m30.820s. sys	1m32.400s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 9 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/genome.fa"" --reads ""/input/HC3-BC_RG_bwa.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@10.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@10.gz"" --regions ""20:10,000,000-10,100,000"" --task {}' returned non-zero exit status 1. ```. The same error develops with your WES-case-study sample file/script. It would be great to solve this problem. . Thank you in advance. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:116,availability,error,error,116,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:356,availability,checkpoint,checkpoint,356,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:651,availability,servic,service,651,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:659,availability,servic,service,659,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:679,availability,servic,service,679,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:802,availability,servic,service,802,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:810,availability,servic,service,810,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:1576,availability,Cluster,ClusterSpec,1576,"2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526952 140624564107008 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 19:19:36.531224 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 19:19:36.546206 140624564107008 data_providers.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3751,availability,operat,operator,3751,_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/m,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4358,availability,Restor,Restoring,4358,"nd will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessErro",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4712,availability,Restor,Restoring,4712,"updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247. ```. I'm attaching the code and the e",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5604,availability,checkpoint,checkpoint,5604,".236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247. ```. I'm attaching the code and the entire output. . Thanks a lot. . [WES_20191214_samplenoshards.txt](https://github.com/google/deepvariant/files/3963193/WES_20191214_samplenoshards.txt). [error_output.txt](https://github.com/google/deepvariant/files/3963194/error_output.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:651,deployability,servic,service,651,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:659,deployability,servic,service,659,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:679,deployability,servic,service,679,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:802,deployability,servic,service,802,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:810,deployability,servic,service,810,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:1576,deployability,Cluster,ClusterSpec,1576,"2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526952 140624564107008 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 19:19:36.531224 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 19:19:36.546206 140624564107008 data_providers.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2447,deployability,version,version,2447,"_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526952 140624564107008 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 19:19:36.531224 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 19:19:36.546206 140624564107008 data_providers.py:367] self.input_read_threads=8. W1213 19:19:36.546560 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2473,deployability,updat,updating,2473,"rain_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526952 140624564107008 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 19:19:36.531224 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 19:19:36.546206 140624564107008 data_providers.py:367] self.input_read_threads=8. W1213 19:19:36.546560 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2504,deployability,automat,automatically,2504,"': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526952 140624564107008 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 19:19:36.531224 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 19:19:36.546206 140624564107008 data_providers.py:367] self.input_read_threads=8. W1213 19:19:36.546560 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] F",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2897,deployability,version,version,2897,"replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526952 140624564107008 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 19:19:36.531224 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 19:19:36.546206 140624564107008 data_providers.py:367] self.input_read_threads=8. W1213 19:19:36.546560 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 moni",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2923,deployability,updat,updating,2923,"0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526952 140624564107008 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 19:19:36.531224 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 19:19:36.546206 140624564107008 data_providers.py:367] self.input_read_threads=8. W1213 19:19:36.546560 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Grap",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3394,deployability,version,version,3394,s) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 19:19:36.546206 140624564107008 data_providers.py:367] self.input_read_threads=8. W1213 19:19:36.546560 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/we,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3420,deployability,updat,updating,3420,be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 19:19:36.546206 140624564107008 data_providers.py:367] self.input_read_threads=8. W1213 19:19:36.546560 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3691,deployability,version,version,3691,iles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 14062456410700,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3717,deployability,updat,updating,3717,oogle_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4208,deployability,version,version,4208," /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subpro",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4234,deployability,updat,updating,4234,"h/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4263,deployability,API,APIs,4263,"ariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4910,deployability,modul,module,4910,"n.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247. ```. I'm attaching the code and the entire output. . Thanks a lot. . [WES_20191214_samplenoshards.txt](https://github.com/google/deepvariant/files/3963193/WES_20191214_samplenoshards.txt). [error_output.txt](https://github.com/google",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:373,energy efficiency,model,models,373,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:384,energy efficiency,model,model,384,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:522,energy efficiency,core,core,522,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:567,energy efficiency,CPU,CPU,567,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:571,energy efficiency,Frequenc,Frequency,571,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:920,energy efficiency,core,core,920,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:1119,energy efficiency,model,modeling,1119,"s below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526952 140624564107008 call_variants.py:381] Writing",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:1149,energy efficiency,model,model,1149," the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526952 140624564107008 call_variants.py:381] Writing calls to /tmp/deepvariant_tm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:1217,energy efficiency,estimat,estimator,1217,"""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526952 140624564107008 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 19:19:36.531224 14062",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:1262,energy efficiency,model,model,1262,"output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526952 140624564107008 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 19:19:36.531224 140624564107008 deprecation.py:323] From /usr/lo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:1333,energy efficiency,estimat,estimator,1333,".tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526952 140624564107008 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 19:19:36.531224 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_librar",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3113,energy efficiency,estimat,estimator,3113,iting calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 19:19:36.531224 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 19:19:36.546206 140624564107008 data_providers.py:367] self.input_read_threads=8. W1213 19:19:36.546560 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensor,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3284,energy efficiency,model,modeling,3284,packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 19:19:36.546206 140624564107008 data_providers.py:367] self.input_read_threads=8. W1213 19:19:36.546560 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files w,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3586,energy efficiency,model,modeling,3586,self.input_read_threads=8. W1213 19:19:36.546560 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I12,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3817,energy efficiency,estimat,estimator,3817,a.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback ,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4389,energy efficiency,model,models,4389,"e version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4400,energy efficiency,model,model,4400,"Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProces",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4625,energy efficiency,model,modeling,4625,"n.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/w",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4743,energy efficiency,model,models,4743,"r of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247. ```. I'm attaching the code and the entire output. . Thanks a lot.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4754,energy efficiency,model,model,4754,"or or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247. ```. I'm attaching the code and the entire output. . Thanks a lot. . [WES_201",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5621,energy efficiency,model,models,5621,".236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247. ```. I'm attaching the code and the entire output. . Thanks a lot. . [WES_20191214_samplenoshards.txt](https://github.com/google/deepvariant/files/3963193/WES_20191214_samplenoshards.txt). [error_output.txt](https://github.com/google/deepvariant/files/3963194/error_output.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5632,energy efficiency,model,model,5632,".236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247. ```. I'm attaching the code and the entire output. . Thanks a lot. . [WES_20191214_samplenoshards.txt](https://github.com/google/deepvariant/files/3963193/WES_20191214_samplenoshards.txt). [error_output.txt](https://github.com/google/deepvariant/files/3963194/error_output.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:651,integrability,servic,service,651,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:659,integrability,servic,service,659,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:679,integrability,servic,service,679,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:802,integrability,servic,service,802,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:810,integrability,servic,service,810,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2447,integrability,version,version,2447,"_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526952 140624564107008 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 19:19:36.531224 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 19:19:36.546206 140624564107008 data_providers.py:367] self.input_read_threads=8. W1213 19:19:36.546560 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2897,integrability,version,version,2897,"replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526952 140624564107008 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 19:19:36.531224 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 19:19:36.546206 140624564107008 data_providers.py:367] self.input_read_threads=8. W1213 19:19:36.546560 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 moni",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3394,integrability,version,version,3394,s) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 19:19:36.546206 140624564107008 data_providers.py:367] self.input_read_threads=8. W1213 19:19:36.546560 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/we,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3691,integrability,version,version,3691,iles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 14062456410700,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4208,integrability,version,version,4208," /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subpro",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4263,integrability,API,APIs,4263,"ariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5206,integrability,sub,subprocess,5206,".236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247. ```. I'm attaching the code and the entire output. . Thanks a lot. . [WES_20191214_samplenoshards.txt](https://github.com/google/deepvariant/files/3963193/WES_20191214_samplenoshards.txt). [error_output.txt](https://github.com/google/deepvariant/files/3963194/error_output.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5299,integrability,sub,subprocess,5299,".236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247. ```. I'm attaching the code and the entire output. . Thanks a lot. . [WES_20191214_samplenoshards.txt](https://github.com/google/deepvariant/files/3963193/WES_20191214_samplenoshards.txt). [error_output.txt](https://github.com/google/deepvariant/files/3963194/error_output.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5380,integrability,sub,subprocess,5380,".236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247. ```. I'm attaching the code and the entire output. . Thanks a lot. . [WES_20191214_samplenoshards.txt](https://github.com/google/deepvariant/files/3963193/WES_20191214_samplenoshards.txt). [error_output.txt](https://github.com/google/deepvariant/files/3963194/error_output.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:527,interoperability,platform,platform,527,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:723,interoperability,platform,platform,723,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4249,interoperability,standard,standard,4249,"google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, exec",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4263,interoperability,API,APIs,4263,"ariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:651,modifiability,servic,service,651,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:659,modifiability,servic,service,659,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:679,modifiability,servic,service,679,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:802,modifiability,servic,service,802,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:810,modifiability,servic,service,810,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:1167,modifiability,paramet,parameters,1167,"time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526952 140624564107008 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_varian",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2288,modifiability,pac,packages,2288,"L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526952 140624564107008 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 19:19:36.531224 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 19:19:36.546206 140624564107008 data_providers.py:367] self.input_read_threads=8. W1213 19:19:36.546560 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2447,modifiability,version,version,2447,"_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526952 140624564107008 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 19:19:36.531224 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 19:19:36.546206 140624564107008 data_providers.py:367] self.input_read_threads=8. W1213 19:19:36.546560 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2897,modifiability,version,version,2897,"replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526952 140624564107008 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 19:19:36.531224 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 19:19:36.546206 140624564107008 data_providers.py:367] self.input_read_threads=8. W1213 19:19:36.546560 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 moni",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3394,modifiability,version,version,3394,s) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 19:19:36.546206 140624564107008 data_providers.py:367] self.input_read_threads=8. W1213 19:19:36.546560 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/we,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3691,modifiability,version,version,3691,iles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 14062456410700,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4037,modifiability,pac,packages,4037,"y:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4208,modifiability,version,version,4208," /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subpro",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4368,modifiability,paramet,parameters,4368," removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4722,modifiability,paramet,parameters,4722," Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247. ```. I'm attaching the code and the entire outp",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4910,modifiability,modul,module,4910,"n.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247. ```. I'm attaching the code and the entire output. . Thanks a lot. . [WES_20191214_samplenoshards.txt](https://github.com/google/deepvariant/files/3963193/WES_20191214_samplenoshards.txt). [error_output.txt](https://github.com/google",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4970,modifiability,pac,packages,4970,".236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247. ```. I'm attaching the code and the entire output. . Thanks a lot. . [WES_20191214_samplenoshards.txt](https://github.com/google/deepvariant/files/3963193/WES_20191214_samplenoshards.txt). [error_output.txt](https://github.com/google/deepvariant/files/3963194/error_output.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5070,modifiability,pac,packages,5070,".236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247. ```. I'm attaching the code and the entire output. . Thanks a lot. . [WES_20191214_samplenoshards.txt](https://github.com/google/deepvariant/files/3963193/WES_20191214_samplenoshards.txt). [error_output.txt](https://github.com/google/deepvariant/files/3963194/error_output.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:116,performance,error,error,116,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:172,performance,time,time,172,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:567,performance,CPU,CPU,567,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:1019,performance,Tune,Tune,1019,"egions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:1068,performance,perform,performance,1068,"ds,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5420,performance,time,time,5420,".236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247. ```. I'm attaching the code and the entire output. . Thanks a lot. . [WES_20191214_samplenoshards.txt](https://github.com/google/deepvariant/files/3963193/WES_20191214_samplenoshards.txt). [error_output.txt](https://github.com/google/deepvariant/files/3963194/error_output.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:356,reliability,checkpoint,checkpoint,356,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4358,reliability,Restor,Restoring,4358,"nd will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessErro",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4712,reliability,Restor,Restoring,4712,"updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247. ```. I'm attaching the code and the e",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5604,reliability,checkpoint,checkpoint,5604,".236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247. ```. I'm attaching the code and the entire output. . Thanks a lot. . [WES_20191214_samplenoshards.txt](https://github.com/google/deepvariant/files/3963193/WES_20191214_samplenoshards.txt). [error_output.txt](https://github.com/google/deepvariant/files/3963194/error_output.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:116,safety,error,error,116,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2473,safety,updat,updating,2473,"rain_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526952 140624564107008 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 19:19:36.531224 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 19:19:36.546206 140624564107008 data_providers.py:367] self.input_read_threads=8. W1213 19:19:36.546560 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2923,safety,updat,updating,2923,"0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526952 140624564107008 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 19:19:36.531224 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 19:19:36.546206 140624564107008 data_providers.py:367] self.input_read_threads=8. W1213 19:19:36.546560 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Grap",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3420,safety,updat,updating,3420,be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 19:19:36.546206 140624564107008 data_providers.py:367] self.input_read_threads=8. W1213 19:19:36.546560 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3717,safety,updat,updating,3717,oogle_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4234,safety,updat,updating,4234,"h/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4910,safety,modul,module,4910,"n.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247. ```. I'm attaching the code and the entire output. . Thanks a lot. . [WES_20191214_samplenoshards.txt](https://github.com/google/deepvariant/files/3963193/WES_20191214_samplenoshards.txt). [error_output.txt](https://github.com/google",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:373,security,model,models,373,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:384,security,model,model,384,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:1119,security,model,modeling,1119,"s below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526952 140624564107008 call_variants.py:381] Writing",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:1149,security,model,model,1149," the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526952 140624564107008 call_variants.py:381] Writing calls to /tmp/deepvariant_tm",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:1262,security,model,model,1262,"output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526952 140624564107008 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 19:19:36.531224 140624564107008 deprecation.py:323] From /usr/lo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2473,security,updat,updating,2473,"rain_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526952 140624564107008 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 19:19:36.531224 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 19:19:36.546206 140624564107008 data_providers.py:367] self.input_read_threads=8. W1213 19:19:36.546560 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2923,security,updat,updating,2923,"0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526952 140624564107008 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 19:19:36.531224 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 19:19:36.546206 140624564107008 data_providers.py:367] self.input_read_threads=8. W1213 19:19:36.546560 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Grap",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3284,security,model,modeling,3284,packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 19:19:36.546206 140624564107008 data_providers.py:367] self.input_read_threads=8. W1213 19:19:36.546560 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files w,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3420,security,updat,updating,3420,be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 19:19:36.546206 140624564107008 data_providers.py:367] self.input_read_threads=8. W1213 19:19:36.546560 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3586,security,model,modeling,3586,self.input_read_threads=8. W1213 19:19:36.546560 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I12,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:3717,security,updat,updating,3717,oogle_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4234,security,updat,updating,4234,"h/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4389,security,model,models,4389,"e version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4400,security,model,model,4400,"Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:882: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProces",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4625,security,model,modeling,4625,"n.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Deprecated in favor of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/w",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4743,security,model,models,4743,"r of operator or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247. ```. I'm attaching the code and the entire output. . Thanks a lot.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4754,security,model,model,4754,"or or tf.math.divide. I1213 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247. ```. I'm attaching the code and the entire output. . Thanks a lot. . [WES_201",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5621,security,model,models,5621,".236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247. ```. I'm attaching the code and the entire output. . Thanks a lot. . [WES_20191214_samplenoshards.txt](https://github.com/google/deepvariant/files/3963193/WES_20191214_samplenoshards.txt). [error_output.txt](https://github.com/google/deepvariant/files/3963194/error_output.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5632,security,model,model,5632,".236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247. ```. I'm attaching the code and the entire output. . Thanks a lot. . [WES_20191214_samplenoshards.txt](https://github.com/google/deepvariant/files/3963193/WES_20191214_samplenoshards.txt). [error_output.txt](https://github.com/google/deepvariant/files/3963194/error_output.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:2504,testability,automat,automatically,2504,"': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526952 140624564107008 call_variants.py:381] Writing calls to /tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz. W1213 19:19:36.531224 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating:. Colocations handled automatically by placer. I1213 19:19:36.546206 140624564107008 data_providers.py:367] self.input_read_threads=8. W1213 19:19:36.546560 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/data_providers.py:372: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.experimental.parallel_interleave(...)`. I1213 19:19:36.562076 140624564107008 data_providers.py:373] self.input_map_threads=48. I1213 19:19:36.584693 140624564107008 estimator.py:1111] Calling model_fn. W1213 19:19:36.584897 140624564107008 deprecation.py:323] From /tmp/Bazel.runfiles_DeisPh/runfiles/com_google_deepvariant/deepvariant/modeling.py:880: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use tf.cast instead. W1213 19:19:36.587405 140624564107008 deprecation.py:323] F",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4812,testability,Trace,Traceback,4812,"estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247. ```. I'm attaching the code and the entire output. . Thanks a lot. . [WES_20191214_samplenoshards.txt](https://github.com/google/deepvari",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:116,usability,error,error,116,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:157,usability,command,command,157,"Dear akolesikov,. --regions ""20:10,000,000-10,100,000"" was ok without shards,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distrib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:1068,usability,perform,performance,1068,"ds,. however, for WES.bed I got a similar error as below. . ```. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt"". I1213 19:19:36.445342 140624564107008 call_variants.py:313] Set KMP_BLOCKTIME to 0. 2019-12-13 19:19:36.497919: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2697915000 Hz. 2019-12-13 19:19:36.499703: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52dd110 executing computations on platform Host. Devices:. 2019-12-13 19:19:36.499773: I tensorflow/compiler/xla/service/service.cc:158] StreamExecutor device (0): <undefined>, <undefined>. 2019-12-13 19:19:36.503204: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1213 19:19:36.524235 140624564107008 modeling.py:560] Initializing model with random parameters. W1213 19:19:36.526154 140624564107008 estimator.py:1760] Using temporary folder as model directory: /tmp/tmp6q1g_L. I1213 19:19:36.526648 140624564107008 estimator.py:201] Using config: {'_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe550820190>, '_model_dir': '/tmp/tmp6q1g_L', '_protocol': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_device_fn': None, '_experimental_distribute': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_global_id_in_cluster': 0, '_master': ''}. I1213 19:19:36.526",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:4782,usability,user,user,4782," 19:19:39.687763 140624564107008 estimator.py:1113] Done calling model_fn. I1213 19:19:41.234924 140624564107008 monitored_session.py:222] Graph was finalized. W1213 19:19:41.236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247. ```. I'm attaching the code and the entire output. . Thanks a lot. . [WES_20191214_samplenoshards.txt](h",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5228,usability,command,command,5228,".236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247. ```. I'm attaching the code and the entire output. . Thanks a lot. . [WES_20191214_samplenoshards.txt](https://github.com/google/deepvariant/files/3963193/WES_20191214_samplenoshards.txt). [error_output.txt](https://github.com/google/deepvariant/files/3963194/error_output.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5411,usability,Command,Command,5411,".236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247. ```. I'm attaching the code and the entire output. . Thanks a lot. . [WES_20191214_samplenoshards.txt](https://github.com/google/deepvariant/files/3963193/WES_20191214_samplenoshards.txt). [error_output.txt](https://github.com/google/deepvariant/files/3963194/error_output.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:5668,usability,statu,status,5668,".236058 140624564107008 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version. Instructions for updating:. Use standard file APIs to check for files with this prefix. I1213 19:19:41.240454 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. I1213 19:19:42.471465 140624564107008 session_manager.py:491] Running local_init_op. I1213 19:19:42.514822 140624564107008 session_manager.py:493] Done running local_init_op. I1213 19:19:42.911899 140624564107008 modeling.py:410] Reloading EMA... I1213 19:19:42.913168 140624564107008 saver.py:1270] Restoring parameters from /opt/models/wes/model.ckpt. real	0m35.093s. user	0m23.000s. sys	2m0.390s. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 317, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 307, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/tmp/deepvariant_tmp_output/call_variants_output.tfrecord.gz"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wes/model.ckpt""' returned non-zero exit status 247. ```. I'm attaching the code and the entire output. . Thanks a lot. . [WES_20191214_samplenoshards.txt](https://github.com/google/deepvariant/files/3963193/WES_20191214_samplenoshards.txt). [error_output.txt](https://github.com/google/deepvariant/files/3963194/error_output.txt).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:298,energy efficiency,reduc,reduce,298,"I tried and was unsuccessful to reproduce the problem with the case study input data. I could try to reproduce the problem with your data if you can attach your BAM (just the 100,000 bases of it) and the reference. As a work around you could run without --num_shards flag, or you could also try to reduce the number of shards.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:74,safety,input,input,74,"I tried and was unsuccessful to reproduce the problem with the case study input data. I could try to reproduce the problem with your data if you can attach your BAM (just the 100,000 bases of it) and the reference. As a work around you could run without --num_shards flag, or you could also try to reduce the number of shards.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:74,usability,input,input,74,"I tried and was unsuccessful to reproduce the problem with the case study input data. I could try to reproduce the problem with your data if you can attach your BAM (just the 100,000 bases of it) and the reference. As a work around you could run without --num_shards flag, or you could also try to reduce the number of shards.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
https://github.com/google/deepvariant/issues/249:75,deployability,updat,update,75,"Hi @se2cheeese . I will close this issue for now because there's no reason update from you. But please feel free to follow up with more questions, either reopening this issue, or another one. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/249
