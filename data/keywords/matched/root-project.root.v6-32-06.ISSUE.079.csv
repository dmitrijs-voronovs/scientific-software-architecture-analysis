id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/root-project/root/issues/12191:28,usability,user,user,28,Mention RDatasetSpec in the user guide; ...and use it in tutorials where it makes sense.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12191
https://github.com/root-project/root/issues/12191:33,usability,guid,guide,33,Mention RDatasetSpec in the user guide; ...and use it in tutorials where it makes sense.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12191
https://github.com/root-project/root/pull/12193:19,deployability,modul,modulemap,19,"Add variant to the modulemap to address a cmssw-related issue.; cc: @davidlange6, @smuzaffar",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12193
https://github.com/root-project/root/pull/12193:19,modifiability,modul,modulemap,19,"Add variant to the modulemap to address a cmssw-related issue.; cc: @davidlange6, @smuzaffar",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12193
https://github.com/root-project/root/pull/12193:19,safety,modul,modulemap,19,"Add variant to the modulemap to address a cmssw-related issue.; cc: @davidlange6, @smuzaffar",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12193
https://github.com/root-project/root/issues/12194:261,availability,down,download,261,"Directory Traversal Vulnerability; My name is Mohammad Sarik, I am a Ethical hacker from INDIA. I found a Directory Traversal Vulnerability in your website. There URL is this:- https://root.cern.ch/ and there Parent Directory URL is this:- https://root.cern.ch/download/ Fix this Vulnerbility because it has very important Files & Data.I give you some proof in terms of screenshot. ![Screenshot_2023-02-01_12_44_54](https://user-images.githubusercontent.com/124130635/215976318-c8943307-7b48-46d7-8356-4828f8952432.png). ![Screenshot_2023-02-01_12_45_02](https://user-images.githubusercontent.com/124130635/215976326-32db3095-1b02-47dc-be54-9c64f8ffab0d.png). ![Screenshot_2023-02-01_12_45_18](https://user-images.githubusercontent.com/124130635/215976335-52ddb636-1931-4d5c-839b-44d10db7b90a.png). some proof in terms of screenshot.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12194
https://github.com/root-project/root/issues/12194:77,security,hack,hacker,77,"Directory Traversal Vulnerability; My name is Mohammad Sarik, I am a Ethical hacker from INDIA. I found a Directory Traversal Vulnerability in your website. There URL is this:- https://root.cern.ch/ and there Parent Directory URL is this:- https://root.cern.ch/download/ Fix this Vulnerbility because it has very important Files & Data.I give you some proof in terms of screenshot. ![Screenshot_2023-02-01_12_44_54](https://user-images.githubusercontent.com/124130635/215976318-c8943307-7b48-46d7-8356-4828f8952432.png). ![Screenshot_2023-02-01_12_45_02](https://user-images.githubusercontent.com/124130635/215976326-32db3095-1b02-47dc-be54-9c64f8ffab0d.png). ![Screenshot_2023-02-01_12_45_18](https://user-images.githubusercontent.com/124130635/215976335-52ddb636-1931-4d5c-839b-44d10db7b90a.png). some proof in terms of screenshot.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12194
https://github.com/root-project/root/issues/12194:424,usability,user,user-images,424,"Directory Traversal Vulnerability; My name is Mohammad Sarik, I am a Ethical hacker from INDIA. I found a Directory Traversal Vulnerability in your website. There URL is this:- https://root.cern.ch/ and there Parent Directory URL is this:- https://root.cern.ch/download/ Fix this Vulnerbility because it has very important Files & Data.I give you some proof in terms of screenshot. ![Screenshot_2023-02-01_12_44_54](https://user-images.githubusercontent.com/124130635/215976318-c8943307-7b48-46d7-8356-4828f8952432.png). ![Screenshot_2023-02-01_12_45_02](https://user-images.githubusercontent.com/124130635/215976326-32db3095-1b02-47dc-be54-9c64f8ffab0d.png). ![Screenshot_2023-02-01_12_45_18](https://user-images.githubusercontent.com/124130635/215976335-52ddb636-1931-4d5c-839b-44d10db7b90a.png). some proof in terms of screenshot.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12194
https://github.com/root-project/root/issues/12194:563,usability,user,user-images,563,"Directory Traversal Vulnerability; My name is Mohammad Sarik, I am a Ethical hacker from INDIA. I found a Directory Traversal Vulnerability in your website. There URL is this:- https://root.cern.ch/ and there Parent Directory URL is this:- https://root.cern.ch/download/ Fix this Vulnerbility because it has very important Files & Data.I give you some proof in terms of screenshot. ![Screenshot_2023-02-01_12_44_54](https://user-images.githubusercontent.com/124130635/215976318-c8943307-7b48-46d7-8356-4828f8952432.png). ![Screenshot_2023-02-01_12_45_02](https://user-images.githubusercontent.com/124130635/215976326-32db3095-1b02-47dc-be54-9c64f8ffab0d.png). ![Screenshot_2023-02-01_12_45_18](https://user-images.githubusercontent.com/124130635/215976335-52ddb636-1931-4d5c-839b-44d10db7b90a.png). some proof in terms of screenshot.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12194
https://github.com/root-project/root/issues/12194:702,usability,user,user-images,702,"Directory Traversal Vulnerability; My name is Mohammad Sarik, I am a Ethical hacker from INDIA. I found a Directory Traversal Vulnerability in your website. There URL is this:- https://root.cern.ch/ and there Parent Directory URL is this:- https://root.cern.ch/download/ Fix this Vulnerbility because it has very important Files & Data.I give you some proof in terms of screenshot. ![Screenshot_2023-02-01_12_44_54](https://user-images.githubusercontent.com/124130635/215976318-c8943307-7b48-46d7-8356-4828f8952432.png). ![Screenshot_2023-02-01_12_45_02](https://user-images.githubusercontent.com/124130635/215976326-32db3095-1b02-47dc-be54-9c64f8ffab0d.png). ![Screenshot_2023-02-01_12_45_18](https://user-images.githubusercontent.com/124130635/215976335-52ddb636-1931-4d5c-839b-44d10db7b90a.png). some proof in terms of screenshot.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12194
https://github.com/root-project/root/pull/12195:18,performance,perform,performance,18,6.28: [DF] Remove performance overhead in construction of RSampleInfo; Backport of https://github.com/root-project/root/pull/12174,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12195
https://github.com/root-project/root/pull/12195:30,performance,overhead,overhead,30,6.28: [DF] Remove performance overhead in construction of RSampleInfo; Backport of https://github.com/root-project/root/pull/12174,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12195
https://github.com/root-project/root/pull/12195:58,security,RSa,RSampleInfo,58,6.28: [DF] Remove performance overhead in construction of RSampleInfo; Backport of https://github.com/root-project/root/pull/12174,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12195
https://github.com/root-project/root/pull/12195:18,usability,perform,performance,18,6.28: [DF] Remove performance overhead in construction of RSampleInfo; Backport of https://github.com/root-project/root/pull/12174,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12195
https://github.com/root-project/root/pull/12196:108,availability,error,error,108,[ci] ubuntu18: no c++17; Should address. ```. /tmp/workspace/src/tree/ntuple/v7/src/RField.cxx:43:10: fatal error: charconv: No such file or directory. #include <charconv>. ^~~~~~~~~~. ```,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12196
https://github.com/root-project/root/pull/12196:108,performance,error,error,108,[ci] ubuntu18: no c++17; Should address. ```. /tmp/workspace/src/tree/ntuple/v7/src/RField.cxx:43:10: fatal error: charconv: No such file or directory. #include <charconv>. ^~~~~~~~~~. ```,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12196
https://github.com/root-project/root/pull/12196:108,safety,error,error,108,[ci] ubuntu18: no c++17; Should address. ```. /tmp/workspace/src/tree/ntuple/v7/src/RField.cxx:43:10: fatal error: charconv: No such file or directory. #include <charconv>. ^~~~~~~~~~. ```,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12196
https://github.com/root-project/root/pull/12196:108,usability,error,error,108,[ci] ubuntu18: no c++17; Should address. ```. /tmp/workspace/src/tree/ntuple/v7/src/RField.cxx:43:10: fatal error: charconv: No such file or directory. #include <charconv>. ^~~~~~~~~~. ```,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12196
https://github.com/root-project/root/pull/12197:26,deployability,API,API,26,[6.28] Use non-deprecated API to initialize Python interpreter; Backport of #12189,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12197
https://github.com/root-project/root/pull/12197:26,integrability,API,API,26,[6.28] Use non-deprecated API to initialize Python interpreter; Backport of #12189,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12197
https://github.com/root-project/root/pull/12197:26,interoperability,API,API,26,[6.28] Use non-deprecated API to initialize Python interpreter; Backport of #12189,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12197
https://github.com/root-project/root/pull/12198:7,safety,Avoid,Avoid,7,[6.28] Avoid deprecated numpy.object; Backport of #12159,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12198
https://github.com/root-project/root/pull/12199:134,availability,error,errors,134,run `chmod a+x build_root.py`; # This Pull request:. Sets the executable bit on `build_root.py`. ## fixes:. Fixes `Permission denied` errors when running workflow. https://github.com/root-project/root/actions/runs/4057126157/jobs/6982483001#step:6:100. ## Checklist:. - [x] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12199
https://github.com/root-project/root/pull/12199:134,performance,error,errors,134,run `chmod a+x build_root.py`; # This Pull request:. Sets the executable bit on `build_root.py`. ## fixes:. Fixes `Permission denied` errors when running workflow. https://github.com/root-project/root/actions/runs/4057126157/jobs/6982483001#step:6:100. ## Checklist:. - [x] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12199
https://github.com/root-project/root/pull/12199:115,safety,Permiss,Permission,115,run `chmod a+x build_root.py`; # This Pull request:. Sets the executable bit on `build_root.py`. ## fixes:. Fixes `Permission denied` errors when running workflow. https://github.com/root-project/root/actions/runs/4057126157/jobs/6982483001#step:6:100. ## Checklist:. - [x] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12199
https://github.com/root-project/root/pull/12199:134,safety,error,errors,134,run `chmod a+x build_root.py`; # This Pull request:. Sets the executable bit on `build_root.py`. ## fixes:. Fixes `Permission denied` errors when running workflow. https://github.com/root-project/root/actions/runs/4057126157/jobs/6982483001#step:6:100. ## Checklist:. - [x] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12199
https://github.com/root-project/root/pull/12199:274,safety,test,tested,274,run `chmod a+x build_root.py`; # This Pull request:. Sets the executable bit on `build_root.py`. ## fixes:. Fixes `Permission denied` errors when running workflow. https://github.com/root-project/root/actions/runs/4057126157/jobs/6982483001#step:6:100. ## Checklist:. - [x] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12199
https://github.com/root-project/root/pull/12199:274,testability,test,tested,274,run `chmod a+x build_root.py`; # This Pull request:. Sets the executable bit on `build_root.py`. ## fixes:. Fixes `Permission denied` errors when running workflow. https://github.com/root-project/root/actions/runs/4057126157/jobs/6982483001#step:6:100. ## Checklist:. - [x] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12199
https://github.com/root-project/root/pull/12199:134,usability,error,errors,134,run `chmod a+x build_root.py`; # This Pull request:. Sets the executable bit on `build_root.py`. ## fixes:. Fixes `Permission denied` errors when running workflow. https://github.com/root-project/root/actions/runs/4057126157/jobs/6982483001#step:6:100. ## Checklist:. - [x] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12199
https://github.com/root-project/root/pull/12199:154,usability,workflow,workflow,154,run `chmod a+x build_root.py`; # This Pull request:. Sets the executable bit on `build_root.py`. ## fixes:. Fixes `Permission denied` errors when running workflow. https://github.com/root-project/root/actions/runs/4057126157/jobs/6982483001#step:6:100. ## Checklist:. - [x] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12199
https://github.com/root-project/root/pull/12200:105,deployability,build,build,105,"[rmkdepend] Work around GCC format truncation warning:; ```. /home/vpadulan/programs/rootproject/rootsrc/build/rmkdepend/include.c:306:37: warning: ‘%s’ directive output may be truncated writing up to 8190 bytes into a region of size between 1 and 8191 [-Wformat-truncation=]. 306 | snprintf(path, BUFSIZ, ""%s/%s"", *pp, include);. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12200
https://github.com/root-project/root/pull/12200:28,interoperability,format,format,28,"[rmkdepend] Work around GCC format truncation warning:; ```. /home/vpadulan/programs/rootproject/rootsrc/build/rmkdepend/include.c:306:37: warning: ‘%s’ directive output may be truncated writing up to 8190 bytes into a region of size between 1 and 8191 [-Wformat-truncation=]. 306 | snprintf(path, BUFSIZ, ""%s/%s"", *pp, include);. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12200
https://github.com/root-project/root/pull/12201:297,availability,unavail,unavailable,297,"[CI] load openstack credentials from file; [skip-ci]. # This Pull request:. Makes the CI load OpenStack object-store credentials from files on runners instead of using GitHub secrets. When `pull_request` is a workflow trigger, the job can't access secrets, which means that the S3 secret token is unavailable. Adding S3 credentials to the runners themselves solves this issue. The OpenStack credentials are defined [here](https://gitlab.cern.ch/ai/it-puppet-hostgroup-lcgapp/-/blob/rootci_test/code/manifests/build/root.pp#L43) (using [teigi](https://configdocs.web.cern.ch/secrets/adding.html)). If a malicious actor makes a PR with a job to print the credentials, or to upload a malicious artifact, it would still have to be approved by a maintainer. A safer alternative is not allowing pull request jobs to upload artifacts at all but then we can't run tests in a separate job. It would also cause builds to take more time on average because the object storage will be less populated. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12201
https://github.com/root-project/root/pull/12201:509,deployability,build,build,509,"[CI] load openstack credentials from file; [skip-ci]. # This Pull request:. Makes the CI load OpenStack object-store credentials from files on runners instead of using GitHub secrets. When `pull_request` is a workflow trigger, the job can't access secrets, which means that the S3 secret token is unavailable. Adding S3 credentials to the runners themselves solves this issue. The OpenStack credentials are defined [here](https://gitlab.cern.ch/ai/it-puppet-hostgroup-lcgapp/-/blob/rootci_test/code/manifests/build/root.pp#L43) (using [teigi](https://configdocs.web.cern.ch/secrets/adding.html)). If a malicious actor makes a PR with a job to print the credentials, or to upload a malicious artifact, it would still have to be approved by a maintainer. A safer alternative is not allowing pull request jobs to upload artifacts at all but then we can't run tests in a separate job. It would also cause builds to take more time on average because the object storage will be less populated. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12201
https://github.com/root-project/root/pull/12201:691,deployability,artifact,artifact,691,"[CI] load openstack credentials from file; [skip-ci]. # This Pull request:. Makes the CI load OpenStack object-store credentials from files on runners instead of using GitHub secrets. When `pull_request` is a workflow trigger, the job can't access secrets, which means that the S3 secret token is unavailable. Adding S3 credentials to the runners themselves solves this issue. The OpenStack credentials are defined [here](https://gitlab.cern.ch/ai/it-puppet-hostgroup-lcgapp/-/blob/rootci_test/code/manifests/build/root.pp#L43) (using [teigi](https://configdocs.web.cern.ch/secrets/adding.html)). If a malicious actor makes a PR with a job to print the credentials, or to upload a malicious artifact, it would still have to be approved by a maintainer. A safer alternative is not allowing pull request jobs to upload artifacts at all but then we can't run tests in a separate job. It would also cause builds to take more time on average because the object storage will be less populated. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12201
https://github.com/root-project/root/pull/12201:817,deployability,artifact,artifacts,817,"[CI] load openstack credentials from file; [skip-ci]. # This Pull request:. Makes the CI load OpenStack object-store credentials from files on runners instead of using GitHub secrets. When `pull_request` is a workflow trigger, the job can't access secrets, which means that the S3 secret token is unavailable. Adding S3 credentials to the runners themselves solves this issue. The OpenStack credentials are defined [here](https://gitlab.cern.ch/ai/it-puppet-hostgroup-lcgapp/-/blob/rootci_test/code/manifests/build/root.pp#L43) (using [teigi](https://configdocs.web.cern.ch/secrets/adding.html)). If a malicious actor makes a PR with a job to print the credentials, or to upload a malicious artifact, it would still have to be approved by a maintainer. A safer alternative is not allowing pull request jobs to upload artifacts at all but then we can't run tests in a separate job. It would also cause builds to take more time on average because the object storage will be less populated. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12201
https://github.com/root-project/root/pull/12201:901,deployability,build,builds,901,"[CI] load openstack credentials from file; [skip-ci]. # This Pull request:. Makes the CI load OpenStack object-store credentials from files on runners instead of using GitHub secrets. When `pull_request` is a workflow trigger, the job can't access secrets, which means that the S3 secret token is unavailable. Adding S3 credentials to the runners themselves solves this issue. The OpenStack credentials are defined [here](https://gitlab.cern.ch/ai/it-puppet-hostgroup-lcgapp/-/blob/rootci_test/code/manifests/build/root.pp#L43) (using [teigi](https://configdocs.web.cern.ch/secrets/adding.html)). If a malicious actor makes a PR with a job to print the credentials, or to upload a malicious artifact, it would still have to be approved by a maintainer. A safer alternative is not allowing pull request jobs to upload artifacts at all but then we can't run tests in a separate job. It would also cause builds to take more time on average because the object storage will be less populated. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12201
https://github.com/root-project/root/pull/12201:5,energy efficiency,load,load,5,"[CI] load openstack credentials from file; [skip-ci]. # This Pull request:. Makes the CI load OpenStack object-store credentials from files on runners instead of using GitHub secrets. When `pull_request` is a workflow trigger, the job can't access secrets, which means that the S3 secret token is unavailable. Adding S3 credentials to the runners themselves solves this issue. The OpenStack credentials are defined [here](https://gitlab.cern.ch/ai/it-puppet-hostgroup-lcgapp/-/blob/rootci_test/code/manifests/build/root.pp#L43) (using [teigi](https://configdocs.web.cern.ch/secrets/adding.html)). If a malicious actor makes a PR with a job to print the credentials, or to upload a malicious artifact, it would still have to be approved by a maintainer. A safer alternative is not allowing pull request jobs to upload artifacts at all but then we can't run tests in a separate job. It would also cause builds to take more time on average because the object storage will be less populated. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12201
https://github.com/root-project/root/pull/12201:89,energy efficiency,load,load,89,"[CI] load openstack credentials from file; [skip-ci]. # This Pull request:. Makes the CI load OpenStack object-store credentials from files on runners instead of using GitHub secrets. When `pull_request` is a workflow trigger, the job can't access secrets, which means that the S3 secret token is unavailable. Adding S3 credentials to the runners themselves solves this issue. The OpenStack credentials are defined [here](https://gitlab.cern.ch/ai/it-puppet-hostgroup-lcgapp/-/blob/rootci_test/code/manifests/build/root.pp#L43) (using [teigi](https://configdocs.web.cern.ch/secrets/adding.html)). If a malicious actor makes a PR with a job to print the credentials, or to upload a malicious artifact, it would still have to be approved by a maintainer. A safer alternative is not allowing pull request jobs to upload artifacts at all but then we can't run tests in a separate job. It would also cause builds to take more time on average because the object storage will be less populated. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12201
https://github.com/root-project/root/pull/12201:741,modifiability,maintain,maintainer,741,"[CI] load openstack credentials from file; [skip-ci]. # This Pull request:. Makes the CI load OpenStack object-store credentials from files on runners instead of using GitHub secrets. When `pull_request` is a workflow trigger, the job can't access secrets, which means that the S3 secret token is unavailable. Adding S3 credentials to the runners themselves solves this issue. The OpenStack credentials are defined [here](https://gitlab.cern.ch/ai/it-puppet-hostgroup-lcgapp/-/blob/rootci_test/code/manifests/build/root.pp#L43) (using [teigi](https://configdocs.web.cern.ch/secrets/adding.html)). If a malicious actor makes a PR with a job to print the credentials, or to upload a malicious artifact, it would still have to be approved by a maintainer. A safer alternative is not allowing pull request jobs to upload artifacts at all but then we can't run tests in a separate job. It would also cause builds to take more time on average because the object storage will be less populated. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12201
https://github.com/root-project/root/pull/12201:5,performance,load,load,5,"[CI] load openstack credentials from file; [skip-ci]. # This Pull request:. Makes the CI load OpenStack object-store credentials from files on runners instead of using GitHub secrets. When `pull_request` is a workflow trigger, the job can't access secrets, which means that the S3 secret token is unavailable. Adding S3 credentials to the runners themselves solves this issue. The OpenStack credentials are defined [here](https://gitlab.cern.ch/ai/it-puppet-hostgroup-lcgapp/-/blob/rootci_test/code/manifests/build/root.pp#L43) (using [teigi](https://configdocs.web.cern.ch/secrets/adding.html)). If a malicious actor makes a PR with a job to print the credentials, or to upload a malicious artifact, it would still have to be approved by a maintainer. A safer alternative is not allowing pull request jobs to upload artifacts at all but then we can't run tests in a separate job. It would also cause builds to take more time on average because the object storage will be less populated. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12201
https://github.com/root-project/root/pull/12201:89,performance,load,load,89,"[CI] load openstack credentials from file; [skip-ci]. # This Pull request:. Makes the CI load OpenStack object-store credentials from files on runners instead of using GitHub secrets. When `pull_request` is a workflow trigger, the job can't access secrets, which means that the S3 secret token is unavailable. Adding S3 credentials to the runners themselves solves this issue. The OpenStack credentials are defined [here](https://gitlab.cern.ch/ai/it-puppet-hostgroup-lcgapp/-/blob/rootci_test/code/manifests/build/root.pp#L43) (using [teigi](https://configdocs.web.cern.ch/secrets/adding.html)). If a malicious actor makes a PR with a job to print the credentials, or to upload a malicious artifact, it would still have to be approved by a maintainer. A safer alternative is not allowing pull request jobs to upload artifacts at all but then we can't run tests in a separate job. It would also cause builds to take more time on average because the object storage will be less populated. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12201
https://github.com/root-project/root/pull/12201:921,performance,time,time,921,"[CI] load openstack credentials from file; [skip-ci]. # This Pull request:. Makes the CI load OpenStack object-store credentials from files on runners instead of using GitHub secrets. When `pull_request` is a workflow trigger, the job can't access secrets, which means that the S3 secret token is unavailable. Adding S3 credentials to the runners themselves solves this issue. The OpenStack credentials are defined [here](https://gitlab.cern.ch/ai/it-puppet-hostgroup-lcgapp/-/blob/rootci_test/code/manifests/build/root.pp#L43) (using [teigi](https://configdocs.web.cern.ch/secrets/adding.html)). If a malicious actor makes a PR with a job to print the credentials, or to upload a malicious artifact, it would still have to be approved by a maintainer. A safer alternative is not allowing pull request jobs to upload artifacts at all but then we can't run tests in a separate job. It would also cause builds to take more time on average because the object storage will be less populated. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12201
https://github.com/root-project/root/pull/12201:741,safety,maintain,maintainer,741,"[CI] load openstack credentials from file; [skip-ci]. # This Pull request:. Makes the CI load OpenStack object-store credentials from files on runners instead of using GitHub secrets. When `pull_request` is a workflow trigger, the job can't access secrets, which means that the S3 secret token is unavailable. Adding S3 credentials to the runners themselves solves this issue. The OpenStack credentials are defined [here](https://gitlab.cern.ch/ai/it-puppet-hostgroup-lcgapp/-/blob/rootci_test/code/manifests/build/root.pp#L43) (using [teigi](https://configdocs.web.cern.ch/secrets/adding.html)). If a malicious actor makes a PR with a job to print the credentials, or to upload a malicious artifact, it would still have to be approved by a maintainer. A safer alternative is not allowing pull request jobs to upload artifacts at all but then we can't run tests in a separate job. It would also cause builds to take more time on average because the object storage will be less populated. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12201
https://github.com/root-project/root/pull/12201:755,safety,safe,safer,755,"[CI] load openstack credentials from file; [skip-ci]. # This Pull request:. Makes the CI load OpenStack object-store credentials from files on runners instead of using GitHub secrets. When `pull_request` is a workflow trigger, the job can't access secrets, which means that the S3 secret token is unavailable. Adding S3 credentials to the runners themselves solves this issue. The OpenStack credentials are defined [here](https://gitlab.cern.ch/ai/it-puppet-hostgroup-lcgapp/-/blob/rootci_test/code/manifests/build/root.pp#L43) (using [teigi](https://configdocs.web.cern.ch/secrets/adding.html)). If a malicious actor makes a PR with a job to print the credentials, or to upload a malicious artifact, it would still have to be approved by a maintainer. A safer alternative is not allowing pull request jobs to upload artifacts at all but then we can't run tests in a separate job. It would also cause builds to take more time on average because the object storage will be less populated. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12201
https://github.com/root-project/root/pull/12201:856,safety,test,tests,856,"[CI] load openstack credentials from file; [skip-ci]. # This Pull request:. Makes the CI load OpenStack object-store credentials from files on runners instead of using GitHub secrets. When `pull_request` is a workflow trigger, the job can't access secrets, which means that the S3 secret token is unavailable. Adding S3 credentials to the runners themselves solves this issue. The OpenStack credentials are defined [here](https://gitlab.cern.ch/ai/it-puppet-hostgroup-lcgapp/-/blob/rootci_test/code/manifests/build/root.pp#L43) (using [teigi](https://configdocs.web.cern.ch/secrets/adding.html)). If a malicious actor makes a PR with a job to print the credentials, or to upload a malicious artifact, it would still have to be approved by a maintainer. A safer alternative is not allowing pull request jobs to upload artifacts at all but then we can't run tests in a separate job. It would also cause builds to take more time on average because the object storage will be less populated. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12201
https://github.com/root-project/root/pull/12201:1009,safety,test,tested,1009,"[CI] load openstack credentials from file; [skip-ci]. # This Pull request:. Makes the CI load OpenStack object-store credentials from files on runners instead of using GitHub secrets. When `pull_request` is a workflow trigger, the job can't access secrets, which means that the S3 secret token is unavailable. Adding S3 credentials to the runners themselves solves this issue. The OpenStack credentials are defined [here](https://gitlab.cern.ch/ai/it-puppet-hostgroup-lcgapp/-/blob/rootci_test/code/manifests/build/root.pp#L43) (using [teigi](https://configdocs.web.cern.ch/secrets/adding.html)). If a malicious actor makes a PR with a job to print the credentials, or to upload a malicious artifact, it would still have to be approved by a maintainer. A safer alternative is not allowing pull request jobs to upload artifacts at all but then we can't run tests in a separate job. It would also cause builds to take more time on average because the object storage will be less populated. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12201
https://github.com/root-project/root/pull/12201:241,security,access,access,241,"[CI] load openstack credentials from file; [skip-ci]. # This Pull request:. Makes the CI load OpenStack object-store credentials from files on runners instead of using GitHub secrets. When `pull_request` is a workflow trigger, the job can't access secrets, which means that the S3 secret token is unavailable. Adding S3 credentials to the runners themselves solves this issue. The OpenStack credentials are defined [here](https://gitlab.cern.ch/ai/it-puppet-hostgroup-lcgapp/-/blob/rootci_test/code/manifests/build/root.pp#L43) (using [teigi](https://configdocs.web.cern.ch/secrets/adding.html)). If a malicious actor makes a PR with a job to print the credentials, or to upload a malicious artifact, it would still have to be approved by a maintainer. A safer alternative is not allowing pull request jobs to upload artifacts at all but then we can't run tests in a separate job. It would also cause builds to take more time on average because the object storage will be less populated. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12201
https://github.com/root-project/root/pull/12201:288,security,token,token,288,"[CI] load openstack credentials from file; [skip-ci]. # This Pull request:. Makes the CI load OpenStack object-store credentials from files on runners instead of using GitHub secrets. When `pull_request` is a workflow trigger, the job can't access secrets, which means that the S3 secret token is unavailable. Adding S3 credentials to the runners themselves solves this issue. The OpenStack credentials are defined [here](https://gitlab.cern.ch/ai/it-puppet-hostgroup-lcgapp/-/blob/rootci_test/code/manifests/build/root.pp#L43) (using [teigi](https://configdocs.web.cern.ch/secrets/adding.html)). If a malicious actor makes a PR with a job to print the credentials, or to upload a malicious artifact, it would still have to be approved by a maintainer. A safer alternative is not allowing pull request jobs to upload artifacts at all but then we can't run tests in a separate job. It would also cause builds to take more time on average because the object storage will be less populated. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12201
https://github.com/root-project/root/pull/12201:856,testability,test,tests,856,"[CI] load openstack credentials from file; [skip-ci]. # This Pull request:. Makes the CI load OpenStack object-store credentials from files on runners instead of using GitHub secrets. When `pull_request` is a workflow trigger, the job can't access secrets, which means that the S3 secret token is unavailable. Adding S3 credentials to the runners themselves solves this issue. The OpenStack credentials are defined [here](https://gitlab.cern.ch/ai/it-puppet-hostgroup-lcgapp/-/blob/rootci_test/code/manifests/build/root.pp#L43) (using [teigi](https://configdocs.web.cern.ch/secrets/adding.html)). If a malicious actor makes a PR with a job to print the credentials, or to upload a malicious artifact, it would still have to be approved by a maintainer. A safer alternative is not allowing pull request jobs to upload artifacts at all but then we can't run tests in a separate job. It would also cause builds to take more time on average because the object storage will be less populated. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12201
https://github.com/root-project/root/pull/12201:1009,testability,test,tested,1009,"[CI] load openstack credentials from file; [skip-ci]. # This Pull request:. Makes the CI load OpenStack object-store credentials from files on runners instead of using GitHub secrets. When `pull_request` is a workflow trigger, the job can't access secrets, which means that the S3 secret token is unavailable. Adding S3 credentials to the runners themselves solves this issue. The OpenStack credentials are defined [here](https://gitlab.cern.ch/ai/it-puppet-hostgroup-lcgapp/-/blob/rootci_test/code/manifests/build/root.pp#L43) (using [teigi](https://configdocs.web.cern.ch/secrets/adding.html)). If a malicious actor makes a PR with a job to print the credentials, or to upload a malicious artifact, it would still have to be approved by a maintainer. A safer alternative is not allowing pull request jobs to upload artifacts at all but then we can't run tests in a separate job. It would also cause builds to take more time on average because the object storage will be less populated. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12201
https://github.com/root-project/root/pull/12201:209,usability,workflow,workflow,209,"[CI] load openstack credentials from file; [skip-ci]. # This Pull request:. Makes the CI load OpenStack object-store credentials from files on runners instead of using GitHub secrets. When `pull_request` is a workflow trigger, the job can't access secrets, which means that the S3 secret token is unavailable. Adding S3 credentials to the runners themselves solves this issue. The OpenStack credentials are defined [here](https://gitlab.cern.ch/ai/it-puppet-hostgroup-lcgapp/-/blob/rootci_test/code/manifests/build/root.pp#L43) (using [teigi](https://configdocs.web.cern.ch/secrets/adding.html)). If a malicious actor makes a PR with a job to print the credentials, or to upload a malicious artifact, it would still have to be approved by a maintainer. A safer alternative is not allowing pull request jobs to upload artifacts at all but then we can't run tests in a separate job. It would also cause builds to take more time on average because the object storage will be less populated. ## Checklist:. - [x] tested changes locally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12201
https://github.com/root-project/root/pull/12202:98,availability,failur,failure,98,"[RF] LikelihoodJob improved precision; # This Pull request:. ## Changes or fixes:. Triggered by a failure to run an ATLAS Higgs combination fit using the MultiProcess-parallelized LikelihoodJob, this PR changes the way offsetting is handled in the TestStatistics::LikelihoodWrapper family of classes. This in turn improves precision of evaluations, making many parallelized likelihood evaluations now bit-wise exactly equal to non-parallel evaluations. This allows us to better debug the Higgs fit. After this PR, the public Higgs workspace used in rootbench can be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At constru",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:1558,availability,toler,tolerance,1558,"be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous ev",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:98,deployability,fail,failure,98,"[RF] LikelihoodJob improved precision; # This Pull request:. ## Changes or fixes:. Triggered by a failure to run an ATLAS Higgs combination fit using the MultiProcess-parallelized LikelihoodJob, this PR changes the way offsetting is handled in the TestStatistics::LikelihoodWrapper family of classes. This in turn improves precision of evaluations, making many parallelized likelihood evaluations now bit-wise exactly equal to non-parallel evaluations. This allows us to better debug the Higgs fit. After this PR, the public Higgs workspace used in rootbench can be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At constru",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:924,deployability,observ,observable,924,"[RF] LikelihoodJob improved precision; # This Pull request:. ## Changes or fixes:. Triggered by a failure to run an ATLAS Higgs combination fit using the MultiProcess-parallelized LikelihoodJob, this PR changes the way offsetting is handled in the TestStatistics::LikelihoodWrapper family of classes. This in turn improves precision of evaluations, making many parallelized likelihood evaluations now bit-wise exactly equal to non-parallel evaluations. This allows us to better debug the Higgs fit. After this PR, the public Higgs workspace used in rootbench can be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At constru",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:1521,deployability,updat,updates,1521,"Higgs workspace used in rootbench can be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:2969,deployability,contain,contains,2969," of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculatin",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:3204,deployability,manag,managing,3204,"rent offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradientJob ""ConstrainedAndO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:3544,deployability,contain,contains,3544,"the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradientJob ""ConstrainedAndOffset"" test cases used the wrong argument for the constrained parameter. These are now corrected from alpha_bkg_obs_A to become alpha_bkg_A. * In LikelihoodJobTest, the added test case ""UnbinnedGaussian1DSelectedParameterValues"" shows where splitting over events can lead to bit-wise differences. This test will be useful in the future if f",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:3578,deployability,contain,contains,3578,"they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradientJob ""ConstrainedAndOffset"" test cases used the wrong argument for the constrained parameter. These are now corrected from alpha_bkg_obs_A to become alpha_bkg_A. * In LikelihoodJobTest, the added test case ""UnbinnedGaussian1DSelectedParameterValues"" shows where splitting over events can lead to bit-wise differences. This test will be useful in the future if further precision enhancements are ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:4639,deployability,updat,updated,4639,"b doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradientJob ""ConstrainedAndOffset"" test cases used the wrong argument for the constrained parameter. These are now corrected from alpha_bkg_obs_A to become alpha_bkg_A. * In LikelihoodJobTest, the added test case ""UnbinnedGaussian1DSelectedParameterValues"" shows where splitting over events can lead to bit-wise differences. This test will be useful in the future if further precision enhancements are made. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:3204,energy efficiency,manag,managing,3204,"rent offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradientJob ""ConstrainedAndO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:3432,energy efficiency,current,currently,3432,"o all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradientJob ""ConstrainedAndOffset"" test cases used the wrong argument for the constrained parameter. These are now corrected from alpha_bkg_obs_A to become alpha_bkg_A. * In LikelihoodJobTest, the added test case ""UnbinnedGaussian1DSelectedParameterValues"" ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:518,integrability,pub,public,518,"[RF] LikelihoodJob improved precision; # This Pull request:. ## Changes or fixes:. Triggered by a failure to run an ATLAS Higgs combination fit using the MultiProcess-parallelized LikelihoodJob, this PR changes the way offsetting is handled in the TestStatistics::LikelihoodWrapper family of classes. This in turn improves precision of evaluations, making many parallelized likelihood evaluations now bit-wise exactly equal to non-parallel evaluations. This allows us to better debug the Higgs fit. After this PR, the public Higgs workspace used in rootbench can be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At constru",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:671,integrability,compon,component,671,"[RF] LikelihoodJob improved precision; # This Pull request:. ## Changes or fixes:. Triggered by a failure to run an ATLAS Higgs combination fit using the MultiProcess-parallelized LikelihoodJob, this PR changes the way offsetting is handled in the TestStatistics::LikelihoodWrapper family of classes. This in turn improves precision of evaluations, making many parallelized likelihood evaluations now bit-wise exactly equal to non-parallel evaluations. This allows us to better debug the Higgs fit. After this PR, the public Higgs workspace used in rootbench can be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At constru",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:805,integrability,compon,component,805,"[RF] LikelihoodJob improved precision; # This Pull request:. ## Changes or fixes:. Triggered by a failure to run an ATLAS Higgs combination fit using the MultiProcess-parallelized LikelihoodJob, this PR changes the way offsetting is handled in the TestStatistics::LikelihoodWrapper family of classes. This in turn improves precision of evaluations, making many parallelized likelihood evaluations now bit-wise exactly equal to non-parallel evaluations. This allows us to better debug the Higgs fit. After this PR, the public Higgs workspace used in rootbench can be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At constru",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:1047,integrability,compon,component,1047,"equest:. ## Changes or fixes:. Triggered by a failure to run an ATLAS Higgs combination fit using the MultiProcess-parallelized LikelihoodJob, this PR changes the way offsetting is handled in the TestStatistics::LikelihoodWrapper family of classes. This in turn improves precision of evaluations, making many parallelized likelihood evaluations now bit-wise exactly equal to non-parallel evaluations. This allows us to better debug the Higgs fit. After this PR, the public Higgs workspace used in rootbench can be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:3381,integrability,compon,component,3381,"oodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradientJob ""ConstrainedAndOffset"" test cases used the wrong argument for the constrained parameter. These are now corrected from alpha_bkg_obs_A to become alpha_bkg_A. * In LikelihoodJobTest, the added tes",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:3486,integrability,interfac,interface,3486,"eck before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradientJob ""ConstrainedAndOffset"" test cases used the wrong argument for the constrained parameter. These are now corrected from alpha_bkg_obs_A to become alpha_bkg_A. * In LikelihoodJobTest, the added test case ""UnbinnedGaussian1DSelectedParameterValues"" shows where splitting over events can lead to bit-wise",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:4464,integrability,event,events,4464,"b doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradientJob ""ConstrainedAndOffset"" test cases used the wrong argument for the constrained parameter. These are now corrected from alpha_bkg_obs_A to become alpha_bkg_A. * In LikelihoodJobTest, the added test case ""UnbinnedGaussian1DSelectedParameterValues"" shows where splitting over events can lead to bit-wise differences. This test will be useful in the future if further precision enhancements are made. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:671,interoperability,compon,component,671,"[RF] LikelihoodJob improved precision; # This Pull request:. ## Changes or fixes:. Triggered by a failure to run an ATLAS Higgs combination fit using the MultiProcess-parallelized LikelihoodJob, this PR changes the way offsetting is handled in the TestStatistics::LikelihoodWrapper family of classes. This in turn improves precision of evaluations, making many parallelized likelihood evaluations now bit-wise exactly equal to non-parallel evaluations. This allows us to better debug the Higgs fit. After this PR, the public Higgs workspace used in rootbench can be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At constru",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:805,interoperability,compon,component,805,"[RF] LikelihoodJob improved precision; # This Pull request:. ## Changes or fixes:. Triggered by a failure to run an ATLAS Higgs combination fit using the MultiProcess-parallelized LikelihoodJob, this PR changes the way offsetting is handled in the TestStatistics::LikelihoodWrapper family of classes. This in turn improves precision of evaluations, making many parallelized likelihood evaluations now bit-wise exactly equal to non-parallel evaluations. This allows us to better debug the Higgs fit. After this PR, the public Higgs workspace used in rootbench can be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At constru",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:1047,interoperability,compon,component,1047,"equest:. ## Changes or fixes:. Triggered by a failure to run an ATLAS Higgs combination fit using the MultiProcess-parallelized LikelihoodJob, this PR changes the way offsetting is handled in the TestStatistics::LikelihoodWrapper family of classes. This in turn improves precision of evaluations, making many parallelized likelihood evaluations now bit-wise exactly equal to non-parallel evaluations. This allows us to better debug the Higgs fit. After this PR, the public Higgs workspace used in rootbench can be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:3381,interoperability,compon,component,3381,"oodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradientJob ""ConstrainedAndOffset"" test cases used the wrong argument for the constrained parameter. These are now corrected from alpha_bkg_obs_A to become alpha_bkg_A. * In LikelihoodJobTest, the added tes",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:3486,interoperability,interfac,interface,3486,"eck before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradientJob ""ConstrainedAndOffset"" test cases used the wrong argument for the constrained parameter. These are now corrected from alpha_bkg_obs_A to become alpha_bkg_A. * In LikelihoodJobTest, the added test case ""UnbinnedGaussian1DSelectedParameterValues"" shows where splitting over events can lead to bit-wise",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:671,modifiability,compon,component,671,"[RF] LikelihoodJob improved precision; # This Pull request:. ## Changes or fixes:. Triggered by a failure to run an ATLAS Higgs combination fit using the MultiProcess-parallelized LikelihoodJob, this PR changes the way offsetting is handled in the TestStatistics::LikelihoodWrapper family of classes. This in turn improves precision of evaluations, making many parallelized likelihood evaluations now bit-wise exactly equal to non-parallel evaluations. This allows us to better debug the Higgs fit. After this PR, the public Higgs workspace used in rootbench can be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At constru",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:805,modifiability,compon,component,805,"[RF] LikelihoodJob improved precision; # This Pull request:. ## Changes or fixes:. Triggered by a failure to run an ATLAS Higgs combination fit using the MultiProcess-parallelized LikelihoodJob, this PR changes the way offsetting is handled in the TestStatistics::LikelihoodWrapper family of classes. This in turn improves precision of evaluations, making many parallelized likelihood evaluations now bit-wise exactly equal to non-parallel evaluations. This allows us to better debug the Higgs fit. After this PR, the public Higgs workspace used in rootbench can be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At constru",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:1047,modifiability,compon,component,1047,"equest:. ## Changes or fixes:. Triggered by a failure to run an ATLAS Higgs combination fit using the MultiProcess-parallelized LikelihoodJob, this PR changes the way offsetting is handled in the TestStatistics::LikelihoodWrapper family of classes. This in turn improves precision of evaluations, making many parallelized likelihood evaluations now bit-wise exactly equal to non-parallel evaluations. This allows us to better debug the Higgs fit. After this PR, the public Higgs workspace used in rootbench can be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:1741,modifiability,paramet,parameterized,1741,"switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:3381,modifiability,compon,component,3381,"oodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradientJob ""ConstrainedAndOffset"" test cases used the wrong argument for the constrained parameter. These are now corrected from alpha_bkg_obs_A to become alpha_bkg_A. * In LikelihoodJobTest, the added tes",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:3486,modifiability,interfac,interface,3486,"eck before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradientJob ""ConstrainedAndOffset"" test cases used the wrong argument for the constrained parameter. These are now corrected from alpha_bkg_obs_A to become alpha_bkg_A. * In LikelihoodJobTest, the added test case ""UnbinnedGaussian1DSelectedParameterValues"" shows where splitting over events can lead to bit-wise",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:4270,modifiability,paramet,parameter,4270,"b doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradientJob ""ConstrainedAndOffset"" test cases used the wrong argument for the constrained parameter. These are now corrected from alpha_bkg_obs_A to become alpha_bkg_A. * In LikelihoodJobTest, the added test case ""UnbinnedGaussian1DSelectedParameterValues"" shows where splitting over events can lead to bit-wise differences. This test will be useful in the future if further precision enhancements are made. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:98,performance,failur,failure,98,"[RF] LikelihoodJob improved precision; # This Pull request:. ## Changes or fixes:. Triggered by a failure to run an ATLAS Higgs combination fit using the MultiProcess-parallelized LikelihoodJob, this PR changes the way offsetting is handled in the TestStatistics::LikelihoodWrapper family of classes. This in turn improves precision of evaluations, making many parallelized likelihood evaluations now bit-wise exactly equal to non-parallel evaluations. This allows us to better debug the Higgs fit. After this PR, the public Higgs workspace used in rootbench can be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At constru",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:167,performance,parallel,parallelized,167,"[RF] LikelihoodJob improved precision; # This Pull request:. ## Changes or fixes:. Triggered by a failure to run an ATLAS Higgs combination fit using the MultiProcess-parallelized LikelihoodJob, this PR changes the way offsetting is handled in the TestStatistics::LikelihoodWrapper family of classes. This in turn improves precision of evaluations, making many parallelized likelihood evaluations now bit-wise exactly equal to non-parallel evaluations. This allows us to better debug the Higgs fit. After this PR, the public Higgs workspace used in rootbench can be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At constru",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:361,performance,parallel,parallelized,361,"[RF] LikelihoodJob improved precision; # This Pull request:. ## Changes or fixes:. Triggered by a failure to run an ATLAS Higgs combination fit using the MultiProcess-parallelized LikelihoodJob, this PR changes the way offsetting is handled in the TestStatistics::LikelihoodWrapper family of classes. This in turn improves precision of evaluations, making many parallelized likelihood evaluations now bit-wise exactly equal to non-parallel evaluations. This allows us to better debug the Higgs fit. After this PR, the public Higgs workspace used in rootbench can be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At constru",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:431,performance,parallel,parallel,431,"[RF] LikelihoodJob improved precision; # This Pull request:. ## Changes or fixes:. Triggered by a failure to run an ATLAS Higgs combination fit using the MultiProcess-parallelized LikelihoodJob, this PR changes the way offsetting is handled in the TestStatistics::LikelihoodWrapper family of classes. This in turn improves precision of evaluations, making many parallelized likelihood evaluations now bit-wise exactly equal to non-parallel evaluations. This allows us to better debug the Higgs fit. After this PR, the public Higgs workspace used in rootbench can be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At constru",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:1860,performance,synch,synchronization,1860,"simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:2006,performance,time,time,2006,"LLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as w",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:2234,performance,time,times,2234,"the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscell",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:2423,performance,synch,synchronized,2423,"ke the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:2755,performance,synch,synchronize,2755,"atrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper no",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:98,reliability,fail,failure,98,"[RF] LikelihoodJob improved precision; # This Pull request:. ## Changes or fixes:. Triggered by a failure to run an ATLAS Higgs combination fit using the MultiProcess-parallelized LikelihoodJob, this PR changes the way offsetting is handled in the TestStatistics::LikelihoodWrapper family of classes. This in turn improves precision of evaluations, making many parallelized likelihood evaluations now bit-wise exactly equal to non-parallel evaluations. This allows us to better debug the Higgs fit. After this PR, the public Higgs workspace used in rootbench can be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At constru",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:1558,reliability,toleran,tolerance,1558,"be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous ev",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:2672,reliability,doe,doesn,2672,"ing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future dev",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:2706,reliability,doe,doesn,2706,"dientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:248,safety,Test,TestStatistics,248,"[RF] LikelihoodJob improved precision; # This Pull request:. ## Changes or fixes:. Triggered by a failure to run an ATLAS Higgs combination fit using the MultiProcess-parallelized LikelihoodJob, this PR changes the way offsetting is handled in the TestStatistics::LikelihoodWrapper family of classes. This in turn improves precision of evaluations, making many parallelized likelihood evaluations now bit-wise exactly equal to non-parallel evaluations. This allows us to better debug the Higgs fit. After this PR, the public Higgs workspace used in rootbench can be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At constru",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:1521,safety,updat,updates,1521,"Higgs workspace used in rootbench can be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:1571,safety,test,tests,1571," LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation an",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:1580,safety,test,testLikelihoodSerial,1580,"nabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:1602,safety,test,testLikelihoodJob,1602,"is PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiP",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:1624,safety,test,testLikelihoodGradientJob,1624,"g:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note th",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:1661,safety,test,tests,1661," * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGrad",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:1692,safety,test,testLikelihoodGradientJob,1692,"offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:1755,safety,test,test,1755,"to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still sy",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:1811,safety,test,test,1811,"t. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculati",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:3204,safety,manag,managing,3204,"rent offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradientJob ""ConstrainedAndO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:3922,safety,avoid,avoids,3922,"b doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradientJob ""ConstrainedAndOffset"" test cases used the wrong argument for the constrained parameter. These are now corrected from alpha_bkg_obs_A to become alpha_bkg_A. * In LikelihoodJobTest, the added test case ""UnbinnedGaussian1DSelectedParameterValues"" shows where splitting over events can lead to bit-wise differences. This test will be useful in the future if further precision enhancements are made. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:4215,safety,test,test,4215,"b doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradientJob ""ConstrainedAndOffset"" test cases used the wrong argument for the constrained parameter. These are now corrected from alpha_bkg_obs_A to become alpha_bkg_A. * In LikelihoodJobTest, the added test case ""UnbinnedGaussian1DSelectedParameterValues"" shows where splitting over events can lead to bit-wise differences. This test will be useful in the future if further precision enhancements are made. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:4383,safety,test,test,4383,"b doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradientJob ""ConstrainedAndOffset"" test cases used the wrong argument for the constrained parameter. These are now corrected from alpha_bkg_obs_A to become alpha_bkg_A. * In LikelihoodJobTest, the added test case ""UnbinnedGaussian1DSelectedParameterValues"" shows where splitting over events can lead to bit-wise differences. This test will be useful in the future if further precision enhancements are made. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:4510,safety,test,test,4510,"b doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradientJob ""ConstrainedAndOffset"" test cases used the wrong argument for the constrained parameter. These are now corrected from alpha_bkg_obs_A to become alpha_bkg_A. * In LikelihoodJobTest, the added test case ""UnbinnedGaussian1DSelectedParameterValues"" shows where splitting over events can lead to bit-wise differences. This test will be useful in the future if further precision enhancements are made. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:4609,safety,test,tested,4609,"b doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradientJob ""ConstrainedAndOffset"" test cases used the wrong argument for the constrained parameter. These are now corrected from alpha_bkg_obs_A to become alpha_bkg_A. * In LikelihoodJobTest, the added test case ""UnbinnedGaussian1DSelectedParameterValues"" shows where splitting over events can lead to bit-wise differences. This test will be useful in the future if further precision enhancements are made. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:4639,safety,updat,updated,4639,"b doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradientJob ""ConstrainedAndOffset"" test cases used the wrong argument for the constrained parameter. These are now corrected from alpha_bkg_obs_A to become alpha_bkg_A. * In LikelihoodJobTest, the added test case ""UnbinnedGaussian1DSelectedParameterValues"" shows where splitting over events can lead to bit-wise differences. This test will be useful in the future if further precision enhancements are made. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:1521,security,updat,updates,1521,"Higgs workspace used in rootbench can be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offs",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:4639,security,updat,updated,4639,"b doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradientJob ""ConstrainedAndOffset"" test cases used the wrong argument for the constrained parameter. These are now corrected from alpha_bkg_obs_A to become alpha_bkg_A. * In LikelihoodJobTest, the added test case ""UnbinnedGaussian1DSelectedParameterValues"" shows where splitting over events can lead to bit-wise differences. This test will be useful in the future if further precision enhancements are made. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:248,testability,Test,TestStatistics,248,"[RF] LikelihoodJob improved precision; # This Pull request:. ## Changes or fixes:. Triggered by a failure to run an ATLAS Higgs combination fit using the MultiProcess-parallelized LikelihoodJob, this PR changes the way offsetting is handled in the TestStatistics::LikelihoodWrapper family of classes. This in turn improves precision of evaluations, making many parallelized likelihood evaluations now bit-wise exactly equal to non-parallel evaluations. This allows us to better debug the Higgs fit. After this PR, the public Higgs workspace used in rootbench can be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At constru",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:868,testability,simul,simultaneous,868,"[RF] LikelihoodJob improved precision; # This Pull request:. ## Changes or fixes:. Triggered by a failure to run an ATLAS Higgs combination fit using the MultiProcess-parallelized LikelihoodJob, this PR changes the way offsetting is handled in the TestStatistics::LikelihoodWrapper family of classes. This in turn improves precision of evaluations, making many parallelized likelihood evaluations now bit-wise exactly equal to non-parallel evaluations. This allows us to better debug the Higgs fit. After this PR, the public Higgs workspace used in rootbench can be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At constru",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:924,testability,observ,observable,924,"[RF] LikelihoodJob improved precision; # This Pull request:. ## Changes or fixes:. Triggered by a failure to run an ATLAS Higgs combination fit using the MultiProcess-parallelized LikelihoodJob, this PR changes the way offsetting is handled in the TestStatistics::LikelihoodWrapper family of classes. This in turn improves precision of evaluations, making many parallelized likelihood evaluations now bit-wise exactly equal to non-parallel evaluations. This allows us to better debug the Higgs fit. After this PR, the public Higgs workspace used in rootbench can be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At constru",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:1571,testability,test,tests,1571," LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation an",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:1580,testability,test,testLikelihoodSerial,1580,"nabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:1602,testability,test,testLikelihoodJob,1602,"is PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiP",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:1624,testability,test,testLikelihoodGradientJob,1624,"g:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note th",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:1661,testability,test,tests,1661," * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGrad",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:1692,testability,test,testLikelihoodGradientJob,1692,"offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:1755,testability,test,test,1755,"to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still sy",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:1811,testability,test,test,1811,"t. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculati",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:2255,testability,understand,understandably,2255,"sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * Likeli",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:2482,testability,simpl,simply,2482,"se changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:4215,testability,test,test,4215,"b doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradientJob ""ConstrainedAndOffset"" test cases used the wrong argument for the constrained parameter. These are now corrected from alpha_bkg_obs_A to become alpha_bkg_A. * In LikelihoodJobTest, the added test case ""UnbinnedGaussian1DSelectedParameterValues"" shows where splitting over events can lead to bit-wise differences. This test will be useful in the future if further precision enhancements are made. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:4383,testability,test,test,4383,"b doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradientJob ""ConstrainedAndOffset"" test cases used the wrong argument for the constrained parameter. These are now corrected from alpha_bkg_obs_A to become alpha_bkg_A. * In LikelihoodJobTest, the added test case ""UnbinnedGaussian1DSelectedParameterValues"" shows where splitting over events can lead to bit-wise differences. This test will be useful in the future if further precision enhancements are made. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:4510,testability,test,test,4510,"b doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradientJob ""ConstrainedAndOffset"" test cases used the wrong argument for the constrained parameter. These are now corrected from alpha_bkg_obs_A to become alpha_bkg_A. * In LikelihoodJobTest, the added test case ""UnbinnedGaussian1DSelectedParameterValues"" shows where splitting over events can lead to bit-wise differences. This test will be useful in the future if further precision enhancements are made. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:4609,testability,test,tested,4609,"b doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradientJob ""ConstrainedAndOffset"" test cases used the wrong argument for the constrained parameter. These are now corrected from alpha_bkg_obs_A to become alpha_bkg_A. * In LikelihoodJobTest, the added test case ""UnbinnedGaussian1DSelectedParameterValues"" shows where splitting over events can lead to bit-wise differences. This test will be useful in the future if further precision enhancements are made. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:980,usability,close,closer,980,"[RF] LikelihoodJob improved precision; # This Pull request:. ## Changes or fixes:. Triggered by a failure to run an ATLAS Higgs combination fit using the MultiProcess-parallelized LikelihoodJob, this PR changes the way offsetting is handled in the TestStatistics::LikelihoodWrapper family of classes. This in turn improves precision of evaluations, making many parallelized likelihood evaluations now bit-wise exactly equal to non-parallel evaluations. This allows us to better debug the Higgs fit. After this PR, the public Higgs workspace used in rootbench can be fit with LikelihoodJob enabled. In detail, this PR changes the following:. - Increased precision:. * Per-component offsets: instead of one offset for the total LikelihoodWrapper, we switched to a vector of offsets: one for each likelihood component. This makes a difference only for RooSumL fits, i.e. simultaneous PDF fits or fits with constraint or global observable terms. This brings the results of these fits closer to the old-style RooNLLVar fits, because those also use per-component offsets (per-RooNLLVar in a RooAddition to be exact). * In LikelihoodJob::evaluate, the result_ KahanSum is no longer initialized to zero, but is initialized to the first value in the results_ array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At constru",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:2245,usability,minim,minimizer,2245,"array, both sum and carry term. This sometimes makes a difference: adding a term with a small but non-zero carry term to an existing sum with a zero sum and zero carry term can make the small non-zero carry term disappear. * Due to these changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous change",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:2482,usability,simpl,simply,2482,"se changes and the earlier KahanSum updates, we were able to tighten the tolerance of tests in testLikelihoodSerial, testLikelihoodJob and testLikelihoodGradientJob, with many tests now passing EXPECT_EQ. * testLikelihoodGradientJob adds offsetting to the parameterized test matrices of the LikelihoodGradientJobTest cases to test all the above (and below) changes. - Offset synchronization:. * LikelihoodWrapper and LikelihoodGradientWrapper now store a shared_ptr to the offsets instead of raw offsets. At construction time within a MinuitFcnGrad, they get passed the same single offset object so that it is always kept synced between the different likelihood calculators. If it isn't synced and the likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:3183,usability,help,helper,3183," likelihood gets different offsets at different times, the minimizer understandably gets very confused. This was the case before this commit, which was, in fact, a bug. * For LikelihoodJob and LikelihoodGradientJob, the offsets are also synchronized to all workers via update_state. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradie",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12202:3460,usability,user,users,3460,"tate. For this, we simply check before evaluation whether offsets have changed since the previous evaluation and if so they are sent over the MultiProcess::Messenger. Note that while the LikelihoodGradientJob doesn't itself use the offset (it doesn't calculate the likelihood), it must still synchronize offsets, because during the gradient calculation the LikelihoodSerial objects on the workers are used to calculate the likelihoods there, so for them the offsets must be up to date. * The LikelihoodJob contains a LikelihoodSerial member as well now. This allows the LikelihoodJob to trigger calculating the offsets on the master process before sending them to the workers. * LikelihoodWrapper has some added private helper functions for managing offsets. - Other miscellaneous changes:. * LikelihoodWrapper::setApplyWeightSquared was implemented properly for RooSumL likelihoods as well, passing along the call to component RooUnbinnedLs. Note, however, that it is currently not reachable for users because there is no interface to pass this along from the RooMinimizer, which contains the MinuitFcnGrad, which contains the LikelihoodWrapper. A comment in MinuitFcnGrad.h refers to this, reminding future devs to also flip offsets_reset_ when (un)setting squared weights. * LikelihoodWrapper now holds the likelihood_type. This cleans up some code duplication in LikelihoodSerial and LikelihoodJob, which previously used the type only in their ctors, and avoids dynamic_casts later, e.g. on when calculating offsets. * A RooSubsidiaryL can now also be computed with LikelihoodSerial and LikelihoodJob; this case was still missing in their evaluation functions. * The LikelihoodSerial, LikelihoodJob and LikelihoodGradientJob ""ConstrainedAndOffset"" test cases used the wrong argument for the constrained parameter. These are now corrected from alpha_bkg_obs_A to become alpha_bkg_A. * In LikelihoodJobTest, the added test case ""UnbinnedGaussian1DSelectedParameterValues"" shows where splitting over",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12202
https://github.com/root-project/root/pull/12203:139,deployability,build,build,139,"[cmake] Remove deprecated alien option, deprecate gfal gsl_shared jemalloc monalisa pyroot_legacy tcmalloc xproofd.; For `alien`, only the build option is removed; the corresponding code will be removed in master. `gsl_shared` is unused. These are a) untested and b) to my knowledge not used by any experiment. (ALICE does not use ROOT's monalisa module.). If we don't deprecate these now we have to wait another release cycle.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12203
https://github.com/root-project/root/pull/12203:347,deployability,modul,module,347,"[cmake] Remove deprecated alien option, deprecate gfal gsl_shared jemalloc monalisa pyroot_legacy tcmalloc xproofd.; For `alien`, only the build option is removed; the corresponding code will be removed in master. `gsl_shared` is unused. These are a) untested and b) to my knowledge not used by any experiment. (ALICE does not use ROOT's monalisa module.). If we don't deprecate these now we have to wait another release cycle.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12203
https://github.com/root-project/root/pull/12203:413,deployability,releas,release,413,"[cmake] Remove deprecated alien option, deprecate gfal gsl_shared jemalloc monalisa pyroot_legacy tcmalloc xproofd.; For `alien`, only the build option is removed; the corresponding code will be removed in master. `gsl_shared` is unused. These are a) untested and b) to my knowledge not used by any experiment. (ALICE does not use ROOT's monalisa module.). If we don't deprecate these now we have to wait another release cycle.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12203
https://github.com/root-project/root/pull/12203:347,modifiability,modul,module,347,"[cmake] Remove deprecated alien option, deprecate gfal gsl_shared jemalloc monalisa pyroot_legacy tcmalloc xproofd.; For `alien`, only the build option is removed; the corresponding code will be removed in master. `gsl_shared` is unused. These are a) untested and b) to my knowledge not used by any experiment. (ALICE does not use ROOT's monalisa module.). If we don't deprecate these now we have to wait another release cycle.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12203
https://github.com/root-project/root/pull/12203:318,reliability,doe,does,318,"[cmake] Remove deprecated alien option, deprecate gfal gsl_shared jemalloc monalisa pyroot_legacy tcmalloc xproofd.; For `alien`, only the build option is removed; the corresponding code will be removed in master. `gsl_shared` is unused. These are a) untested and b) to my knowledge not used by any experiment. (ALICE does not use ROOT's monalisa module.). If we don't deprecate these now we have to wait another release cycle.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12203
https://github.com/root-project/root/pull/12203:347,safety,modul,module,347,"[cmake] Remove deprecated alien option, deprecate gfal gsl_shared jemalloc monalisa pyroot_legacy tcmalloc xproofd.; For `alien`, only the build option is removed; the corresponding code will be removed in master. `gsl_shared` is unused. These are a) untested and b) to my knowledge not used by any experiment. (ALICE does not use ROOT's monalisa module.). If we don't deprecate these now we have to wait another release cycle.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12203
https://github.com/root-project/root/pull/12206:229,deployability,updat,updated,229,PYMVA: removed deprecated code; # This Pull request:. remove deprecated code for PyMVA. ## Changes or fixes:. remove a couple of methods for python that are not needed anymore. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12206
https://github.com/root-project/root/pull/12206:119,integrability,coupl,couple,119,PYMVA: removed deprecated code; # This Pull request:. remove deprecated code for PyMVA. ## Changes or fixes:. remove a couple of methods for python that are not needed anymore. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12206
https://github.com/root-project/root/pull/12206:119,modifiability,coupl,couple,119,PYMVA: removed deprecated code; # This Pull request:. remove deprecated code for PyMVA. ## Changes or fixes:. remove a couple of methods for python that are not needed anymore. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12206
https://github.com/root-project/root/pull/12206:199,safety,test,tested,199,PYMVA: removed deprecated code; # This Pull request:. remove deprecated code for PyMVA. ## Changes or fixes:. remove a couple of methods for python that are not needed anymore. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12206
https://github.com/root-project/root/pull/12206:229,safety,updat,updated,229,PYMVA: removed deprecated code; # This Pull request:. remove deprecated code for PyMVA. ## Changes or fixes:. remove a couple of methods for python that are not needed anymore. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12206
https://github.com/root-project/root/pull/12206:229,security,updat,updated,229,PYMVA: removed deprecated code; # This Pull request:. remove deprecated code for PyMVA. ## Changes or fixes:. remove a couple of methods for python that are not needed anymore. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12206
https://github.com/root-project/root/pull/12206:119,testability,coupl,couple,119,PYMVA: removed deprecated code; # This Pull request:. remove deprecated code for PyMVA. ## Changes or fixes:. remove a couple of methods for python that are not needed anymore. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12206
https://github.com/root-project/root/pull/12206:199,testability,test,tested,199,PYMVA: removed deprecated code; # This Pull request:. remove deprecated code for PyMVA. ## Changes or fixes:. remove a couple of methods for python that are not needed anymore. ## Checklist:. - [ X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12206
https://github.com/root-project/root/pull/12207:10,deployability,updat,updates,10,[RF] HS3: updates to reflect the suggested changes in the RooFit JSON standard; * Use proper infinity checks in RooFit HS3. * New `domains` section in JSON to store variable ranges. * Some refactoring of RooFit HS3. * Decouple `RooDataHist` reading from rest of workspace in RooFitHS3. * Add likelihoods and analyses fields for HS3 v2. * Complete also the reading of likelihoods and analysis fields. * Rename fields in JSON file to match new standard. More description in the commit descriptions.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12207
https://github.com/root-project/root/pull/12207:70,interoperability,standard,standard,70,[RF] HS3: updates to reflect the suggested changes in the RooFit JSON standard; * Use proper infinity checks in RooFit HS3. * New `domains` section in JSON to store variable ranges. * Some refactoring of RooFit HS3. * Decouple `RooDataHist` reading from rest of workspace in RooFitHS3. * Add likelihoods and analyses fields for HS3 v2. * Complete also the reading of likelihoods and analysis fields. * Rename fields in JSON file to match new standard. More description in the commit descriptions.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12207
https://github.com/root-project/root/pull/12207:442,interoperability,standard,standard,442,[RF] HS3: updates to reflect the suggested changes in the RooFit JSON standard; * Use proper infinity checks in RooFit HS3. * New `domains` section in JSON to store variable ranges. * Some refactoring of RooFit HS3. * Decouple `RooDataHist` reading from rest of workspace in RooFitHS3. * Add likelihoods and analyses fields for HS3 v2. * Complete also the reading of likelihoods and analysis fields. * Rename fields in JSON file to match new standard. More description in the commit descriptions.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12207
https://github.com/root-project/root/pull/12207:165,modifiability,variab,variable,165,[RF] HS3: updates to reflect the suggested changes in the RooFit JSON standard; * Use proper infinity checks in RooFit HS3. * New `domains` section in JSON to store variable ranges. * Some refactoring of RooFit HS3. * Decouple `RooDataHist` reading from rest of workspace in RooFitHS3. * Add likelihoods and analyses fields for HS3 v2. * Complete also the reading of likelihoods and analysis fields. * Rename fields in JSON file to match new standard. More description in the commit descriptions.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12207
https://github.com/root-project/root/pull/12207:189,modifiability,refact,refactoring,189,[RF] HS3: updates to reflect the suggested changes in the RooFit JSON standard; * Use proper infinity checks in RooFit HS3. * New `domains` section in JSON to store variable ranges. * Some refactoring of RooFit HS3. * Decouple `RooDataHist` reading from rest of workspace in RooFitHS3. * Add likelihoods and analyses fields for HS3 v2. * Complete also the reading of likelihoods and analysis fields. * Rename fields in JSON file to match new standard. More description in the commit descriptions.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12207
https://github.com/root-project/root/pull/12207:218,modifiability,Deco,Decouple,218,[RF] HS3: updates to reflect the suggested changes in the RooFit JSON standard; * Use proper infinity checks in RooFit HS3. * New `domains` section in JSON to store variable ranges. * Some refactoring of RooFit HS3. * Decouple `RooDataHist` reading from rest of workspace in RooFitHS3. * Add likelihoods and analyses fields for HS3 v2. * Complete also the reading of likelihoods and analysis fields. * Rename fields in JSON file to match new standard. More description in the commit descriptions.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12207
https://github.com/root-project/root/pull/12207:189,performance,refactor,refactoring,189,[RF] HS3: updates to reflect the suggested changes in the RooFit JSON standard; * Use proper infinity checks in RooFit HS3. * New `domains` section in JSON to store variable ranges. * Some refactoring of RooFit HS3. * Decouple `RooDataHist` reading from rest of workspace in RooFitHS3. * Add likelihoods and analyses fields for HS3 v2. * Complete also the reading of likelihoods and analysis fields. * Rename fields in JSON file to match new standard. More description in the commit descriptions.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12207
https://github.com/root-project/root/pull/12207:10,safety,updat,updates,10,[RF] HS3: updates to reflect the suggested changes in the RooFit JSON standard; * Use proper infinity checks in RooFit HS3. * New `domains` section in JSON to store variable ranges. * Some refactoring of RooFit HS3. * Decouple `RooDataHist` reading from rest of workspace in RooFitHS3. * Add likelihoods and analyses fields for HS3 v2. * Complete also the reading of likelihoods and analysis fields. * Rename fields in JSON file to match new standard. More description in the commit descriptions.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12207
https://github.com/root-project/root/pull/12207:338,safety,Compl,Complete,338,[RF] HS3: updates to reflect the suggested changes in the RooFit JSON standard; * Use proper infinity checks in RooFit HS3. * New `domains` section in JSON to store variable ranges. * Some refactoring of RooFit HS3. * Decouple `RooDataHist` reading from rest of workspace in RooFitHS3. * Add likelihoods and analyses fields for HS3 v2. * Complete also the reading of likelihoods and analysis fields. * Rename fields in JSON file to match new standard. More description in the commit descriptions.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12207
https://github.com/root-project/root/pull/12207:10,security,updat,updates,10,[RF] HS3: updates to reflect the suggested changes in the RooFit JSON standard; * Use proper infinity checks in RooFit HS3. * New `domains` section in JSON to store variable ranges. * Some refactoring of RooFit HS3. * Decouple `RooDataHist` reading from rest of workspace in RooFitHS3. * Add likelihoods and analyses fields for HS3 v2. * Complete also the reading of likelihoods and analysis fields. * Rename fields in JSON file to match new standard. More description in the commit descriptions.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12207
https://github.com/root-project/root/pull/12207:338,security,Compl,Complete,338,[RF] HS3: updates to reflect the suggested changes in the RooFit JSON standard; * Use proper infinity checks in RooFit HS3. * New `domains` section in JSON to store variable ranges. * Some refactoring of RooFit HS3. * Decouple `RooDataHist` reading from rest of workspace in RooFitHS3. * Add likelihoods and analyses fields for HS3 v2. * Complete also the reading of likelihoods and analysis fields. * Rename fields in JSON file to match new standard. More description in the commit descriptions.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12207
https://github.com/root-project/root/issues/12208:1902,availability,replic,replicated,1902,"ly transported. Float7BitMantissa_t might be more verbose. . Regarding the limits, I notice that for most types, the listed values are the minimum/maximum value that type can take, for example:. ```const UInt_t kMaxUInt = UInt_t(~0);```. (NB: on a system where ``sizeof(int)==2``, the compiler is (afaik) free to interpret 0 as int, whose complement will then be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and even smaller startups are picking up on the trend. ``</sarcasm>``. (Also, while the kMaxUShort error is rendered harmless by the bitshift in kMaxShort, the kMaxUChar error means that kMinChar and kMaxChar are wrong. In fact, Char_t(kMinChar)>Char_t(kMaxChar) is true. However, nine out of ten math professors agree that the maximum of a set of values should be at least as large as the minimum of that set. ``[[citation needed]]``). These issues have been present in the codebase since at least ROOT5, so fixing them would break backwards compatibility. My suggestion is a different one. C++14 introduces an attribute called ``[[deprecated]]``. ```. [[deprecated(""kMaxUChar has a misleading value and should not be used."". "" Please use std::numeric_limits<unsigned char>::max()"")]] . const Int_t kMaxUChar = 256;. ```. And while we are at it, let's be honest: Most users are already somewhat aware that there ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:2093,availability,error,error,2093,"ple:. ```const UInt_t kMaxUInt = UInt_t(~0);```. (NB: on a system where ``sizeof(int)==2``, the compiler is (afaik) free to interpret 0 as int, whose complement will then be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and even smaller startups are picking up on the trend. ``</sarcasm>``. (Also, while the kMaxUShort error is rendered harmless by the bitshift in kMaxShort, the kMaxUChar error means that kMinChar and kMaxChar are wrong. In fact, Char_t(kMinChar)>Char_t(kMaxChar) is true. However, nine out of ten math professors agree that the maximum of a set of values should be at least as large as the minimum of that set. ``[[citation needed]]``). These issues have been present in the codebase since at least ROOT5, so fixing them would break backwards compatibility. My suggestion is a different one. C++14 introduces an attribute called ``[[deprecated]]``. ```. [[deprecated(""kMaxUChar has a misleading value and should not be used."". "" Please use std::numeric_limits<unsigned char>::max()"")]] . const Int_t kMaxUChar = 256;. ```. And while we are at it, let's be honest: Most users are already somewhat aware that there is a C++ ecosystem outside the safe-ish space that is ROOT. The fallout of vendor-specific implementations has long decayed to a safe level, the air is fresh and breathable, standard compli",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:2164,availability,error,error,2164," ``sizeof(int)==2``, the compiler is (afaik) free to interpret 0 as int, whose complement will then be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and even smaller startups are picking up on the trend. ``</sarcasm>``. (Also, while the kMaxUShort error is rendered harmless by the bitshift in kMaxShort, the kMaxUChar error means that kMinChar and kMaxChar are wrong. In fact, Char_t(kMinChar)>Char_t(kMaxChar) is true. However, nine out of ten math professors agree that the maximum of a set of values should be at least as large as the minimum of that set. ``[[citation needed]]``). These issues have been present in the codebase since at least ROOT5, so fixing them would break backwards compatibility. My suggestion is a different one. C++14 introduces an attribute called ``[[deprecated]]``. ```. [[deprecated(""kMaxUChar has a misleading value and should not be used."". "" Please use std::numeric_limits<unsigned char>::max()"")]] . const Int_t kMaxUChar = 256;. ```. And while we are at it, let's be honest: Most users are already somewhat aware that there is a C++ ecosystem outside the safe-ish space that is ROOT. The fallout of vendor-specific implementations has long decayed to a safe level, the air is fresh and breathable, standard compliant implementations are blooming. Thus:. ```. [[deprecated(""Just call i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:602,energy efficiency,core,core,602,"Deprecating RtypesCore.h; Dear ROOT devs,. as you may be aware, recent developments in the standardization of C++ brought the C99 **stdint** to C++11. When the original Rtypes.h was written in the nineties, there may have been some need for making sure that sizeof(int) was at least 4. Today, some 37 years after the Intel 80386, I suspect that the only systems where ``sizeof(int)==2`` are 16 bit microcontrollers which lack _any_ 32 bit data types and are probably a bit too constrained with regard to addressable memory to run ROOT. . [RtypesCore.h](https://github.com/root-project/root/blob/master/core/foundation/inc/RtypesCore.h) seems to be a bit outdated. . From my understanding, Float16_t and Double32_t are meant to warn the user that parts of the mantissa are truncated. Given the prevalence of stdint (where the number denotes the stored size in bits), I am unsure if that meaning is successfully transported. Float7BitMantissa_t might be more verbose. . Regarding the limits, I notice that for most types, the listed values are the minimum/maximum value that type can take, for example:. ```const UInt_t kMaxUInt = UInt_t(~0);```. (NB: on a system where ``sizeof(int)==2``, the compiler is (afaik) free to interpret 0 as int, whose complement will then be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and ev",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:91,integrability,standardiz,standardization,91,"Deprecating RtypesCore.h; Dear ROOT devs,. as you may be aware, recent developments in the standardization of C++ brought the C99 **stdint** to C++11. When the original Rtypes.h was written in the nineties, there may have been some need for making sure that sizeof(int) was at least 4. Today, some 37 years after the Intel 80386, I suspect that the only systems where ``sizeof(int)==2`` are 16 bit microcontrollers which lack _any_ 32 bit data types and are probably a bit too constrained with regard to addressable memory to run ROOT. . [RtypesCore.h](https://github.com/root-project/root/blob/master/core/foundation/inc/RtypesCore.h) seems to be a bit outdated. . From my understanding, Float16_t and Double32_t are meant to warn the user that parts of the mantissa are truncated. Given the prevalence of stdint (where the number denotes the stored size in bits), I am unsure if that meaning is successfully transported. Float7BitMantissa_t might be more verbose. . Regarding the limits, I notice that for most types, the listed values are the minimum/maximum value that type can take, for example:. ```const UInt_t kMaxUInt = UInt_t(~0);```. (NB: on a system where ``sizeof(int)==2``, the compiler is (afaik) free to interpret 0 as int, whose complement will then be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and ev",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:1453,integrability,pub,publications,1453,"robably a bit too constrained with regard to addressable memory to run ROOT. . [RtypesCore.h](https://github.com/root-project/root/blob/master/core/foundation/inc/RtypesCore.h) seems to be a bit outdated. . From my understanding, Float16_t and Double32_t are meant to warn the user that parts of the mantissa are truncated. Given the prevalence of stdint (where the number denotes the stored size in bits), I am unsure if that meaning is successfully transported. Float7BitMantissa_t might be more verbose. . Regarding the limits, I notice that for most types, the listed values are the minimum/maximum value that type can take, for example:. ```const UInt_t kMaxUInt = UInt_t(~0);```. (NB: on a system where ``sizeof(int)==2``, the compiler is (afaik) free to interpret 0 as int, whose complement will then be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and even smaller startups are picking up on the trend. ``</sarcasm>``. (Also, while the kMaxUShort error is rendered harmless by the bitshift in kMaxShort, the kMaxUChar error means that kMinChar and kMaxChar are wrong. In fact, Char_t(kMinChar)>Char_t(kMaxChar) is true. However, nine out of ten math professors agree that the maximum of a set of values should be at least as large as the minimum of that set. ``[[citation needed]]``). These issues have been prese",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:1943,integrability,rout,routinely,1943," be more verbose. . Regarding the limits, I notice that for most types, the listed values are the minimum/maximum value that type can take, for example:. ```const UInt_t kMaxUInt = UInt_t(~0);```. (NB: on a system where ``sizeof(int)==2``, the compiler is (afaik) free to interpret 0 as int, whose complement will then be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and even smaller startups are picking up on the trend. ``</sarcasm>``. (Also, while the kMaxUShort error is rendered harmless by the bitshift in kMaxShort, the kMaxUChar error means that kMinChar and kMaxChar are wrong. In fact, Char_t(kMinChar)>Char_t(kMaxChar) is true. However, nine out of ten math professors agree that the maximum of a set of values should be at least as large as the minimum of that set. ``[[citation needed]]``). These issues have been present in the codebase since at least ROOT5, so fixing them would break backwards compatibility. My suggestion is a different one. C++14 introduces an attribute called ``[[deprecated]]``. ```. [[deprecated(""kMaxUChar has a misleading value and should not be used."". "" Please use std::numeric_limits<unsigned char>::max()"")]] . const Int_t kMaxUChar = 256;. ```. And while we are at it, let's be honest: Most users are already somewhat aware that there is a C++ ecosystem outside the safe-ish s",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:3090,integrability,complian,compliant,3090,"be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and even smaller startups are picking up on the trend. ``</sarcasm>``. (Also, while the kMaxUShort error is rendered harmless by the bitshift in kMaxShort, the kMaxUChar error means that kMinChar and kMaxChar are wrong. In fact, Char_t(kMinChar)>Char_t(kMaxChar) is true. However, nine out of ten math professors agree that the maximum of a set of values should be at least as large as the minimum of that set. ``[[citation needed]]``). These issues have been present in the codebase since at least ROOT5, so fixing them would break backwards compatibility. My suggestion is a different one. C++14 introduces an attribute called ``[[deprecated]]``. ```. [[deprecated(""kMaxUChar has a misleading value and should not be used."". "" Please use std::numeric_limits<unsigned char>::max()"")]] . const Int_t kMaxUChar = 256;. ```. And while we are at it, let's be honest: Most users are already somewhat aware that there is a C++ ecosystem outside the safe-ish space that is ROOT. The fallout of vendor-specific implementations has long decayed to a safe level, the air is fresh and breathable, standard compliant implementations are blooming. Thus:. ```. [[deprecated(""Just call it \""int\""."")]]. typedef int Int_t; //Signed integer 4 bytes (int). ```. Just my two cents,. Philipp.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:91,interoperability,standard,standardization,91,"Deprecating RtypesCore.h; Dear ROOT devs,. as you may be aware, recent developments in the standardization of C++ brought the C99 **stdint** to C++11. When the original Rtypes.h was written in the nineties, there may have been some need for making sure that sizeof(int) was at least 4. Today, some 37 years after the Intel 80386, I suspect that the only systems where ``sizeof(int)==2`` are 16 bit microcontrollers which lack _any_ 32 bit data types and are probably a bit too constrained with regard to addressable memory to run ROOT. . [RtypesCore.h](https://github.com/root-project/root/blob/master/core/foundation/inc/RtypesCore.h) seems to be a bit outdated. . From my understanding, Float16_t and Double32_t are meant to warn the user that parts of the mantissa are truncated. Given the prevalence of stdint (where the number denotes the stored size in bits), I am unsure if that meaning is successfully transported. Float7BitMantissa_t might be more verbose. . Regarding the limits, I notice that for most types, the listed values are the minimum/maximum value that type can take, for example:. ```const UInt_t kMaxUInt = UInt_t(~0);```. (NB: on a system where ``sizeof(int)==2``, the compiler is (afaik) free to interpret 0 as int, whose complement will then be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and ev",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:2537,interoperability,compatib,compatibility,2537,"be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and even smaller startups are picking up on the trend. ``</sarcasm>``. (Also, while the kMaxUShort error is rendered harmless by the bitshift in kMaxShort, the kMaxUChar error means that kMinChar and kMaxChar are wrong. In fact, Char_t(kMinChar)>Char_t(kMaxChar) is true. However, nine out of ten math professors agree that the maximum of a set of values should be at least as large as the minimum of that set. ``[[citation needed]]``). These issues have been present in the codebase since at least ROOT5, so fixing them would break backwards compatibility. My suggestion is a different one. C++14 introduces an attribute called ``[[deprecated]]``. ```. [[deprecated(""kMaxUChar has a misleading value and should not be used."". "" Please use std::numeric_limits<unsigned char>::max()"")]] . const Int_t kMaxUChar = 256;. ```. And while we are at it, let's be honest: Most users are already somewhat aware that there is a C++ ecosystem outside the safe-ish space that is ROOT. The fallout of vendor-specific implementations has long decayed to a safe level, the air is fresh and breathable, standard compliant implementations are blooming. Thus:. ```. [[deprecated(""Just call it \""int\""."")]]. typedef int Int_t; //Signed integer 4 bytes (int). ```. Just my two cents,. Philipp.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:2989,interoperability,specif,specific,2989,"be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and even smaller startups are picking up on the trend. ``</sarcasm>``. (Also, while the kMaxUShort error is rendered harmless by the bitshift in kMaxShort, the kMaxUChar error means that kMinChar and kMaxChar are wrong. In fact, Char_t(kMinChar)>Char_t(kMaxChar) is true. However, nine out of ten math professors agree that the maximum of a set of values should be at least as large as the minimum of that set. ``[[citation needed]]``). These issues have been present in the codebase since at least ROOT5, so fixing them would break backwards compatibility. My suggestion is a different one. C++14 introduces an attribute called ``[[deprecated]]``. ```. [[deprecated(""kMaxUChar has a misleading value and should not be used."". "" Please use std::numeric_limits<unsigned char>::max()"")]] . const Int_t kMaxUChar = 256;. ```. And while we are at it, let's be honest: Most users are already somewhat aware that there is a C++ ecosystem outside the safe-ish space that is ROOT. The fallout of vendor-specific implementations has long decayed to a safe level, the air is fresh and breathable, standard compliant implementations are blooming. Thus:. ```. [[deprecated(""Just call it \""int\""."")]]. typedef int Int_t; //Signed integer 4 bytes (int). ```. Just my two cents,. Philipp.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:3081,interoperability,standard,standard,3081,"be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and even smaller startups are picking up on the trend. ``</sarcasm>``. (Also, while the kMaxUShort error is rendered harmless by the bitshift in kMaxShort, the kMaxUChar error means that kMinChar and kMaxChar are wrong. In fact, Char_t(kMinChar)>Char_t(kMaxChar) is true. However, nine out of ten math professors agree that the maximum of a set of values should be at least as large as the minimum of that set. ``[[citation needed]]``). These issues have been present in the codebase since at least ROOT5, so fixing them would break backwards compatibility. My suggestion is a different one. C++14 introduces an attribute called ``[[deprecated]]``. ```. [[deprecated(""kMaxUChar has a misleading value and should not be used."". "" Please use std::numeric_limits<unsigned char>::max()"")]] . const Int_t kMaxUChar = 256;. ```. And while we are at it, let's be honest: Most users are already somewhat aware that there is a C++ ecosystem outside the safe-ish space that is ROOT. The fallout of vendor-specific implementations has long decayed to a safe level, the air is fresh and breathable, standard compliant implementations are blooming. Thus:. ```. [[deprecated(""Just call it \""int\""."")]]. typedef int Int_t; //Signed integer 4 bytes (int). ```. Just my two cents,. Philipp.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:516,performance,memor,memory,516,"Deprecating RtypesCore.h; Dear ROOT devs,. as you may be aware, recent developments in the standardization of C++ brought the C99 **stdint** to C++11. When the original Rtypes.h was written in the nineties, there may have been some need for making sure that sizeof(int) was at least 4. Today, some 37 years after the Intel 80386, I suspect that the only systems where ``sizeof(int)==2`` are 16 bit microcontrollers which lack _any_ 32 bit data types and are probably a bit too constrained with regard to addressable memory to run ROOT. . [RtypesCore.h](https://github.com/root-project/root/blob/master/core/foundation/inc/RtypesCore.h) seems to be a bit outdated. . From my understanding, Float16_t and Double32_t are meant to warn the user that parts of the mantissa are truncated. Given the prevalence of stdint (where the number denotes the stored size in bits), I am unsure if that meaning is successfully transported. Float7BitMantissa_t might be more verbose. . Regarding the limits, I notice that for most types, the listed values are the minimum/maximum value that type can take, for example:. ```const UInt_t kMaxUInt = UInt_t(~0);```. (NB: on a system where ``sizeof(int)==2``, the compiler is (afaik) free to interpret 0 as int, whose complement will then be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and ev",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:2093,performance,error,error,2093,"ple:. ```const UInt_t kMaxUInt = UInt_t(~0);```. (NB: on a system where ``sizeof(int)==2``, the compiler is (afaik) free to interpret 0 as int, whose complement will then be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and even smaller startups are picking up on the trend. ``</sarcasm>``. (Also, while the kMaxUShort error is rendered harmless by the bitshift in kMaxShort, the kMaxUChar error means that kMinChar and kMaxChar are wrong. In fact, Char_t(kMinChar)>Char_t(kMaxChar) is true. However, nine out of ten math professors agree that the maximum of a set of values should be at least as large as the minimum of that set. ``[[citation needed]]``). These issues have been present in the codebase since at least ROOT5, so fixing them would break backwards compatibility. My suggestion is a different one. C++14 introduces an attribute called ``[[deprecated]]``. ```. [[deprecated(""kMaxUChar has a misleading value and should not be used."". "" Please use std::numeric_limits<unsigned char>::max()"")]] . const Int_t kMaxUChar = 256;. ```. And while we are at it, let's be honest: Most users are already somewhat aware that there is a C++ ecosystem outside the safe-ish space that is ROOT. The fallout of vendor-specific implementations has long decayed to a safe level, the air is fresh and breathable, standard compli",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:2164,performance,error,error,2164," ``sizeof(int)==2``, the compiler is (afaik) free to interpret 0 as int, whose complement will then be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and even smaller startups are picking up on the trend. ``</sarcasm>``. (Also, while the kMaxUShort error is rendered harmless by the bitshift in kMaxShort, the kMaxUChar error means that kMinChar and kMaxChar are wrong. In fact, Char_t(kMinChar)>Char_t(kMaxChar) is true. However, nine out of ten math professors agree that the maximum of a set of values should be at least as large as the minimum of that set. ``[[citation needed]]``). These issues have been present in the codebase since at least ROOT5, so fixing them would break backwards compatibility. My suggestion is a different one. C++14 introduces an attribute called ``[[deprecated]]``. ```. [[deprecated(""kMaxUChar has a misleading value and should not be used."". "" Please use std::numeric_limits<unsigned char>::max()"")]] . const Int_t kMaxUChar = 256;. ```. And while we are at it, let's be honest: Most users are already somewhat aware that there is a C++ ecosystem outside the safe-ish space that is ROOT. The fallout of vendor-specific implementations has long decayed to a safe level, the air is fresh and breathable, standard compliant implementations are blooming. Thus:. ```. [[deprecated(""Just call i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:1246,safety,compl,complement,1246,"e that sizeof(int) was at least 4. Today, some 37 years after the Intel 80386, I suspect that the only systems where ``sizeof(int)==2`` are 16 bit microcontrollers which lack _any_ 32 bit data types and are probably a bit too constrained with regard to addressable memory to run ROOT. . [RtypesCore.h](https://github.com/root-project/root/blob/master/core/foundation/inc/RtypesCore.h) seems to be a bit outdated. . From my understanding, Float16_t and Double32_t are meant to warn the user that parts of the mantissa are truncated. Given the prevalence of stdint (where the number denotes the stored size in bits), I am unsure if that meaning is successfully transported. Float7BitMantissa_t might be more verbose. . Regarding the limits, I notice that for most types, the listed values are the minimum/maximum value that type can take, for example:. ```const UInt_t kMaxUInt = UInt_t(~0);```. (NB: on a system where ``sizeof(int)==2``, the compiler is (afaik) free to interpret 0 as int, whose complement will then be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and even smaller startups are picking up on the trend. ``</sarcasm>``. (Also, while the kMaxUShort error is rendered harmless by the bitshift in kMaxShort, the kMaxUChar error means that kMinChar and kMaxChar are wrong. In fact, Char_t(kMinChar)>Char_t(kMax",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:2093,safety,error,error,2093,"ple:. ```const UInt_t kMaxUInt = UInt_t(~0);```. (NB: on a system where ``sizeof(int)==2``, the compiler is (afaik) free to interpret 0 as int, whose complement will then be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and even smaller startups are picking up on the trend. ``</sarcasm>``. (Also, while the kMaxUShort error is rendered harmless by the bitshift in kMaxShort, the kMaxUChar error means that kMinChar and kMaxChar are wrong. In fact, Char_t(kMinChar)>Char_t(kMaxChar) is true. However, nine out of ten math professors agree that the maximum of a set of values should be at least as large as the minimum of that set. ``[[citation needed]]``). These issues have been present in the codebase since at least ROOT5, so fixing them would break backwards compatibility. My suggestion is a different one. C++14 introduces an attribute called ``[[deprecated]]``. ```. [[deprecated(""kMaxUChar has a misleading value and should not be used."". "" Please use std::numeric_limits<unsigned char>::max()"")]] . const Int_t kMaxUChar = 256;. ```. And while we are at it, let's be honest: Most users are already somewhat aware that there is a C++ ecosystem outside the safe-ish space that is ROOT. The fallout of vendor-specific implementations has long decayed to a safe level, the air is fresh and breathable, standard compli",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:2164,safety,error,error,2164," ``sizeof(int)==2``, the compiler is (afaik) free to interpret 0 as int, whose complement will then be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and even smaller startups are picking up on the trend. ``</sarcasm>``. (Also, while the kMaxUShort error is rendered harmless by the bitshift in kMaxShort, the kMaxUChar error means that kMinChar and kMaxChar are wrong. In fact, Char_t(kMinChar)>Char_t(kMaxChar) is true. However, nine out of ten math professors agree that the maximum of a set of values should be at least as large as the minimum of that set. ``[[citation needed]]``). These issues have been present in the codebase since at least ROOT5, so fixing them would break backwards compatibility. My suggestion is a different one. C++14 introduces an attribute called ``[[deprecated]]``. ```. [[deprecated(""kMaxUChar has a misleading value and should not be used."". "" Please use std::numeric_limits<unsigned char>::max()"")]] . const Int_t kMaxUChar = 256;. ```. And while we are at it, let's be honest: Most users are already somewhat aware that there is a C++ ecosystem outside the safe-ish space that is ROOT. The fallout of vendor-specific implementations has long decayed to a safe level, the air is fresh and breathable, standard compliant implementations are blooming. Thus:. ```. [[deprecated(""Just call i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:2938,safety,safe,safe-ish,2938,"be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and even smaller startups are picking up on the trend. ``</sarcasm>``. (Also, while the kMaxUShort error is rendered harmless by the bitshift in kMaxShort, the kMaxUChar error means that kMinChar and kMaxChar are wrong. In fact, Char_t(kMinChar)>Char_t(kMaxChar) is true. However, nine out of ten math professors agree that the maximum of a set of values should be at least as large as the minimum of that set. ``[[citation needed]]``). These issues have been present in the codebase since at least ROOT5, so fixing them would break backwards compatibility. My suggestion is a different one. C++14 introduces an attribute called ``[[deprecated]]``. ```. [[deprecated(""kMaxUChar has a misleading value and should not be used."". "" Please use std::numeric_limits<unsigned char>::max()"")]] . const Int_t kMaxUChar = 256;. ```. And while we are at it, let's be honest: Most users are already somewhat aware that there is a C++ ecosystem outside the safe-ish space that is ROOT. The fallout of vendor-specific implementations has long decayed to a safe level, the air is fresh and breathable, standard compliant implementations are blooming. Thus:. ```. [[deprecated(""Just call it \""int\""."")]]. typedef int Int_t; //Signed integer 4 bytes (int). ```. Just my two cents,. Philipp.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:3036,safety,safe,safe,3036,"be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and even smaller startups are picking up on the trend. ``</sarcasm>``. (Also, while the kMaxUShort error is rendered harmless by the bitshift in kMaxShort, the kMaxUChar error means that kMinChar and kMaxChar are wrong. In fact, Char_t(kMinChar)>Char_t(kMaxChar) is true. However, nine out of ten math professors agree that the maximum of a set of values should be at least as large as the minimum of that set. ``[[citation needed]]``). These issues have been present in the codebase since at least ROOT5, so fixing them would break backwards compatibility. My suggestion is a different one. C++14 introduces an attribute called ``[[deprecated]]``. ```. [[deprecated(""kMaxUChar has a misleading value and should not be used."". "" Please use std::numeric_limits<unsigned char>::max()"")]] . const Int_t kMaxUChar = 256;. ```. And while we are at it, let's be honest: Most users are already somewhat aware that there is a C++ ecosystem outside the safe-ish space that is ROOT. The fallout of vendor-specific implementations has long decayed to a safe level, the air is fresh and breathable, standard compliant implementations are blooming. Thus:. ```. [[deprecated(""Just call it \""int\""."")]]. typedef int Int_t; //Signed integer 4 bytes (int). ```. Just my two cents,. Philipp.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:3090,safety,compl,compliant,3090,"be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and even smaller startups are picking up on the trend. ``</sarcasm>``. (Also, while the kMaxUShort error is rendered harmless by the bitshift in kMaxShort, the kMaxUChar error means that kMinChar and kMaxChar are wrong. In fact, Char_t(kMinChar)>Char_t(kMaxChar) is true. However, nine out of ten math professors agree that the maximum of a set of values should be at least as large as the minimum of that set. ``[[citation needed]]``). These issues have been present in the codebase since at least ROOT5, so fixing them would break backwards compatibility. My suggestion is a different one. C++14 introduces an attribute called ``[[deprecated]]``. ```. [[deprecated(""kMaxUChar has a misleading value and should not be used."". "" Please use std::numeric_limits<unsigned char>::max()"")]] . const Int_t kMaxUChar = 256;. ```. And while we are at it, let's be honest: Most users are already somewhat aware that there is a C++ ecosystem outside the safe-ish space that is ROOT. The fallout of vendor-specific implementations has long decayed to a safe level, the air is fresh and breathable, standard compliant implementations are blooming. Thus:. ```. [[deprecated(""Just call it \""int\""."")]]. typedef int Int_t; //Signed integer 4 bytes (int). ```. Just my two cents,. Philipp.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:1246,security,compl,complement,1246,"e that sizeof(int) was at least 4. Today, some 37 years after the Intel 80386, I suspect that the only systems where ``sizeof(int)==2`` are 16 bit microcontrollers which lack _any_ 32 bit data types and are probably a bit too constrained with regard to addressable memory to run ROOT. . [RtypesCore.h](https://github.com/root-project/root/blob/master/core/foundation/inc/RtypesCore.h) seems to be a bit outdated. . From my understanding, Float16_t and Double32_t are meant to warn the user that parts of the mantissa are truncated. Given the prevalence of stdint (where the number denotes the stored size in bits), I am unsure if that meaning is successfully transported. Float7BitMantissa_t might be more verbose. . Regarding the limits, I notice that for most types, the listed values are the minimum/maximum value that type can take, for example:. ```const UInt_t kMaxUInt = UInt_t(~0);```. (NB: on a system where ``sizeof(int)==2``, the compiler is (afaik) free to interpret 0 as int, whose complement will then be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and even smaller startups are picking up on the trend. ``</sarcasm>``. (Also, while the kMaxUShort error is rendered harmless by the bitshift in kMaxShort, the kMaxUChar error means that kMinChar and kMaxChar are wrong. In fact, Char_t(kMinChar)>Char_t(kMax",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:3090,security,compl,compliant,3090,"be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and even smaller startups are picking up on the trend. ``</sarcasm>``. (Also, while the kMaxUShort error is rendered harmless by the bitshift in kMaxShort, the kMaxUChar error means that kMinChar and kMaxChar are wrong. In fact, Char_t(kMinChar)>Char_t(kMaxChar) is true. However, nine out of ten math professors agree that the maximum of a set of values should be at least as large as the minimum of that set. ``[[citation needed]]``). These issues have been present in the codebase since at least ROOT5, so fixing them would break backwards compatibility. My suggestion is a different one. C++14 introduces an attribute called ``[[deprecated]]``. ```. [[deprecated(""kMaxUChar has a misleading value and should not be used."". "" Please use std::numeric_limits<unsigned char>::max()"")]] . const Int_t kMaxUChar = 256;. ```. And while we are at it, let's be honest: Most users are already somewhat aware that there is a C++ ecosystem outside the safe-ish space that is ROOT. The fallout of vendor-specific implementations has long decayed to a safe level, the air is fresh and breathable, standard compliant implementations are blooming. Thus:. ```. [[deprecated(""Just call it \""int\""."")]]. typedef int Int_t; //Signed integer 4 bytes (int). ```. Just my two cents,. Philipp.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:3204,security,Sign,Signed,3204,"be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and even smaller startups are picking up on the trend. ``</sarcasm>``. (Also, while the kMaxUShort error is rendered harmless by the bitshift in kMaxShort, the kMaxUChar error means that kMinChar and kMaxChar are wrong. In fact, Char_t(kMinChar)>Char_t(kMaxChar) is true. However, nine out of ten math professors agree that the maximum of a set of values should be at least as large as the minimum of that set. ``[[citation needed]]``). These issues have been present in the codebase since at least ROOT5, so fixing them would break backwards compatibility. My suggestion is a different one. C++14 introduces an attribute called ``[[deprecated]]``. ```. [[deprecated(""kMaxUChar has a misleading value and should not be used."". "" Please use std::numeric_limits<unsigned char>::max()"")]] . const Int_t kMaxUChar = 256;. ```. And while we are at it, let's be honest: Most users are already somewhat aware that there is a C++ ecosystem outside the safe-ish space that is ROOT. The fallout of vendor-specific implementations has long decayed to a safe level, the air is fresh and breathable, standard compliant implementations are blooming. Thus:. ```. [[deprecated(""Just call it \""int\""."")]]. typedef int Int_t; //Signed integer 4 bytes (int). ```. Just my two cents,. Philipp.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:674,testability,understand,understanding,674,"Deprecating RtypesCore.h; Dear ROOT devs,. as you may be aware, recent developments in the standardization of C++ brought the C99 **stdint** to C++11. When the original Rtypes.h was written in the nineties, there may have been some need for making sure that sizeof(int) was at least 4. Today, some 37 years after the Intel 80386, I suspect that the only systems where ``sizeof(int)==2`` are 16 bit microcontrollers which lack _any_ 32 bit data types and are probably a bit too constrained with regard to addressable memory to run ROOT. . [RtypesCore.h](https://github.com/root-project/root/blob/master/core/foundation/inc/RtypesCore.h) seems to be a bit outdated. . From my understanding, Float16_t and Double32_t are meant to warn the user that parts of the mantissa are truncated. Given the prevalence of stdint (where the number denotes the stored size in bits), I am unsure if that meaning is successfully transported. Float7BitMantissa_t might be more verbose. . Regarding the limits, I notice that for most types, the listed values are the minimum/maximum value that type can take, for example:. ```const UInt_t kMaxUInt = UInt_t(~0);```. (NB: on a system where ``sizeof(int)==2``, the compiler is (afaik) free to interpret 0 as int, whose complement will then be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and ev",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:516,usability,memor,memory,516,"Deprecating RtypesCore.h; Dear ROOT devs,. as you may be aware, recent developments in the standardization of C++ brought the C99 **stdint** to C++11. When the original Rtypes.h was written in the nineties, there may have been some need for making sure that sizeof(int) was at least 4. Today, some 37 years after the Intel 80386, I suspect that the only systems where ``sizeof(int)==2`` are 16 bit microcontrollers which lack _any_ 32 bit data types and are probably a bit too constrained with regard to addressable memory to run ROOT. . [RtypesCore.h](https://github.com/root-project/root/blob/master/core/foundation/inc/RtypesCore.h) seems to be a bit outdated. . From my understanding, Float16_t and Double32_t are meant to warn the user that parts of the mantissa are truncated. Given the prevalence of stdint (where the number denotes the stored size in bits), I am unsure if that meaning is successfully transported. Float7BitMantissa_t might be more verbose. . Regarding the limits, I notice that for most types, the listed values are the minimum/maximum value that type can take, for example:. ```const UInt_t kMaxUInt = UInt_t(~0);```. (NB: on a system where ``sizeof(int)==2``, the compiler is (afaik) free to interpret 0 as int, whose complement will then be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and ev",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:736,usability,user,user,736,"Deprecating RtypesCore.h; Dear ROOT devs,. as you may be aware, recent developments in the standardization of C++ brought the C99 **stdint** to C++11. When the original Rtypes.h was written in the nineties, there may have been some need for making sure that sizeof(int) was at least 4. Today, some 37 years after the Intel 80386, I suspect that the only systems where ``sizeof(int)==2`` are 16 bit microcontrollers which lack _any_ 32 bit data types and are probably a bit too constrained with regard to addressable memory to run ROOT. . [RtypesCore.h](https://github.com/root-project/root/blob/master/core/foundation/inc/RtypesCore.h) seems to be a bit outdated. . From my understanding, Float16_t and Double32_t are meant to warn the user that parts of the mantissa are truncated. Given the prevalence of stdint (where the number denotes the stored size in bits), I am unsure if that meaning is successfully transported. Float7BitMantissa_t might be more verbose. . Regarding the limits, I notice that for most types, the listed values are the minimum/maximum value that type can take, for example:. ```const UInt_t kMaxUInt = UInt_t(~0);```. (NB: on a system where ``sizeof(int)==2``, the compiler is (afaik) free to interpret 0 as int, whose complement will then be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and ev",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:1046,usability,minim,minimum,1046,"may be aware, recent developments in the standardization of C++ brought the C99 **stdint** to C++11. When the original Rtypes.h was written in the nineties, there may have been some need for making sure that sizeof(int) was at least 4. Today, some 37 years after the Intel 80386, I suspect that the only systems where ``sizeof(int)==2`` are 16 bit microcontrollers which lack _any_ 32 bit data types and are probably a bit too constrained with regard to addressable memory to run ROOT. . [RtypesCore.h](https://github.com/root-project/root/blob/master/core/foundation/inc/RtypesCore.h) seems to be a bit outdated. . From my understanding, Float16_t and Double32_t are meant to warn the user that parts of the mantissa are truncated. Given the prevalence of stdint (where the number denotes the stored size in bits), I am unsure if that meaning is successfully transported. Float7BitMantissa_t might be more verbose. . Regarding the limits, I notice that for most types, the listed values are the minimum/maximum value that type can take, for example:. ```const UInt_t kMaxUInt = UInt_t(~0);```. (NB: on a system where ``sizeof(int)==2``, the compiler is (afaik) free to interpret 0 as int, whose complement will then be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and even smaller startups are picking up on the trend. `",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:2093,usability,error,error,2093,"ple:. ```const UInt_t kMaxUInt = UInt_t(~0);```. (NB: on a system where ``sizeof(int)==2``, the compiler is (afaik) free to interpret 0 as int, whose complement will then be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and even smaller startups are picking up on the trend. ``</sarcasm>``. (Also, while the kMaxUShort error is rendered harmless by the bitshift in kMaxShort, the kMaxUChar error means that kMinChar and kMaxChar are wrong. In fact, Char_t(kMinChar)>Char_t(kMaxChar) is true. However, nine out of ten math professors agree that the maximum of a set of values should be at least as large as the minimum of that set. ``[[citation needed]]``). These issues have been present in the codebase since at least ROOT5, so fixing them would break backwards compatibility. My suggestion is a different one. C++14 introduces an attribute called ``[[deprecated]]``. ```. [[deprecated(""kMaxUChar has a misleading value and should not be used."". "" Please use std::numeric_limits<unsigned char>::max()"")]] . const Int_t kMaxUChar = 256;. ```. And while we are at it, let's be honest: Most users are already somewhat aware that there is a C++ ecosystem outside the safe-ish space that is ROOT. The fallout of vendor-specific implementations has long decayed to a safe level, the air is fresh and breathable, standard compli",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:2164,usability,error,error,2164," ``sizeof(int)==2``, the compiler is (afaik) free to interpret 0 as int, whose complement will then be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and even smaller startups are picking up on the trend. ``</sarcasm>``. (Also, while the kMaxUShort error is rendered harmless by the bitshift in kMaxShort, the kMaxUChar error means that kMinChar and kMaxChar are wrong. In fact, Char_t(kMinChar)>Char_t(kMaxChar) is true. However, nine out of ten math professors agree that the maximum of a set of values should be at least as large as the minimum of that set. ``[[citation needed]]``). These issues have been present in the codebase since at least ROOT5, so fixing them would break backwards compatibility. My suggestion is a different one. C++14 introduces an attribute called ``[[deprecated]]``. ```. [[deprecated(""kMaxUChar has a misleading value and should not be used."". "" Please use std::numeric_limits<unsigned char>::max()"")]] . const Int_t kMaxUChar = 256;. ```. And while we are at it, let's be honest: Most users are already somewhat aware that there is a C++ ecosystem outside the safe-ish space that is ROOT. The fallout of vendor-specific implementations has long decayed to a safe level, the air is fresh and breathable, standard compliant implementations are blooming. Thus:. ```. [[deprecated(""Just call i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:2384,usability,minim,minimum,2384,"be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and even smaller startups are picking up on the trend. ``</sarcasm>``. (Also, while the kMaxUShort error is rendered harmless by the bitshift in kMaxShort, the kMaxUChar error means that kMinChar and kMaxChar are wrong. In fact, Char_t(kMinChar)>Char_t(kMaxChar) is true. However, nine out of ten math professors agree that the maximum of a set of values should be at least as large as the minimum of that set. ``[[citation needed]]``). These issues have been present in the codebase since at least ROOT5, so fixing them would break backwards compatibility. My suggestion is a different one. C++14 introduces an attribute called ``[[deprecated]]``. ```. [[deprecated(""kMaxUChar has a misleading value and should not be used."". "" Please use std::numeric_limits<unsigned char>::max()"")]] . const Int_t kMaxUChar = 256;. ```. And while we are at it, let's be honest: Most users are already somewhat aware that there is a C++ ecosystem outside the safe-ish space that is ROOT. The fallout of vendor-specific implementations has long decayed to a safe level, the air is fresh and breathable, standard compliant implementations are blooming. Thus:. ```. [[deprecated(""Just call it \""int\""."")]]. typedef int Int_t; //Signed integer 4 bytes (int). ```. Just my two cents,. Philipp.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12208:2863,usability,user,users,2863,"be disappointingly small.). Under this interpretation, I want to cast doubt on . ```. const Int_t kMaxUChar = 256;. const Int_t kMaxUShort = 65534;. ```. While there were some promising publications of computer scientists claiming to have succeeded in storing 256 in an unsigned char, later attempts to reproduce that research found that the bit sequence was indistinguishable from zero. The general consensus among computer scientists today is that the highest value which can be stored in a uint8_t is in fact 255. On the other hand, a few years later initially doubtful claims that 65535 could be stored in an unsigned short *were* replicated. Today, big tech (e.g. GAFAM) routinely store that value in their 16 bit numbers and even smaller startups are picking up on the trend. ``</sarcasm>``. (Also, while the kMaxUShort error is rendered harmless by the bitshift in kMaxShort, the kMaxUChar error means that kMinChar and kMaxChar are wrong. In fact, Char_t(kMinChar)>Char_t(kMaxChar) is true. However, nine out of ten math professors agree that the maximum of a set of values should be at least as large as the minimum of that set. ``[[citation needed]]``). These issues have been present in the codebase since at least ROOT5, so fixing them would break backwards compatibility. My suggestion is a different one. C++14 introduces an attribute called ``[[deprecated]]``. ```. [[deprecated(""kMaxUChar has a misleading value and should not be used."". "" Please use std::numeric_limits<unsigned char>::max()"")]] . const Int_t kMaxUChar = 256;. ```. And while we are at it, let's be honest: Most users are already somewhat aware that there is a C++ ecosystem outside the safe-ish space that is ROOT. The fallout of vendor-specific implementations has long decayed to a safe level, the air is fresh and breathable, standard compliant implementations are blooming. Thus:. ```. [[deprecated(""Just call it \""int\""."")]]. typedef int Int_t; //Signed integer 4 bytes (int). ```. Just my two cents,. Philipp.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12208
https://github.com/root-project/root/issues/12209:12,availability,error,error,12,"Compilation error while compile; I get:. ```bash. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::ActOnStartOfSwitchStmt(clang::SourceLocation, clang::Stmt*, clang::Sema::ConditionResult)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ImplicitCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::ExprValueKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CallExpr::Create(clang::ASTContext const&, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, unsigned int, clang::CallExpr::ADLCallKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::NoteOverloadCandidate(clang::NamedDecl*, clang::FunctionDecl*, clang::QualType, bool)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `llvm::SmallVectorBase::grow_pod(void*, un",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:9065,availability,error,error,9065,"Kind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::WhileStmt::Create(clang::ASTContext const&, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ASTContext::getConstantArrayType(clang::QualType, llvm::APInt const&, clang::ArrayType::ArraySizeModifier, unsigned int) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXFunctionalCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::TypeSourceInfo*, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::SourceLocation, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXMethodDecl::Create(clang::ASTContext&, clang::CXXRecordDecl*, clang::SourceLocation, clang::DeclarationNameInfo const&, clang::QualType, clang::TypeSourceInfo*, clang::StorageClass, bool, clang::ConstexprSpecKind, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: collect2: error: ld returned 1 exit status. ```. when compiling with (v6-28-00-patches) 5ffba22ef571dea2d6eaf186662e19d5a7789a05.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:137,deployability,Toolchain,Toolchain,137,"Compilation error while compile; I get:. ```bash. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::ActOnStartOfSwitchStmt(clang::SourceLocation, clang::Stmt*, clang::Sema::ConditionResult)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ImplicitCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::ExprValueKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CallExpr::Create(clang::ASTContext const&, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, unsigned int, clang::CallExpr::ADLCallKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::NoteOverloadCandidate(clang::NamedDecl*, clang::FunctionDecl*, clang::QualType, bool)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `llvm::SmallVectorBase::grow_pod(void*, un",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:505,deployability,Toolchain,Toolchain,505,"Compilation error while compile; I get:. ```bash. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::ActOnStartOfSwitchStmt(clang::SourceLocation, clang::Stmt*, clang::Sema::ConditionResult)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ImplicitCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::ExprValueKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CallExpr::Create(clang::ASTContext const&, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, unsigned int, clang::CallExpr::ADLCallKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::NoteOverloadCandidate(clang::NamedDecl*, clang::FunctionDecl*, clang::QualType, bool)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `llvm::SmallVectorBase::grow_pod(void*, un",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:954,deployability,Toolchain,Toolchain,954,"Compilation error while compile; I get:. ```bash. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::ActOnStartOfSwitchStmt(clang::SourceLocation, clang::Stmt*, clang::Sema::ConditionResult)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ImplicitCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::ExprValueKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CallExpr::Create(clang::ASTContext const&, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, unsigned int, clang::CallExpr::ADLCallKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::NoteOverloadCandidate(clang::NamedDecl*, clang::FunctionDecl*, clang::QualType, bool)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `llvm::SmallVectorBase::grow_pod(void*, un",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:1419,deployability,Toolchain,Toolchain,1419,"2-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ImplicitCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::ExprValueKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CallExpr::Create(clang::ASTContext const&, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, unsigned int, clang::CallExpr::ADLCallKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::NoteOverloadCandidate(clang::NamedDecl*, clang::FunctionDecl*, clang::QualType, bool)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `llvm::SmallVectorBase::grow_pod(void*, unsigned long, unsigned long)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::SwitchStmt::Create(clang::ASTContext const&, clang::Stmt*, clang::VarDecl*, clang::Expr*)'. 2023-02-02@14:29:38:DEBUG:O2Phys",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:1783,deployability,Toolchain,Toolchain,1783,"lvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::ExprValueKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CallExpr::Create(clang::ASTContext const&, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, unsigned int, clang::CallExpr::ADLCallKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::NoteOverloadCandidate(clang::NamedDecl*, clang::FunctionDecl*, clang::QualType, bool)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `llvm::SmallVectorBase::grow_pod(void*, unsigned long, unsigned long)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::SwitchStmt::Create(clang::ASTContext const&, clang::Stmt*, clang::VarDecl*, clang::Expr*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ExprWithCleanups::Create(clang::ASTContext const&, clang::Expr*, bool, llvm::ArrayRef<clang::BlockDecl*>)'. 2023-02-02@14:29:3",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:2117,deployability,Toolchain,Toolchain,2117,"nce to `clang::CallExpr::Create(clang::ASTContext const&, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, unsigned int, clang::CallExpr::ADLCallKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::NoteOverloadCandidate(clang::NamedDecl*, clang::FunctionDecl*, clang::QualType, bool)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `llvm::SmallVectorBase::grow_pod(void*, unsigned long, unsigned long)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::SwitchStmt::Create(clang::ASTContext const&, clang::Stmt*, clang::VarDecl*, clang::Expr*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ExprWithCleanups::Create(clang::ASTContext const&, clang::Expr*, bool, llvm::ArrayRef<clang::BlockDecl*>)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXOperatorCallExpr::Create(clang::ASTContext const&, clang::OverloadedOperatorKin",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:2479,deployability,Toolchain,Toolchain,2479,"ux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::NoteOverloadCandidate(clang::NamedDecl*, clang::FunctionDecl*, clang::QualType, bool)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `llvm::SmallVectorBase::grow_pod(void*, unsigned long, unsigned long)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::SwitchStmt::Create(clang::ASTContext const&, clang::Stmt*, clang::VarDecl*, clang::Expr*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ExprWithCleanups::Create(clang::ASTContext const&, clang::Expr*, bool, llvm::ArrayRef<clang::BlockDecl*>)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXOperatorCallExpr::Create(clang::ASTContext const&, clang::OverloadedOperatorKind, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, clang::FPOptions, clang::CallExpr::ADLCallKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:2857,deployability,Toolchain,Toolchain,2857,"../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `llvm::SmallVectorBase::grow_pod(void*, unsigned long, unsigned long)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::SwitchStmt::Create(clang::ASTContext const&, clang::Stmt*, clang::VarDecl*, clang::Expr*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ExprWithCleanups::Create(clang::ASTContext const&, clang::Expr*, bool, llvm::ArrayRef<clang::BlockDecl*>)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXOperatorCallExpr::Create(clang::ASTContext const&, clang::OverloadedOperatorKind, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, clang::FPOptions, clang::CallExpr::ADLCallKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::IfStmt::Create(clang::ASTContext const&, clang::SourceLocation, bool, clang::Stmt*, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation, clang::Stmt*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-un",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:3368,deployability,Toolchain,Toolchain,3368,"*, clang::Expr*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ExprWithCleanups::Create(clang::ASTContext const&, clang::Expr*, bool, llvm::ArrayRef<clang::BlockDecl*>)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXOperatorCallExpr::Create(clang::ASTContext const&, clang::OverloadedOperatorKind, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, clang::FPOptions, clang::CallExpr::ADLCallKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::IfStmt::Create(clang::ASTContext const&, clang::SourceLocation, bool, clang::Stmt*, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation, clang::Stmt*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::FunctionDecl::isDefined(clang::FunctionDecl const*&) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::ActOnWhileStmt(clang::SourceLocation, clang::Se",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:3806,deployability,Toolchain,Toolchain,3806,"0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXOperatorCallExpr::Create(clang::ASTContext const&, clang::OverloadedOperatorKind, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, clang::FPOptions, clang::CallExpr::ADLCallKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::IfStmt::Create(clang::ASTContext const&, clang::SourceLocation, bool, clang::Stmt*, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation, clang::Stmt*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::FunctionDecl::isDefined(clang::FunctionDecl const*&) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::ActOnWhileStmt(clang::SourceLocation, clang::Sema::ConditionResult, clang::Stmt*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXMemberCallExpr::Create(clang::ASTContext const&, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:4137,deployability,Toolchain,Toolchain,4137,"m::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, clang::FPOptions, clang::CallExpr::ADLCallKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::IfStmt::Create(clang::ASTContext const&, clang::SourceLocation, bool, clang::Stmt*, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation, clang::Stmt*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::FunctionDecl::isDefined(clang::FunctionDecl const*&) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::ActOnWhileStmt(clang::SourceLocation, clang::Sema::ConditionResult, clang::Stmt*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXMemberCallExpr::Create(clang::ASTContext const&, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, unsigned int)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::BuildCallToM",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:4497,deployability,Toolchain,Toolchain,4497,"Cling.so.6.27.99: undefined reference to `clang::IfStmt::Create(clang::ASTContext const&, clang::SourceLocation, bool, clang::Stmt*, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation, clang::Stmt*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::FunctionDecl::isDefined(clang::FunctionDecl const*&) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::ActOnWhileStmt(clang::SourceLocation, clang::Sema::ConditionResult, clang::Stmt*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXMemberCallExpr::Create(clang::ASTContext const&, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, unsigned int)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::BuildCallToMemberFunction(clang::Scope*, clang::Expr*, clang::SourceLocation, llvm::MutableArrayRef<clang::Expr*>, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:4941,deployability,Toolchain,Toolchain,4941,"so.6.27.99: undefined reference to `clang::FunctionDecl::isDefined(clang::FunctionDecl const*&) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::ActOnWhileStmt(clang::SourceLocation, clang::Sema::ConditionResult, clang::Stmt*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXMemberCallExpr::Create(clang::ASTContext const&, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, unsigned int)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::BuildCallToMemberFunction(clang::Scope*, clang::Expr*, clang::SourceLocation, llvm::MutableArrayRef<clang::Expr*>, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ConstantExpr::Create(clang::ASTContext const&, clang::Expr*, clang::ConstantExpr::ResultStorageKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXStaticCastExpr::Create(clang::",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:5130,deployability,Build,BuildCallToMemberFunction,5130,"ain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::ActOnWhileStmt(clang::SourceLocation, clang::Sema::ConditionResult, clang::Stmt*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXMemberCallExpr::Create(clang::ASTContext const&, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, unsigned int)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::BuildCallToMemberFunction(clang::Scope*, clang::Expr*, clang::SourceLocation, llvm::MutableArrayRef<clang::Expr*>, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ConstantExpr::Create(clang::ASTContext const&, clang::Expr*, clang::ConstantExpr::ResultStorageKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXStaticCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::TypeSourceInfo*, clang::SourceLocation, clang",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:5357,deployability,Toolchain,Toolchain,5357,", clang::Sema::ConditionResult, clang::Stmt*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXMemberCallExpr::Create(clang::ASTContext const&, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, unsigned int)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::BuildCallToMemberFunction(clang::Scope*, clang::Expr*, clang::SourceLocation, llvm::MutableArrayRef<clang::Expr*>, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ConstantExpr::Create(clang::ASTContext const&, clang::Expr*, clang::ConstantExpr::ResultStorageKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXStaticCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::TypeSourceInfo*, clang::SourceLocation, clang::SourceLocation, clang::SourceRange)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:5730,deployability,Toolchain,Toolchain,5730,"ng::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, unsigned int)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::BuildCallToMemberFunction(clang::Scope*, clang::Expr*, clang::SourceLocation, llvm::MutableArrayRef<clang::Expr*>, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ConstantExpr::Create(clang::ASTContext const&, clang::Expr*, clang::ConstantExpr::ResultStorageKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXStaticCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::TypeSourceInfo*, clang::SourceLocation, clang::SourceLocation, clang::SourceRange)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CStyleCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::TypeSourceInfo*, clang::SourceLocation, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:6270,deployability,Toolchain,Toolchain,6270,"02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ConstantExpr::Create(clang::ASTContext const&, clang::Expr*, clang::ConstantExpr::ResultStorageKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXStaticCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::TypeSourceInfo*, clang::SourceLocation, clang::SourceLocation, clang::SourceRange)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CStyleCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::TypeSourceInfo*, clang::SourceLocation, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::FunctionDecl::Create(clang::ASTContext&, clang::DeclContext*, clang::SourceLocation, clang::DeclarationNameInfo const&, clang::QualType, clang::TypeSourceInfo*, clang::StorageClass, bool, bool, clang::ConstexprSpecKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:6787,deployability,Toolchain,Toolchain,6787,"linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXStaticCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::TypeSourceInfo*, clang::SourceLocation, clang::SourceLocation, clang::SourceRange)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CStyleCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::TypeSourceInfo*, clang::SourceLocation, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::FunctionDecl::Create(clang::ASTContext&, clang::DeclContext*, clang::SourceLocation, clang::DeclarationNameInfo const&, clang::QualType, clang::TypeSourceInfo*, clang::StorageClass, bool, bool, clang::ConstexprSpecKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::WhileStmt::Create(clang::ASTContext const&, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../li",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:7279,deployability,Toolchain,Toolchain,7279,"2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CStyleCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::TypeSourceInfo*, clang::SourceLocation, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::FunctionDecl::Create(clang::ASTContext&, clang::DeclContext*, clang::SourceLocation, clang::DeclarationNameInfo const&, clang::QualType, clang::TypeSourceInfo*, clang::StorageClass, bool, bool, clang::ConstexprSpecKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::WhileStmt::Create(clang::ASTContext const&, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ASTContext::getConstantArrayType(clang::QualType, llvm::APInt const&, clang::ArrayType::ArraySizeModifier, unsigned int) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXFunctionalCastExpr::Create(clang::AS",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:7663,deployability,Toolchain,Toolchain,7663,"ation, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::FunctionDecl::Create(clang::ASTContext&, clang::DeclContext*, clang::SourceLocation, clang::DeclarationNameInfo const&, clang::QualType, clang::TypeSourceInfo*, clang::StorageClass, bool, bool, clang::ConstexprSpecKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::WhileStmt::Create(clang::ASTContext const&, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ASTContext::getConstantArrayType(clang::QualType, llvm::APInt const&, clang::ArrayType::ArraySizeModifier, unsigned int) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXFunctionalCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::TypeSourceInfo*, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::SourceLocation, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:7902,deployability,API,APInt,7902,"n/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::FunctionDecl::Create(clang::ASTContext&, clang::DeclContext*, clang::SourceLocation, clang::DeclarationNameInfo const&, clang::QualType, clang::TypeSourceInfo*, clang::StorageClass, bool, bool, clang::ConstexprSpecKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::WhileStmt::Create(clang::ASTContext const&, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ASTContext::getConstantArrayType(clang::QualType, llvm::APInt const&, clang::ArrayType::ArraySizeModifier, unsigned int) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXFunctionalCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::TypeSourceInfo*, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::SourceLocation, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXMethodDecl::Create(clang::ASTContext&, clang::CXXRecordDecl*, clang::SourceLocation, clang::DeclarationNameInfo const&, clang::QualTy",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:8062,deployability,Toolchain,Toolchain,8062,"rationNameInfo const&, clang::QualType, clang::TypeSourceInfo*, clang::StorageClass, bool, bool, clang::ConstexprSpecKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::WhileStmt::Create(clang::ASTContext const&, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ASTContext::getConstantArrayType(clang::QualType, llvm::APInt const&, clang::ArrayType::ArraySizeModifier, unsigned int) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXFunctionalCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::TypeSourceInfo*, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::SourceLocation, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXMethodDecl::Create(clang::ASTContext&, clang::CXXRecordDecl*, clang::SourceLocation, clang::DeclarationNameInfo const&, clang::QualType, clang::TypeSourceInfo*, clang::StorageClass, bool, clang::ConstexprSpecKind, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: collect2: er",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:8586,deployability,Toolchain,Toolchain,8586,"Kind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::WhileStmt::Create(clang::ASTContext const&, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ASTContext::getConstantArrayType(clang::QualType, llvm::APInt const&, clang::ArrayType::ArraySizeModifier, unsigned int) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXFunctionalCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::TypeSourceInfo*, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::SourceLocation, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXMethodDecl::Create(clang::ASTContext&, clang::CXXRecordDecl*, clang::SourceLocation, clang::DeclarationNameInfo const&, clang::QualType, clang::TypeSourceInfo*, clang::StorageClass, bool, clang::ConstexprSpecKind, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: collect2: error: ld returned 1 exit status. ```. when compiling with (v6-28-00-patches) 5ffba22ef571dea2d6eaf186662e19d5a7789a05.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:9134,deployability,patch,patches,9134,"Kind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::WhileStmt::Create(clang::ASTContext const&, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ASTContext::getConstantArrayType(clang::QualType, llvm::APInt const&, clang::ArrayType::ArraySizeModifier, unsigned int) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXFunctionalCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::TypeSourceInfo*, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::SourceLocation, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXMethodDecl::Create(clang::ASTContext&, clang::CXXRecordDecl*, clang::SourceLocation, clang::DeclarationNameInfo const&, clang::QualType, clang::TypeSourceInfo*, clang::StorageClass, bool, clang::ConstexprSpecKind, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: collect2: error: ld returned 1 exit status. ```. when compiling with (v6-28-00-patches) 5ffba22ef571dea2d6eaf186662e19d5a7789a05.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:7902,integrability,API,APInt,7902,"n/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::FunctionDecl::Create(clang::ASTContext&, clang::DeclContext*, clang::SourceLocation, clang::DeclarationNameInfo const&, clang::QualType, clang::TypeSourceInfo*, clang::StorageClass, bool, bool, clang::ConstexprSpecKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::WhileStmt::Create(clang::ASTContext const&, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ASTContext::getConstantArrayType(clang::QualType, llvm::APInt const&, clang::ArrayType::ArraySizeModifier, unsigned int) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXFunctionalCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::TypeSourceInfo*, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::SourceLocation, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXMethodDecl::Create(clang::ASTContext&, clang::CXXRecordDecl*, clang::SourceLocation, clang::DeclarationNameInfo const&, clang::QualTy",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:7902,interoperability,API,APInt,7902,"n/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::FunctionDecl::Create(clang::ASTContext&, clang::DeclContext*, clang::SourceLocation, clang::DeclarationNameInfo const&, clang::QualType, clang::TypeSourceInfo*, clang::StorageClass, bool, bool, clang::ConstexprSpecKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::WhileStmt::Create(clang::ASTContext const&, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ASTContext::getConstantArrayType(clang::QualType, llvm::APInt const&, clang::ArrayType::ArraySizeModifier, unsigned int) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXFunctionalCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::TypeSourceInfo*, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::SourceLocation, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXMethodDecl::Create(clang::ASTContext&, clang::CXXRecordDecl*, clang::SourceLocation, clang::DeclarationNameInfo const&, clang::QualTy",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:12,performance,error,error,12,"Compilation error while compile; I get:. ```bash. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::ActOnStartOfSwitchStmt(clang::SourceLocation, clang::Stmt*, clang::Sema::ConditionResult)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ImplicitCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::ExprValueKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CallExpr::Create(clang::ASTContext const&, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, unsigned int, clang::CallExpr::ADLCallKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::NoteOverloadCandidate(clang::NamedDecl*, clang::FunctionDecl*, clang::QualType, bool)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `llvm::SmallVectorBase::grow_pod(void*, un",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:9065,performance,error,error,9065,"Kind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::WhileStmt::Create(clang::ASTContext const&, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ASTContext::getConstantArrayType(clang::QualType, llvm::APInt const&, clang::ArrayType::ArraySizeModifier, unsigned int) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXFunctionalCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::TypeSourceInfo*, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::SourceLocation, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXMethodDecl::Create(clang::ASTContext&, clang::CXXRecordDecl*, clang::SourceLocation, clang::DeclarationNameInfo const&, clang::QualType, clang::TypeSourceInfo*, clang::StorageClass, bool, clang::ConstexprSpecKind, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: collect2: error: ld returned 1 exit status. ```. when compiling with (v6-28-00-patches) 5ffba22ef571dea2d6eaf186662e19d5a7789a05.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:12,safety,error,error,12,"Compilation error while compile; I get:. ```bash. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::ActOnStartOfSwitchStmt(clang::SourceLocation, clang::Stmt*, clang::Sema::ConditionResult)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ImplicitCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::ExprValueKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CallExpr::Create(clang::ASTContext const&, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, unsigned int, clang::CallExpr::ADLCallKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::NoteOverloadCandidate(clang::NamedDecl*, clang::FunctionDecl*, clang::QualType, bool)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `llvm::SmallVectorBase::grow_pod(void*, un",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:9065,safety,error,error,9065,"Kind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::WhileStmt::Create(clang::ASTContext const&, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ASTContext::getConstantArrayType(clang::QualType, llvm::APInt const&, clang::ArrayType::ArraySizeModifier, unsigned int) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXFunctionalCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::TypeSourceInfo*, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::SourceLocation, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXMethodDecl::Create(clang::ASTContext&, clang::CXXRecordDecl*, clang::SourceLocation, clang::DeclarationNameInfo const&, clang::QualType, clang::TypeSourceInfo*, clang::StorageClass, bool, clang::ConstexprSpecKind, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: collect2: error: ld returned 1 exit status. ```. when compiling with (v6-28-00-patches) 5ffba22ef571dea2d6eaf186662e19d5a7789a05.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:9134,safety,patch,patches,9134,"Kind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::WhileStmt::Create(clang::ASTContext const&, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ASTContext::getConstantArrayType(clang::QualType, llvm::APInt const&, clang::ArrayType::ArraySizeModifier, unsigned int) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXFunctionalCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::TypeSourceInfo*, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::SourceLocation, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXMethodDecl::Create(clang::ASTContext&, clang::CXXRecordDecl*, clang::SourceLocation, clang::DeclarationNameInfo const&, clang::QualType, clang::TypeSourceInfo*, clang::StorageClass, bool, clang::ConstexprSpecKind, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: collect2: error: ld returned 1 exit status. ```. when compiling with (v6-28-00-patches) 5ffba22ef571dea2d6eaf186662e19d5a7789a05.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:9134,security,patch,patches,9134,"Kind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::WhileStmt::Create(clang::ASTContext const&, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ASTContext::getConstantArrayType(clang::QualType, llvm::APInt const&, clang::ArrayType::ArraySizeModifier, unsigned int) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXFunctionalCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::TypeSourceInfo*, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::SourceLocation, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXMethodDecl::Create(clang::ASTContext&, clang::CXXRecordDecl*, clang::SourceLocation, clang::DeclarationNameInfo const&, clang::QualType, clang::TypeSourceInfo*, clang::StorageClass, bool, clang::ConstexprSpecKind, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: collect2: error: ld returned 1 exit status. ```. when compiling with (v6-28-00-patches) 5ffba22ef571dea2d6eaf186662e19d5a7789a05.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:12,usability,error,error,12,"Compilation error while compile; I get:. ```bash. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::ActOnStartOfSwitchStmt(clang::SourceLocation, clang::Stmt*, clang::Sema::ConditionResult)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ImplicitCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::ExprValueKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CallExpr::Create(clang::ASTContext const&, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, unsigned int, clang::CallExpr::ADLCallKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::NoteOverloadCandidate(clang::NamedDecl*, clang::FunctionDecl*, clang::QualType, bool)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `llvm::SmallVectorBase::grow_pod(void*, un",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:137,usability,Tool,Toolchain,137,"Compilation error while compile; I get:. ```bash. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::ActOnStartOfSwitchStmt(clang::SourceLocation, clang::Stmt*, clang::Sema::ConditionResult)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ImplicitCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::ExprValueKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CallExpr::Create(clang::ASTContext const&, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, unsigned int, clang::CallExpr::ADLCallKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::NoteOverloadCandidate(clang::NamedDecl*, clang::FunctionDecl*, clang::QualType, bool)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `llvm::SmallVectorBase::grow_pod(void*, un",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:505,usability,Tool,Toolchain,505,"Compilation error while compile; I get:. ```bash. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::ActOnStartOfSwitchStmt(clang::SourceLocation, clang::Stmt*, clang::Sema::ConditionResult)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ImplicitCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::ExprValueKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CallExpr::Create(clang::ASTContext const&, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, unsigned int, clang::CallExpr::ADLCallKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::NoteOverloadCandidate(clang::NamedDecl*, clang::FunctionDecl*, clang::QualType, bool)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `llvm::SmallVectorBase::grow_pod(void*, un",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:954,usability,Tool,Toolchain,954,"Compilation error while compile; I get:. ```bash. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::ActOnStartOfSwitchStmt(clang::SourceLocation, clang::Stmt*, clang::Sema::ConditionResult)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ImplicitCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::ExprValueKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CallExpr::Create(clang::ASTContext const&, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, unsigned int, clang::CallExpr::ADLCallKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::NoteOverloadCandidate(clang::NamedDecl*, clang::FunctionDecl*, clang::QualType, bool)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `llvm::SmallVectorBase::grow_pod(void*, un",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:1419,usability,Tool,Toolchain,1419,"2-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ImplicitCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::ExprValueKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CallExpr::Create(clang::ASTContext const&, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, unsigned int, clang::CallExpr::ADLCallKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::NoteOverloadCandidate(clang::NamedDecl*, clang::FunctionDecl*, clang::QualType, bool)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `llvm::SmallVectorBase::grow_pod(void*, unsigned long, unsigned long)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::SwitchStmt::Create(clang::ASTContext const&, clang::Stmt*, clang::VarDecl*, clang::Expr*)'. 2023-02-02@14:29:38:DEBUG:O2Phys",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:1783,usability,Tool,Toolchain,1783,"lvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::ExprValueKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CallExpr::Create(clang::ASTContext const&, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, unsigned int, clang::CallExpr::ADLCallKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::NoteOverloadCandidate(clang::NamedDecl*, clang::FunctionDecl*, clang::QualType, bool)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `llvm::SmallVectorBase::grow_pod(void*, unsigned long, unsigned long)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::SwitchStmt::Create(clang::ASTContext const&, clang::Stmt*, clang::VarDecl*, clang::Expr*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ExprWithCleanups::Create(clang::ASTContext const&, clang::Expr*, bool, llvm::ArrayRef<clang::BlockDecl*>)'. 2023-02-02@14:29:3",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:2117,usability,Tool,Toolchain,2117,"nce to `clang::CallExpr::Create(clang::ASTContext const&, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, unsigned int, clang::CallExpr::ADLCallKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::NoteOverloadCandidate(clang::NamedDecl*, clang::FunctionDecl*, clang::QualType, bool)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `llvm::SmallVectorBase::grow_pod(void*, unsigned long, unsigned long)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::SwitchStmt::Create(clang::ASTContext const&, clang::Stmt*, clang::VarDecl*, clang::Expr*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ExprWithCleanups::Create(clang::ASTContext const&, clang::Expr*, bool, llvm::ArrayRef<clang::BlockDecl*>)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXOperatorCallExpr::Create(clang::ASTContext const&, clang::OverloadedOperatorKin",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:2479,usability,Tool,Toolchain,2479,"ux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::NoteOverloadCandidate(clang::NamedDecl*, clang::FunctionDecl*, clang::QualType, bool)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `llvm::SmallVectorBase::grow_pod(void*, unsigned long, unsigned long)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::SwitchStmt::Create(clang::ASTContext const&, clang::Stmt*, clang::VarDecl*, clang::Expr*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ExprWithCleanups::Create(clang::ASTContext const&, clang::Expr*, bool, llvm::ArrayRef<clang::BlockDecl*>)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXOperatorCallExpr::Create(clang::ASTContext const&, clang::OverloadedOperatorKind, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, clang::FPOptions, clang::CallExpr::ADLCallKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:2857,usability,Tool,Toolchain,2857,"../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `llvm::SmallVectorBase::grow_pod(void*, unsigned long, unsigned long)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::SwitchStmt::Create(clang::ASTContext const&, clang::Stmt*, clang::VarDecl*, clang::Expr*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ExprWithCleanups::Create(clang::ASTContext const&, clang::Expr*, bool, llvm::ArrayRef<clang::BlockDecl*>)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXOperatorCallExpr::Create(clang::ASTContext const&, clang::OverloadedOperatorKind, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, clang::FPOptions, clang::CallExpr::ADLCallKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::IfStmt::Create(clang::ASTContext const&, clang::SourceLocation, bool, clang::Stmt*, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation, clang::Stmt*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-un",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:3368,usability,Tool,Toolchain,3368,"*, clang::Expr*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ExprWithCleanups::Create(clang::ASTContext const&, clang::Expr*, bool, llvm::ArrayRef<clang::BlockDecl*>)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXOperatorCallExpr::Create(clang::ASTContext const&, clang::OverloadedOperatorKind, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, clang::FPOptions, clang::CallExpr::ADLCallKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::IfStmt::Create(clang::ASTContext const&, clang::SourceLocation, bool, clang::Stmt*, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation, clang::Stmt*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::FunctionDecl::isDefined(clang::FunctionDecl const*&) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::ActOnWhileStmt(clang::SourceLocation, clang::Se",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:3806,usability,Tool,Toolchain,3806,"0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXOperatorCallExpr::Create(clang::ASTContext const&, clang::OverloadedOperatorKind, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, clang::FPOptions, clang::CallExpr::ADLCallKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::IfStmt::Create(clang::ASTContext const&, clang::SourceLocation, bool, clang::Stmt*, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation, clang::Stmt*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::FunctionDecl::isDefined(clang::FunctionDecl const*&) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::ActOnWhileStmt(clang::SourceLocation, clang::Sema::ConditionResult, clang::Stmt*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXMemberCallExpr::Create(clang::ASTContext const&, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:4137,usability,Tool,Toolchain,4137,"m::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, clang::FPOptions, clang::CallExpr::ADLCallKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::IfStmt::Create(clang::ASTContext const&, clang::SourceLocation, bool, clang::Stmt*, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation, clang::Stmt*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::FunctionDecl::isDefined(clang::FunctionDecl const*&) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::ActOnWhileStmt(clang::SourceLocation, clang::Sema::ConditionResult, clang::Stmt*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXMemberCallExpr::Create(clang::ASTContext const&, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, unsigned int)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::BuildCallToM",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:4497,usability,Tool,Toolchain,4497,"Cling.so.6.27.99: undefined reference to `clang::IfStmt::Create(clang::ASTContext const&, clang::SourceLocation, bool, clang::Stmt*, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation, clang::Stmt*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::FunctionDecl::isDefined(clang::FunctionDecl const*&) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::ActOnWhileStmt(clang::SourceLocation, clang::Sema::ConditionResult, clang::Stmt*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXMemberCallExpr::Create(clang::ASTContext const&, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, unsigned int)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::BuildCallToMemberFunction(clang::Scope*, clang::Expr*, clang::SourceLocation, llvm::MutableArrayRef<clang::Expr*>, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:4941,usability,Tool,Toolchain,4941,"so.6.27.99: undefined reference to `clang::FunctionDecl::isDefined(clang::FunctionDecl const*&) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::ActOnWhileStmt(clang::SourceLocation, clang::Sema::ConditionResult, clang::Stmt*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXMemberCallExpr::Create(clang::ASTContext const&, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, unsigned int)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::BuildCallToMemberFunction(clang::Scope*, clang::Expr*, clang::SourceLocation, llvm::MutableArrayRef<clang::Expr*>, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ConstantExpr::Create(clang::ASTContext const&, clang::Expr*, clang::ConstantExpr::ResultStorageKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXStaticCastExpr::Create(clang::",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:5357,usability,Tool,Toolchain,5357,", clang::Sema::ConditionResult, clang::Stmt*)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXMemberCallExpr::Create(clang::ASTContext const&, clang::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, unsigned int)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::BuildCallToMemberFunction(clang::Scope*, clang::Expr*, clang::SourceLocation, llvm::MutableArrayRef<clang::Expr*>, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ConstantExpr::Create(clang::ASTContext const&, clang::Expr*, clang::ConstantExpr::ResultStorageKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXStaticCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::TypeSourceInfo*, clang::SourceLocation, clang::SourceLocation, clang::SourceRange)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:5730,usability,Tool,Toolchain,5730,"ng::Expr*, llvm::ArrayRef<clang::Expr*>, clang::QualType, clang::ExprValueKind, clang::SourceLocation, unsigned int)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::Sema::BuildCallToMemberFunction(clang::Scope*, clang::Expr*, clang::SourceLocation, llvm::MutableArrayRef<clang::Expr*>, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ConstantExpr::Create(clang::ASTContext const&, clang::Expr*, clang::ConstantExpr::ResultStorageKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXStaticCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::TypeSourceInfo*, clang::SourceLocation, clang::SourceLocation, clang::SourceRange)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CStyleCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::TypeSourceInfo*, clang::SourceLocation, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:6270,usability,Tool,Toolchain,6270,"02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ConstantExpr::Create(clang::ASTContext const&, clang::Expr*, clang::ConstantExpr::ResultStorageKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXStaticCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::TypeSourceInfo*, clang::SourceLocation, clang::SourceLocation, clang::SourceRange)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CStyleCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::TypeSourceInfo*, clang::SourceLocation, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::FunctionDecl::Create(clang::ASTContext&, clang::DeclContext*, clang::SourceLocation, clang::DeclarationNameInfo const&, clang::QualType, clang::TypeSourceInfo*, clang::StorageClass, bool, bool, clang::ConstexprSpecKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:6787,usability,Tool,Toolchain,6787,"linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXStaticCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::TypeSourceInfo*, clang::SourceLocation, clang::SourceLocation, clang::SourceRange)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CStyleCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::TypeSourceInfo*, clang::SourceLocation, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::FunctionDecl::Create(clang::ASTContext&, clang::DeclContext*, clang::SourceLocation, clang::DeclarationNameInfo const&, clang::QualType, clang::TypeSourceInfo*, clang::StorageClass, bool, bool, clang::ConstexprSpecKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::WhileStmt::Create(clang::ASTContext const&, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../li",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:7279,usability,Tool,Toolchain,7279,"2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CStyleCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::TypeSourceInfo*, clang::SourceLocation, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::FunctionDecl::Create(clang::ASTContext&, clang::DeclContext*, clang::SourceLocation, clang::DeclarationNameInfo const&, clang::QualType, clang::TypeSourceInfo*, clang::StorageClass, bool, bool, clang::ConstexprSpecKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::WhileStmt::Create(clang::ASTContext const&, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ASTContext::getConstantArrayType(clang::QualType, llvm::APInt const&, clang::ArrayType::ArraySizeModifier, unsigned int) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXFunctionalCastExpr::Create(clang::AS",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:7663,usability,Tool,Toolchain,7663,"ation, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::FunctionDecl::Create(clang::ASTContext&, clang::DeclContext*, clang::SourceLocation, clang::DeclarationNameInfo const&, clang::QualType, clang::TypeSourceInfo*, clang::StorageClass, bool, bool, clang::ConstexprSpecKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::WhileStmt::Create(clang::ASTContext const&, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ASTContext::getConstantArrayType(clang::QualType, llvm::APInt const&, clang::ArrayType::ArraySizeModifier, unsigned int) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXFunctionalCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::TypeSourceInfo*, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::SourceLocation, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:8062,usability,Tool,Toolchain,8062,"rationNameInfo const&, clang::QualType, clang::TypeSourceInfo*, clang::StorageClass, bool, bool, clang::ConstexprSpecKind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::WhileStmt::Create(clang::ASTContext const&, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ASTContext::getConstantArrayType(clang::QualType, llvm::APInt const&, clang::ArrayType::ArraySizeModifier, unsigned int) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXFunctionalCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::TypeSourceInfo*, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::SourceLocation, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXMethodDecl::Create(clang::ASTContext&, clang::CXXRecordDecl*, clang::SourceLocation, clang::DeclarationNameInfo const&, clang::QualType, clang::TypeSourceInfo*, clang::StorageClass, bool, clang::ConstexprSpecKind, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: collect2: er",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:8586,usability,Tool,Toolchain,8586,"Kind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::WhileStmt::Create(clang::ASTContext const&, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ASTContext::getConstantArrayType(clang::QualType, llvm::APInt const&, clang::ArrayType::ArraySizeModifier, unsigned int) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXFunctionalCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::TypeSourceInfo*, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::SourceLocation, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXMethodDecl::Create(clang::ASTContext&, clang::CXXRecordDecl*, clang::SourceLocation, clang::DeclarationNameInfo const&, clang::QualType, clang::TypeSourceInfo*, clang::StorageClass, bool, clang::ConstexprSpecKind, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: collect2: error: ld returned 1 exit status. ```. when compiling with (v6-28-00-patches) 5ffba22ef571dea2d6eaf186662e19d5a7789a05.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:9065,usability,error,error,9065,"Kind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::WhileStmt::Create(clang::ASTContext const&, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ASTContext::getConstantArrayType(clang::QualType, llvm::APInt const&, clang::ArrayType::ArraySizeModifier, unsigned int) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXFunctionalCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::TypeSourceInfo*, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::SourceLocation, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXMethodDecl::Create(clang::ASTContext&, clang::CXXRecordDecl*, clang::SourceLocation, clang::DeclarationNameInfo const&, clang::QualType, clang::TypeSourceInfo*, clang::StorageClass, bool, clang::ConstexprSpecKind, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: collect2: error: ld returned 1 exit status. ```. when compiling with (v6-28-00-patches) 5ffba22ef571dea2d6eaf186662e19d5a7789a05.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/issues/12209:9091,usability,statu,status,9091,"Kind)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::WhileStmt::Create(clang::ASTContext const&, clang::VarDecl*, clang::Expr*, clang::Stmt*, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::ASTContext::getConstantArrayType(clang::QualType, llvm::APInt const&, clang::ArrayType::ArraySizeModifier, unsigned int) const'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXFunctionalCastExpr::Create(clang::ASTContext const&, clang::QualType, clang::ExprValueKind, clang::TypeSourceInfo*, clang::CastKind, clang::Expr*, llvm::SmallVector<clang::CXXBaseSpecifier*, 4u> const*, clang::SourceLocation, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: /home/eulisse/src/sw/ubuntu1804_x86-64/GCC-Toolchain/v10.2.0-alice2-local1/bin/../lib/gcc/x86_64-unknown-linux-gnu/10.2.0/../../../../x86_64-unknown-linux-gnu/bin/ld: ../lib/libCling.so.6.27.99: undefined reference to `clang::CXXMethodDecl::Create(clang::ASTContext&, clang::CXXRecordDecl*, clang::SourceLocation, clang::DeclarationNameInfo const&, clang::QualType, clang::TypeSourceInfo*, clang::StorageClass, bool, clang::ConstexprSpecKind, clang::SourceLocation)'. 2023-02-02@14:29:38:DEBUG:O2Physics:ROOT:0: collect2: error: ld returned 1 exit status. ```. when compiling with (v6-28-00-patches) 5ffba22ef571dea2d6eaf186662e19d5a7789a05.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12209
https://github.com/root-project/root/pull/12211:15,deployability,depend,dependency,15,[tmva] Fix the dependency of TMVA tutorials and PyMVA tests ; This Pull request fixes the correct dependency of some TMVA tutorial and PyMVA tests to avoid that the input data files are written at the same time. The PR contains also a fix for th TMVA_SOFIE_RSofieReader tutorial to handle correctly the model output vector.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12211
https://github.com/root-project/root/pull/12211:98,deployability,depend,dependency,98,[tmva] Fix the dependency of TMVA tutorials and PyMVA tests ; This Pull request fixes the correct dependency of some TMVA tutorial and PyMVA tests to avoid that the input data files are written at the same time. The PR contains also a fix for th TMVA_SOFIE_RSofieReader tutorial to handle correctly the model output vector.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12211
https://github.com/root-project/root/pull/12211:219,deployability,contain,contains,219,[tmva] Fix the dependency of TMVA tutorials and PyMVA tests ; This Pull request fixes the correct dependency of some TMVA tutorial and PyMVA tests to avoid that the input data files are written at the same time. The PR contains also a fix for th TMVA_SOFIE_RSofieReader tutorial to handle correctly the model output vector.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12211
https://github.com/root-project/root/pull/12211:303,energy efficiency,model,model,303,[tmva] Fix the dependency of TMVA tutorials and PyMVA tests ; This Pull request fixes the correct dependency of some TMVA tutorial and PyMVA tests to avoid that the input data files are written at the same time. The PR contains also a fix for th TMVA_SOFIE_RSofieReader tutorial to handle correctly the model output vector.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12211
https://github.com/root-project/root/pull/12211:15,integrability,depend,dependency,15,[tmva] Fix the dependency of TMVA tutorials and PyMVA tests ; This Pull request fixes the correct dependency of some TMVA tutorial and PyMVA tests to avoid that the input data files are written at the same time. The PR contains also a fix for th TMVA_SOFIE_RSofieReader tutorial to handle correctly the model output vector.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12211
https://github.com/root-project/root/pull/12211:98,integrability,depend,dependency,98,[tmva] Fix the dependency of TMVA tutorials and PyMVA tests ; This Pull request fixes the correct dependency of some TMVA tutorial and PyMVA tests to avoid that the input data files are written at the same time. The PR contains also a fix for th TMVA_SOFIE_RSofieReader tutorial to handle correctly the model output vector.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12211
https://github.com/root-project/root/pull/12211:15,modifiability,depend,dependency,15,[tmva] Fix the dependency of TMVA tutorials and PyMVA tests ; This Pull request fixes the correct dependency of some TMVA tutorial and PyMVA tests to avoid that the input data files are written at the same time. The PR contains also a fix for th TMVA_SOFIE_RSofieReader tutorial to handle correctly the model output vector.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12211
https://github.com/root-project/root/pull/12211:98,modifiability,depend,dependency,98,[tmva] Fix the dependency of TMVA tutorials and PyMVA tests ; This Pull request fixes the correct dependency of some TMVA tutorial and PyMVA tests to avoid that the input data files are written at the same time. The PR contains also a fix for th TMVA_SOFIE_RSofieReader tutorial to handle correctly the model output vector.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12211
https://github.com/root-project/root/pull/12211:206,performance,time,time,206,[tmva] Fix the dependency of TMVA tutorials and PyMVA tests ; This Pull request fixes the correct dependency of some TMVA tutorial and PyMVA tests to avoid that the input data files are written at the same time. The PR contains also a fix for th TMVA_SOFIE_RSofieReader tutorial to handle correctly the model output vector.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12211
https://github.com/root-project/root/pull/12211:15,safety,depend,dependency,15,[tmva] Fix the dependency of TMVA tutorials and PyMVA tests ; This Pull request fixes the correct dependency of some TMVA tutorial and PyMVA tests to avoid that the input data files are written at the same time. The PR contains also a fix for th TMVA_SOFIE_RSofieReader tutorial to handle correctly the model output vector.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12211
https://github.com/root-project/root/pull/12211:54,safety,test,tests,54,[tmva] Fix the dependency of TMVA tutorials and PyMVA tests ; This Pull request fixes the correct dependency of some TMVA tutorial and PyMVA tests to avoid that the input data files are written at the same time. The PR contains also a fix for th TMVA_SOFIE_RSofieReader tutorial to handle correctly the model output vector.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12211
https://github.com/root-project/root/pull/12211:98,safety,depend,dependency,98,[tmva] Fix the dependency of TMVA tutorials and PyMVA tests ; This Pull request fixes the correct dependency of some TMVA tutorial and PyMVA tests to avoid that the input data files are written at the same time. The PR contains also a fix for th TMVA_SOFIE_RSofieReader tutorial to handle correctly the model output vector.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12211
https://github.com/root-project/root/pull/12211:141,safety,test,tests,141,[tmva] Fix the dependency of TMVA tutorials and PyMVA tests ; This Pull request fixes the correct dependency of some TMVA tutorial and PyMVA tests to avoid that the input data files are written at the same time. The PR contains also a fix for th TMVA_SOFIE_RSofieReader tutorial to handle correctly the model output vector.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12211
https://github.com/root-project/root/pull/12211:150,safety,avoid,avoid,150,[tmva] Fix the dependency of TMVA tutorials and PyMVA tests ; This Pull request fixes the correct dependency of some TMVA tutorial and PyMVA tests to avoid that the input data files are written at the same time. The PR contains also a fix for th TMVA_SOFIE_RSofieReader tutorial to handle correctly the model output vector.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12211
https://github.com/root-project/root/pull/12211:165,safety,input,input,165,[tmva] Fix the dependency of TMVA tutorials and PyMVA tests ; This Pull request fixes the correct dependency of some TMVA tutorial and PyMVA tests to avoid that the input data files are written at the same time. The PR contains also a fix for th TMVA_SOFIE_RSofieReader tutorial to handle correctly the model output vector.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12211
https://github.com/root-project/root/pull/12211:303,security,model,model,303,[tmva] Fix the dependency of TMVA tutorials and PyMVA tests ; This Pull request fixes the correct dependency of some TMVA tutorial and PyMVA tests to avoid that the input data files are written at the same time. The PR contains also a fix for th TMVA_SOFIE_RSofieReader tutorial to handle correctly the model output vector.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12211
https://github.com/root-project/root/pull/12211:15,testability,depend,dependency,15,[tmva] Fix the dependency of TMVA tutorials and PyMVA tests ; This Pull request fixes the correct dependency of some TMVA tutorial and PyMVA tests to avoid that the input data files are written at the same time. The PR contains also a fix for th TMVA_SOFIE_RSofieReader tutorial to handle correctly the model output vector.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12211
https://github.com/root-project/root/pull/12211:54,testability,test,tests,54,[tmva] Fix the dependency of TMVA tutorials and PyMVA tests ; This Pull request fixes the correct dependency of some TMVA tutorial and PyMVA tests to avoid that the input data files are written at the same time. The PR contains also a fix for th TMVA_SOFIE_RSofieReader tutorial to handle correctly the model output vector.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12211
https://github.com/root-project/root/pull/12211:98,testability,depend,dependency,98,[tmva] Fix the dependency of TMVA tutorials and PyMVA tests ; This Pull request fixes the correct dependency of some TMVA tutorial and PyMVA tests to avoid that the input data files are written at the same time. The PR contains also a fix for th TMVA_SOFIE_RSofieReader tutorial to handle correctly the model output vector.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12211
https://github.com/root-project/root/pull/12211:141,testability,test,tests,141,[tmva] Fix the dependency of TMVA tutorials and PyMVA tests ; This Pull request fixes the correct dependency of some TMVA tutorial and PyMVA tests to avoid that the input data files are written at the same time. The PR contains also a fix for th TMVA_SOFIE_RSofieReader tutorial to handle correctly the model output vector.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12211
https://github.com/root-project/root/pull/12211:165,usability,input,input,165,[tmva] Fix the dependency of TMVA tutorials and PyMVA tests ; This Pull request fixes the correct dependency of some TMVA tutorial and PyMVA tests to avoid that the input data files are written at the same time. The PR contains also a fix for th TMVA_SOFIE_RSofieReader tutorial to handle correctly the model output vector.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12211
https://github.com/root-project/root/pull/12212:130,availability,failur,failure,130,[DF] Removing failing test with shorter friends (v6.28); This is a backport of #12025 by @hahnjo and fixes the corresponding test failure in v6-28-00-patches.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12212
https://github.com/root-project/root/pull/12212:14,deployability,fail,failing,14,[DF] Removing failing test with shorter friends (v6.28); This is a backport of #12025 by @hahnjo and fixes the corresponding test failure in v6-28-00-patches.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12212
https://github.com/root-project/root/pull/12212:130,deployability,fail,failure,130,[DF] Removing failing test with shorter friends (v6.28); This is a backport of #12025 by @hahnjo and fixes the corresponding test failure in v6-28-00-patches.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12212
https://github.com/root-project/root/pull/12212:150,deployability,patch,patches,150,[DF] Removing failing test with shorter friends (v6.28); This is a backport of #12025 by @hahnjo and fixes the corresponding test failure in v6-28-00-patches.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12212
https://github.com/root-project/root/pull/12212:130,performance,failur,failure,130,[DF] Removing failing test with shorter friends (v6.28); This is a backport of #12025 by @hahnjo and fixes the corresponding test failure in v6-28-00-patches.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12212
https://github.com/root-project/root/pull/12212:14,reliability,fail,failing,14,[DF] Removing failing test with shorter friends (v6.28); This is a backport of #12025 by @hahnjo and fixes the corresponding test failure in v6-28-00-patches.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12212
https://github.com/root-project/root/pull/12212:130,reliability,fail,failure,130,[DF] Removing failing test with shorter friends (v6.28); This is a backport of #12025 by @hahnjo and fixes the corresponding test failure in v6-28-00-patches.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12212
https://github.com/root-project/root/pull/12212:22,safety,test,test,22,[DF] Removing failing test with shorter friends (v6.28); This is a backport of #12025 by @hahnjo and fixes the corresponding test failure in v6-28-00-patches.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12212
https://github.com/root-project/root/pull/12212:125,safety,test,test,125,[DF] Removing failing test with shorter friends (v6.28); This is a backport of #12025 by @hahnjo and fixes the corresponding test failure in v6-28-00-patches.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12212
https://github.com/root-project/root/pull/12212:150,safety,patch,patches,150,[DF] Removing failing test with shorter friends (v6.28); This is a backport of #12025 by @hahnjo and fixes the corresponding test failure in v6-28-00-patches.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12212
https://github.com/root-project/root/pull/12212:150,security,patch,patches,150,[DF] Removing failing test with shorter friends (v6.28); This is a backport of #12025 by @hahnjo and fixes the corresponding test failure in v6-28-00-patches.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12212
https://github.com/root-project/root/pull/12212:22,testability,test,test,22,[DF] Removing failing test with shorter friends (v6.28); This is a backport of #12025 by @hahnjo and fixes the corresponding test failure in v6-28-00-patches.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12212
https://github.com/root-project/root/pull/12212:125,testability,test,test,125,[DF] Removing failing test with shorter friends (v6.28); This is a backport of #12025 by @hahnjo and fixes the corresponding test failure in v6-28-00-patches.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12212
https://github.com/root-project/root/pull/12214:216,interoperability,convers,conversation,216,"[VecOps] Avoid -ffast-math; The performance gains are unclear and the option can harm users linking against the library with gcc<13, see also https://gcc.gnu.org/bugzilla/show_bug.cgi?id=55522 . EDIT: relevant forum conversation: https://root-forum.cern.ch/t/rootvecops-enables-ffast-math/53422",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12214
https://github.com/root-project/root/pull/12214:32,performance,perform,performance,32,"[VecOps] Avoid -ffast-math; The performance gains are unclear and the option can harm users linking against the library with gcc<13, see also https://gcc.gnu.org/bugzilla/show_bug.cgi?id=55522 . EDIT: relevant forum conversation: https://root-forum.cern.ch/t/rootvecops-enables-ffast-math/53422",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12214
https://github.com/root-project/root/pull/12214:9,safety,Avoid,Avoid,9,"[VecOps] Avoid -ffast-math; The performance gains are unclear and the option can harm users linking against the library with gcc<13, see also https://gcc.gnu.org/bugzilla/show_bug.cgi?id=55522 . EDIT: relevant forum conversation: https://root-forum.cern.ch/t/rootvecops-enables-ffast-math/53422",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12214
https://github.com/root-project/root/pull/12214:32,usability,perform,performance,32,"[VecOps] Avoid -ffast-math; The performance gains are unclear and the option can harm users linking against the library with gcc<13, see also https://gcc.gnu.org/bugzilla/show_bug.cgi?id=55522 . EDIT: relevant forum conversation: https://root-forum.cern.ch/t/rootvecops-enables-ffast-math/53422",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12214
https://github.com/root-project/root/pull/12214:86,usability,user,users,86,"[VecOps] Avoid -ffast-math; The performance gains are unclear and the option can harm users linking against the library with gcc<13, see also https://gcc.gnu.org/bugzilla/show_bug.cgi?id=55522 . EDIT: relevant forum conversation: https://root-forum.cern.ch/t/rootvecops-enables-ffast-math/53422",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12214
https://github.com/root-project/root/pull/12216:33,safety,test,test,33,Add missing include to metacling test; Detected with -Ddev=ON cmake flags.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12216
https://github.com/root-project/root/pull/12216:39,safety,Detect,Detected,39,Add missing include to metacling test; Detected with -Ddev=ON cmake flags.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12216
https://github.com/root-project/root/pull/12216:39,security,Detect,Detected,39,Add missing include to metacling test; Detected with -Ddev=ON cmake flags.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12216
https://github.com/root-project/root/pull/12216:33,testability,test,test,33,Add missing include to metacling test; Detected with -Ddev=ON cmake flags.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12216
https://github.com/root-project/root/pull/12219:132,integrability,wrap,wrapped,132,[RF] Add clad derivative support to RooFuncWrapper; This PR uses clad to calculate the AD-based derivatives for the C/C++ functions wrapped by the RooFuncWrapper class and introduces the 'getGradient' interface to get these derivatives from the generated gradient function. It also replaces a `std::span` templated type with `std::size` to avoid conflicts with system headers.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12219
https://github.com/root-project/root/pull/12219:201,integrability,interfac,interface,201,[RF] Add clad derivative support to RooFuncWrapper; This PR uses clad to calculate the AD-based derivatives for the C/C++ functions wrapped by the RooFuncWrapper class and introduces the 'getGradient' interface to get these derivatives from the generated gradient function. It also replaces a `std::span` templated type with `std::size` to avoid conflicts with system headers.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12219
https://github.com/root-project/root/pull/12219:201,interoperability,interfac,interface,201,[RF] Add clad derivative support to RooFuncWrapper; This PR uses clad to calculate the AD-based derivatives for the C/C++ functions wrapped by the RooFuncWrapper class and introduces the 'getGradient' interface to get these derivatives from the generated gradient function. It also replaces a `std::span` templated type with `std::size` to avoid conflicts with system headers.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12219
https://github.com/root-project/root/pull/12219:346,interoperability,conflict,conflicts,346,[RF] Add clad derivative support to RooFuncWrapper; This PR uses clad to calculate the AD-based derivatives for the C/C++ functions wrapped by the RooFuncWrapper class and introduces the 'getGradient' interface to get these derivatives from the generated gradient function. It also replaces a `std::span` templated type with `std::size` to avoid conflicts with system headers.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12219
https://github.com/root-project/root/pull/12219:201,modifiability,interfac,interface,201,[RF] Add clad derivative support to RooFuncWrapper; This PR uses clad to calculate the AD-based derivatives for the C/C++ functions wrapped by the RooFuncWrapper class and introduces the 'getGradient' interface to get these derivatives from the generated gradient function. It also replaces a `std::span` templated type with `std::size` to avoid conflicts with system headers.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12219
https://github.com/root-project/root/pull/12219:340,safety,avoid,avoid,340,[RF] Add clad derivative support to RooFuncWrapper; This PR uses clad to calculate the AD-based derivatives for the C/C++ functions wrapped by the RooFuncWrapper class and introduces the 'getGradient' interface to get these derivatives from the generated gradient function. It also replaces a `std::span` templated type with `std::size` to avoid conflicts with system headers.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12219
https://github.com/root-project/root/pull/12219:25,usability,support,support,25,[RF] Add clad derivative support to RooFuncWrapper; This PR uses clad to calculate the AD-based derivatives for the C/C++ functions wrapped by the RooFuncWrapper class and introduces the 'getGradient' interface to get these derivatives from the generated gradient function. It also replaces a `std::span` templated type with `std::size` to avoid conflicts with system headers.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12219
https://github.com/root-project/root/pull/12220:13,usability,support,support,13,"[ntuple] Add support for float, double, Int split encodings; As a follow up of #12133, this PR adds support for the column types. - kSplitReal64. - kSplitReal32. - kSplitInt64. - kSplitInt32. - kSplitInt16. It makes the split encoding the default unless the ntuple is stored uncompressed. A follow-up PR will take care of kSplitIndex[32|64].",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12220
https://github.com/root-project/root/pull/12220:100,usability,support,support,100,"[ntuple] Add support for float, double, Int split encodings; As a follow up of #12133, this PR adds support for the column types. - kSplitReal64. - kSplitReal32. - kSplitInt64. - kSplitInt32. - kSplitInt16. It makes the split encoding the default unless the ntuple is stored uncompressed. A follow-up PR will take care of kSplitIndex[32|64].",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12220
https://github.com/root-project/root/pull/12221:56,deployability,build,building,56,"[RF] Make it possible to switch to `ryml` backend after building ROOT; ROOT introduced a build flag in 6.26.00 that allowed you to build it using the `ryml` library instead of nlohmann-json as the backend for the JSON IO. But that was not particularly great. The `ryml` backend code is at risk of rotting, because to try and test it one needs a special ROOT build. It would be much better to just build both backends if `ryml` is installed on the system, and have a mechanism for developers to try this other backend. This is implemented in this commit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12221
https://github.com/root-project/root/pull/12221:89,deployability,build,build,89,"[RF] Make it possible to switch to `ryml` backend after building ROOT; ROOT introduced a build flag in 6.26.00 that allowed you to build it using the `ryml` library instead of nlohmann-json as the backend for the JSON IO. But that was not particularly great. The `ryml` backend code is at risk of rotting, because to try and test it one needs a special ROOT build. It would be much better to just build both backends if `ryml` is installed on the system, and have a mechanism for developers to try this other backend. This is implemented in this commit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12221
https://github.com/root-project/root/pull/12221:131,deployability,build,build,131,"[RF] Make it possible to switch to `ryml` backend after building ROOT; ROOT introduced a build flag in 6.26.00 that allowed you to build it using the `ryml` library instead of nlohmann-json as the backend for the JSON IO. But that was not particularly great. The `ryml` backend code is at risk of rotting, because to try and test it one needs a special ROOT build. It would be much better to just build both backends if `ryml` is installed on the system, and have a mechanism for developers to try this other backend. This is implemented in this commit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12221
https://github.com/root-project/root/pull/12221:358,deployability,build,build,358,"[RF] Make it possible to switch to `ryml` backend after building ROOT; ROOT introduced a build flag in 6.26.00 that allowed you to build it using the `ryml` library instead of nlohmann-json as the backend for the JSON IO. But that was not particularly great. The `ryml` backend code is at risk of rotting, because to try and test it one needs a special ROOT build. It would be much better to just build both backends if `ryml` is installed on the system, and have a mechanism for developers to try this other backend. This is implemented in this commit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12221
https://github.com/root-project/root/pull/12221:397,deployability,build,build,397,"[RF] Make it possible to switch to `ryml` backend after building ROOT; ROOT introduced a build flag in 6.26.00 that allowed you to build it using the `ryml` library instead of nlohmann-json as the backend for the JSON IO. But that was not particularly great. The `ryml` backend code is at risk of rotting, because to try and test it one needs a special ROOT build. It would be much better to just build both backends if `ryml` is installed on the system, and have a mechanism for developers to try this other backend. This is implemented in this commit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12221
https://github.com/root-project/root/pull/12221:430,deployability,instal,installed,430,"[RF] Make it possible to switch to `ryml` backend after building ROOT; ROOT introduced a build flag in 6.26.00 that allowed you to build it using the `ryml` library instead of nlohmann-json as the backend for the JSON IO. But that was not particularly great. The `ryml` backend code is at risk of rotting, because to try and test it one needs a special ROOT build. It would be much better to just build both backends if `ryml` is installed on the system, and have a mechanism for developers to try this other backend. This is implemented in this commit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12221
https://github.com/root-project/root/pull/12221:289,safety,risk,risk,289,"[RF] Make it possible to switch to `ryml` backend after building ROOT; ROOT introduced a build flag in 6.26.00 that allowed you to build it using the `ryml` library instead of nlohmann-json as the backend for the JSON IO. But that was not particularly great. The `ryml` backend code is at risk of rotting, because to try and test it one needs a special ROOT build. It would be much better to just build both backends if `ryml` is installed on the system, and have a mechanism for developers to try this other backend. This is implemented in this commit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12221
https://github.com/root-project/root/pull/12221:325,safety,test,test,325,"[RF] Make it possible to switch to `ryml` backend after building ROOT; ROOT introduced a build flag in 6.26.00 that allowed you to build it using the `ryml` library instead of nlohmann-json as the backend for the JSON IO. But that was not particularly great. The `ryml` backend code is at risk of rotting, because to try and test it one needs a special ROOT build. It would be much better to just build both backends if `ryml` is installed on the system, and have a mechanism for developers to try this other backend. This is implemented in this commit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12221
https://github.com/root-project/root/pull/12221:289,security,risk,risk,289,"[RF] Make it possible to switch to `ryml` backend after building ROOT; ROOT introduced a build flag in 6.26.00 that allowed you to build it using the `ryml` library instead of nlohmann-json as the backend for the JSON IO. But that was not particularly great. The `ryml` backend code is at risk of rotting, because to try and test it one needs a special ROOT build. It would be much better to just build both backends if `ryml` is installed on the system, and have a mechanism for developers to try this other backend. This is implemented in this commit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12221
https://github.com/root-project/root/pull/12221:325,testability,test,test,325,"[RF] Make it possible to switch to `ryml` backend after building ROOT; ROOT introduced a build flag in 6.26.00 that allowed you to build it using the `ryml` library instead of nlohmann-json as the backend for the JSON IO. But that was not particularly great. The `ryml` backend code is at risk of rotting, because to try and test it one needs a special ROOT build. It would be much better to just build both backends if `ryml` is installed on the system, and have a mechanism for developers to try this other backend. This is implemented in this commit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12221
https://github.com/root-project/root/pull/12223:120,energy efficiency,model,model,120,"RF] Use `double` and not `float` all the way in RooFit JSON IO ; RooFit uses doubles everywhere else, so if importing a model from JSON. should give the same biswise results as creating the model in the. workspace factory language, `double` needs to be used in the JSON. interface too. There is also another commit that fixes a typo, and another commit that adds an easy way to fill lists via the JSON interface in order to reduce the number of lines of code needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12223
https://github.com/root-project/root/pull/12223:190,energy efficiency,model,model,190,"RF] Use `double` and not `float` all the way in RooFit JSON IO ; RooFit uses doubles everywhere else, so if importing a model from JSON. should give the same biswise results as creating the model in the. workspace factory language, `double` needs to be used in the JSON. interface too. There is also another commit that fixes a typo, and another commit that adds an easy way to fill lists via the JSON interface in order to reduce the number of lines of code needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12223
https://github.com/root-project/root/pull/12223:424,energy efficiency,reduc,reduce,424,"RF] Use `double` and not `float` all the way in RooFit JSON IO ; RooFit uses doubles everywhere else, so if importing a model from JSON. should give the same biswise results as creating the model in the. workspace factory language, `double` needs to be used in the JSON. interface too. There is also another commit that fixes a typo, and another commit that adds an easy way to fill lists via the JSON interface in order to reduce the number of lines of code needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12223
https://github.com/root-project/root/pull/12223:271,integrability,interfac,interface,271,"RF] Use `double` and not `float` all the way in RooFit JSON IO ; RooFit uses doubles everywhere else, so if importing a model from JSON. should give the same biswise results as creating the model in the. workspace factory language, `double` needs to be used in the JSON. interface too. There is also another commit that fixes a typo, and another commit that adds an easy way to fill lists via the JSON interface in order to reduce the number of lines of code needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12223
https://github.com/root-project/root/pull/12223:402,integrability,interfac,interface,402,"RF] Use `double` and not `float` all the way in RooFit JSON IO ; RooFit uses doubles everywhere else, so if importing a model from JSON. should give the same biswise results as creating the model in the. workspace factory language, `double` needs to be used in the JSON. interface too. There is also another commit that fixes a typo, and another commit that adds an easy way to fill lists via the JSON interface in order to reduce the number of lines of code needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12223
https://github.com/root-project/root/pull/12223:271,interoperability,interfac,interface,271,"RF] Use `double` and not `float` all the way in RooFit JSON IO ; RooFit uses doubles everywhere else, so if importing a model from JSON. should give the same biswise results as creating the model in the. workspace factory language, `double` needs to be used in the JSON. interface too. There is also another commit that fixes a typo, and another commit that adds an easy way to fill lists via the JSON interface in order to reduce the number of lines of code needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12223
https://github.com/root-project/root/pull/12223:402,interoperability,interfac,interface,402,"RF] Use `double` and not `float` all the way in RooFit JSON IO ; RooFit uses doubles everywhere else, so if importing a model from JSON. should give the same biswise results as creating the model in the. workspace factory language, `double` needs to be used in the JSON. interface too. There is also another commit that fixes a typo, and another commit that adds an easy way to fill lists via the JSON interface in order to reduce the number of lines of code needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12223
https://github.com/root-project/root/pull/12223:271,modifiability,interfac,interface,271,"RF] Use `double` and not `float` all the way in RooFit JSON IO ; RooFit uses doubles everywhere else, so if importing a model from JSON. should give the same biswise results as creating the model in the. workspace factory language, `double` needs to be used in the JSON. interface too. There is also another commit that fixes a typo, and another commit that adds an easy way to fill lists via the JSON interface in order to reduce the number of lines of code needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12223
https://github.com/root-project/root/pull/12223:402,modifiability,interfac,interface,402,"RF] Use `double` and not `float` all the way in RooFit JSON IO ; RooFit uses doubles everywhere else, so if importing a model from JSON. should give the same biswise results as creating the model in the. workspace factory language, `double` needs to be used in the JSON. interface too. There is also another commit that fixes a typo, and another commit that adds an easy way to fill lists via the JSON interface in order to reduce the number of lines of code needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12223
https://github.com/root-project/root/pull/12223:120,security,model,model,120,"RF] Use `double` and not `float` all the way in RooFit JSON IO ; RooFit uses doubles everywhere else, so if importing a model from JSON. should give the same biswise results as creating the model in the. workspace factory language, `double` needs to be used in the JSON. interface too. There is also another commit that fixes a typo, and another commit that adds an easy way to fill lists via the JSON interface in order to reduce the number of lines of code needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12223
https://github.com/root-project/root/pull/12223:190,security,model,model,190,"RF] Use `double` and not `float` all the way in RooFit JSON IO ; RooFit uses doubles everywhere else, so if importing a model from JSON. should give the same biswise results as creating the model in the. workspace factory language, `double` needs to be used in the JSON. interface too. There is also another commit that fixes a typo, and another commit that adds an easy way to fill lists via the JSON interface in order to reduce the number of lines of code needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12223
https://github.com/root-project/root/issues/12224:17,usability,help,help,17,"`rootreadspeed --help` has ""random"" linebreaks; My terminal and `rootreadspeed --help` disagree on where the line breaks should be. I'd propose to not insert line breaks in rootreadspeed's text paragraph output and let the terminal handle that. ![image](https://user-images.githubusercontent.com/144675/216666135-5c556c9d-ac25-4e58-8467-673bf21f9bf9.png).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12224
https://github.com/root-project/root/issues/12224:81,usability,help,help,81,"`rootreadspeed --help` has ""random"" linebreaks; My terminal and `rootreadspeed --help` disagree on where the line breaks should be. I'd propose to not insert line breaks in rootreadspeed's text paragraph output and let the terminal handle that. ![image](https://user-images.githubusercontent.com/144675/216666135-5c556c9d-ac25-4e58-8467-673bf21f9bf9.png).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12224
https://github.com/root-project/root/issues/12224:262,usability,user,user-images,262,"`rootreadspeed --help` has ""random"" linebreaks; My terminal and `rootreadspeed --help` disagree on where the line breaks should be. I'd propose to not insert line breaks in rootreadspeed's text paragraph output and let the terminal handle that. ![image](https://user-images.githubusercontent.com/144675/216666135-5c556c9d-ac25-4e58-8467-673bf21f9bf9.png).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12224
https://github.com/root-project/root/issues/12225:415,availability,fault,fault,415,"[RF] Allowing to use AddPreprocessFunction for shape factors in HistFactory; We would like to have an option to reparametrise shape-factors, i.e. the per-bin normalisation factors in HistFactory. This would be useful for template fits where different histograms represent different values of some parameter, e.g. mass. Currently, it seems that only NormFactors can be reparametrised and the code crashes with a seg fault when trying to reparametrise the shape factors. See the example attached. [shapeFactorCrash.zip](https://github.com/root-project/root/files/10581134/shapeFactorCrash.zip). ### Describe the solution you'd like. We would like to be able to use HistFactory::Measurement::AddPreprocessFunction for shapefactors. ### Describe alternatives you've considered. There is a workaround by doing this reparametrisation manually, but it cumbersome and errorprone. ### Additional context. Note that even if this is not supported, the code should probably not crash with a seg fault (tested with ROOT Version: 6.27/01).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12225
https://github.com/root-project/root/issues/12225:860,availability,error,errorprone,860,"[RF] Allowing to use AddPreprocessFunction for shape factors in HistFactory; We would like to have an option to reparametrise shape-factors, i.e. the per-bin normalisation factors in HistFactory. This would be useful for template fits where different histograms represent different values of some parameter, e.g. mass. Currently, it seems that only NormFactors can be reparametrised and the code crashes with a seg fault when trying to reparametrise the shape factors. See the example attached. [shapeFactorCrash.zip](https://github.com/root-project/root/files/10581134/shapeFactorCrash.zip). ### Describe the solution you'd like. We would like to be able to use HistFactory::Measurement::AddPreprocessFunction for shapefactors. ### Describe alternatives you've considered. There is a workaround by doing this reparametrisation manually, but it cumbersome and errorprone. ### Additional context. Note that even if this is not supported, the code should probably not crash with a seg fault (tested with ROOT Version: 6.27/01).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12225
https://github.com/root-project/root/issues/12225:983,availability,fault,fault,983,"[RF] Allowing to use AddPreprocessFunction for shape factors in HistFactory; We would like to have an option to reparametrise shape-factors, i.e. the per-bin normalisation factors in HistFactory. This would be useful for template fits where different histograms represent different values of some parameter, e.g. mass. Currently, it seems that only NormFactors can be reparametrised and the code crashes with a seg fault when trying to reparametrise the shape factors. See the example attached. [shapeFactorCrash.zip](https://github.com/root-project/root/files/10581134/shapeFactorCrash.zip). ### Describe the solution you'd like. We would like to be able to use HistFactory::Measurement::AddPreprocessFunction for shapefactors. ### Describe alternatives you've considered. There is a workaround by doing this reparametrisation manually, but it cumbersome and errorprone. ### Additional context. Note that even if this is not supported, the code should probably not crash with a seg fault (tested with ROOT Version: 6.27/01).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12225
https://github.com/root-project/root/issues/12225:1007,deployability,Version,Version,1007,"[RF] Allowing to use AddPreprocessFunction for shape factors in HistFactory; We would like to have an option to reparametrise shape-factors, i.e. the per-bin normalisation factors in HistFactory. This would be useful for template fits where different histograms represent different values of some parameter, e.g. mass. Currently, it seems that only NormFactors can be reparametrised and the code crashes with a seg fault when trying to reparametrise the shape factors. See the example attached. [shapeFactorCrash.zip](https://github.com/root-project/root/files/10581134/shapeFactorCrash.zip). ### Describe the solution you'd like. We would like to be able to use HistFactory::Measurement::AddPreprocessFunction for shapefactors. ### Describe alternatives you've considered. There is a workaround by doing this reparametrisation manually, but it cumbersome and errorprone. ### Additional context. Note that even if this is not supported, the code should probably not crash with a seg fault (tested with ROOT Version: 6.27/01).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12225
https://github.com/root-project/root/issues/12225:319,energy efficiency,Current,Currently,319,"[RF] Allowing to use AddPreprocessFunction for shape factors in HistFactory; We would like to have an option to reparametrise shape-factors, i.e. the per-bin normalisation factors in HistFactory. This would be useful for template fits where different histograms represent different values of some parameter, e.g. mass. Currently, it seems that only NormFactors can be reparametrised and the code crashes with a seg fault when trying to reparametrise the shape factors. See the example attached. [shapeFactorCrash.zip](https://github.com/root-project/root/files/10581134/shapeFactorCrash.zip). ### Describe the solution you'd like. We would like to be able to use HistFactory::Measurement::AddPreprocessFunction for shapefactors. ### Describe alternatives you've considered. There is a workaround by doing this reparametrisation manually, but it cumbersome and errorprone. ### Additional context. Note that even if this is not supported, the code should probably not crash with a seg fault (tested with ROOT Version: 6.27/01).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12225
https://github.com/root-project/root/issues/12225:415,energy efficiency,fault,fault,415,"[RF] Allowing to use AddPreprocessFunction for shape factors in HistFactory; We would like to have an option to reparametrise shape-factors, i.e. the per-bin normalisation factors in HistFactory. This would be useful for template fits where different histograms represent different values of some parameter, e.g. mass. Currently, it seems that only NormFactors can be reparametrised and the code crashes with a seg fault when trying to reparametrise the shape factors. See the example attached. [shapeFactorCrash.zip](https://github.com/root-project/root/files/10581134/shapeFactorCrash.zip). ### Describe the solution you'd like. We would like to be able to use HistFactory::Measurement::AddPreprocessFunction for shapefactors. ### Describe alternatives you've considered. There is a workaround by doing this reparametrisation manually, but it cumbersome and errorprone. ### Additional context. Note that even if this is not supported, the code should probably not crash with a seg fault (tested with ROOT Version: 6.27/01).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12225
https://github.com/root-project/root/issues/12225:676,energy efficiency,Measur,Measurement,676,"[RF] Allowing to use AddPreprocessFunction for shape factors in HistFactory; We would like to have an option to reparametrise shape-factors, i.e. the per-bin normalisation factors in HistFactory. This would be useful for template fits where different histograms represent different values of some parameter, e.g. mass. Currently, it seems that only NormFactors can be reparametrised and the code crashes with a seg fault when trying to reparametrise the shape factors. See the example attached. [shapeFactorCrash.zip](https://github.com/root-project/root/files/10581134/shapeFactorCrash.zip). ### Describe the solution you'd like. We would like to be able to use HistFactory::Measurement::AddPreprocessFunction for shapefactors. ### Describe alternatives you've considered. There is a workaround by doing this reparametrisation manually, but it cumbersome and errorprone. ### Additional context. Note that even if this is not supported, the code should probably not crash with a seg fault (tested with ROOT Version: 6.27/01).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12225
https://github.com/root-project/root/issues/12225:983,energy efficiency,fault,fault,983,"[RF] Allowing to use AddPreprocessFunction for shape factors in HistFactory; We would like to have an option to reparametrise shape-factors, i.e. the per-bin normalisation factors in HistFactory. This would be useful for template fits where different histograms represent different values of some parameter, e.g. mass. Currently, it seems that only NormFactors can be reparametrised and the code crashes with a seg fault when trying to reparametrise the shape factors. See the example attached. [shapeFactorCrash.zip](https://github.com/root-project/root/files/10581134/shapeFactorCrash.zip). ### Describe the solution you'd like. We would like to be able to use HistFactory::Measurement::AddPreprocessFunction for shapefactors. ### Describe alternatives you've considered. There is a workaround by doing this reparametrisation manually, but it cumbersome and errorprone. ### Additional context. Note that even if this is not supported, the code should probably not crash with a seg fault (tested with ROOT Version: 6.27/01).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12225
https://github.com/root-project/root/issues/12225:1007,integrability,Version,Version,1007,"[RF] Allowing to use AddPreprocessFunction for shape factors in HistFactory; We would like to have an option to reparametrise shape-factors, i.e. the per-bin normalisation factors in HistFactory. This would be useful for template fits where different histograms represent different values of some parameter, e.g. mass. Currently, it seems that only NormFactors can be reparametrised and the code crashes with a seg fault when trying to reparametrise the shape factors. See the example attached. [shapeFactorCrash.zip](https://github.com/root-project/root/files/10581134/shapeFactorCrash.zip). ### Describe the solution you'd like. We would like to be able to use HistFactory::Measurement::AddPreprocessFunction for shapefactors. ### Describe alternatives you've considered. There is a workaround by doing this reparametrisation manually, but it cumbersome and errorprone. ### Additional context. Note that even if this is not supported, the code should probably not crash with a seg fault (tested with ROOT Version: 6.27/01).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12225
https://github.com/root-project/root/issues/12225:297,modifiability,paramet,parameter,297,"[RF] Allowing to use AddPreprocessFunction for shape factors in HistFactory; We would like to have an option to reparametrise shape-factors, i.e. the per-bin normalisation factors in HistFactory. This would be useful for template fits where different histograms represent different values of some parameter, e.g. mass. Currently, it seems that only NormFactors can be reparametrised and the code crashes with a seg fault when trying to reparametrise the shape factors. See the example attached. [shapeFactorCrash.zip](https://github.com/root-project/root/files/10581134/shapeFactorCrash.zip). ### Describe the solution you'd like. We would like to be able to use HistFactory::Measurement::AddPreprocessFunction for shapefactors. ### Describe alternatives you've considered. There is a workaround by doing this reparametrisation manually, but it cumbersome and errorprone. ### Additional context. Note that even if this is not supported, the code should probably not crash with a seg fault (tested with ROOT Version: 6.27/01).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12225
https://github.com/root-project/root/issues/12225:1007,modifiability,Version,Version,1007,"[RF] Allowing to use AddPreprocessFunction for shape factors in HistFactory; We would like to have an option to reparametrise shape-factors, i.e. the per-bin normalisation factors in HistFactory. This would be useful for template fits where different histograms represent different values of some parameter, e.g. mass. Currently, it seems that only NormFactors can be reparametrised and the code crashes with a seg fault when trying to reparametrise the shape factors. See the example attached. [shapeFactorCrash.zip](https://github.com/root-project/root/files/10581134/shapeFactorCrash.zip). ### Describe the solution you'd like. We would like to be able to use HistFactory::Measurement::AddPreprocessFunction for shapefactors. ### Describe alternatives you've considered. There is a workaround by doing this reparametrisation manually, but it cumbersome and errorprone. ### Additional context. Note that even if this is not supported, the code should probably not crash with a seg fault (tested with ROOT Version: 6.27/01).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12225
https://github.com/root-project/root/issues/12225:415,performance,fault,fault,415,"[RF] Allowing to use AddPreprocessFunction for shape factors in HistFactory; We would like to have an option to reparametrise shape-factors, i.e. the per-bin normalisation factors in HistFactory. This would be useful for template fits where different histograms represent different values of some parameter, e.g. mass. Currently, it seems that only NormFactors can be reparametrised and the code crashes with a seg fault when trying to reparametrise the shape factors. See the example attached. [shapeFactorCrash.zip](https://github.com/root-project/root/files/10581134/shapeFactorCrash.zip). ### Describe the solution you'd like. We would like to be able to use HistFactory::Measurement::AddPreprocessFunction for shapefactors. ### Describe alternatives you've considered. There is a workaround by doing this reparametrisation manually, but it cumbersome and errorprone. ### Additional context. Note that even if this is not supported, the code should probably not crash with a seg fault (tested with ROOT Version: 6.27/01).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12225
https://github.com/root-project/root/issues/12225:860,performance,error,errorprone,860,"[RF] Allowing to use AddPreprocessFunction for shape factors in HistFactory; We would like to have an option to reparametrise shape-factors, i.e. the per-bin normalisation factors in HistFactory. This would be useful for template fits where different histograms represent different values of some parameter, e.g. mass. Currently, it seems that only NormFactors can be reparametrised and the code crashes with a seg fault when trying to reparametrise the shape factors. See the example attached. [shapeFactorCrash.zip](https://github.com/root-project/root/files/10581134/shapeFactorCrash.zip). ### Describe the solution you'd like. We would like to be able to use HistFactory::Measurement::AddPreprocessFunction for shapefactors. ### Describe alternatives you've considered. There is a workaround by doing this reparametrisation manually, but it cumbersome and errorprone. ### Additional context. Note that even if this is not supported, the code should probably not crash with a seg fault (tested with ROOT Version: 6.27/01).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12225
https://github.com/root-project/root/issues/12225:983,performance,fault,fault,983,"[RF] Allowing to use AddPreprocessFunction for shape factors in HistFactory; We would like to have an option to reparametrise shape-factors, i.e. the per-bin normalisation factors in HistFactory. This would be useful for template fits where different histograms represent different values of some parameter, e.g. mass. Currently, it seems that only NormFactors can be reparametrised and the code crashes with a seg fault when trying to reparametrise the shape factors. See the example attached. [shapeFactorCrash.zip](https://github.com/root-project/root/files/10581134/shapeFactorCrash.zip). ### Describe the solution you'd like. We would like to be able to use HistFactory::Measurement::AddPreprocessFunction for shapefactors. ### Describe alternatives you've considered. There is a workaround by doing this reparametrisation manually, but it cumbersome and errorprone. ### Additional context. Note that even if this is not supported, the code should probably not crash with a seg fault (tested with ROOT Version: 6.27/01).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12225
https://github.com/root-project/root/issues/12225:415,reliability,fault,fault,415,"[RF] Allowing to use AddPreprocessFunction for shape factors in HistFactory; We would like to have an option to reparametrise shape-factors, i.e. the per-bin normalisation factors in HistFactory. This would be useful for template fits where different histograms represent different values of some parameter, e.g. mass. Currently, it seems that only NormFactors can be reparametrised and the code crashes with a seg fault when trying to reparametrise the shape factors. See the example attached. [shapeFactorCrash.zip](https://github.com/root-project/root/files/10581134/shapeFactorCrash.zip). ### Describe the solution you'd like. We would like to be able to use HistFactory::Measurement::AddPreprocessFunction for shapefactors. ### Describe alternatives you've considered. There is a workaround by doing this reparametrisation manually, but it cumbersome and errorprone. ### Additional context. Note that even if this is not supported, the code should probably not crash with a seg fault (tested with ROOT Version: 6.27/01).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12225
https://github.com/root-project/root/issues/12225:983,reliability,fault,fault,983,"[RF] Allowing to use AddPreprocessFunction for shape factors in HistFactory; We would like to have an option to reparametrise shape-factors, i.e. the per-bin normalisation factors in HistFactory. This would be useful for template fits where different histograms represent different values of some parameter, e.g. mass. Currently, it seems that only NormFactors can be reparametrised and the code crashes with a seg fault when trying to reparametrise the shape factors. See the example attached. [shapeFactorCrash.zip](https://github.com/root-project/root/files/10581134/shapeFactorCrash.zip). ### Describe the solution you'd like. We would like to be able to use HistFactory::Measurement::AddPreprocessFunction for shapefactors. ### Describe alternatives you've considered. There is a workaround by doing this reparametrisation manually, but it cumbersome and errorprone. ### Additional context. Note that even if this is not supported, the code should probably not crash with a seg fault (tested with ROOT Version: 6.27/01).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12225
https://github.com/root-project/root/issues/12225:415,safety,fault,fault,415,"[RF] Allowing to use AddPreprocessFunction for shape factors in HistFactory; We would like to have an option to reparametrise shape-factors, i.e. the per-bin normalisation factors in HistFactory. This would be useful for template fits where different histograms represent different values of some parameter, e.g. mass. Currently, it seems that only NormFactors can be reparametrised and the code crashes with a seg fault when trying to reparametrise the shape factors. See the example attached. [shapeFactorCrash.zip](https://github.com/root-project/root/files/10581134/shapeFactorCrash.zip). ### Describe the solution you'd like. We would like to be able to use HistFactory::Measurement::AddPreprocessFunction for shapefactors. ### Describe alternatives you've considered. There is a workaround by doing this reparametrisation manually, but it cumbersome and errorprone. ### Additional context. Note that even if this is not supported, the code should probably not crash with a seg fault (tested with ROOT Version: 6.27/01).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12225
https://github.com/root-project/root/issues/12225:860,safety,error,errorprone,860,"[RF] Allowing to use AddPreprocessFunction for shape factors in HistFactory; We would like to have an option to reparametrise shape-factors, i.e. the per-bin normalisation factors in HistFactory. This would be useful for template fits where different histograms represent different values of some parameter, e.g. mass. Currently, it seems that only NormFactors can be reparametrised and the code crashes with a seg fault when trying to reparametrise the shape factors. See the example attached. [shapeFactorCrash.zip](https://github.com/root-project/root/files/10581134/shapeFactorCrash.zip). ### Describe the solution you'd like. We would like to be able to use HistFactory::Measurement::AddPreprocessFunction for shapefactors. ### Describe alternatives you've considered. There is a workaround by doing this reparametrisation manually, but it cumbersome and errorprone. ### Additional context. Note that even if this is not supported, the code should probably not crash with a seg fault (tested with ROOT Version: 6.27/01).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12225
https://github.com/root-project/root/issues/12225:983,safety,fault,fault,983,"[RF] Allowing to use AddPreprocessFunction for shape factors in HistFactory; We would like to have an option to reparametrise shape-factors, i.e. the per-bin normalisation factors in HistFactory. This would be useful for template fits where different histograms represent different values of some parameter, e.g. mass. Currently, it seems that only NormFactors can be reparametrised and the code crashes with a seg fault when trying to reparametrise the shape factors. See the example attached. [shapeFactorCrash.zip](https://github.com/root-project/root/files/10581134/shapeFactorCrash.zip). ### Describe the solution you'd like. We would like to be able to use HistFactory::Measurement::AddPreprocessFunction for shapefactors. ### Describe alternatives you've considered. There is a workaround by doing this reparametrisation manually, but it cumbersome and errorprone. ### Additional context. Note that even if this is not supported, the code should probably not crash with a seg fault (tested with ROOT Version: 6.27/01).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12225
https://github.com/root-project/root/issues/12225:990,safety,test,tested,990,"[RF] Allowing to use AddPreprocessFunction for shape factors in HistFactory; We would like to have an option to reparametrise shape-factors, i.e. the per-bin normalisation factors in HistFactory. This would be useful for template fits where different histograms represent different values of some parameter, e.g. mass. Currently, it seems that only NormFactors can be reparametrised and the code crashes with a seg fault when trying to reparametrise the shape factors. See the example attached. [shapeFactorCrash.zip](https://github.com/root-project/root/files/10581134/shapeFactorCrash.zip). ### Describe the solution you'd like. We would like to be able to use HistFactory::Measurement::AddPreprocessFunction for shapefactors. ### Describe alternatives you've considered. There is a workaround by doing this reparametrisation manually, but it cumbersome and errorprone. ### Additional context. Note that even if this is not supported, the code should probably not crash with a seg fault (tested with ROOT Version: 6.27/01).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12225
https://github.com/root-project/root/issues/12225:887,testability,context,context,887,"[RF] Allowing to use AddPreprocessFunction for shape factors in HistFactory; We would like to have an option to reparametrise shape-factors, i.e. the per-bin normalisation factors in HistFactory. This would be useful for template fits where different histograms represent different values of some parameter, e.g. mass. Currently, it seems that only NormFactors can be reparametrised and the code crashes with a seg fault when trying to reparametrise the shape factors. See the example attached. [shapeFactorCrash.zip](https://github.com/root-project/root/files/10581134/shapeFactorCrash.zip). ### Describe the solution you'd like. We would like to be able to use HistFactory::Measurement::AddPreprocessFunction for shapefactors. ### Describe alternatives you've considered. There is a workaround by doing this reparametrisation manually, but it cumbersome and errorprone. ### Additional context. Note that even if this is not supported, the code should probably not crash with a seg fault (tested with ROOT Version: 6.27/01).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12225
https://github.com/root-project/root/issues/12225:990,testability,test,tested,990,"[RF] Allowing to use AddPreprocessFunction for shape factors in HistFactory; We would like to have an option to reparametrise shape-factors, i.e. the per-bin normalisation factors in HistFactory. This would be useful for template fits where different histograms represent different values of some parameter, e.g. mass. Currently, it seems that only NormFactors can be reparametrised and the code crashes with a seg fault when trying to reparametrise the shape factors. See the example attached. [shapeFactorCrash.zip](https://github.com/root-project/root/files/10581134/shapeFactorCrash.zip). ### Describe the solution you'd like. We would like to be able to use HistFactory::Measurement::AddPreprocessFunction for shapefactors. ### Describe alternatives you've considered. There is a workaround by doing this reparametrisation manually, but it cumbersome and errorprone. ### Additional context. Note that even if this is not supported, the code should probably not crash with a seg fault (tested with ROOT Version: 6.27/01).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12225
https://github.com/root-project/root/issues/12225:860,usability,error,errorprone,860,"[RF] Allowing to use AddPreprocessFunction for shape factors in HistFactory; We would like to have an option to reparametrise shape-factors, i.e. the per-bin normalisation factors in HistFactory. This would be useful for template fits where different histograms represent different values of some parameter, e.g. mass. Currently, it seems that only NormFactors can be reparametrised and the code crashes with a seg fault when trying to reparametrise the shape factors. See the example attached. [shapeFactorCrash.zip](https://github.com/root-project/root/files/10581134/shapeFactorCrash.zip). ### Describe the solution you'd like. We would like to be able to use HistFactory::Measurement::AddPreprocessFunction for shapefactors. ### Describe alternatives you've considered. There is a workaround by doing this reparametrisation manually, but it cumbersome and errorprone. ### Additional context. Note that even if this is not supported, the code should probably not crash with a seg fault (tested with ROOT Version: 6.27/01).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12225
https://github.com/root-project/root/issues/12225:926,usability,support,supported,926,"[RF] Allowing to use AddPreprocessFunction for shape factors in HistFactory; We would like to have an option to reparametrise shape-factors, i.e. the per-bin normalisation factors in HistFactory. This would be useful for template fits where different histograms represent different values of some parameter, e.g. mass. Currently, it seems that only NormFactors can be reparametrised and the code crashes with a seg fault when trying to reparametrise the shape factors. See the example attached. [shapeFactorCrash.zip](https://github.com/root-project/root/files/10581134/shapeFactorCrash.zip). ### Describe the solution you'd like. We would like to be able to use HistFactory::Measurement::AddPreprocessFunction for shapefactors. ### Describe alternatives you've considered. There is a workaround by doing this reparametrisation manually, but it cumbersome and errorprone. ### Additional context. Note that even if this is not supported, the code should probably not crash with a seg fault (tested with ROOT Version: 6.27/01).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12225
https://github.com/root-project/root/issues/12226:126,usability,user,users,126,"No doc for `ROOT::RDF::Experimental::FromRNTuple`; IIUC, `ROOT::RDF::Experimental::FromRNTuple` is *the* main entry point for users to use `RNTuple`. https://root.cern.ch/doc/master/namespaceROOT_1_1RDF_1_1Experimental.html#a1307bb3c667a2c5b77b09fb4ef2e161a",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12226
https://github.com/root-project/root/pull/12227:336,availability,sli,slices,336,"[RF] Improve importing other `RooAbsData` when creating a `RooDataSet`; Several improvements to the [`RooDataSet` constructor](https://root.cern.ch/doc/master/classRooDataSet.html#a6a2302f27e1b016a0351f6e0a0329fa2) that takes command arguments to import other data:. 1. Automatically create weight variable when importing multiple data slices (closes #11487). 2. Support importing also RooDataHists (also as slices for combined datasets), and filling the weight errors correctly to match the `weightSquared()`. 3. Create the weight variable on the fly if it was specified by name in `WeightVar()` but is not in the list of variables. 4. Have a default argument for `WeightVar(=""weight"")`, because that's usually the name anyway. 5. Fix `RooVectorDataStore::loadValues()` for loading values from another vector data store: so far it used `assignValueOnly` to copy the values over, but the values might have errors, like for example in the case of importing a RooDataHist. That's why the regular `RooAbsCollection::assign()` is used now. All of these changes result in several code simplifications in the cases where RooDataSets are imported from other data, and fixes the bugs that might have been because the `weightSqaured()` was usually not transferred correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12227
https://github.com/root-project/root/pull/12227:408,availability,sli,slices,408,"[RF] Improve importing other `RooAbsData` when creating a `RooDataSet`; Several improvements to the [`RooDataSet` constructor](https://root.cern.ch/doc/master/classRooDataSet.html#a6a2302f27e1b016a0351f6e0a0329fa2) that takes command arguments to import other data:. 1. Automatically create weight variable when importing multiple data slices (closes #11487). 2. Support importing also RooDataHists (also as slices for combined datasets), and filling the weight errors correctly to match the `weightSquared()`. 3. Create the weight variable on the fly if it was specified by name in `WeightVar()` but is not in the list of variables. 4. Have a default argument for `WeightVar(=""weight"")`, because that's usually the name anyway. 5. Fix `RooVectorDataStore::loadValues()` for loading values from another vector data store: so far it used `assignValueOnly` to copy the values over, but the values might have errors, like for example in the case of importing a RooDataHist. That's why the regular `RooAbsCollection::assign()` is used now. All of these changes result in several code simplifications in the cases where RooDataSets are imported from other data, and fixes the bugs that might have been because the `weightSqaured()` was usually not transferred correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12227
https://github.com/root-project/root/pull/12227:462,availability,error,errors,462,"[RF] Improve importing other `RooAbsData` when creating a `RooDataSet`; Several improvements to the [`RooDataSet` constructor](https://root.cern.ch/doc/master/classRooDataSet.html#a6a2302f27e1b016a0351f6e0a0329fa2) that takes command arguments to import other data:. 1. Automatically create weight variable when importing multiple data slices (closes #11487). 2. Support importing also RooDataHists (also as slices for combined datasets), and filling the weight errors correctly to match the `weightSquared()`. 3. Create the weight variable on the fly if it was specified by name in `WeightVar()` but is not in the list of variables. 4. Have a default argument for `WeightVar(=""weight"")`, because that's usually the name anyway. 5. Fix `RooVectorDataStore::loadValues()` for loading values from another vector data store: so far it used `assignValueOnly` to copy the values over, but the values might have errors, like for example in the case of importing a RooDataHist. That's why the regular `RooAbsCollection::assign()` is used now. All of these changes result in several code simplifications in the cases where RooDataSets are imported from other data, and fixes the bugs that might have been because the `weightSqaured()` was usually not transferred correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12227
https://github.com/root-project/root/pull/12227:906,availability,error,errors,906,"[RF] Improve importing other `RooAbsData` when creating a `RooDataSet`; Several improvements to the [`RooDataSet` constructor](https://root.cern.ch/doc/master/classRooDataSet.html#a6a2302f27e1b016a0351f6e0a0329fa2) that takes command arguments to import other data:. 1. Automatically create weight variable when importing multiple data slices (closes #11487). 2. Support importing also RooDataHists (also as slices for combined datasets), and filling the weight errors correctly to match the `weightSquared()`. 3. Create the weight variable on the fly if it was specified by name in `WeightVar()` but is not in the list of variables. 4. Have a default argument for `WeightVar(=""weight"")`, because that's usually the name anyway. 5. Fix `RooVectorDataStore::loadValues()` for loading values from another vector data store: so far it used `assignValueOnly` to copy the values over, but the values might have errors, like for example in the case of importing a RooDataHist. That's why the regular `RooAbsCollection::assign()` is used now. All of these changes result in several code simplifications in the cases where RooDataSets are imported from other data, and fixes the bugs that might have been because the `weightSqaured()` was usually not transferred correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12227
https://github.com/root-project/root/pull/12227:270,deployability,Automat,Automatically,270,"[RF] Improve importing other `RooAbsData` when creating a `RooDataSet`; Several improvements to the [`RooDataSet` constructor](https://root.cern.ch/doc/master/classRooDataSet.html#a6a2302f27e1b016a0351f6e0a0329fa2) that takes command arguments to import other data:. 1. Automatically create weight variable when importing multiple data slices (closes #11487). 2. Support importing also RooDataHists (also as slices for combined datasets), and filling the weight errors correctly to match the `weightSquared()`. 3. Create the weight variable on the fly if it was specified by name in `WeightVar()` but is not in the list of variables. 4. Have a default argument for `WeightVar(=""weight"")`, because that's usually the name anyway. 5. Fix `RooVectorDataStore::loadValues()` for loading values from another vector data store: so far it used `assignValueOnly` to copy the values over, but the values might have errors, like for example in the case of importing a RooDataHist. That's why the regular `RooAbsCollection::assign()` is used now. All of these changes result in several code simplifications in the cases where RooDataSets are imported from other data, and fixes the bugs that might have been because the `weightSqaured()` was usually not transferred correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12227
https://github.com/root-project/root/pull/12227:757,energy efficiency,load,loadValues,757,"[RF] Improve importing other `RooAbsData` when creating a `RooDataSet`; Several improvements to the [`RooDataSet` constructor](https://root.cern.ch/doc/master/classRooDataSet.html#a6a2302f27e1b016a0351f6e0a0329fa2) that takes command arguments to import other data:. 1. Automatically create weight variable when importing multiple data slices (closes #11487). 2. Support importing also RooDataHists (also as slices for combined datasets), and filling the weight errors correctly to match the `weightSquared()`. 3. Create the weight variable on the fly if it was specified by name in `WeightVar()` but is not in the list of variables. 4. Have a default argument for `WeightVar(=""weight"")`, because that's usually the name anyway. 5. Fix `RooVectorDataStore::loadValues()` for loading values from another vector data store: so far it used `assignValueOnly` to copy the values over, but the values might have errors, like for example in the case of importing a RooDataHist. That's why the regular `RooAbsCollection::assign()` is used now. All of these changes result in several code simplifications in the cases where RooDataSets are imported from other data, and fixes the bugs that might have been because the `weightSqaured()` was usually not transferred correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12227
https://github.com/root-project/root/pull/12227:775,energy efficiency,load,loading,775,"[RF] Improve importing other `RooAbsData` when creating a `RooDataSet`; Several improvements to the [`RooDataSet` constructor](https://root.cern.ch/doc/master/classRooDataSet.html#a6a2302f27e1b016a0351f6e0a0329fa2) that takes command arguments to import other data:. 1. Automatically create weight variable when importing multiple data slices (closes #11487). 2. Support importing also RooDataHists (also as slices for combined datasets), and filling the weight errors correctly to match the `weightSquared()`. 3. Create the weight variable on the fly if it was specified by name in `WeightVar()` but is not in the list of variables. 4. Have a default argument for `WeightVar(=""weight"")`, because that's usually the name anyway. 5. Fix `RooVectorDataStore::loadValues()` for loading values from another vector data store: so far it used `assignValueOnly` to copy the values over, but the values might have errors, like for example in the case of importing a RooDataHist. That's why the regular `RooAbsCollection::assign()` is used now. All of these changes result in several code simplifications in the cases where RooDataSets are imported from other data, and fixes the bugs that might have been because the `weightSqaured()` was usually not transferred correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12227
https://github.com/root-project/root/pull/12227:562,interoperability,specif,specified,562,"[RF] Improve importing other `RooAbsData` when creating a `RooDataSet`; Several improvements to the [`RooDataSet` constructor](https://root.cern.ch/doc/master/classRooDataSet.html#a6a2302f27e1b016a0351f6e0a0329fa2) that takes command arguments to import other data:. 1. Automatically create weight variable when importing multiple data slices (closes #11487). 2. Support importing also RooDataHists (also as slices for combined datasets), and filling the weight errors correctly to match the `weightSquared()`. 3. Create the weight variable on the fly if it was specified by name in `WeightVar()` but is not in the list of variables. 4. Have a default argument for `WeightVar(=""weight"")`, because that's usually the name anyway. 5. Fix `RooVectorDataStore::loadValues()` for loading values from another vector data store: so far it used `assignValueOnly` to copy the values over, but the values might have errors, like for example in the case of importing a RooDataHist. That's why the regular `RooAbsCollection::assign()` is used now. All of these changes result in several code simplifications in the cases where RooDataSets are imported from other data, and fixes the bugs that might have been because the `weightSqaured()` was usually not transferred correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12227
https://github.com/root-project/root/pull/12227:298,modifiability,variab,variable,298,"[RF] Improve importing other `RooAbsData` when creating a `RooDataSet`; Several improvements to the [`RooDataSet` constructor](https://root.cern.ch/doc/master/classRooDataSet.html#a6a2302f27e1b016a0351f6e0a0329fa2) that takes command arguments to import other data:. 1. Automatically create weight variable when importing multiple data slices (closes #11487). 2. Support importing also RooDataHists (also as slices for combined datasets), and filling the weight errors correctly to match the `weightSquared()`. 3. Create the weight variable on the fly if it was specified by name in `WeightVar()` but is not in the list of variables. 4. Have a default argument for `WeightVar(=""weight"")`, because that's usually the name anyway. 5. Fix `RooVectorDataStore::loadValues()` for loading values from another vector data store: so far it used `assignValueOnly` to copy the values over, but the values might have errors, like for example in the case of importing a RooDataHist. That's why the regular `RooAbsCollection::assign()` is used now. All of these changes result in several code simplifications in the cases where RooDataSets are imported from other data, and fixes the bugs that might have been because the `weightSqaured()` was usually not transferred correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12227
https://github.com/root-project/root/pull/12227:532,modifiability,variab,variable,532,"[RF] Improve importing other `RooAbsData` when creating a `RooDataSet`; Several improvements to the [`RooDataSet` constructor](https://root.cern.ch/doc/master/classRooDataSet.html#a6a2302f27e1b016a0351f6e0a0329fa2) that takes command arguments to import other data:. 1. Automatically create weight variable when importing multiple data slices (closes #11487). 2. Support importing also RooDataHists (also as slices for combined datasets), and filling the weight errors correctly to match the `weightSquared()`. 3. Create the weight variable on the fly if it was specified by name in `WeightVar()` but is not in the list of variables. 4. Have a default argument for `WeightVar(=""weight"")`, because that's usually the name anyway. 5. Fix `RooVectorDataStore::loadValues()` for loading values from another vector data store: so far it used `assignValueOnly` to copy the values over, but the values might have errors, like for example in the case of importing a RooDataHist. That's why the regular `RooAbsCollection::assign()` is used now. All of these changes result in several code simplifications in the cases where RooDataSets are imported from other data, and fixes the bugs that might have been because the `weightSqaured()` was usually not transferred correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12227
https://github.com/root-project/root/pull/12227:623,modifiability,variab,variables,623,"[RF] Improve importing other `RooAbsData` when creating a `RooDataSet`; Several improvements to the [`RooDataSet` constructor](https://root.cern.ch/doc/master/classRooDataSet.html#a6a2302f27e1b016a0351f6e0a0329fa2) that takes command arguments to import other data:. 1. Automatically create weight variable when importing multiple data slices (closes #11487). 2. Support importing also RooDataHists (also as slices for combined datasets), and filling the weight errors correctly to match the `weightSquared()`. 3. Create the weight variable on the fly if it was specified by name in `WeightVar()` but is not in the list of variables. 4. Have a default argument for `WeightVar(=""weight"")`, because that's usually the name anyway. 5. Fix `RooVectorDataStore::loadValues()` for loading values from another vector data store: so far it used `assignValueOnly` to copy the values over, but the values might have errors, like for example in the case of importing a RooDataHist. That's why the regular `RooAbsCollection::assign()` is used now. All of these changes result in several code simplifications in the cases where RooDataSets are imported from other data, and fixes the bugs that might have been because the `weightSqaured()` was usually not transferred correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12227
https://github.com/root-project/root/pull/12227:462,performance,error,errors,462,"[RF] Improve importing other `RooAbsData` when creating a `RooDataSet`; Several improvements to the [`RooDataSet` constructor](https://root.cern.ch/doc/master/classRooDataSet.html#a6a2302f27e1b016a0351f6e0a0329fa2) that takes command arguments to import other data:. 1. Automatically create weight variable when importing multiple data slices (closes #11487). 2. Support importing also RooDataHists (also as slices for combined datasets), and filling the weight errors correctly to match the `weightSquared()`. 3. Create the weight variable on the fly if it was specified by name in `WeightVar()` but is not in the list of variables. 4. Have a default argument for `WeightVar(=""weight"")`, because that's usually the name anyway. 5. Fix `RooVectorDataStore::loadValues()` for loading values from another vector data store: so far it used `assignValueOnly` to copy the values over, but the values might have errors, like for example in the case of importing a RooDataHist. That's why the regular `RooAbsCollection::assign()` is used now. All of these changes result in several code simplifications in the cases where RooDataSets are imported from other data, and fixes the bugs that might have been because the `weightSqaured()` was usually not transferred correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12227
https://github.com/root-project/root/pull/12227:757,performance,load,loadValues,757,"[RF] Improve importing other `RooAbsData` when creating a `RooDataSet`; Several improvements to the [`RooDataSet` constructor](https://root.cern.ch/doc/master/classRooDataSet.html#a6a2302f27e1b016a0351f6e0a0329fa2) that takes command arguments to import other data:. 1. Automatically create weight variable when importing multiple data slices (closes #11487). 2. Support importing also RooDataHists (also as slices for combined datasets), and filling the weight errors correctly to match the `weightSquared()`. 3. Create the weight variable on the fly if it was specified by name in `WeightVar()` but is not in the list of variables. 4. Have a default argument for `WeightVar(=""weight"")`, because that's usually the name anyway. 5. Fix `RooVectorDataStore::loadValues()` for loading values from another vector data store: so far it used `assignValueOnly` to copy the values over, but the values might have errors, like for example in the case of importing a RooDataHist. That's why the regular `RooAbsCollection::assign()` is used now. All of these changes result in several code simplifications in the cases where RooDataSets are imported from other data, and fixes the bugs that might have been because the `weightSqaured()` was usually not transferred correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12227
https://github.com/root-project/root/pull/12227:775,performance,load,loading,775,"[RF] Improve importing other `RooAbsData` when creating a `RooDataSet`; Several improvements to the [`RooDataSet` constructor](https://root.cern.ch/doc/master/classRooDataSet.html#a6a2302f27e1b016a0351f6e0a0329fa2) that takes command arguments to import other data:. 1. Automatically create weight variable when importing multiple data slices (closes #11487). 2. Support importing also RooDataHists (also as slices for combined datasets), and filling the weight errors correctly to match the `weightSquared()`. 3. Create the weight variable on the fly if it was specified by name in `WeightVar()` but is not in the list of variables. 4. Have a default argument for `WeightVar(=""weight"")`, because that's usually the name anyway. 5. Fix `RooVectorDataStore::loadValues()` for loading values from another vector data store: so far it used `assignValueOnly` to copy the values over, but the values might have errors, like for example in the case of importing a RooDataHist. That's why the regular `RooAbsCollection::assign()` is used now. All of these changes result in several code simplifications in the cases where RooDataSets are imported from other data, and fixes the bugs that might have been because the `weightSqaured()` was usually not transferred correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12227
https://github.com/root-project/root/pull/12227:906,performance,error,errors,906,"[RF] Improve importing other `RooAbsData` when creating a `RooDataSet`; Several improvements to the [`RooDataSet` constructor](https://root.cern.ch/doc/master/classRooDataSet.html#a6a2302f27e1b016a0351f6e0a0329fa2) that takes command arguments to import other data:. 1. Automatically create weight variable when importing multiple data slices (closes #11487). 2. Support importing also RooDataHists (also as slices for combined datasets), and filling the weight errors correctly to match the `weightSquared()`. 3. Create the weight variable on the fly if it was specified by name in `WeightVar()` but is not in the list of variables. 4. Have a default argument for `WeightVar(=""weight"")`, because that's usually the name anyway. 5. Fix `RooVectorDataStore::loadValues()` for loading values from another vector data store: so far it used `assignValueOnly` to copy the values over, but the values might have errors, like for example in the case of importing a RooDataHist. That's why the regular `RooAbsCollection::assign()` is used now. All of these changes result in several code simplifications in the cases where RooDataSets are imported from other data, and fixes the bugs that might have been because the `weightSqaured()` was usually not transferred correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12227
https://github.com/root-project/root/pull/12227:336,reliability,sli,slices,336,"[RF] Improve importing other `RooAbsData` when creating a `RooDataSet`; Several improvements to the [`RooDataSet` constructor](https://root.cern.ch/doc/master/classRooDataSet.html#a6a2302f27e1b016a0351f6e0a0329fa2) that takes command arguments to import other data:. 1. Automatically create weight variable when importing multiple data slices (closes #11487). 2. Support importing also RooDataHists (also as slices for combined datasets), and filling the weight errors correctly to match the `weightSquared()`. 3. Create the weight variable on the fly if it was specified by name in `WeightVar()` but is not in the list of variables. 4. Have a default argument for `WeightVar(=""weight"")`, because that's usually the name anyway. 5. Fix `RooVectorDataStore::loadValues()` for loading values from another vector data store: so far it used `assignValueOnly` to copy the values over, but the values might have errors, like for example in the case of importing a RooDataHist. That's why the regular `RooAbsCollection::assign()` is used now. All of these changes result in several code simplifications in the cases where RooDataSets are imported from other data, and fixes the bugs that might have been because the `weightSqaured()` was usually not transferred correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12227
https://github.com/root-project/root/pull/12227:408,reliability,sli,slices,408,"[RF] Improve importing other `RooAbsData` when creating a `RooDataSet`; Several improvements to the [`RooDataSet` constructor](https://root.cern.ch/doc/master/classRooDataSet.html#a6a2302f27e1b016a0351f6e0a0329fa2) that takes command arguments to import other data:. 1. Automatically create weight variable when importing multiple data slices (closes #11487). 2. Support importing also RooDataHists (also as slices for combined datasets), and filling the weight errors correctly to match the `weightSquared()`. 3. Create the weight variable on the fly if it was specified by name in `WeightVar()` but is not in the list of variables. 4. Have a default argument for `WeightVar(=""weight"")`, because that's usually the name anyway. 5. Fix `RooVectorDataStore::loadValues()` for loading values from another vector data store: so far it used `assignValueOnly` to copy the values over, but the values might have errors, like for example in the case of importing a RooDataHist. That's why the regular `RooAbsCollection::assign()` is used now. All of these changes result in several code simplifications in the cases where RooDataSets are imported from other data, and fixes the bugs that might have been because the `weightSqaured()` was usually not transferred correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12227
https://github.com/root-project/root/pull/12227:462,safety,error,errors,462,"[RF] Improve importing other `RooAbsData` when creating a `RooDataSet`; Several improvements to the [`RooDataSet` constructor](https://root.cern.ch/doc/master/classRooDataSet.html#a6a2302f27e1b016a0351f6e0a0329fa2) that takes command arguments to import other data:. 1. Automatically create weight variable when importing multiple data slices (closes #11487). 2. Support importing also RooDataHists (also as slices for combined datasets), and filling the weight errors correctly to match the `weightSquared()`. 3. Create the weight variable on the fly if it was specified by name in `WeightVar()` but is not in the list of variables. 4. Have a default argument for `WeightVar(=""weight"")`, because that's usually the name anyway. 5. Fix `RooVectorDataStore::loadValues()` for loading values from another vector data store: so far it used `assignValueOnly` to copy the values over, but the values might have errors, like for example in the case of importing a RooDataHist. That's why the regular `RooAbsCollection::assign()` is used now. All of these changes result in several code simplifications in the cases where RooDataSets are imported from other data, and fixes the bugs that might have been because the `weightSqaured()` was usually not transferred correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12227
https://github.com/root-project/root/pull/12227:906,safety,error,errors,906,"[RF] Improve importing other `RooAbsData` when creating a `RooDataSet`; Several improvements to the [`RooDataSet` constructor](https://root.cern.ch/doc/master/classRooDataSet.html#a6a2302f27e1b016a0351f6e0a0329fa2) that takes command arguments to import other data:. 1. Automatically create weight variable when importing multiple data slices (closes #11487). 2. Support importing also RooDataHists (also as slices for combined datasets), and filling the weight errors correctly to match the `weightSquared()`. 3. Create the weight variable on the fly if it was specified by name in `WeightVar()` but is not in the list of variables. 4. Have a default argument for `WeightVar(=""weight"")`, because that's usually the name anyway. 5. Fix `RooVectorDataStore::loadValues()` for loading values from another vector data store: so far it used `assignValueOnly` to copy the values over, but the values might have errors, like for example in the case of importing a RooDataHist. That's why the regular `RooAbsCollection::assign()` is used now. All of these changes result in several code simplifications in the cases where RooDataSets are imported from other data, and fixes the bugs that might have been because the `weightSqaured()` was usually not transferred correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12227
https://github.com/root-project/root/pull/12227:270,testability,Automat,Automatically,270,"[RF] Improve importing other `RooAbsData` when creating a `RooDataSet`; Several improvements to the [`RooDataSet` constructor](https://root.cern.ch/doc/master/classRooDataSet.html#a6a2302f27e1b016a0351f6e0a0329fa2) that takes command arguments to import other data:. 1. Automatically create weight variable when importing multiple data slices (closes #11487). 2. Support importing also RooDataHists (also as slices for combined datasets), and filling the weight errors correctly to match the `weightSquared()`. 3. Create the weight variable on the fly if it was specified by name in `WeightVar()` but is not in the list of variables. 4. Have a default argument for `WeightVar(=""weight"")`, because that's usually the name anyway. 5. Fix `RooVectorDataStore::loadValues()` for loading values from another vector data store: so far it used `assignValueOnly` to copy the values over, but the values might have errors, like for example in the case of importing a RooDataHist. That's why the regular `RooAbsCollection::assign()` is used now. All of these changes result in several code simplifications in the cases where RooDataSets are imported from other data, and fixes the bugs that might have been because the `weightSqaured()` was usually not transferred correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12227
https://github.com/root-project/root/pull/12227:1080,testability,simpl,simplifications,1080,"[RF] Improve importing other `RooAbsData` when creating a `RooDataSet`; Several improvements to the [`RooDataSet` constructor](https://root.cern.ch/doc/master/classRooDataSet.html#a6a2302f27e1b016a0351f6e0a0329fa2) that takes command arguments to import other data:. 1. Automatically create weight variable when importing multiple data slices (closes #11487). 2. Support importing also RooDataHists (also as slices for combined datasets), and filling the weight errors correctly to match the `weightSquared()`. 3. Create the weight variable on the fly if it was specified by name in `WeightVar()` but is not in the list of variables. 4. Have a default argument for `WeightVar(=""weight"")`, because that's usually the name anyway. 5. Fix `RooVectorDataStore::loadValues()` for loading values from another vector data store: so far it used `assignValueOnly` to copy the values over, but the values might have errors, like for example in the case of importing a RooDataHist. That's why the regular `RooAbsCollection::assign()` is used now. All of these changes result in several code simplifications in the cases where RooDataSets are imported from other data, and fixes the bugs that might have been because the `weightSqaured()` was usually not transferred correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12227
https://github.com/root-project/root/pull/12227:226,usability,command,command,226,"[RF] Improve importing other `RooAbsData` when creating a `RooDataSet`; Several improvements to the [`RooDataSet` constructor](https://root.cern.ch/doc/master/classRooDataSet.html#a6a2302f27e1b016a0351f6e0a0329fa2) that takes command arguments to import other data:. 1. Automatically create weight variable when importing multiple data slices (closes #11487). 2. Support importing also RooDataHists (also as slices for combined datasets), and filling the weight errors correctly to match the `weightSquared()`. 3. Create the weight variable on the fly if it was specified by name in `WeightVar()` but is not in the list of variables. 4. Have a default argument for `WeightVar(=""weight"")`, because that's usually the name anyway. 5. Fix `RooVectorDataStore::loadValues()` for loading values from another vector data store: so far it used `assignValueOnly` to copy the values over, but the values might have errors, like for example in the case of importing a RooDataHist. That's why the regular `RooAbsCollection::assign()` is used now. All of these changes result in several code simplifications in the cases where RooDataSets are imported from other data, and fixes the bugs that might have been because the `weightSqaured()` was usually not transferred correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12227
https://github.com/root-project/root/pull/12227:344,usability,close,closes,344,"[RF] Improve importing other `RooAbsData` when creating a `RooDataSet`; Several improvements to the [`RooDataSet` constructor](https://root.cern.ch/doc/master/classRooDataSet.html#a6a2302f27e1b016a0351f6e0a0329fa2) that takes command arguments to import other data:. 1. Automatically create weight variable when importing multiple data slices (closes #11487). 2. Support importing also RooDataHists (also as slices for combined datasets), and filling the weight errors correctly to match the `weightSquared()`. 3. Create the weight variable on the fly if it was specified by name in `WeightVar()` but is not in the list of variables. 4. Have a default argument for `WeightVar(=""weight"")`, because that's usually the name anyway. 5. Fix `RooVectorDataStore::loadValues()` for loading values from another vector data store: so far it used `assignValueOnly` to copy the values over, but the values might have errors, like for example in the case of importing a RooDataHist. That's why the regular `RooAbsCollection::assign()` is used now. All of these changes result in several code simplifications in the cases where RooDataSets are imported from other data, and fixes the bugs that might have been because the `weightSqaured()` was usually not transferred correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12227
https://github.com/root-project/root/pull/12227:363,usability,Support,Support,363,"[RF] Improve importing other `RooAbsData` when creating a `RooDataSet`; Several improvements to the [`RooDataSet` constructor](https://root.cern.ch/doc/master/classRooDataSet.html#a6a2302f27e1b016a0351f6e0a0329fa2) that takes command arguments to import other data:. 1. Automatically create weight variable when importing multiple data slices (closes #11487). 2. Support importing also RooDataHists (also as slices for combined datasets), and filling the weight errors correctly to match the `weightSquared()`. 3. Create the weight variable on the fly if it was specified by name in `WeightVar()` but is not in the list of variables. 4. Have a default argument for `WeightVar(=""weight"")`, because that's usually the name anyway. 5. Fix `RooVectorDataStore::loadValues()` for loading values from another vector data store: so far it used `assignValueOnly` to copy the values over, but the values might have errors, like for example in the case of importing a RooDataHist. That's why the regular `RooAbsCollection::assign()` is used now. All of these changes result in several code simplifications in the cases where RooDataSets are imported from other data, and fixes the bugs that might have been because the `weightSqaured()` was usually not transferred correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12227
https://github.com/root-project/root/pull/12227:462,usability,error,errors,462,"[RF] Improve importing other `RooAbsData` when creating a `RooDataSet`; Several improvements to the [`RooDataSet` constructor](https://root.cern.ch/doc/master/classRooDataSet.html#a6a2302f27e1b016a0351f6e0a0329fa2) that takes command arguments to import other data:. 1. Automatically create weight variable when importing multiple data slices (closes #11487). 2. Support importing also RooDataHists (also as slices for combined datasets), and filling the weight errors correctly to match the `weightSquared()`. 3. Create the weight variable on the fly if it was specified by name in `WeightVar()` but is not in the list of variables. 4. Have a default argument for `WeightVar(=""weight"")`, because that's usually the name anyway. 5. Fix `RooVectorDataStore::loadValues()` for loading values from another vector data store: so far it used `assignValueOnly` to copy the values over, but the values might have errors, like for example in the case of importing a RooDataHist. That's why the regular `RooAbsCollection::assign()` is used now. All of these changes result in several code simplifications in the cases where RooDataSets are imported from other data, and fixes the bugs that might have been because the `weightSqaured()` was usually not transferred correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12227
https://github.com/root-project/root/pull/12227:906,usability,error,errors,906,"[RF] Improve importing other `RooAbsData` when creating a `RooDataSet`; Several improvements to the [`RooDataSet` constructor](https://root.cern.ch/doc/master/classRooDataSet.html#a6a2302f27e1b016a0351f6e0a0329fa2) that takes command arguments to import other data:. 1. Automatically create weight variable when importing multiple data slices (closes #11487). 2. Support importing also RooDataHists (also as slices for combined datasets), and filling the weight errors correctly to match the `weightSquared()`. 3. Create the weight variable on the fly if it was specified by name in `WeightVar()` but is not in the list of variables. 4. Have a default argument for `WeightVar(=""weight"")`, because that's usually the name anyway. 5. Fix `RooVectorDataStore::loadValues()` for loading values from another vector data store: so far it used `assignValueOnly` to copy the values over, but the values might have errors, like for example in the case of importing a RooDataHist. That's why the regular `RooAbsCollection::assign()` is used now. All of these changes result in several code simplifications in the cases where RooDataSets are imported from other data, and fixes the bugs that might have been because the `weightSqaured()` was usually not transferred correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12227
https://github.com/root-project/root/pull/12227:1080,usability,simpl,simplifications,1080,"[RF] Improve importing other `RooAbsData` when creating a `RooDataSet`; Several improvements to the [`RooDataSet` constructor](https://root.cern.ch/doc/master/classRooDataSet.html#a6a2302f27e1b016a0351f6e0a0329fa2) that takes command arguments to import other data:. 1. Automatically create weight variable when importing multiple data slices (closes #11487). 2. Support importing also RooDataHists (also as slices for combined datasets), and filling the weight errors correctly to match the `weightSquared()`. 3. Create the weight variable on the fly if it was specified by name in `WeightVar()` but is not in the list of variables. 4. Have a default argument for `WeightVar(=""weight"")`, because that's usually the name anyway. 5. Fix `RooVectorDataStore::loadValues()` for loading values from another vector data store: so far it used `assignValueOnly` to copy the values over, but the values might have errors, like for example in the case of importing a RooDataHist. That's why the regular `RooAbsCollection::assign()` is used now. All of these changes result in several code simplifications in the cases where RooDataSets are imported from other data, and fixes the bugs that might have been because the `weightSqaured()` was usually not transferred correctly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12227
https://github.com/root-project/root/issues/12230:201,availability,error,error,201,"Wrong conversion from Numpy Array to `std.vector` when using the wrong type; In PyROOT it is possible to convert a Numa array in a std.vector. However when the types are different instead of having an error, a wrong conversion happens. . Here is an example:. ```python. import ROOT. import numpy as np. x = np.array([1., 2., 3.]). v = ROOT.std.vector('float')(x). print(v). ```. The obtained result is . ```. { 0.00000f, 1.87500f, 0.00000f }. ```. without getting any error. . Instead if I use the correct type:. ```. x = np.array([1.,2.,3.], dtype='float32'). v = ROOT.std.vector('float')(x). print(v). ```. I obtain the correct result. . This can cause give wrong results when calling from Python C++ functions taking std::vector as argument and the wrong type of Numpy array is passed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12230
https://github.com/root-project/root/issues/12230:468,availability,error,error,468,"Wrong conversion from Numpy Array to `std.vector` when using the wrong type; In PyROOT it is possible to convert a Numa array in a std.vector. However when the types are different instead of having an error, a wrong conversion happens. . Here is an example:. ```python. import ROOT. import numpy as np. x = np.array([1., 2., 3.]). v = ROOT.std.vector('float')(x). print(v). ```. The obtained result is . ```. { 0.00000f, 1.87500f, 0.00000f }. ```. without getting any error. . Instead if I use the correct type:. ```. x = np.array([1.,2.,3.], dtype='float32'). v = ROOT.std.vector('float')(x). print(v). ```. I obtain the correct result. . This can cause give wrong results when calling from Python C++ functions taking std::vector as argument and the wrong type of Numpy array is passed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12230
https://github.com/root-project/root/issues/12230:6,interoperability,convers,conversion,6,"Wrong conversion from Numpy Array to `std.vector` when using the wrong type; In PyROOT it is possible to convert a Numa array in a std.vector. However when the types are different instead of having an error, a wrong conversion happens. . Here is an example:. ```python. import ROOT. import numpy as np. x = np.array([1., 2., 3.]). v = ROOT.std.vector('float')(x). print(v). ```. The obtained result is . ```. { 0.00000f, 1.87500f, 0.00000f }. ```. without getting any error. . Instead if I use the correct type:. ```. x = np.array([1.,2.,3.], dtype='float32'). v = ROOT.std.vector('float')(x). print(v). ```. I obtain the correct result. . This can cause give wrong results when calling from Python C++ functions taking std::vector as argument and the wrong type of Numpy array is passed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12230
https://github.com/root-project/root/issues/12230:216,interoperability,convers,conversion,216,"Wrong conversion from Numpy Array to `std.vector` when using the wrong type; In PyROOT it is possible to convert a Numa array in a std.vector. However when the types are different instead of having an error, a wrong conversion happens. . Here is an example:. ```python. import ROOT. import numpy as np. x = np.array([1., 2., 3.]). v = ROOT.std.vector('float')(x). print(v). ```. The obtained result is . ```. { 0.00000f, 1.87500f, 0.00000f }. ```. without getting any error. . Instead if I use the correct type:. ```. x = np.array([1.,2.,3.], dtype='float32'). v = ROOT.std.vector('float')(x). print(v). ```. I obtain the correct result. . This can cause give wrong results when calling from Python C++ functions taking std::vector as argument and the wrong type of Numpy array is passed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12230
https://github.com/root-project/root/issues/12230:201,performance,error,error,201,"Wrong conversion from Numpy Array to `std.vector` when using the wrong type; In PyROOT it is possible to convert a Numa array in a std.vector. However when the types are different instead of having an error, a wrong conversion happens. . Here is an example:. ```python. import ROOT. import numpy as np. x = np.array([1., 2., 3.]). v = ROOT.std.vector('float')(x). print(v). ```. The obtained result is . ```. { 0.00000f, 1.87500f, 0.00000f }. ```. without getting any error. . Instead if I use the correct type:. ```. x = np.array([1.,2.,3.], dtype='float32'). v = ROOT.std.vector('float')(x). print(v). ```. I obtain the correct result. . This can cause give wrong results when calling from Python C++ functions taking std::vector as argument and the wrong type of Numpy array is passed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12230
https://github.com/root-project/root/issues/12230:468,performance,error,error,468,"Wrong conversion from Numpy Array to `std.vector` when using the wrong type; In PyROOT it is possible to convert a Numa array in a std.vector. However when the types are different instead of having an error, a wrong conversion happens. . Here is an example:. ```python. import ROOT. import numpy as np. x = np.array([1., 2., 3.]). v = ROOT.std.vector('float')(x). print(v). ```. The obtained result is . ```. { 0.00000f, 1.87500f, 0.00000f }. ```. without getting any error. . Instead if I use the correct type:. ```. x = np.array([1.,2.,3.], dtype='float32'). v = ROOT.std.vector('float')(x). print(v). ```. I obtain the correct result. . This can cause give wrong results when calling from Python C++ functions taking std::vector as argument and the wrong type of Numpy array is passed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12230
https://github.com/root-project/root/issues/12230:201,safety,error,error,201,"Wrong conversion from Numpy Array to `std.vector` when using the wrong type; In PyROOT it is possible to convert a Numa array in a std.vector. However when the types are different instead of having an error, a wrong conversion happens. . Here is an example:. ```python. import ROOT. import numpy as np. x = np.array([1., 2., 3.]). v = ROOT.std.vector('float')(x). print(v). ```. The obtained result is . ```. { 0.00000f, 1.87500f, 0.00000f }. ```. without getting any error. . Instead if I use the correct type:. ```. x = np.array([1.,2.,3.], dtype='float32'). v = ROOT.std.vector('float')(x). print(v). ```. I obtain the correct result. . This can cause give wrong results when calling from Python C++ functions taking std::vector as argument and the wrong type of Numpy array is passed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12230
https://github.com/root-project/root/issues/12230:468,safety,error,error,468,"Wrong conversion from Numpy Array to `std.vector` when using the wrong type; In PyROOT it is possible to convert a Numa array in a std.vector. However when the types are different instead of having an error, a wrong conversion happens. . Here is an example:. ```python. import ROOT. import numpy as np. x = np.array([1., 2., 3.]). v = ROOT.std.vector('float')(x). print(v). ```. The obtained result is . ```. { 0.00000f, 1.87500f, 0.00000f }. ```. without getting any error. . Instead if I use the correct type:. ```. x = np.array([1.,2.,3.], dtype='float32'). v = ROOT.std.vector('float')(x). print(v). ```. I obtain the correct result. . This can cause give wrong results when calling from Python C++ functions taking std::vector as argument and the wrong type of Numpy array is passed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12230
https://github.com/root-project/root/issues/12230:201,usability,error,error,201,"Wrong conversion from Numpy Array to `std.vector` when using the wrong type; In PyROOT it is possible to convert a Numa array in a std.vector. However when the types are different instead of having an error, a wrong conversion happens. . Here is an example:. ```python. import ROOT. import numpy as np. x = np.array([1., 2., 3.]). v = ROOT.std.vector('float')(x). print(v). ```. The obtained result is . ```. { 0.00000f, 1.87500f, 0.00000f }. ```. without getting any error. . Instead if I use the correct type:. ```. x = np.array([1.,2.,3.], dtype='float32'). v = ROOT.std.vector('float')(x). print(v). ```. I obtain the correct result. . This can cause give wrong results when calling from Python C++ functions taking std::vector as argument and the wrong type of Numpy array is passed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12230
https://github.com/root-project/root/issues/12230:468,usability,error,error,468,"Wrong conversion from Numpy Array to `std.vector` when using the wrong type; In PyROOT it is possible to convert a Numa array in a std.vector. However when the types are different instead of having an error, a wrong conversion happens. . Here is an example:. ```python. import ROOT. import numpy as np. x = np.array([1., 2., 3.]). v = ROOT.std.vector('float')(x). print(v). ```. The obtained result is . ```. { 0.00000f, 1.87500f, 0.00000f }. ```. without getting any error. . Instead if I use the correct type:. ```. x = np.array([1.,2.,3.], dtype='float32'). v = ROOT.std.vector('float')(x). print(v). ```. I obtain the correct result. . This can cause give wrong results when calling from Python C++ functions taking std::vector as argument and the wrong type of Numpy array is passed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12230
https://github.com/root-project/root/issues/12231:141,deployability,updat,update,141,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:160,deployability,upgrad,upgrade,160,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:173,deployability,instal,install,173,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:226,deployability,build,build,226,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:284,deployability,build,build,284,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:335,deployability,Releas,Release,335,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:1345,deployability,instal,installing,1345,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:1539,deployability,log,log,1539,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:272,integrability,configur,configure,272,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:883,integrability,protocol,protocol,883,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:1236,integrability,protocol,protocol,1236,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:1641,integrability,protocol,protocol,1641,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:883,interoperability,protocol,protocol,883,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:1236,interoperability,protocol,protocol,1236,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:1641,interoperability,protocol,protocol,1641,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:160,modifiability,upgrad,upgrade,160,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:272,modifiability,configur,configure,272,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:1376,modifiability,pac,package,1376,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:949,performance,cach,cache,949,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:141,safety,updat,update,141,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:1539,safety,log,log,1539,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:137,security,apt,apt,137,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:141,security,updat,update,141,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:151,security,apt,apt,151,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:169,security,apt,apt,169,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:272,security,configur,configure,272,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:624,security,authenticat,authentication,624,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:743,security,authenticat,authenticate,743,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:1097,security,authenticat,authenticate,1097,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:1307,security,certif,certificate,1307,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:1539,security,log,log,1539,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:1582,security,authenticat,authenticate,1582,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:1664,security,sign,signaled,1664,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:1293,testability,verif,verify,1293,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/issues/12231:1539,testability,log,log,1539,"Hang with XRootD from eospublic on Debian Unstable; Starting from the `debian:sid` Docker image, create the following environment:. ```. apt update && apt dist-upgrade. apt install cmake gcc g++ git libxrootd-client-dev ninja-build python3. ```. Then clone `root.git` and configure + build with. ```. cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -Dx11=OFF ../root/. ninja. ```. Afterwards try executing `./bin/root.exe tutorials/dataframe/df103_NanoAODHiggsAnalysis.C`. It will hang and setting `XRD_LOGLEVEL=Debug` reveals:. ```. [2023-02-06 12:00:28.136048 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Sending authentication data. [2023-02-06 12:00:28.137346 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using krb5. [2023-02-06 12:00:28.137406 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol krb5: Seckrb5: No or invalid credentials; No credentials cache found (p=xrootd/eospublic.cern.ch@CERN.CH). [2023-02-06 12:00:28.137968 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Trying to authenticate using gsi. [2023-02-06 12:00:32.761097 +0000][Debug ][XRootDTransport ] [eospublic.cern.ch:1094.0] Cannot get credentials for protocol gsi: Secgsi: ErrParseBuffer: unknown CA: cannot verify server certificate: kXGS_init. ```. Instead, installing the `xrootd-client` package and running. ```. xrdcp root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod_skimmed/SMHiggsToZZTo4L.root . ```. works just fine - the `Debug` log shows that it proceeds with `Trying to authenticate using uni` (after `Cannot get credentials for protocol gsi` was also signaled kind of immediately).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12231
https://github.com/root-project/root/pull/12232:57,safety,test,test,57,[RF] Support RooPolynomial in RooFit JSON IO and improve test suite; Title says it all.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12232
https://github.com/root-project/root/pull/12232:57,testability,test,test,57,[RF] Support RooPolynomial in RooFit JSON IO and improve test suite; Title says it all.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12232
https://github.com/root-project/root/pull/12232:5,usability,Support,Support,5,[RF] Support RooPolynomial in RooFit JSON IO and improve test suite; Title says it all.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12232
https://github.com/root-project/root/pull/12233:53,deployability,observ,observables,53,"[RF] Iron out inconsistencies in treatment of global observables; Iron out some inconsistencies in the treatment of global observables with the new CPU evaluation backend. To check that everything works now, all the tests in `testGlobalObservables` are now done with both the old legacy backend and the new CPU evaluation backend. More detail in the commit descriptions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12233
https://github.com/root-project/root/pull/12233:123,deployability,observ,observables,123,"[RF] Iron out inconsistencies in treatment of global observables; Iron out some inconsistencies in the treatment of global observables with the new CPU evaluation backend. To check that everything works now, all the tests in `testGlobalObservables` are now done with both the old legacy backend and the new CPU evaluation backend. More detail in the commit descriptions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12233
https://github.com/root-project/root/pull/12233:148,energy efficiency,CPU,CPU,148,"[RF] Iron out inconsistencies in treatment of global observables; Iron out some inconsistencies in the treatment of global observables with the new CPU evaluation backend. To check that everything works now, all the tests in `testGlobalObservables` are now done with both the old legacy backend and the new CPU evaluation backend. More detail in the commit descriptions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12233
https://github.com/root-project/root/pull/12233:307,energy efficiency,CPU,CPU,307,"[RF] Iron out inconsistencies in treatment of global observables; Iron out some inconsistencies in the treatment of global observables with the new CPU evaluation backend. To check that everything works now, all the tests in `testGlobalObservables` are now done with both the old legacy backend and the new CPU evaluation backend. More detail in the commit descriptions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12233
https://github.com/root-project/root/pull/12233:148,performance,CPU,CPU,148,"[RF] Iron out inconsistencies in treatment of global observables; Iron out some inconsistencies in the treatment of global observables with the new CPU evaluation backend. To check that everything works now, all the tests in `testGlobalObservables` are now done with both the old legacy backend and the new CPU evaluation backend. More detail in the commit descriptions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12233
https://github.com/root-project/root/pull/12233:307,performance,CPU,CPU,307,"[RF] Iron out inconsistencies in treatment of global observables; Iron out some inconsistencies in the treatment of global observables with the new CPU evaluation backend. To check that everything works now, all the tests in `testGlobalObservables` are now done with both the old legacy backend and the new CPU evaluation backend. More detail in the commit descriptions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12233
https://github.com/root-project/root/pull/12233:216,safety,test,tests,216,"[RF] Iron out inconsistencies in treatment of global observables; Iron out some inconsistencies in the treatment of global observables with the new CPU evaluation backend. To check that everything works now, all the tests in `testGlobalObservables` are now done with both the old legacy backend and the new CPU evaluation backend. More detail in the commit descriptions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12233
https://github.com/root-project/root/pull/12233:226,safety,test,testGlobalObservables,226,"[RF] Iron out inconsistencies in treatment of global observables; Iron out some inconsistencies in the treatment of global observables with the new CPU evaluation backend. To check that everything works now, all the tests in `testGlobalObservables` are now done with both the old legacy backend and the new CPU evaluation backend. More detail in the commit descriptions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12233
https://github.com/root-project/root/pull/12233:53,testability,observ,observables,53,"[RF] Iron out inconsistencies in treatment of global observables; Iron out some inconsistencies in the treatment of global observables with the new CPU evaluation backend. To check that everything works now, all the tests in `testGlobalObservables` are now done with both the old legacy backend and the new CPU evaluation backend. More detail in the commit descriptions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12233
https://github.com/root-project/root/pull/12233:123,testability,observ,observables,123,"[RF] Iron out inconsistencies in treatment of global observables; Iron out some inconsistencies in the treatment of global observables with the new CPU evaluation backend. To check that everything works now, all the tests in `testGlobalObservables` are now done with both the old legacy backend and the new CPU evaluation backend. More detail in the commit descriptions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12233
https://github.com/root-project/root/pull/12233:216,testability,test,tests,216,"[RF] Iron out inconsistencies in treatment of global observables; Iron out some inconsistencies in the treatment of global observables with the new CPU evaluation backend. To check that everything works now, all the tests in `testGlobalObservables` are now done with both the old legacy backend and the new CPU evaluation backend. More detail in the commit descriptions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12233
https://github.com/root-project/root/pull/12233:226,testability,test,testGlobalObservables,226,"[RF] Iron out inconsistencies in treatment of global observables; Iron out some inconsistencies in the treatment of global observables with the new CPU evaluation backend. To check that everything works now, all the tests in `testGlobalObservables` are now done with both the old legacy backend and the new CPU evaluation backend. More detail in the commit descriptions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12233
https://github.com/root-project/root/issues/12234:1307,availability,Operat,Operating,1307,"Numba issues with RVecs; ### Describe the bug. When using RVecs (namely RvecF) with Numba in PyRoot the exception ""Failed to extract template argument of type RVecF"" raises. Changing RVecF to RVec\<float\> fixes the issue. Numba functions also don't seem to allow defining RVecs inside them, giving . ```. TypingError: Failed in nopython mode pipeline (step: nopython frontend). Unknown attribute 'RVec' of type Module(<module 'ROOT' from '/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py'>). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. During: typing of get attribute at /tmp/ipykernel_594/4272152336.py (3). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. ```. when defining a function such as. ```. @ROOT.Numba.Declare(['RVec<float>', 'int'], 'RVec<float>'). def pypowarray(x, y):. v = ROOT.RVec['float'](). return x**y. ```. ### To Reproduce. The PyRoot tutorial pyroot004_NumbaDeclare.py (https://root.cern.ch/doc/master/pyroot004__NumbaDeclare_8py.html) directly reproduces the issue with RVecF. Modifying the code where pypowarray is defined to match the code above reproduces the issue with defintions. ### Setup. 1. ROOT Version: 6.26/08. 2. Operating system: CentOS 7. 3. I used SWAN notebooks with LCG 102b. The notebook was created directly from the ""Open in SWAN"" button in the tutorial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12234
https://github.com/root-project/root/issues/12234:115,deployability,Fail,Failed,115,"Numba issues with RVecs; ### Describe the bug. When using RVecs (namely RvecF) with Numba in PyRoot the exception ""Failed to extract template argument of type RVecF"" raises. Changing RVecF to RVec\<float\> fixes the issue. Numba functions also don't seem to allow defining RVecs inside them, giving . ```. TypingError: Failed in nopython mode pipeline (step: nopython frontend). Unknown attribute 'RVec' of type Module(<module 'ROOT' from '/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py'>). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. During: typing of get attribute at /tmp/ipykernel_594/4272152336.py (3). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. ```. when defining a function such as. ```. @ROOT.Numba.Declare(['RVec<float>', 'int'], 'RVec<float>'). def pypowarray(x, y):. v = ROOT.RVec['float'](). return x**y. ```. ### To Reproduce. The PyRoot tutorial pyroot004_NumbaDeclare.py (https://root.cern.ch/doc/master/pyroot004__NumbaDeclare_8py.html) directly reproduces the issue with RVecF. Modifying the code where pypowarray is defined to match the code above reproduces the issue with defintions. ### Setup. 1. ROOT Version: 6.26/08. 2. Operating system: CentOS 7. 3. I used SWAN notebooks with LCG 102b. The notebook was created directly from the ""Open in SWAN"" button in the tutorial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12234
https://github.com/root-project/root/issues/12234:319,deployability,Fail,Failed,319,"Numba issues with RVecs; ### Describe the bug. When using RVecs (namely RvecF) with Numba in PyRoot the exception ""Failed to extract template argument of type RVecF"" raises. Changing RVecF to RVec\<float\> fixes the issue. Numba functions also don't seem to allow defining RVecs inside them, giving . ```. TypingError: Failed in nopython mode pipeline (step: nopython frontend). Unknown attribute 'RVec' of type Module(<module 'ROOT' from '/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py'>). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. During: typing of get attribute at /tmp/ipykernel_594/4272152336.py (3). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. ```. when defining a function such as. ```. @ROOT.Numba.Declare(['RVec<float>', 'int'], 'RVec<float>'). def pypowarray(x, y):. v = ROOT.RVec['float'](). return x**y. ```. ### To Reproduce. The PyRoot tutorial pyroot004_NumbaDeclare.py (https://root.cern.ch/doc/master/pyroot004__NumbaDeclare_8py.html) directly reproduces the issue with RVecF. Modifying the code where pypowarray is defined to match the code above reproduces the issue with defintions. ### Setup. 1. ROOT Version: 6.26/08. 2. Operating system: CentOS 7. 3. I used SWAN notebooks with LCG 102b. The notebook was created directly from the ""Open in SWAN"" button in the tutorial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12234
https://github.com/root-project/root/issues/12234:343,deployability,pipelin,pipeline,343,"Numba issues with RVecs; ### Describe the bug. When using RVecs (namely RvecF) with Numba in PyRoot the exception ""Failed to extract template argument of type RVecF"" raises. Changing RVecF to RVec\<float\> fixes the issue. Numba functions also don't seem to allow defining RVecs inside them, giving . ```. TypingError: Failed in nopython mode pipeline (step: nopython frontend). Unknown attribute 'RVec' of type Module(<module 'ROOT' from '/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py'>). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. During: typing of get attribute at /tmp/ipykernel_594/4272152336.py (3). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. ```. when defining a function such as. ```. @ROOT.Numba.Declare(['RVec<float>', 'int'], 'RVec<float>'). def pypowarray(x, y):. v = ROOT.RVec['float'](). return x**y. ```. ### To Reproduce. The PyRoot tutorial pyroot004_NumbaDeclare.py (https://root.cern.ch/doc/master/pyroot004__NumbaDeclare_8py.html) directly reproduces the issue with RVecF. Modifying the code where pypowarray is defined to match the code above reproduces the issue with defintions. ### Setup. 1. ROOT Version: 6.26/08. 2. Operating system: CentOS 7. 3. I used SWAN notebooks with LCG 102b. The notebook was created directly from the ""Open in SWAN"" button in the tutorial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12234
https://github.com/root-project/root/issues/12234:412,deployability,Modul,Module,412,"Numba issues with RVecs; ### Describe the bug. When using RVecs (namely RvecF) with Numba in PyRoot the exception ""Failed to extract template argument of type RVecF"" raises. Changing RVecF to RVec\<float\> fixes the issue. Numba functions also don't seem to allow defining RVecs inside them, giving . ```. TypingError: Failed in nopython mode pipeline (step: nopython frontend). Unknown attribute 'RVec' of type Module(<module 'ROOT' from '/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py'>). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. During: typing of get attribute at /tmp/ipykernel_594/4272152336.py (3). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. ```. when defining a function such as. ```. @ROOT.Numba.Declare(['RVec<float>', 'int'], 'RVec<float>'). def pypowarray(x, y):. v = ROOT.RVec['float'](). return x**y. ```. ### To Reproduce. The PyRoot tutorial pyroot004_NumbaDeclare.py (https://root.cern.ch/doc/master/pyroot004__NumbaDeclare_8py.html) directly reproduces the issue with RVecF. Modifying the code where pypowarray is defined to match the code above reproduces the issue with defintions. ### Setup. 1. ROOT Version: 6.26/08. 2. Operating system: CentOS 7. 3. I used SWAN notebooks with LCG 102b. The notebook was created directly from the ""Open in SWAN"" button in the tutorial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12234
https://github.com/root-project/root/issues/12234:420,deployability,modul,module,420,"Numba issues with RVecs; ### Describe the bug. When using RVecs (namely RvecF) with Numba in PyRoot the exception ""Failed to extract template argument of type RVecF"" raises. Changing RVecF to RVec\<float\> fixes the issue. Numba functions also don't seem to allow defining RVecs inside them, giving . ```. TypingError: Failed in nopython mode pipeline (step: nopython frontend). Unknown attribute 'RVec' of type Module(<module 'ROOT' from '/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py'>). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. During: typing of get attribute at /tmp/ipykernel_594/4272152336.py (3). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. ```. when defining a function such as. ```. @ROOT.Numba.Declare(['RVec<float>', 'int'], 'RVec<float>'). def pypowarray(x, y):. v = ROOT.RVec['float'](). return x**y. ```. ### To Reproduce. The PyRoot tutorial pyroot004_NumbaDeclare.py (https://root.cern.ch/doc/master/pyroot004__NumbaDeclare_8py.html) directly reproduces the issue with RVecF. Modifying the code where pypowarray is defined to match the code above reproduces the issue with defintions. ### Setup. 1. ROOT Version: 6.26/08. 2. Operating system: CentOS 7. 3. I used SWAN notebooks with LCG 102b. The notebook was created directly from the ""Open in SWAN"" button in the tutorial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12234
https://github.com/root-project/root/issues/12234:1286,deployability,Version,Version,1286,"Numba issues with RVecs; ### Describe the bug. When using RVecs (namely RvecF) with Numba in PyRoot the exception ""Failed to extract template argument of type RVecF"" raises. Changing RVecF to RVec\<float\> fixes the issue. Numba functions also don't seem to allow defining RVecs inside them, giving . ```. TypingError: Failed in nopython mode pipeline (step: nopython frontend). Unknown attribute 'RVec' of type Module(<module 'ROOT' from '/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py'>). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. During: typing of get attribute at /tmp/ipykernel_594/4272152336.py (3). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. ```. when defining a function such as. ```. @ROOT.Numba.Declare(['RVec<float>', 'int'], 'RVec<float>'). def pypowarray(x, y):. v = ROOT.RVec['float'](). return x**y. ```. ### To Reproduce. The PyRoot tutorial pyroot004_NumbaDeclare.py (https://root.cern.ch/doc/master/pyroot004__NumbaDeclare_8py.html) directly reproduces the issue with RVecF. Modifying the code where pypowarray is defined to match the code above reproduces the issue with defintions. ### Setup. 1. ROOT Version: 6.26/08. 2. Operating system: CentOS 7. 3. I used SWAN notebooks with LCG 102b. The notebook was created directly from the ""Open in SWAN"" button in the tutorial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12234
https://github.com/root-project/root/issues/12234:343,integrability,pipelin,pipeline,343,"Numba issues with RVecs; ### Describe the bug. When using RVecs (namely RvecF) with Numba in PyRoot the exception ""Failed to extract template argument of type RVecF"" raises. Changing RVecF to RVec\<float\> fixes the issue. Numba functions also don't seem to allow defining RVecs inside them, giving . ```. TypingError: Failed in nopython mode pipeline (step: nopython frontend). Unknown attribute 'RVec' of type Module(<module 'ROOT' from '/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py'>). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. During: typing of get attribute at /tmp/ipykernel_594/4272152336.py (3). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. ```. when defining a function such as. ```. @ROOT.Numba.Declare(['RVec<float>', 'int'], 'RVec<float>'). def pypowarray(x, y):. v = ROOT.RVec['float'](). return x**y. ```. ### To Reproduce. The PyRoot tutorial pyroot004_NumbaDeclare.py (https://root.cern.ch/doc/master/pyroot004__NumbaDeclare_8py.html) directly reproduces the issue with RVecF. Modifying the code where pypowarray is defined to match the code above reproduces the issue with defintions. ### Setup. 1. ROOT Version: 6.26/08. 2. Operating system: CentOS 7. 3. I used SWAN notebooks with LCG 102b. The notebook was created directly from the ""Open in SWAN"" button in the tutorial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12234
https://github.com/root-project/root/issues/12234:1286,integrability,Version,Version,1286,"Numba issues with RVecs; ### Describe the bug. When using RVecs (namely RvecF) with Numba in PyRoot the exception ""Failed to extract template argument of type RVecF"" raises. Changing RVecF to RVec\<float\> fixes the issue. Numba functions also don't seem to allow defining RVecs inside them, giving . ```. TypingError: Failed in nopython mode pipeline (step: nopython frontend). Unknown attribute 'RVec' of type Module(<module 'ROOT' from '/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py'>). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. During: typing of get attribute at /tmp/ipykernel_594/4272152336.py (3). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. ```. when defining a function such as. ```. @ROOT.Numba.Declare(['RVec<float>', 'int'], 'RVec<float>'). def pypowarray(x, y):. v = ROOT.RVec['float'](). return x**y. ```. ### To Reproduce. The PyRoot tutorial pyroot004_NumbaDeclare.py (https://root.cern.ch/doc/master/pyroot004__NumbaDeclare_8py.html) directly reproduces the issue with RVecF. Modifying the code where pypowarray is defined to match the code above reproduces the issue with defintions. ### Setup. 1. ROOT Version: 6.26/08. 2. Operating system: CentOS 7. 3. I used SWAN notebooks with LCG 102b. The notebook was created directly from the ""Open in SWAN"" button in the tutorial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12234
https://github.com/root-project/root/issues/12234:412,modifiability,Modul,Module,412,"Numba issues with RVecs; ### Describe the bug. When using RVecs (namely RvecF) with Numba in PyRoot the exception ""Failed to extract template argument of type RVecF"" raises. Changing RVecF to RVec\<float\> fixes the issue. Numba functions also don't seem to allow defining RVecs inside them, giving . ```. TypingError: Failed in nopython mode pipeline (step: nopython frontend). Unknown attribute 'RVec' of type Module(<module 'ROOT' from '/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py'>). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. During: typing of get attribute at /tmp/ipykernel_594/4272152336.py (3). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. ```. when defining a function such as. ```. @ROOT.Numba.Declare(['RVec<float>', 'int'], 'RVec<float>'). def pypowarray(x, y):. v = ROOT.RVec['float'](). return x**y. ```. ### To Reproduce. The PyRoot tutorial pyroot004_NumbaDeclare.py (https://root.cern.ch/doc/master/pyroot004__NumbaDeclare_8py.html) directly reproduces the issue with RVecF. Modifying the code where pypowarray is defined to match the code above reproduces the issue with defintions. ### Setup. 1. ROOT Version: 6.26/08. 2. Operating system: CentOS 7. 3. I used SWAN notebooks with LCG 102b. The notebook was created directly from the ""Open in SWAN"" button in the tutorial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12234
https://github.com/root-project/root/issues/12234:420,modifiability,modul,module,420,"Numba issues with RVecs; ### Describe the bug. When using RVecs (namely RvecF) with Numba in PyRoot the exception ""Failed to extract template argument of type RVecF"" raises. Changing RVecF to RVec\<float\> fixes the issue. Numba functions also don't seem to allow defining RVecs inside them, giving . ```. TypingError: Failed in nopython mode pipeline (step: nopython frontend). Unknown attribute 'RVec' of type Module(<module 'ROOT' from '/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py'>). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. During: typing of get attribute at /tmp/ipykernel_594/4272152336.py (3). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. ```. when defining a function such as. ```. @ROOT.Numba.Declare(['RVec<float>', 'int'], 'RVec<float>'). def pypowarray(x, y):. v = ROOT.RVec['float'](). return x**y. ```. ### To Reproduce. The PyRoot tutorial pyroot004_NumbaDeclare.py (https://root.cern.ch/doc/master/pyroot004__NumbaDeclare_8py.html) directly reproduces the issue with RVecF. Modifying the code where pypowarray is defined to match the code above reproduces the issue with defintions. ### Setup. 1. ROOT Version: 6.26/08. 2. Operating system: CentOS 7. 3. I used SWAN notebooks with LCG 102b. The notebook was created directly from the ""Open in SWAN"" button in the tutorial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12234
https://github.com/root-project/root/issues/12234:1286,modifiability,Version,Version,1286,"Numba issues with RVecs; ### Describe the bug. When using RVecs (namely RvecF) with Numba in PyRoot the exception ""Failed to extract template argument of type RVecF"" raises. Changing RVecF to RVec\<float\> fixes the issue. Numba functions also don't seem to allow defining RVecs inside them, giving . ```. TypingError: Failed in nopython mode pipeline (step: nopython frontend). Unknown attribute 'RVec' of type Module(<module 'ROOT' from '/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py'>). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. During: typing of get attribute at /tmp/ipykernel_594/4272152336.py (3). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. ```. when defining a function such as. ```. @ROOT.Numba.Declare(['RVec<float>', 'int'], 'RVec<float>'). def pypowarray(x, y):. v = ROOT.RVec['float'](). return x**y. ```. ### To Reproduce. The PyRoot tutorial pyroot004_NumbaDeclare.py (https://root.cern.ch/doc/master/pyroot004__NumbaDeclare_8py.html) directly reproduces the issue with RVecF. Modifying the code where pypowarray is defined to match the code above reproduces the issue with defintions. ### Setup. 1. ROOT Version: 6.26/08. 2. Operating system: CentOS 7. 3. I used SWAN notebooks with LCG 102b. The notebook was created directly from the ""Open in SWAN"" button in the tutorial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12234
https://github.com/root-project/root/issues/12234:115,reliability,Fail,Failed,115,"Numba issues with RVecs; ### Describe the bug. When using RVecs (namely RvecF) with Numba in PyRoot the exception ""Failed to extract template argument of type RVecF"" raises. Changing RVecF to RVec\<float\> fixes the issue. Numba functions also don't seem to allow defining RVecs inside them, giving . ```. TypingError: Failed in nopython mode pipeline (step: nopython frontend). Unknown attribute 'RVec' of type Module(<module 'ROOT' from '/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py'>). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. During: typing of get attribute at /tmp/ipykernel_594/4272152336.py (3). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. ```. when defining a function such as. ```. @ROOT.Numba.Declare(['RVec<float>', 'int'], 'RVec<float>'). def pypowarray(x, y):. v = ROOT.RVec['float'](). return x**y. ```. ### To Reproduce. The PyRoot tutorial pyroot004_NumbaDeclare.py (https://root.cern.ch/doc/master/pyroot004__NumbaDeclare_8py.html) directly reproduces the issue with RVecF. Modifying the code where pypowarray is defined to match the code above reproduces the issue with defintions. ### Setup. 1. ROOT Version: 6.26/08. 2. Operating system: CentOS 7. 3. I used SWAN notebooks with LCG 102b. The notebook was created directly from the ""Open in SWAN"" button in the tutorial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12234
https://github.com/root-project/root/issues/12234:319,reliability,Fail,Failed,319,"Numba issues with RVecs; ### Describe the bug. When using RVecs (namely RvecF) with Numba in PyRoot the exception ""Failed to extract template argument of type RVecF"" raises. Changing RVecF to RVec\<float\> fixes the issue. Numba functions also don't seem to allow defining RVecs inside them, giving . ```. TypingError: Failed in nopython mode pipeline (step: nopython frontend). Unknown attribute 'RVec' of type Module(<module 'ROOT' from '/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py'>). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. During: typing of get attribute at /tmp/ipykernel_594/4272152336.py (3). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. ```. when defining a function such as. ```. @ROOT.Numba.Declare(['RVec<float>', 'int'], 'RVec<float>'). def pypowarray(x, y):. v = ROOT.RVec['float'](). return x**y. ```. ### To Reproduce. The PyRoot tutorial pyroot004_NumbaDeclare.py (https://root.cern.ch/doc/master/pyroot004__NumbaDeclare_8py.html) directly reproduces the issue with RVecF. Modifying the code where pypowarray is defined to match the code above reproduces the issue with defintions. ### Setup. 1. ROOT Version: 6.26/08. 2. Operating system: CentOS 7. 3. I used SWAN notebooks with LCG 102b. The notebook was created directly from the ""Open in SWAN"" button in the tutorial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12234
https://github.com/root-project/root/issues/12234:104,safety,except,exception,104,"Numba issues with RVecs; ### Describe the bug. When using RVecs (namely RvecF) with Numba in PyRoot the exception ""Failed to extract template argument of type RVecF"" raises. Changing RVecF to RVec\<float\> fixes the issue. Numba functions also don't seem to allow defining RVecs inside them, giving . ```. TypingError: Failed in nopython mode pipeline (step: nopython frontend). Unknown attribute 'RVec' of type Module(<module 'ROOT' from '/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py'>). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. During: typing of get attribute at /tmp/ipykernel_594/4272152336.py (3). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. ```. when defining a function such as. ```. @ROOT.Numba.Declare(['RVec<float>', 'int'], 'RVec<float>'). def pypowarray(x, y):. v = ROOT.RVec['float'](). return x**y. ```. ### To Reproduce. The PyRoot tutorial pyroot004_NumbaDeclare.py (https://root.cern.ch/doc/master/pyroot004__NumbaDeclare_8py.html) directly reproduces the issue with RVecF. Modifying the code where pypowarray is defined to match the code above reproduces the issue with defintions. ### Setup. 1. ROOT Version: 6.26/08. 2. Operating system: CentOS 7. 3. I used SWAN notebooks with LCG 102b. The notebook was created directly from the ""Open in SWAN"" button in the tutorial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12234
https://github.com/root-project/root/issues/12234:412,safety,Modul,Module,412,"Numba issues with RVecs; ### Describe the bug. When using RVecs (namely RvecF) with Numba in PyRoot the exception ""Failed to extract template argument of type RVecF"" raises. Changing RVecF to RVec\<float\> fixes the issue. Numba functions also don't seem to allow defining RVecs inside them, giving . ```. TypingError: Failed in nopython mode pipeline (step: nopython frontend). Unknown attribute 'RVec' of type Module(<module 'ROOT' from '/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py'>). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. During: typing of get attribute at /tmp/ipykernel_594/4272152336.py (3). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. ```. when defining a function such as. ```. @ROOT.Numba.Declare(['RVec<float>', 'int'], 'RVec<float>'). def pypowarray(x, y):. v = ROOT.RVec['float'](). return x**y. ```. ### To Reproduce. The PyRoot tutorial pyroot004_NumbaDeclare.py (https://root.cern.ch/doc/master/pyroot004__NumbaDeclare_8py.html) directly reproduces the issue with RVecF. Modifying the code where pypowarray is defined to match the code above reproduces the issue with defintions. ### Setup. 1. ROOT Version: 6.26/08. 2. Operating system: CentOS 7. 3. I used SWAN notebooks with LCG 102b. The notebook was created directly from the ""Open in SWAN"" button in the tutorial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12234
https://github.com/root-project/root/issues/12234:420,safety,modul,module,420,"Numba issues with RVecs; ### Describe the bug. When using RVecs (namely RvecF) with Numba in PyRoot the exception ""Failed to extract template argument of type RVecF"" raises. Changing RVecF to RVec\<float\> fixes the issue. Numba functions also don't seem to allow defining RVecs inside them, giving . ```. TypingError: Failed in nopython mode pipeline (step: nopython frontend). Unknown attribute 'RVec' of type Module(<module 'ROOT' from '/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py'>). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. During: typing of get attribute at /tmp/ipykernel_594/4272152336.py (3). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. ```. when defining a function such as. ```. @ROOT.Numba.Declare(['RVec<float>', 'int'], 'RVec<float>'). def pypowarray(x, y):. v = ROOT.RVec['float'](). return x**y. ```. ### To Reproduce. The PyRoot tutorial pyroot004_NumbaDeclare.py (https://root.cern.ch/doc/master/pyroot004__NumbaDeclare_8py.html) directly reproduces the issue with RVecF. Modifying the code where pypowarray is defined to match the code above reproduces the issue with defintions. ### Setup. 1. ROOT Version: 6.26/08. 2. Operating system: CentOS 7. 3. I used SWAN notebooks with LCG 102b. The notebook was created directly from the ""Open in SWAN"" button in the tutorial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12234
https://github.com/root-project/root/issues/12234:1158,security,Modif,Modifying,1158,"Numba issues with RVecs; ### Describe the bug. When using RVecs (namely RvecF) with Numba in PyRoot the exception ""Failed to extract template argument of type RVecF"" raises. Changing RVecF to RVec\<float\> fixes the issue. Numba functions also don't seem to allow defining RVecs inside them, giving . ```. TypingError: Failed in nopython mode pipeline (step: nopython frontend). Unknown attribute 'RVec' of type Module(<module 'ROOT' from '/cvmfs/sft.cern.ch/lcg/views/LCG_102b_swan/x86_64-centos7-gcc11-opt/lib/ROOT/__init__.py'>). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. During: typing of get attribute at /tmp/ipykernel_594/4272152336.py (3). File ""../../../../../../tmp/ipykernel_594/4272152336.py"", line 3:. <source missing, REPL/exec in use?>. ```. when defining a function such as. ```. @ROOT.Numba.Declare(['RVec<float>', 'int'], 'RVec<float>'). def pypowarray(x, y):. v = ROOT.RVec['float'](). return x**y. ```. ### To Reproduce. The PyRoot tutorial pyroot004_NumbaDeclare.py (https://root.cern.ch/doc/master/pyroot004__NumbaDeclare_8py.html) directly reproduces the issue with RVecF. Modifying the code where pypowarray is defined to match the code above reproduces the issue with defintions. ### Setup. 1. ROOT Version: 6.26/08. 2. Operating system: CentOS 7. 3. I used SWAN notebooks with LCG 102b. The notebook was created directly from the ""Open in SWAN"" button in the tutorial.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12234
https://github.com/root-project/root/pull/12235:30,availability,error,error,30,Implement reversed graphs for error bars and log scale.; Reversed graphs were not working in log scale. As explained here:. https://github.com/root-project/root/issues/11938.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12235
https://github.com/root-project/root/pull/12235:45,deployability,log,log,45,Implement reversed graphs for error bars and log scale.; Reversed graphs were not working in log scale. As explained here:. https://github.com/root-project/root/issues/11938.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12235
https://github.com/root-project/root/pull/12235:49,deployability,scale,scale,49,Implement reversed graphs for error bars and log scale.; Reversed graphs were not working in log scale. As explained here:. https://github.com/root-project/root/issues/11938.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12235
https://github.com/root-project/root/pull/12235:93,deployability,log,log,93,Implement reversed graphs for error bars and log scale.; Reversed graphs were not working in log scale. As explained here:. https://github.com/root-project/root/issues/11938.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12235
https://github.com/root-project/root/pull/12235:97,deployability,scale,scale,97,Implement reversed graphs for error bars and log scale.; Reversed graphs were not working in log scale. As explained here:. https://github.com/root-project/root/issues/11938.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12235
https://github.com/root-project/root/pull/12235:49,energy efficiency,scale,scale,49,Implement reversed graphs for error bars and log scale.; Reversed graphs were not working in log scale. As explained here:. https://github.com/root-project/root/issues/11938.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12235
https://github.com/root-project/root/pull/12235:97,energy efficiency,scale,scale,97,Implement reversed graphs for error bars and log scale.; Reversed graphs were not working in log scale. As explained here:. https://github.com/root-project/root/issues/11938.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12235
https://github.com/root-project/root/pull/12235:49,modifiability,scal,scale,49,Implement reversed graphs for error bars and log scale.; Reversed graphs were not working in log scale. As explained here:. https://github.com/root-project/root/issues/11938.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12235
https://github.com/root-project/root/pull/12235:97,modifiability,scal,scale,97,Implement reversed graphs for error bars and log scale.; Reversed graphs were not working in log scale. As explained here:. https://github.com/root-project/root/issues/11938.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12235
https://github.com/root-project/root/pull/12235:30,performance,error,error,30,Implement reversed graphs for error bars and log scale.; Reversed graphs were not working in log scale. As explained here:. https://github.com/root-project/root/issues/11938.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12235
https://github.com/root-project/root/pull/12235:49,performance,scale,scale,49,Implement reversed graphs for error bars and log scale.; Reversed graphs were not working in log scale. As explained here:. https://github.com/root-project/root/issues/11938.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12235
https://github.com/root-project/root/pull/12235:97,performance,scale,scale,97,Implement reversed graphs for error bars and log scale.; Reversed graphs were not working in log scale. As explained here:. https://github.com/root-project/root/issues/11938.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12235
https://github.com/root-project/root/pull/12235:30,safety,error,error,30,Implement reversed graphs for error bars and log scale.; Reversed graphs were not working in log scale. As explained here:. https://github.com/root-project/root/issues/11938.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12235
https://github.com/root-project/root/pull/12235:45,safety,log,log,45,Implement reversed graphs for error bars and log scale.; Reversed graphs were not working in log scale. As explained here:. https://github.com/root-project/root/issues/11938.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12235
https://github.com/root-project/root/pull/12235:93,safety,log,log,93,Implement reversed graphs for error bars and log scale.; Reversed graphs were not working in log scale. As explained here:. https://github.com/root-project/root/issues/11938.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12235
https://github.com/root-project/root/pull/12235:45,security,log,log,45,Implement reversed graphs for error bars and log scale.; Reversed graphs were not working in log scale. As explained here:. https://github.com/root-project/root/issues/11938.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12235
https://github.com/root-project/root/pull/12235:93,security,log,log,93,Implement reversed graphs for error bars and log scale.; Reversed graphs were not working in log scale. As explained here:. https://github.com/root-project/root/issues/11938.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12235
https://github.com/root-project/root/pull/12235:45,testability,log,log,45,Implement reversed graphs for error bars and log scale.; Reversed graphs were not working in log scale. As explained here:. https://github.com/root-project/root/issues/11938.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12235
https://github.com/root-project/root/pull/12235:93,testability,log,log,93,Implement reversed graphs for error bars and log scale.; Reversed graphs were not working in log scale. As explained here:. https://github.com/root-project/root/issues/11938.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12235
https://github.com/root-project/root/pull/12235:30,usability,error,error,30,Implement reversed graphs for error bars and log scale.; Reversed graphs were not working in log scale. As explained here:. https://github.com/root-project/root/issues/11938.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12235
https://github.com/root-project/root/pull/12236:497,deployability,log,logic,497,"[RF] Support again same-name pdfs in RooSimultaneous with BatchMode; Since a few weeks, having pdfs with the same name in a RooSimultaneous fit with BatchMode didn't work anymore. This was because when setting up the computation graph for a given normalization set, all pdfs are cloned and redirected with `RooAbsArg::redirectServers()`, which doesn't work if servers have the same name. This commit suggests to instead delete the pdf servers and proxies and then recreate them by hand. Also, the logic of `RooSimultaneous::compileForNormSet()` was updated to iterate directly over the pdfs instead of iterating over the index categories and then getting the pdfs. The unit tests in `testAbsPdf` are now also parametrized to cover both BatchMode on and off, such that the case of the `RooSimultaneous` with one pdf in used in two channels is also covered buy the tests for BatchMode.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12236
https://github.com/root-project/root/pull/12236:549,deployability,updat,updated,549,"[RF] Support again same-name pdfs in RooSimultaneous with BatchMode; Since a few weeks, having pdfs with the same name in a RooSimultaneous fit with BatchMode didn't work anymore. This was because when setting up the computation graph for a given normalization set, all pdfs are cloned and redirected with `RooAbsArg::redirectServers()`, which doesn't work if servers have the same name. This commit suggests to instead delete the pdf servers and proxies and then recreate them by hand. Also, the logic of `RooSimultaneous::compileForNormSet()` was updated to iterate directly over the pdfs instead of iterating over the index categories and then getting the pdfs. The unit tests in `testAbsPdf` are now also parametrized to cover both BatchMode on and off, such that the case of the `RooSimultaneous` with one pdf in used in two channels is also covered buy the tests for BatchMode.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12236
https://github.com/root-project/root/pull/12236:58,integrability,Batch,BatchMode,58,"[RF] Support again same-name pdfs in RooSimultaneous with BatchMode; Since a few weeks, having pdfs with the same name in a RooSimultaneous fit with BatchMode didn't work anymore. This was because when setting up the computation graph for a given normalization set, all pdfs are cloned and redirected with `RooAbsArg::redirectServers()`, which doesn't work if servers have the same name. This commit suggests to instead delete the pdf servers and proxies and then recreate them by hand. Also, the logic of `RooSimultaneous::compileForNormSet()` was updated to iterate directly over the pdfs instead of iterating over the index categories and then getting the pdfs. The unit tests in `testAbsPdf` are now also parametrized to cover both BatchMode on and off, such that the case of the `RooSimultaneous` with one pdf in used in two channels is also covered buy the tests for BatchMode.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12236
https://github.com/root-project/root/pull/12236:149,integrability,Batch,BatchMode,149,"[RF] Support again same-name pdfs in RooSimultaneous with BatchMode; Since a few weeks, having pdfs with the same name in a RooSimultaneous fit with BatchMode didn't work anymore. This was because when setting up the computation graph for a given normalization set, all pdfs are cloned and redirected with `RooAbsArg::redirectServers()`, which doesn't work if servers have the same name. This commit suggests to instead delete the pdf servers and proxies and then recreate them by hand. Also, the logic of `RooSimultaneous::compileForNormSet()` was updated to iterate directly over the pdfs instead of iterating over the index categories and then getting the pdfs. The unit tests in `testAbsPdf` are now also parametrized to cover both BatchMode on and off, such that the case of the `RooSimultaneous` with one pdf in used in two channels is also covered buy the tests for BatchMode.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12236
https://github.com/root-project/root/pull/12236:736,integrability,Batch,BatchMode,736,"[RF] Support again same-name pdfs in RooSimultaneous with BatchMode; Since a few weeks, having pdfs with the same name in a RooSimultaneous fit with BatchMode didn't work anymore. This was because when setting up the computation graph for a given normalization set, all pdfs are cloned and redirected with `RooAbsArg::redirectServers()`, which doesn't work if servers have the same name. This commit suggests to instead delete the pdf servers and proxies and then recreate them by hand. Also, the logic of `RooSimultaneous::compileForNormSet()` was updated to iterate directly over the pdfs instead of iterating over the index categories and then getting the pdfs. The unit tests in `testAbsPdf` are now also parametrized to cover both BatchMode on and off, such that the case of the `RooSimultaneous` with one pdf in used in two channels is also covered buy the tests for BatchMode.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12236
https://github.com/root-project/root/pull/12236:873,integrability,Batch,BatchMode,873,"[RF] Support again same-name pdfs in RooSimultaneous with BatchMode; Since a few weeks, having pdfs with the same name in a RooSimultaneous fit with BatchMode didn't work anymore. This was because when setting up the computation graph for a given normalization set, all pdfs are cloned and redirected with `RooAbsArg::redirectServers()`, which doesn't work if servers have the same name. This commit suggests to instead delete the pdf servers and proxies and then recreate them by hand. Also, the logic of `RooSimultaneous::compileForNormSet()` was updated to iterate directly over the pdfs instead of iterating over the index categories and then getting the pdfs. The unit tests in `testAbsPdf` are now also parametrized to cover both BatchMode on and off, such that the case of the `RooSimultaneous` with one pdf in used in two channels is also covered buy the tests for BatchMode.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12236
https://github.com/root-project/root/pull/12236:447,interoperability,prox,proxies,447,"[RF] Support again same-name pdfs in RooSimultaneous with BatchMode; Since a few weeks, having pdfs with the same name in a RooSimultaneous fit with BatchMode didn't work anymore. This was because when setting up the computation graph for a given normalization set, all pdfs are cloned and redirected with `RooAbsArg::redirectServers()`, which doesn't work if servers have the same name. This commit suggests to instead delete the pdf servers and proxies and then recreate them by hand. Also, the logic of `RooSimultaneous::compileForNormSet()` was updated to iterate directly over the pdfs instead of iterating over the index categories and then getting the pdfs. The unit tests in `testAbsPdf` are now also parametrized to cover both BatchMode on and off, such that the case of the `RooSimultaneous` with one pdf in used in two channels is also covered buy the tests for BatchMode.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12236
https://github.com/root-project/root/pull/12236:709,modifiability,paramet,parametrized,709,"[RF] Support again same-name pdfs in RooSimultaneous with BatchMode; Since a few weeks, having pdfs with the same name in a RooSimultaneous fit with BatchMode didn't work anymore. This was because when setting up the computation graph for a given normalization set, all pdfs are cloned and redirected with `RooAbsArg::redirectServers()`, which doesn't work if servers have the same name. This commit suggests to instead delete the pdf servers and proxies and then recreate them by hand. Also, the logic of `RooSimultaneous::compileForNormSet()` was updated to iterate directly over the pdfs instead of iterating over the index categories and then getting the pdfs. The unit tests in `testAbsPdf` are now also parametrized to cover both BatchMode on and off, such that the case of the `RooSimultaneous` with one pdf in used in two channels is also covered buy the tests for BatchMode.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12236
https://github.com/root-project/root/pull/12236:58,performance,Batch,BatchMode,58,"[RF] Support again same-name pdfs in RooSimultaneous with BatchMode; Since a few weeks, having pdfs with the same name in a RooSimultaneous fit with BatchMode didn't work anymore. This was because when setting up the computation graph for a given normalization set, all pdfs are cloned and redirected with `RooAbsArg::redirectServers()`, which doesn't work if servers have the same name. This commit suggests to instead delete the pdf servers and proxies and then recreate them by hand. Also, the logic of `RooSimultaneous::compileForNormSet()` was updated to iterate directly over the pdfs instead of iterating over the index categories and then getting the pdfs. The unit tests in `testAbsPdf` are now also parametrized to cover both BatchMode on and off, such that the case of the `RooSimultaneous` with one pdf in used in two channels is also covered buy the tests for BatchMode.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12236
https://github.com/root-project/root/pull/12236:149,performance,Batch,BatchMode,149,"[RF] Support again same-name pdfs in RooSimultaneous with BatchMode; Since a few weeks, having pdfs with the same name in a RooSimultaneous fit with BatchMode didn't work anymore. This was because when setting up the computation graph for a given normalization set, all pdfs are cloned and redirected with `RooAbsArg::redirectServers()`, which doesn't work if servers have the same name. This commit suggests to instead delete the pdf servers and proxies and then recreate them by hand. Also, the logic of `RooSimultaneous::compileForNormSet()` was updated to iterate directly over the pdfs instead of iterating over the index categories and then getting the pdfs. The unit tests in `testAbsPdf` are now also parametrized to cover both BatchMode on and off, such that the case of the `RooSimultaneous` with one pdf in used in two channels is also covered buy the tests for BatchMode.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12236
https://github.com/root-project/root/pull/12236:736,performance,Batch,BatchMode,736,"[RF] Support again same-name pdfs in RooSimultaneous with BatchMode; Since a few weeks, having pdfs with the same name in a RooSimultaneous fit with BatchMode didn't work anymore. This was because when setting up the computation graph for a given normalization set, all pdfs are cloned and redirected with `RooAbsArg::redirectServers()`, which doesn't work if servers have the same name. This commit suggests to instead delete the pdf servers and proxies and then recreate them by hand. Also, the logic of `RooSimultaneous::compileForNormSet()` was updated to iterate directly over the pdfs instead of iterating over the index categories and then getting the pdfs. The unit tests in `testAbsPdf` are now also parametrized to cover both BatchMode on and off, such that the case of the `RooSimultaneous` with one pdf in used in two channels is also covered buy the tests for BatchMode.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12236
https://github.com/root-project/root/pull/12236:873,performance,Batch,BatchMode,873,"[RF] Support again same-name pdfs in RooSimultaneous with BatchMode; Since a few weeks, having pdfs with the same name in a RooSimultaneous fit with BatchMode didn't work anymore. This was because when setting up the computation graph for a given normalization set, all pdfs are cloned and redirected with `RooAbsArg::redirectServers()`, which doesn't work if servers have the same name. This commit suggests to instead delete the pdf servers and proxies and then recreate them by hand. Also, the logic of `RooSimultaneous::compileForNormSet()` was updated to iterate directly over the pdfs instead of iterating over the index categories and then getting the pdfs. The unit tests in `testAbsPdf` are now also parametrized to cover both BatchMode on and off, such that the case of the `RooSimultaneous` with one pdf in used in two channels is also covered buy the tests for BatchMode.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12236
https://github.com/root-project/root/pull/12236:344,reliability,doe,doesn,344,"[RF] Support again same-name pdfs in RooSimultaneous with BatchMode; Since a few weeks, having pdfs with the same name in a RooSimultaneous fit with BatchMode didn't work anymore. This was because when setting up the computation graph for a given normalization set, all pdfs are cloned and redirected with `RooAbsArg::redirectServers()`, which doesn't work if servers have the same name. This commit suggests to instead delete the pdf servers and proxies and then recreate them by hand. Also, the logic of `RooSimultaneous::compileForNormSet()` was updated to iterate directly over the pdfs instead of iterating over the index categories and then getting the pdfs. The unit tests in `testAbsPdf` are now also parametrized to cover both BatchMode on and off, such that the case of the `RooSimultaneous` with one pdf in used in two channels is also covered buy the tests for BatchMode.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12236
https://github.com/root-project/root/pull/12236:497,safety,log,logic,497,"[RF] Support again same-name pdfs in RooSimultaneous with BatchMode; Since a few weeks, having pdfs with the same name in a RooSimultaneous fit with BatchMode didn't work anymore. This was because when setting up the computation graph for a given normalization set, all pdfs are cloned and redirected with `RooAbsArg::redirectServers()`, which doesn't work if servers have the same name. This commit suggests to instead delete the pdf servers and proxies and then recreate them by hand. Also, the logic of `RooSimultaneous::compileForNormSet()` was updated to iterate directly over the pdfs instead of iterating over the index categories and then getting the pdfs. The unit tests in `testAbsPdf` are now also parametrized to cover both BatchMode on and off, such that the case of the `RooSimultaneous` with one pdf in used in two channels is also covered buy the tests for BatchMode.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12236
https://github.com/root-project/root/pull/12236:549,safety,updat,updated,549,"[RF] Support again same-name pdfs in RooSimultaneous with BatchMode; Since a few weeks, having pdfs with the same name in a RooSimultaneous fit with BatchMode didn't work anymore. This was because when setting up the computation graph for a given normalization set, all pdfs are cloned and redirected with `RooAbsArg::redirectServers()`, which doesn't work if servers have the same name. This commit suggests to instead delete the pdf servers and proxies and then recreate them by hand. Also, the logic of `RooSimultaneous::compileForNormSet()` was updated to iterate directly over the pdfs instead of iterating over the index categories and then getting the pdfs. The unit tests in `testAbsPdf` are now also parametrized to cover both BatchMode on and off, such that the case of the `RooSimultaneous` with one pdf in used in two channels is also covered buy the tests for BatchMode.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12236
https://github.com/root-project/root/pull/12236:674,safety,test,tests,674,"[RF] Support again same-name pdfs in RooSimultaneous with BatchMode; Since a few weeks, having pdfs with the same name in a RooSimultaneous fit with BatchMode didn't work anymore. This was because when setting up the computation graph for a given normalization set, all pdfs are cloned and redirected with `RooAbsArg::redirectServers()`, which doesn't work if servers have the same name. This commit suggests to instead delete the pdf servers and proxies and then recreate them by hand. Also, the logic of `RooSimultaneous::compileForNormSet()` was updated to iterate directly over the pdfs instead of iterating over the index categories and then getting the pdfs. The unit tests in `testAbsPdf` are now also parametrized to cover both BatchMode on and off, such that the case of the `RooSimultaneous` with one pdf in used in two channels is also covered buy the tests for BatchMode.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12236
https://github.com/root-project/root/pull/12236:684,safety,test,testAbsPdf,684,"[RF] Support again same-name pdfs in RooSimultaneous with BatchMode; Since a few weeks, having pdfs with the same name in a RooSimultaneous fit with BatchMode didn't work anymore. This was because when setting up the computation graph for a given normalization set, all pdfs are cloned and redirected with `RooAbsArg::redirectServers()`, which doesn't work if servers have the same name. This commit suggests to instead delete the pdf servers and proxies and then recreate them by hand. Also, the logic of `RooSimultaneous::compileForNormSet()` was updated to iterate directly over the pdfs instead of iterating over the index categories and then getting the pdfs. The unit tests in `testAbsPdf` are now also parametrized to cover both BatchMode on and off, such that the case of the `RooSimultaneous` with one pdf in used in two channels is also covered buy the tests for BatchMode.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12236
https://github.com/root-project/root/pull/12236:863,safety,test,tests,863,"[RF] Support again same-name pdfs in RooSimultaneous with BatchMode; Since a few weeks, having pdfs with the same name in a RooSimultaneous fit with BatchMode didn't work anymore. This was because when setting up the computation graph for a given normalization set, all pdfs are cloned and redirected with `RooAbsArg::redirectServers()`, which doesn't work if servers have the same name. This commit suggests to instead delete the pdf servers and proxies and then recreate them by hand. Also, the logic of `RooSimultaneous::compileForNormSet()` was updated to iterate directly over the pdfs instead of iterating over the index categories and then getting the pdfs. The unit tests in `testAbsPdf` are now also parametrized to cover both BatchMode on and off, such that the case of the `RooSimultaneous` with one pdf in used in two channels is also covered buy the tests for BatchMode.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12236
https://github.com/root-project/root/pull/12236:497,security,log,logic,497,"[RF] Support again same-name pdfs in RooSimultaneous with BatchMode; Since a few weeks, having pdfs with the same name in a RooSimultaneous fit with BatchMode didn't work anymore. This was because when setting up the computation graph for a given normalization set, all pdfs are cloned and redirected with `RooAbsArg::redirectServers()`, which doesn't work if servers have the same name. This commit suggests to instead delete the pdf servers and proxies and then recreate them by hand. Also, the logic of `RooSimultaneous::compileForNormSet()` was updated to iterate directly over the pdfs instead of iterating over the index categories and then getting the pdfs. The unit tests in `testAbsPdf` are now also parametrized to cover both BatchMode on and off, such that the case of the `RooSimultaneous` with one pdf in used in two channels is also covered buy the tests for BatchMode.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12236
https://github.com/root-project/root/pull/12236:549,security,updat,updated,549,"[RF] Support again same-name pdfs in RooSimultaneous with BatchMode; Since a few weeks, having pdfs with the same name in a RooSimultaneous fit with BatchMode didn't work anymore. This was because when setting up the computation graph for a given normalization set, all pdfs are cloned and redirected with `RooAbsArg::redirectServers()`, which doesn't work if servers have the same name. This commit suggests to instead delete the pdf servers and proxies and then recreate them by hand. Also, the logic of `RooSimultaneous::compileForNormSet()` was updated to iterate directly over the pdfs instead of iterating over the index categories and then getting the pdfs. The unit tests in `testAbsPdf` are now also parametrized to cover both BatchMode on and off, such that the case of the `RooSimultaneous` with one pdf in used in two channels is also covered buy the tests for BatchMode.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12236
https://github.com/root-project/root/pull/12236:497,testability,log,logic,497,"[RF] Support again same-name pdfs in RooSimultaneous with BatchMode; Since a few weeks, having pdfs with the same name in a RooSimultaneous fit with BatchMode didn't work anymore. This was because when setting up the computation graph for a given normalization set, all pdfs are cloned and redirected with `RooAbsArg::redirectServers()`, which doesn't work if servers have the same name. This commit suggests to instead delete the pdf servers and proxies and then recreate them by hand. Also, the logic of `RooSimultaneous::compileForNormSet()` was updated to iterate directly over the pdfs instead of iterating over the index categories and then getting the pdfs. The unit tests in `testAbsPdf` are now also parametrized to cover both BatchMode on and off, such that the case of the `RooSimultaneous` with one pdf in used in two channels is also covered buy the tests for BatchMode.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12236
https://github.com/root-project/root/pull/12236:669,testability,unit,unit,669,"[RF] Support again same-name pdfs in RooSimultaneous with BatchMode; Since a few weeks, having pdfs with the same name in a RooSimultaneous fit with BatchMode didn't work anymore. This was because when setting up the computation graph for a given normalization set, all pdfs are cloned and redirected with `RooAbsArg::redirectServers()`, which doesn't work if servers have the same name. This commit suggests to instead delete the pdf servers and proxies and then recreate them by hand. Also, the logic of `RooSimultaneous::compileForNormSet()` was updated to iterate directly over the pdfs instead of iterating over the index categories and then getting the pdfs. The unit tests in `testAbsPdf` are now also parametrized to cover both BatchMode on and off, such that the case of the `RooSimultaneous` with one pdf in used in two channels is also covered buy the tests for BatchMode.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12236
https://github.com/root-project/root/pull/12236:674,testability,test,tests,674,"[RF] Support again same-name pdfs in RooSimultaneous with BatchMode; Since a few weeks, having pdfs with the same name in a RooSimultaneous fit with BatchMode didn't work anymore. This was because when setting up the computation graph for a given normalization set, all pdfs are cloned and redirected with `RooAbsArg::redirectServers()`, which doesn't work if servers have the same name. This commit suggests to instead delete the pdf servers and proxies and then recreate them by hand. Also, the logic of `RooSimultaneous::compileForNormSet()` was updated to iterate directly over the pdfs instead of iterating over the index categories and then getting the pdfs. The unit tests in `testAbsPdf` are now also parametrized to cover both BatchMode on and off, such that the case of the `RooSimultaneous` with one pdf in used in two channels is also covered buy the tests for BatchMode.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12236
https://github.com/root-project/root/pull/12236:684,testability,test,testAbsPdf,684,"[RF] Support again same-name pdfs in RooSimultaneous with BatchMode; Since a few weeks, having pdfs with the same name in a RooSimultaneous fit with BatchMode didn't work anymore. This was because when setting up the computation graph for a given normalization set, all pdfs are cloned and redirected with `RooAbsArg::redirectServers()`, which doesn't work if servers have the same name. This commit suggests to instead delete the pdf servers and proxies and then recreate them by hand. Also, the logic of `RooSimultaneous::compileForNormSet()` was updated to iterate directly over the pdfs instead of iterating over the index categories and then getting the pdfs. The unit tests in `testAbsPdf` are now also parametrized to cover both BatchMode on and off, such that the case of the `RooSimultaneous` with one pdf in used in two channels is also covered buy the tests for BatchMode.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12236
https://github.com/root-project/root/pull/12236:863,testability,test,tests,863,"[RF] Support again same-name pdfs in RooSimultaneous with BatchMode; Since a few weeks, having pdfs with the same name in a RooSimultaneous fit with BatchMode didn't work anymore. This was because when setting up the computation graph for a given normalization set, all pdfs are cloned and redirected with `RooAbsArg::redirectServers()`, which doesn't work if servers have the same name. This commit suggests to instead delete the pdf servers and proxies and then recreate them by hand. Also, the logic of `RooSimultaneous::compileForNormSet()` was updated to iterate directly over the pdfs instead of iterating over the index categories and then getting the pdfs. The unit tests in `testAbsPdf` are now also parametrized to cover both BatchMode on and off, such that the case of the `RooSimultaneous` with one pdf in used in two channels is also covered buy the tests for BatchMode.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12236
https://github.com/root-project/root/pull/12236:5,usability,Support,Support,5,"[RF] Support again same-name pdfs in RooSimultaneous with BatchMode; Since a few weeks, having pdfs with the same name in a RooSimultaneous fit with BatchMode didn't work anymore. This was because when setting up the computation graph for a given normalization set, all pdfs are cloned and redirected with `RooAbsArg::redirectServers()`, which doesn't work if servers have the same name. This commit suggests to instead delete the pdf servers and proxies and then recreate them by hand. Also, the logic of `RooSimultaneous::compileForNormSet()` was updated to iterate directly over the pdfs instead of iterating over the index categories and then getting the pdfs. The unit tests in `testAbsPdf` are now also parametrized to cover both BatchMode on and off, such that the case of the `RooSimultaneous` with one pdf in used in two channels is also covered buy the tests for BatchMode.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12236
https://github.com/root-project/root/pull/12237:34,energy efficiency,model,model,34,[cling] Switch back to large code model for macOS on AArch64; It results in relocation targets that are out-of-range.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12237
https://github.com/root-project/root/pull/12237:34,security,model,model,34,[cling] Switch back to large code model for macOS on AArch64; It results in relocation targets that are out-of-range.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12237
https://github.com/root-project/root/pull/12238:143,deployability,continu,continuously,143,"Revert D41416: ""Do not deserialize all lazy template specializations when looking for one.; The lazy loading approach may be faster, but it is continuously leading to problems with template instantiations and ODR violation checks in the most inconvenient places. Fixes #12003",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12238
https://github.com/root-project/root/pull/12238:101,energy efficiency,load,loading,101,"Revert D41416: ""Do not deserialize all lazy template specializations when looking for one.; The lazy loading approach may be faster, but it is continuously leading to problems with template instantiations and ODR violation checks in the most inconvenient places. Fixes #12003",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12238
https://github.com/root-project/root/pull/12238:101,performance,load,loading,101,"Revert D41416: ""Do not deserialize all lazy template specializations when looking for one.; The lazy loading approach may be faster, but it is continuously leading to problems with template instantiations and ODR violation checks in the most inconvenient places. Fixes #12003",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12238
https://github.com/root-project/root/issues/12240:231,availability,error,errors,231,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:403,availability,error,error,403,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:1089,availability,operat,operator,1089,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:1207,availability,error,errors,1207,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:1247,availability,error,errors,1247,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:12,deployability,modul,module,12,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:141,deployability,build,building,141,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:171,deployability,stack,stack,171,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:385,deployability,modul,modulemap,385,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:410,deployability,modul,module,410,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:482,deployability,modul,module,482,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:724,deployability,modul,module,724,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:1101,deployability,fail,failed,1101,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:1241,deployability,build,build,1241,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:701,integrability,sub,submodule,701,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:12,modifiability,modul,module,12,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:385,modifiability,modul,modulemap,385,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:410,modifiability,modul,module,410,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:482,modifiability,modul,module,482,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:724,modifiability,modul,module,724,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:231,performance,error,errors,231,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:403,performance,error,error,403,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:1207,performance,error,errors,1207,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:1247,performance,error,errors,1247,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:1101,reliability,fail,failed,1101,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:12,safety,modul,module,12,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:231,safety,error,errors,231,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:286,safety,test,tests,286,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:292,safety,test,testBuildDir,292,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:385,safety,modul,modulemap,385,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:403,safety,error,error,403,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:410,safety,modul,module,410,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:482,safety,modul,module,482,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:565,safety,test,tests,565,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:571,safety,test,testBuildDir,571,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:724,safety,modul,module,724,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:1154,safety,test,tested,1154,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:1207,safety,error,errors,1207,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:1247,safety,error,errors,1247,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:286,testability,test,tests,286,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:292,testability,test,testBuildDir,292,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:565,testability,test,tests,565,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:571,testability,test,testBuildDir,571,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:1039,testability,Assert,Assertion,1039,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:1154,testability,test,tested,1154,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:231,usability,error,errors,231,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:403,usability,error,error,403,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:925,usability,tool,tools,925,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:1207,usability,error,errors,1207,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:1228,usability,behavi,behavior,1228,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/issues/12240:1247,usability,error,errors,1247,"[ROOT 6.29] module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'; - [x] Checked for duplicates. ### Describe the bug. When building CMS offline software stack with the ROOT commit 6f02c75fea, we get the following errors:. ```. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/etc/cling/std.modulemap:497:10: error: module 'std.bits/uses_allocator_args.h' requires feature 'cplusplus20'. module ""bits/uses_allocator_args.h"" {. ^. /data/cmsbld/jenkins/workspace/ib-run-pr-tests/testBuildDir/el8_amd64_gcc11/external/gcc/11.2.1-f9b9dfdd886f71cd63f5538223d8f161/include/c++/11.2.1/memory_resource:42:10: note: submodule of top-level module 'std' implicitly imported here. #include // uninitialized_construct_using_alloc. ^. ```. ```. python3: /(...)/lcg/root/6.29.01-8b1fb99c2f98c5fc80c3d3abd70c9452/root-6.29.01/interpreter/llvm/src/tools/clang/lib/AST/DeclCXX.cpp:1499: clang::NamedDecl* getLambdaCallOperatorHelper(const clang::CXXRecordDecl&): Assertion `!Calls.empty() && ""Missing lambda call operator!""' failed. *** Break *** abort. ```. We have previously tested ROOT commit 0bd51969ce, and did not get these errors. ### Expected behavior. No build errors. ### Setup. ROOT 6.29.01 / 6f02c75fea on AlmaLinux 8, built from source (gcc 11.2).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12240
https://github.com/root-project/root/pull/12241:9,usability,help,help,9,reformat help; reformat help as requested here:. https://github.com/root-project/root/issues/12224.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12241
https://github.com/root-project/root/pull/12241:24,usability,help,help,24,reformat help; reformat help as requested here:. https://github.com/root-project/root/issues/12224.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12241
https://github.com/root-project/root/issues/12242:1643,availability,restor,restore,1643,"GeoVolumeAssembly through the `MakePhysicalNode > Align` sequence, the BoundingBox of this TGeoVolumeAssembly may end up with 0 size (GetDX, GetDY and GetDZ returning 0). This is not expected as it means there are other effects on the Volume aside from the translation/rotation, even when shifting something without leaving its parent volume. Something similar happens if a translation/rotation is applied to a Node which is part of a TGeoVolumeAssembly, but there it probably happens only if the changes leads to part of the assembly exceeding the original boundaries. We (me and @fuhlig1) suspect that this may partially be recursive (affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1. Go to this folder, load you",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:2385,availability,Down,Download,2385,"ngBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1. Go to this folder, load your ROOT environment. 1. Run. ```. root -l -b. root [0] .L alignment_map_def.h+. root [1] .x BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; id",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:3882,availability,Operat,Operating,3882,"n the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT version. 3. Operating system. 5. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. - Fixed for now on the Fairroot side by [PR 1244](https://github.com/FairRootGroup/FairRoot/pull/1244/files#diff-91fa880fced775e0a97b72507da489affb1a15a59197901ae774ed40d6ca1ca1) ([Issue 1243](https://github.com/FairRootGroup/FairRoot/issues/1243)). - Unsure if this is a not-well documented intended behavior or an unexpected bug. - Adding a call to `gGeoManager->CloseGeometry();` instead of the fix used in FairRoot (as advised in [ROOT-7420](https://sft.its.cern.ch/jira/browse/ROOT-7420) for the AddNode case) does not cure the problem and results in a warning that the geometry is already closed. - I am not the author nor an expert of the section of code used to apply the alignment matrices in Fairsoft, which I copied in the example macro. For questions there I may have to forward to the corresponding developers. - Investigation done by myself and @fuhlig1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:3957,availability,down,download,3957," the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT version. 3. Operating system. 5. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. - Fixed for now on the Fairroot side by [PR 1244](https://github.com/FairRootGroup/FairRoot/pull/1244/files#diff-91fa880fced775e0a97b72507da489affb1a15a59197901ae774ed40d6ca1ca1) ([Issue 1243](https://github.com/FairRootGroup/FairRoot/issues/1243)). - Unsure if this is a not-well documented intended behavior or an unexpected bug. - Adding a call to `gGeoManager->CloseGeometry();` instead of the fix used in FairRoot (as advised in [ROOT-7420](https://sft.its.cern.ch/jira/browse/ROOT-7420) for the AddNode case) does not cure the problem and results in a warning that the geometry is already closed. - I am not the author nor an expert of the section of code used to apply the alignment matrices in Fairsoft, which I copied in the example macro. For questions there I may have to forward to the corresponding developers. - Investigation done by myself and @fuhlig1.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:2280,deployability,version,versions,2280,"affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1. Go to this folder, load your ROOT environment. 1. Run. ```. root -l -b. root [0] .L alignment_map_def.h+. root [1] .x BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:2313,deployability,version,versions,2313,"ed volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1. Go to this folder, load your ROOT environment. 1. Run. ```. root -l -b. root [0] .L alignment_map_def.h+. root [1] .x BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:2364,deployability,version,version,2364,"utation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1. Go to this folder, load your ROOT environment. 1. Run. ```. root -l -b. root [0] .L alignment_map_def.h+. root [1] .x BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:2553,deployability,contain,container,2553,"ible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1. Go to this folder, load your ROOT environment. 1. Run. ```. root -l -b. root [0] .L alignment_map_def.h+. root [1] .x BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:3512,deployability,build,build,3512,"ip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1. Go to this folder, load your ROOT environment. 1. Run. ```. root -l -b. root [0] .L alignment_map_def.h+. root [1] .x BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT version. 3. Operating system. 5. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. - Fixed for now on the Fairroot side by [PR 1244](https://github.com/FairRootGroup/FairRoot/pull/1244/files#diff-91fa880fced775e0a97b72507da489affb1a15a59197901ae774ed40d6ca1ca1) ([Issue 1243](https://github.com/FairRootGroup/FairRoot/issues/1243)). - Unsure if this is a not-well documented intended behavior or an unexpected bug. - Adding a call to `gGeoManager->CloseGeometry();` instead of the fix used in FairRoot (as advised in [ROOT-7420](https://sft.its.cern.ch/jira/browse/ROOT-7420) fo",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:3685,deployability,instal,installation,3685," root [0] .L alignment_map_def.h+. root [1] .x BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT version. 3. Operating system. 5. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. - Fixed for now on the Fairroot side by [PR 1244](https://github.com/FairRootGroup/FairRoot/pull/1244/files#diff-91fa880fced775e0a97b72507da489affb1a15a59197901ae774ed40d6ca1ca1) ([Issue 1243](https://github.com/FairRootGroup/FairRoot/issues/1243)). - Unsure if this is a not-well documented intended behavior or an unexpected bug. - Adding a call to `gGeoManager->CloseGeometry();` instead of the fix used in FairRoot (as advised in [ROOT-7420](https://sft.its.cern.ch/jira/browse/ROOT-7420) for the AddNode case) does not cure the problem and results in a warning that the geometry is already closed. - I am not the author nor an expert of the section of code used to a",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:3728,deployability,patch,patch,3728,"[1] .x BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT version. 3. Operating system. 5. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. - Fixed for now on the Fairroot side by [PR 1244](https://github.com/FairRootGroup/FairRoot/pull/1244/files#diff-91fa880fced775e0a97b72507da489affb1a15a59197901ae774ed40d6ca1ca1) ([Issue 1243](https://github.com/FairRootGroup/FairRoot/issues/1243)). - Unsure if this is a not-well documented intended behavior or an unexpected bug. - Adding a call to `gGeoManager->CloseGeometry();` instead of the fix used in FairRoot (as advised in [ROOT-7420](https://sft.its.cern.ch/jira/browse/ROOT-7420) for the AddNode case) does not cure the problem and results in a warning that the geometry is already closed. - I am not the author nor an expert of the section of code used to apply the alignment matrices in Fairsoft,",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:3734,deployability,releas,releases,3734,"BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT version. 3. Operating system. 5. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. - Fixed for now on the Fairroot side by [PR 1244](https://github.com/FairRootGroup/FairRoot/pull/1244/files#diff-91fa880fced775e0a97b72507da489affb1a15a59197901ae774ed40d6ca1ca1) ([Issue 1243](https://github.com/FairRootGroup/FairRoot/issues/1243)). - Unsure if this is a not-well documented intended behavior or an unexpected bug. - Adding a call to `gGeoManager->CloseGeometry();` instead of the fix used in FairRoot (as advised in [ROOT-7420](https://sft.its.cern.ch/jira/browse/ROOT-7420) for the AddNode case) does not cure the problem and results in a warning that the geometry is already closed. - I am not the author nor an expert of the section of code used to apply the alignment matrices in Fairsoft, which ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:3803,deployability,patch,patch,3803,"rices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT version. 3. Operating system. 5. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. - Fixed for now on the Fairroot side by [PR 1244](https://github.com/FairRootGroup/FairRoot/pull/1244/files#diff-91fa880fced775e0a97b72507da489affb1a15a59197901ae774ed40d6ca1ca1) ([Issue 1243](https://github.com/FairRootGroup/FairRoot/issues/1243)). - Unsure if this is a not-well documented intended behavior or an unexpected bug. - Adding a call to `gGeoManager->CloseGeometry();` instead of the fix used in FairRoot (as advised in [ROOT-7420](https://sft.its.cern.ch/jira/browse/ROOT-7420) for the AddNode case) does not cure the problem and results in a warning that the geometry is already closed. - I am not the author nor an expert of the section of code used to apply the alignment matrices in Fairsoft, which I copied in the example macro. For questions there I may have to for",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:3809,deployability,releas,releases,3809,"cbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT version. 3. Operating system. 5. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. - Fixed for now on the Fairroot side by [PR 1244](https://github.com/FairRootGroup/FairRoot/pull/1244/files#diff-91fa880fced775e0a97b72507da489affb1a15a59197901ae774ed40d6ca1ca1) ([Issue 1243](https://github.com/FairRootGroup/FairRoot/issues/1243)). - Unsure if this is a not-well documented intended behavior or an unexpected bug. - Adding a call to `gGeoManager->CloseGeometry();` instead of the fix used in FairRoot (as advised in [ROOT-7420](https://sft.its.cern.ch/jira/browse/ROOT-7420) for the AddNode case) does not cure the problem and results in a warning that the geometry is already closed. - I am not the author nor an expert of the section of code used to apply the alignment matrices in Fairsoft, which I copied in the example macro. For questions there I may have to forward to",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:3870,deployability,version,version,3870,"ons visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT version. 3. Operating system. 5. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. - Fixed for now on the Fairroot side by [PR 1244](https://github.com/FairRootGroup/FairRoot/pull/1244/files#diff-91fa880fced775e0a97b72507da489affb1a15a59197901ae774ed40d6ca1ca1) ([Issue 1243](https://github.com/FairRootGroup/FairRoot/issues/1243)). - Unsure if this is a not-well documented intended behavior or an unexpected bug. - Adding a call to `gGeoManager->CloseGeometry();` instead of the fix used in FairRoot (as advised in [ROOT-7420](https://sft.its.cern.ch/jira/browse/ROOT-7420) for the AddNode case) does not cure the problem and results in a warning that the geometry is already closed. - I am not the author nor an expert of the section of code used to apply the alignment matrices in Fairsoft, which I copied in the example macro. For questions there I may have to forward to the corresponding developers. - Investigation done by myself",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:3939,deployability,instal,install,3939," the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT version. 3. Operating system. 5. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. - Fixed for now on the Fairroot side by [PR 1244](https://github.com/FairRootGroup/FairRoot/pull/1244/files#diff-91fa880fced775e0a97b72507da489affb1a15a59197901ae774ed40d6ca1ca1) ([Issue 1243](https://github.com/FairRootGroup/FairRoot/issues/1243)). - Unsure if this is a not-well documented intended behavior or an unexpected bug. - Adding a call to `gGeoManager->CloseGeometry();` instead of the fix used in FairRoot (as advised in [ROOT-7420](https://sft.its.cern.ch/jira/browse/ROOT-7420) for the AddNode case) does not cure the problem and results in a warning that the geometry is already closed. - I am not the author nor an expert of the section of code used to apply the alignment matrices in Fairsoft, which I copied in the example macro. For questions there I may have to forward to the corresponding developers. - Investigation done by myself and @fuhlig1.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:2639,energy efficiency,load,load,2639,"o restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1. Go to this folder, load your ROOT environment. 1. Run. ```. root -l -b. root [0] .L alignment_map_def.h+. root [1] .x BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:63,integrability,transform,transformation,63,"Zero size bounding box for some TGeoVolumeAssembly nodes after transformation by translation or rotation; - [x] Checked for duplicates. => Maybe linked/similar to https://sft.its.cern.ch/jira/browse/ROOT-7420 ? (Zero size BBox after using AddNode). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. After a translation/rotation is applied to a TGeoVolumeAssembly through the `MakePhysicalNode > Align` sequence, the BoundingBox of this TGeoVolumeAssembly may end up with 0 size (GetDX, GetDY and GetDZ returning 0). This is not expected as it means there are other effects on the Volume aside from the translation/rotation, even when shifting something without leaving its parent volume. Something similar happens if a translation/rotation is applied to a Node which is part of a TGeoVolumeAssembly, but there it probably happens only if the changes leads to part of the assembly exceeding the original boundaries. We (me and @fuhlig1) suspect that this may partially be recursive (affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for ex",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:81,integrability,translat,translation,81,"Zero size bounding box for some TGeoVolumeAssembly nodes after transformation by translation or rotation; - [x] Checked for duplicates. => Maybe linked/similar to https://sft.its.cern.ch/jira/browse/ROOT-7420 ? (Zero size BBox after using AddNode). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. After a translation/rotation is applied to a TGeoVolumeAssembly through the `MakePhysicalNode > Align` sequence, the BoundingBox of this TGeoVolumeAssembly may end up with 0 size (GetDX, GetDY and GetDZ returning 0). This is not expected as it means there are other effects on the Volume aside from the translation/rotation, even when shifting something without leaving its parent volume. Something similar happens if a translation/rotation is applied to a Node which is part of a TGeoVolumeAssembly, but there it probably happens only if the changes leads to part of the assembly exceeding the original boundaries. We (me and @fuhlig1) suspect that this may partially be recursive (affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for ex",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:609,integrability,translat,translation,609,"Zero size bounding box for some TGeoVolumeAssembly nodes after transformation by translation or rotation; - [x] Checked for duplicates. => Maybe linked/similar to https://sft.its.cern.ch/jira/browse/ROOT-7420 ? (Zero size BBox after using AddNode). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. After a translation/rotation is applied to a TGeoVolumeAssembly through the `MakePhysicalNode > Align` sequence, the BoundingBox of this TGeoVolumeAssembly may end up with 0 size (GetDX, GetDY and GetDZ returning 0). This is not expected as it means there are other effects on the Volume aside from the translation/rotation, even when shifting something without leaving its parent volume. Something similar happens if a translation/rotation is applied to a Node which is part of a TGeoVolumeAssembly, but there it probably happens only if the changes leads to part of the assembly exceeding the original boundaries. We (me and @fuhlig1) suspect that this may partially be recursive (affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for ex",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:904,integrability,translat,translation,904,"Zero size bounding box for some TGeoVolumeAssembly nodes after transformation by translation or rotation; - [x] Checked for duplicates. => Maybe linked/similar to https://sft.its.cern.ch/jira/browse/ROOT-7420 ? (Zero size BBox after using AddNode). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. After a translation/rotation is applied to a TGeoVolumeAssembly through the `MakePhysicalNode > Align` sequence, the BoundingBox of this TGeoVolumeAssembly may end up with 0 size (GetDX, GetDY and GetDZ returning 0). This is not expected as it means there are other effects on the Volume aside from the translation/rotation, even when shifting something without leaving its parent volume. Something similar happens if a translation/rotation is applied to a Node which is part of a TGeoVolumeAssembly, but there it probably happens only if the changes leads to part of the assembly exceeding the original boundaries. We (me and @fuhlig1) suspect that this may partially be recursive (affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for ex",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:1021,integrability,translat,translation,1021,"some TGeoVolumeAssembly nodes after transformation by translation or rotation; - [x] Checked for duplicates. => Maybe linked/similar to https://sft.its.cern.ch/jira/browse/ROOT-7420 ? (Zero size BBox after using AddNode). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. After a translation/rotation is applied to a TGeoVolumeAssembly through the `MakePhysicalNode > Align` sequence, the BoundingBox of this TGeoVolumeAssembly may end up with 0 size (GetDX, GetDY and GetDZ returning 0). This is not expected as it means there are other effects on the Volume aside from the translation/rotation, even when shifting something without leaving its parent volume. Something similar happens if a translation/rotation is applied to a Node which is part of a TGeoVolumeAssembly, but there it probably happens only if the changes leads to part of the assembly exceeding the original boundaries. We (me and @fuhlig1) suspect that this may partially be recursive (affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:2280,integrability,version,versions,2280,"affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1. Go to this folder, load your ROOT environment. 1. Run. ```. root -l -b. root [0] .L alignment_map_def.h+. root [1] .x BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:2313,integrability,version,versions,2313,"ed volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1. Go to this folder, load your ROOT environment. 1. Run. ```. root -l -b. root [0] .L alignment_map_def.h+. root [1] .x BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:2364,integrability,version,version,2364,"utation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1. Go to this folder, load your ROOT environment. 1. Run. ```. root -l -b. root [0] .L alignment_map_def.h+. root [1] .x BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:2862,integrability,transform,transformations,2862,"o track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1. Go to this folder, load your ROOT environment. 1. Run. ```. root -l -b. root [0] .L alignment_map_def.h+. root [1] .x BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:3870,integrability,version,version,3870,"ons visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT version. 3. Operating system. 5. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. - Fixed for now on the Fairroot side by [PR 1244](https://github.com/FairRootGroup/FairRoot/pull/1244/files#diff-91fa880fced775e0a97b72507da489affb1a15a59197901ae774ed40d6ca1ca1) ([Issue 1243](https://github.com/FairRootGroup/FairRoot/issues/1243)). - Unsure if this is a not-well documented intended behavior or an unexpected bug. - Adding a call to `gGeoManager->CloseGeometry();` instead of the fix used in FairRoot (as advised in [ROOT-7420](https://sft.its.cern.ch/jira/browse/ROOT-7420) for the AddNode case) does not cure the problem and results in a warning that the geometry is already closed. - I am not the author nor an expert of the section of code used to apply the alignment matrices in Fairsoft, which I copied in the example macro. For questions there I may have to forward to the corresponding developers. - Investigation done by myself",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:63,interoperability,transform,transformation,63,"Zero size bounding box for some TGeoVolumeAssembly nodes after transformation by translation or rotation; - [x] Checked for duplicates. => Maybe linked/similar to https://sft.its.cern.ch/jira/browse/ROOT-7420 ? (Zero size BBox after using AddNode). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. After a translation/rotation is applied to a TGeoVolumeAssembly through the `MakePhysicalNode > Align` sequence, the BoundingBox of this TGeoVolumeAssembly may end up with 0 size (GetDX, GetDY and GetDZ returning 0). This is not expected as it means there are other effects on the Volume aside from the translation/rotation, even when shifting something without leaving its parent volume. Something similar happens if a translation/rotation is applied to a Node which is part of a TGeoVolumeAssembly, but there it probably happens only if the changes leads to part of the assembly exceeding the original boundaries. We (me and @fuhlig1) suspect that this may partially be recursive (affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for ex",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:81,interoperability,translat,translation,81,"Zero size bounding box for some TGeoVolumeAssembly nodes after transformation by translation or rotation; - [x] Checked for duplicates. => Maybe linked/similar to https://sft.its.cern.ch/jira/browse/ROOT-7420 ? (Zero size BBox after using AddNode). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. After a translation/rotation is applied to a TGeoVolumeAssembly through the `MakePhysicalNode > Align` sequence, the BoundingBox of this TGeoVolumeAssembly may end up with 0 size (GetDX, GetDY and GetDZ returning 0). This is not expected as it means there are other effects on the Volume aside from the translation/rotation, even when shifting something without leaving its parent volume. Something similar happens if a translation/rotation is applied to a Node which is part of a TGeoVolumeAssembly, but there it probably happens only if the changes leads to part of the assembly exceeding the original boundaries. We (me and @fuhlig1) suspect that this may partially be recursive (affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for ex",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:609,interoperability,translat,translation,609,"Zero size bounding box for some TGeoVolumeAssembly nodes after transformation by translation or rotation; - [x] Checked for duplicates. => Maybe linked/similar to https://sft.its.cern.ch/jira/browse/ROOT-7420 ? (Zero size BBox after using AddNode). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. After a translation/rotation is applied to a TGeoVolumeAssembly through the `MakePhysicalNode > Align` sequence, the BoundingBox of this TGeoVolumeAssembly may end up with 0 size (GetDX, GetDY and GetDZ returning 0). This is not expected as it means there are other effects on the Volume aside from the translation/rotation, even when shifting something without leaving its parent volume. Something similar happens if a translation/rotation is applied to a Node which is part of a TGeoVolumeAssembly, but there it probably happens only if the changes leads to part of the assembly exceeding the original boundaries. We (me and @fuhlig1) suspect that this may partially be recursive (affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for ex",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:904,interoperability,translat,translation,904,"Zero size bounding box for some TGeoVolumeAssembly nodes after transformation by translation or rotation; - [x] Checked for duplicates. => Maybe linked/similar to https://sft.its.cern.ch/jira/browse/ROOT-7420 ? (Zero size BBox after using AddNode). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. After a translation/rotation is applied to a TGeoVolumeAssembly through the `MakePhysicalNode > Align` sequence, the BoundingBox of this TGeoVolumeAssembly may end up with 0 size (GetDX, GetDY and GetDZ returning 0). This is not expected as it means there are other effects on the Volume aside from the translation/rotation, even when shifting something without leaving its parent volume. Something similar happens if a translation/rotation is applied to a Node which is part of a TGeoVolumeAssembly, but there it probably happens only if the changes leads to part of the assembly exceeding the original boundaries. We (me and @fuhlig1) suspect that this may partially be recursive (affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for ex",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:1021,interoperability,translat,translation,1021,"some TGeoVolumeAssembly nodes after transformation by translation or rotation; - [x] Checked for duplicates. => Maybe linked/similar to https://sft.its.cern.ch/jira/browse/ROOT-7420 ? (Zero size BBox after using AddNode). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. After a translation/rotation is applied to a TGeoVolumeAssembly through the `MakePhysicalNode > Align` sequence, the BoundingBox of this TGeoVolumeAssembly may end up with 0 size (GetDX, GetDY and GetDZ returning 0). This is not expected as it means there are other effects on the Volume aside from the translation/rotation, even when shifting something without leaving its parent volume. Something similar happens if a translation/rotation is applied to a Node which is part of a TGeoVolumeAssembly, but there it probably happens only if the changes leads to part of the assembly exceeding the original boundaries. We (me and @fuhlig1) suspect that this may partially be recursive (affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:2544,interoperability,standard,standard,2544,"f not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1. Go to this folder, load your ROOT environment. 1. Run. ```. root -l -b. root [0] .L alignment_map_def.h+. root [1] .x BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ...",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:2862,interoperability,transform,transformations,2862,"o track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1. Go to this folder, load your ROOT environment. 1. Run. ```. root -l -b. root [0] .L alignment_map_def.h+. root [1] .x BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:2280,modifiability,version,versions,2280,"affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1. Go to this folder, load your ROOT environment. 1. Run. ```. root -l -b. root [0] .L alignment_map_def.h+. root [1] .x BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:2313,modifiability,version,versions,2313,"ed volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1. Go to this folder, load your ROOT environment. 1. Run. ```. root -l -b. root [0] .L alignment_map_def.h+. root [1] .x BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:2364,modifiability,version,version,2364,"utation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1. Go to this folder, load your ROOT environment. 1. Run. ```. root -l -b. root [0] .L alignment_map_def.h+. root [1] .x BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:3870,modifiability,version,version,3870,"ons visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT version. 3. Operating system. 5. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. - Fixed for now on the Fairroot side by [PR 1244](https://github.com/FairRootGroup/FairRoot/pull/1244/files#diff-91fa880fced775e0a97b72507da489affb1a15a59197901ae774ed40d6ca1ca1) ([Issue 1243](https://github.com/FairRootGroup/FairRoot/issues/1243)). - Unsure if this is a not-well documented intended behavior or an unexpected bug. - Adding a call to `gGeoManager->CloseGeometry();` instead of the fix used in FairRoot (as advised in [ROOT-7420](https://sft.its.cern.ch/jira/browse/ROOT-7420) for the AddNode case) does not cure the problem and results in a warning that the geometry is already closed. - I am not the author nor an expert of the section of code used to apply the alignment matrices in Fairsoft, which I copied in the example macro. For questions there I may have to forward to the corresponding developers. - Investigation done by myself",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:1570,performance,perform,performance,1570,">. ### Describe the bug. After a translation/rotation is applied to a TGeoVolumeAssembly through the `MakePhysicalNode > Align` sequence, the BoundingBox of this TGeoVolumeAssembly may end up with 0 size (GetDX, GetDY and GetDZ returning 0). This is not expected as it means there are other effects on the Volume aside from the translation/rotation, even when shifting something without leaving its parent volume. Something similar happens if a translation/rotation is applied to a Node which is part of a TGeoVolumeAssembly, but there it probably happens only if the changes leads to part of the assembly exceeding the original boundaries. We (me and @fuhlig1) suspect that this may partially be recursive (affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary he",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:2639,performance,load,load,2639,"o restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1. Go to this folder, load your ROOT environment. 1. Run. ```. root -l -b. root [0] .L alignment_map_def.h+. root [1] .x BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:1643,reliability,restor,restore,1643,"GeoVolumeAssembly through the `MakePhysicalNode > Align` sequence, the BoundingBox of this TGeoVolumeAssembly may end up with 0 size (GetDX, GetDY and GetDZ returning 0). This is not expected as it means there are other effects on the Volume aside from the translation/rotation, even when shifting something without leaving its parent volume. Something similar happens if a translation/rotation is applied to a Node which is part of a TGeoVolumeAssembly, but there it probably happens only if the changes leads to part of the assembly exceeding the original boundaries. We (me and @fuhlig1) suspect that this may partially be recursive (affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1. Go to this folder, load you",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:4535,reliability,doe,does,4535," the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT version. 3. Operating system. 5. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. - Fixed for now on the Fairroot side by [PR 1244](https://github.com/FairRootGroup/FairRoot/pull/1244/files#diff-91fa880fced775e0a97b72507da489affb1a15a59197901ae774ed40d6ca1ca1) ([Issue 1243](https://github.com/FairRootGroup/FairRoot/issues/1243)). - Unsure if this is a not-well documented intended behavior or an unexpected bug. - Adding a call to `gGeoManager->CloseGeometry();` instead of the fix used in FairRoot (as advised in [ROOT-7420](https://sft.its.cern.ch/jira/browse/ROOT-7420) for the AddNode case) does not cure the problem and results in a warning that the geometry is already closed. - I am not the author nor an expert of the section of code used to apply the alignment matrices in Fairsoft, which I copied in the example macro. For questions there I may have to forward to the corresponding developers. - Investigation done by myself and @fuhlig1.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:1537,safety,valid,valid,1537," still exists in today's master"". -->. ### Describe the bug. After a translation/rotation is applied to a TGeoVolumeAssembly through the `MakePhysicalNode > Align` sequence, the BoundingBox of this TGeoVolumeAssembly may end up with 0 size (GetDX, GetDY and GetDZ returning 0). This is not expected as it means there are other effects on the Volume aside from the translation/rotation, even when shifting something without leaving its parent volume. Something similar happens if a translation/rotation is applied to a Node which is part of a TGeoVolumeAssembly, but there it probably happens only if the changes leads to part of the assembly exceeding the original boundaries. We (me and @fuhlig1) suspect that this may partially be recursive (affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:1974,safety,compl,complete,1974,"ent volume. Something similar happens if a translation/rotation is applied to a Node which is part of a TGeoVolumeAssembly, but there it probably happens only if the changes leads to part of the assembly exceeding the original boundaries. We (me and @fuhlig1) suspect that this may partially be recursive (affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1. Go to this folder, load your ROOT environment. 1. Run. ```. root -l -b. root [0] .L alignment_map_def.h+. root [1] .x BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:3466,safety,input,input,3466,"iles/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1. Go to this folder, load your ROOT environment. 1. Run. ```. root -l -b. root [0] .L alignment_map_def.h+. root [1] .x BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT version. 3. Operating system. 5. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. - Fixed for now on the Fairroot side by [PR 1244](https://github.com/FairRootGroup/FairRoot/pull/1244/files#diff-91fa880fced775e0a97b72507da489affb1a15a59197901ae774ed40d6ca1ca1) ([Issue 1243](https://github.com/FairRootGroup/FairRoot/issues/1243)). - Unsure if this is a not-well documented intended behavior or an unexpected bug. - Adding a call to `gGeoManager->CloseGeometry();` instead of the fix used in FairRoot (as advised in [ROOT-7420](htt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:3728,safety,patch,patch,3728,"[1] .x BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT version. 3. Operating system. 5. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. - Fixed for now on the Fairroot side by [PR 1244](https://github.com/FairRootGroup/FairRoot/pull/1244/files#diff-91fa880fced775e0a97b72507da489affb1a15a59197901ae774ed40d6ca1ca1) ([Issue 1243](https://github.com/FairRootGroup/FairRoot/issues/1243)). - Unsure if this is a not-well documented intended behavior or an unexpected bug. - Adding a call to `gGeoManager->CloseGeometry();` instead of the fix used in FairRoot (as advised in [ROOT-7420](https://sft.its.cern.ch/jira/browse/ROOT-7420) for the AddNode case) does not cure the problem and results in a warning that the geometry is already closed. - I am not the author nor an expert of the section of code used to apply the alignment matrices in Fairsoft,",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:3803,safety,patch,patch,3803,"rices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT version. 3. Operating system. 5. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. - Fixed for now on the Fairroot side by [PR 1244](https://github.com/FairRootGroup/FairRoot/pull/1244/files#diff-91fa880fced775e0a97b72507da489affb1a15a59197901ae774ed40d6ca1ca1) ([Issue 1243](https://github.com/FairRootGroup/FairRoot/issues/1243)). - Unsure if this is a not-well documented intended behavior or an unexpected bug. - Adding a call to `gGeoManager->CloseGeometry();` instead of the fix used in FairRoot (as advised in [ROOT-7420](https://sft.its.cern.ch/jira/browse/ROOT-7420) for the AddNode case) does not cure the problem and results in a warning that the geometry is already closed. - I am not the author nor an expert of the section of code used to apply the alignment matrices in Fairsoft, which I copied in the example macro. For questions there I may have to for",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:96,security,rotat,rotation,96,"Zero size bounding box for some TGeoVolumeAssembly nodes after transformation by translation or rotation; - [x] Checked for duplicates. => Maybe linked/similar to https://sft.its.cern.ch/jira/browse/ROOT-7420 ? (Zero size BBox after using AddNode). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. After a translation/rotation is applied to a TGeoVolumeAssembly through the `MakePhysicalNode > Align` sequence, the BoundingBox of this TGeoVolumeAssembly may end up with 0 size (GetDX, GetDY and GetDZ returning 0). This is not expected as it means there are other effects on the Volume aside from the translation/rotation, even when shifting something without leaving its parent volume. Something similar happens if a translation/rotation is applied to a Node which is part of a TGeoVolumeAssembly, but there it probably happens only if the changes leads to part of the assembly exceeding the original boundaries. We (me and @fuhlig1) suspect that this may partially be recursive (affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for ex",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:621,security,rotat,rotation,621,"Zero size bounding box for some TGeoVolumeAssembly nodes after transformation by translation or rotation; - [x] Checked for duplicates. => Maybe linked/similar to https://sft.its.cern.ch/jira/browse/ROOT-7420 ? (Zero size BBox after using AddNode). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. After a translation/rotation is applied to a TGeoVolumeAssembly through the `MakePhysicalNode > Align` sequence, the BoundingBox of this TGeoVolumeAssembly may end up with 0 size (GetDX, GetDY and GetDZ returning 0). This is not expected as it means there are other effects on the Volume aside from the translation/rotation, even when shifting something without leaving its parent volume. Something similar happens if a translation/rotation is applied to a Node which is part of a TGeoVolumeAssembly, but there it probably happens only if the changes leads to part of the assembly exceeding the original boundaries. We (me and @fuhlig1) suspect that this may partially be recursive (affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for ex",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:916,security,rotat,rotation,916,"Zero size bounding box for some TGeoVolumeAssembly nodes after transformation by translation or rotation; - [x] Checked for duplicates. => Maybe linked/similar to https://sft.its.cern.ch/jira/browse/ROOT-7420 ? (Zero size BBox after using AddNode). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. After a translation/rotation is applied to a TGeoVolumeAssembly through the `MakePhysicalNode > Align` sequence, the BoundingBox of this TGeoVolumeAssembly may end up with 0 size (GetDX, GetDY and GetDZ returning 0). This is not expected as it means there are other effects on the Volume aside from the translation/rotation, even when shifting something without leaving its parent volume. Something similar happens if a translation/rotation is applied to a Node which is part of a TGeoVolumeAssembly, but there it probably happens only if the changes leads to part of the assembly exceeding the original boundaries. We (me and @fuhlig1) suspect that this may partially be recursive (affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for ex",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:1033,security,rotat,rotation,1033,"olumeAssembly nodes after transformation by translation or rotation; - [x] Checked for duplicates. => Maybe linked/similar to https://sft.its.cern.ch/jira/browse/ROOT-7420 ? (Zero size BBox after using AddNode). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. After a translation/rotation is applied to a TGeoVolumeAssembly through the `MakePhysicalNode > Align` sequence, the BoundingBox of this TGeoVolumeAssembly may end up with 0 size (GetDX, GetDY and GetDZ returning 0). This is not expected as it means there are other effects on the Volume aside from the translation/rotation, even when shifting something without leaving its parent volume. Something similar happens if a translation/rotation is applied to a Node which is part of a TGeoVolumeAssembly, but there it probably happens only if the changes leads to part of the assembly exceeding the original boundaries. We (me and @fuhlig1) suspect that this may partially be recursive (affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:1501,security,rotat,rotated,1501,"xisting report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. After a translation/rotation is applied to a TGeoVolumeAssembly through the `MakePhysicalNode > Align` sequence, the BoundingBox of this TGeoVolumeAssembly may end up with 0 size (GetDX, GetDY and GetDZ returning 0). This is not expected as it means there are other effects on the Volume aside from the translation/rotation, even when shifting something without leaving its parent volume. Something similar happens if a translation/rotation is applied to a Node which is part of a TGeoVolumeAssembly, but there it probably happens only if the changes leads to part of the assembly exceeding the original boundaries. We (me and @fuhlig1) suspect that this may partially be recursive (affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_20",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:1974,security,compl,complete,1974,"ent volume. Something similar happens if a translation/rotation is applied to a Node which is part of a TGeoVolumeAssembly, but there it probably happens only if the changes leads to part of the assembly exceeding the original boundaries. We (me and @fuhlig1) suspect that this may partially be recursive (affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1. Go to this folder, load your ROOT environment. 1. Run. ```. root -l -b. root [0] .L alignment_map_def.h+. root [1] .x BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:3728,security,patch,patch,3728,"[1] .x BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT version. 3. Operating system. 5. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. - Fixed for now on the Fairroot side by [PR 1244](https://github.com/FairRootGroup/FairRoot/pull/1244/files#diff-91fa880fced775e0a97b72507da489affb1a15a59197901ae774ed40d6ca1ca1) ([Issue 1243](https://github.com/FairRootGroup/FairRoot/issues/1243)). - Unsure if this is a not-well documented intended behavior or an unexpected bug. - Adding a call to `gGeoManager->CloseGeometry();` instead of the fix used in FairRoot (as advised in [ROOT-7420](https://sft.its.cern.ch/jira/browse/ROOT-7420) for the AddNode case) does not cure the problem and results in a warning that the geometry is already closed. - I am not the author nor an expert of the section of code used to apply the alignment matrices in Fairsoft,",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:3803,security,patch,patch,3803,"rices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT version. 3. Operating system. 5. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. - Fixed for now on the Fairroot side by [PR 1244](https://github.com/FairRootGroup/FairRoot/pull/1244/files#diff-91fa880fced775e0a97b72507da489affb1a15a59197901ae774ed40d6ca1ca1) ([Issue 1243](https://github.com/FairRootGroup/FairRoot/issues/1243)). - Unsure if this is a not-well documented intended behavior or an unexpected bug. - Adding a call to `gGeoManager->CloseGeometry();` instead of the fix used in FairRoot (as advised in [ROOT-7420](https://sft.its.cern.ch/jira/browse/ROOT-7420) for the AddNode case) does not cure the problem and results in a warning that the geometry is already closed. - I am not the author nor an expert of the section of code used to apply the alignment matrices in Fairsoft, which I copied in the example macro. For questions there I may have to for",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:4638,security,auth,author,4638," the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT version. 3. Operating system. 5. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. - Fixed for now on the Fairroot side by [PR 1244](https://github.com/FairRootGroup/FairRoot/pull/1244/files#diff-91fa880fced775e0a97b72507da489affb1a15a59197901ae774ed40d6ca1ca1) ([Issue 1243](https://github.com/FairRootGroup/FairRoot/issues/1243)). - Unsure if this is a not-well documented intended behavior or an unexpected bug. - Adding a call to `gGeoManager->CloseGeometry();` instead of the fix used in FairRoot (as advised in [ROOT-7420](https://sft.its.cern.ch/jira/browse/ROOT-7420) for the AddNode case) does not cure the problem and results in a warning that the geometry is already closed. - I am not the author nor an expert of the section of code used to apply the alignment matrices in Fairsoft, which I copied in the example macro. For questions there I may have to forward to the corresponding developers. - Investigation done by myself and @fuhlig1.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:1739,testability,simpl,simply,1739,"VolumeAssembly may end up with 0 size (GetDX, GetDY and GetDZ returning 0). This is not expected as it means there are other effects on the Volume aside from the translation/rotation, even when shifting something without leaving its parent volume. Something similar happens if a translation/rotation is applied to a Node which is part of a TGeoVolumeAssembly, but there it probably happens only if the changes leads to part of the assembly exceeding the original boundaries. We (me and @fuhlig1) suspect that this may partially be recursive (affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1. Go to this folder, load your ROOT environment. 1. Run. ```. root -l -b. root [0] .L alignment_map_def.h+. root [1] .x Bbox",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:4011,testability,context,context,4011," the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT version. 3. Operating system. 5. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. - Fixed for now on the Fairroot side by [PR 1244](https://github.com/FairRootGroup/FairRoot/pull/1244/files#diff-91fa880fced775e0a97b72507da489affb1a15a59197901ae774ed40d6ca1ca1) ([Issue 1243](https://github.com/FairRootGroup/FairRoot/issues/1243)). - Unsure if this is a not-well documented intended behavior or an unexpected bug. - Adding a call to `gGeoManager->CloseGeometry();` instead of the fix used in FairRoot (as advised in [ROOT-7420](https://sft.its.cern.ch/jira/browse/ROOT-7420) for the AddNode case) does not cure the problem and results in a warning that the geometry is already closed. - I am not the author nor an expert of the section of code used to apply the alignment matrices in Fairsoft, which I copied in the example macro. For questions there I may have to forward to the corresponding developers. - Investigation done by myself and @fuhlig1.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:1432,usability,behavi,behavior,1432," of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. After a translation/rotation is applied to a TGeoVolumeAssembly through the `MakePhysicalNode > Align` sequence, the BoundingBox of this TGeoVolumeAssembly may end up with 0 size (GetDX, GetDY and GetDZ returning 0). This is not expected as it means there are other effects on the Volume aside from the translation/rotation, even when shifting something without leaving its parent volume. Something similar happens if a translation/rotation is applied to a Node which is part of a TGeoVolumeAssembly, but there it probably happens only if the changes leads to part of the assembly exceeding the original boundaries. We (me and @fuhlig1) suspect that this may partially be recursive (affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:1570,usability,perform,performance,1570,">. ### Describe the bug. After a translation/rotation is applied to a TGeoVolumeAssembly through the `MakePhysicalNode > Align` sequence, the BoundingBox of this TGeoVolumeAssembly may end up with 0 size (GetDX, GetDY and GetDZ returning 0). This is not expected as it means there are other effects on the Volume aside from the translation/rotation, even when shifting something without leaving its parent volume. Something similar happens if a translation/rotation is applied to a Node which is part of a TGeoVolumeAssembly, but there it probably happens only if the changes leads to part of the assembly exceeding the original boundaries. We (me and @fuhlig1) suspect that this may partially be recursive (affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary he",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:1617,usability,hint,hint,1617,"n/rotation is applied to a TGeoVolumeAssembly through the `MakePhysicalNode > Align` sequence, the BoundingBox of this TGeoVolumeAssembly may end up with 0 size (GetDX, GetDY and GetDZ returning 0). This is not expected as it means there are other effects on the Volume aside from the translation/rotation, even when shifting something without leaving its parent volume. Something similar happens if a translation/rotation is applied to a Node which is part of a TGeoVolumeAssembly, but there it probably happens only if the changes leads to part of the assembly exceeding the original boundaries. We (me and @fuhlig1) suspect that this may partially be recursive (affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:1739,usability,simpl,simply,1739,"VolumeAssembly may end up with 0 size (GetDX, GetDY and GetDZ returning 0). This is not expected as it means there are other effects on the Volume aside from the translation/rotation, even when shifting something without leaving its parent volume. Something similar happens if a translation/rotation is applied to a Node which is part of a TGeoVolumeAssembly, but there it probably happens only if the changes leads to part of the assembly exceeding the original boundaries. We (me and @fuhlig1) suspect that this may partially be recursive (affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1. Go to this folder, load your ROOT environment. 1. Run. ```. root -l -b. root [0] .L alignment_map_def.h+. root [1] .x Bbox",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:2061,usability,behavi,behavior,2061,"ich is part of a TGeoVolumeAssembly, but there it probably happens only if the changes leads to part of the assembly exceeding the original boundaries. We (me and @fuhlig1) suspect that this may partially be recursive (affecting the parent of the aligned volume). This can be cured by forcing the recomputation of the BoundingBox of the affected Volume. ### Expected behavior. After alignment of the nodes, all volumes/nodes are offset/rotated with their other properties valid. Or if not possible due to performance, a warning should be printout with hint of the proper way to restore/recompute these values. A temporary fix was introduced for now in FairRoot, which is to simply do the recompute for all TGeoVolumeAssembly in the geometry tree, which seems to be fast enough that we do not have to try to track affected Volumes to be more selective. . This may however not be the case later when applied to complete geometries for experiments like CBM. ### To Reproduce. Steps to reproduce the behavior with the attached files (includes ""ROOT-only"" examples both for problem and for macro-level fix):. 1. Compile a copy of ROOT 6.22.08 (done with FairSoft apr21p2 and FairRoot v18.6.7, should work with any older versions of each and with recent versions of FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1. Go to this folder, load your ROOT environment. 1. Run. ```. root -l -b. root [0] .L alignment_map_def.h+. root [1] .x BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:3321,usability,behavi,behavior,3321,"FairRoot, as well as with a standalone version of ROOT). 1. Download [BboxAlignPb_example_2023_02_07.zip](https://github.com/root-project/root/files/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1. Go to this folder, load your ROOT environment. 1. Run. ```. root -l -b. root [0] .L alignment_map_def.h+. root [1] .x BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT version. 3. Operating system. 5. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. - Fixed for now on the Fairroot side by [PR 1244](https://github.com/FairRootGroup/FairRoot/pull/1244/files#diff-91fa880fced775e0a97b72507da489affb1a15a59197901ae774ed40d6ca1ca1) ([Issue 1243](https://github.com/FairRootGroup/FairRoot/issues/1243)). - Unsure if this is a not-well documented intended beha",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:3466,usability,input,input,3466,"iles/10674368/BboxAlignPb_example_2023_02_07.zip) and unzip the macro, the standard container dictionary header and the two root files in a folder. 1. Go to this folder, load your ROOT environment. 1. Run. ```. root -l -b. root [0] .L alignment_map_def.h+. root [1] .x BboxAlignBug.C(""mcbm_beam_2022_05_23_nickel.geo.root"", ""AlignmentMatrices_mcbm_beam_2022_05_23_nickel.root""). ```. Of the 3 transformations visible in the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT version. 3. Operating system. 5. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. - Fixed for now on the Fairroot side by [PR 1244](https://github.com/FairRootGroup/FairRoot/pull/1244/files#diff-91fa880fced775e0a97b72507da489affb1a15a59197901ae774ed40d6ca1ca1) ([Issue 1243](https://github.com/FairRootGroup/FairRoot/issues/1243)). - Unsure if this is a not-well documented intended behavior or an unexpected bug. - Adding a call to `gGeoManager->CloseGeometry();` instead of the fix used in FairRoot (as advised in [ROOT-7420](htt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:4301,usability,document,documented,4301," the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT version. 3. Operating system. 5. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. - Fixed for now on the Fairroot side by [PR 1244](https://github.com/FairRootGroup/FairRoot/pull/1244/files#diff-91fa880fced775e0a97b72507da489affb1a15a59197901ae774ed40d6ca1ca1) ([Issue 1243](https://github.com/FairRootGroup/FairRoot/issues/1243)). - Unsure if this is a not-well documented intended behavior or an unexpected bug. - Adding a call to `gGeoManager->CloseGeometry();` instead of the fix used in FairRoot (as advised in [ROOT-7420](https://sft.its.cern.ch/jira/browse/ROOT-7420) for the AddNode case) does not cure the problem and results in a warning that the geometry is already closed. - I am not the author nor an expert of the section of code used to apply the alignment matrices in Fairsoft, which I copied in the example macro. For questions there I may have to forward to the corresponding developers. - Investigation done by myself and @fuhlig1.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:4321,usability,behavi,behavior,4321," the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT version. 3. Operating system. 5. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. - Fixed for now on the Fairroot side by [PR 1244](https://github.com/FairRootGroup/FairRoot/pull/1244/files#diff-91fa880fced775e0a97b72507da489affb1a15a59197901ae774ed40d6ca1ca1) ([Issue 1243](https://github.com/FairRootGroup/FairRoot/issues/1243)). - Unsure if this is a not-well documented intended behavior or an unexpected bug. - Adding a call to `gGeoManager->CloseGeometry();` instead of the fix used in FairRoot (as advised in [ROOT-7420](https://sft.its.cern.ch/jira/browse/ROOT-7420) for the AddNode case) does not cure the problem and results in a warning that the geometry is already closed. - I am not the author nor an expert of the section of code used to apply the alignment matrices in Fairsoft, which I copied in the example macro. For questions there I may have to forward to the corresponding developers. - Investigation done by myself and @fuhlig1.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:4385,usability,Close,CloseGeometry,4385," the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT version. 3. Operating system. 5. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. - Fixed for now on the Fairroot side by [PR 1244](https://github.com/FairRootGroup/FairRoot/pull/1244/files#diff-91fa880fced775e0a97b72507da489affb1a15a59197901ae774ed40d6ca1ca1) ([Issue 1243](https://github.com/FairRootGroup/FairRoot/issues/1243)). - Unsure if this is a not-well documented intended behavior or an unexpected bug. - Adding a call to `gGeoManager->CloseGeometry();` instead of the fix used in FairRoot (as advised in [ROOT-7420](https://sft.its.cern.ch/jira/browse/ROOT-7420) for the AddNode case) does not cure the problem and results in a warning that the geometry is already closed. - I am not the author nor an expert of the section of code used to apply the alignment matrices in Fairsoft, which I copied in the example macro. For questions there I may have to forward to the corresponding developers. - Investigation done by myself and @fuhlig1.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/issues/12242:4615,usability,close,closed,4615," the printout. - Two are applied to TGeoVolumeAssembly objects and lead to these assembly having zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0` and `/cave_1/sts_v22e_mcbm_0/Station01_1`). - One is applied to a Node and leads to 2 TGeoVolumeAssembly higher in the hierarchy to have zero size bounding boxes (`/cave_1/sts_v22e_mcbm_0/Station02_2/Ladder10_2/HalfLadder10d_2/HalfLadder10d_Module04_2`). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 3. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT 6.22.08, 6.26.10. 1. OS: Debian 8, Debian 10, Ubuntu 20.04. 1. Compiler: GCC > 8. 1. ROOT provided (compilation/installation) from:. - FairSoft apr21 (and patch releases) for 6.22, Legacy mode (""not Spack""). - FairSoft nov22 (and patch releases) for 6.26, Legacy mode (""not Spack""). <!--. 1. ROOT version. 3. Operating system. 5. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ### Additional context. - Fixed for now on the Fairroot side by [PR 1244](https://github.com/FairRootGroup/FairRoot/pull/1244/files#diff-91fa880fced775e0a97b72507da489affb1a15a59197901ae774ed40d6ca1ca1) ([Issue 1243](https://github.com/FairRootGroup/FairRoot/issues/1243)). - Unsure if this is a not-well documented intended behavior or an unexpected bug. - Adding a call to `gGeoManager->CloseGeometry();` instead of the fix used in FairRoot (as advised in [ROOT-7420](https://sft.its.cern.ch/jira/browse/ROOT-7420) for the AddNode case) does not cure the problem and results in a warning that the geometry is already closed. - I am not the author nor an expert of the section of code used to apply the alignment matrices in Fairsoft, which I copied in the example macro. For questions there I may have to forward to the corresponding developers. - Investigation done by myself and @fuhlig1.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12242
https://github.com/root-project/root/pull/12243:94,availability,failur,failure,94,Don't cast a TDirectory pointer argument to a Long_t (even if its value is 0); Should fix the failure of tutorial/tree/run_h1analysis.C on Win64,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12243
https://github.com/root-project/root/pull/12243:94,deployability,fail,failure,94,Don't cast a TDirectory pointer argument to a Long_t (even if its value is 0); Should fix the failure of tutorial/tree/run_h1analysis.C on Win64,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12243
https://github.com/root-project/root/pull/12243:94,performance,failur,failure,94,Don't cast a TDirectory pointer argument to a Long_t (even if its value is 0); Should fix the failure of tutorial/tree/run_h1analysis.C on Win64,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12243
https://github.com/root-project/root/pull/12243:94,reliability,fail,failure,94,Don't cast a TDirectory pointer argument to a Long_t (even if its value is 0); Should fix the failure of tutorial/tree/run_h1analysis.C on Win64,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12243
https://github.com/root-project/root/pull/12245:200,energy efficiency,draw,drawn,200,"[webcanvas] support reverse axes on lego plots; Also fixing several other issues:. - labels with reverse axes. - correct zooming in ratio plots. - customized stats box. - suppress title for histogram drawn with ""same"" draw option. Many syntax improvements in JSROOT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12245
https://github.com/root-project/root/pull/12245:218,energy efficiency,draw,draw,218,"[webcanvas] support reverse axes on lego plots; Also fixing several other issues:. - labels with reverse axes. - correct zooming in ratio plots. - customized stats box. - suppress title for histogram drawn with ""same"" draw option. Many syntax improvements in JSROOT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12245
https://github.com/root-project/root/pull/12245:12,usability,support,support,12,"[webcanvas] support reverse axes on lego plots; Also fixing several other issues:. - labels with reverse axes. - correct zooming in ratio plots. - customized stats box. - suppress title for histogram drawn with ""same"" draw option. Many syntax improvements in JSROOT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12245
https://github.com/root-project/root/pull/12245:147,usability,custom,customized,147,"[webcanvas] support reverse axes on lego plots; Also fixing several other issues:. - labels with reverse axes. - correct zooming in ratio plots. - customized stats box. - suppress title for histogram drawn with ""same"" draw option. Many syntax improvements in JSROOT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12245
https://github.com/root-project/root/pull/12246:174,energy efficiency,draw,draw,174,Fixes in web canvas and JSROOT for 6.28 branch; 1. Do not create title for second histogram in web canvas. 2. Preserve custom stats box. 3. Properly handle violin and candle draw options. 4. Labels position on reversed axes,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12246
https://github.com/root-project/root/pull/12246:119,usability,custom,custom,119,Fixes in web canvas and JSROOT for 6.28 branch; 1. Do not create title for second histogram in web canvas. 2. Preserve custom stats box. 3. Properly handle violin and candle draw options. 4. Labels position on reversed axes,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12246
https://github.com/root-project/root/pull/12247:8,deployability,Updat,Update,8,[CMake] Update XRootD builtin to version 5.5.2; I also uploaded the tarball to lcgpackages so builds using the new builtin should work fine.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12247
https://github.com/root-project/root/pull/12247:33,deployability,version,version,33,[CMake] Update XRootD builtin to version 5.5.2; I also uploaded the tarball to lcgpackages so builds using the new builtin should work fine.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12247
https://github.com/root-project/root/pull/12247:94,deployability,build,builds,94,[CMake] Update XRootD builtin to version 5.5.2; I also uploaded the tarball to lcgpackages so builds using the new builtin should work fine.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12247
https://github.com/root-project/root/pull/12247:33,integrability,version,version,33,[CMake] Update XRootD builtin to version 5.5.2; I also uploaded the tarball to lcgpackages so builds using the new builtin should work fine.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12247
https://github.com/root-project/root/pull/12247:33,modifiability,version,version,33,[CMake] Update XRootD builtin to version 5.5.2; I also uploaded the tarball to lcgpackages so builds using the new builtin should work fine.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12247
https://github.com/root-project/root/pull/12247:8,safety,Updat,Update,8,[CMake] Update XRootD builtin to version 5.5.2; I also uploaded the tarball to lcgpackages so builds using the new builtin should work fine.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12247
https://github.com/root-project/root/pull/12247:8,security,Updat,Update,8,[CMake] Update XRootD builtin to version 5.5.2; I also uploaded the tarball to lcgpackages so builds using the new builtin should work fine.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12247
https://github.com/root-project/root/pull/12250:4,deployability,build,build,4,Fix build with -Dbuiltin_gtest:BOOL=OFF on EPEL 8; # This Pull request:. ## Changes or fixes:. Some new tests need the backward compatibility tweaks to work with the system gtest on RHEL/EPEL 8. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12250
https://github.com/root-project/root/pull/12250:246,deployability,updat,updated,246,Fix build with -Dbuiltin_gtest:BOOL=OFF on EPEL 8; # This Pull request:. ## Changes or fixes:. Some new tests need the backward compatibility tweaks to work with the system gtest on RHEL/EPEL 8. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12250
https://github.com/root-project/root/pull/12250:128,interoperability,compatib,compatibility,128,Fix build with -Dbuiltin_gtest:BOOL=OFF on EPEL 8; # This Pull request:. ## Changes or fixes:. Some new tests need the backward compatibility tweaks to work with the system gtest on RHEL/EPEL 8. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12250
https://github.com/root-project/root/pull/12250:104,safety,test,tests,104,Fix build with -Dbuiltin_gtest:BOOL=OFF on EPEL 8; # This Pull request:. ## Changes or fixes:. Some new tests need the backward compatibility tweaks to work with the system gtest on RHEL/EPEL 8. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12250
https://github.com/root-project/root/pull/12250:216,safety,test,tested,216,Fix build with -Dbuiltin_gtest:BOOL=OFF on EPEL 8; # This Pull request:. ## Changes or fixes:. Some new tests need the backward compatibility tweaks to work with the system gtest on RHEL/EPEL 8. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12250
https://github.com/root-project/root/pull/12250:246,safety,updat,updated,246,Fix build with -Dbuiltin_gtest:BOOL=OFF on EPEL 8; # This Pull request:. ## Changes or fixes:. Some new tests need the backward compatibility tweaks to work with the system gtest on RHEL/EPEL 8. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12250
https://github.com/root-project/root/pull/12250:246,security,updat,updated,246,Fix build with -Dbuiltin_gtest:BOOL=OFF on EPEL 8; # This Pull request:. ## Changes or fixes:. Some new tests need the backward compatibility tweaks to work with the system gtest on RHEL/EPEL 8. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12250
https://github.com/root-project/root/pull/12250:104,testability,test,tests,104,Fix build with -Dbuiltin_gtest:BOOL=OFF on EPEL 8; # This Pull request:. ## Changes or fixes:. Some new tests need the backward compatibility tweaks to work with the system gtest on RHEL/EPEL 8. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12250
https://github.com/root-project/root/pull/12250:216,testability,test,tested,216,Fix build with -Dbuiltin_gtest:BOOL=OFF on EPEL 8; # This Pull request:. ## Changes or fixes:. Some new tests need the backward compatibility tweaks to work with the system gtest on RHEL/EPEL 8. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12250
https://github.com/root-project/root/issues/12251:1663,deployability,contain,contain,1663,"ble_t[1];. p[0] = 0.5;. Double_t *q = new Double_t[1];. q[0] = 0;. h->GetQuantiles(1,q,p);. cout << ""Median of h:"" << q[0] << std::endl;. cout << ""This is ok!"" << endl;. TH1D *h2 = new TH1D(""h2"",""h2"",10,0,10);. //for (int i = 0; i < 10; ++i) h2->Fill(i); . h2->Fill(2);. h2->Fill(8);. c1->cd(2);. h2->Draw();. Double_t *p2 = new Double_t[1];. p2[0] = 0.5;. Double_t *q2 = new Double_t[1];. q2[0] = 0;. int nq = h2->GetQuantiles(1,q2,p2);. cout << ""Median of h2 (and is never the same result when you execute the macro several times).: "" << q2[0] << "" nq = "" << nq << std::endl;. cout << ""NO!!! should be 5.5 as well"" << endl;. }. ```. and the one from the forum:. ```. new TCanvas();. TH1F *h = new TH1F(""hb"", ""hb"", 30, -100., 200.); h->Draw();. for(int j = 11; j <= 20; j++) h->SetBinContent(j, 1.);. const int nq = 100;. double xq[(nq + 1)]; // positions where to compute the quantiles in [0., 1.]. for(int j = 0; j <= nq; j++) xq[j] = double(j) / double(nq);. double yq[(nq + 1)]; // array to contain the quantiles. h->GetQuantiles(nq + 1, yq, xq);. // note: ""0 %"" should return 0 and ""100 %"" should return 100. for(int j = 0; j <= nq; j++) std::cout << j << "" % : "" << yq[j] << ""\n"";. ```. or all-together:. ```. #include ""TCanvas.h"". #include <iostream>. #include ""TH1D.h"". #include ""TH1F.h"". using std::cout, std::endl;. void quantiles() {. TCanvas *c1 = new TCanvas();. c1->Divide(1,2);. TH1D *h = new TH1D(""h"",""h"",10,0,10);. h->Fill(5);. c1->cd(1);. h->Draw();. Double_t *p = new Double_t[3];. p[0] = 0.;. p[1] = 0.5;. p[2] = 1;. Double_t *q = new Double_t[3];. h->GetQuantiles(3,q,p);. cout << ""Median of h:"" << q[0] << "" "" << q[1] << "" "" << q[2] << std::endl;. cout << ""This is ok!"" << endl;. TH1D *h2 = new TH1D(""h2"",""h2"",10,0,10);. //for (int i = 0; i < 10; ++i) h2->Fill(i);. h2->Fill(2);. h2->Fill(8);. c1->cd(2);. h2->Draw();. Double_t *q2 = new Double_t[3];. int nq = h2->GetQuantiles(3,q2,p);. cout << ""Median of h2:"" << q2[0] << "" "" << q2[1] << "" "" << q2[2] << std::endl;. cout << """,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12251
https://github.com/root-project/root/issues/12251:3017,deployability,contain,contain,3017," nq = "" << nq << std::endl;. cout << ""NO!!! should be 5.5 as well"" << endl;. }. ```. and the one from the forum:. ```. new TCanvas();. TH1F *h = new TH1F(""hb"", ""hb"", 30, -100., 200.); h->Draw();. for(int j = 11; j <= 20; j++) h->SetBinContent(j, 1.);. const int nq = 100;. double xq[(nq + 1)]; // positions where to compute the quantiles in [0., 1.]. for(int j = 0; j <= nq; j++) xq[j] = double(j) / double(nq);. double yq[(nq + 1)]; // array to contain the quantiles. h->GetQuantiles(nq + 1, yq, xq);. // note: ""0 %"" should return 0 and ""100 %"" should return 100. for(int j = 0; j <= nq; j++) std::cout << j << "" % : "" << yq[j] << ""\n"";. ```. or all-together:. ```. #include ""TCanvas.h"". #include <iostream>. #include ""TH1D.h"". #include ""TH1F.h"". using std::cout, std::endl;. void quantiles() {. TCanvas *c1 = new TCanvas();. c1->Divide(1,2);. TH1D *h = new TH1D(""h"",""h"",10,0,10);. h->Fill(5);. c1->cd(1);. h->Draw();. Double_t *p = new Double_t[3];. p[0] = 0.;. p[1] = 0.5;. p[2] = 1;. Double_t *q = new Double_t[3];. h->GetQuantiles(3,q,p);. cout << ""Median of h:"" << q[0] << "" "" << q[1] << "" "" << q[2] << std::endl;. cout << ""This is ok!"" << endl;. TH1D *h2 = new TH1D(""h2"",""h2"",10,0,10);. //for (int i = 0; i < 10; ++i) h2->Fill(i);. h2->Fill(2);. h2->Fill(8);. c1->cd(2);. h2->Draw();. Double_t *q2 = new Double_t[3];. int nq = h2->GetQuantiles(3,q2,p);. cout << ""Median of h2:"" << q2[0] << "" "" << q2[1] << "" "" << q2[2] << std::endl;. cout << ""NO!!! should be 5.5 as well"" << endl;. new TCanvas();. h = new TH1D(""hb"", ""hb"", 30, -100., 200.); h->Draw();. for(int j = 11; j <= 20; j++) h->SetBinContent(j, 1.);. nq = 100;. double xq[(nq + 1)]; // positions where to compute the quantiles in [0., 1.]. for(int j = 0; j <= nq; j++) xq[j] = double(j) / double(nq);. double yq[(nq + 1)]; // array to contain the quantiles. h->GetQuantiles(nq + 1, yq, xq);. // note: ""0 %"" should return 0 and ""100 %"" should return 100. for(int j = 0; j <= nq; j++) std::cout << j << "" % : "" << yq[j] << ""\n"";. }. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12251
https://github.com/root-project/root/issues/12251:637,energy efficiency,Draw,Draw,637,"Problems with `TH1::GetQuantiles`; The function `TH1::GetQuantile` is not returning in some case the correct result. . There is already this JIRA issue open: https://sft.its.cern.ch/jira/browse/ROOT-8085. and not it is reported that gives wrong values for 0 and 100 percentiles, see: . https://root-forum.cern.ch/t/th1-getquantiles-gives-wrong-value-for-100-percentile/53284/3. See this example from JIRA:. ```. #include ""TCanvas.h"". #include <iostream>. #include ""TH1D.h"". using std::cout, std::endl;. void quantiles() {. TCanvas *c1 = new TCanvas();. c1->Divide(1,2);. TH1D *h = new TH1D(""h"",""h"",10,0,10);. h->Fill(5);. c1->cd(1);. h->Draw();. Double_t *p = new Double_t[1];. p[0] = 0.5;. Double_t *q = new Double_t[1];. q[0] = 0;. h->GetQuantiles(1,q,p);. cout << ""Median of h:"" << q[0] << std::endl;. cout << ""This is ok!"" << endl;. TH1D *h2 = new TH1D(""h2"",""h2"",10,0,10);. //for (int i = 0; i < 10; ++i) h2->Fill(i); . h2->Fill(2);. h2->Fill(8);. c1->cd(2);. h2->Draw();. Double_t *p2 = new Double_t[1];. p2[0] = 0.5;. Double_t *q2 = new Double_t[1];. q2[0] = 0;. int nq = h2->GetQuantiles(1,q2,p2);. cout << ""Median of h2 (and is never the same result when you execute the macro several times).: "" << q2[0] << "" nq = "" << nq << std::endl;. cout << ""NO!!! should be 5.5 as well"" << endl;. }. ```. and the one from the forum:. ```. new TCanvas();. TH1F *h = new TH1F(""hb"", ""hb"", 30, -100., 200.); h->Draw();. for(int j = 11; j <= 20; j++) h->SetBinContent(j, 1.);. const int nq = 100;. double xq[(nq + 1)]; // positions where to compute the quantiles in [0., 1.]. for(int j = 0; j <= nq; j++) xq[j] = double(j) / double(nq);. double yq[(nq + 1)]; // array to contain the quantiles. h->GetQuantiles(nq + 1, yq, xq);. // note: ""0 %"" should return 0 and ""100 %"" should return 100. for(int j = 0; j <= nq; j++) std::cout << j << "" % : "" << yq[j] << ""\n"";. ```. or all-together:. ```. #include ""TCanvas.h"". #include <iostream>. #include ""TH1D.h"". #include ""TH1F.h"". using std::cout, std::endl;. void q",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12251
https://github.com/root-project/root/issues/12251:968,energy efficiency,Draw,Draw,968,"Problems with `TH1::GetQuantiles`; The function `TH1::GetQuantile` is not returning in some case the correct result. . There is already this JIRA issue open: https://sft.its.cern.ch/jira/browse/ROOT-8085. and not it is reported that gives wrong values for 0 and 100 percentiles, see: . https://root-forum.cern.ch/t/th1-getquantiles-gives-wrong-value-for-100-percentile/53284/3. See this example from JIRA:. ```. #include ""TCanvas.h"". #include <iostream>. #include ""TH1D.h"". using std::cout, std::endl;. void quantiles() {. TCanvas *c1 = new TCanvas();. c1->Divide(1,2);. TH1D *h = new TH1D(""h"",""h"",10,0,10);. h->Fill(5);. c1->cd(1);. h->Draw();. Double_t *p = new Double_t[1];. p[0] = 0.5;. Double_t *q = new Double_t[1];. q[0] = 0;. h->GetQuantiles(1,q,p);. cout << ""Median of h:"" << q[0] << std::endl;. cout << ""This is ok!"" << endl;. TH1D *h2 = new TH1D(""h2"",""h2"",10,0,10);. //for (int i = 0; i < 10; ++i) h2->Fill(i); . h2->Fill(2);. h2->Fill(8);. c1->cd(2);. h2->Draw();. Double_t *p2 = new Double_t[1];. p2[0] = 0.5;. Double_t *q2 = new Double_t[1];. q2[0] = 0;. int nq = h2->GetQuantiles(1,q2,p2);. cout << ""Median of h2 (and is never the same result when you execute the macro several times).: "" << q2[0] << "" nq = "" << nq << std::endl;. cout << ""NO!!! should be 5.5 as well"" << endl;. }. ```. and the one from the forum:. ```. new TCanvas();. TH1F *h = new TH1F(""hb"", ""hb"", 30, -100., 200.); h->Draw();. for(int j = 11; j <= 20; j++) h->SetBinContent(j, 1.);. const int nq = 100;. double xq[(nq + 1)]; // positions where to compute the quantiles in [0., 1.]. for(int j = 0; j <= nq; j++) xq[j] = double(j) / double(nq);. double yq[(nq + 1)]; // array to contain the quantiles. h->GetQuantiles(nq + 1, yq, xq);. // note: ""0 %"" should return 0 and ""100 %"" should return 100. for(int j = 0; j <= nq; j++) std::cout << j << "" % : "" << yq[j] << ""\n"";. ```. or all-together:. ```. #include ""TCanvas.h"". #include <iostream>. #include ""TH1D.h"". #include ""TH1F.h"". using std::cout, std::endl;. void q",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12251
https://github.com/root-project/root/issues/12251:1404,energy efficiency,Draw,Draw,1404," ```. #include ""TCanvas.h"". #include <iostream>. #include ""TH1D.h"". using std::cout, std::endl;. void quantiles() {. TCanvas *c1 = new TCanvas();. c1->Divide(1,2);. TH1D *h = new TH1D(""h"",""h"",10,0,10);. h->Fill(5);. c1->cd(1);. h->Draw();. Double_t *p = new Double_t[1];. p[0] = 0.5;. Double_t *q = new Double_t[1];. q[0] = 0;. h->GetQuantiles(1,q,p);. cout << ""Median of h:"" << q[0] << std::endl;. cout << ""This is ok!"" << endl;. TH1D *h2 = new TH1D(""h2"",""h2"",10,0,10);. //for (int i = 0; i < 10; ++i) h2->Fill(i); . h2->Fill(2);. h2->Fill(8);. c1->cd(2);. h2->Draw();. Double_t *p2 = new Double_t[1];. p2[0] = 0.5;. Double_t *q2 = new Double_t[1];. q2[0] = 0;. int nq = h2->GetQuantiles(1,q2,p2);. cout << ""Median of h2 (and is never the same result when you execute the macro several times).: "" << q2[0] << "" nq = "" << nq << std::endl;. cout << ""NO!!! should be 5.5 as well"" << endl;. }. ```. and the one from the forum:. ```. new TCanvas();. TH1F *h = new TH1F(""hb"", ""hb"", 30, -100., 200.); h->Draw();. for(int j = 11; j <= 20; j++) h->SetBinContent(j, 1.);. const int nq = 100;. double xq[(nq + 1)]; // positions where to compute the quantiles in [0., 1.]. for(int j = 0; j <= nq; j++) xq[j] = double(j) / double(nq);. double yq[(nq + 1)]; // array to contain the quantiles. h->GetQuantiles(nq + 1, yq, xq);. // note: ""0 %"" should return 0 and ""100 %"" should return 100. for(int j = 0; j <= nq; j++) std::cout << j << "" % : "" << yq[j] << ""\n"";. ```. or all-together:. ```. #include ""TCanvas.h"". #include <iostream>. #include ""TH1D.h"". #include ""TH1F.h"". using std::cout, std::endl;. void quantiles() {. TCanvas *c1 = new TCanvas();. c1->Divide(1,2);. TH1D *h = new TH1D(""h"",""h"",10,0,10);. h->Fill(5);. c1->cd(1);. h->Draw();. Double_t *p = new Double_t[3];. p[0] = 0.;. p[1] = 0.5;. p[2] = 1;. Double_t *q = new Double_t[3];. h->GetQuantiles(3,q,p);. cout << ""Median of h:"" << q[0] << "" "" << q[1] << "" "" << q[2] << std::endl;. cout << ""This is ok!"" << endl;. TH1D *h2 = new TH1D(""h2"",""h2"",10,0,1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12251
https://github.com/root-project/root/issues/12251:2128,energy efficiency,Draw,Draw,2128,"nd is never the same result when you execute the macro several times).: "" << q2[0] << "" nq = "" << nq << std::endl;. cout << ""NO!!! should be 5.5 as well"" << endl;. }. ```. and the one from the forum:. ```. new TCanvas();. TH1F *h = new TH1F(""hb"", ""hb"", 30, -100., 200.); h->Draw();. for(int j = 11; j <= 20; j++) h->SetBinContent(j, 1.);. const int nq = 100;. double xq[(nq + 1)]; // positions where to compute the quantiles in [0., 1.]. for(int j = 0; j <= nq; j++) xq[j] = double(j) / double(nq);. double yq[(nq + 1)]; // array to contain the quantiles. h->GetQuantiles(nq + 1, yq, xq);. // note: ""0 %"" should return 0 and ""100 %"" should return 100. for(int j = 0; j <= nq; j++) std::cout << j << "" % : "" << yq[j] << ""\n"";. ```. or all-together:. ```. #include ""TCanvas.h"". #include <iostream>. #include ""TH1D.h"". #include ""TH1F.h"". using std::cout, std::endl;. void quantiles() {. TCanvas *c1 = new TCanvas();. c1->Divide(1,2);. TH1D *h = new TH1D(""h"",""h"",10,0,10);. h->Fill(5);. c1->cd(1);. h->Draw();. Double_t *p = new Double_t[3];. p[0] = 0.;. p[1] = 0.5;. p[2] = 1;. Double_t *q = new Double_t[3];. h->GetQuantiles(3,q,p);. cout << ""Median of h:"" << q[0] << "" "" << q[1] << "" "" << q[2] << std::endl;. cout << ""This is ok!"" << endl;. TH1D *h2 = new TH1D(""h2"",""h2"",10,0,10);. //for (int i = 0; i < 10; ++i) h2->Fill(i);. h2->Fill(2);. h2->Fill(8);. c1->cd(2);. h2->Draw();. Double_t *q2 = new Double_t[3];. int nq = h2->GetQuantiles(3,q2,p);. cout << ""Median of h2:"" << q2[0] << "" "" << q2[1] << "" "" << q2[2] << std::endl;. cout << ""NO!!! should be 5.5 as well"" << endl;. new TCanvas();. h = new TH1D(""hb"", ""hb"", 30, -100., 200.); h->Draw();. for(int j = 11; j <= 20; j++) h->SetBinContent(j, 1.);. nq = 100;. double xq[(nq + 1)]; // positions where to compute the quantiles in [0., 1.]. for(int j = 0; j <= nq; j++) xq[j] = double(j) / double(nq);. double yq[(nq + 1)]; // array to contain the quantiles. h->GetQuantiles(nq + 1, yq, xq);. // note: ""0 %"" should return 0 and ""100 %"" should return",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12251
https://github.com/root-project/root/issues/12251:2500,energy efficiency,Draw,Draw,2500," nq = "" << nq << std::endl;. cout << ""NO!!! should be 5.5 as well"" << endl;. }. ```. and the one from the forum:. ```. new TCanvas();. TH1F *h = new TH1F(""hb"", ""hb"", 30, -100., 200.); h->Draw();. for(int j = 11; j <= 20; j++) h->SetBinContent(j, 1.);. const int nq = 100;. double xq[(nq + 1)]; // positions where to compute the quantiles in [0., 1.]. for(int j = 0; j <= nq; j++) xq[j] = double(j) / double(nq);. double yq[(nq + 1)]; // array to contain the quantiles. h->GetQuantiles(nq + 1, yq, xq);. // note: ""0 %"" should return 0 and ""100 %"" should return 100. for(int j = 0; j <= nq; j++) std::cout << j << "" % : "" << yq[j] << ""\n"";. ```. or all-together:. ```. #include ""TCanvas.h"". #include <iostream>. #include ""TH1D.h"". #include ""TH1F.h"". using std::cout, std::endl;. void quantiles() {. TCanvas *c1 = new TCanvas();. c1->Divide(1,2);. TH1D *h = new TH1D(""h"",""h"",10,0,10);. h->Fill(5);. c1->cd(1);. h->Draw();. Double_t *p = new Double_t[3];. p[0] = 0.;. p[1] = 0.5;. p[2] = 1;. Double_t *q = new Double_t[3];. h->GetQuantiles(3,q,p);. cout << ""Median of h:"" << q[0] << "" "" << q[1] << "" "" << q[2] << std::endl;. cout << ""This is ok!"" << endl;. TH1D *h2 = new TH1D(""h2"",""h2"",10,0,10);. //for (int i = 0; i < 10; ++i) h2->Fill(i);. h2->Fill(2);. h2->Fill(8);. c1->cd(2);. h2->Draw();. Double_t *q2 = new Double_t[3];. int nq = h2->GetQuantiles(3,q2,p);. cout << ""Median of h2:"" << q2[0] << "" "" << q2[1] << "" "" << q2[2] << std::endl;. cout << ""NO!!! should be 5.5 as well"" << endl;. new TCanvas();. h = new TH1D(""hb"", ""hb"", 30, -100., 200.); h->Draw();. for(int j = 11; j <= 20; j++) h->SetBinContent(j, 1.);. nq = 100;. double xq[(nq + 1)]; // positions where to compute the quantiles in [0., 1.]. for(int j = 0; j <= nq; j++) xq[j] = double(j) / double(nq);. double yq[(nq + 1)]; // array to contain the quantiles. h->GetQuantiles(nq + 1, yq, xq);. // note: ""0 %"" should return 0 and ""100 %"" should return 100. for(int j = 0; j <= nq; j++) std::cout << j << "" % : "" << yq[j] << ""\n"";. }. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12251
https://github.com/root-project/root/issues/12251:2768,energy efficiency,Draw,Draw,2768," nq = "" << nq << std::endl;. cout << ""NO!!! should be 5.5 as well"" << endl;. }. ```. and the one from the forum:. ```. new TCanvas();. TH1F *h = new TH1F(""hb"", ""hb"", 30, -100., 200.); h->Draw();. for(int j = 11; j <= 20; j++) h->SetBinContent(j, 1.);. const int nq = 100;. double xq[(nq + 1)]; // positions where to compute the quantiles in [0., 1.]. for(int j = 0; j <= nq; j++) xq[j] = double(j) / double(nq);. double yq[(nq + 1)]; // array to contain the quantiles. h->GetQuantiles(nq + 1, yq, xq);. // note: ""0 %"" should return 0 and ""100 %"" should return 100. for(int j = 0; j <= nq; j++) std::cout << j << "" % : "" << yq[j] << ""\n"";. ```. or all-together:. ```. #include ""TCanvas.h"". #include <iostream>. #include ""TH1D.h"". #include ""TH1F.h"". using std::cout, std::endl;. void quantiles() {. TCanvas *c1 = new TCanvas();. c1->Divide(1,2);. TH1D *h = new TH1D(""h"",""h"",10,0,10);. h->Fill(5);. c1->cd(1);. h->Draw();. Double_t *p = new Double_t[3];. p[0] = 0.;. p[1] = 0.5;. p[2] = 1;. Double_t *q = new Double_t[3];. h->GetQuantiles(3,q,p);. cout << ""Median of h:"" << q[0] << "" "" << q[1] << "" "" << q[2] << std::endl;. cout << ""This is ok!"" << endl;. TH1D *h2 = new TH1D(""h2"",""h2"",10,0,10);. //for (int i = 0; i < 10; ++i) h2->Fill(i);. h2->Fill(2);. h2->Fill(8);. c1->cd(2);. h2->Draw();. Double_t *q2 = new Double_t[3];. int nq = h2->GetQuantiles(3,q2,p);. cout << ""Median of h2:"" << q2[0] << "" "" << q2[1] << "" "" << q2[2] << std::endl;. cout << ""NO!!! should be 5.5 as well"" << endl;. new TCanvas();. h = new TH1D(""hb"", ""hb"", 30, -100., 200.); h->Draw();. for(int j = 11; j <= 20; j++) h->SetBinContent(j, 1.);. nq = 100;. double xq[(nq + 1)]; // positions where to compute the quantiles in [0., 1.]. for(int j = 0; j <= nq; j++) xq[j] = double(j) / double(nq);. double yq[(nq + 1)]; // array to contain the quantiles. h->GetQuantiles(nq + 1, yq, xq);. // note: ""0 %"" should return 0 and ""100 %"" should return 100. for(int j = 0; j <= nq; j++) std::cout << j << "" % : "" << yq[j] << ""\n"";. }. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12251
https://github.com/root-project/root/issues/12251:1193,performance,time,times,1193,"OT-8085. and not it is reported that gives wrong values for 0 and 100 percentiles, see: . https://root-forum.cern.ch/t/th1-getquantiles-gives-wrong-value-for-100-percentile/53284/3. See this example from JIRA:. ```. #include ""TCanvas.h"". #include <iostream>. #include ""TH1D.h"". using std::cout, std::endl;. void quantiles() {. TCanvas *c1 = new TCanvas();. c1->Divide(1,2);. TH1D *h = new TH1D(""h"",""h"",10,0,10);. h->Fill(5);. c1->cd(1);. h->Draw();. Double_t *p = new Double_t[1];. p[0] = 0.5;. Double_t *q = new Double_t[1];. q[0] = 0;. h->GetQuantiles(1,q,p);. cout << ""Median of h:"" << q[0] << std::endl;. cout << ""This is ok!"" << endl;. TH1D *h2 = new TH1D(""h2"",""h2"",10,0,10);. //for (int i = 0; i < 10; ++i) h2->Fill(i); . h2->Fill(2);. h2->Fill(8);. c1->cd(2);. h2->Draw();. Double_t *p2 = new Double_t[1];. p2[0] = 0.5;. Double_t *q2 = new Double_t[1];. q2[0] = 0;. int nq = h2->GetQuantiles(1,q2,p2);. cout << ""Median of h2 (and is never the same result when you execute the macro several times).: "" << q2[0] << "" nq = "" << nq << std::endl;. cout << ""NO!!! should be 5.5 as well"" << endl;. }. ```. and the one from the forum:. ```. new TCanvas();. TH1F *h = new TH1F(""hb"", ""hb"", 30, -100., 200.); h->Draw();. for(int j = 11; j <= 20; j++) h->SetBinContent(j, 1.);. const int nq = 100;. double xq[(nq + 1)]; // positions where to compute the quantiles in [0., 1.]. for(int j = 0; j <= nq; j++) xq[j] = double(j) / double(nq);. double yq[(nq + 1)]; // array to contain the quantiles. h->GetQuantiles(nq + 1, yq, xq);. // note: ""0 %"" should return 0 and ""100 %"" should return 100. for(int j = 0; j <= nq; j++) std::cout << j << "" % : "" << yq[j] << ""\n"";. ```. or all-together:. ```. #include ""TCanvas.h"". #include <iostream>. #include ""TH1D.h"". #include ""TH1F.h"". using std::cout, std::endl;. void quantiles() {. TCanvas *c1 = new TCanvas();. c1->Divide(1,2);. TH1D *h = new TH1D(""h"",""h"",10,0,10);. h->Fill(5);. c1->cd(1);. h->Draw();. Double_t *p = new Double_t[3];. p[0] = 0.;. p[1] = 0.5;. p[",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12251
https://github.com/root-project/root/pull/12253:0,usability,MENU,MENU,0,MENU was missing on TGraph::SaveAs; MENU was missing on TGraph::SaveAs,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12253
https://github.com/root-project/root/pull/12253:36,usability,MENU,MENU,36,MENU was missing on TGraph::SaveAs; MENU was missing on TGraph::SaveAs,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12253
https://github.com/root-project/root/pull/12255:20,usability,MENU,MENU,20,Backport the SaveAs MENU fix from master; Backport the TGraph::SaveAs MENU fix from master.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12255
https://github.com/root-project/root/pull/12255:70,usability,MENU,MENU,70,Backport the SaveAs MENU fix from master; Backport the TGraph::SaveAs MENU fix from master.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12255
https://github.com/root-project/root/pull/12256:5,availability,Error,Error,5,"[DF] Error out when TTreeIndex is used in distributed mode; We do not support it at the moment, so better to raise an explicit error.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12256
https://github.com/root-project/root/pull/12256:127,availability,error,error,127,"[DF] Error out when TTreeIndex is used in distributed mode; We do not support it at the moment, so better to raise an explicit error.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12256
https://github.com/root-project/root/pull/12256:42,interoperability,distribut,distributed,42,"[DF] Error out when TTreeIndex is used in distributed mode; We do not support it at the moment, so better to raise an explicit error.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12256
https://github.com/root-project/root/pull/12256:5,performance,Error,Error,5,"[DF] Error out when TTreeIndex is used in distributed mode; We do not support it at the moment, so better to raise an explicit error.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12256
https://github.com/root-project/root/pull/12256:127,performance,error,error,127,"[DF] Error out when TTreeIndex is used in distributed mode; We do not support it at the moment, so better to raise an explicit error.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12256
https://github.com/root-project/root/pull/12256:5,safety,Error,Error,5,"[DF] Error out when TTreeIndex is used in distributed mode; We do not support it at the moment, so better to raise an explicit error.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12256
https://github.com/root-project/root/pull/12256:127,safety,error,error,127,"[DF] Error out when TTreeIndex is used in distributed mode; We do not support it at the moment, so better to raise an explicit error.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12256
https://github.com/root-project/root/pull/12256:5,usability,Error,Error,5,"[DF] Error out when TTreeIndex is used in distributed mode; We do not support it at the moment, so better to raise an explicit error.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12256
https://github.com/root-project/root/pull/12256:70,usability,support,support,70,"[DF] Error out when TTreeIndex is used in distributed mode; We do not support it at the moment, so better to raise an explicit error.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12256
https://github.com/root-project/root/pull/12256:127,usability,error,error,127,"[DF] Error out when TTreeIndex is used in distributed mode; We do not support it at the moment, so better to raise an explicit error.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12256
https://github.com/root-project/root/pull/12257:280,availability,down,downcast,280,"[math] Add virtual HasGradient() to ROOT::Math function base classes and simplify them; The fact that gradient computations are supported in a `ROOT::Math`. function wrapper was only transmitted by the static class type. However, this is rather inconvenient:. 1. If you forget to downcast your function to the gradient type, the. provided gradient won't be used. 2. Many minimizer function signatures must be overloaded for both the. function with and without gradients. 3. In RooFit, this caused particular pain: depending on if an external. gradient is provided, the function wrapper in the `RooMinimizer`. needs to have a different base class, and the RooMinimizer needs to. cast it correctly when fitting. This commit suggests two new virtual functions:. * `IBaseFunctionMultiDimTempl::HasGradient()` for multi-dim functions. * `IBaseFunctionOneDim::HasGradient()` for 1D functions. Like this, the gradient support can be queried without dynamic casting. at runtime, simplifying lots of other code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12257
https://github.com/root-project/root/pull/12257:514,deployability,depend,depending,514,"[math] Add virtual HasGradient() to ROOT::Math function base classes and simplify them; The fact that gradient computations are supported in a `ROOT::Math`. function wrapper was only transmitted by the static class type. However, this is rather inconvenient:. 1. If you forget to downcast your function to the gradient type, the. provided gradient won't be used. 2. Many minimizer function signatures must be overloaded for both the. function with and without gradients. 3. In RooFit, this caused particular pain: depending on if an external. gradient is provided, the function wrapper in the `RooMinimizer`. needs to have a different base class, and the RooMinimizer needs to. cast it correctly when fitting. This commit suggests two new virtual functions:. * `IBaseFunctionMultiDimTempl::HasGradient()` for multi-dim functions. * `IBaseFunctionOneDim::HasGradient()` for 1D functions. Like this, the gradient support can be queried without dynamic casting. at runtime, simplifying lots of other code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12257
https://github.com/root-project/root/pull/12257:166,integrability,wrap,wrapper,166,"[math] Add virtual HasGradient() to ROOT::Math function base classes and simplify them; The fact that gradient computations are supported in a `ROOT::Math`. function wrapper was only transmitted by the static class type. However, this is rather inconvenient:. 1. If you forget to downcast your function to the gradient type, the. provided gradient won't be used. 2. Many minimizer function signatures must be overloaded for both the. function with and without gradients. 3. In RooFit, this caused particular pain: depending on if an external. gradient is provided, the function wrapper in the `RooMinimizer`. needs to have a different base class, and the RooMinimizer needs to. cast it correctly when fitting. This commit suggests two new virtual functions:. * `IBaseFunctionMultiDimTempl::HasGradient()` for multi-dim functions. * `IBaseFunctionOneDim::HasGradient()` for 1D functions. Like this, the gradient support can be queried without dynamic casting. at runtime, simplifying lots of other code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12257
https://github.com/root-project/root/pull/12257:514,integrability,depend,depending,514,"[math] Add virtual HasGradient() to ROOT::Math function base classes and simplify them; The fact that gradient computations are supported in a `ROOT::Math`. function wrapper was only transmitted by the static class type. However, this is rather inconvenient:. 1. If you forget to downcast your function to the gradient type, the. provided gradient won't be used. 2. Many minimizer function signatures must be overloaded for both the. function with and without gradients. 3. In RooFit, this caused particular pain: depending on if an external. gradient is provided, the function wrapper in the `RooMinimizer`. needs to have a different base class, and the RooMinimizer needs to. cast it correctly when fitting. This commit suggests two new virtual functions:. * `IBaseFunctionMultiDimTempl::HasGradient()` for multi-dim functions. * `IBaseFunctionOneDim::HasGradient()` for 1D functions. Like this, the gradient support can be queried without dynamic casting. at runtime, simplifying lots of other code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12257
https://github.com/root-project/root/pull/12257:578,integrability,wrap,wrapper,578,"[math] Add virtual HasGradient() to ROOT::Math function base classes and simplify them; The fact that gradient computations are supported in a `ROOT::Math`. function wrapper was only transmitted by the static class type. However, this is rather inconvenient:. 1. If you forget to downcast your function to the gradient type, the. provided gradient won't be used. 2. Many minimizer function signatures must be overloaded for both the. function with and without gradients. 3. In RooFit, this caused particular pain: depending on if an external. gradient is provided, the function wrapper in the `RooMinimizer`. needs to have a different base class, and the RooMinimizer needs to. cast it correctly when fitting. This commit suggests two new virtual functions:. * `IBaseFunctionMultiDimTempl::HasGradient()` for multi-dim functions. * `IBaseFunctionOneDim::HasGradient()` for 1D functions. Like this, the gradient support can be queried without dynamic casting. at runtime, simplifying lots of other code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12257
https://github.com/root-project/root/pull/12257:166,interoperability,wrapper,wrapper,166,"[math] Add virtual HasGradient() to ROOT::Math function base classes and simplify them; The fact that gradient computations are supported in a `ROOT::Math`. function wrapper was only transmitted by the static class type. However, this is rather inconvenient:. 1. If you forget to downcast your function to the gradient type, the. provided gradient won't be used. 2. Many minimizer function signatures must be overloaded for both the. function with and without gradients. 3. In RooFit, this caused particular pain: depending on if an external. gradient is provided, the function wrapper in the `RooMinimizer`. needs to have a different base class, and the RooMinimizer needs to. cast it correctly when fitting. This commit suggests two new virtual functions:. * `IBaseFunctionMultiDimTempl::HasGradient()` for multi-dim functions. * `IBaseFunctionOneDim::HasGradient()` for 1D functions. Like this, the gradient support can be queried without dynamic casting. at runtime, simplifying lots of other code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12257
https://github.com/root-project/root/pull/12257:578,interoperability,wrapper,wrapper,578,"[math] Add virtual HasGradient() to ROOT::Math function base classes and simplify them; The fact that gradient computations are supported in a `ROOT::Math`. function wrapper was only transmitted by the static class type. However, this is rather inconvenient:. 1. If you forget to downcast your function to the gradient type, the. provided gradient won't be used. 2. Many minimizer function signatures must be overloaded for both the. function with and without gradients. 3. In RooFit, this caused particular pain: depending on if an external. gradient is provided, the function wrapper in the `RooMinimizer`. needs to have a different base class, and the RooMinimizer needs to. cast it correctly when fitting. This commit suggests two new virtual functions:. * `IBaseFunctionMultiDimTempl::HasGradient()` for multi-dim functions. * `IBaseFunctionOneDim::HasGradient()` for 1D functions. Like this, the gradient support can be queried without dynamic casting. at runtime, simplifying lots of other code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12257
https://github.com/root-project/root/pull/12257:514,modifiability,depend,depending,514,"[math] Add virtual HasGradient() to ROOT::Math function base classes and simplify them; The fact that gradient computations are supported in a `ROOT::Math`. function wrapper was only transmitted by the static class type. However, this is rather inconvenient:. 1. If you forget to downcast your function to the gradient type, the. provided gradient won't be used. 2. Many minimizer function signatures must be overloaded for both the. function with and without gradients. 3. In RooFit, this caused particular pain: depending on if an external. gradient is provided, the function wrapper in the `RooMinimizer`. needs to have a different base class, and the RooMinimizer needs to. cast it correctly when fitting. This commit suggests two new virtual functions:. * `IBaseFunctionMultiDimTempl::HasGradient()` for multi-dim functions. * `IBaseFunctionOneDim::HasGradient()` for 1D functions. Like this, the gradient support can be queried without dynamic casting. at runtime, simplifying lots of other code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12257
https://github.com/root-project/root/pull/12257:514,safety,depend,depending,514,"[math] Add virtual HasGradient() to ROOT::Math function base classes and simplify them; The fact that gradient computations are supported in a `ROOT::Math`. function wrapper was only transmitted by the static class type. However, this is rather inconvenient:. 1. If you forget to downcast your function to the gradient type, the. provided gradient won't be used. 2. Many minimizer function signatures must be overloaded for both the. function with and without gradients. 3. In RooFit, this caused particular pain: depending on if an external. gradient is provided, the function wrapper in the `RooMinimizer`. needs to have a different base class, and the RooMinimizer needs to. cast it correctly when fitting. This commit suggests two new virtual functions:. * `IBaseFunctionMultiDimTempl::HasGradient()` for multi-dim functions. * `IBaseFunctionOneDim::HasGradient()` for 1D functions. Like this, the gradient support can be queried without dynamic casting. at runtime, simplifying lots of other code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12257
https://github.com/root-project/root/pull/12257:390,security,sign,signatures,390,"[math] Add virtual HasGradient() to ROOT::Math function base classes and simplify them; The fact that gradient computations are supported in a `ROOT::Math`. function wrapper was only transmitted by the static class type. However, this is rather inconvenient:. 1. If you forget to downcast your function to the gradient type, the. provided gradient won't be used. 2. Many minimizer function signatures must be overloaded for both the. function with and without gradients. 3. In RooFit, this caused particular pain: depending on if an external. gradient is provided, the function wrapper in the `RooMinimizer`. needs to have a different base class, and the RooMinimizer needs to. cast it correctly when fitting. This commit suggests two new virtual functions:. * `IBaseFunctionMultiDimTempl::HasGradient()` for multi-dim functions. * `IBaseFunctionOneDim::HasGradient()` for 1D functions. Like this, the gradient support can be queried without dynamic casting. at runtime, simplifying lots of other code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12257
https://github.com/root-project/root/pull/12257:73,testability,simpl,simplify,73,"[math] Add virtual HasGradient() to ROOT::Math function base classes and simplify them; The fact that gradient computations are supported in a `ROOT::Math`. function wrapper was only transmitted by the static class type. However, this is rather inconvenient:. 1. If you forget to downcast your function to the gradient type, the. provided gradient won't be used. 2. Many minimizer function signatures must be overloaded for both the. function with and without gradients. 3. In RooFit, this caused particular pain: depending on if an external. gradient is provided, the function wrapper in the `RooMinimizer`. needs to have a different base class, and the RooMinimizer needs to. cast it correctly when fitting. This commit suggests two new virtual functions:. * `IBaseFunctionMultiDimTempl::HasGradient()` for multi-dim functions. * `IBaseFunctionOneDim::HasGradient()` for 1D functions. Like this, the gradient support can be queried without dynamic casting. at runtime, simplifying lots of other code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12257
https://github.com/root-project/root/pull/12257:514,testability,depend,depending,514,"[math] Add virtual HasGradient() to ROOT::Math function base classes and simplify them; The fact that gradient computations are supported in a `ROOT::Math`. function wrapper was only transmitted by the static class type. However, this is rather inconvenient:. 1. If you forget to downcast your function to the gradient type, the. provided gradient won't be used. 2. Many minimizer function signatures must be overloaded for both the. function with and without gradients. 3. In RooFit, this caused particular pain: depending on if an external. gradient is provided, the function wrapper in the `RooMinimizer`. needs to have a different base class, and the RooMinimizer needs to. cast it correctly when fitting. This commit suggests two new virtual functions:. * `IBaseFunctionMultiDimTempl::HasGradient()` for multi-dim functions. * `IBaseFunctionOneDim::HasGradient()` for 1D functions. Like this, the gradient support can be queried without dynamic casting. at runtime, simplifying lots of other code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12257
https://github.com/root-project/root/pull/12257:971,testability,simpl,simplifying,971,"[math] Add virtual HasGradient() to ROOT::Math function base classes and simplify them; The fact that gradient computations are supported in a `ROOT::Math`. function wrapper was only transmitted by the static class type. However, this is rather inconvenient:. 1. If you forget to downcast your function to the gradient type, the. provided gradient won't be used. 2. Many minimizer function signatures must be overloaded for both the. function with and without gradients. 3. In RooFit, this caused particular pain: depending on if an external. gradient is provided, the function wrapper in the `RooMinimizer`. needs to have a different base class, and the RooMinimizer needs to. cast it correctly when fitting. This commit suggests two new virtual functions:. * `IBaseFunctionMultiDimTempl::HasGradient()` for multi-dim functions. * `IBaseFunctionOneDim::HasGradient()` for 1D functions. Like this, the gradient support can be queried without dynamic casting. at runtime, simplifying lots of other code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12257
https://github.com/root-project/root/pull/12257:73,usability,simpl,simplify,73,"[math] Add virtual HasGradient() to ROOT::Math function base classes and simplify them; The fact that gradient computations are supported in a `ROOT::Math`. function wrapper was only transmitted by the static class type. However, this is rather inconvenient:. 1. If you forget to downcast your function to the gradient type, the. provided gradient won't be used. 2. Many minimizer function signatures must be overloaded for both the. function with and without gradients. 3. In RooFit, this caused particular pain: depending on if an external. gradient is provided, the function wrapper in the `RooMinimizer`. needs to have a different base class, and the RooMinimizer needs to. cast it correctly when fitting. This commit suggests two new virtual functions:. * `IBaseFunctionMultiDimTempl::HasGradient()` for multi-dim functions. * `IBaseFunctionOneDim::HasGradient()` for 1D functions. Like this, the gradient support can be queried without dynamic casting. at runtime, simplifying lots of other code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12257
https://github.com/root-project/root/pull/12257:128,usability,support,supported,128,"[math] Add virtual HasGradient() to ROOT::Math function base classes and simplify them; The fact that gradient computations are supported in a `ROOT::Math`. function wrapper was only transmitted by the static class type. However, this is rather inconvenient:. 1. If you forget to downcast your function to the gradient type, the. provided gradient won't be used. 2. Many minimizer function signatures must be overloaded for both the. function with and without gradients. 3. In RooFit, this caused particular pain: depending on if an external. gradient is provided, the function wrapper in the `RooMinimizer`. needs to have a different base class, and the RooMinimizer needs to. cast it correctly when fitting. This commit suggests two new virtual functions:. * `IBaseFunctionMultiDimTempl::HasGradient()` for multi-dim functions. * `IBaseFunctionOneDim::HasGradient()` for 1D functions. Like this, the gradient support can be queried without dynamic casting. at runtime, simplifying lots of other code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12257
https://github.com/root-project/root/pull/12257:371,usability,minim,minimizer,371,"[math] Add virtual HasGradient() to ROOT::Math function base classes and simplify them; The fact that gradient computations are supported in a `ROOT::Math`. function wrapper was only transmitted by the static class type. However, this is rather inconvenient:. 1. If you forget to downcast your function to the gradient type, the. provided gradient won't be used. 2. Many minimizer function signatures must be overloaded for both the. function with and without gradients. 3. In RooFit, this caused particular pain: depending on if an external. gradient is provided, the function wrapper in the `RooMinimizer`. needs to have a different base class, and the RooMinimizer needs to. cast it correctly when fitting. This commit suggests two new virtual functions:. * `IBaseFunctionMultiDimTempl::HasGradient()` for multi-dim functions. * `IBaseFunctionOneDim::HasGradient()` for 1D functions. Like this, the gradient support can be queried without dynamic casting. at runtime, simplifying lots of other code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12257
https://github.com/root-project/root/pull/12257:911,usability,support,support,911,"[math] Add virtual HasGradient() to ROOT::Math function base classes and simplify them; The fact that gradient computations are supported in a `ROOT::Math`. function wrapper was only transmitted by the static class type. However, this is rather inconvenient:. 1. If you forget to downcast your function to the gradient type, the. provided gradient won't be used. 2. Many minimizer function signatures must be overloaded for both the. function with and without gradients. 3. In RooFit, this caused particular pain: depending on if an external. gradient is provided, the function wrapper in the `RooMinimizer`. needs to have a different base class, and the RooMinimizer needs to. cast it correctly when fitting. This commit suggests two new virtual functions:. * `IBaseFunctionMultiDimTempl::HasGradient()` for multi-dim functions. * `IBaseFunctionOneDim::HasGradient()` for 1D functions. Like this, the gradient support can be queried without dynamic casting. at runtime, simplifying lots of other code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12257
https://github.com/root-project/root/pull/12257:971,usability,simpl,simplifying,971,"[math] Add virtual HasGradient() to ROOT::Math function base classes and simplify them; The fact that gradient computations are supported in a `ROOT::Math`. function wrapper was only transmitted by the static class type. However, this is rather inconvenient:. 1. If you forget to downcast your function to the gradient type, the. provided gradient won't be used. 2. Many minimizer function signatures must be overloaded for both the. function with and without gradients. 3. In RooFit, this caused particular pain: depending on if an external. gradient is provided, the function wrapper in the `RooMinimizer`. needs to have a different base class, and the RooMinimizer needs to. cast it correctly when fitting. This commit suggests two new virtual functions:. * `IBaseFunctionMultiDimTempl::HasGradient()` for multi-dim functions. * `IBaseFunctionOneDim::HasGradient()` for 1D functions. Like this, the gradient support can be queried without dynamic casting. at runtime, simplifying lots of other code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12257
https://github.com/root-project/root/pull/12259:68,safety,compl,complex,68,Remove the __CINT__ workarounds when parsing.; We helped CINT parse complex code and that is not needed anymore. This will help further simpliciations when parsing dictionaries with rootcling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12259
https://github.com/root-project/root/pull/12259:68,security,compl,complex,68,Remove the __CINT__ workarounds when parsing.; We helped CINT parse complex code and that is not needed anymore. This will help further simpliciations when parsing dictionaries with rootcling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12259
https://github.com/root-project/root/pull/12259:136,testability,simpl,simpliciations,136,Remove the __CINT__ workarounds when parsing.; We helped CINT parse complex code and that is not needed anymore. This will help further simpliciations when parsing dictionaries with rootcling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12259
https://github.com/root-project/root/pull/12259:50,usability,help,helped,50,Remove the __CINT__ workarounds when parsing.; We helped CINT parse complex code and that is not needed anymore. This will help further simpliciations when parsing dictionaries with rootcling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12259
https://github.com/root-project/root/pull/12259:123,usability,help,help,123,Remove the __CINT__ workarounds when parsing.; We helped CINT parse complex code and that is not needed anymore. This will help further simpliciations when parsing dictionaries with rootcling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12259
https://github.com/root-project/root/pull/12259:136,usability,simpl,simpliciations,136,Remove the __CINT__ workarounds when parsing.; We helped CINT parse complex code and that is not needed anymore. This will help further simpliciations when parsing dictionaries with rootcling.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12259
https://github.com/root-project/root/issues/12260:312,availability,cluster,cluster,312,[DF] Bogus data read from indexed friend trees in multi-thread runs; TTreeProcessorMT should call `friend->BuildIndex` in each multi-thread task but doesn't. The test we have is single-thread only. First reported at https://root-forum.cern.ch/t/reading-friend-trees-using-rdataframe-in-multithread-mode-or-spark-cluster/53513 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12260
https://github.com/root-project/root/issues/12260:107,deployability,Build,BuildIndex,107,[DF] Bogus data read from indexed friend trees in multi-thread runs; TTreeProcessorMT should call `friend->BuildIndex` in each multi-thread task but doesn't. The test we have is single-thread only. First reported at https://root-forum.cern.ch/t/reading-friend-trees-using-rdataframe-in-multithread-mode-or-spark-cluster/53513 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12260
https://github.com/root-project/root/issues/12260:312,deployability,cluster,cluster,312,[DF] Bogus data read from indexed friend trees in multi-thread runs; TTreeProcessorMT should call `friend->BuildIndex` in each multi-thread task but doesn't. The test we have is single-thread only. First reported at https://root-forum.cern.ch/t/reading-friend-trees-using-rdataframe-in-multithread-mode-or-spark-cluster/53513 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12260
https://github.com/root-project/root/issues/12260:50,performance,multi-thread,multi-thread,50,[DF] Bogus data read from indexed friend trees in multi-thread runs; TTreeProcessorMT should call `friend->BuildIndex` in each multi-thread task but doesn't. The test we have is single-thread only. First reported at https://root-forum.cern.ch/t/reading-friend-trees-using-rdataframe-in-multithread-mode-or-spark-cluster/53513 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12260
https://github.com/root-project/root/issues/12260:127,performance,multi-thread,multi-thread,127,[DF] Bogus data read from indexed friend trees in multi-thread runs; TTreeProcessorMT should call `friend->BuildIndex` in each multi-thread task but doesn't. The test we have is single-thread only. First reported at https://root-forum.cern.ch/t/reading-friend-trees-using-rdataframe-in-multithread-mode-or-spark-cluster/53513 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12260
https://github.com/root-project/root/issues/12260:149,reliability,doe,doesn,149,[DF] Bogus data read from indexed friend trees in multi-thread runs; TTreeProcessorMT should call `friend->BuildIndex` in each multi-thread task but doesn't. The test we have is single-thread only. First reported at https://root-forum.cern.ch/t/reading-friend-trees-using-rdataframe-in-multithread-mode-or-spark-cluster/53513 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12260
https://github.com/root-project/root/issues/12260:162,safety,test,test,162,[DF] Bogus data read from indexed friend trees in multi-thread runs; TTreeProcessorMT should call `friend->BuildIndex` in each multi-thread task but doesn't. The test we have is single-thread only. First reported at https://root-forum.cern.ch/t/reading-friend-trees-using-rdataframe-in-multithread-mode-or-spark-cluster/53513 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12260
https://github.com/root-project/root/issues/12260:162,testability,test,test,162,[DF] Bogus data read from indexed friend trees in multi-thread runs; TTreeProcessorMT should call `friend->BuildIndex` in each multi-thread task but doesn't. The test we have is single-thread only. First reported at https://root-forum.cern.ch/t/reading-friend-trees-using-rdataframe-in-multithread-mode-or-spark-cluster/53513 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12260
https://github.com/root-project/root/pull/12261:14,energy efficiency,Optim,Optimize,14,[tmva][pymva] Optimize Evaluation in PyKeras; Disable tensorflow eager execution when evaluating the model in MethodPyKeras This speeds up by more than 100 the model prediction. Re-arrange the code and fixes also a memory leak in allocating the input array.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12261
https://github.com/root-project/root/pull/12261:101,energy efficiency,model,model,101,[tmva][pymva] Optimize Evaluation in PyKeras; Disable tensorflow eager execution when evaluating the model in MethodPyKeras This speeds up by more than 100 the model prediction. Re-arrange the code and fixes also a memory leak in allocating the input array.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12261
https://github.com/root-project/root/pull/12261:160,energy efficiency,model,model,160,[tmva][pymva] Optimize Evaluation in PyKeras; Disable tensorflow eager execution when evaluating the model in MethodPyKeras This speeds up by more than 100 the model prediction. Re-arrange the code and fixes also a memory leak in allocating the input array.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12261
https://github.com/root-project/root/pull/12261:166,energy efficiency,predict,prediction,166,[tmva][pymva] Optimize Evaluation in PyKeras; Disable tensorflow eager execution when evaluating the model in MethodPyKeras This speeds up by more than 100 the model prediction. Re-arrange the code and fixes also a memory leak in allocating the input array.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12261
https://github.com/root-project/root/pull/12261:230,energy efficiency,alloc,allocating,230,[tmva][pymva] Optimize Evaluation in PyKeras; Disable tensorflow eager execution when evaluating the model in MethodPyKeras This speeds up by more than 100 the model prediction. Re-arrange the code and fixes also a memory leak in allocating the input array.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12261
https://github.com/root-project/root/pull/12261:14,performance,Optimiz,Optimize,14,[tmva][pymva] Optimize Evaluation in PyKeras; Disable tensorflow eager execution when evaluating the model in MethodPyKeras This speeds up by more than 100 the model prediction. Re-arrange the code and fixes also a memory leak in allocating the input array.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12261
https://github.com/root-project/root/pull/12261:215,performance,memor,memory,215,[tmva][pymva] Optimize Evaluation in PyKeras; Disable tensorflow eager execution when evaluating the model in MethodPyKeras This speeds up by more than 100 the model prediction. Re-arrange the code and fixes also a memory leak in allocating the input array.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12261
https://github.com/root-project/root/pull/12261:166,safety,predict,prediction,166,[tmva][pymva] Optimize Evaluation in PyKeras; Disable tensorflow eager execution when evaluating the model in MethodPyKeras This speeds up by more than 100 the model prediction. Re-arrange the code and fixes also a memory leak in allocating the input array.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12261
https://github.com/root-project/root/pull/12261:245,safety,input,input,245,[tmva][pymva] Optimize Evaluation in PyKeras; Disable tensorflow eager execution when evaluating the model in MethodPyKeras This speeds up by more than 100 the model prediction. Re-arrange the code and fixes also a memory leak in allocating the input array.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12261
https://github.com/root-project/root/pull/12261:101,security,model,model,101,[tmva][pymva] Optimize Evaluation in PyKeras; Disable tensorflow eager execution when evaluating the model in MethodPyKeras This speeds up by more than 100 the model prediction. Re-arrange the code and fixes also a memory leak in allocating the input array.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12261
https://github.com/root-project/root/pull/12261:160,security,model,model,160,[tmva][pymva] Optimize Evaluation in PyKeras; Disable tensorflow eager execution when evaluating the model in MethodPyKeras This speeds up by more than 100 the model prediction. Re-arrange the code and fixes also a memory leak in allocating the input array.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12261
https://github.com/root-project/root/pull/12261:215,usability,memor,memory,215,[tmva][pymva] Optimize Evaluation in PyKeras; Disable tensorflow eager execution when evaluating the model in MethodPyKeras This speeds up by more than 100 the model prediction. Re-arrange the code and fixes also a memory leak in allocating the input array.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12261
https://github.com/root-project/root/pull/12261:245,usability,input,input,245,[tmva][pymva] Optimize Evaluation in PyKeras; Disable tensorflow eager execution when evaluating the model in MethodPyKeras This speeds up by more than 100 the model prediction. Re-arrange the code and fixes also a memory leak in allocating the input array.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12261
https://github.com/root-project/root/issues/12263:94,deployability,depend,dependencies,94,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:216,deployability,integr,integration,216,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:281,deployability,integr,integration,281,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:321,deployability,MODUL,MODULE,321,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:339,deployability,integr,integration,339,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:352,deployability,DEPEND,DEPENDENCIES,352,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:471,deployability,integr,integration,471,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:1019,deployability,instal,installed,1019,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:1049,deployability,fail,fails,1049,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:1070,deployability,contain,contains,1070,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:1180,deployability,fail,fails,1180,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:413,energy efficiency,core,corecel,413,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:94,integrability,depend,dependencies,94,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:216,integrability,integr,integration,216,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:281,integrability,integr,integration,281,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:339,integrability,integr,integration,339,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:352,integrability,DEPEND,DEPENDENCIES,352,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:471,integrability,integr,integration,471,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:1007,integrability,pub,publish,1007,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:216,interoperability,integr,integration,216,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:281,interoperability,integr,integration,281,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:339,interoperability,integr,integration,339,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:471,interoperability,integr,integration,471,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:94,modifiability,depend,dependencies,94,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:216,modifiability,integr,integration,216,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:281,modifiability,integr,integration,281,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:321,modifiability,MODUL,MODULE,321,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:339,modifiability,integr,integration,339,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:352,modifiability,DEPEND,DEPENDENCIES,352,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:471,modifiability,integr,integration,471,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:25,reliability,doe,does,25,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:216,reliability,integr,integration,216,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:281,reliability,integr,integration,281,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:339,reliability,integr,integration,339,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:471,reliability,integr,integration,471,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:1049,reliability,fail,fails,1049,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:1112,reliability,doe,does,1112,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:1180,reliability,fail,fails,1180,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:94,safety,depend,dependencies,94,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:321,safety,MODUL,MODULE,321,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:352,safety,DEPEND,DEPENDENCIES,352,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:216,security,integr,integration,216,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:281,security,integr,integration,281,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:339,security,integr,integration,339,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:471,security,integr,integration,471,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:94,testability,depend,dependencies,94,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:216,testability,integr,integration,216,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:281,testability,integr,integration,281,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:339,testability,integr,integration,339,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:352,testability,DEPEND,DEPENDENCIES,352,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:471,testability,integr,integration,471,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:769,usability,help,help,769,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/issues/12263:893,usability,help,help,893,"root_generate_dictionary does not properly handle ""all"" include directory properties from its dependencies.; If we have. ```. root_generate_dictionary(HitClassesRootInterfaces. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitRootIO.hh. ${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/SensitiveHit.hh. NOINSTALL. MODULE demo-geant-integration. DEPENDENCIES Celeritas::accel ${Geant4_LIBRARIES} Celeritas::corecel . LINKDEF ""${CMAKE_CURRENT_SOURCE_DIR}/demo-geant-integration/HitClassesLinkDef.h"". ). ```. `root_generate_dictionary` will call (if they are proper target at that point) `get_property(dep_include_dirs TARGET ${dep} PROPERTY INCLUDE_DIRECTORIES)`. However there is 2 problems. (a) It ignores [INTERFACE_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_INCLUDE_DIRECTORIES.html) and [INTERFACE_SYSTEM_INCLUDE_DIRECTORIES](https://cmake.org/cmake/help/latest/prop_tgt/INTERFACE_SYSTEM_INCLUDE_DIRECTORIES.html); the former is used by `Geant4` (as it should) to publish its installed directories. (b) It fails the properties contains cmake generator expressions that does not expand yet. For example `$<INSTALL_INTERFACE:include>`; it fails badly because it then passed to rootcling a `-I` followed by 'nothing' hence shallowing the next arguments.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12263
https://github.com/root-project/root/pull/12264:94,deployability,depend,dependencies,94,root_generate_dictionary: Improve propagation of INCLUDE_DIRECTORY properties from target and dependencies.; This fixes #12263 at least as tested from the Celeritas builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12264
https://github.com/root-project/root/pull/12264:165,deployability,build,builds,165,root_generate_dictionary: Improve propagation of INCLUDE_DIRECTORY properties from target and dependencies.; This fixes #12263 at least as tested from the Celeritas builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12264
https://github.com/root-project/root/pull/12264:94,integrability,depend,dependencies,94,root_generate_dictionary: Improve propagation of INCLUDE_DIRECTORY properties from target and dependencies.; This fixes #12263 at least as tested from the Celeritas builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12264
https://github.com/root-project/root/pull/12264:94,modifiability,depend,dependencies,94,root_generate_dictionary: Improve propagation of INCLUDE_DIRECTORY properties from target and dependencies.; This fixes #12263 at least as tested from the Celeritas builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12264
https://github.com/root-project/root/pull/12264:94,safety,depend,dependencies,94,root_generate_dictionary: Improve propagation of INCLUDE_DIRECTORY properties from target and dependencies.; This fixes #12263 at least as tested from the Celeritas builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12264
https://github.com/root-project/root/pull/12264:139,safety,test,tested,139,root_generate_dictionary: Improve propagation of INCLUDE_DIRECTORY properties from target and dependencies.; This fixes #12263 at least as tested from the Celeritas builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12264
https://github.com/root-project/root/pull/12264:94,testability,depend,dependencies,94,root_generate_dictionary: Improve propagation of INCLUDE_DIRECTORY properties from target and dependencies.; This fixes #12263 at least as tested from the Celeritas builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12264
https://github.com/root-project/root/pull/12264:139,testability,test,tested,139,root_generate_dictionary: Improve propagation of INCLUDE_DIRECTORY properties from target and dependencies.; This fixes #12263 at least as tested from the Celeritas builds.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12264
https://github.com/root-project/root/issues/12267:27,usability,support,support,27,CI: macOS; The new CI must support macOS runners.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12267
https://github.com/root-project/root/issues/12268:53,deployability,build,builds,53,CI: Windows runners; The new CI must support Windows builds,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12268
https://github.com/root-project/root/issues/12268:37,usability,support,support,37,CI: Windows runners; The new CI must support Windows builds,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12268
https://github.com/root-project/root/pull/12269:124,performance,multi-thread,multi-thread,124,"[tree] Propagate TTreeIndex info through GetFriendInfo/MakeFriends ; This in turn fixes a problem with TTreeProcessorMT and multi-thread. RDataFrame ""forgetting"" about the TTreeIndexes associated with. input friend trees. It fixes https://github.com/root-project/root/issues/12260,. ""[DF] Bogus data read from indexed friend trees in multi-thread runs"". A test is added for this case as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12269
https://github.com/root-project/root/pull/12269:334,performance,multi-thread,multi-thread,334,"[tree] Propagate TTreeIndex info through GetFriendInfo/MakeFriends ; This in turn fixes a problem with TTreeProcessorMT and multi-thread. RDataFrame ""forgetting"" about the TTreeIndexes associated with. input friend trees. It fixes https://github.com/root-project/root/issues/12260,. ""[DF] Bogus data read from indexed friend trees in multi-thread runs"". A test is added for this case as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12269
https://github.com/root-project/root/pull/12269:202,safety,input,input,202,"[tree] Propagate TTreeIndex info through GetFriendInfo/MakeFriends ; This in turn fixes a problem with TTreeProcessorMT and multi-thread. RDataFrame ""forgetting"" about the TTreeIndexes associated with. input friend trees. It fixes https://github.com/root-project/root/issues/12260,. ""[DF] Bogus data read from indexed friend trees in multi-thread runs"". A test is added for this case as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12269
https://github.com/root-project/root/pull/12269:356,safety,test,test,356,"[tree] Propagate TTreeIndex info through GetFriendInfo/MakeFriends ; This in turn fixes a problem with TTreeProcessorMT and multi-thread. RDataFrame ""forgetting"" about the TTreeIndexes associated with. input friend trees. It fixes https://github.com/root-project/root/issues/12260,. ""[DF] Bogus data read from indexed friend trees in multi-thread runs"". A test is added for this case as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12269
https://github.com/root-project/root/pull/12269:356,testability,test,test,356,"[tree] Propagate TTreeIndex info through GetFriendInfo/MakeFriends ; This in turn fixes a problem with TTreeProcessorMT and multi-thread. RDataFrame ""forgetting"" about the TTreeIndexes associated with. input friend trees. It fixes https://github.com/root-project/root/issues/12260,. ""[DF] Bogus data read from indexed friend trees in multi-thread runs"". A test is added for this case as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12269
https://github.com/root-project/root/pull/12269:202,usability,input,input,202,"[tree] Propagate TTreeIndex info through GetFriendInfo/MakeFriends ; This in turn fixes a problem with TTreeProcessorMT and multi-thread. RDataFrame ""forgetting"" about the TTreeIndexes associated with. input friend trees. It fixes https://github.com/root-project/root/issues/12260,. ""[DF] Bogus data read from indexed friend trees in multi-thread runs"". A test is added for this case as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12269
https://github.com/root-project/root/issues/12271:28,deployability,build,build,28,CI: roottest CI; We need to build ROOT and run roottest as part of roottest's CI (i.e. for the roottest repo),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12271
https://github.com/root-project/root/issues/12272:485,availability,avail,available,485,"CI: releases; We need to be able to build release binaries. This is likely somehow connected also to the new CI :-) @smuzaffar I'd be interested to hear your thoughts on this... Maybe we can address this (and still enable https://github.com/root-project/root/issues/12270) by the following sequence for the regular CI:. 1. build ROOT. 2. build the (tar.gz|rpm|deb|...) package. 4. delete build and source dir. 5. unpack the tar.gz package. 6. run roottest. 7. if release: make package available on root.cern. Installing a `.pkg` file on macOS, or an install package on Windows will be very intrusive, so maybe there we can only do steps 5 and 6 using a tar.gz / zip, but that's already better than what we have today. The goal should be to ""test what we release"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12272
https://github.com/root-project/root/issues/12272:4,deployability,releas,releases,4,"CI: releases; We need to be able to build release binaries. This is likely somehow connected also to the new CI :-) @smuzaffar I'd be interested to hear your thoughts on this... Maybe we can address this (and still enable https://github.com/root-project/root/issues/12270) by the following sequence for the regular CI:. 1. build ROOT. 2. build the (tar.gz|rpm|deb|...) package. 4. delete build and source dir. 5. unpack the tar.gz package. 6. run roottest. 7. if release: make package available on root.cern. Installing a `.pkg` file on macOS, or an install package on Windows will be very intrusive, so maybe there we can only do steps 5 and 6 using a tar.gz / zip, but that's already better than what we have today. The goal should be to ""test what we release"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12272
https://github.com/root-project/root/issues/12272:36,deployability,build,build,36,"CI: releases; We need to be able to build release binaries. This is likely somehow connected also to the new CI :-) @smuzaffar I'd be interested to hear your thoughts on this... Maybe we can address this (and still enable https://github.com/root-project/root/issues/12270) by the following sequence for the regular CI:. 1. build ROOT. 2. build the (tar.gz|rpm|deb|...) package. 4. delete build and source dir. 5. unpack the tar.gz package. 6. run roottest. 7. if release: make package available on root.cern. Installing a `.pkg` file on macOS, or an install package on Windows will be very intrusive, so maybe there we can only do steps 5 and 6 using a tar.gz / zip, but that's already better than what we have today. The goal should be to ""test what we release"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12272
https://github.com/root-project/root/issues/12272:42,deployability,releas,release,42,"CI: releases; We need to be able to build release binaries. This is likely somehow connected also to the new CI :-) @smuzaffar I'd be interested to hear your thoughts on this... Maybe we can address this (and still enable https://github.com/root-project/root/issues/12270) by the following sequence for the regular CI:. 1. build ROOT. 2. build the (tar.gz|rpm|deb|...) package. 4. delete build and source dir. 5. unpack the tar.gz package. 6. run roottest. 7. if release: make package available on root.cern. Installing a `.pkg` file on macOS, or an install package on Windows will be very intrusive, so maybe there we can only do steps 5 and 6 using a tar.gz / zip, but that's already better than what we have today. The goal should be to ""test what we release"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12272
https://github.com/root-project/root/issues/12272:323,deployability,build,build,323,"CI: releases; We need to be able to build release binaries. This is likely somehow connected also to the new CI :-) @smuzaffar I'd be interested to hear your thoughts on this... Maybe we can address this (and still enable https://github.com/root-project/root/issues/12270) by the following sequence for the regular CI:. 1. build ROOT. 2. build the (tar.gz|rpm|deb|...) package. 4. delete build and source dir. 5. unpack the tar.gz package. 6. run roottest. 7. if release: make package available on root.cern. Installing a `.pkg` file on macOS, or an install package on Windows will be very intrusive, so maybe there we can only do steps 5 and 6 using a tar.gz / zip, but that's already better than what we have today. The goal should be to ""test what we release"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12272
https://github.com/root-project/root/issues/12272:338,deployability,build,build,338,"CI: releases; We need to be able to build release binaries. This is likely somehow connected also to the new CI :-) @smuzaffar I'd be interested to hear your thoughts on this... Maybe we can address this (and still enable https://github.com/root-project/root/issues/12270) by the following sequence for the regular CI:. 1. build ROOT. 2. build the (tar.gz|rpm|deb|...) package. 4. delete build and source dir. 5. unpack the tar.gz package. 6. run roottest. 7. if release: make package available on root.cern. Installing a `.pkg` file on macOS, or an install package on Windows will be very intrusive, so maybe there we can only do steps 5 and 6 using a tar.gz / zip, but that's already better than what we have today. The goal should be to ""test what we release"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12272
https://github.com/root-project/root/issues/12272:388,deployability,build,build,388,"CI: releases; We need to be able to build release binaries. This is likely somehow connected also to the new CI :-) @smuzaffar I'd be interested to hear your thoughts on this... Maybe we can address this (and still enable https://github.com/root-project/root/issues/12270) by the following sequence for the regular CI:. 1. build ROOT. 2. build the (tar.gz|rpm|deb|...) package. 4. delete build and source dir. 5. unpack the tar.gz package. 6. run roottest. 7. if release: make package available on root.cern. Installing a `.pkg` file on macOS, or an install package on Windows will be very intrusive, so maybe there we can only do steps 5 and 6 using a tar.gz / zip, but that's already better than what we have today. The goal should be to ""test what we release"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12272
https://github.com/root-project/root/issues/12272:463,deployability,releas,release,463,"CI: releases; We need to be able to build release binaries. This is likely somehow connected also to the new CI :-) @smuzaffar I'd be interested to hear your thoughts on this... Maybe we can address this (and still enable https://github.com/root-project/root/issues/12270) by the following sequence for the regular CI:. 1. build ROOT. 2. build the (tar.gz|rpm|deb|...) package. 4. delete build and source dir. 5. unpack the tar.gz package. 6. run roottest. 7. if release: make package available on root.cern. Installing a `.pkg` file on macOS, or an install package on Windows will be very intrusive, so maybe there we can only do steps 5 and 6 using a tar.gz / zip, but that's already better than what we have today. The goal should be to ""test what we release"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12272
https://github.com/root-project/root/issues/12272:509,deployability,Instal,Installing,509,"CI: releases; We need to be able to build release binaries. This is likely somehow connected also to the new CI :-) @smuzaffar I'd be interested to hear your thoughts on this... Maybe we can address this (and still enable https://github.com/root-project/root/issues/12270) by the following sequence for the regular CI:. 1. build ROOT. 2. build the (tar.gz|rpm|deb|...) package. 4. delete build and source dir. 5. unpack the tar.gz package. 6. run roottest. 7. if release: make package available on root.cern. Installing a `.pkg` file on macOS, or an install package on Windows will be very intrusive, so maybe there we can only do steps 5 and 6 using a tar.gz / zip, but that's already better than what we have today. The goal should be to ""test what we release"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12272
https://github.com/root-project/root/issues/12272:550,deployability,instal,install,550,"CI: releases; We need to be able to build release binaries. This is likely somehow connected also to the new CI :-) @smuzaffar I'd be interested to hear your thoughts on this... Maybe we can address this (and still enable https://github.com/root-project/root/issues/12270) by the following sequence for the regular CI:. 1. build ROOT. 2. build the (tar.gz|rpm|deb|...) package. 4. delete build and source dir. 5. unpack the tar.gz package. 6. run roottest. 7. if release: make package available on root.cern. Installing a `.pkg` file on macOS, or an install package on Windows will be very intrusive, so maybe there we can only do steps 5 and 6 using a tar.gz / zip, but that's already better than what we have today. The goal should be to ""test what we release"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12272
https://github.com/root-project/root/issues/12272:754,deployability,releas,release,754,"CI: releases; We need to be able to build release binaries. This is likely somehow connected also to the new CI :-) @smuzaffar I'd be interested to hear your thoughts on this... Maybe we can address this (and still enable https://github.com/root-project/root/issues/12270) by the following sequence for the regular CI:. 1. build ROOT. 2. build the (tar.gz|rpm|deb|...) package. 4. delete build and source dir. 5. unpack the tar.gz package. 6. run roottest. 7. if release: make package available on root.cern. Installing a `.pkg` file on macOS, or an install package on Windows will be very intrusive, so maybe there we can only do steps 5 and 6 using a tar.gz / zip, but that's already better than what we have today. The goal should be to ""test what we release"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12272
https://github.com/root-project/root/issues/12272:369,modifiability,pac,package,369,"CI: releases; We need to be able to build release binaries. This is likely somehow connected also to the new CI :-) @smuzaffar I'd be interested to hear your thoughts on this... Maybe we can address this (and still enable https://github.com/root-project/root/issues/12270) by the following sequence for the regular CI:. 1. build ROOT. 2. build the (tar.gz|rpm|deb|...) package. 4. delete build and source dir. 5. unpack the tar.gz package. 6. run roottest. 7. if release: make package available on root.cern. Installing a `.pkg` file on macOS, or an install package on Windows will be very intrusive, so maybe there we can only do steps 5 and 6 using a tar.gz / zip, but that's already better than what we have today. The goal should be to ""test what we release"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12272
https://github.com/root-project/root/issues/12272:431,modifiability,pac,package,431,"CI: releases; We need to be able to build release binaries. This is likely somehow connected also to the new CI :-) @smuzaffar I'd be interested to hear your thoughts on this... Maybe we can address this (and still enable https://github.com/root-project/root/issues/12270) by the following sequence for the regular CI:. 1. build ROOT. 2. build the (tar.gz|rpm|deb|...) package. 4. delete build and source dir. 5. unpack the tar.gz package. 6. run roottest. 7. if release: make package available on root.cern. Installing a `.pkg` file on macOS, or an install package on Windows will be very intrusive, so maybe there we can only do steps 5 and 6 using a tar.gz / zip, but that's already better than what we have today. The goal should be to ""test what we release"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12272
https://github.com/root-project/root/issues/12272:477,modifiability,pac,package,477,"CI: releases; We need to be able to build release binaries. This is likely somehow connected also to the new CI :-) @smuzaffar I'd be interested to hear your thoughts on this... Maybe we can address this (and still enable https://github.com/root-project/root/issues/12270) by the following sequence for the regular CI:. 1. build ROOT. 2. build the (tar.gz|rpm|deb|...) package. 4. delete build and source dir. 5. unpack the tar.gz package. 6. run roottest. 7. if release: make package available on root.cern. Installing a `.pkg` file on macOS, or an install package on Windows will be very intrusive, so maybe there we can only do steps 5 and 6 using a tar.gz / zip, but that's already better than what we have today. The goal should be to ""test what we release"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12272
https://github.com/root-project/root/issues/12272:558,modifiability,pac,package,558,"CI: releases; We need to be able to build release binaries. This is likely somehow connected also to the new CI :-) @smuzaffar I'd be interested to hear your thoughts on this... Maybe we can address this (and still enable https://github.com/root-project/root/issues/12270) by the following sequence for the regular CI:. 1. build ROOT. 2. build the (tar.gz|rpm|deb|...) package. 4. delete build and source dir. 5. unpack the tar.gz package. 6. run roottest. 7. if release: make package available on root.cern. Installing a `.pkg` file on macOS, or an install package on Windows will be very intrusive, so maybe there we can only do steps 5 and 6 using a tar.gz / zip, but that's already better than what we have today. The goal should be to ""test what we release"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12272
https://github.com/root-project/root/issues/12272:485,reliability,availab,available,485,"CI: releases; We need to be able to build release binaries. This is likely somehow connected also to the new CI :-) @smuzaffar I'd be interested to hear your thoughts on this... Maybe we can address this (and still enable https://github.com/root-project/root/issues/12270) by the following sequence for the regular CI:. 1. build ROOT. 2. build the (tar.gz|rpm|deb|...) package. 4. delete build and source dir. 5. unpack the tar.gz package. 6. run roottest. 7. if release: make package available on root.cern. Installing a `.pkg` file on macOS, or an install package on Windows will be very intrusive, so maybe there we can only do steps 5 and 6 using a tar.gz / zip, but that's already better than what we have today. The goal should be to ""test what we release"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12272
https://github.com/root-project/root/issues/12272:485,safety,avail,available,485,"CI: releases; We need to be able to build release binaries. This is likely somehow connected also to the new CI :-) @smuzaffar I'd be interested to hear your thoughts on this... Maybe we can address this (and still enable https://github.com/root-project/root/issues/12270) by the following sequence for the regular CI:. 1. build ROOT. 2. build the (tar.gz|rpm|deb|...) package. 4. delete build and source dir. 5. unpack the tar.gz package. 6. run roottest. 7. if release: make package available on root.cern. Installing a `.pkg` file on macOS, or an install package on Windows will be very intrusive, so maybe there we can only do steps 5 and 6 using a tar.gz / zip, but that's already better than what we have today. The goal should be to ""test what we release"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12272
https://github.com/root-project/root/issues/12272:741,safety,test,test,741,"CI: releases; We need to be able to build release binaries. This is likely somehow connected also to the new CI :-) @smuzaffar I'd be interested to hear your thoughts on this... Maybe we can address this (and still enable https://github.com/root-project/root/issues/12270) by the following sequence for the regular CI:. 1. build ROOT. 2. build the (tar.gz|rpm|deb|...) package. 4. delete build and source dir. 5. unpack the tar.gz package. 6. run roottest. 7. if release: make package available on root.cern. Installing a `.pkg` file on macOS, or an install package on Windows will be very intrusive, so maybe there we can only do steps 5 and 6 using a tar.gz / zip, but that's already better than what we have today. The goal should be to ""test what we release"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12272
https://github.com/root-project/root/issues/12272:485,security,availab,available,485,"CI: releases; We need to be able to build release binaries. This is likely somehow connected also to the new CI :-) @smuzaffar I'd be interested to hear your thoughts on this... Maybe we can address this (and still enable https://github.com/root-project/root/issues/12270) by the following sequence for the regular CI:. 1. build ROOT. 2. build the (tar.gz|rpm|deb|...) package. 4. delete build and source dir. 5. unpack the tar.gz package. 6. run roottest. 7. if release: make package available on root.cern. Installing a `.pkg` file on macOS, or an install package on Windows will be very intrusive, so maybe there we can only do steps 5 and 6 using a tar.gz / zip, but that's already better than what we have today. The goal should be to ""test what we release"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12272
https://github.com/root-project/root/issues/12272:590,security,intrus,intrusive,590,"CI: releases; We need to be able to build release binaries. This is likely somehow connected also to the new CI :-) @smuzaffar I'd be interested to hear your thoughts on this... Maybe we can address this (and still enable https://github.com/root-project/root/issues/12270) by the following sequence for the regular CI:. 1. build ROOT. 2. build the (tar.gz|rpm|deb|...) package. 4. delete build and source dir. 5. unpack the tar.gz package. 6. run roottest. 7. if release: make package available on root.cern. Installing a `.pkg` file on macOS, or an install package on Windows will be very intrusive, so maybe there we can only do steps 5 and 6 using a tar.gz / zip, but that's already better than what we have today. The goal should be to ""test what we release"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12272
https://github.com/root-project/root/issues/12272:741,testability,test,test,741,"CI: releases; We need to be able to build release binaries. This is likely somehow connected also to the new CI :-) @smuzaffar I'd be interested to hear your thoughts on this... Maybe we can address this (and still enable https://github.com/root-project/root/issues/12270) by the following sequence for the regular CI:. 1. build ROOT. 2. build the (tar.gz|rpm|deb|...) package. 4. delete build and source dir. 5. unpack the tar.gz package. 6. run roottest. 7. if release: make package available on root.cern. Installing a `.pkg` file on macOS, or an install package on Windows will be very intrusive, so maybe there we can only do steps 5 and 6 using a tar.gz / zip, but that's already better than what we have today. The goal should be to ""test what we release"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12272
https://github.com/root-project/root/pull/12273:183,testability,context,context,183,"[webcanvas] Provide interactivity for several basic classes; Now objects like `TText`, `TMarker`, `TPolyMarker`, `TEllipse`, `TLine`, `TPolyLine` and several others. can be moved and context menu can be invoked. Fix several minors problems",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12273
https://github.com/root-project/root/pull/12273:20,usability,interact,interactivity,20,"[webcanvas] Provide interactivity for several basic classes; Now objects like `TText`, `TMarker`, `TPolyMarker`, `TEllipse`, `TLine`, `TPolyLine` and several others. can be moved and context menu can be invoked. Fix several minors problems",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12273
https://github.com/root-project/root/pull/12273:191,usability,menu,menu,191,"[webcanvas] Provide interactivity for several basic classes; Now objects like `TText`, `TMarker`, `TPolyMarker`, `TEllipse`, `TLine`, `TPolyLine` and several others. can be moved and context menu can be invoked. Fix several minors problems",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12273
https://github.com/root-project/root/pull/12274:35,usability,minim,minimization,35,[math] Add new Python tutorial for minimization; Convert `NumericalMinimization.C` tutorial to Python,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12274
https://github.com/root-project/root/pull/12275:329,deployability,build,builds,329,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:384,deployability,build,builds,384,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:452,deployability,build,builds,452,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:583,deployability,build,build,583,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:981,deployability,updat,updated,981,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:394,energy efficiency,Load,Loads,394,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:515,energy efficiency,Reduc,Reduces,515,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:556,energy efficiency,Reduc,Reduces,556,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:825,energy efficiency,Current,Currently,825,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:620,integrability,repositor,repository,620,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:741,integrability,buffer,buffering,741,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:620,interoperability,repositor,repository,620,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:394,performance,Load,Loads,394,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:754,performance,improve perform,improve performance,754,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:32,safety,test,testing,32,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:261,safety,test,tests,261,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:465,safety,valid,valid,465,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:564,safety,permiss,permissions,564,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:840,safety,test,tests,840,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:951,safety,test,tested,951,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:981,safety,updat,updated,981,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:981,security,updat,updated,981,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:32,testability,test,testing,32,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:261,testability,test,tests,261,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:840,testability,test,tests,840,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:951,testability,test,tested,951,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:589,usability,workflow,workflow,589,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:702,usability,workflow,workflow,702,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12275:762,usability,perform,performance,762,"[ci] Disable PR uploads, enable testing; [skip-ci]. # This Pull request:. Adds a lot of changes to address. https://github.com/root-project/root/issues/12270. https://github.com/root-project/root/pull/12201#issuecomment-1417627970. ## Changes or fixes:. - Runs tests on CI (has to be done in the same job for now, at least on PR builds). - Disables use of OpenStack credentials in PR builds. - Loads OpenStack credentials from GitHub secrets on non-PR builds (i.e. valid secrets are no longer stored on runners). - Reduces verbosity in the config files. - Reduces permissions of the build workflow. It can now only read repository (when PR commenting is getting implemented it has to run in a separate workflow anyways). - Re-enables output buffering to improve performance, at the cost of stderr being redirected to stdout. Currently runs tests on **every** type of job, could look into ways to skip it under certain conditions. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12275
https://github.com/root-project/root/pull/12276:89,availability,failur,failure,89,[cxxmodules] Add a module for experimental/string_view; That should fix a recent nightly failure with gcc11.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:19,deployability,modul,module,19,[cxxmodules] Add a module for experimental/string_view; That should fix a recent nightly failure with gcc11.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:89,deployability,fail,failure,89,[cxxmodules] Add a module for experimental/string_view; That should fix a recent nightly failure with gcc11.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:19,modifiability,modul,module,19,[cxxmodules] Add a module for experimental/string_view; That should fix a recent nightly failure with gcc11.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:89,performance,failur,failure,89,[cxxmodules] Add a module for experimental/string_view; That should fix a recent nightly failure with gcc11.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:89,reliability,fail,failure,89,[cxxmodules] Add a module for experimental/string_view; That should fix a recent nightly failure with gcc11.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/pull/12276:19,safety,modul,module,19,[cxxmodules] Add a module for experimental/string_view; That should fix a recent nightly failure with gcc11.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12276
https://github.com/root-project/root/issues/12277:474,deployability,fail,failed,474,"Duplicate symbols for the JIT; ```cpp. $ cat test.h. int add42(int i);. $ cat test.cpp. int add42(int i) {. return i + 42;. }. $ clang++ test.cpp -shared -fPIC -o libtest.so. $ root -l -b. root [0] #include ""test.h"". root [1] gSystem->Load(""./libtest.so""). (int) 0. root [2] add42(1) // postpone this and all is fine!! (int) 43. root [3] gInterpreter->Declare(""double add42d(double d) { return d + 42.; }\nint add42(int i) { return i + 42; }""). [IncrementalJIT] addModule() failed: Duplicate definition of symbol '_Z5add42i'. (bool) true. root [4] add42d(1.) // innocent bystander. IncrementalExecutor::executeFunction: symbol '_Z6add42dd' unresolved while linking [cling interface function]! You are probably missing the definition of add42d(double). Maybe you need to load the corresponding shared library? root [5] . ```. I believe the JIT considers `add42` as a strong symbol and when we re-define it we have a problem. I think this is the right behavior however we allowed this in the past and we might be breaking (sometimes silently) existing code. cc: @wlav",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12277
https://github.com/root-project/root/issues/12277:235,energy efficiency,Load,Load,235,"Duplicate symbols for the JIT; ```cpp. $ cat test.h. int add42(int i);. $ cat test.cpp. int add42(int i) {. return i + 42;. }. $ clang++ test.cpp -shared -fPIC -o libtest.so. $ root -l -b. root [0] #include ""test.h"". root [1] gSystem->Load(""./libtest.so""). (int) 0. root [2] add42(1) // postpone this and all is fine!! (int) 43. root [3] gInterpreter->Declare(""double add42d(double d) { return d + 42.; }\nint add42(int i) { return i + 42; }""). [IncrementalJIT] addModule() failed: Duplicate definition of symbol '_Z5add42i'. (bool) true. root [4] add42d(1.) // innocent bystander. IncrementalExecutor::executeFunction: symbol '_Z6add42dd' unresolved while linking [cling interface function]! You are probably missing the definition of add42d(double). Maybe you need to load the corresponding shared library? root [5] . ```. I believe the JIT considers `add42` as a strong symbol and when we re-define it we have a problem. I think this is the right behavior however we allowed this in the past and we might be breaking (sometimes silently) existing code. cc: @wlav",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12277
https://github.com/root-project/root/issues/12277:770,energy efficiency,load,load,770,"Duplicate symbols for the JIT; ```cpp. $ cat test.h. int add42(int i);. $ cat test.cpp. int add42(int i) {. return i + 42;. }. $ clang++ test.cpp -shared -fPIC -o libtest.so. $ root -l -b. root [0] #include ""test.h"". root [1] gSystem->Load(""./libtest.so""). (int) 0. root [2] add42(1) // postpone this and all is fine!! (int) 43. root [3] gInterpreter->Declare(""double add42d(double d) { return d + 42.; }\nint add42(int i) { return i + 42; }""). [IncrementalJIT] addModule() failed: Duplicate definition of symbol '_Z5add42i'. (bool) true. root [4] add42d(1.) // innocent bystander. IncrementalExecutor::executeFunction: symbol '_Z6add42dd' unresolved while linking [cling interface function]! You are probably missing the definition of add42d(double). Maybe you need to load the corresponding shared library? root [5] . ```. I believe the JIT considers `add42` as a strong symbol and when we re-define it we have a problem. I think this is the right behavior however we allowed this in the past and we might be breaking (sometimes silently) existing code. cc: @wlav",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12277
https://github.com/root-project/root/issues/12277:672,integrability,interfac,interface,672,"Duplicate symbols for the JIT; ```cpp. $ cat test.h. int add42(int i);. $ cat test.cpp. int add42(int i) {. return i + 42;. }. $ clang++ test.cpp -shared -fPIC -o libtest.so. $ root -l -b. root [0] #include ""test.h"". root [1] gSystem->Load(""./libtest.so""). (int) 0. root [2] add42(1) // postpone this and all is fine!! (int) 43. root [3] gInterpreter->Declare(""double add42d(double d) { return d + 42.; }\nint add42(int i) { return i + 42; }""). [IncrementalJIT] addModule() failed: Duplicate definition of symbol '_Z5add42i'. (bool) true. root [4] add42d(1.) // innocent bystander. IncrementalExecutor::executeFunction: symbol '_Z6add42dd' unresolved while linking [cling interface function]! You are probably missing the definition of add42d(double). Maybe you need to load the corresponding shared library? root [5] . ```. I believe the JIT considers `add42` as a strong symbol and when we re-define it we have a problem. I think this is the right behavior however we allowed this in the past and we might be breaking (sometimes silently) existing code. cc: @wlav",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12277
https://github.com/root-project/root/issues/12277:147,interoperability,share,shared,147,"Duplicate symbols for the JIT; ```cpp. $ cat test.h. int add42(int i);. $ cat test.cpp. int add42(int i) {. return i + 42;. }. $ clang++ test.cpp -shared -fPIC -o libtest.so. $ root -l -b. root [0] #include ""test.h"". root [1] gSystem->Load(""./libtest.so""). (int) 0. root [2] add42(1) // postpone this and all is fine!! (int) 43. root [3] gInterpreter->Declare(""double add42d(double d) { return d + 42.; }\nint add42(int i) { return i + 42; }""). [IncrementalJIT] addModule() failed: Duplicate definition of symbol '_Z5add42i'. (bool) true. root [4] add42d(1.) // innocent bystander. IncrementalExecutor::executeFunction: symbol '_Z6add42dd' unresolved while linking [cling interface function]! You are probably missing the definition of add42d(double). Maybe you need to load the corresponding shared library? root [5] . ```. I believe the JIT considers `add42` as a strong symbol and when we re-define it we have a problem. I think this is the right behavior however we allowed this in the past and we might be breaking (sometimes silently) existing code. cc: @wlav",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12277
https://github.com/root-project/root/issues/12277:672,interoperability,interfac,interface,672,"Duplicate symbols for the JIT; ```cpp. $ cat test.h. int add42(int i);. $ cat test.cpp. int add42(int i) {. return i + 42;. }. $ clang++ test.cpp -shared -fPIC -o libtest.so. $ root -l -b. root [0] #include ""test.h"". root [1] gSystem->Load(""./libtest.so""). (int) 0. root [2] add42(1) // postpone this and all is fine!! (int) 43. root [3] gInterpreter->Declare(""double add42d(double d) { return d + 42.; }\nint add42(int i) { return i + 42; }""). [IncrementalJIT] addModule() failed: Duplicate definition of symbol '_Z5add42i'. (bool) true. root [4] add42d(1.) // innocent bystander. IncrementalExecutor::executeFunction: symbol '_Z6add42dd' unresolved while linking [cling interface function]! You are probably missing the definition of add42d(double). Maybe you need to load the corresponding shared library? root [5] . ```. I believe the JIT considers `add42` as a strong symbol and when we re-define it we have a problem. I think this is the right behavior however we allowed this in the past and we might be breaking (sometimes silently) existing code. cc: @wlav",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12277
https://github.com/root-project/root/issues/12277:793,interoperability,share,shared,793,"Duplicate symbols for the JIT; ```cpp. $ cat test.h. int add42(int i);. $ cat test.cpp. int add42(int i) {. return i + 42;. }. $ clang++ test.cpp -shared -fPIC -o libtest.so. $ root -l -b. root [0] #include ""test.h"". root [1] gSystem->Load(""./libtest.so""). (int) 0. root [2] add42(1) // postpone this and all is fine!! (int) 43. root [3] gInterpreter->Declare(""double add42d(double d) { return d + 42.; }\nint add42(int i) { return i + 42; }""). [IncrementalJIT] addModule() failed: Duplicate definition of symbol '_Z5add42i'. (bool) true. root [4] add42d(1.) // innocent bystander. IncrementalExecutor::executeFunction: symbol '_Z6add42dd' unresolved while linking [cling interface function]! You are probably missing the definition of add42d(double). Maybe you need to load the corresponding shared library? root [5] . ```. I believe the JIT considers `add42` as a strong symbol and when we re-define it we have a problem. I think this is the right behavior however we allowed this in the past and we might be breaking (sometimes silently) existing code. cc: @wlav",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12277
https://github.com/root-project/root/issues/12277:672,modifiability,interfac,interface,672,"Duplicate symbols for the JIT; ```cpp. $ cat test.h. int add42(int i);. $ cat test.cpp. int add42(int i) {. return i + 42;. }. $ clang++ test.cpp -shared -fPIC -o libtest.so. $ root -l -b. root [0] #include ""test.h"". root [1] gSystem->Load(""./libtest.so""). (int) 0. root [2] add42(1) // postpone this and all is fine!! (int) 43. root [3] gInterpreter->Declare(""double add42d(double d) { return d + 42.; }\nint add42(int i) { return i + 42; }""). [IncrementalJIT] addModule() failed: Duplicate definition of symbol '_Z5add42i'. (bool) true. root [4] add42d(1.) // innocent bystander. IncrementalExecutor::executeFunction: symbol '_Z6add42dd' unresolved while linking [cling interface function]! You are probably missing the definition of add42d(double). Maybe you need to load the corresponding shared library? root [5] . ```. I believe the JIT considers `add42` as a strong symbol and when we re-define it we have a problem. I think this is the right behavior however we allowed this in the past and we might be breaking (sometimes silently) existing code. cc: @wlav",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12277
https://github.com/root-project/root/issues/12277:235,performance,Load,Load,235,"Duplicate symbols for the JIT; ```cpp. $ cat test.h. int add42(int i);. $ cat test.cpp. int add42(int i) {. return i + 42;. }. $ clang++ test.cpp -shared -fPIC -o libtest.so. $ root -l -b. root [0] #include ""test.h"". root [1] gSystem->Load(""./libtest.so""). (int) 0. root [2] add42(1) // postpone this and all is fine!! (int) 43. root [3] gInterpreter->Declare(""double add42d(double d) { return d + 42.; }\nint add42(int i) { return i + 42; }""). [IncrementalJIT] addModule() failed: Duplicate definition of symbol '_Z5add42i'. (bool) true. root [4] add42d(1.) // innocent bystander. IncrementalExecutor::executeFunction: symbol '_Z6add42dd' unresolved while linking [cling interface function]! You are probably missing the definition of add42d(double). Maybe you need to load the corresponding shared library? root [5] . ```. I believe the JIT considers `add42` as a strong symbol and when we re-define it we have a problem. I think this is the right behavior however we allowed this in the past and we might be breaking (sometimes silently) existing code. cc: @wlav",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12277
https://github.com/root-project/root/issues/12277:770,performance,load,load,770,"Duplicate symbols for the JIT; ```cpp. $ cat test.h. int add42(int i);. $ cat test.cpp. int add42(int i) {. return i + 42;. }. $ clang++ test.cpp -shared -fPIC -o libtest.so. $ root -l -b. root [0] #include ""test.h"". root [1] gSystem->Load(""./libtest.so""). (int) 0. root [2] add42(1) // postpone this and all is fine!! (int) 43. root [3] gInterpreter->Declare(""double add42d(double d) { return d + 42.; }\nint add42(int i) { return i + 42; }""). [IncrementalJIT] addModule() failed: Duplicate definition of symbol '_Z5add42i'. (bool) true. root [4] add42d(1.) // innocent bystander. IncrementalExecutor::executeFunction: symbol '_Z6add42dd' unresolved while linking [cling interface function]! You are probably missing the definition of add42d(double). Maybe you need to load the corresponding shared library? root [5] . ```. I believe the JIT considers `add42` as a strong symbol and when we re-define it we have a problem. I think this is the right behavior however we allowed this in the past and we might be breaking (sometimes silently) existing code. cc: @wlav",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12277
https://github.com/root-project/root/issues/12277:474,reliability,fail,failed,474,"Duplicate symbols for the JIT; ```cpp. $ cat test.h. int add42(int i);. $ cat test.cpp. int add42(int i) {. return i + 42;. }. $ clang++ test.cpp -shared -fPIC -o libtest.so. $ root -l -b. root [0] #include ""test.h"". root [1] gSystem->Load(""./libtest.so""). (int) 0. root [2] add42(1) // postpone this and all is fine!! (int) 43. root [3] gInterpreter->Declare(""double add42d(double d) { return d + 42.; }\nint add42(int i) { return i + 42; }""). [IncrementalJIT] addModule() failed: Duplicate definition of symbol '_Z5add42i'. (bool) true. root [4] add42d(1.) // innocent bystander. IncrementalExecutor::executeFunction: symbol '_Z6add42dd' unresolved while linking [cling interface function]! You are probably missing the definition of add42d(double). Maybe you need to load the corresponding shared library? root [5] . ```. I believe the JIT considers `add42` as a strong symbol and when we re-define it we have a problem. I think this is the right behavior however we allowed this in the past and we might be breaking (sometimes silently) existing code. cc: @wlav",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12277
https://github.com/root-project/root/issues/12277:45,safety,test,test,45,"Duplicate symbols for the JIT; ```cpp. $ cat test.h. int add42(int i);. $ cat test.cpp. int add42(int i) {. return i + 42;. }. $ clang++ test.cpp -shared -fPIC -o libtest.so. $ root -l -b. root [0] #include ""test.h"". root [1] gSystem->Load(""./libtest.so""). (int) 0. root [2] add42(1) // postpone this and all is fine!! (int) 43. root [3] gInterpreter->Declare(""double add42d(double d) { return d + 42.; }\nint add42(int i) { return i + 42; }""). [IncrementalJIT] addModule() failed: Duplicate definition of symbol '_Z5add42i'. (bool) true. root [4] add42d(1.) // innocent bystander. IncrementalExecutor::executeFunction: symbol '_Z6add42dd' unresolved while linking [cling interface function]! You are probably missing the definition of add42d(double). Maybe you need to load the corresponding shared library? root [5] . ```. I believe the JIT considers `add42` as a strong symbol and when we re-define it we have a problem. I think this is the right behavior however we allowed this in the past and we might be breaking (sometimes silently) existing code. cc: @wlav",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12277
https://github.com/root-project/root/issues/12277:78,safety,test,test,78,"Duplicate symbols for the JIT; ```cpp. $ cat test.h. int add42(int i);. $ cat test.cpp. int add42(int i) {. return i + 42;. }. $ clang++ test.cpp -shared -fPIC -o libtest.so. $ root -l -b. root [0] #include ""test.h"". root [1] gSystem->Load(""./libtest.so""). (int) 0. root [2] add42(1) // postpone this and all is fine!! (int) 43. root [3] gInterpreter->Declare(""double add42d(double d) { return d + 42.; }\nint add42(int i) { return i + 42; }""). [IncrementalJIT] addModule() failed: Duplicate definition of symbol '_Z5add42i'. (bool) true. root [4] add42d(1.) // innocent bystander. IncrementalExecutor::executeFunction: symbol '_Z6add42dd' unresolved while linking [cling interface function]! You are probably missing the definition of add42d(double). Maybe you need to load the corresponding shared library? root [5] . ```. I believe the JIT considers `add42` as a strong symbol and when we re-define it we have a problem. I think this is the right behavior however we allowed this in the past and we might be breaking (sometimes silently) existing code. cc: @wlav",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12277
https://github.com/root-project/root/issues/12277:137,safety,test,test,137,"Duplicate symbols for the JIT; ```cpp. $ cat test.h. int add42(int i);. $ cat test.cpp. int add42(int i) {. return i + 42;. }. $ clang++ test.cpp -shared -fPIC -o libtest.so. $ root -l -b. root [0] #include ""test.h"". root [1] gSystem->Load(""./libtest.so""). (int) 0. root [2] add42(1) // postpone this and all is fine!! (int) 43. root [3] gInterpreter->Declare(""double add42d(double d) { return d + 42.; }\nint add42(int i) { return i + 42; }""). [IncrementalJIT] addModule() failed: Duplicate definition of symbol '_Z5add42i'. (bool) true. root [4] add42d(1.) // innocent bystander. IncrementalExecutor::executeFunction: symbol '_Z6add42dd' unresolved while linking [cling interface function]! You are probably missing the definition of add42d(double). Maybe you need to load the corresponding shared library? root [5] . ```. I believe the JIT considers `add42` as a strong symbol and when we re-define it we have a problem. I think this is the right behavior however we allowed this in the past and we might be breaking (sometimes silently) existing code. cc: @wlav",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12277
https://github.com/root-project/root/issues/12277:208,safety,test,test,208,"Duplicate symbols for the JIT; ```cpp. $ cat test.h. int add42(int i);. $ cat test.cpp. int add42(int i) {. return i + 42;. }. $ clang++ test.cpp -shared -fPIC -o libtest.so. $ root -l -b. root [0] #include ""test.h"". root [1] gSystem->Load(""./libtest.so""). (int) 0. root [2] add42(1) // postpone this and all is fine!! (int) 43. root [3] gInterpreter->Declare(""double add42d(double d) { return d + 42.; }\nint add42(int i) { return i + 42; }""). [IncrementalJIT] addModule() failed: Duplicate definition of symbol '_Z5add42i'. (bool) true. root [4] add42d(1.) // innocent bystander. IncrementalExecutor::executeFunction: symbol '_Z6add42dd' unresolved while linking [cling interface function]! You are probably missing the definition of add42d(double). Maybe you need to load the corresponding shared library? root [5] . ```. I believe the JIT considers `add42` as a strong symbol and when we re-define it we have a problem. I think this is the right behavior however we allowed this in the past and we might be breaking (sometimes silently) existing code. cc: @wlav",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12277
https://github.com/root-project/root/issues/12277:45,testability,test,test,45,"Duplicate symbols for the JIT; ```cpp. $ cat test.h. int add42(int i);. $ cat test.cpp. int add42(int i) {. return i + 42;. }. $ clang++ test.cpp -shared -fPIC -o libtest.so. $ root -l -b. root [0] #include ""test.h"". root [1] gSystem->Load(""./libtest.so""). (int) 0. root [2] add42(1) // postpone this and all is fine!! (int) 43. root [3] gInterpreter->Declare(""double add42d(double d) { return d + 42.; }\nint add42(int i) { return i + 42; }""). [IncrementalJIT] addModule() failed: Duplicate definition of symbol '_Z5add42i'. (bool) true. root [4] add42d(1.) // innocent bystander. IncrementalExecutor::executeFunction: symbol '_Z6add42dd' unresolved while linking [cling interface function]! You are probably missing the definition of add42d(double). Maybe you need to load the corresponding shared library? root [5] . ```. I believe the JIT considers `add42` as a strong symbol and when we re-define it we have a problem. I think this is the right behavior however we allowed this in the past and we might be breaking (sometimes silently) existing code. cc: @wlav",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12277
https://github.com/root-project/root/issues/12277:78,testability,test,test,78,"Duplicate symbols for the JIT; ```cpp. $ cat test.h. int add42(int i);. $ cat test.cpp. int add42(int i) {. return i + 42;. }. $ clang++ test.cpp -shared -fPIC -o libtest.so. $ root -l -b. root [0] #include ""test.h"". root [1] gSystem->Load(""./libtest.so""). (int) 0. root [2] add42(1) // postpone this and all is fine!! (int) 43. root [3] gInterpreter->Declare(""double add42d(double d) { return d + 42.; }\nint add42(int i) { return i + 42; }""). [IncrementalJIT] addModule() failed: Duplicate definition of symbol '_Z5add42i'. (bool) true. root [4] add42d(1.) // innocent bystander. IncrementalExecutor::executeFunction: symbol '_Z6add42dd' unresolved while linking [cling interface function]! You are probably missing the definition of add42d(double). Maybe you need to load the corresponding shared library? root [5] . ```. I believe the JIT considers `add42` as a strong symbol and when we re-define it we have a problem. I think this is the right behavior however we allowed this in the past and we might be breaking (sometimes silently) existing code. cc: @wlav",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12277
https://github.com/root-project/root/issues/12277:137,testability,test,test,137,"Duplicate symbols for the JIT; ```cpp. $ cat test.h. int add42(int i);. $ cat test.cpp. int add42(int i) {. return i + 42;. }. $ clang++ test.cpp -shared -fPIC -o libtest.so. $ root -l -b. root [0] #include ""test.h"". root [1] gSystem->Load(""./libtest.so""). (int) 0. root [2] add42(1) // postpone this and all is fine!! (int) 43. root [3] gInterpreter->Declare(""double add42d(double d) { return d + 42.; }\nint add42(int i) { return i + 42; }""). [IncrementalJIT] addModule() failed: Duplicate definition of symbol '_Z5add42i'. (bool) true. root [4] add42d(1.) // innocent bystander. IncrementalExecutor::executeFunction: symbol '_Z6add42dd' unresolved while linking [cling interface function]! You are probably missing the definition of add42d(double). Maybe you need to load the corresponding shared library? root [5] . ```. I believe the JIT considers `add42` as a strong symbol and when we re-define it we have a problem. I think this is the right behavior however we allowed this in the past and we might be breaking (sometimes silently) existing code. cc: @wlav",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12277
https://github.com/root-project/root/issues/12277:208,testability,test,test,208,"Duplicate symbols for the JIT; ```cpp. $ cat test.h. int add42(int i);. $ cat test.cpp. int add42(int i) {. return i + 42;. }. $ clang++ test.cpp -shared -fPIC -o libtest.so. $ root -l -b. root [0] #include ""test.h"". root [1] gSystem->Load(""./libtest.so""). (int) 0. root [2] add42(1) // postpone this and all is fine!! (int) 43. root [3] gInterpreter->Declare(""double add42d(double d) { return d + 42.; }\nint add42(int i) { return i + 42; }""). [IncrementalJIT] addModule() failed: Duplicate definition of symbol '_Z5add42i'. (bool) true. root [4] add42d(1.) // innocent bystander. IncrementalExecutor::executeFunction: symbol '_Z6add42dd' unresolved while linking [cling interface function]! You are probably missing the definition of add42d(double). Maybe you need to load the corresponding shared library? root [5] . ```. I believe the JIT considers `add42` as a strong symbol and when we re-define it we have a problem. I think this is the right behavior however we allowed this in the past and we might be breaking (sometimes silently) existing code. cc: @wlav",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12277
https://github.com/root-project/root/issues/12277:950,usability,behavi,behavior,950,"Duplicate symbols for the JIT; ```cpp. $ cat test.h. int add42(int i);. $ cat test.cpp. int add42(int i) {. return i + 42;. }. $ clang++ test.cpp -shared -fPIC -o libtest.so. $ root -l -b. root [0] #include ""test.h"". root [1] gSystem->Load(""./libtest.so""). (int) 0. root [2] add42(1) // postpone this and all is fine!! (int) 43. root [3] gInterpreter->Declare(""double add42d(double d) { return d + 42.; }\nint add42(int i) { return i + 42; }""). [IncrementalJIT] addModule() failed: Duplicate definition of symbol '_Z5add42i'. (bool) true. root [4] add42d(1.) // innocent bystander. IncrementalExecutor::executeFunction: symbol '_Z6add42dd' unresolved while linking [cling interface function]! You are probably missing the definition of add42d(double). Maybe you need to load the corresponding shared library? root [5] . ```. I believe the JIT considers `add42` as a strong symbol and when we re-define it we have a problem. I think this is the right behavior however we allowed this in the past and we might be breaking (sometimes silently) existing code. cc: @wlav",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12277
https://github.com/root-project/root/pull/12279:1686,deployability,updat,updated,1686,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:24,energy efficiency,alloc,allocator,24,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:62,energy efficiency,alloc,allocations,62,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:109,energy efficiency,alloc,allocator,109,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:140,energy efficiency,alloc,allocations,140,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:348,energy efficiency,alloc,allocations,348,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:394,energy efficiency,reduc,reduces,394,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:422,energy efficiency,alloc,allocator,422,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:472,energy efficiency,alloc,allocator,472,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:526,energy efficiency,reduc,reduce,526,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:939,energy efficiency,alloc,allocator,939,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:1135,energy efficiency,alloc,allocated,1135,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:1228,energy efficiency,alloc,allocator,1228,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:1239,energy efficiency,Alloc,AllocT,1239,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:1292,energy efficiency,alloc,allocate,1292,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:1145,integrability,buffer,buffer,1145,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:1464,integrability,interfac,interface,1464,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:1464,interoperability,interfac,interface,1464,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:39,modifiability,reu,reuses,39,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:332,modifiability,Reu,Reuse,332,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:1464,modifiability,interfac,interface,1464,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:55,performance,memor,memory,55,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:124,performance,cach,caches,124,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:179,performance,cach,cache,179,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:341,performance,memor,memory,341,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:504,performance,lock,locked,504,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:533,performance,content,contention,533,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:549,performance,cach,cache,549,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:638,performance,cach,cache,638,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:776,performance,Performance evalu,Performance evaluation,776,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:818,performance,multi-thread,multi-threaded,818,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:1052,performance,memor,memory,1052,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:1106,performance,cach,cache,1106,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:1159,performance,cach,cache,1159,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:1301,performance,memor,memory,1301,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:1020,reliability,doe,does,1020,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:492,safety,safe,safe,492,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:708,safety,compl,complex,708,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:1656,safety,test,tested,1656,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:1686,safety,updat,updated,1686,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:504,security,lock,locked,504,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:708,security,compl,complex,708,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:1322,security,sign,signature,1322,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:1686,security,updat,updated,1686,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:673,testability,simpl,simple,673,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:1656,testability,test,tested,1656,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:55,usability,memor,memory,55,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:341,usability,memor,memory,341,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:673,usability,simpl,simple,673,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:776,usability,Perform,Performance,776,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:1052,usability,memor,memory,1052,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12279:1301,usability,memor,memory,1301,"[ntuple] Provide a page allocator that reuses previous memory allocations; This pull request provides a page allocator that caches previous allocations up to a certain limit. The cache is thread-local and defaults to 16 pages per thread (~1MiB per thread for default-sized pages). This PR is largely based on the concepts in #8634. Reuse of memory allocations in `RPageAllocatorCache` not only reduces calls to the global allocator but also heap fragmentation. The global allocator is thread-safe albeit locked; thus, to also reduce contention, the cache in `RPageAllocatorCache` is thread-local. Given the small size of the (per-thread) cache, the internal structure is a simple `std::deque`. Anything more complex is not justified at the moment of this writing. . **NOTE:** Performance evaluation (specially for the multi-threaded case) should be inserted here tomorrow. ## Changes or fixes:. - Add `RPageAllocatorCache`: this templated allocator returns pages that have at least the required capacity. `DeletePage()` does not immediately deallocate memory; instead, pages are returned to a thread-local cache, dropping the smallest allocated buffer if the cache is full. If a previous page cannot be recycled, the underlying allocator `AllocT` (`RPageAllocatorHeap` by default) is used to allocate memory. - Change the signature of `RPageSource::UnsealPage()`: `SealPage()`, the counterpart of `UnsealPage()` takes an RPage and returns an RSealedPage. Make the interface of `UnsealPage()` symmetric and return an RPage. - Make `UnsealPage()` use `RPageAllocatorCache` by default. - Remove stray `RPageAllocator{File,Daos}` classes. ## Checklist:. - [X] tested changes locally. - [X] updated the docs (if necessary). This PR supersedes #8634.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12279
https://github.com/root-project/root/pull/12282:86,deployability,log,log,86,[webcanvas] fix log2 support; - Correctly set pad range and pad user range in case of log scale. - Properly set zooming scale to histogram without context. - Fix THStack update problem,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12282
https://github.com/root-project/root/pull/12282:90,deployability,scale,scale,90,[webcanvas] fix log2 support; - Correctly set pad range and pad user range in case of log scale. - Properly set zooming scale to histogram without context. - Fix THStack update problem,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12282
https://github.com/root-project/root/pull/12282:120,deployability,scale,scale,120,[webcanvas] fix log2 support; - Correctly set pad range and pad user range in case of log scale. - Properly set zooming scale to histogram without context. - Fix THStack update problem,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12282
https://github.com/root-project/root/pull/12282:170,deployability,updat,update,170,[webcanvas] fix log2 support; - Correctly set pad range and pad user range in case of log scale. - Properly set zooming scale to histogram without context. - Fix THStack update problem,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12282
https://github.com/root-project/root/pull/12282:90,energy efficiency,scale,scale,90,[webcanvas] fix log2 support; - Correctly set pad range and pad user range in case of log scale. - Properly set zooming scale to histogram without context. - Fix THStack update problem,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12282
https://github.com/root-project/root/pull/12282:120,energy efficiency,scale,scale,120,[webcanvas] fix log2 support; - Correctly set pad range and pad user range in case of log scale. - Properly set zooming scale to histogram without context. - Fix THStack update problem,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12282
https://github.com/root-project/root/pull/12282:90,modifiability,scal,scale,90,[webcanvas] fix log2 support; - Correctly set pad range and pad user range in case of log scale. - Properly set zooming scale to histogram without context. - Fix THStack update problem,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12282
https://github.com/root-project/root/pull/12282:120,modifiability,scal,scale,120,[webcanvas] fix log2 support; - Correctly set pad range and pad user range in case of log scale. - Properly set zooming scale to histogram without context. - Fix THStack update problem,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12282
https://github.com/root-project/root/pull/12282:90,performance,scale,scale,90,[webcanvas] fix log2 support; - Correctly set pad range and pad user range in case of log scale. - Properly set zooming scale to histogram without context. - Fix THStack update problem,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12282
https://github.com/root-project/root/pull/12282:120,performance,scale,scale,120,[webcanvas] fix log2 support; - Correctly set pad range and pad user range in case of log scale. - Properly set zooming scale to histogram without context. - Fix THStack update problem,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12282
https://github.com/root-project/root/pull/12282:86,safety,log,log,86,[webcanvas] fix log2 support; - Correctly set pad range and pad user range in case of log scale. - Properly set zooming scale to histogram without context. - Fix THStack update problem,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12282
https://github.com/root-project/root/pull/12282:170,safety,updat,update,170,[webcanvas] fix log2 support; - Correctly set pad range and pad user range in case of log scale. - Properly set zooming scale to histogram without context. - Fix THStack update problem,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12282
https://github.com/root-project/root/pull/12282:86,security,log,log,86,[webcanvas] fix log2 support; - Correctly set pad range and pad user range in case of log scale. - Properly set zooming scale to histogram without context. - Fix THStack update problem,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12282
https://github.com/root-project/root/pull/12282:170,security,updat,update,170,[webcanvas] fix log2 support; - Correctly set pad range and pad user range in case of log scale. - Properly set zooming scale to histogram without context. - Fix THStack update problem,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12282
https://github.com/root-project/root/pull/12282:86,testability,log,log,86,[webcanvas] fix log2 support; - Correctly set pad range and pad user range in case of log scale. - Properly set zooming scale to histogram without context. - Fix THStack update problem,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12282
https://github.com/root-project/root/pull/12282:147,testability,context,context,147,[webcanvas] fix log2 support; - Correctly set pad range and pad user range in case of log scale. - Properly set zooming scale to histogram without context. - Fix THStack update problem,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12282
https://github.com/root-project/root/pull/12282:21,usability,support,support,21,[webcanvas] fix log2 support; - Correctly set pad range and pad user range in case of log scale. - Properly set zooming scale to histogram without context. - Fix THStack update problem,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12282
https://github.com/root-project/root/pull/12282:64,usability,user,user,64,[webcanvas] fix log2 support; - Correctly set pad range and pad user range in case of log scale. - Properly set zooming scale to histogram without context. - Fix THStack update problem,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12282
https://github.com/root-project/root/pull/12283:21,usability,support,support,21,[webcanvas] fix log2 support [6.28]; Backport of fixes from #12282 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12283
https://github.com/root-project/root/pull/12285:213,deployability,build,build-with-miniconda-python-,213,"Disable BZip2 in freetype on Windows; This should fix a potential problem with BZip2 unresolved symbols with Miniconda 3 (Python 3.10), [as reported on the Forum](https://root-forum.cern.ch/t/windows-10-root-6-28-build-with-miniconda-python-3-10-crashed/53554)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12285
https://github.com/root-project/root/issues/12286:2625,availability,Operat,Operating,2625,"` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y', '', {y}). proto.add(ROOT.RooArgSet(y)). # still correct. dt_base_with_proto = pdf_x.generate({x}, NumEvents = 10000, ProtoData = proto). # broken. dt_keys_with_proto = pdf_keys.generate({x}, NumEvents = 10000, ProtoData = proto). frame = x.frame(). dt_base.plotOn(frame). dt_keys.plotOn(frame, MarkerColor = 'b'). dt_keys_with_proto.plotOn(frame, MarkerColor = 'r'). dt_base_with_proto.plotOn(frame, MarkerColor = 'g'). frame.Draw(). ```. Note that while in the example the prototype is useless this can easily happen when the `RooKeysPdf` is part of a larger pdf which does use the it. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master from LCG dev3. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:2700,availability,down,download,2700,"` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y', '', {y}). proto.add(ROOT.RooArgSet(y)). # still correct. dt_base_with_proto = pdf_x.generate({x}, NumEvents = 10000, ProtoData = proto). # broken. dt_keys_with_proto = pdf_keys.generate({x}, NumEvents = 10000, ProtoData = proto). frame = x.frame(). dt_base.plotOn(frame). dt_keys.plotOn(frame, MarkerColor = 'b'). dt_keys_with_proto.plotOn(frame, MarkerColor = 'r'). dt_base_with_proto.plotOn(frame, MarkerColor = 'g'). frame.Draw(). ```. Note that while in the example the prototype is useless this can easily happen when the `RooKeysPdf` is part of a larger pdf which does use the it. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master from LCG dev3. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:30,deployability,fail,fails,30,"[RF] Generation of RooKeysPdf fails if using protodata; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. `RooKeysPdf` do not have an internal generation method, and relies on numerical generation (e.g. `RooAcceptReject`). However, if the call to generate contains `ProtoData`, the distribution of the generated data is not correct. . I tried the same with other numerically generated pdf, specifically `RooGenericPdf`, but only `RooKeysPdf` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y',",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:662,deployability,contain,contains,662,"[RF] Generation of RooKeysPdf fails if using protodata; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. `RooKeysPdf` do not have an internal generation method, and relies on numerical generation (e.g. `RooAcceptReject`). However, if the call to generate contains `ProtoData`, the distribution of the generated data is not correct. . I tried the same with other numerically generated pdf, specifically `RooGenericPdf`, but only `RooKeysPdf` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y',",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:1562,deployability,build,build,1562,"d, and relies on numerical generation (e.g. `RooAcceptReject`). However, if the call to generate contains `ProtoData`, the distribution of the generated data is not correct. . I tried the same with other numerically generated pdf, specifically `RooGenericPdf`, but only `RooKeysPdf` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y', '', {y}). proto.add(ROOT.RooArgSet(y)). # still correct. dt_base_with_proto = pdf_x.generate({x}, NumEvents = 10000, ProtoData = proto). # broken. dt_keys_with_proto = pdf_keys.generate({x}, NumEvents = 10000, ProtoData = proto). frame = x.frame(). dt_base.plotOn(frame). dt_keys.plotOn(frame, MarkerColor = 'b'). dt_keys_with_proto.plotOn(frame, MarkerColor = 'r'). dt_base_with_proto.plotOn(frame, MarkerColor = 'g'). frame.Draw(). ```. Note that while in the example the prototype is useless this can easily happen when the `RooKeysPdf` is part of a larger pdf ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:2613,deployability,version,version,2613,"` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y', '', {y}). proto.add(ROOT.RooArgSet(y)). # still correct. dt_base_with_proto = pdf_x.generate({x}, NumEvents = 10000, ProtoData = proto). # broken. dt_keys_with_proto = pdf_keys.generate({x}, NumEvents = 10000, ProtoData = proto). frame = x.frame(). dt_base.plotOn(frame). dt_keys.plotOn(frame, MarkerColor = 'b'). dt_keys_with_proto.plotOn(frame, MarkerColor = 'r'). dt_base_with_proto.plotOn(frame, MarkerColor = 'g'). frame.Draw(). ```. Note that while in the example the prototype is useless this can easily happen when the `RooKeysPdf` is part of a larger pdf which does use the it. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master from LCG dev3. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:2682,deployability,instal,install,2682,"` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y', '', {y}). proto.add(ROOT.RooArgSet(y)). # still correct. dt_base_with_proto = pdf_x.generate({x}, NumEvents = 10000, ProtoData = proto). # broken. dt_keys_with_proto = pdf_keys.generate({x}, NumEvents = 10000, ProtoData = proto). frame = x.frame(). dt_base.plotOn(frame). dt_keys.plotOn(frame, MarkerColor = 'b'). dt_keys_with_proto.plotOn(frame, MarkerColor = 'r'). dt_base_with_proto.plotOn(frame, MarkerColor = 'g'). frame.Draw(). ```. Note that while in the example the prototype is useless this can easily happen when the `RooKeysPdf` is part of a larger pdf which does use the it. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master from LCG dev3. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:2427,energy efficiency,Draw,Draw,2427,"` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y', '', {y}). proto.add(ROOT.RooArgSet(y)). # still correct. dt_base_with_proto = pdf_x.generate({x}, NumEvents = 10000, ProtoData = proto). # broken. dt_keys_with_proto = pdf_keys.generate({x}, NumEvents = 10000, ProtoData = proto). frame = x.frame(). dt_base.plotOn(frame). dt_keys.plotOn(frame, MarkerColor = 'b'). dt_keys_with_proto.plotOn(frame, MarkerColor = 'r'). dt_base_with_proto.plotOn(frame, MarkerColor = 'g'). frame.Draw(). ```. Note that while in the example the prototype is useless this can easily happen when the `RooKeysPdf` is part of a larger pdf which does use the it. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master from LCG dev3. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:2613,integrability,version,version,2613,"` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y', '', {y}). proto.add(ROOT.RooArgSet(y)). # still correct. dt_base_with_proto = pdf_x.generate({x}, NumEvents = 10000, ProtoData = proto). # broken. dt_keys_with_proto = pdf_keys.generate({x}, NumEvents = 10000, ProtoData = proto). frame = x.frame(). dt_base.plotOn(frame). dt_keys.plotOn(frame, MarkerColor = 'b'). dt_keys_with_proto.plotOn(frame, MarkerColor = 'r'). dt_base_with_proto.plotOn(frame, MarkerColor = 'g'). frame.Draw(). ```. Note that while in the example the prototype is useless this can easily happen when the `RooKeysPdf` is part of a larger pdf which does use the it. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master from LCG dev3. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:688,interoperability,distribut,distribution,688,"[RF] Generation of RooKeysPdf fails if using protodata; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. `RooKeysPdf` do not have an internal generation method, and relies on numerical generation (e.g. `RooAcceptReject`). However, if the call to generate contains `ProtoData`, the distribution of the generated data is not correct. . I tried the same with other numerically generated pdf, specifically `RooGenericPdf`, but only `RooKeysPdf` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y',",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:796,interoperability,specif,specifically,796,"[RF] Generation of RooKeysPdf fails if using protodata; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. `RooKeysPdf` do not have an internal generation method, and relies on numerical generation (e.g. `RooAcceptReject`). However, if the call to generate contains `ProtoData`, the distribution of the generated data is not correct. . I tried the same with other numerically generated pdf, specifically `RooGenericPdf`, but only `RooKeysPdf` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y',",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:2613,modifiability,version,version,2613,"` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y', '', {y}). proto.add(ROOT.RooArgSet(y)). # still correct. dt_base_with_proto = pdf_x.generate({x}, NumEvents = 10000, ProtoData = proto). # broken. dt_keys_with_proto = pdf_keys.generate({x}, NumEvents = 10000, ProtoData = proto). frame = x.frame(). dt_base.plotOn(frame). dt_keys.plotOn(frame, MarkerColor = 'b'). dt_keys_with_proto.plotOn(frame, MarkerColor = 'r'). dt_base_with_proto.plotOn(frame, MarkerColor = 'g'). frame.Draw(). ```. Note that while in the example the prototype is useless this can easily happen when the `RooKeysPdf` is part of a larger pdf which does use the it. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master from LCG dev3. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:30,reliability,fail,fails,30,"[RF] Generation of RooKeysPdf fails if using protodata; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. `RooKeysPdf` do not have an internal generation method, and relies on numerical generation (e.g. `RooAcceptReject`). However, if the call to generate contains `ProtoData`, the distribution of the generated data is not correct. . I tried the same with other numerically generated pdf, specifically `RooGenericPdf`, but only `RooKeysPdf` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y',",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:2571,reliability,doe,does,2571,"` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y', '', {y}). proto.add(ROOT.RooArgSet(y)). # still correct. dt_base_with_proto = pdf_x.generate({x}, NumEvents = 10000, ProtoData = proto). # broken. dt_keys_with_proto = pdf_keys.generate({x}, NumEvents = 10000, ProtoData = proto). frame = x.frame(). dt_base.plotOn(frame). dt_keys.plotOn(frame, MarkerColor = 'b'). dt_keys_with_proto.plotOn(frame, MarkerColor = 'r'). dt_base_with_proto.plotOn(frame, MarkerColor = 'g'). frame.Draw(). ```. Note that while in the example the prototype is useless this can easily happen when the `RooKeysPdf` is part of a larger pdf which does use the it. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master from LCG dev3. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:1516,safety,input,input,1516,"sPdf` do not have an internal generation method, and relies on numerical generation (e.g. `RooAcceptReject`). However, if the call to generate contains `ProtoData`, the distribution of the generated data is not correct. . I tried the same with other numerically generated pdf, specifically `RooGenericPdf`, but only `RooKeysPdf` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y', '', {y}). proto.add(ROOT.RooArgSet(y)). # still correct. dt_base_with_proto = pdf_x.generate({x}, NumEvents = 10000, ProtoData = proto). # broken. dt_keys_with_proto = pdf_keys.generate({x}, NumEvents = 10000, ProtoData = proto). frame = x.frame(). dt_base.plotOn(frame). dt_keys.plotOn(frame, MarkerColor = 'b'). dt_keys_with_proto.plotOn(frame, MarkerColor = 'r'). dt_base_with_proto.plotOn(frame, MarkerColor = 'g'). frame.Draw(). ```. Note that while in the example the prototype is useless this can easily happen ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:1050,testability,verif,verified,1050,"; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. `RooKeysPdf` do not have an internal generation method, and relies on numerical generation (e.g. `RooAcceptReject`). However, if the call to generate contains `ProtoData`, the distribution of the generated data is not correct. . I tried the same with other numerically generated pdf, specifically `RooGenericPdf`, but only `RooKeysPdf` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y', '', {y}). proto.add(ROOT.RooArgSet(y)). # still corre",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:2781,testability,context,context,2781,"` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y', '', {y}). proto.add(ROOT.RooArgSet(y)). # still correct. dt_base_with_proto = pdf_x.generate({x}, NumEvents = 10000, ProtoData = proto). # broken. dt_keys_with_proto = pdf_keys.generate({x}, NumEvents = 10000, ProtoData = proto). frame = x.frame(). dt_base.plotOn(frame). dt_keys.plotOn(frame, MarkerColor = 'b'). dt_keys_with_proto.plotOn(frame, MarkerColor = 'r'). dt_base_with_proto.plotOn(frame, MarkerColor = 'g'). frame.Draw(). ```. Note that while in the example the prototype is useless this can easily happen when the `RooKeysPdf` is part of a larger pdf which does use the it. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master from LCG dev3. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:2810,testability,context,context,2810,"` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y', '', {y}). proto.add(ROOT.RooArgSet(y)). # still correct. dt_base_with_proto = pdf_x.generate({x}, NumEvents = 10000, ProtoData = proto). # broken. dt_keys_with_proto = pdf_keys.generate({x}, NumEvents = 10000, ProtoData = proto). frame = x.frame(). dt_base.plotOn(frame). dt_keys.plotOn(frame, MarkerColor = 'b'). dt_keys_with_proto.plotOn(frame, MarkerColor = 'r'). dt_base_with_proto.plotOn(frame, MarkerColor = 'g'). frame.Draw(). ```. Note that while in the example the prototype is useless this can easily happen when the `RooKeysPdf` is part of a larger pdf which does use the it. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master from LCG dev3. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:446,usability,clear,clear,446,"[RF] Generation of RooKeysPdf fails if using protodata; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. `RooKeysPdf` do not have an internal generation method, and relies on numerical generation (e.g. `RooAcceptReject`). However, if the call to generate contains `ProtoData`, the distribution of the generated data is not correct. . I tried the same with other numerically generated pdf, specifically `RooGenericPdf`, but only `RooKeysPdf` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y',",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:494,usability,behavi,behavior,494,"[RF] Generation of RooKeysPdf fails if using protodata; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. `RooKeysPdf` do not have an internal generation method, and relies on numerical generation (e.g. `RooAcceptReject`). However, if the call to generate contains `ProtoData`, the distribution of the generated data is not correct. . I tried the same with other numerically generated pdf, specifically `RooGenericPdf`, but only `RooKeysPdf` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y',",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:898,usability,interact,interaction,898,"[RF] Generation of RooKeysPdf fails if using protodata; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. `RooKeysPdf` do not have an internal generation method, and relies on numerical generation (e.g. `RooAcceptReject`). However, if the call to generate contains `ProtoData`, the distribution of the generated data is not correct. . I tried the same with other numerically generated pdf, specifically `RooGenericPdf`, but only `RooKeysPdf` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y',",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:969,usability,prototyp,prototype,969,"[RF] Generation of RooKeysPdf fails if using protodata; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. `RooKeysPdf` do not have an internal generation method, and relies on numerical generation (e.g. `RooAcceptReject`). However, if the call to generate contains `ProtoData`, the distribution of the generated data is not correct. . I tried the same with other numerically generated pdf, specifically `RooGenericPdf`, but only `RooKeysPdf` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y',",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:1182,usability,behavi,behavior,1182,"[Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. `RooKeysPdf` do not have an internal generation method, and relies on numerical generation (e.g. `RooAcceptReject`). However, if the call to generate contains `ProtoData`, the distribution of the generated data is not correct. . I tried the same with other numerically generated pdf, specifically `RooGenericPdf`, but only `RooKeysPdf` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y', '', {y}). proto.add(ROOT.RooArgSet(y)). # still correct. dt_base_with_proto = pdf_x.generate({x}, NumEvents = 10000, ProtoData = proto). # broken. dt_keys_with_proto = pdf_keys.generate",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:1200,usability,clear,clear,1200,"t.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. `RooKeysPdf` do not have an internal generation method, and relies on numerical generation (e.g. `RooAcceptReject`). However, if the call to generate contains `ProtoData`, the distribution of the generated data is not correct. . I tried the same with other numerically generated pdf, specifically `RooGenericPdf`, but only `RooKeysPdf` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y', '', {y}). proto.add(ROOT.RooArgSet(y)). # still correct. dt_base_with_proto = pdf_x.generate({x}, NumEvents = 10000, ProtoData = proto). # broken. dt_keys_with_proto = pdf_keys.generate({x}, NumEvents =",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:1308,usability,prototyp,prototype,1308," very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. `RooKeysPdf` do not have an internal generation method, and relies on numerical generation (e.g. `RooAcceptReject`). However, if the call to generate contains `ProtoData`, the distribution of the generated data is not correct. . I tried the same with other numerically generated pdf, specifically `RooGenericPdf`, but only `RooKeysPdf` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y', '', {y}). proto.add(ROOT.RooArgSet(y)). # still correct. dt_base_with_proto = pdf_x.generate({x}, NumEvents = 10000, ProtoData = proto). # broken. dt_keys_with_proto = pdf_keys.generate({x}, NumEvents = 10000, ProtoData = proto). frame = x.frame(). dt_base.plotOn(frame). dt_keys.plotOn(frame, MarkerColor = 'b')",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:1371,usability,behavi,behavior,1371,"ue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. `RooKeysPdf` do not have an internal generation method, and relies on numerical generation (e.g. `RooAcceptReject`). However, if the call to generate contains `ProtoData`, the distribution of the generated data is not correct. . I tried the same with other numerically generated pdf, specifically `RooGenericPdf`, but only `RooKeysPdf` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y', '', {y}). proto.add(ROOT.RooArgSet(y)). # still correct. dt_base_with_proto = pdf_x.generate({x}, NumEvents = 10000, ProtoData = proto). # broken. dt_keys_with_proto = pdf_keys.generate({x}, NumEvents = 10000, ProtoData = proto). frame = x.frame(). dt_base.plotOn(frame). dt_keys.plotOn(frame, MarkerColor = 'b'). dt_keys_with_proto.plotOn(frame, MarkerColor = 'r'). dt_base",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:1516,usability,input,input,1516,"sPdf` do not have an internal generation method, and relies on numerical generation (e.g. `RooAcceptReject`). However, if the call to generate contains `ProtoData`, the distribution of the generated data is not correct. . I tried the same with other numerically generated pdf, specifically `RooGenericPdf`, but only `RooKeysPdf` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y', '', {y}). proto.add(ROOT.RooArgSet(y)). # still correct. dt_base_with_proto = pdf_x.generate({x}, NumEvents = 10000, ProtoData = proto). # broken. dt_keys_with_proto = pdf_keys.generate({x}, NumEvents = 10000, ProtoData = proto). frame = x.frame(). dt_base.plotOn(frame). dt_keys.plotOn(frame, MarkerColor = 'b'). dt_keys_with_proto.plotOn(frame, MarkerColor = 'r'). dt_base_with_proto.plotOn(frame, MarkerColor = 'g'). frame.Draw(). ```. Note that while in the example the prototype is useless this can easily happen ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/issues/12286:2475,usability,prototyp,prototype,2475,"` seems to be affected. This may be caused by a bad interaction between `RooKeysPdf` and `RooAcceptReject`, since adding a prototype switches the generator from `RooFoamGenerator` to `RooAcceptReject`. I verified that forcing `RooFoamGenerator` (which I can only do by recompiling ROOT, as far as I know) solves the issue. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Generation works correctly regardless of prototype data. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. import ROOT. x = ROOT.RooRealVar('x', '', 0, 1). pdf_x = ROOT.RooGenericPdf('pdf_x', 'x', [x]). # correct, of course. dt_base = pdf_x.generate({x}, NumEvents = 10000). pdf_keys = ROOT.RooKeysPdf('pdf_keys', '', x, dt_base, ROOT.RooKeysPdf.MirrorBoth). # also correct. dt_keys = pdf_keys.generate({x}, NumEvents = 10000). y = ROOT.RooRealVar('y', '', 0, 1). proto = ROOT.RooDataSet('proto_y', '', {y}). proto.add(ROOT.RooArgSet(y)). # still correct. dt_base_with_proto = pdf_x.generate({x}, NumEvents = 10000, ProtoData = proto). # broken. dt_keys_with_proto = pdf_keys.generate({x}, NumEvents = 10000, ProtoData = proto). frame = x.frame(). dt_base.plotOn(frame). dt_keys.plotOn(frame, MarkerColor = 'b'). dt_keys_with_proto.plotOn(frame, MarkerColor = 'r'). dt_base_with_proto.plotOn(frame, MarkerColor = 'g'). frame.Draw(). ```. Note that while in the example the prototype is useless this can easily happen when the `RooKeysPdf` is part of a larger pdf which does use the it. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT master from LCG dev3. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12286
https://github.com/root-project/root/pull/12287:207,usability,Close,Closes,207,"[RF] Correctly normalize max possible val in generation with proto data; The code branch without a proto data in `RooGenContext` already did this, and now it's also done when using proto dataset generation. Closes #12286.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12287
https://github.com/root-project/root/pull/12289:9,deployability,observ,observables,9,"[RF] Add observables as another parameter in RooFuncWrapper.; This commit separates the parameters and observables passed to RooFuncWrapper. Now, the wrapper function accepts two different arrays and only calculates the gradient of the underlying func wrt. the parameter array.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12289
https://github.com/root-project/root/pull/12289:103,deployability,observ,observables,103,"[RF] Add observables as another parameter in RooFuncWrapper.; This commit separates the parameters and observables passed to RooFuncWrapper. Now, the wrapper function accepts two different arrays and only calculates the gradient of the underlying func wrt. the parameter array.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12289
https://github.com/root-project/root/pull/12289:150,integrability,wrap,wrapper,150,"[RF] Add observables as another parameter in RooFuncWrapper.; This commit separates the parameters and observables passed to RooFuncWrapper. Now, the wrapper function accepts two different arrays and only calculates the gradient of the underlying func wrt. the parameter array.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12289
https://github.com/root-project/root/pull/12289:150,interoperability,wrapper,wrapper,150,"[RF] Add observables as another parameter in RooFuncWrapper.; This commit separates the parameters and observables passed to RooFuncWrapper. Now, the wrapper function accepts two different arrays and only calculates the gradient of the underlying func wrt. the parameter array.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12289
https://github.com/root-project/root/pull/12289:32,modifiability,paramet,parameter,32,"[RF] Add observables as another parameter in RooFuncWrapper.; This commit separates the parameters and observables passed to RooFuncWrapper. Now, the wrapper function accepts two different arrays and only calculates the gradient of the underlying func wrt. the parameter array.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12289
https://github.com/root-project/root/pull/12289:88,modifiability,paramet,parameters,88,"[RF] Add observables as another parameter in RooFuncWrapper.; This commit separates the parameters and observables passed to RooFuncWrapper. Now, the wrapper function accepts two different arrays and only calculates the gradient of the underlying func wrt. the parameter array.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12289
https://github.com/root-project/root/pull/12289:261,modifiability,paramet,parameter,261,"[RF] Add observables as another parameter in RooFuncWrapper.; This commit separates the parameters and observables passed to RooFuncWrapper. Now, the wrapper function accepts two different arrays and only calculates the gradient of the underlying func wrt. the parameter array.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12289
https://github.com/root-project/root/pull/12289:9,testability,observ,observables,9,"[RF] Add observables as another parameter in RooFuncWrapper.; This commit separates the parameters and observables passed to RooFuncWrapper. Now, the wrapper function accepts two different arrays and only calculates the gradient of the underlying func wrt. the parameter array.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12289
https://github.com/root-project/root/pull/12289:103,testability,observ,observables,103,"[RF] Add observables as another parameter in RooFuncWrapper.; This commit separates the parameters and observables passed to RooFuncWrapper. Now, the wrapper function accepts two different arrays and only calculates the gradient of the underlying func wrt. the parameter array.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12289
https://github.com/root-project/root/issues/12290:759,deployability,integr,integrals,759,"Documentation for TH1's Chi2Test() routine; ### Explain what you would like to see improved. The man page for the Chi2Test method (https://root.cern.ch/doc/master/classTH1.html#ab7d63c7c177ccbf879b5dc31f2311b27) says it is a ""chi2 test for comparing weighted and unweighted histograms"" without saying that they are normalised. If you follow the maths two pages later it does have this information but....who reads the details of the maths used to calculate a chi2? It took us an hour trying to understand the details of the rebin method which was being used in our example, and was irrelevant, to see why the NDF was not equal to the bin count. ### Optional: share how it could be improved. Add in the first page that the comparison is a normalised test: the integrals are not used. e.g. ""chi2 test for a shape comparison of weighted and unweighted histograms"". ### To Reproduce. No code needed...just documentation. ### Setup. WWW. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12290
https://github.com/root-project/root/issues/12290:35,integrability,rout,routine,35,"Documentation for TH1's Chi2Test() routine; ### Explain what you would like to see improved. The man page for the Chi2Test method (https://root.cern.ch/doc/master/classTH1.html#ab7d63c7c177ccbf879b5dc31f2311b27) says it is a ""chi2 test for comparing weighted and unweighted histograms"" without saying that they are normalised. If you follow the maths two pages later it does have this information but....who reads the details of the maths used to calculate a chi2? It took us an hour trying to understand the details of the rebin method which was being used in our example, and was irrelevant, to see why the NDF was not equal to the bin count. ### Optional: share how it could be improved. Add in the first page that the comparison is a normalised test: the integrals are not used. e.g. ""chi2 test for a shape comparison of weighted and unweighted histograms"". ### To Reproduce. No code needed...just documentation. ### Setup. WWW. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12290
https://github.com/root-project/root/issues/12290:759,integrability,integr,integrals,759,"Documentation for TH1's Chi2Test() routine; ### Explain what you would like to see improved. The man page for the Chi2Test method (https://root.cern.ch/doc/master/classTH1.html#ab7d63c7c177ccbf879b5dc31f2311b27) says it is a ""chi2 test for comparing weighted and unweighted histograms"" without saying that they are normalised. If you follow the maths two pages later it does have this information but....who reads the details of the maths used to calculate a chi2? It took us an hour trying to understand the details of the rebin method which was being used in our example, and was irrelevant, to see why the NDF was not equal to the bin count. ### Optional: share how it could be improved. Add in the first page that the comparison is a normalised test: the integrals are not used. e.g. ""chi2 test for a shape comparison of weighted and unweighted histograms"". ### To Reproduce. No code needed...just documentation. ### Setup. WWW. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12290
https://github.com/root-project/root/issues/12290:659,interoperability,share,share,659,"Documentation for TH1's Chi2Test() routine; ### Explain what you would like to see improved. The man page for the Chi2Test method (https://root.cern.ch/doc/master/classTH1.html#ab7d63c7c177ccbf879b5dc31f2311b27) says it is a ""chi2 test for comparing weighted and unweighted histograms"" without saying that they are normalised. If you follow the maths two pages later it does have this information but....who reads the details of the maths used to calculate a chi2? It took us an hour trying to understand the details of the rebin method which was being used in our example, and was irrelevant, to see why the NDF was not equal to the bin count. ### Optional: share how it could be improved. Add in the first page that the comparison is a normalised test: the integrals are not used. e.g. ""chi2 test for a shape comparison of weighted and unweighted histograms"". ### To Reproduce. No code needed...just documentation. ### Setup. WWW. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12290
https://github.com/root-project/root/issues/12290:759,interoperability,integr,integrals,759,"Documentation for TH1's Chi2Test() routine; ### Explain what you would like to see improved. The man page for the Chi2Test method (https://root.cern.ch/doc/master/classTH1.html#ab7d63c7c177ccbf879b5dc31f2311b27) says it is a ""chi2 test for comparing weighted and unweighted histograms"" without saying that they are normalised. If you follow the maths two pages later it does have this information but....who reads the details of the maths used to calculate a chi2? It took us an hour trying to understand the details of the rebin method which was being used in our example, and was irrelevant, to see why the NDF was not equal to the bin count. ### Optional: share how it could be improved. Add in the first page that the comparison is a normalised test: the integrals are not used. e.g. ""chi2 test for a shape comparison of weighted and unweighted histograms"". ### To Reproduce. No code needed...just documentation. ### Setup. WWW. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12290
https://github.com/root-project/root/issues/12290:759,modifiability,integr,integrals,759,"Documentation for TH1's Chi2Test() routine; ### Explain what you would like to see improved. The man page for the Chi2Test method (https://root.cern.ch/doc/master/classTH1.html#ab7d63c7c177ccbf879b5dc31f2311b27) says it is a ""chi2 test for comparing weighted and unweighted histograms"" without saying that they are normalised. If you follow the maths two pages later it does have this information but....who reads the details of the maths used to calculate a chi2? It took us an hour trying to understand the details of the rebin method which was being used in our example, and was irrelevant, to see why the NDF was not equal to the bin count. ### Optional: share how it could be improved. Add in the first page that the comparison is a normalised test: the integrals are not used. e.g. ""chi2 test for a shape comparison of weighted and unweighted histograms"". ### To Reproduce. No code needed...just documentation. ### Setup. WWW. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12290
https://github.com/root-project/root/issues/12290:370,reliability,doe,does,370,"Documentation for TH1's Chi2Test() routine; ### Explain what you would like to see improved. The man page for the Chi2Test method (https://root.cern.ch/doc/master/classTH1.html#ab7d63c7c177ccbf879b5dc31f2311b27) says it is a ""chi2 test for comparing weighted and unweighted histograms"" without saying that they are normalised. If you follow the maths two pages later it does have this information but....who reads the details of the maths used to calculate a chi2? It took us an hour trying to understand the details of the rebin method which was being used in our example, and was irrelevant, to see why the NDF was not equal to the bin count. ### Optional: share how it could be improved. Add in the first page that the comparison is a normalised test: the integrals are not used. e.g. ""chi2 test for a shape comparison of weighted and unweighted histograms"". ### To Reproduce. No code needed...just documentation. ### Setup. WWW. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12290
https://github.com/root-project/root/issues/12290:759,reliability,integr,integrals,759,"Documentation for TH1's Chi2Test() routine; ### Explain what you would like to see improved. The man page for the Chi2Test method (https://root.cern.ch/doc/master/classTH1.html#ab7d63c7c177ccbf879b5dc31f2311b27) says it is a ""chi2 test for comparing weighted and unweighted histograms"" without saying that they are normalised. If you follow the maths two pages later it does have this information but....who reads the details of the maths used to calculate a chi2? It took us an hour trying to understand the details of the rebin method which was being used in our example, and was irrelevant, to see why the NDF was not equal to the bin count. ### Optional: share how it could be improved. Add in the first page that the comparison is a normalised test: the integrals are not used. e.g. ""chi2 test for a shape comparison of weighted and unweighted histograms"". ### To Reproduce. No code needed...just documentation. ### Setup. WWW. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12290
https://github.com/root-project/root/issues/12290:231,safety,test,test,231,"Documentation for TH1's Chi2Test() routine; ### Explain what you would like to see improved. The man page for the Chi2Test method (https://root.cern.ch/doc/master/classTH1.html#ab7d63c7c177ccbf879b5dc31f2311b27) says it is a ""chi2 test for comparing weighted and unweighted histograms"" without saying that they are normalised. If you follow the maths two pages later it does have this information but....who reads the details of the maths used to calculate a chi2? It took us an hour trying to understand the details of the rebin method which was being used in our example, and was irrelevant, to see why the NDF was not equal to the bin count. ### Optional: share how it could be improved. Add in the first page that the comparison is a normalised test: the integrals are not used. e.g. ""chi2 test for a shape comparison of weighted and unweighted histograms"". ### To Reproduce. No code needed...just documentation. ### Setup. WWW. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12290
https://github.com/root-project/root/issues/12290:749,safety,test,test,749,"Documentation for TH1's Chi2Test() routine; ### Explain what you would like to see improved. The man page for the Chi2Test method (https://root.cern.ch/doc/master/classTH1.html#ab7d63c7c177ccbf879b5dc31f2311b27) says it is a ""chi2 test for comparing weighted and unweighted histograms"" without saying that they are normalised. If you follow the maths two pages later it does have this information but....who reads the details of the maths used to calculate a chi2? It took us an hour trying to understand the details of the rebin method which was being used in our example, and was irrelevant, to see why the NDF was not equal to the bin count. ### Optional: share how it could be improved. Add in the first page that the comparison is a normalised test: the integrals are not used. e.g. ""chi2 test for a shape comparison of weighted and unweighted histograms"". ### To Reproduce. No code needed...just documentation. ### Setup. WWW. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12290
https://github.com/root-project/root/issues/12290:794,safety,test,test,794,"Documentation for TH1's Chi2Test() routine; ### Explain what you would like to see improved. The man page for the Chi2Test method (https://root.cern.ch/doc/master/classTH1.html#ab7d63c7c177ccbf879b5dc31f2311b27) says it is a ""chi2 test for comparing weighted and unweighted histograms"" without saying that they are normalised. If you follow the maths two pages later it does have this information but....who reads the details of the maths used to calculate a chi2? It took us an hour trying to understand the details of the rebin method which was being used in our example, and was irrelevant, to see why the NDF was not equal to the bin count. ### Optional: share how it could be improved. Add in the first page that the comparison is a normalised test: the integrals are not used. e.g. ""chi2 test for a shape comparison of weighted and unweighted histograms"". ### To Reproduce. No code needed...just documentation. ### Setup. WWW. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12290
https://github.com/root-project/root/issues/12290:759,security,integr,integrals,759,"Documentation for TH1's Chi2Test() routine; ### Explain what you would like to see improved. The man page for the Chi2Test method (https://root.cern.ch/doc/master/classTH1.html#ab7d63c7c177ccbf879b5dc31f2311b27) says it is a ""chi2 test for comparing weighted and unweighted histograms"" without saying that they are normalised. If you follow the maths two pages later it does have this information but....who reads the details of the maths used to calculate a chi2? It took us an hour trying to understand the details of the rebin method which was being used in our example, and was irrelevant, to see why the NDF was not equal to the bin count. ### Optional: share how it could be improved. Add in the first page that the comparison is a normalised test: the integrals are not used. e.g. ""chi2 test for a shape comparison of weighted and unweighted histograms"". ### To Reproduce. No code needed...just documentation. ### Setup. WWW. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12290
https://github.com/root-project/root/issues/12290:231,testability,test,test,231,"Documentation for TH1's Chi2Test() routine; ### Explain what you would like to see improved. The man page for the Chi2Test method (https://root.cern.ch/doc/master/classTH1.html#ab7d63c7c177ccbf879b5dc31f2311b27) says it is a ""chi2 test for comparing weighted and unweighted histograms"" without saying that they are normalised. If you follow the maths two pages later it does have this information but....who reads the details of the maths used to calculate a chi2? It took us an hour trying to understand the details of the rebin method which was being used in our example, and was irrelevant, to see why the NDF was not equal to the bin count. ### Optional: share how it could be improved. Add in the first page that the comparison is a normalised test: the integrals are not used. e.g. ""chi2 test for a shape comparison of weighted and unweighted histograms"". ### To Reproduce. No code needed...just documentation. ### Setup. WWW. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12290
https://github.com/root-project/root/issues/12290:494,testability,understand,understand,494,"Documentation for TH1's Chi2Test() routine; ### Explain what you would like to see improved. The man page for the Chi2Test method (https://root.cern.ch/doc/master/classTH1.html#ab7d63c7c177ccbf879b5dc31f2311b27) says it is a ""chi2 test for comparing weighted and unweighted histograms"" without saying that they are normalised. If you follow the maths two pages later it does have this information but....who reads the details of the maths used to calculate a chi2? It took us an hour trying to understand the details of the rebin method which was being used in our example, and was irrelevant, to see why the NDF was not equal to the bin count. ### Optional: share how it could be improved. Add in the first page that the comparison is a normalised test: the integrals are not used. e.g. ""chi2 test for a shape comparison of weighted and unweighted histograms"". ### To Reproduce. No code needed...just documentation. ### Setup. WWW. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12290
https://github.com/root-project/root/issues/12290:749,testability,test,test,749,"Documentation for TH1's Chi2Test() routine; ### Explain what you would like to see improved. The man page for the Chi2Test method (https://root.cern.ch/doc/master/classTH1.html#ab7d63c7c177ccbf879b5dc31f2311b27) says it is a ""chi2 test for comparing weighted and unweighted histograms"" without saying that they are normalised. If you follow the maths two pages later it does have this information but....who reads the details of the maths used to calculate a chi2? It took us an hour trying to understand the details of the rebin method which was being used in our example, and was irrelevant, to see why the NDF was not equal to the bin count. ### Optional: share how it could be improved. Add in the first page that the comparison is a normalised test: the integrals are not used. e.g. ""chi2 test for a shape comparison of weighted and unweighted histograms"". ### To Reproduce. No code needed...just documentation. ### Setup. WWW. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12290
https://github.com/root-project/root/issues/12290:759,testability,integr,integrals,759,"Documentation for TH1's Chi2Test() routine; ### Explain what you would like to see improved. The man page for the Chi2Test method (https://root.cern.ch/doc/master/classTH1.html#ab7d63c7c177ccbf879b5dc31f2311b27) says it is a ""chi2 test for comparing weighted and unweighted histograms"" without saying that they are normalised. If you follow the maths two pages later it does have this information but....who reads the details of the maths used to calculate a chi2? It took us an hour trying to understand the details of the rebin method which was being used in our example, and was irrelevant, to see why the NDF was not equal to the bin count. ### Optional: share how it could be improved. Add in the first page that the comparison is a normalised test: the integrals are not used. e.g. ""chi2 test for a shape comparison of weighted and unweighted histograms"". ### To Reproduce. No code needed...just documentation. ### Setup. WWW. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12290
https://github.com/root-project/root/issues/12290:794,testability,test,test,794,"Documentation for TH1's Chi2Test() routine; ### Explain what you would like to see improved. The man page for the Chi2Test method (https://root.cern.ch/doc/master/classTH1.html#ab7d63c7c177ccbf879b5dc31f2311b27) says it is a ""chi2 test for comparing weighted and unweighted histograms"" without saying that they are normalised. If you follow the maths two pages later it does have this information but....who reads the details of the maths used to calculate a chi2? It took us an hour trying to understand the details of the rebin method which was being used in our example, and was irrelevant, to see why the NDF was not equal to the bin count. ### Optional: share how it could be improved. Add in the first page that the comparison is a normalised test: the integrals are not used. e.g. ""chi2 test for a shape comparison of weighted and unweighted histograms"". ### To Reproduce. No code needed...just documentation. ### Setup. WWW. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12290
https://github.com/root-project/root/issues/12290:948,testability,context,context,948,"Documentation for TH1's Chi2Test() routine; ### Explain what you would like to see improved. The man page for the Chi2Test method (https://root.cern.ch/doc/master/classTH1.html#ab7d63c7c177ccbf879b5dc31f2311b27) says it is a ""chi2 test for comparing weighted and unweighted histograms"" without saying that they are normalised. If you follow the maths two pages later it does have this information but....who reads the details of the maths used to calculate a chi2? It took us an hour trying to understand the details of the rebin method which was being used in our example, and was irrelevant, to see why the NDF was not equal to the bin count. ### Optional: share how it could be improved. Add in the first page that the comparison is a normalised test: the integrals are not used. e.g. ""chi2 test for a shape comparison of weighted and unweighted histograms"". ### To Reproduce. No code needed...just documentation. ### Setup. WWW. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12290
https://github.com/root-project/root/issues/12290:0,usability,Document,Documentation,0,"Documentation for TH1's Chi2Test() routine; ### Explain what you would like to see improved. The man page for the Chi2Test method (https://root.cern.ch/doc/master/classTH1.html#ab7d63c7c177ccbf879b5dc31f2311b27) says it is a ""chi2 test for comparing weighted and unweighted histograms"" without saying that they are normalised. If you follow the maths two pages later it does have this information but....who reads the details of the maths used to calculate a chi2? It took us an hour trying to understand the details of the rebin method which was being used in our example, and was irrelevant, to see why the NDF was not equal to the bin count. ### Optional: share how it could be improved. Add in the first page that the comparison is a normalised test: the integrals are not used. e.g. ""chi2 test for a shape comparison of weighted and unweighted histograms"". ### To Reproduce. No code needed...just documentation. ### Setup. WWW. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12290
https://github.com/root-project/root/issues/12290:902,usability,document,documentation,902,"Documentation for TH1's Chi2Test() routine; ### Explain what you would like to see improved. The man page for the Chi2Test method (https://root.cern.ch/doc/master/classTH1.html#ab7d63c7c177ccbf879b5dc31f2311b27) says it is a ""chi2 test for comparing weighted and unweighted histograms"" without saying that they are normalised. If you follow the maths two pages later it does have this information but....who reads the details of the maths used to calculate a chi2? It took us an hour trying to understand the details of the rebin method which was being used in our example, and was irrelevant, to see why the NDF was not equal to the bin count. ### Optional: share how it could be improved. Add in the first page that the comparison is a normalised test: the integrals are not used. e.g. ""chi2 test for a shape comparison of weighted and unweighted histograms"". ### To Reproduce. No code needed...just documentation. ### Setup. WWW. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12290
https://github.com/root-project/root/issues/12291:25,deployability,build,build,25,CI: add a an arch-native build; Tests fail in case of `-march=native` so we ought to test that.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12291
https://github.com/root-project/root/issues/12291:38,deployability,fail,fail,38,CI: add a an arch-native build; Tests fail in case of `-march=native` so we ought to test that.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12291
https://github.com/root-project/root/issues/12291:38,reliability,fail,fail,38,CI: add a an arch-native build; Tests fail in case of `-march=native` so we ought to test that.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12291
https://github.com/root-project/root/issues/12291:32,safety,Test,Tests,32,CI: add a an arch-native build; Tests fail in case of `-march=native` so we ought to test that.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12291
https://github.com/root-project/root/issues/12291:85,safety,test,test,85,CI: add a an arch-native build; Tests fail in case of `-march=native` so we ought to test that.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12291
https://github.com/root-project/root/issues/12291:32,testability,Test,Tests,32,CI: add a an arch-native build; Tests fail in case of `-march=native` so we ought to test that.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12291
https://github.com/root-project/root/issues/12291:85,testability,test,test,85,CI: add a an arch-native build; Tests fail in case of `-march=native` so we ought to test that.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12291
https://github.com/root-project/root/issues/12293:1393,availability,error,error,1393,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1602,availability,error,error,1602,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:13,deployability,fail,fails,13,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:35,deployability,modul,modules,35,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:110,deployability,fail,fails,110,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:172,deployability,build,builddir,172,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:181,deployability,build,build,181,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:187,deployability,BUILD,BUILD,187,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:259,deployability,build,builddir,259,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:268,deployability,build,build,268,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:274,deployability,BUILD,BUILD,274,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:353,deployability,build,builddir,353,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:362,deployability,build,build,362,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:368,deployability,BUILD,BUILD,368,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:488,deployability,fail,failed,488,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:502,deployability,modul,modules,502,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:594,deployability,modul,module,594,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:825,deployability,fail,failed,825,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:839,deployability,modul,modules,839,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:931,deployability,modul,module,931,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1037,deployability,fail,failed,1037,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1051,deployability,modul,modules,1051,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1143,deployability,modul,module,1143,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1275,deployability,Build,Build,1275,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1297,deployability,Build,Build,1297,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1303,deployability,fail,fails,1303,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1364,deployability,build,build,1364,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1419,deployability,version,version,1419,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1554,deployability,build,build,1554,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1636,deployability,version,versions,1636,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1419,integrability,version,version,1419,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1636,integrability,version,versions,1636,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:48,interoperability,incompatib,incompatible,48,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:515,interoperability,incompatib,incompatible,515,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:852,interoperability,incompatib,incompatible,852,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1064,interoperability,incompatib,incompatible,1064,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:35,modifiability,modul,modules,35,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:502,modifiability,modul,modules,502,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:594,modifiability,modul,module,594,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:839,modifiability,modul,modules,839,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:931,modifiability,modul,module,931,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1051,modifiability,modul,modules,1051,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1143,modifiability,modul,module,1143,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1419,modifiability,version,version,1419,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1546,modifiability,Pac,Package,1546,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1636,modifiability,version,versions,1636,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1393,performance,error,error,1393,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1602,performance,error,error,1602,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:13,reliability,fail,fails,13,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:110,reliability,fail,fails,110,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:488,reliability,fail,failed,488,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:825,reliability,fail,failed,825,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1037,reliability,fail,failed,1037,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1303,reliability,fail,fails,1303,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:35,safety,modul,modules,35,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:502,safety,modul,modules,502,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:594,safety,modul,module,594,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:839,safety,modul,modules,839,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:931,safety,modul,module,931,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1051,safety,modul,modules,1051,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1143,safety,modul,module,1143,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1393,safety,error,error,1393,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1602,safety,error,error,1602,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1588,testability,context,context,1588,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1613,testability,regress,regression,1613,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1233,usability,behavi,behavior,1233,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1393,usability,error,error,1393,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12293:1602,usability,error,error,1602,"ROOT 6.28.00 fails on s390x: Added modules have incompatible data layouts; ### Describe the bug. ROOT 6.28.00 fails on s390x. [100%] Generating tutorials/hsimple.root. cd /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/tutorials && LD_LIBRARY_PATH=/builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/lib: ROOTIGNOREPREFIX=1 ROOT_HIST=0 /builddir/build/BUILD/root-6.28.00/s390x-redhat-linux-gnu/bin/root.exe -l -q -b -n -x hsimple.C -e return. [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). Replaced symbol atexit cannot be found in JIT! Replaced symbol at_quick_exit cannot be found in JIT! Processing hsimple.C... [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). [IncrementalJIT] addModule() failed: Added modules have incompatible data layouts: E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-a:8:16-n32:64 (module) vs E-m:e-i1:8:16-i8:8:16-i64:64-f128:64-v128:64-a:8:16-n32:64 (jit). ### Expected behavior. Working ROOT. ### To Reproduce. Build ROOT for s390x. Build fails when the hsimple.C macro is executed at the end of the build process with the above error. ### Setup. 1. ROOT version 6.28.00. 2. GNU/Linux on RHEL+EPEL 8, RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. This error is a regression wrt earlier versions that did not have this problem.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12293
https://github.com/root-project/root/issues/12294:49,availability,error,error,49,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:153,availability,error,errors,153,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:190,availability,error,error,190,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:288,availability,error,error,288,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:399,availability,error,error,399,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:510,availability,error,error,510,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:738,availability,Operat,Operating,738,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:13,deployability,fail,fails,13,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:56,deployability,Fail,Failed,56,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:132,deployability,fail,fail,132,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:197,deployability,Fail,Failed,197,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:295,deployability,Fail,Failed,295,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:406,deployability,Fail,Failed,406,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:517,deployability,Fail,Failed,517,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:634,deployability,fail,failing,634,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:667,deployability,Build,Build,667,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:718,deployability,version,version,718,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:854,deployability,build,build,854,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:932,deployability,fail,failed,932,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:985,deployability,fail,failed,985,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:1038,deployability,fail,failed,1038,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:1091,deployability,fail,failed,1091,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:718,integrability,version,version,718,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:718,modifiability,version,version,718,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:846,modifiability,Pac,Package,846,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:49,performance,error,error,49,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:153,performance,error,errors,153,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:190,performance,error,error,190,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:288,performance,error,error,288,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:399,performance,error,error,399,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:510,performance,error,error,510,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:13,reliability,fail,fails,13,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:56,reliability,Fail,Failed,56,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:132,reliability,fail,fail,132,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:197,reliability,Fail,Failed,197,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:295,reliability,Fail,Failed,295,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:406,reliability,Fail,Failed,406,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:517,reliability,Fail,Failed,517,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:634,reliability,fail,failing,634,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:932,reliability,fail,failed,932,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:985,reliability,fail,failed,985,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:1038,reliability,fail,failed,1038,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:1091,reliability,fail,failed,1091,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:49,safety,error,error,49,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:126,safety,test,tests,126,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:153,safety,error,errors,153,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:190,safety,error,error,190,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:288,safety,error,error,288,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:399,safety,error,error,399,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:510,safety,error,error,510,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:642,safety,test,tests,642,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:703,safety,test,tests,703,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:908,safety,test,tests,908,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:926,safety,test,tests,926,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:961,safety,test,tests,961,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:979,safety,test,tests,979,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:1014,safety,test,tests,1014,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:1032,safety,test,tests,1032,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:1067,safety,test,tests,1067,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:1085,safety,test,tests,1085,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:41,security,session,session,41,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:182,security,session,session,182,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:280,security,session,session,280,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:391,security,session,session,391,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:502,security,session,session,502,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:126,testability,test,tests,126,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:642,testability,test,tests,642,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:703,testability,test,tests,703,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:888,testability,context,context,888,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:908,testability,test,tests,908,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:926,testability,test,tests,926,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:961,testability,test,tests,961,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:979,testability,test,tests,979,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:1014,testability,test,tests,1014,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:1032,testability,test,tests,1032,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:1067,testability,test,tests,1067,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:1085,testability,test,tests,1085,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:49,usability,error,error,49,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:153,usability,error,errors,153,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:190,usability,error,error,190,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:288,usability,error,error,288,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:399,usability,error,error,399,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:510,usability,error,error,510,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12294:621,usability,behavi,behavior,621,"ROOT 6.28.00 fails on aarch64: cling JIT session error: Failed to materialize symbols; ### Describe the bug. About 1/3 of the tests fail on aarch64 with errors like:. ~~~. cling JIT session error: Failed to materialize symbols: { (main, { __aarch64_ldadd8_acq_rel }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. cling JIT session error: Failed to materialize symbols: { (main, { _ZN9RooArgSetC1IJEEERK9RooAbsArgDpOT_ }) }. ~~~. ### Expected behavior. No failing tests. ### To Reproduce. Build ROOT 6.28.00 for aarch64, run tests. 1. ROOT version 6.28.00. 2. Operating system GNU/Linux RHEL+EPEL 9, Fedora 36. Fedora 37, Fedora 38. Fedora 39 - same result on all. 3. Package build from source. ### Additional context. epel9: 67% tests passed, 434 tests failed out of 1317. f36: 67% tests passed, 435 tests failed out of 1318. f37: 67% tests passed, 435 tests failed out of 1318. f38: 67% tests passed, 436 tests failed out of 1318. Some of the symbols that can't be found are in libgcc:. $ nm /usr/lib/gcc/aarch64-redhat-linux/12/libgcc.a | grep __aarch64_ldadd4_acq_rel. 0000000000000000 T __aarch64_ldadd4_acq_rel.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12294
https://github.com/root-project/root/issues/12296:1829,deployability,build,build,1829,"TGraph collapses when supplied with invalid values; - [x] Checked for duplicates. ### Describe the bug. Supplying invalid values (np.nan) to TGraph does not warn me of invalid data, and the TGraph collapses into a single line. The same thing happens for TGraphErrors as well. For a user such as myself, it takes time to figure out what is going on. I've had many problems with ROOT not drawing something, so it took quite a lot of debugging to figure out the problem was the data this time. It would improve user experience and save time for end users. ### Expected behavior. Warning or exception should be raised. Optionally, an empty graph can be drawn. . ### To Reproduce. Reproducible code with a bug (with np.nan values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409911-59aa5edb-e2d2-4410-b3e9-0159b3750721.png). Reproducible code **without** a bug (with valid y-axis values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.arange(num_values, dtype='float')). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409848-d88d2b5d-c4f6-4e0c-b02d-cb4a74bc49f0.png). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Using ROOT inside SWAN. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:386,energy efficiency,draw,drawing,386,"TGraph collapses when supplied with invalid values; - [x] Checked for duplicates. ### Describe the bug. Supplying invalid values (np.nan) to TGraph does not warn me of invalid data, and the TGraph collapses into a single line. The same thing happens for TGraphErrors as well. For a user such as myself, it takes time to figure out what is going on. I've had many problems with ROOT not drawing something, so it took quite a lot of debugging to figure out the problem was the data this time. It would improve user experience and save time for end users. ### Expected behavior. Warning or exception should be raised. Optionally, an empty graph can be drawn. . ### To Reproduce. Reproducible code with a bug (with np.nan values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409911-59aa5edb-e2d2-4410-b3e9-0159b3750721.png). Reproducible code **without** a bug (with valid y-axis values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.arange(num_values, dtype='float')). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409848-d88d2b5d-c4f6-4e0c-b02d-cb4a74bc49f0.png). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Using ROOT inside SWAN. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:649,energy efficiency,draw,drawn,649,"TGraph collapses when supplied with invalid values; - [x] Checked for duplicates. ### Describe the bug. Supplying invalid values (np.nan) to TGraph does not warn me of invalid data, and the TGraph collapses into a single line. The same thing happens for TGraphErrors as well. For a user such as myself, it takes time to figure out what is going on. I've had many problems with ROOT not drawing something, so it took quite a lot of debugging to figure out the problem was the data this time. It would improve user experience and save time for end users. ### Expected behavior. Warning or exception should be raised. Optionally, an empty graph can be drawn. . ### To Reproduce. Reproducible code with a bug (with np.nan values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409911-59aa5edb-e2d2-4410-b3e9-0159b3750721.png). Reproducible code **without** a bug (with valid y-axis values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.arange(num_values, dtype='float')). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409848-d88d2b5d-c4f6-4e0c-b02d-cb4a74bc49f0.png). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Using ROOT inside SWAN. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:811,energy efficiency,Draw,Draw,811,"TGraph collapses when supplied with invalid values; - [x] Checked for duplicates. ### Describe the bug. Supplying invalid values (np.nan) to TGraph does not warn me of invalid data, and the TGraph collapses into a single line. The same thing happens for TGraphErrors as well. For a user such as myself, it takes time to figure out what is going on. I've had many problems with ROOT not drawing something, so it took quite a lot of debugging to figure out the problem was the data this time. It would improve user experience and save time for end users. ### Expected behavior. Warning or exception should be raised. Optionally, an empty graph can be drawn. . ### To Reproduce. Reproducible code with a bug (with np.nan values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409911-59aa5edb-e2d2-4410-b3e9-0159b3750721.png). Reproducible code **without** a bug (with valid y-axis values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.arange(num_values, dtype='float')). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409848-d88d2b5d-c4f6-4e0c-b02d-cb4a74bc49f0.png). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Using ROOT inside SWAN. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:1002,energy efficiency,Draw,DrawClone,1002,"TGraph collapses when supplied with invalid values; - [x] Checked for duplicates. ### Describe the bug. Supplying invalid values (np.nan) to TGraph does not warn me of invalid data, and the TGraph collapses into a single line. The same thing happens for TGraphErrors as well. For a user such as myself, it takes time to figure out what is going on. I've had many problems with ROOT not drawing something, so it took quite a lot of debugging to figure out the problem was the data this time. It would improve user experience and save time for end users. ### Expected behavior. Warning or exception should be raised. Optionally, an empty graph can be drawn. . ### To Reproduce. Reproducible code with a bug (with np.nan values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409911-59aa5edb-e2d2-4410-b3e9-0159b3750721.png). Reproducible code **without** a bug (with valid y-axis values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.arange(num_values, dtype='float')). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409848-d88d2b5d-c4f6-4e0c-b02d-cb4a74bc49f0.png). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Using ROOT inside SWAN. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:1285,energy efficiency,Draw,Draw,1285,"TGraph collapses when supplied with invalid values; - [x] Checked for duplicates. ### Describe the bug. Supplying invalid values (np.nan) to TGraph does not warn me of invalid data, and the TGraph collapses into a single line. The same thing happens for TGraphErrors as well. For a user such as myself, it takes time to figure out what is going on. I've had many problems with ROOT not drawing something, so it took quite a lot of debugging to figure out the problem was the data this time. It would improve user experience and save time for end users. ### Expected behavior. Warning or exception should be raised. Optionally, an empty graph can be drawn. . ### To Reproduce. Reproducible code with a bug (with np.nan values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409911-59aa5edb-e2d2-4410-b3e9-0159b3750721.png). Reproducible code **without** a bug (with valid y-axis values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.arange(num_values, dtype='float')). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409848-d88d2b5d-c4f6-4e0c-b02d-cb4a74bc49f0.png). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Using ROOT inside SWAN. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:1474,energy efficiency,Draw,DrawClone,1474,"TGraph collapses when supplied with invalid values; - [x] Checked for duplicates. ### Describe the bug. Supplying invalid values (np.nan) to TGraph does not warn me of invalid data, and the TGraph collapses into a single line. The same thing happens for TGraphErrors as well. For a user such as myself, it takes time to figure out what is going on. I've had many problems with ROOT not drawing something, so it took quite a lot of debugging to figure out the problem was the data this time. It would improve user experience and save time for end users. ### Expected behavior. Warning or exception should be raised. Optionally, an empty graph can be drawn. . ### To Reproduce. Reproducible code with a bug (with np.nan values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409911-59aa5edb-e2d2-4410-b3e9-0159b3750721.png). Reproducible code **without** a bug (with valid y-axis values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.arange(num_values, dtype='float')). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409848-d88d2b5d-c4f6-4e0c-b02d-cb4a74bc49f0.png). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Using ROOT inside SWAN. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:312,performance,time,time,312,"TGraph collapses when supplied with invalid values; - [x] Checked for duplicates. ### Describe the bug. Supplying invalid values (np.nan) to TGraph does not warn me of invalid data, and the TGraph collapses into a single line. The same thing happens for TGraphErrors as well. For a user such as myself, it takes time to figure out what is going on. I've had many problems with ROOT not drawing something, so it took quite a lot of debugging to figure out the problem was the data this time. It would improve user experience and save time for end users. ### Expected behavior. Warning or exception should be raised. Optionally, an empty graph can be drawn. . ### To Reproduce. Reproducible code with a bug (with np.nan values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409911-59aa5edb-e2d2-4410-b3e9-0159b3750721.png). Reproducible code **without** a bug (with valid y-axis values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.arange(num_values, dtype='float')). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409848-d88d2b5d-c4f6-4e0c-b02d-cb4a74bc49f0.png). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Using ROOT inside SWAN. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:485,performance,time,time,485,"TGraph collapses when supplied with invalid values; - [x] Checked for duplicates. ### Describe the bug. Supplying invalid values (np.nan) to TGraph does not warn me of invalid data, and the TGraph collapses into a single line. The same thing happens for TGraphErrors as well. For a user such as myself, it takes time to figure out what is going on. I've had many problems with ROOT not drawing something, so it took quite a lot of debugging to figure out the problem was the data this time. It would improve user experience and save time for end users. ### Expected behavior. Warning or exception should be raised. Optionally, an empty graph can be drawn. . ### To Reproduce. Reproducible code with a bug (with np.nan values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409911-59aa5edb-e2d2-4410-b3e9-0159b3750721.png). Reproducible code **without** a bug (with valid y-axis values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.arange(num_values, dtype='float')). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409848-d88d2b5d-c4f6-4e0c-b02d-cb4a74bc49f0.png). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Using ROOT inside SWAN. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:533,performance,time,time,533,"TGraph collapses when supplied with invalid values; - [x] Checked for duplicates. ### Describe the bug. Supplying invalid values (np.nan) to TGraph does not warn me of invalid data, and the TGraph collapses into a single line. The same thing happens for TGraphErrors as well. For a user such as myself, it takes time to figure out what is going on. I've had many problems with ROOT not drawing something, so it took quite a lot of debugging to figure out the problem was the data this time. It would improve user experience and save time for end users. ### Expected behavior. Warning or exception should be raised. Optionally, an empty graph can be drawn. . ### To Reproduce. Reproducible code with a bug (with np.nan values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409911-59aa5edb-e2d2-4410-b3e9-0159b3750721.png). Reproducible code **without** a bug (with valid y-axis values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.arange(num_values, dtype='float')). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409848-d88d2b5d-c4f6-4e0c-b02d-cb4a74bc49f0.png). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Using ROOT inside SWAN. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:148,reliability,doe,does,148,"TGraph collapses when supplied with invalid values; - [x] Checked for duplicates. ### Describe the bug. Supplying invalid values (np.nan) to TGraph does not warn me of invalid data, and the TGraph collapses into a single line. The same thing happens for TGraphErrors as well. For a user such as myself, it takes time to figure out what is going on. I've had many problems with ROOT not drawing something, so it took quite a lot of debugging to figure out the problem was the data this time. It would improve user experience and save time for end users. ### Expected behavior. Warning or exception should be raised. Optionally, an empty graph can be drawn. . ### To Reproduce. Reproducible code with a bug (with np.nan values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409911-59aa5edb-e2d2-4410-b3e9-0159b3750721.png). Reproducible code **without** a bug (with valid y-axis values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.arange(num_values, dtype='float')). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409848-d88d2b5d-c4f6-4e0c-b02d-cb4a74bc49f0.png). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Using ROOT inside SWAN. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:587,safety,except,exception,587,"TGraph collapses when supplied with invalid values; - [x] Checked for duplicates. ### Describe the bug. Supplying invalid values (np.nan) to TGraph does not warn me of invalid data, and the TGraph collapses into a single line. The same thing happens for TGraphErrors as well. For a user such as myself, it takes time to figure out what is going on. I've had many problems with ROOT not drawing something, so it took quite a lot of debugging to figure out the problem was the data this time. It would improve user experience and save time for end users. ### Expected behavior. Warning or exception should be raised. Optionally, an empty graph can be drawn. . ### To Reproduce. Reproducible code with a bug (with np.nan values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409911-59aa5edb-e2d2-4410-b3e9-0159b3750721.png). Reproducible code **without** a bug (with valid y-axis values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.arange(num_values, dtype='float')). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409848-d88d2b5d-c4f6-4e0c-b02d-cb4a74bc49f0.png). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Using ROOT inside SWAN. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:1179,safety,valid,valid,1179,"TGraph collapses when supplied with invalid values; - [x] Checked for duplicates. ### Describe the bug. Supplying invalid values (np.nan) to TGraph does not warn me of invalid data, and the TGraph collapses into a single line. The same thing happens for TGraphErrors as well. For a user such as myself, it takes time to figure out what is going on. I've had many problems with ROOT not drawing something, so it took quite a lot of debugging to figure out the problem was the data this time. It would improve user experience and save time for end users. ### Expected behavior. Warning or exception should be raised. Optionally, an empty graph can be drawn. . ### To Reproduce. Reproducible code with a bug (with np.nan values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409911-59aa5edb-e2d2-4410-b3e9-0159b3750721.png). Reproducible code **without** a bug (with valid y-axis values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.arange(num_values, dtype='float')). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409848-d88d2b5d-c4f6-4e0c-b02d-cb4a74bc49f0.png). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Using ROOT inside SWAN. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:1783,safety,input,input,1783,"TGraph collapses when supplied with invalid values; - [x] Checked for duplicates. ### Describe the bug. Supplying invalid values (np.nan) to TGraph does not warn me of invalid data, and the TGraph collapses into a single line. The same thing happens for TGraphErrors as well. For a user such as myself, it takes time to figure out what is going on. I've had many problems with ROOT not drawing something, so it took quite a lot of debugging to figure out the problem was the data this time. It would improve user experience and save time for end users. ### Expected behavior. Warning or exception should be raised. Optionally, an empty graph can be drawn. . ### To Reproduce. Reproducible code with a bug (with np.nan values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409911-59aa5edb-e2d2-4410-b3e9-0159b3750721.png). Reproducible code **without** a bug (with valid y-axis values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.arange(num_values, dtype='float')). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409848-d88d2b5d-c4f6-4e0c-b02d-cb4a74bc49f0.png). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Using ROOT inside SWAN. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:1921,testability,context,context,1921,"TGraph collapses when supplied with invalid values; - [x] Checked for duplicates. ### Describe the bug. Supplying invalid values (np.nan) to TGraph does not warn me of invalid data, and the TGraph collapses into a single line. The same thing happens for TGraphErrors as well. For a user such as myself, it takes time to figure out what is going on. I've had many problems with ROOT not drawing something, so it took quite a lot of debugging to figure out the problem was the data this time. It would improve user experience and save time for end users. ### Expected behavior. Warning or exception should be raised. Optionally, an empty graph can be drawn. . ### To Reproduce. Reproducible code with a bug (with np.nan values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409911-59aa5edb-e2d2-4410-b3e9-0159b3750721.png). Reproducible code **without** a bug (with valid y-axis values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.arange(num_values, dtype='float')). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409848-d88d2b5d-c4f6-4e0c-b02d-cb4a74bc49f0.png). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Using ROOT inside SWAN. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:282,usability,user,user,282,"TGraph collapses when supplied with invalid values; - [x] Checked for duplicates. ### Describe the bug. Supplying invalid values (np.nan) to TGraph does not warn me of invalid data, and the TGraph collapses into a single line. The same thing happens for TGraphErrors as well. For a user such as myself, it takes time to figure out what is going on. I've had many problems with ROOT not drawing something, so it took quite a lot of debugging to figure out the problem was the data this time. It would improve user experience and save time for end users. ### Expected behavior. Warning or exception should be raised. Optionally, an empty graph can be drawn. . ### To Reproduce. Reproducible code with a bug (with np.nan values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409911-59aa5edb-e2d2-4410-b3e9-0159b3750721.png). Reproducible code **without** a bug (with valid y-axis values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.arange(num_values, dtype='float')). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409848-d88d2b5d-c4f6-4e0c-b02d-cb4a74bc49f0.png). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Using ROOT inside SWAN. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:508,usability,user,user,508,"TGraph collapses when supplied with invalid values; - [x] Checked for duplicates. ### Describe the bug. Supplying invalid values (np.nan) to TGraph does not warn me of invalid data, and the TGraph collapses into a single line. The same thing happens for TGraphErrors as well. For a user such as myself, it takes time to figure out what is going on. I've had many problems with ROOT not drawing something, so it took quite a lot of debugging to figure out the problem was the data this time. It would improve user experience and save time for end users. ### Expected behavior. Warning or exception should be raised. Optionally, an empty graph can be drawn. . ### To Reproduce. Reproducible code with a bug (with np.nan values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409911-59aa5edb-e2d2-4410-b3e9-0159b3750721.png). Reproducible code **without** a bug (with valid y-axis values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.arange(num_values, dtype='float')). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409848-d88d2b5d-c4f6-4e0c-b02d-cb4a74bc49f0.png). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Using ROOT inside SWAN. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:513,usability,experien,experience,513,"TGraph collapses when supplied with invalid values; - [x] Checked for duplicates. ### Describe the bug. Supplying invalid values (np.nan) to TGraph does not warn me of invalid data, and the TGraph collapses into a single line. The same thing happens for TGraphErrors as well. For a user such as myself, it takes time to figure out what is going on. I've had many problems with ROOT not drawing something, so it took quite a lot of debugging to figure out the problem was the data this time. It would improve user experience and save time for end users. ### Expected behavior. Warning or exception should be raised. Optionally, an empty graph can be drawn. . ### To Reproduce. Reproducible code with a bug (with np.nan values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409911-59aa5edb-e2d2-4410-b3e9-0159b3750721.png). Reproducible code **without** a bug (with valid y-axis values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.arange(num_values, dtype='float')). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409848-d88d2b5d-c4f6-4e0c-b02d-cb4a74bc49f0.png). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Using ROOT inside SWAN. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:546,usability,user,users,546,"TGraph collapses when supplied with invalid values; - [x] Checked for duplicates. ### Describe the bug. Supplying invalid values (np.nan) to TGraph does not warn me of invalid data, and the TGraph collapses into a single line. The same thing happens for TGraphErrors as well. For a user such as myself, it takes time to figure out what is going on. I've had many problems with ROOT not drawing something, so it took quite a lot of debugging to figure out the problem was the data this time. It would improve user experience and save time for end users. ### Expected behavior. Warning or exception should be raised. Optionally, an empty graph can be drawn. . ### To Reproduce. Reproducible code with a bug (with np.nan values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409911-59aa5edb-e2d2-4410-b3e9-0159b3750721.png). Reproducible code **without** a bug (with valid y-axis values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.arange(num_values, dtype='float')). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409848-d88d2b5d-c4f6-4e0c-b02d-cb4a74bc49f0.png). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Using ROOT inside SWAN. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:566,usability,behavi,behavior,566,"TGraph collapses when supplied with invalid values; - [x] Checked for duplicates. ### Describe the bug. Supplying invalid values (np.nan) to TGraph does not warn me of invalid data, and the TGraph collapses into a single line. The same thing happens for TGraphErrors as well. For a user such as myself, it takes time to figure out what is going on. I've had many problems with ROOT not drawing something, so it took quite a lot of debugging to figure out the problem was the data this time. It would improve user experience and save time for end users. ### Expected behavior. Warning or exception should be raised. Optionally, an empty graph can be drawn. . ### To Reproduce. Reproducible code with a bug (with np.nan values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409911-59aa5edb-e2d2-4410-b3e9-0159b3750721.png). Reproducible code **without** a bug (with valid y-axis values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.arange(num_values, dtype='float')). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409848-d88d2b5d-c4f6-4e0c-b02d-cb4a74bc49f0.png). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Using ROOT inside SWAN. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:1041,usability,user,user-images,1041,"TGraph collapses when supplied with invalid values; - [x] Checked for duplicates. ### Describe the bug. Supplying invalid values (np.nan) to TGraph does not warn me of invalid data, and the TGraph collapses into a single line. The same thing happens for TGraphErrors as well. For a user such as myself, it takes time to figure out what is going on. I've had many problems with ROOT not drawing something, so it took quite a lot of debugging to figure out the problem was the data this time. It would improve user experience and save time for end users. ### Expected behavior. Warning or exception should be raised. Optionally, an empty graph can be drawn. . ### To Reproduce. Reproducible code with a bug (with np.nan values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409911-59aa5edb-e2d2-4410-b3e9-0159b3750721.png). Reproducible code **without** a bug (with valid y-axis values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.arange(num_values, dtype='float')). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409848-d88d2b5d-c4f6-4e0c-b02d-cb4a74bc49f0.png). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Using ROOT inside SWAN. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:1513,usability,user,user-images,1513,"TGraph collapses when supplied with invalid values; - [x] Checked for duplicates. ### Describe the bug. Supplying invalid values (np.nan) to TGraph does not warn me of invalid data, and the TGraph collapses into a single line. The same thing happens for TGraphErrors as well. For a user such as myself, it takes time to figure out what is going on. I've had many problems with ROOT not drawing something, so it took quite a lot of debugging to figure out the problem was the data this time. It would improve user experience and save time for end users. ### Expected behavior. Warning or exception should be raised. Optionally, an empty graph can be drawn. . ### To Reproduce. Reproducible code with a bug (with np.nan values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409911-59aa5edb-e2d2-4410-b3e9-0159b3750721.png). Reproducible code **without** a bug (with valid y-axis values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.arange(num_values, dtype='float')). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409848-d88d2b5d-c4f6-4e0c-b02d-cb4a74bc49f0.png). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Using ROOT inside SWAN. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:1638,usability,behavi,behavior,1638,"TGraph collapses when supplied with invalid values; - [x] Checked for duplicates. ### Describe the bug. Supplying invalid values (np.nan) to TGraph does not warn me of invalid data, and the TGraph collapses into a single line. The same thing happens for TGraphErrors as well. For a user such as myself, it takes time to figure out what is going on. I've had many problems with ROOT not drawing something, so it took quite a lot of debugging to figure out the problem was the data this time. It would improve user experience and save time for end users. ### Expected behavior. Warning or exception should be raised. Optionally, an empty graph can be drawn. . ### To Reproduce. Reproducible code with a bug (with np.nan values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409911-59aa5edb-e2d2-4410-b3e9-0159b3750721.png). Reproducible code **without** a bug (with valid y-axis values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.arange(num_values, dtype='float')). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409848-d88d2b5d-c4f6-4e0c-b02d-cb4a74bc49f0.png). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Using ROOT inside SWAN. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12296:1783,usability,input,input,1783,"TGraph collapses when supplied with invalid values; - [x] Checked for duplicates. ### Describe the bug. Supplying invalid values (np.nan) to TGraph does not warn me of invalid data, and the TGraph collapses into a single line. The same thing happens for TGraphErrors as well. For a user such as myself, it takes time to figure out what is going on. I've had many problems with ROOT not drawing something, so it took quite a lot of debugging to figure out the problem was the data this time. It would improve user experience and save time for end users. ### Expected behavior. Warning or exception should be raised. Optionally, an empty graph can be drawn. . ### To Reproduce. Reproducible code with a bug (with np.nan values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.full(num_values, fill_value=np.nan)). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409911-59aa5edb-e2d2-4410-b3e9-0159b3750721.png). Reproducible code **without** a bug (with valid y-axis values):. ```. import ROOT. canvas = ROOT.TCanvas(f""test_canvas"", ""title"", 400, 400). canvas.Draw(). canvas.cd(). num_values = 5. g = ROOT.TGraph(num_values, . np.arange(num_values, dtype='float'), . np.arange(num_values, dtype='float')). g.SetMarkerSize(2). g.SetMarkerStyle(2). g.DrawClone('AP'). ```. ![image](https://user-images.githubusercontent.com/22337362/218409848-d88d2b5d-c4f6-4e0c-b02d-cb4a74bc49f0.png). <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. Using ROOT inside SWAN. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12296
https://github.com/root-project/root/issues/12297:230,deployability,build,buildroot,230,"CI: config specification; We need to be able to specify ""`ubuntu22` combined with `-DDLLVM_BUILD_TYPE=Debug -Dsoversion=On`"". Ideally we can trigger such a bit from a PR commit. Also for the matrix specified in `.github/workflows/buildroot.yml`:. ```yaml. strategy:. matrix:. image: [""fedora37"", ""centos8"", ""ubuntu18"", ""ubuntu20"", ""ubuntu22""]. config: [""Release""]. ```. we want to specify the flags. We discussed changing this to a list; for me, `[""ubuntu22"", ""-DDLLVM_BUILD_TYPE=Debug"", ""-Dsoversion=On""]` would work well as a replacement for the current `""ubuntu22""` entry.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12297
https://github.com/root-project/root/issues/12297:354,deployability,Releas,Release,354,"CI: config specification; We need to be able to specify ""`ubuntu22` combined with `-DDLLVM_BUILD_TYPE=Debug -Dsoversion=On`"". Ideally we can trigger such a bit from a PR commit. Also for the matrix specified in `.github/workflows/buildroot.yml`:. ```yaml. strategy:. matrix:. image: [""fedora37"", ""centos8"", ""ubuntu18"", ""ubuntu20"", ""ubuntu22""]. config: [""Release""]. ```. we want to specify the flags. We discussed changing this to a list; for me, `[""ubuntu22"", ""-DDLLVM_BUILD_TYPE=Debug"", ""-Dsoversion=On""]` would work well as a replacement for the current `""ubuntu22""` entry.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12297
https://github.com/root-project/root/issues/12297:548,energy efficiency,current,current,548,"CI: config specification; We need to be able to specify ""`ubuntu22` combined with `-DDLLVM_BUILD_TYPE=Debug -Dsoversion=On`"". Ideally we can trigger such a bit from a PR commit. Also for the matrix specified in `.github/workflows/buildroot.yml`:. ```yaml. strategy:. matrix:. image: [""fedora37"", ""centos8"", ""ubuntu18"", ""ubuntu20"", ""ubuntu22""]. config: [""Release""]. ```. we want to specify the flags. We discussed changing this to a list; for me, `[""ubuntu22"", ""-DDLLVM_BUILD_TYPE=Debug"", ""-Dsoversion=On""]` would work well as a replacement for the current `""ubuntu22""` entry.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12297
https://github.com/root-project/root/issues/12297:11,interoperability,specif,specification,11,"CI: config specification; We need to be able to specify ""`ubuntu22` combined with `-DDLLVM_BUILD_TYPE=Debug -Dsoversion=On`"". Ideally we can trigger such a bit from a PR commit. Also for the matrix specified in `.github/workflows/buildroot.yml`:. ```yaml. strategy:. matrix:. image: [""fedora37"", ""centos8"", ""ubuntu18"", ""ubuntu20"", ""ubuntu22""]. config: [""Release""]. ```. we want to specify the flags. We discussed changing this to a list; for me, `[""ubuntu22"", ""-DDLLVM_BUILD_TYPE=Debug"", ""-Dsoversion=On""]` would work well as a replacement for the current `""ubuntu22""` entry.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12297
https://github.com/root-project/root/issues/12297:48,interoperability,specif,specify,48,"CI: config specification; We need to be able to specify ""`ubuntu22` combined with `-DDLLVM_BUILD_TYPE=Debug -Dsoversion=On`"". Ideally we can trigger such a bit from a PR commit. Also for the matrix specified in `.github/workflows/buildroot.yml`:. ```yaml. strategy:. matrix:. image: [""fedora37"", ""centos8"", ""ubuntu18"", ""ubuntu20"", ""ubuntu22""]. config: [""Release""]. ```. we want to specify the flags. We discussed changing this to a list; for me, `[""ubuntu22"", ""-DDLLVM_BUILD_TYPE=Debug"", ""-Dsoversion=On""]` would work well as a replacement for the current `""ubuntu22""` entry.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12297
https://github.com/root-project/root/issues/12297:198,interoperability,specif,specified,198,"CI: config specification; We need to be able to specify ""`ubuntu22` combined with `-DDLLVM_BUILD_TYPE=Debug -Dsoversion=On`"". Ideally we can trigger such a bit from a PR commit. Also for the matrix specified in `.github/workflows/buildroot.yml`:. ```yaml. strategy:. matrix:. image: [""fedora37"", ""centos8"", ""ubuntu18"", ""ubuntu20"", ""ubuntu22""]. config: [""Release""]. ```. we want to specify the flags. We discussed changing this to a list; for me, `[""ubuntu22"", ""-DDLLVM_BUILD_TYPE=Debug"", ""-Dsoversion=On""]` would work well as a replacement for the current `""ubuntu22""` entry.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12297
https://github.com/root-project/root/issues/12297:381,interoperability,specif,specify,381,"CI: config specification; We need to be able to specify ""`ubuntu22` combined with `-DDLLVM_BUILD_TYPE=Debug -Dsoversion=On`"". Ideally we can trigger such a bit from a PR commit. Also for the matrix specified in `.github/workflows/buildroot.yml`:. ```yaml. strategy:. matrix:. image: [""fedora37"", ""centos8"", ""ubuntu18"", ""ubuntu20"", ""ubuntu22""]. config: [""Release""]. ```. we want to specify the flags. We discussed changing this to a list; for me, `[""ubuntu22"", ""-DDLLVM_BUILD_TYPE=Debug"", ""-Dsoversion=On""]` would work well as a replacement for the current `""ubuntu22""` entry.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12297
https://github.com/root-project/root/issues/12297:220,usability,workflow,workflows,220,"CI: config specification; We need to be able to specify ""`ubuntu22` combined with `-DDLLVM_BUILD_TYPE=Debug -Dsoversion=On`"". Ideally we can trigger such a bit from a PR commit. Also for the matrix specified in `.github/workflows/buildroot.yml`:. ```yaml. strategy:. matrix:. image: [""fedora37"", ""centos8"", ""ubuntu18"", ""ubuntu20"", ""ubuntu22""]. config: [""Release""]. ```. we want to specify the flags. We discussed changing this to a list; for me, `[""ubuntu22"", ""-DDLLVM_BUILD_TYPE=Debug"", ""-Dsoversion=On""]` would work well as a replacement for the current `""ubuntu22""` entry.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12297
https://github.com/root-project/root/pull/12298:44,deployability,Releas,ReleasePage,44,[ntuple] RPageSinkBuf: add missing call to `ReleasePage()`; Add missing call to `ReleasePage()` to free memory used for all the buffered pages after the vector write case (call to `CommitSealedPageV()`). This fixes an unfortunate memory leak we introduced in https://github.com/root-project/root/pull/10775. Thanks @glmiotto! ## Checklist:. - [X] tested changes locally,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12298
https://github.com/root-project/root/pull/12298:81,deployability,Releas,ReleasePage,81,[ntuple] RPageSinkBuf: add missing call to `ReleasePage()`; Add missing call to `ReleasePage()` to free memory used for all the buffered pages after the vector write case (call to `CommitSealedPageV()`). This fixes an unfortunate memory leak we introduced in https://github.com/root-project/root/pull/10775. Thanks @glmiotto! ## Checklist:. - [X] tested changes locally,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12298
https://github.com/root-project/root/pull/12298:128,integrability,buffer,buffered,128,[ntuple] RPageSinkBuf: add missing call to `ReleasePage()`; Add missing call to `ReleasePage()` to free memory used for all the buffered pages after the vector write case (call to `CommitSealedPageV()`). This fixes an unfortunate memory leak we introduced in https://github.com/root-project/root/pull/10775. Thanks @glmiotto! ## Checklist:. - [X] tested changes locally,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12298
https://github.com/root-project/root/pull/12298:104,performance,memor,memory,104,[ntuple] RPageSinkBuf: add missing call to `ReleasePage()`; Add missing call to `ReleasePage()` to free memory used for all the buffered pages after the vector write case (call to `CommitSealedPageV()`). This fixes an unfortunate memory leak we introduced in https://github.com/root-project/root/pull/10775. Thanks @glmiotto! ## Checklist:. - [X] tested changes locally,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12298
https://github.com/root-project/root/pull/12298:230,performance,memor,memory,230,[ntuple] RPageSinkBuf: add missing call to `ReleasePage()`; Add missing call to `ReleasePage()` to free memory used for all the buffered pages after the vector write case (call to `CommitSealedPageV()`). This fixes an unfortunate memory leak we introduced in https://github.com/root-project/root/pull/10775. Thanks @glmiotto! ## Checklist:. - [X] tested changes locally,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12298
https://github.com/root-project/root/pull/12298:347,safety,test,tested,347,[ntuple] RPageSinkBuf: add missing call to `ReleasePage()`; Add missing call to `ReleasePage()` to free memory used for all the buffered pages after the vector write case (call to `CommitSealedPageV()`). This fixes an unfortunate memory leak we introduced in https://github.com/root-project/root/pull/10775. Thanks @glmiotto! ## Checklist:. - [X] tested changes locally,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12298
https://github.com/root-project/root/pull/12298:347,testability,test,tested,347,[ntuple] RPageSinkBuf: add missing call to `ReleasePage()`; Add missing call to `ReleasePage()` to free memory used for all the buffered pages after the vector write case (call to `CommitSealedPageV()`). This fixes an unfortunate memory leak we introduced in https://github.com/root-project/root/pull/10775. Thanks @glmiotto! ## Checklist:. - [X] tested changes locally,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12298
https://github.com/root-project/root/pull/12298:104,usability,memor,memory,104,[ntuple] RPageSinkBuf: add missing call to `ReleasePage()`; Add missing call to `ReleasePage()` to free memory used for all the buffered pages after the vector write case (call to `CommitSealedPageV()`). This fixes an unfortunate memory leak we introduced in https://github.com/root-project/root/pull/10775. Thanks @glmiotto! ## Checklist:. - [X] tested changes locally,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12298
https://github.com/root-project/root/pull/12298:230,usability,memor,memory,230,[ntuple] RPageSinkBuf: add missing call to `ReleasePage()`; Add missing call to `ReleasePage()` to free memory used for all the buffered pages after the vector write case (call to `CommitSealedPageV()`). This fixes an unfortunate memory leak we introduced in https://github.com/root-project/root/pull/10775. Thanks @glmiotto! ## Checklist:. - [X] tested changes locally,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12298
https://github.com/root-project/root/pull/12299:1,deployability,build,build,1,"[build] Add Python executable to root-config; To allow. ```. vpadulan@fedora [~/programs/rootproject/rootinstall]: root-config --python-executable. /usr/bin/python3.10. vpadulan@fedora [~/programs/rootproject/rootinstall]: root-config --python3-executable. /usr/bin/python3.10. vpadulan@fedora [~/programs/rootproject/rootinstall]: root-config --python2-executable. /usr/bin/python2.7. vpadulan@fedora [~/programs/rootproject/rootinstall]: `root-config --python2-executable` -c ""import ROOT; print(ROOT.__version__)"". 6.29/01. vpadulan@fedora [~/programs/rootproject/rootinstall]: `root-config --python-executable` -c ""import ROOT; print(ROOT.__version__)"". 6.29/01. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12299
https://github.com/root-project/root/pull/12300:21,usability,document,documentation,21,Fixing a typo in the documentation: `SetOptStats --> SetOptStat`; `SetOptStats` --> `SetOptStat`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12300
https://github.com/root-project/root/pull/12301:21,usability,document,documentation,21,fixing a typo in the documentation; `SetOptStats` --> `SetOptStat`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12301
https://github.com/root-project/root/issues/12302:36,deployability,build,build,36,[ci] Make it possible to force a CI build from scratch; For some types of changes incremental builds are expected to fail (e.g. if source files are moved or removed). For those cases we probably need a way to ask the CI to rebuild from scratch rather than perform an incremental build.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:94,deployability,build,builds,94,[ci] Make it possible to force a CI build from scratch; For some types of changes incremental builds are expected to fail (e.g. if source files are moved or removed). For those cases we probably need a way to ask the CI to rebuild from scratch rather than perform an incremental build.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:117,deployability,fail,fail,117,[ci] Make it possible to force a CI build from scratch; For some types of changes incremental builds are expected to fail (e.g. if source files are moved or removed). For those cases we probably need a way to ask the CI to rebuild from scratch rather than perform an incremental build.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:279,deployability,build,build,279,[ci] Make it possible to force a CI build from scratch; For some types of changes incremental builds are expected to fail (e.g. if source files are moved or removed). For those cases we probably need a way to ask the CI to rebuild from scratch rather than perform an incremental build.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:256,performance,perform,perform,256,[ci] Make it possible to force a CI build from scratch; For some types of changes incremental builds are expected to fail (e.g. if source files are moved or removed). For those cases we probably need a way to ask the CI to rebuild from scratch rather than perform an incremental build.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:117,reliability,fail,fail,117,[ci] Make it possible to force a CI build from scratch; For some types of changes incremental builds are expected to fail (e.g. if source files are moved or removed). For those cases we probably need a way to ask the CI to rebuild from scratch rather than perform an incremental build.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12302:256,usability,perform,perform,256,[ci] Make it possible to force a CI build from scratch; For some types of changes incremental builds are expected to fail (e.g. if source files are moved or removed). For those cases we probably need a way to ask the CI to rebuild from scratch rather than perform an incremental build.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12302
https://github.com/root-project/root/issues/12303:438,deployability,contain,contains,438,"[DF] Implement weighted Filters; Serious analyses involve running on MC samples which are tipically assigned a weight. If `Filters` could be informed of event weights, `Report`s could take that into account (as requested at https://root-forum.cern.ch/t/rdataframe-feature-request-weighted-cut-reports/53570). Alternative we could add a mechanism to keep track of event weights separately, in a dedicated ""virtual"" column (that by default contains all ones, e.g., as discussed with G. Petrucciani from CMS a couple of times:. ```python. df.UpdateEventWeight(""w1""). .UpdateEventWeight(""w2""). .Filter(""x > 0""). .Histo1D(""x"", ""rdfeventweight_""). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12303
https://github.com/root-project/root/issues/12303:539,deployability,Updat,UpdateEventWeight,539,"[DF] Implement weighted Filters; Serious analyses involve running on MC samples which are tipically assigned a weight. If `Filters` could be informed of event weights, `Report`s could take that into account (as requested at https://root-forum.cern.ch/t/rdataframe-feature-request-weighted-cut-reports/53570). Alternative we could add a mechanism to keep track of event weights separately, in a dedicated ""virtual"" column (that by default contains all ones, e.g., as discussed with G. Petrucciani from CMS a couple of times:. ```python. df.UpdateEventWeight(""w1""). .UpdateEventWeight(""w2""). .Filter(""x > 0""). .Histo1D(""x"", ""rdfeventweight_""). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12303
https://github.com/root-project/root/issues/12303:565,deployability,Updat,UpdateEventWeight,565,"[DF] Implement weighted Filters; Serious analyses involve running on MC samples which are tipically assigned a weight. If `Filters` could be informed of event weights, `Report`s could take that into account (as requested at https://root-forum.cern.ch/t/rdataframe-feature-request-weighted-cut-reports/53570). Alternative we could add a mechanism to keep track of event weights separately, in a dedicated ""virtual"" column (that by default contains all ones, e.g., as discussed with G. Petrucciani from CMS a couple of times:. ```python. df.UpdateEventWeight(""w1""). .UpdateEventWeight(""w2""). .Filter(""x > 0""). .Histo1D(""x"", ""rdfeventweight_""). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12303
https://github.com/root-project/root/issues/12303:24,integrability,Filter,Filters,24,"[DF] Implement weighted Filters; Serious analyses involve running on MC samples which are tipically assigned a weight. If `Filters` could be informed of event weights, `Report`s could take that into account (as requested at https://root-forum.cern.ch/t/rdataframe-feature-request-weighted-cut-reports/53570). Alternative we could add a mechanism to keep track of event weights separately, in a dedicated ""virtual"" column (that by default contains all ones, e.g., as discussed with G. Petrucciani from CMS a couple of times:. ```python. df.UpdateEventWeight(""w1""). .UpdateEventWeight(""w2""). .Filter(""x > 0""). .Histo1D(""x"", ""rdfeventweight_""). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12303
https://github.com/root-project/root/issues/12303:123,integrability,Filter,Filters,123,"[DF] Implement weighted Filters; Serious analyses involve running on MC samples which are tipically assigned a weight. If `Filters` could be informed of event weights, `Report`s could take that into account (as requested at https://root-forum.cern.ch/t/rdataframe-feature-request-weighted-cut-reports/53570). Alternative we could add a mechanism to keep track of event weights separately, in a dedicated ""virtual"" column (that by default contains all ones, e.g., as discussed with G. Petrucciani from CMS a couple of times:. ```python. df.UpdateEventWeight(""w1""). .UpdateEventWeight(""w2""). .Filter(""x > 0""). .Histo1D(""x"", ""rdfeventweight_""). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12303
https://github.com/root-project/root/issues/12303:153,integrability,event,event,153,"[DF] Implement weighted Filters; Serious analyses involve running on MC samples which are tipically assigned a weight. If `Filters` could be informed of event weights, `Report`s could take that into account (as requested at https://root-forum.cern.ch/t/rdataframe-feature-request-weighted-cut-reports/53570). Alternative we could add a mechanism to keep track of event weights separately, in a dedicated ""virtual"" column (that by default contains all ones, e.g., as discussed with G. Petrucciani from CMS a couple of times:. ```python. df.UpdateEventWeight(""w1""). .UpdateEventWeight(""w2""). .Filter(""x > 0""). .Histo1D(""x"", ""rdfeventweight_""). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12303
https://github.com/root-project/root/issues/12303:363,integrability,event,event,363,"[DF] Implement weighted Filters; Serious analyses involve running on MC samples which are tipically assigned a weight. If `Filters` could be informed of event weights, `Report`s could take that into account (as requested at https://root-forum.cern.ch/t/rdataframe-feature-request-weighted-cut-reports/53570). Alternative we could add a mechanism to keep track of event weights separately, in a dedicated ""virtual"" column (that by default contains all ones, e.g., as discussed with G. Petrucciani from CMS a couple of times:. ```python. df.UpdateEventWeight(""w1""). .UpdateEventWeight(""w2""). .Filter(""x > 0""). .Histo1D(""x"", ""rdfeventweight_""). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12303
https://github.com/root-project/root/issues/12303:507,integrability,coupl,couple,507,"[DF] Implement weighted Filters; Serious analyses involve running on MC samples which are tipically assigned a weight. If `Filters` could be informed of event weights, `Report`s could take that into account (as requested at https://root-forum.cern.ch/t/rdataframe-feature-request-weighted-cut-reports/53570). Alternative we could add a mechanism to keep track of event weights separately, in a dedicated ""virtual"" column (that by default contains all ones, e.g., as discussed with G. Petrucciani from CMS a couple of times:. ```python. df.UpdateEventWeight(""w1""). .UpdateEventWeight(""w2""). .Filter(""x > 0""). .Histo1D(""x"", ""rdfeventweight_""). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12303
https://github.com/root-project/root/issues/12303:591,integrability,Filter,Filter,591,"[DF] Implement weighted Filters; Serious analyses involve running on MC samples which are tipically assigned a weight. If `Filters` could be informed of event weights, `Report`s could take that into account (as requested at https://root-forum.cern.ch/t/rdataframe-feature-request-weighted-cut-reports/53570). Alternative we could add a mechanism to keep track of event weights separately, in a dedicated ""virtual"" column (that by default contains all ones, e.g., as discussed with G. Petrucciani from CMS a couple of times:. ```python. df.UpdateEventWeight(""w1""). .UpdateEventWeight(""w2""). .Filter(""x > 0""). .Histo1D(""x"", ""rdfeventweight_""). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12303
https://github.com/root-project/root/issues/12303:507,modifiability,coupl,couple,507,"[DF] Implement weighted Filters; Serious analyses involve running on MC samples which are tipically assigned a weight. If `Filters` could be informed of event weights, `Report`s could take that into account (as requested at https://root-forum.cern.ch/t/rdataframe-feature-request-weighted-cut-reports/53570). Alternative we could add a mechanism to keep track of event weights separately, in a dedicated ""virtual"" column (that by default contains all ones, e.g., as discussed with G. Petrucciani from CMS a couple of times:. ```python. df.UpdateEventWeight(""w1""). .UpdateEventWeight(""w2""). .Filter(""x > 0""). .Histo1D(""x"", ""rdfeventweight_""). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12303
https://github.com/root-project/root/issues/12303:517,performance,time,times,517,"[DF] Implement weighted Filters; Serious analyses involve running on MC samples which are tipically assigned a weight. If `Filters` could be informed of event weights, `Report`s could take that into account (as requested at https://root-forum.cern.ch/t/rdataframe-feature-request-weighted-cut-reports/53570). Alternative we could add a mechanism to keep track of event weights separately, in a dedicated ""virtual"" column (that by default contains all ones, e.g., as discussed with G. Petrucciani from CMS a couple of times:. ```python. df.UpdateEventWeight(""w1""). .UpdateEventWeight(""w2""). .Filter(""x > 0""). .Histo1D(""x"", ""rdfeventweight_""). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12303
https://github.com/root-project/root/issues/12303:539,safety,Updat,UpdateEventWeight,539,"[DF] Implement weighted Filters; Serious analyses involve running on MC samples which are tipically assigned a weight. If `Filters` could be informed of event weights, `Report`s could take that into account (as requested at https://root-forum.cern.ch/t/rdataframe-feature-request-weighted-cut-reports/53570). Alternative we could add a mechanism to keep track of event weights separately, in a dedicated ""virtual"" column (that by default contains all ones, e.g., as discussed with G. Petrucciani from CMS a couple of times:. ```python. df.UpdateEventWeight(""w1""). .UpdateEventWeight(""w2""). .Filter(""x > 0""). .Histo1D(""x"", ""rdfeventweight_""). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12303
https://github.com/root-project/root/issues/12303:565,safety,Updat,UpdateEventWeight,565,"[DF] Implement weighted Filters; Serious analyses involve running on MC samples which are tipically assigned a weight. If `Filters` could be informed of event weights, `Report`s could take that into account (as requested at https://root-forum.cern.ch/t/rdataframe-feature-request-weighted-cut-reports/53570). Alternative we could add a mechanism to keep track of event weights separately, in a dedicated ""virtual"" column (that by default contains all ones, e.g., as discussed with G. Petrucciani from CMS a couple of times:. ```python. df.UpdateEventWeight(""w1""). .UpdateEventWeight(""w2""). .Filter(""x > 0""). .Histo1D(""x"", ""rdfeventweight_""). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12303
https://github.com/root-project/root/issues/12303:539,security,Updat,UpdateEventWeight,539,"[DF] Implement weighted Filters; Serious analyses involve running on MC samples which are tipically assigned a weight. If `Filters` could be informed of event weights, `Report`s could take that into account (as requested at https://root-forum.cern.ch/t/rdataframe-feature-request-weighted-cut-reports/53570). Alternative we could add a mechanism to keep track of event weights separately, in a dedicated ""virtual"" column (that by default contains all ones, e.g., as discussed with G. Petrucciani from CMS a couple of times:. ```python. df.UpdateEventWeight(""w1""). .UpdateEventWeight(""w2""). .Filter(""x > 0""). .Histo1D(""x"", ""rdfeventweight_""). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12303
https://github.com/root-project/root/issues/12303:565,security,Updat,UpdateEventWeight,565,"[DF] Implement weighted Filters; Serious analyses involve running on MC samples which are tipically assigned a weight. If `Filters` could be informed of event weights, `Report`s could take that into account (as requested at https://root-forum.cern.ch/t/rdataframe-feature-request-weighted-cut-reports/53570). Alternative we could add a mechanism to keep track of event weights separately, in a dedicated ""virtual"" column (that by default contains all ones, e.g., as discussed with G. Petrucciani from CMS a couple of times:. ```python. df.UpdateEventWeight(""w1""). .UpdateEventWeight(""w2""). .Filter(""x > 0""). .Histo1D(""x"", ""rdfeventweight_""). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12303
https://github.com/root-project/root/issues/12303:507,testability,coupl,couple,507,"[DF] Implement weighted Filters; Serious analyses involve running on MC samples which are tipically assigned a weight. If `Filters` could be informed of event weights, `Report`s could take that into account (as requested at https://root-forum.cern.ch/t/rdataframe-feature-request-weighted-cut-reports/53570). Alternative we could add a mechanism to keep track of event weights separately, in a dedicated ""virtual"" column (that by default contains all ones, e.g., as discussed with G. Petrucciani from CMS a couple of times:. ```python. df.UpdateEventWeight(""w1""). .UpdateEventWeight(""w2""). .Filter(""x > 0""). .Histo1D(""x"", ""rdfeventweight_""). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12303
https://github.com/root-project/root/issues/12303:90,usability,tip,tipically,90,"[DF] Implement weighted Filters; Serious analyses involve running on MC samples which are tipically assigned a weight. If `Filters` could be informed of event weights, `Report`s could take that into account (as requested at https://root-forum.cern.ch/t/rdataframe-feature-request-weighted-cut-reports/53570). Alternative we could add a mechanism to keep track of event weights separately, in a dedicated ""virtual"" column (that by default contains all ones, e.g., as discussed with G. Petrucciani from CMS a couple of times:. ```python. df.UpdateEventWeight(""w1""). .UpdateEventWeight(""w2""). .Filter(""x > 0""). .Histo1D(""x"", ""rdfeventweight_""). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12303
https://github.com/root-project/root/pull/12304:211,deployability,observ,observables,211,"[RF] Where appropriate, take titles from input objects in HistFactory; It would be nice if HistFactory propagated some additional information from the input objects to the workspace. For starters, the titles of observables could be taken from the axis of the input histograms, and channel and sample names from the titles of histograms. . It would be good to think about how to best port over additional info (like histogram styling) once we have settled on a convention for that!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12304
https://github.com/root-project/root/pull/12304:41,safety,input,input,41,"[RF] Where appropriate, take titles from input objects in HistFactory; It would be nice if HistFactory propagated some additional information from the input objects to the workspace. For starters, the titles of observables could be taken from the axis of the input histograms, and channel and sample names from the titles of histograms. . It would be good to think about how to best port over additional info (like histogram styling) once we have settled on a convention for that!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12304
https://github.com/root-project/root/pull/12304:151,safety,input,input,151,"[RF] Where appropriate, take titles from input objects in HistFactory; It would be nice if HistFactory propagated some additional information from the input objects to the workspace. For starters, the titles of observables could be taken from the axis of the input histograms, and channel and sample names from the titles of histograms. . It would be good to think about how to best port over additional info (like histogram styling) once we have settled on a convention for that!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12304
https://github.com/root-project/root/pull/12304:259,safety,input,input,259,"[RF] Where appropriate, take titles from input objects in HistFactory; It would be nice if HistFactory propagated some additional information from the input objects to the workspace. For starters, the titles of observables could be taken from the axis of the input histograms, and channel and sample names from the titles of histograms. . It would be good to think about how to best port over additional info (like histogram styling) once we have settled on a convention for that!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12304
https://github.com/root-project/root/pull/12304:211,testability,observ,observables,211,"[RF] Where appropriate, take titles from input objects in HistFactory; It would be nice if HistFactory propagated some additional information from the input objects to the workspace. For starters, the titles of observables could be taken from the axis of the input histograms, and channel and sample names from the titles of histograms. . It would be good to think about how to best port over additional info (like histogram styling) once we have settled on a convention for that!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12304
https://github.com/root-project/root/pull/12304:41,usability,input,input,41,"[RF] Where appropriate, take titles from input objects in HistFactory; It would be nice if HistFactory propagated some additional information from the input objects to the workspace. For starters, the titles of observables could be taken from the axis of the input histograms, and channel and sample names from the titles of histograms. . It would be good to think about how to best port over additional info (like histogram styling) once we have settled on a convention for that!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12304
https://github.com/root-project/root/pull/12304:151,usability,input,input,151,"[RF] Where appropriate, take titles from input objects in HistFactory; It would be nice if HistFactory propagated some additional information from the input objects to the workspace. For starters, the titles of observables could be taken from the axis of the input histograms, and channel and sample names from the titles of histograms. . It would be good to think about how to best port over additional info (like histogram styling) once we have settled on a convention for that!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12304
https://github.com/root-project/root/pull/12304:259,usability,input,input,259,"[RF] Where appropriate, take titles from input objects in HistFactory; It would be nice if HistFactory propagated some additional information from the input objects to the workspace. For starters, the titles of observables could be taken from the axis of the input histograms, and channel and sample names from the titles of histograms. . It would be good to think about how to best port over additional info (like histogram styling) once we have settled on a convention for that!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12304
https://github.com/root-project/root/pull/12305:280,availability,error,error,280,"[RF] Support `RooAbsCategoryLValue::setBin()` for non-existing ranges ; In `RooAbsCategoryLValue::setBin()`, there is a check for passing a. named binning, because the function doesn't support named binnings. However, if a binning with that name doesn't exist, it is fine to not. error out, because the default range is used. This supports the fit in this forum post:. https://root-forum.cern.ch/t/roosimultaneous-and-roofftconvpdf/53606. There are also two additional commits with some code modernization as usual.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12305
https://github.com/root-project/root/pull/12305:280,performance,error,error,280,"[RF] Support `RooAbsCategoryLValue::setBin()` for non-existing ranges ; In `RooAbsCategoryLValue::setBin()`, there is a check for passing a. named binning, because the function doesn't support named binnings. However, if a binning with that name doesn't exist, it is fine to not. error out, because the default range is used. This supports the fit in this forum post:. https://root-forum.cern.ch/t/roosimultaneous-and-roofftconvpdf/53606. There are also two additional commits with some code modernization as usual.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12305
https://github.com/root-project/root/pull/12305:177,reliability,doe,doesn,177,"[RF] Support `RooAbsCategoryLValue::setBin()` for non-existing ranges ; In `RooAbsCategoryLValue::setBin()`, there is a check for passing a. named binning, because the function doesn't support named binnings. However, if a binning with that name doesn't exist, it is fine to not. error out, because the default range is used. This supports the fit in this forum post:. https://root-forum.cern.ch/t/roosimultaneous-and-roofftconvpdf/53606. There are also two additional commits with some code modernization as usual.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12305
https://github.com/root-project/root/pull/12305:246,reliability,doe,doesn,246,"[RF] Support `RooAbsCategoryLValue::setBin()` for non-existing ranges ; In `RooAbsCategoryLValue::setBin()`, there is a check for passing a. named binning, because the function doesn't support named binnings. However, if a binning with that name doesn't exist, it is fine to not. error out, because the default range is used. This supports the fit in this forum post:. https://root-forum.cern.ch/t/roosimultaneous-and-roofftconvpdf/53606. There are also two additional commits with some code modernization as usual.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12305
https://github.com/root-project/root/pull/12305:280,safety,error,error,280,"[RF] Support `RooAbsCategoryLValue::setBin()` for non-existing ranges ; In `RooAbsCategoryLValue::setBin()`, there is a check for passing a. named binning, because the function doesn't support named binnings. However, if a binning with that name doesn't exist, it is fine to not. error out, because the default range is used. This supports the fit in this forum post:. https://root-forum.cern.ch/t/roosimultaneous-and-roofftconvpdf/53606. There are also two additional commits with some code modernization as usual.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12305
https://github.com/root-project/root/pull/12305:5,usability,Support,Support,5,"[RF] Support `RooAbsCategoryLValue::setBin()` for non-existing ranges ; In `RooAbsCategoryLValue::setBin()`, there is a check for passing a. named binning, because the function doesn't support named binnings. However, if a binning with that name doesn't exist, it is fine to not. error out, because the default range is used. This supports the fit in this forum post:. https://root-forum.cern.ch/t/roosimultaneous-and-roofftconvpdf/53606. There are also two additional commits with some code modernization as usual.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12305
https://github.com/root-project/root/pull/12305:185,usability,support,support,185,"[RF] Support `RooAbsCategoryLValue::setBin()` for non-existing ranges ; In `RooAbsCategoryLValue::setBin()`, there is a check for passing a. named binning, because the function doesn't support named binnings. However, if a binning with that name doesn't exist, it is fine to not. error out, because the default range is used. This supports the fit in this forum post:. https://root-forum.cern.ch/t/roosimultaneous-and-roofftconvpdf/53606. There are also two additional commits with some code modernization as usual.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12305
https://github.com/root-project/root/pull/12305:280,usability,error,error,280,"[RF] Support `RooAbsCategoryLValue::setBin()` for non-existing ranges ; In `RooAbsCategoryLValue::setBin()`, there is a check for passing a. named binning, because the function doesn't support named binnings. However, if a binning with that name doesn't exist, it is fine to not. error out, because the default range is used. This supports the fit in this forum post:. https://root-forum.cern.ch/t/roosimultaneous-and-roofftconvpdf/53606. There are also two additional commits with some code modernization as usual.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12305
https://github.com/root-project/root/pull/12305:331,usability,support,supports,331,"[RF] Support `RooAbsCategoryLValue::setBin()` for non-existing ranges ; In `RooAbsCategoryLValue::setBin()`, there is a check for passing a. named binning, because the function doesn't support named binnings. However, if a binning with that name doesn't exist, it is fine to not. error out, because the default range is used. This supports the fit in this forum post:. https://root-forum.cern.ch/t/roosimultaneous-and-roofftconvpdf/53606. There are also two additional commits with some code modernization as usual.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12305
https://github.com/root-project/root/issues/12306:466,energy efficiency,draw,drawing,466,"[graphics] Consider adding legend to `TRatioPlot` example; Adding a legend to the first example in the [TRatioPlot documentation](https://root.cern.ch/doc/master/classTRatioPlot.html) would prevent recurring questions like these:. * https://root-forum.cern.ch/t/tlegend-disappears-when-i-add-a-tratioplot-pyroot/53609. * https://root-forum.cern.ch/t/creating-legend-for-upper-plot-in-tratioplot/35235. One should also add a not right at the example that the default drawing options for the histograms are `""hist""` and `""E""` for h1 and h2 respectively, and mention that these can be changed with `SetH1DrawOpt` and `SetH2DrawOpt` (as this also triggered questions on the forum).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12306
https://github.com/root-project/root/issues/12306:190,safety,prevent,prevent,190,"[graphics] Consider adding legend to `TRatioPlot` example; Adding a legend to the first example in the [TRatioPlot documentation](https://root.cern.ch/doc/master/classTRatioPlot.html) would prevent recurring questions like these:. * https://root-forum.cern.ch/t/tlegend-disappears-when-i-add-a-tratioplot-pyroot/53609. * https://root-forum.cern.ch/t/creating-legend-for-upper-plot-in-tratioplot/35235. One should also add a not right at the example that the default drawing options for the histograms are `""hist""` and `""E""` for h1 and h2 respectively, and mention that these can be changed with `SetH1DrawOpt` and `SetH2DrawOpt` (as this also triggered questions on the forum).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12306
https://github.com/root-project/root/issues/12306:190,security,preven,prevent,190,"[graphics] Consider adding legend to `TRatioPlot` example; Adding a legend to the first example in the [TRatioPlot documentation](https://root.cern.ch/doc/master/classTRatioPlot.html) would prevent recurring questions like these:. * https://root-forum.cern.ch/t/tlegend-disappears-when-i-add-a-tratioplot-pyroot/53609. * https://root-forum.cern.ch/t/creating-legend-for-upper-plot-in-tratioplot/35235. One should also add a not right at the example that the default drawing options for the histograms are `""hist""` and `""E""` for h1 and h2 respectively, and mention that these can be changed with `SetH1DrawOpt` and `SetH2DrawOpt` (as this also triggered questions on the forum).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12306
https://github.com/root-project/root/issues/12306:115,usability,document,documentation,115,"[graphics] Consider adding legend to `TRatioPlot` example; Adding a legend to the first example in the [TRatioPlot documentation](https://root.cern.ch/doc/master/classTRatioPlot.html) would prevent recurring questions like these:. * https://root-forum.cern.ch/t/tlegend-disappears-when-i-add-a-tratioplot-pyroot/53609. * https://root-forum.cern.ch/t/creating-legend-for-upper-plot-in-tratioplot/35235. One should also add a not right at the example that the default drawing options for the histograms are `""hist""` and `""E""` for h1 and h2 respectively, and mention that these can be changed with `SetH1DrawOpt` and `SetH2DrawOpt` (as this also triggered questions on the forum).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12306
https://github.com/root-project/root/issues/12307:5,deployability,Build,Build,5,[CI] Build is green even if tests are failing; See for example the centos8 build in this PR:. https://github.com/root-project/root/actions/runs/4161503868/jobs/7199554467. Here is a screenshot to archive what I saw there in case the results time out:. ![Screenshot_2023-02-14_04-29-57](https://user-images.githubusercontent.com/6578603/218632202-07977e7b-1f5f-483e-a6f2-91093da019db.png).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:38,deployability,fail,failing,38,[CI] Build is green even if tests are failing; See for example the centos8 build in this PR:. https://github.com/root-project/root/actions/runs/4161503868/jobs/7199554467. Here is a screenshot to archive what I saw there in case the results time out:. ![Screenshot_2023-02-14_04-29-57](https://user-images.githubusercontent.com/6578603/218632202-07977e7b-1f5f-483e-a6f2-91093da019db.png).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:75,deployability,build,build,75,[CI] Build is green even if tests are failing; See for example the centos8 build in this PR:. https://github.com/root-project/root/actions/runs/4161503868/jobs/7199554467. Here is a screenshot to archive what I saw there in case the results time out:. ![Screenshot_2023-02-14_04-29-57](https://user-images.githubusercontent.com/6578603/218632202-07977e7b-1f5f-483e-a6f2-91093da019db.png).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:14,energy efficiency,green,green,14,[CI] Build is green even if tests are failing; See for example the centos8 build in this PR:. https://github.com/root-project/root/actions/runs/4161503868/jobs/7199554467. Here is a screenshot to archive what I saw there in case the results time out:. ![Screenshot_2023-02-14_04-29-57](https://user-images.githubusercontent.com/6578603/218632202-07977e7b-1f5f-483e-a6f2-91093da019db.png).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:241,performance,time,time,241,[CI] Build is green even if tests are failing; See for example the centos8 build in this PR:. https://github.com/root-project/root/actions/runs/4161503868/jobs/7199554467. Here is a screenshot to archive what I saw there in case the results time out:. ![Screenshot_2023-02-14_04-29-57](https://user-images.githubusercontent.com/6578603/218632202-07977e7b-1f5f-483e-a6f2-91093da019db.png).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:38,reliability,fail,failing,38,[CI] Build is green even if tests are failing; See for example the centos8 build in this PR:. https://github.com/root-project/root/actions/runs/4161503868/jobs/7199554467. Here is a screenshot to archive what I saw there in case the results time out:. ![Screenshot_2023-02-14_04-29-57](https://user-images.githubusercontent.com/6578603/218632202-07977e7b-1f5f-483e-a6f2-91093da019db.png).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:28,safety,test,tests,28,[CI] Build is green even if tests are failing; See for example the centos8 build in this PR:. https://github.com/root-project/root/actions/runs/4161503868/jobs/7199554467. Here is a screenshot to archive what I saw there in case the results time out:. ![Screenshot_2023-02-14_04-29-57](https://user-images.githubusercontent.com/6578603/218632202-07977e7b-1f5f-483e-a6f2-91093da019db.png).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:28,testability,test,tests,28,[CI] Build is green even if tests are failing; See for example the centos8 build in this PR:. https://github.com/root-project/root/actions/runs/4161503868/jobs/7199554467. Here is a screenshot to archive what I saw there in case the results time out:. ![Screenshot_2023-02-14_04-29-57](https://user-images.githubusercontent.com/6578603/218632202-07977e7b-1f5f-483e-a6f2-91093da019db.png).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/issues/12307:294,usability,user,user-images,294,[CI] Build is green even if tests are failing; See for example the centos8 build in this PR:. https://github.com/root-project/root/actions/runs/4161503868/jobs/7199554467. Here is a screenshot to archive what I saw there in case the results time out:. ![Screenshot_2023-02-14_04-29-57](https://user-images.githubusercontent.com/6578603/218632202-07977e7b-1f5f-483e-a6f2-91093da019db.png).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12307
https://github.com/root-project/root/pull/12308:45,deployability,fail,fail,45,fix a line in PyMethodBase.cxx which make it fail to build; fixed a bug in tmva/pymva/src/PyMethodBase.cxx,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:53,deployability,build,build,53,fix a line in PyMethodBase.cxx which make it fail to build; fixed a bug in tmva/pymva/src/PyMethodBase.cxx,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12308:45,reliability,fail,fail,45,fix a line in PyMethodBase.cxx which make it fail to build; fixed a bug in tmva/pymva/src/PyMethodBase.cxx,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12308
https://github.com/root-project/root/pull/12309:108,deployability,contain,containers,108,"[ci] Rename files and fix disk size issue; # This Pull request:. - Cleans up dangling[^1] images and unused containers before running. - Renames `buildroot.yml` to `root-ci.yml` and `rootci-installers/` to `root-ci-config`. - Enables unbuffered python output again. Buffered python output sometimes (often) causes the output to be sorted by stderr first, then stdout. This makes the grouping wrong and warnings out of order. Disabling buffering is also a very minor performance loss for the CI because CMake, CTest and git writes most of their output to stderr, which is already unbuffered. [^1]: Images that are still on disk, but no longer tagged because they are overwritten by an updated one.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12309
https://github.com/root-project/root/pull/12309:146,deployability,build,buildroot,146,"[ci] Rename files and fix disk size issue; # This Pull request:. - Cleans up dangling[^1] images and unused containers before running. - Renames `buildroot.yml` to `root-ci.yml` and `rootci-installers/` to `root-ci-config`. - Enables unbuffered python output again. Buffered python output sometimes (often) causes the output to be sorted by stderr first, then stdout. This makes the grouping wrong and warnings out of order. Disabling buffering is also a very minor performance loss for the CI because CMake, CTest and git writes most of their output to stderr, which is already unbuffered. [^1]: Images that are still on disk, but no longer tagged because they are overwritten by an updated one.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12309
https://github.com/root-project/root/pull/12309:190,deployability,instal,installers,190,"[ci] Rename files and fix disk size issue; # This Pull request:. - Cleans up dangling[^1] images and unused containers before running. - Renames `buildroot.yml` to `root-ci.yml` and `rootci-installers/` to `root-ci-config`. - Enables unbuffered python output again. Buffered python output sometimes (often) causes the output to be sorted by stderr first, then stdout. This makes the grouping wrong and warnings out of order. Disabling buffering is also a very minor performance loss for the CI because CMake, CTest and git writes most of their output to stderr, which is already unbuffered. [^1]: Images that are still on disk, but no longer tagged because they are overwritten by an updated one.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12309
https://github.com/root-project/root/pull/12309:684,deployability,updat,updated,684,"[ci] Rename files and fix disk size issue; # This Pull request:. - Cleans up dangling[^1] images and unused containers before running. - Renames `buildroot.yml` to `root-ci.yml` and `rootci-installers/` to `root-ci-config`. - Enables unbuffered python output again. Buffered python output sometimes (often) causes the output to be sorted by stderr first, then stdout. This makes the grouping wrong and warnings out of order. Disabling buffering is also a very minor performance loss for the CI because CMake, CTest and git writes most of their output to stderr, which is already unbuffered. [^1]: Images that are still on disk, but no longer tagged because they are overwritten by an updated one.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12309
https://github.com/root-project/root/pull/12309:266,integrability,Buffer,Buffered,266,"[ci] Rename files and fix disk size issue; # This Pull request:. - Cleans up dangling[^1] images and unused containers before running. - Renames `buildroot.yml` to `root-ci.yml` and `rootci-installers/` to `root-ci-config`. - Enables unbuffered python output again. Buffered python output sometimes (often) causes the output to be sorted by stderr first, then stdout. This makes the grouping wrong and warnings out of order. Disabling buffering is also a very minor performance loss for the CI because CMake, CTest and git writes most of their output to stderr, which is already unbuffered. [^1]: Images that are still on disk, but no longer tagged because they are overwritten by an updated one.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12309
https://github.com/root-project/root/pull/12309:435,integrability,buffer,buffering,435,"[ci] Rename files and fix disk size issue; # This Pull request:. - Cleans up dangling[^1] images and unused containers before running. - Renames `buildroot.yml` to `root-ci.yml` and `rootci-installers/` to `root-ci-config`. - Enables unbuffered python output again. Buffered python output sometimes (often) causes the output to be sorted by stderr first, then stdout. This makes the grouping wrong and warnings out of order. Disabling buffering is also a very minor performance loss for the CI because CMake, CTest and git writes most of their output to stderr, which is already unbuffered. [^1]: Images that are still on disk, but no longer tagged because they are overwritten by an updated one.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12309
https://github.com/root-project/root/pull/12309:26,performance,disk,disk,26,"[ci] Rename files and fix disk size issue; # This Pull request:. - Cleans up dangling[^1] images and unused containers before running. - Renames `buildroot.yml` to `root-ci.yml` and `rootci-installers/` to `root-ci-config`. - Enables unbuffered python output again. Buffered python output sometimes (often) causes the output to be sorted by stderr first, then stdout. This makes the grouping wrong and warnings out of order. Disabling buffering is also a very minor performance loss for the CI because CMake, CTest and git writes most of their output to stderr, which is already unbuffered. [^1]: Images that are still on disk, but no longer tagged because they are overwritten by an updated one.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12309
https://github.com/root-project/root/pull/12309:466,performance,perform,performance,466,"[ci] Rename files and fix disk size issue; # This Pull request:. - Cleans up dangling[^1] images and unused containers before running. - Renames `buildroot.yml` to `root-ci.yml` and `rootci-installers/` to `root-ci-config`. - Enables unbuffered python output again. Buffered python output sometimes (often) causes the output to be sorted by stderr first, then stdout. This makes the grouping wrong and warnings out of order. Disabling buffering is also a very minor performance loss for the CI because CMake, CTest and git writes most of their output to stderr, which is already unbuffered. [^1]: Images that are still on disk, but no longer tagged because they are overwritten by an updated one.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12309
https://github.com/root-project/root/pull/12309:622,performance,disk,disk,622,"[ci] Rename files and fix disk size issue; # This Pull request:. - Cleans up dangling[^1] images and unused containers before running. - Renames `buildroot.yml` to `root-ci.yml` and `rootci-installers/` to `root-ci-config`. - Enables unbuffered python output again. Buffered python output sometimes (often) causes the output to be sorted by stderr first, then stdout. This makes the grouping wrong and warnings out of order. Disabling buffering is also a very minor performance loss for the CI because CMake, CTest and git writes most of their output to stderr, which is already unbuffered. [^1]: Images that are still on disk, but no longer tagged because they are overwritten by an updated one.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12309
https://github.com/root-project/root/pull/12309:684,safety,updat,updated,684,"[ci] Rename files and fix disk size issue; # This Pull request:. - Cleans up dangling[^1] images and unused containers before running. - Renames `buildroot.yml` to `root-ci.yml` and `rootci-installers/` to `root-ci-config`. - Enables unbuffered python output again. Buffered python output sometimes (often) causes the output to be sorted by stderr first, then stdout. This makes the grouping wrong and warnings out of order. Disabling buffering is also a very minor performance loss for the CI because CMake, CTest and git writes most of their output to stderr, which is already unbuffered. [^1]: Images that are still on disk, but no longer tagged because they are overwritten by an updated one.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12309
https://github.com/root-project/root/pull/12309:478,security,loss,loss,478,"[ci] Rename files and fix disk size issue; # This Pull request:. - Cleans up dangling[^1] images and unused containers before running. - Renames `buildroot.yml` to `root-ci.yml` and `rootci-installers/` to `root-ci-config`. - Enables unbuffered python output again. Buffered python output sometimes (often) causes the output to be sorted by stderr first, then stdout. This makes the grouping wrong and warnings out of order. Disabling buffering is also a very minor performance loss for the CI because CMake, CTest and git writes most of their output to stderr, which is already unbuffered. [^1]: Images that are still on disk, but no longer tagged because they are overwritten by an updated one.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12309
https://github.com/root-project/root/pull/12309:684,security,updat,updated,684,"[ci] Rename files and fix disk size issue; # This Pull request:. - Cleans up dangling[^1] images and unused containers before running. - Renames `buildroot.yml` to `root-ci.yml` and `rootci-installers/` to `root-ci-config`. - Enables unbuffered python output again. Buffered python output sometimes (often) causes the output to be sorted by stderr first, then stdout. This makes the grouping wrong and warnings out of order. Disabling buffering is also a very minor performance loss for the CI because CMake, CTest and git writes most of their output to stderr, which is already unbuffered. [^1]: Images that are still on disk, but no longer tagged because they are overwritten by an updated one.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12309
https://github.com/root-project/root/pull/12309:466,usability,perform,performance,466,"[ci] Rename files and fix disk size issue; # This Pull request:. - Cleans up dangling[^1] images and unused containers before running. - Renames `buildroot.yml` to `root-ci.yml` and `rootci-installers/` to `root-ci-config`. - Enables unbuffered python output again. Buffered python output sometimes (often) causes the output to be sorted by stderr first, then stdout. This makes the grouping wrong and warnings out of order. Disabling buffering is also a very minor performance loss for the CI because CMake, CTest and git writes most of their output to stderr, which is already unbuffered. [^1]: Images that are still on disk, but no longer tagged because they are overwritten by an updated one.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12309
https://github.com/root-project/root/pull/12310:173,energy efficiency,Reduc,Reduce,173,[tmva] Speed up TMVA CNN and RNN tutorials; Run tutorials with a maximum of 4 threads to avoid MT problems on some machines. Disable also OpenMP when running in MT in ROOT. Reduce also by a factor of 5 the number of input events.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12310
https://github.com/root-project/root/pull/12310:222,integrability,event,events,222,[tmva] Speed up TMVA CNN and RNN tutorials; Run tutorials with a maximum of 4 threads to avoid MT problems on some machines. Disable also OpenMP when running in MT in ROOT. Reduce also by a factor of 5 the number of input events.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12310
https://github.com/root-project/root/pull/12310:89,safety,avoid,avoid,89,[tmva] Speed up TMVA CNN and RNN tutorials; Run tutorials with a maximum of 4 threads to avoid MT problems on some machines. Disable also OpenMP when running in MT in ROOT. Reduce also by a factor of 5 the number of input events.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12310
https://github.com/root-project/root/pull/12310:216,safety,input,input,216,[tmva] Speed up TMVA CNN and RNN tutorials; Run tutorials with a maximum of 4 threads to avoid MT problems on some machines. Disable also OpenMP when running in MT in ROOT. Reduce also by a factor of 5 the number of input events.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12310
https://github.com/root-project/root/pull/12310:216,usability,input,input,216,[tmva] Speed up TMVA CNN and RNN tutorials; Run tutorials with a maximum of 4 threads to avoid MT problems on some machines. Disable also OpenMP when running in MT in ROOT. Reduce also by a factor of 5 the number of input events.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12310
https://github.com/root-project/root/pull/12311:159,deployability,build,build-with-miniconda-python-,159,Add a missing %PATH% on Windows.; Final fix for the issue reported on the Forum with Miniconda and Python 10 https://root-forum.cern.ch/t/windows-10-root-6-28-build-with-miniconda-python-3-10-crashed/53554/11,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12311
https://github.com/root-project/root/pull/12312:144,deployability,Updat,Update,144,"[rbrowser] Fix click in RBrowser on ""@size"" branch; TTree::Draw expression was mail-formed in some case. Use TWebCanvas by default in RBrowser. Update JSROOT to support more kind of log scale",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12312
https://github.com/root-project/root/pull/12312:182,deployability,log,log,182,"[rbrowser] Fix click in RBrowser on ""@size"" branch; TTree::Draw expression was mail-formed in some case. Use TWebCanvas by default in RBrowser. Update JSROOT to support more kind of log scale",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12312
https://github.com/root-project/root/pull/12312:186,deployability,scale,scale,186,"[rbrowser] Fix click in RBrowser on ""@size"" branch; TTree::Draw expression was mail-formed in some case. Use TWebCanvas by default in RBrowser. Update JSROOT to support more kind of log scale",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12312
https://github.com/root-project/root/pull/12312:59,energy efficiency,Draw,Draw,59,"[rbrowser] Fix click in RBrowser on ""@size"" branch; TTree::Draw expression was mail-formed in some case. Use TWebCanvas by default in RBrowser. Update JSROOT to support more kind of log scale",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12312
https://github.com/root-project/root/pull/12312:186,energy efficiency,scale,scale,186,"[rbrowser] Fix click in RBrowser on ""@size"" branch; TTree::Draw expression was mail-formed in some case. Use TWebCanvas by default in RBrowser. Update JSROOT to support more kind of log scale",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12312
https://github.com/root-project/root/pull/12312:186,modifiability,scal,scale,186,"[rbrowser] Fix click in RBrowser on ""@size"" branch; TTree::Draw expression was mail-formed in some case. Use TWebCanvas by default in RBrowser. Update JSROOT to support more kind of log scale",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12312
https://github.com/root-project/root/pull/12312:186,performance,scale,scale,186,"[rbrowser] Fix click in RBrowser on ""@size"" branch; TTree::Draw expression was mail-formed in some case. Use TWebCanvas by default in RBrowser. Update JSROOT to support more kind of log scale",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12312
https://github.com/root-project/root/pull/12312:144,safety,Updat,Update,144,"[rbrowser] Fix click in RBrowser on ""@size"" branch; TTree::Draw expression was mail-formed in some case. Use TWebCanvas by default in RBrowser. Update JSROOT to support more kind of log scale",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12312
https://github.com/root-project/root/pull/12312:182,safety,log,log,182,"[rbrowser] Fix click in RBrowser on ""@size"" branch; TTree::Draw expression was mail-formed in some case. Use TWebCanvas by default in RBrowser. Update JSROOT to support more kind of log scale",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12312
https://github.com/root-project/root/pull/12312:144,security,Updat,Update,144,"[rbrowser] Fix click in RBrowser on ""@size"" branch; TTree::Draw expression was mail-formed in some case. Use TWebCanvas by default in RBrowser. Update JSROOT to support more kind of log scale",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12312
https://github.com/root-project/root/pull/12312:182,security,log,log,182,"[rbrowser] Fix click in RBrowser on ""@size"" branch; TTree::Draw expression was mail-formed in some case. Use TWebCanvas by default in RBrowser. Update JSROOT to support more kind of log scale",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12312
https://github.com/root-project/root/pull/12312:182,testability,log,log,182,"[rbrowser] Fix click in RBrowser on ""@size"" branch; TTree::Draw expression was mail-formed in some case. Use TWebCanvas by default in RBrowser. Update JSROOT to support more kind of log scale",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12312
https://github.com/root-project/root/pull/12312:161,usability,support,support,161,"[rbrowser] Fix click in RBrowser on ""@size"" branch; TTree::Draw expression was mail-formed in some case. Use TWebCanvas by default in RBrowser. Update JSROOT to support more kind of log scale",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12312
https://github.com/root-project/root/pull/12314:139,deployability,build,builds,139,[ci] Add test summary to pull requests; # This Pull request:. - (https://github.com/root-project/root/issues/12186) Adds test summaries to builds. Writes comments on pull-requests: [example](https://github.com/olemorud/root/pull/9). - Adds the `--rm` flag to containers as a temporary fix for the disk space problem (puppet fix coming soon). ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). [skip-ci],MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:259,deployability,contain,containers,259,[ci] Add test summary to pull requests; # This Pull request:. - (https://github.com/root-project/root/issues/12186) Adds test summaries to builds. Writes comments on pull-requests: [example](https://github.com/olemorud/root/pull/9). - Adds the `--rm` flag to containers as a temporary fix for the disk space problem (puppet fix coming soon). ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). [skip-ci],MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:393,deployability,updat,updated,393,[ci] Add test summary to pull requests; # This Pull request:. - (https://github.com/root-project/root/issues/12186) Adds test summaries to builds. Writes comments on pull-requests: [example](https://github.com/olemorud/root/pull/9). - Adds the `--rm` flag to containers as a temporary fix for the disk space problem (puppet fix coming soon). ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). [skip-ci],MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:206,interoperability,com/ole,com/olemorud,206,[ci] Add test summary to pull requests; # This Pull request:. - (https://github.com/root-project/root/issues/12186) Adds test summaries to builds. Writes comments on pull-requests: [example](https://github.com/olemorud/root/pull/9). - Adds the `--rm` flag to containers as a temporary fix for the disk space problem (puppet fix coming soon). ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). [skip-ci],MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:297,performance,disk,disk,297,[ci] Add test summary to pull requests; # This Pull request:. - (https://github.com/root-project/root/issues/12186) Adds test summaries to builds. Writes comments on pull-requests: [example](https://github.com/olemorud/root/pull/9). - Adds the `--rm` flag to containers as a temporary fix for the disk space problem (puppet fix coming soon). ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). [skip-ci],MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:9,safety,test,test,9,[ci] Add test summary to pull requests; # This Pull request:. - (https://github.com/root-project/root/issues/12186) Adds test summaries to builds. Writes comments on pull-requests: [example](https://github.com/olemorud/root/pull/9). - Adds the `--rm` flag to containers as a temporary fix for the disk space problem (puppet fix coming soon). ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). [skip-ci],MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:121,safety,test,test,121,[ci] Add test summary to pull requests; # This Pull request:. - (https://github.com/root-project/root/issues/12186) Adds test summaries to builds. Writes comments on pull-requests: [example](https://github.com/olemorud/root/pull/9). - Adds the `--rm` flag to containers as a temporary fix for the disk space problem (puppet fix coming soon). ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). [skip-ci],MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:363,safety,test,tested,363,[ci] Add test summary to pull requests; # This Pull request:. - (https://github.com/root-project/root/issues/12186) Adds test summaries to builds. Writes comments on pull-requests: [example](https://github.com/olemorud/root/pull/9). - Adds the `--rm` flag to containers as a temporary fix for the disk space problem (puppet fix coming soon). ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). [skip-ci],MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:393,safety,updat,updated,393,[ci] Add test summary to pull requests; # This Pull request:. - (https://github.com/root-project/root/issues/12186) Adds test summaries to builds. Writes comments on pull-requests: [example](https://github.com/olemorud/root/pull/9). - Adds the `--rm` flag to containers as a temporary fix for the disk space problem (puppet fix coming soon). ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). [skip-ci],MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:393,security,updat,updated,393,[ci] Add test summary to pull requests; # This Pull request:. - (https://github.com/root-project/root/issues/12186) Adds test summaries to builds. Writes comments on pull-requests: [example](https://github.com/olemorud/root/pull/9). - Adds the `--rm` flag to containers as a temporary fix for the disk space problem (puppet fix coming soon). ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). [skip-ci],MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:9,testability,test,test,9,[ci] Add test summary to pull requests; # This Pull request:. - (https://github.com/root-project/root/issues/12186) Adds test summaries to builds. Writes comments on pull-requests: [example](https://github.com/olemorud/root/pull/9). - Adds the `--rm` flag to containers as a temporary fix for the disk space problem (puppet fix coming soon). ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). [skip-ci],MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:121,testability,test,test,121,[ci] Add test summary to pull requests; # This Pull request:. - (https://github.com/root-project/root/issues/12186) Adds test summaries to builds. Writes comments on pull-requests: [example](https://github.com/olemorud/root/pull/9). - Adds the `--rm` flag to containers as a temporary fix for the disk space problem (puppet fix coming soon). ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). [skip-ci],MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12314:363,testability,test,tested,363,[ci] Add test summary to pull requests; # This Pull request:. - (https://github.com/root-project/root/issues/12186) Adds test summaries to builds. Writes comments on pull-requests: [example](https://github.com/olemorud/root/pull/9). - Adds the `--rm` flag to containers as a temporary fix for the disk space problem (puppet fix coming soon). ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). [skip-ci],MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12314
https://github.com/root-project/root/pull/12315:433,deployability,updat,updated,433,"[geom] Extended TGeoVGShape with extra solids; Added support for tesselated, ellipsoid, hyperboloid and cut tube in the ROOT to VecGeom converter. Added the macro tutorials/geom/tessellatedNav.C importing and raytracing a tessellated solid. # This Pull request:. Completes solid conversion to VecGeom support. ## Changes or fixes:. Adding the macro tutorials/geom/tessellatedNav.C. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes #11271.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:279,interoperability,convers,conversion,279,"[geom] Extended TGeoVGShape with extra solids; Added support for tesselated, ellipsoid, hyperboloid and cut tube in the ROOT to VecGeom converter. Added the macro tutorials/geom/tessellatedNav.C importing and raytracing a tessellated solid. # This Pull request:. Completes solid conversion to VecGeom support. ## Changes or fixes:. Adding the macro tutorials/geom/tessellatedNav.C. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes #11271.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:7,modifiability,Exten,Extended,7,"[geom] Extended TGeoVGShape with extra solids; Added support for tesselated, ellipsoid, hyperboloid and cut tube in the ROOT to VecGeom converter. Added the macro tutorials/geom/tessellatedNav.C importing and raytracing a tessellated solid. # This Pull request:. Completes solid conversion to VecGeom support. ## Changes or fixes:. Adding the macro tutorials/geom/tessellatedNav.C. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes #11271.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:263,safety,Compl,Completes,263,"[geom] Extended TGeoVGShape with extra solids; Added support for tesselated, ellipsoid, hyperboloid and cut tube in the ROOT to VecGeom converter. Added the macro tutorials/geom/tessellatedNav.C importing and raytracing a tessellated solid. # This Pull request:. Completes solid conversion to VecGeom support. ## Changes or fixes:. Adding the macro tutorials/geom/tessellatedNav.C. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes #11271.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:403,safety,test,tested,403,"[geom] Extended TGeoVGShape with extra solids; Added support for tesselated, ellipsoid, hyperboloid and cut tube in the ROOT to VecGeom converter. Added the macro tutorials/geom/tessellatedNav.C importing and raytracing a tessellated solid. # This Pull request:. Completes solid conversion to VecGeom support. ## Changes or fixes:. Adding the macro tutorials/geom/tessellatedNav.C. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes #11271.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:433,safety,updat,updated,433,"[geom] Extended TGeoVGShape with extra solids; Added support for tesselated, ellipsoid, hyperboloid and cut tube in the ROOT to VecGeom converter. Added the macro tutorials/geom/tessellatedNav.C importing and raytracing a tessellated solid. # This Pull request:. Completes solid conversion to VecGeom support. ## Changes or fixes:. Adding the macro tutorials/geom/tessellatedNav.C. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes #11271.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:263,security,Compl,Completes,263,"[geom] Extended TGeoVGShape with extra solids; Added support for tesselated, ellipsoid, hyperboloid and cut tube in the ROOT to VecGeom converter. Added the macro tutorials/geom/tessellatedNav.C importing and raytracing a tessellated solid. # This Pull request:. Completes solid conversion to VecGeom support. ## Changes or fixes:. Adding the macro tutorials/geom/tessellatedNav.C. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes #11271.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:433,security,updat,updated,433,"[geom] Extended TGeoVGShape with extra solids; Added support for tesselated, ellipsoid, hyperboloid and cut tube in the ROOT to VecGeom converter. Added the macro tutorials/geom/tessellatedNav.C importing and raytracing a tessellated solid. # This Pull request:. Completes solid conversion to VecGeom support. ## Changes or fixes:. Adding the macro tutorials/geom/tessellatedNav.C. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes #11271.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:403,testability,test,tested,403,"[geom] Extended TGeoVGShape with extra solids; Added support for tesselated, ellipsoid, hyperboloid and cut tube in the ROOT to VecGeom converter. Added the macro tutorials/geom/tessellatedNav.C importing and raytracing a tessellated solid. # This Pull request:. Completes solid conversion to VecGeom support. ## Changes or fixes:. Adding the macro tutorials/geom/tessellatedNav.C. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes #11271.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:53,usability,support,support,53,"[geom] Extended TGeoVGShape with extra solids; Added support for tesselated, ellipsoid, hyperboloid and cut tube in the ROOT to VecGeom converter. Added the macro tutorials/geom/tessellatedNav.C importing and raytracing a tessellated solid. # This Pull request:. Completes solid conversion to VecGeom support. ## Changes or fixes:. Adding the macro tutorials/geom/tessellatedNav.C. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes #11271.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12315:301,usability,support,support,301,"[geom] Extended TGeoVGShape with extra solids; Added support for tesselated, ellipsoid, hyperboloid and cut tube in the ROOT to VecGeom converter. Added the macro tutorials/geom/tessellatedNav.C importing and raytracing a tessellated solid. # This Pull request:. Completes solid conversion to VecGeom support. ## Changes or fixes:. Adding the macro tutorials/geom/tessellatedNav.C. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes #11271.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12315
https://github.com/root-project/root/pull/12316:163,reliability,doe,does,163,"[DF] Prefer `file?#tree` to `file/tree`; Now that #11483 is fixed we can use the more general notation everywhere (`file/tree` is problematic in case the filename does not end with .root, see https://github.com/root-project/root/pull/8820).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12316
https://github.com/root-project/root/pull/12316:5,usability,Prefer,Prefer,5,"[DF] Prefer `file?#tree` to `file/tree`; Now that #11483 is fixed we can use the more general notation everywhere (`file/tree` is problematic in case the filename does not end with .root, see https://github.com/root-project/root/pull/8820).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12316
https://github.com/root-project/root/issues/12317:1602,deployability,observ,observables,1602,"lpha, n);. RooCBShape cbShape(""cb2"", ""cb2"", x, x0, sigma, alpha, n);. // This one is not exact, and it fact should not be implemented. // It is unnecessary because it forwards to the generator of the underlying Pdf. RooBinSamplingPdf binSamplingPdf(""binSamplingPdf"", ""binSamplingPdf"", x, crystalBall);. RooDataHist templHist{""templHist"", ""templHist"", x};. templHist.set(x.getBin(), 100.0, -1.0);. RooDataSet templData{""templData"", ""templData"", x};. for (int i = 0; i < x.numBins(); ++i) {. x.setBin(i);. templData.add(x);. }. x.setVal(2.5);. // no interpolation. RooHistFunc histFunc{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. RooHistPdf(): 500 nan. RooKeysPdf(): 0.201299 nan. RooCrystalBall(): 1 nan. RooCBShape(): 1 nan. RooWrapperPdf(): 100 nan. RooBinSamplingPdf(): 0.308511 nan. RooHistFunc(x): 100 105. RooHistPdf(x): 5 105. RooKeysPdf(x): 0.218569 0.205937. RooCrystalBall(x): 9.92564 9.92",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:1309,integrability,wrap,wrapperPdf,1309,"y"", ""y"", 2.5, 0, 5};. x.setBins(25);. y.setBins(25);. RooRealVar x0(""x0"", ""x0"", 2.5, -5., 5.);. RooRealVar sigma(""sigma"", ""sigma"", 0.02, 1.E-4, 1.);. RooRealVar alpha(""a"", ""a"", 1., 1.E-6, 100.);. RooRealVar n(""n"", ""n"", 1., 1.E-6, 100.);. RooCrystalBall crystalBall(""cb1"", ""cb1"", x, x0, sigma, alpha, n);. RooCBShape cbShape(""cb2"", ""cb2"", x, x0, sigma, alpha, n);. // This one is not exact, and it fact should not be implemented. // It is unnecessary because it forwards to the generator of the underlying Pdf. RooBinSamplingPdf binSamplingPdf(""binSamplingPdf"", ""binSamplingPdf"", x, crystalBall);. RooDataHist templHist{""templHist"", ""templHist"", x};. templHist.set(x.getBin(), 100.0, -1.0);. RooDataSet templData{""templData"", ""templData"", x};. for (int i = 0; i < x.numBins(); ++i) {. x.setBin(i);. templData.add(x);. }. x.setVal(2.5);. // no interpolation. RooHistFunc histFunc{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:1321,integrability,wrap,wrapperPdf,1321,", 0, 5};. x.setBins(25);. y.setBins(25);. RooRealVar x0(""x0"", ""x0"", 2.5, -5., 5.);. RooRealVar sigma(""sigma"", ""sigma"", 0.02, 1.E-4, 1.);. RooRealVar alpha(""a"", ""a"", 1., 1.E-6, 100.);. RooRealVar n(""n"", ""n"", 1., 1.E-6, 100.);. RooCrystalBall crystalBall(""cb1"", ""cb1"", x, x0, sigma, alpha, n);. RooCBShape cbShape(""cb2"", ""cb2"", x, x0, sigma, alpha, n);. // This one is not exact, and it fact should not be implemented. // It is unnecessary because it forwards to the generator of the underlying Pdf. RooBinSamplingPdf binSamplingPdf(""binSamplingPdf"", ""binSamplingPdf"", x, crystalBall);. RooDataHist templHist{""templHist"", ""templHist"", x};. templHist.set(x.getBin(), 100.0, -1.0);. RooDataSet templData{""templData"", ""templData"", x};. for (int i = 0; i < x.numBins(); ++i) {. x.setBin(i);. templData.add(x);. }. x.setVal(2.5);. // no interpolation. RooHistFunc histFunc{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:1335,integrability,wrap,wrapperPdf,1335,"tBins(25);. y.setBins(25);. RooRealVar x0(""x0"", ""x0"", 2.5, -5., 5.);. RooRealVar sigma(""sigma"", ""sigma"", 0.02, 1.E-4, 1.);. RooRealVar alpha(""a"", ""a"", 1., 1.E-6, 100.);. RooRealVar n(""n"", ""n"", 1., 1.E-6, 100.);. RooCrystalBall crystalBall(""cb1"", ""cb1"", x, x0, sigma, alpha, n);. RooCBShape cbShape(""cb2"", ""cb2"", x, x0, sigma, alpha, n);. // This one is not exact, and it fact should not be implemented. // It is unnecessary because it forwards to the generator of the underlying Pdf. RooBinSamplingPdf binSamplingPdf(""binSamplingPdf"", ""binSamplingPdf"", x, crystalBall);. RooDataHist templHist{""templHist"", ""templHist"", x};. templHist.set(x.getBin(), 100.0, -1.0);. RooDataSet templData{""templData"", ""templData"", x};. for (int i = 0; i < x.numBins(); ++i) {. x.setBin(i);. templData.add(x);. }. x.setVal(2.5);. // no interpolation. RooHistFunc histFunc{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. Ro",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:1631,integrability,wrap,wrapperPdf,1631,"e(""cb2"", ""cb2"", x, x0, sigma, alpha, n);. // This one is not exact, and it fact should not be implemented. // It is unnecessary because it forwards to the generator of the underlying Pdf. RooBinSamplingPdf binSamplingPdf(""binSamplingPdf"", ""binSamplingPdf"", x, crystalBall);. RooDataHist templHist{""templHist"", ""templHist"", x};. templHist.set(x.getBin(), 100.0, -1.0);. RooDataSet templData{""templData"", ""templData"", x};. for (int i = 0; i < x.numBins(); ++i) {. x.setBin(i);. templData.add(x);. }. x.setVal(2.5);. // no interpolation. RooHistFunc histFunc{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. RooHistPdf(): 500 nan. RooKeysPdf(): 0.201299 nan. RooCrystalBall(): 1 nan. RooCBShape(): 1 nan. RooWrapperPdf(): 100 nan. RooBinSamplingPdf(): 0.308511 nan. RooHistFunc(x): 100 105. RooHistPdf(x): 5 105. RooKeysPdf(x): 0.218569 0.205937. RooCrystalBall(x): 9.92564 9.92564. RooCBShape(x): 9.92564 ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:2165,integrability,wrap,wrapperPdf,2165," RooHistFunc histFunc{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. RooHistPdf(): 500 nan. RooKeysPdf(): 0.201299 nan. RooCrystalBall(): 1 nan. RooCBShape(): 1 nan. RooWrapperPdf(): 100 nan. RooBinSamplingPdf(): 0.308511 nan. RooHistFunc(x): 100 105. RooHistPdf(x): 5 105. RooKeysPdf(x): 0.218569 0.205937. RooCrystalBall(x): 9.92564 9.92564. RooCBShape(x): 9.92564 9.92564. RooWrapperPdf(x): 5 105. RooBinSamplingPdf(x): 3.06217 9.92564. RooHistFunc(x,y): 100 105. RooHistPdf(x,y): 5 105. RooKeysPdf(x,y): 0.218569 0.205937. RooCrystalBall(x,y): 9.92564 9.92564. RooCBShape(x,y): 9.92564 9.92564. RooWrapperPdf(x,y): 5 105. RooBinSamplingPdf(x,y): 3.06217 9.92564. ```. * It's probably okay to not return values when the normalization set is empty, although it could easily implemented to do it (well, maybe not for the `RooAddPdf`...). * Expect for the crystal ball functions, the values are not co",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:1309,interoperability,wrapper,wrapperPdf,1309,"y"", ""y"", 2.5, 0, 5};. x.setBins(25);. y.setBins(25);. RooRealVar x0(""x0"", ""x0"", 2.5, -5., 5.);. RooRealVar sigma(""sigma"", ""sigma"", 0.02, 1.E-4, 1.);. RooRealVar alpha(""a"", ""a"", 1., 1.E-6, 100.);. RooRealVar n(""n"", ""n"", 1., 1.E-6, 100.);. RooCrystalBall crystalBall(""cb1"", ""cb1"", x, x0, sigma, alpha, n);. RooCBShape cbShape(""cb2"", ""cb2"", x, x0, sigma, alpha, n);. // This one is not exact, and it fact should not be implemented. // It is unnecessary because it forwards to the generator of the underlying Pdf. RooBinSamplingPdf binSamplingPdf(""binSamplingPdf"", ""binSamplingPdf"", x, crystalBall);. RooDataHist templHist{""templHist"", ""templHist"", x};. templHist.set(x.getBin(), 100.0, -1.0);. RooDataSet templData{""templData"", ""templData"", x};. for (int i = 0; i < x.numBins(); ++i) {. x.setBin(i);. templData.add(x);. }. x.setVal(2.5);. // no interpolation. RooHistFunc histFunc{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:1321,interoperability,wrapper,wrapperPdf,1321,", 0, 5};. x.setBins(25);. y.setBins(25);. RooRealVar x0(""x0"", ""x0"", 2.5, -5., 5.);. RooRealVar sigma(""sigma"", ""sigma"", 0.02, 1.E-4, 1.);. RooRealVar alpha(""a"", ""a"", 1., 1.E-6, 100.);. RooRealVar n(""n"", ""n"", 1., 1.E-6, 100.);. RooCrystalBall crystalBall(""cb1"", ""cb1"", x, x0, sigma, alpha, n);. RooCBShape cbShape(""cb2"", ""cb2"", x, x0, sigma, alpha, n);. // This one is not exact, and it fact should not be implemented. // It is unnecessary because it forwards to the generator of the underlying Pdf. RooBinSamplingPdf binSamplingPdf(""binSamplingPdf"", ""binSamplingPdf"", x, crystalBall);. RooDataHist templHist{""templHist"", ""templHist"", x};. templHist.set(x.getBin(), 100.0, -1.0);. RooDataSet templData{""templData"", ""templData"", x};. for (int i = 0; i < x.numBins(); ++i) {. x.setBin(i);. templData.add(x);. }. x.setVal(2.5);. // no interpolation. RooHistFunc histFunc{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:1335,interoperability,wrapper,wrapperPdf,1335,"tBins(25);. y.setBins(25);. RooRealVar x0(""x0"", ""x0"", 2.5, -5., 5.);. RooRealVar sigma(""sigma"", ""sigma"", 0.02, 1.E-4, 1.);. RooRealVar alpha(""a"", ""a"", 1., 1.E-6, 100.);. RooRealVar n(""n"", ""n"", 1., 1.E-6, 100.);. RooCrystalBall crystalBall(""cb1"", ""cb1"", x, x0, sigma, alpha, n);. RooCBShape cbShape(""cb2"", ""cb2"", x, x0, sigma, alpha, n);. // This one is not exact, and it fact should not be implemented. // It is unnecessary because it forwards to the generator of the underlying Pdf. RooBinSamplingPdf binSamplingPdf(""binSamplingPdf"", ""binSamplingPdf"", x, crystalBall);. RooDataHist templHist{""templHist"", ""templHist"", x};. templHist.set(x.getBin(), 100.0, -1.0);. RooDataSet templData{""templData"", ""templData"", x};. for (int i = 0; i < x.numBins(); ++i) {. x.setBin(i);. templData.add(x);. }. x.setVal(2.5);. // no interpolation. RooHistFunc histFunc{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. Ro",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:1631,interoperability,wrapper,wrapperPdf,1631,"e(""cb2"", ""cb2"", x, x0, sigma, alpha, n);. // This one is not exact, and it fact should not be implemented. // It is unnecessary because it forwards to the generator of the underlying Pdf. RooBinSamplingPdf binSamplingPdf(""binSamplingPdf"", ""binSamplingPdf"", x, crystalBall);. RooDataHist templHist{""templHist"", ""templHist"", x};. templHist.set(x.getBin(), 100.0, -1.0);. RooDataSet templData{""templData"", ""templData"", x};. for (int i = 0; i < x.numBins(); ++i) {. x.setBin(i);. templData.add(x);. }. x.setVal(2.5);. // no interpolation. RooHistFunc histFunc{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. RooHistPdf(): 500 nan. RooKeysPdf(): 0.201299 nan. RooCrystalBall(): 1 nan. RooCBShape(): 1 nan. RooWrapperPdf(): 100 nan. RooBinSamplingPdf(): 0.308511 nan. RooHistFunc(x): 100 105. RooHistPdf(x): 5 105. RooKeysPdf(x): 0.218569 0.205937. RooCrystalBall(x): 9.92564 9.92564. RooCBShape(x): 9.92564 ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:2165,interoperability,wrapper,wrapperPdf,2165," RooHistFunc histFunc{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. RooHistPdf(): 500 nan. RooKeysPdf(): 0.201299 nan. RooCrystalBall(): 1 nan. RooCBShape(): 1 nan. RooWrapperPdf(): 100 nan. RooBinSamplingPdf(): 0.308511 nan. RooHistFunc(x): 100 105. RooHistPdf(x): 5 105. RooKeysPdf(x): 0.218569 0.205937. RooCrystalBall(x): 9.92564 9.92564. RooCBShape(x): 9.92564 9.92564. RooWrapperPdf(x): 5 105. RooBinSamplingPdf(x): 3.06217 9.92564. RooHistFunc(x,y): 100 105. RooHistPdf(x,y): 5 105. RooKeysPdf(x,y): 0.218569 0.205937. RooCrystalBall(x,y): 9.92564 9.92564. RooCBShape(x,y): 9.92564 9.92564. RooWrapperPdf(x,y): 5 105. RooBinSamplingPdf(x,y): 3.06217 9.92564. ```. * It's probably okay to not return values when the normalization set is empty, although it could easily implemented to do it (well, maybe not for the `RooAddPdf`...). * Expect for the crystal ball functions, the values are not co",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:1623,performance,cach,caches,1623,"ape cbShape(""cb2"", ""cb2"", x, x0, sigma, alpha, n);. // This one is not exact, and it fact should not be implemented. // It is unnecessary because it forwards to the generator of the underlying Pdf. RooBinSamplingPdf binSamplingPdf(""binSamplingPdf"", ""binSamplingPdf"", x, crystalBall);. RooDataHist templHist{""templHist"", ""templHist"", x};. templHist.set(x.getBin(), 100.0, -1.0);. RooDataSet templData{""templData"", ""templData"", x};. for (int i = 0; i < x.numBins(); ++i) {. x.setBin(i);. templData.add(x);. }. x.setVal(2.5);. // no interpolation. RooHistFunc histFunc{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. RooHistPdf(): 500 nan. RooKeysPdf(): 0.201299 nan. RooCrystalBall(): 1 nan. RooCBShape(): 1 nan. RooWrapperPdf(): 100 nan. RooBinSamplingPdf(): 0.308511 nan. RooHistFunc(x): 100 105. RooHistPdf(x): 5 105. RooKeysPdf(x): 0.218569 0.205937. RooCrystalBall(x): 9.92564 9.92564. RooCBShape(x)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:3233,performance,time,time,3233,"perPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. RooHistPdf(): 500 nan. RooKeysPdf(): 0.201299 nan. RooCrystalBall(): 1 nan. RooCBShape(): 1 nan. RooWrapperPdf(): 100 nan. RooBinSamplingPdf(): 0.308511 nan. RooHistFunc(x): 100 105. RooHistPdf(x): 5 105. RooKeysPdf(x): 0.218569 0.205937. RooCrystalBall(x): 9.92564 9.92564. RooCBShape(x): 9.92564 9.92564. RooWrapperPdf(x): 5 105. RooBinSamplingPdf(x): 3.06217 9.92564. RooHistFunc(x,y): 100 105. RooHistPdf(x,y): 5 105. RooKeysPdf(x,y): 0.218569 0.205937. RooCrystalBall(x,y): 9.92564 9.92564. RooCBShape(x,y): 9.92564 9.92564. RooWrapperPdf(x,y): 5 105. RooBinSamplingPdf(x,y): 3.06217 9.92564. ```. * It's probably okay to not return values when the normalization set is empty, although it could easily implemented to do it (well, maybe not for the `RooAddPdf`...). * Expect for the crystal ball functions, the values are not correct. The implementations should be corrected and at the same time the usage of `RooAbsReal::getMaxVal()` and `maxVal()` inside RooFit should be reviewed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:1666,safety,test,test,1666,"pha, n);. // This one is not exact, and it fact should not be implemented. // It is unnecessary because it forwards to the generator of the underlying Pdf. RooBinSamplingPdf binSamplingPdf(""binSamplingPdf"", ""binSamplingPdf"", x, crystalBall);. RooDataHist templHist{""templHist"", ""templHist"", x};. templHist.set(x.getBin(), 100.0, -1.0);. RooDataSet templData{""templData"", ""templData"", x};. for (int i = 0; i < x.numBins(); ++i) {. x.setBin(i);. templData.add(x);. }. x.setVal(2.5);. // no interpolation. RooHistFunc histFunc{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. RooHistPdf(): 500 nan. RooKeysPdf(): 0.201299 nan. RooCrystalBall(): 1 nan. RooCBShape(): 1 nan. RooWrapperPdf(): 100 nan. RooBinSamplingPdf(): 0.308511 nan. RooHistFunc(x): 100 105. RooHistPdf(x): 5 105. RooKeysPdf(x): 0.218569 0.205937. RooCrystalBall(x): 9.92564 9.92564. RooCBShape(x): 9.92564 9.92564. RooWrapperPdf(x): 5 105",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:2030,safety,test,test,2030,"Data"", ""templData"", x};. for (int i = 0; i < x.numBins(); ++i) {. x.setBin(i);. templData.add(x);. }. x.setVal(2.5);. // no interpolation. RooHistFunc histFunc{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. RooHistPdf(): 500 nan. RooKeysPdf(): 0.201299 nan. RooCrystalBall(): 1 nan. RooCBShape(): 1 nan. RooWrapperPdf(): 100 nan. RooBinSamplingPdf(): 0.308511 nan. RooHistFunc(x): 100 105. RooHistPdf(x): 5 105. RooKeysPdf(x): 0.218569 0.205937. RooCrystalBall(x): 9.92564 9.92564. RooCBShape(x): 9.92564 9.92564. RooWrapperPdf(x): 5 105. RooBinSamplingPdf(x): 3.06217 9.92564. RooHistFunc(x,y): 100 105. RooHistPdf(x,y): 5 105. RooKeysPdf(x,y): 0.218569 0.205937. RooCrystalBall(x,y): 9.92564 9.92564. RooCBShape(x,y): 9.92564 9.92564. RooWrapperPdf(x,y): 5 105. RooBinSamplingPdf(x,y): 3.06217 9.92564. ```. * It's probably okay to not return values when the normalization set is empty, although it ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:2056,safety,test,test,2056,"or (int i = 0; i < x.numBins(); ++i) {. x.setBin(i);. templData.add(x);. }. x.setVal(2.5);. // no interpolation. RooHistFunc histFunc{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. RooHistPdf(): 500 nan. RooKeysPdf(): 0.201299 nan. RooCrystalBall(): 1 nan. RooCBShape(): 1 nan. RooWrapperPdf(): 100 nan. RooBinSamplingPdf(): 0.308511 nan. RooHistFunc(x): 100 105. RooHistPdf(x): 5 105. RooKeysPdf(x): 0.218569 0.205937. RooCrystalBall(x): 9.92564 9.92564. RooCBShape(x): 9.92564 9.92564. RooWrapperPdf(x): 5 105. RooBinSamplingPdf(x): 3.06217 9.92564. RooHistFunc(x,y): 100 105. RooHistPdf(x,y): 5 105. RooKeysPdf(x,y): 0.218569 0.205937. RooCrystalBall(x,y): 9.92564 9.92564. RooCBShape(x,y): 9.92564 9.92564. RooWrapperPdf(x,y): 5 105. RooBinSamplingPdf(x,y): 3.06217 9.92564. ```. * It's probably okay to not return values when the normalization set is empty, although it could easily implemented t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:2081,safety,test,test,2081,"ins(); ++i) {. x.setBin(i);. templData.add(x);. }. x.setVal(2.5);. // no interpolation. RooHistFunc histFunc{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. RooHistPdf(): 500 nan. RooKeysPdf(): 0.201299 nan. RooCrystalBall(): 1 nan. RooCBShape(): 1 nan. RooWrapperPdf(): 100 nan. RooBinSamplingPdf(): 0.308511 nan. RooHistFunc(x): 100 105. RooHistPdf(x): 5 105. RooKeysPdf(x): 0.218569 0.205937. RooCrystalBall(x): 9.92564 9.92564. RooCBShape(x): 9.92564 9.92564. RooWrapperPdf(x): 5 105. RooBinSamplingPdf(x): 3.06217 9.92564. RooHistFunc(x,y): 100 105. RooHistPdf(x,y): 5 105. RooKeysPdf(x,y): 0.218569 0.205937. RooCrystalBall(x,y): 9.92564 9.92564. RooCBShape(x,y): 9.92564 9.92564. RooWrapperPdf(x,y): 5 105. RooBinSamplingPdf(x,y): 3.06217 9.92564. ```. * It's probably okay to not return values when the normalization set is empty, although it could easily implemented to do it (well, maybe not ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:2106,safety,test,test,2106,");. templData.add(x);. }. x.setVal(2.5);. // no interpolation. RooHistFunc histFunc{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. RooHistPdf(): 500 nan. RooKeysPdf(): 0.201299 nan. RooCrystalBall(): 1 nan. RooCBShape(): 1 nan. RooWrapperPdf(): 100 nan. RooBinSamplingPdf(): 0.308511 nan. RooHistFunc(x): 100 105. RooHistPdf(x): 5 105. RooKeysPdf(x): 0.218569 0.205937. RooCrystalBall(x): 9.92564 9.92564. RooCBShape(x): 9.92564 9.92564. RooWrapperPdf(x): 5 105. RooBinSamplingPdf(x): 3.06217 9.92564. RooHistFunc(x,y): 100 105. RooHistPdf(x,y): 5 105. RooKeysPdf(x,y): 0.218569 0.205937. RooCrystalBall(x,y): 9.92564 9.92564. RooCBShape(x,y): 9.92564 9.92564. RooWrapperPdf(x,y): 5 105. RooBinSamplingPdf(x,y): 3.06217 9.92564. ```. * It's probably okay to not return values when the normalization set is empty, although it could easily implemented to do it (well, maybe not for the `RooAddPdf`...). ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:2135,safety,test,test,2135,"etVal(2.5);. // no interpolation. RooHistFunc histFunc{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. RooHistPdf(): 500 nan. RooKeysPdf(): 0.201299 nan. RooCrystalBall(): 1 nan. RooCBShape(): 1 nan. RooWrapperPdf(): 100 nan. RooBinSamplingPdf(): 0.308511 nan. RooHistFunc(x): 100 105. RooHistPdf(x): 5 105. RooKeysPdf(x): 0.218569 0.205937. RooCrystalBall(x): 9.92564 9.92564. RooCBShape(x): 9.92564 9.92564. RooWrapperPdf(x): 5 105. RooBinSamplingPdf(x): 3.06217 9.92564. RooHistFunc(x,y): 100 105. RooHistPdf(x,y): 5 105. RooKeysPdf(x,y): 0.218569 0.205937. RooCrystalBall(x,y): 9.92564 9.92564. RooCBShape(x,y): 9.92564 9.92564. RooWrapperPdf(x,y): 5 105. RooBinSamplingPdf(x,y): 3.06217 9.92564. ```. * It's probably okay to not return values when the normalization set is empty, although it could easily implemented to do it (well, maybe not for the `RooAddPdf`...). * Expect for the crystal ball",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:2160,safety,test,test,2160,"olation. RooHistFunc histFunc{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. RooHistPdf(): 500 nan. RooKeysPdf(): 0.201299 nan. RooCrystalBall(): 1 nan. RooCBShape(): 1 nan. RooWrapperPdf(): 100 nan. RooBinSamplingPdf(): 0.308511 nan. RooHistFunc(x): 100 105. RooHistPdf(x): 5 105. RooKeysPdf(x): 0.218569 0.205937. RooCrystalBall(x): 9.92564 9.92564. RooCBShape(x): 9.92564 9.92564. RooWrapperPdf(x): 5 105. RooBinSamplingPdf(x): 3.06217 9.92564. RooHistFunc(x,y): 100 105. RooHistPdf(x,y): 5 105. RooKeysPdf(x,y): 0.218569 0.205937. RooCrystalBall(x,y): 9.92564 9.92564. RooCBShape(x,y): 9.92564 9.92564. RooWrapperPdf(x,y): 5 105. RooBinSamplingPdf(x,y): 3.06217 9.92564. ```. * It's probably okay to not return values when the normalization set is empty, although it could easily implemented to do it (well, maybe not for the `RooAddPdf`...). * Expect for the crystal ball functions, the values ar",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:2188,safety,test,test,2188,"c{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. RooHistPdf(): 500 nan. RooKeysPdf(): 0.201299 nan. RooCrystalBall(): 1 nan. RooCBShape(): 1 nan. RooWrapperPdf(): 100 nan. RooBinSamplingPdf(): 0.308511 nan. RooHistFunc(x): 100 105. RooHistPdf(x): 5 105. RooKeysPdf(x): 0.218569 0.205937. RooCrystalBall(x): 9.92564 9.92564. RooCBShape(x): 9.92564 9.92564. RooWrapperPdf(x): 5 105. RooBinSamplingPdf(x): 3.06217 9.92564. RooHistFunc(x,y): 100 105. RooHistPdf(x,y): 5 105. RooKeysPdf(x,y): 0.218569 0.205937. RooCrystalBall(x,y): 9.92564 9.92564. RooCBShape(x,y): 9.92564 9.92564. RooWrapperPdf(x,y): 5 105. RooBinSamplingPdf(x,y): 3.06217 9.92564. ```. * It's probably okay to not return values when the normalization set is empty, although it could easily implemented to do it (well, maybe not for the `RooAddPdf`...). * Expect for the crystal ball functions, the values are not correct. The implement",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:3316,safety,review,reviewed,3316,"perPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. RooHistPdf(): 500 nan. RooKeysPdf(): 0.201299 nan. RooCrystalBall(): 1 nan. RooCBShape(): 1 nan. RooWrapperPdf(): 100 nan. RooBinSamplingPdf(): 0.308511 nan. RooHistFunc(x): 100 105. RooHistPdf(x): 5 105. RooKeysPdf(x): 0.218569 0.205937. RooCrystalBall(x): 9.92564 9.92564. RooCBShape(x): 9.92564 9.92564. RooWrapperPdf(x): 5 105. RooBinSamplingPdf(x): 3.06217 9.92564. RooHistFunc(x,y): 100 105. RooHistPdf(x,y): 5 105. RooKeysPdf(x,y): 0.218569 0.205937. RooCrystalBall(x,y): 9.92564 9.92564. RooCBShape(x,y): 9.92564 9.92564. RooWrapperPdf(x,y): 5 105. RooBinSamplingPdf(x,y): 3.06217 9.92564. ```. * It's probably okay to not return values when the normalization set is empty, although it could easily implemented to do it (well, maybe not for the `RooAddPdf`...). * Expect for the crystal ball functions, the values are not correct. The implementations should be corrected and at the same time the usage of `RooAbsReal::getMaxVal()` and `maxVal()` inside RooFit should be reviewed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:1602,testability,observ,observables,1602,"lpha, n);. RooCBShape cbShape(""cb2"", ""cb2"", x, x0, sigma, alpha, n);. // This one is not exact, and it fact should not be implemented. // It is unnecessary because it forwards to the generator of the underlying Pdf. RooBinSamplingPdf binSamplingPdf(""binSamplingPdf"", ""binSamplingPdf"", x, crystalBall);. RooDataHist templHist{""templHist"", ""templHist"", x};. templHist.set(x.getBin(), 100.0, -1.0);. RooDataSet templData{""templData"", ""templData"", x};. for (int i = 0; i < x.numBins(); ++i) {. x.setBin(i);. templData.add(x);. }. x.setVal(2.5);. // no interpolation. RooHistFunc histFunc{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. RooHistPdf(): 500 nan. RooKeysPdf(): 0.201299 nan. RooCrystalBall(): 1 nan. RooCBShape(): 1 nan. RooWrapperPdf(): 100 nan. RooBinSamplingPdf(): 0.308511 nan. RooHistFunc(x): 100 105. RooHistPdf(x): 5 105. RooKeysPdf(x): 0.218569 0.205937. RooCrystalBall(x): 9.92564 9.92",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:1666,testability,test,test,1666,"pha, n);. // This one is not exact, and it fact should not be implemented. // It is unnecessary because it forwards to the generator of the underlying Pdf. RooBinSamplingPdf binSamplingPdf(""binSamplingPdf"", ""binSamplingPdf"", x, crystalBall);. RooDataHist templHist{""templHist"", ""templHist"", x};. templHist.set(x.getBin(), 100.0, -1.0);. RooDataSet templData{""templData"", ""templData"", x};. for (int i = 0; i < x.numBins(); ++i) {. x.setBin(i);. templData.add(x);. }. x.setVal(2.5);. // no interpolation. RooHistFunc histFunc{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. RooHistPdf(): 500 nan. RooKeysPdf(): 0.201299 nan. RooCrystalBall(): 1 nan. RooCBShape(): 1 nan. RooWrapperPdf(): 100 nan. RooBinSamplingPdf(): 0.308511 nan. RooHistFunc(x): 100 105. RooHistPdf(x): 5 105. RooKeysPdf(x): 0.218569 0.205937. RooCrystalBall(x): 9.92564 9.92564. RooCBShape(x): 9.92564 9.92564. RooWrapperPdf(x): 5 105",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:2030,testability,test,test,2030,"Data"", ""templData"", x};. for (int i = 0; i < x.numBins(); ++i) {. x.setBin(i);. templData.add(x);. }. x.setVal(2.5);. // no interpolation. RooHistFunc histFunc{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. RooHistPdf(): 500 nan. RooKeysPdf(): 0.201299 nan. RooCrystalBall(): 1 nan. RooCBShape(): 1 nan. RooWrapperPdf(): 100 nan. RooBinSamplingPdf(): 0.308511 nan. RooHistFunc(x): 100 105. RooHistPdf(x): 5 105. RooKeysPdf(x): 0.218569 0.205937. RooCrystalBall(x): 9.92564 9.92564. RooCBShape(x): 9.92564 9.92564. RooWrapperPdf(x): 5 105. RooBinSamplingPdf(x): 3.06217 9.92564. RooHistFunc(x,y): 100 105. RooHistPdf(x,y): 5 105. RooKeysPdf(x,y): 0.218569 0.205937. RooCrystalBall(x,y): 9.92564 9.92564. RooCBShape(x,y): 9.92564 9.92564. RooWrapperPdf(x,y): 5 105. RooBinSamplingPdf(x,y): 3.06217 9.92564. ```. * It's probably okay to not return values when the normalization set is empty, although it ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:2056,testability,test,test,2056,"or (int i = 0; i < x.numBins(); ++i) {. x.setBin(i);. templData.add(x);. }. x.setVal(2.5);. // no interpolation. RooHistFunc histFunc{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. RooHistPdf(): 500 nan. RooKeysPdf(): 0.201299 nan. RooCrystalBall(): 1 nan. RooCBShape(): 1 nan. RooWrapperPdf(): 100 nan. RooBinSamplingPdf(): 0.308511 nan. RooHistFunc(x): 100 105. RooHistPdf(x): 5 105. RooKeysPdf(x): 0.218569 0.205937. RooCrystalBall(x): 9.92564 9.92564. RooCBShape(x): 9.92564 9.92564. RooWrapperPdf(x): 5 105. RooBinSamplingPdf(x): 3.06217 9.92564. RooHistFunc(x,y): 100 105. RooHistPdf(x,y): 5 105. RooKeysPdf(x,y): 0.218569 0.205937. RooCrystalBall(x,y): 9.92564 9.92564. RooCBShape(x,y): 9.92564 9.92564. RooWrapperPdf(x,y): 5 105. RooBinSamplingPdf(x,y): 3.06217 9.92564. ```. * It's probably okay to not return values when the normalization set is empty, although it could easily implemented t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:2081,testability,test,test,2081,"ins(); ++i) {. x.setBin(i);. templData.add(x);. }. x.setVal(2.5);. // no interpolation. RooHistFunc histFunc{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. RooHistPdf(): 500 nan. RooKeysPdf(): 0.201299 nan. RooCrystalBall(): 1 nan. RooCBShape(): 1 nan. RooWrapperPdf(): 100 nan. RooBinSamplingPdf(): 0.308511 nan. RooHistFunc(x): 100 105. RooHistPdf(x): 5 105. RooKeysPdf(x): 0.218569 0.205937. RooCrystalBall(x): 9.92564 9.92564. RooCBShape(x): 9.92564 9.92564. RooWrapperPdf(x): 5 105. RooBinSamplingPdf(x): 3.06217 9.92564. RooHistFunc(x,y): 100 105. RooHistPdf(x,y): 5 105. RooKeysPdf(x,y): 0.218569 0.205937. RooCrystalBall(x,y): 9.92564 9.92564. RooCBShape(x,y): 9.92564 9.92564. RooWrapperPdf(x,y): 5 105. RooBinSamplingPdf(x,y): 3.06217 9.92564. ```. * It's probably okay to not return values when the normalization set is empty, although it could easily implemented to do it (well, maybe not ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:2106,testability,test,test,2106,");. templData.add(x);. }. x.setVal(2.5);. // no interpolation. RooHistFunc histFunc{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. RooHistPdf(): 500 nan. RooKeysPdf(): 0.201299 nan. RooCrystalBall(): 1 nan. RooCBShape(): 1 nan. RooWrapperPdf(): 100 nan. RooBinSamplingPdf(): 0.308511 nan. RooHistFunc(x): 100 105. RooHistPdf(x): 5 105. RooKeysPdf(x): 0.218569 0.205937. RooCrystalBall(x): 9.92564 9.92564. RooCBShape(x): 9.92564 9.92564. RooWrapperPdf(x): 5 105. RooBinSamplingPdf(x): 3.06217 9.92564. RooHistFunc(x,y): 100 105. RooHistPdf(x,y): 5 105. RooKeysPdf(x,y): 0.218569 0.205937. RooCrystalBall(x,y): 9.92564 9.92564. RooCBShape(x,y): 9.92564 9.92564. RooWrapperPdf(x,y): 5 105. RooBinSamplingPdf(x,y): 3.06217 9.92564. ```. * It's probably okay to not return values when the normalization set is empty, although it could easily implemented to do it (well, maybe not for the `RooAddPdf`...). ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:2135,testability,test,test,2135,"etVal(2.5);. // no interpolation. RooHistFunc histFunc{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. RooHistPdf(): 500 nan. RooKeysPdf(): 0.201299 nan. RooCrystalBall(): 1 nan. RooCBShape(): 1 nan. RooWrapperPdf(): 100 nan. RooBinSamplingPdf(): 0.308511 nan. RooHistFunc(x): 100 105. RooHistPdf(x): 5 105. RooKeysPdf(x): 0.218569 0.205937. RooCrystalBall(x): 9.92564 9.92564. RooCBShape(x): 9.92564 9.92564. RooWrapperPdf(x): 5 105. RooBinSamplingPdf(x): 3.06217 9.92564. RooHistFunc(x,y): 100 105. RooHistPdf(x,y): 5 105. RooKeysPdf(x,y): 0.218569 0.205937. RooCrystalBall(x,y): 9.92564 9.92564. RooCBShape(x,y): 9.92564 9.92564. RooWrapperPdf(x,y): 5 105. RooBinSamplingPdf(x,y): 3.06217 9.92564. ```. * It's probably okay to not return values when the normalization set is empty, although it could easily implemented to do it (well, maybe not for the `RooAddPdf`...). * Expect for the crystal ball",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:2160,testability,test,test,2160,"olation. RooHistFunc histFunc{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. RooHistPdf(): 500 nan. RooKeysPdf(): 0.201299 nan. RooCrystalBall(): 1 nan. RooCBShape(): 1 nan. RooWrapperPdf(): 100 nan. RooBinSamplingPdf(): 0.308511 nan. RooHistFunc(x): 100 105. RooHistPdf(x): 5 105. RooKeysPdf(x): 0.218569 0.205937. RooCrystalBall(x): 9.92564 9.92564. RooCBShape(x): 9.92564 9.92564. RooWrapperPdf(x): 5 105. RooBinSamplingPdf(x): 3.06217 9.92564. RooHistFunc(x,y): 100 105. RooHistPdf(x,y): 5 105. RooKeysPdf(x,y): 0.218569 0.205937. RooCrystalBall(x,y): 9.92564 9.92564. RooCBShape(x,y): 9.92564 9.92564. RooWrapperPdf(x,y): 5 105. RooBinSamplingPdf(x,y): 3.06217 9.92564. ```. * It's probably okay to not return values when the normalization set is empty, although it could easily implemented to do it (well, maybe not for the `RooAddPdf`...). * Expect for the crystal ball functions, the values ar",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:2188,testability,test,test,2188,"c{""histFunc"", ""histFunc"", x, templHist, 0};. RooHistPdf histPdf{""histPdf"", ""histPdf"", x, templHist, 0};. RooWrapperPdf wrapperPdf{""wrapperPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. RooHistPdf(): 500 nan. RooKeysPdf(): 0.201299 nan. RooCrystalBall(): 1 nan. RooCBShape(): 1 nan. RooWrapperPdf(): 100 nan. RooBinSamplingPdf(): 0.308511 nan. RooHistFunc(x): 100 105. RooHistPdf(x): 5 105. RooKeysPdf(x): 0.218569 0.205937. RooCrystalBall(x): 9.92564 9.92564. RooCBShape(x): 9.92564 9.92564. RooWrapperPdf(x): 5 105. RooBinSamplingPdf(x): 3.06217 9.92564. RooHistFunc(x,y): 100 105. RooHistPdf(x,y): 5 105. RooKeysPdf(x,y): 0.218569 0.205937. RooCrystalBall(x,y): 9.92564 9.92564. RooCBShape(x,y): 9.92564 9.92564. RooWrapperPdf(x,y): 5 105. RooBinSamplingPdf(x,y): 3.06217 9.92564. ```. * It's probably okay to not return values when the normalization set is empty, although it could easily implemented to do it (well, maybe not for the `RooAddPdf`...). * Expect for the crystal ball functions, the values are not correct. The implement",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12317:3316,testability,review,reviewed,3316,"perPdf"", ""wrapperPdf"", histFunc};. RooKeysPdf keysPdf{""keysPdf"", ""keysPdf"", x, templData};. RooArgSet normSet0{}; // check empty normalization set. RooArgSet normSet1{x}; // check ""usual"" normalization set. RooArgSet normSet2{x, y}; // it should also handle extra disconnected observables. // init caches. wrapperPdf.getVal(normSet1);. auto test = [&](RooAbsReal const &func, RooArgSet const &nset) {. int maxValCode = func.getMaxVal(nset);. double maxVal = NAN;. if (maxValCode != 0). maxVal = func.maxVal(maxValCode);. std::cout << func.ClassName() << nset << "": "" << func.getVal(nset) << "" "" << maxVal << std::endl;. };. for (auto &normSet : {normSet0, normSet1, normSet2}) {. std::cout << std::endl;. test(histFunc, normSet);. test(histPdf, normSet);. test(keysPdf, normSet);. test(crystalBall, normSet);. test(cbShape, normSet);. test(wrapperPdf, normSet);. test(binSamplingPdf, normSet);. // still missing: RooFFTConvPdf, RooSPHarmonic, and RooLegendre. }. ```. The output is:. ```. RooHistFunc(): 100 nan. RooHistPdf(): 500 nan. RooKeysPdf(): 0.201299 nan. RooCrystalBall(): 1 nan. RooCBShape(): 1 nan. RooWrapperPdf(): 100 nan. RooBinSamplingPdf(): 0.308511 nan. RooHistFunc(x): 100 105. RooHistPdf(x): 5 105. RooKeysPdf(x): 0.218569 0.205937. RooCrystalBall(x): 9.92564 9.92564. RooCBShape(x): 9.92564 9.92564. RooWrapperPdf(x): 5 105. RooBinSamplingPdf(x): 3.06217 9.92564. RooHistFunc(x,y): 100 105. RooHistPdf(x,y): 5 105. RooKeysPdf(x,y): 0.218569 0.205937. RooCrystalBall(x,y): 9.92564 9.92564. RooCBShape(x,y): 9.92564 9.92564. RooWrapperPdf(x,y): 5 105. RooBinSamplingPdf(x,y): 3.06217 9.92564. ```. * It's probably okay to not return values when the normalization set is empty, although it could easily implemented to do it (well, maybe not for the `RooAddPdf`...). * Expect for the crystal ball functions, the values are not correct. The implementations should be corrected and at the same time the usage of `RooAbsReal::getMaxVal()` and `maxVal()` inside RooFit should be reviewed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12317
https://github.com/root-project/root/issues/12319:47,deployability,patch,patch,47,"[RF] RooFit open issues and backports for 6.28 patch releases; The related issues for the original 6.28.00 release:. 1. https://github.com/root-project/root/issues/11856. # 6.28.02. **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/12178. - [x] https://github.com/root-project/root/pull/12125. - [x] https://github.com/root-project/root/pull/12236. - [x] https://github.com/root-project/root/pull/12250. - [x] https://github.com/root-project/root/pull/12305. - [x] https://github.com/root-project/root/pull/12287. The backports were grouped in a few PRs to `v6-28-00-patches`:. 1. https://github.com/root-project/root/pull/12321.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:53,deployability,releas,releases,53,"[RF] RooFit open issues and backports for 6.28 patch releases; The related issues for the original 6.28.00 release:. 1. https://github.com/root-project/root/issues/11856. # 6.28.02. **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/12178. - [x] https://github.com/root-project/root/pull/12125. - [x] https://github.com/root-project/root/pull/12236. - [x] https://github.com/root-project/root/pull/12250. - [x] https://github.com/root-project/root/pull/12305. - [x] https://github.com/root-project/root/pull/12287. The backports were grouped in a few PRs to `v6-28-00-patches`:. 1. https://github.com/root-project/root/pull/12321.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:107,deployability,releas,release,107,"[RF] RooFit open issues and backports for 6.28 patch releases; The related issues for the original 6.28.00 release:. 1. https://github.com/root-project/root/issues/11856. # 6.28.02. **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/12178. - [x] https://github.com/root-project/root/pull/12125. - [x] https://github.com/root-project/root/pull/12236. - [x] https://github.com/root-project/root/pull/12250. - [x] https://github.com/root-project/root/pull/12305. - [x] https://github.com/root-project/root/pull/12287. The backports were grouped in a few PRs to `v6-28-00-patches`:. 1. https://github.com/root-project/root/pull/12321.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:725,deployability,patch,patches,725,"[RF] RooFit open issues and backports for 6.28 patch releases; The related issues for the original 6.28.00 release:. 1. https://github.com/root-project/root/issues/11856. # 6.28.02. **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/12178. - [x] https://github.com/root-project/root/pull/12125. - [x] https://github.com/root-project/root/pull/12236. - [x] https://github.com/root-project/root/pull/12250. - [x] https://github.com/root-project/root/pull/12305. - [x] https://github.com/root-project/root/pull/12287. The backports were grouped in a few PRs to `v6-28-00-patches`:. 1. https://github.com/root-project/root/pull/12321.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:47,safety,patch,patch,47,"[RF] RooFit open issues and backports for 6.28 patch releases; The related issues for the original 6.28.00 release:. 1. https://github.com/root-project/root/issues/11856. # 6.28.02. **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/12178. - [x] https://github.com/root-project/root/pull/12125. - [x] https://github.com/root-project/root/pull/12236. - [x] https://github.com/root-project/root/pull/12250. - [x] https://github.com/root-project/root/pull/12305. - [x] https://github.com/root-project/root/pull/12287. The backports were grouped in a few PRs to `v6-28-00-patches`:. 1. https://github.com/root-project/root/pull/12321.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:725,safety,patch,patches,725,"[RF] RooFit open issues and backports for 6.28 patch releases; The related issues for the original 6.28.00 release:. 1. https://github.com/root-project/root/issues/11856. # 6.28.02. **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/12178. - [x] https://github.com/root-project/root/pull/12125. - [x] https://github.com/root-project/root/pull/12236. - [x] https://github.com/root-project/root/pull/12250. - [x] https://github.com/root-project/root/pull/12305. - [x] https://github.com/root-project/root/pull/12287. The backports were grouped in a few PRs to `v6-28-00-patches`:. 1. https://github.com/root-project/root/pull/12321.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:47,security,patch,patch,47,"[RF] RooFit open issues and backports for 6.28 patch releases; The related issues for the original 6.28.00 release:. 1. https://github.com/root-project/root/issues/11856. # 6.28.02. **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/12178. - [x] https://github.com/root-project/root/pull/12125. - [x] https://github.com/root-project/root/pull/12236. - [x] https://github.com/root-project/root/pull/12250. - [x] https://github.com/root-project/root/pull/12305. - [x] https://github.com/root-project/root/pull/12287. The backports were grouped in a few PRs to `v6-28-00-patches`:. 1. https://github.com/root-project/root/pull/12321.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/issues/12319:725,security,patch,patches,725,"[RF] RooFit open issues and backports for 6.28 patch releases; The related issues for the original 6.28.00 release:. 1. https://github.com/root-project/root/issues/11856. # 6.28.02. **Backports** that need to be made for the v6.28 branch (in this particular order from top to bottom, to not have a commit history too different from master):. - [x] https://github.com/root-project/root/pull/12178. - [x] https://github.com/root-project/root/pull/12125. - [x] https://github.com/root-project/root/pull/12236. - [x] https://github.com/root-project/root/pull/12250. - [x] https://github.com/root-project/root/pull/12305. - [x] https://github.com/root-project/root/pull/12287. The backports were grouped in a few PRs to `v6-28-00-patches`:. 1. https://github.com/root-project/root/pull/12321.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12319
https://github.com/root-project/root/pull/12320:468,integrability,configur,configured,468,"[webwindow] use `window.resizeTo` function for changing web browser size; In Chrome browser one can change window size from JavaScript using `window.resizeTo` method. This solves problem when different `RWebWindow` instances with different sizes need to be used - . like in `tutorials/geom/geodemo.C`. Introduce also X and Y coordinate for `RWebWindow`, use `window.moveTo` to move browser to specified position. Use this features for `TWebCanvas` to preserve/enforce configured canvas size. Let change canvas size via context menu.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12320
https://github.com/root-project/root/pull/12320:325,interoperability,coordinat,coordinate,325,"[webwindow] use `window.resizeTo` function for changing web browser size; In Chrome browser one can change window size from JavaScript using `window.resizeTo` method. This solves problem when different `RWebWindow` instances with different sizes need to be used - . like in `tutorials/geom/geodemo.C`. Introduce also X and Y coordinate for `RWebWindow`, use `window.moveTo` to move browser to specified position. Use this features for `TWebCanvas` to preserve/enforce configured canvas size. Let change canvas size via context menu.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12320
https://github.com/root-project/root/pull/12320:393,interoperability,specif,specified,393,"[webwindow] use `window.resizeTo` function for changing web browser size; In Chrome browser one can change window size from JavaScript using `window.resizeTo` method. This solves problem when different `RWebWindow` instances with different sizes need to be used - . like in `tutorials/geom/geodemo.C`. Introduce also X and Y coordinate for `RWebWindow`, use `window.moveTo` to move browser to specified position. Use this features for `TWebCanvas` to preserve/enforce configured canvas size. Let change canvas size via context menu.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12320
https://github.com/root-project/root/pull/12320:468,modifiability,configur,configured,468,"[webwindow] use `window.resizeTo` function for changing web browser size; In Chrome browser one can change window size from JavaScript using `window.resizeTo` method. This solves problem when different `RWebWindow` instances with different sizes need to be used - . like in `tutorials/geom/geodemo.C`. Introduce also X and Y coordinate for `RWebWindow`, use `window.moveTo` to move browser to specified position. Use this features for `TWebCanvas` to preserve/enforce configured canvas size. Let change canvas size via context menu.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12320
https://github.com/root-project/root/pull/12320:468,security,configur,configured,468,"[webwindow] use `window.resizeTo` function for changing web browser size; In Chrome browser one can change window size from JavaScript using `window.resizeTo` method. This solves problem when different `RWebWindow` instances with different sizes need to be used - . like in `tutorials/geom/geodemo.C`. Introduce also X and Y coordinate for `RWebWindow`, use `window.moveTo` to move browser to specified position. Use this features for `TWebCanvas` to preserve/enforce configured canvas size. Let change canvas size via context menu.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12320
https://github.com/root-project/root/pull/12320:519,testability,context,context,519,"[webwindow] use `window.resizeTo` function for changing web browser size; In Chrome browser one can change window size from JavaScript using `window.resizeTo` method. This solves problem when different `RWebWindow` instances with different sizes need to be used - . like in `tutorials/geom/geodemo.C`. Introduce also X and Y coordinate for `RWebWindow`, use `window.moveTo` to move browser to specified position. Use this features for `TWebCanvas` to preserve/enforce configured canvas size. Let change canvas size via context menu.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12320
https://github.com/root-project/root/pull/12320:527,usability,menu,menu,527,"[webwindow] use `window.resizeTo` function for changing web browser size; In Chrome browser one can change window size from JavaScript using `window.resizeTo` method. This solves problem when different `RWebWindow` instances with different sizes need to be used - . like in `tutorials/geom/geodemo.C`. Introduce also X and Y coordinate for `RWebWindow`, use `window.moveTo` to move browser to specified position. Use this features for `TWebCanvas` to preserve/enforce configured canvas size. Let change canvas size via context menu.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12320
https://github.com/root-project/root/pull/12321:48,deployability,patch,patches,48,"[v628][RF] Backports of RooFit PRs to `v6-28-00-patches`: Part 11; This is a backport of all the relevant RooFit PRs that were recently merged to master to v6-28-00-patches (in the right order, to not have the commit history diverge too much). 1. https://github.com/root-project/root/pull/12178. 2. https://github.com/root-project/root/pull/12125. 3. https://github.com/root-project/root/pull/12236. 4. https://github.com/root-project/root/pull/12250. 5. https://github.com/root-project/root/pull/12305. 6. https://github.com/root-project/root/pull/12287. Related to https://github.com/root-project/root/issues/12319.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12321
https://github.com/root-project/root/pull/12321:165,deployability,patch,patches,165,"[v628][RF] Backports of RooFit PRs to `v6-28-00-patches`: Part 11; This is a backport of all the relevant RooFit PRs that were recently merged to master to v6-28-00-patches (in the right order, to not have the commit history diverge too much). 1. https://github.com/root-project/root/pull/12178. 2. https://github.com/root-project/root/pull/12125. 3. https://github.com/root-project/root/pull/12236. 4. https://github.com/root-project/root/pull/12250. 5. https://github.com/root-project/root/pull/12305. 6. https://github.com/root-project/root/pull/12287. Related to https://github.com/root-project/root/issues/12319.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12321
https://github.com/root-project/root/pull/12321:48,safety,patch,patches,48,"[v628][RF] Backports of RooFit PRs to `v6-28-00-patches`: Part 11; This is a backport of all the relevant RooFit PRs that were recently merged to master to v6-28-00-patches (in the right order, to not have the commit history diverge too much). 1. https://github.com/root-project/root/pull/12178. 2. https://github.com/root-project/root/pull/12125. 3. https://github.com/root-project/root/pull/12236. 4. https://github.com/root-project/root/pull/12250. 5. https://github.com/root-project/root/pull/12305. 6. https://github.com/root-project/root/pull/12287. Related to https://github.com/root-project/root/issues/12319.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12321
https://github.com/root-project/root/pull/12321:165,safety,patch,patches,165,"[v628][RF] Backports of RooFit PRs to `v6-28-00-patches`: Part 11; This is a backport of all the relevant RooFit PRs that were recently merged to master to v6-28-00-patches (in the right order, to not have the commit history diverge too much). 1. https://github.com/root-project/root/pull/12178. 2. https://github.com/root-project/root/pull/12125. 3. https://github.com/root-project/root/pull/12236. 4. https://github.com/root-project/root/pull/12250. 5. https://github.com/root-project/root/pull/12305. 6. https://github.com/root-project/root/pull/12287. Related to https://github.com/root-project/root/issues/12319.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12321
https://github.com/root-project/root/pull/12321:48,security,patch,patches,48,"[v628][RF] Backports of RooFit PRs to `v6-28-00-patches`: Part 11; This is a backport of all the relevant RooFit PRs that were recently merged to master to v6-28-00-patches (in the right order, to not have the commit history diverge too much). 1. https://github.com/root-project/root/pull/12178. 2. https://github.com/root-project/root/pull/12125. 3. https://github.com/root-project/root/pull/12236. 4. https://github.com/root-project/root/pull/12250. 5. https://github.com/root-project/root/pull/12305. 6. https://github.com/root-project/root/pull/12287. Related to https://github.com/root-project/root/issues/12319.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12321
https://github.com/root-project/root/pull/12321:165,security,patch,patches,165,"[v628][RF] Backports of RooFit PRs to `v6-28-00-patches`: Part 11; This is a backport of all the relevant RooFit PRs that were recently merged to master to v6-28-00-patches (in the right order, to not have the commit history diverge too much). 1. https://github.com/root-project/root/pull/12178. 2. https://github.com/root-project/root/pull/12125. 3. https://github.com/root-project/root/pull/12236. 4. https://github.com/root-project/root/pull/12250. 5. https://github.com/root-project/root/pull/12305. 6. https://github.com/root-project/root/pull/12287. Related to https://github.com/root-project/root/issues/12319.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12321
https://github.com/root-project/root/pull/12322:48,deployability,patch,patches,48,"[v626][RF] Backports of RooFit PRs to `v6-26-00-patches`: Part 27; This is a backport of all the relevant bugfix RooFit PRs that were recently merged to master to v6-26-00-patches (in the right order, to not have the commit history diverge too much). 1. https://github.com/root-project/root/pull/12119. 2. https://github.com/root-project/root/pull/12305. Only the first commit that is not code modernization. Related to https://github.com/root-project/root/issues/11534.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12322
https://github.com/root-project/root/pull/12322:172,deployability,patch,patches,172,"[v626][RF] Backports of RooFit PRs to `v6-26-00-patches`: Part 27; This is a backport of all the relevant bugfix RooFit PRs that were recently merged to master to v6-26-00-patches (in the right order, to not have the commit history diverge too much). 1. https://github.com/root-project/root/pull/12119. 2. https://github.com/root-project/root/pull/12305. Only the first commit that is not code modernization. Related to https://github.com/root-project/root/issues/11534.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12322
https://github.com/root-project/root/pull/12322:48,safety,patch,patches,48,"[v626][RF] Backports of RooFit PRs to `v6-26-00-patches`: Part 27; This is a backport of all the relevant bugfix RooFit PRs that were recently merged to master to v6-26-00-patches (in the right order, to not have the commit history diverge too much). 1. https://github.com/root-project/root/pull/12119. 2. https://github.com/root-project/root/pull/12305. Only the first commit that is not code modernization. Related to https://github.com/root-project/root/issues/11534.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12322
https://github.com/root-project/root/pull/12322:172,safety,patch,patches,172,"[v626][RF] Backports of RooFit PRs to `v6-26-00-patches`: Part 27; This is a backport of all the relevant bugfix RooFit PRs that were recently merged to master to v6-26-00-patches (in the right order, to not have the commit history diverge too much). 1. https://github.com/root-project/root/pull/12119. 2. https://github.com/root-project/root/pull/12305. Only the first commit that is not code modernization. Related to https://github.com/root-project/root/issues/11534.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12322
https://github.com/root-project/root/pull/12322:48,security,patch,patches,48,"[v626][RF] Backports of RooFit PRs to `v6-26-00-patches`: Part 27; This is a backport of all the relevant bugfix RooFit PRs that were recently merged to master to v6-26-00-patches (in the right order, to not have the commit history diverge too much). 1. https://github.com/root-project/root/pull/12119. 2. https://github.com/root-project/root/pull/12305. Only the first commit that is not code modernization. Related to https://github.com/root-project/root/issues/11534.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12322
https://github.com/root-project/root/pull/12322:172,security,patch,patches,172,"[v626][RF] Backports of RooFit PRs to `v6-26-00-patches`: Part 27; This is a backport of all the relevant bugfix RooFit PRs that were recently merged to master to v6-26-00-patches (in the right order, to not have the commit history diverge too much). 1. https://github.com/root-project/root/pull/12119. 2. https://github.com/root-project/root/pull/12305. Only the first commit that is not code modernization. Related to https://github.com/root-project/root/issues/11534.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12322
https://github.com/root-project/root/pull/12323:196,deployability,scale,scaled,196,"Use gStyle attributes for candle and violin; * Introduce new `TStyle` attributes. * Keep old `TCandle` static methods - just redirect them to gStyle. * Fix `candlescaled.C` tutorial - was drawing scaled violin, but title was saying un-scaled. * Adjust JSROOT to support new attributes. With these changes TWebCanvas will correctly display histogram from `candlescaled.C` tutorial",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12323
https://github.com/root-project/root/pull/12323:235,deployability,scale,scaled,235,"Use gStyle attributes for candle and violin; * Introduce new `TStyle` attributes. * Keep old `TCandle` static methods - just redirect them to gStyle. * Fix `candlescaled.C` tutorial - was drawing scaled violin, but title was saying un-scaled. * Adjust JSROOT to support new attributes. With these changes TWebCanvas will correctly display histogram from `candlescaled.C` tutorial",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12323
https://github.com/root-project/root/pull/12323:188,energy efficiency,draw,drawing,188,"Use gStyle attributes for candle and violin; * Introduce new `TStyle` attributes. * Keep old `TCandle` static methods - just redirect them to gStyle. * Fix `candlescaled.C` tutorial - was drawing scaled violin, but title was saying un-scaled. * Adjust JSROOT to support new attributes. With these changes TWebCanvas will correctly display histogram from `candlescaled.C` tutorial",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12323
https://github.com/root-project/root/pull/12323:196,energy efficiency,scale,scaled,196,"Use gStyle attributes for candle and violin; * Introduce new `TStyle` attributes. * Keep old `TCandle` static methods - just redirect them to gStyle. * Fix `candlescaled.C` tutorial - was drawing scaled violin, but title was saying un-scaled. * Adjust JSROOT to support new attributes. With these changes TWebCanvas will correctly display histogram from `candlescaled.C` tutorial",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12323
https://github.com/root-project/root/pull/12323:235,energy efficiency,scale,scaled,235,"Use gStyle attributes for candle and violin; * Introduce new `TStyle` attributes. * Keep old `TCandle` static methods - just redirect them to gStyle. * Fix `candlescaled.C` tutorial - was drawing scaled violin, but title was saying un-scaled. * Adjust JSROOT to support new attributes. With these changes TWebCanvas will correctly display histogram from `candlescaled.C` tutorial",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12323
https://github.com/root-project/root/pull/12323:196,modifiability,scal,scaled,196,"Use gStyle attributes for candle and violin; * Introduce new `TStyle` attributes. * Keep old `TCandle` static methods - just redirect them to gStyle. * Fix `candlescaled.C` tutorial - was drawing scaled violin, but title was saying un-scaled. * Adjust JSROOT to support new attributes. With these changes TWebCanvas will correctly display histogram from `candlescaled.C` tutorial",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12323
https://github.com/root-project/root/pull/12323:235,modifiability,scal,scaled,235,"Use gStyle attributes for candle and violin; * Introduce new `TStyle` attributes. * Keep old `TCandle` static methods - just redirect them to gStyle. * Fix `candlescaled.C` tutorial - was drawing scaled violin, but title was saying un-scaled. * Adjust JSROOT to support new attributes. With these changes TWebCanvas will correctly display histogram from `candlescaled.C` tutorial",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12323
https://github.com/root-project/root/pull/12323:196,performance,scale,scaled,196,"Use gStyle attributes for candle and violin; * Introduce new `TStyle` attributes. * Keep old `TCandle` static methods - just redirect them to gStyle. * Fix `candlescaled.C` tutorial - was drawing scaled violin, but title was saying un-scaled. * Adjust JSROOT to support new attributes. With these changes TWebCanvas will correctly display histogram from `candlescaled.C` tutorial",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12323
https://github.com/root-project/root/pull/12323:235,performance,scale,scaled,235,"Use gStyle attributes for candle and violin; * Introduce new `TStyle` attributes. * Keep old `TCandle` static methods - just redirect them to gStyle. * Fix `candlescaled.C` tutorial - was drawing scaled violin, but title was saying un-scaled. * Adjust JSROOT to support new attributes. With these changes TWebCanvas will correctly display histogram from `candlescaled.C` tutorial",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12323
https://github.com/root-project/root/pull/12323:262,usability,support,support,262,"Use gStyle attributes for candle and violin; * Introduce new `TStyle` attributes. * Keep old `TCandle` static methods - just redirect them to gStyle. * Fix `candlescaled.C` tutorial - was drawing scaled violin, but title was saying un-scaled. * Adjust JSROOT to support new attributes. With these changes TWebCanvas will correctly display histogram from `candlescaled.C` tutorial",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12323
https://github.com/root-project/root/pull/12324:125,availability,operat,operation,125,Add missing TH1K::RetrieveBinContent; Makes lot of warnings when drawing TH1K like in `tutorials/hist/hksimple.C` - any zoom operation makes:. ```. Warning in <TH1K::RetrieveBinContent>: this method must be overridden! ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12324
https://github.com/root-project/root/pull/12324:65,energy efficiency,draw,drawing,65,Add missing TH1K::RetrieveBinContent; Makes lot of warnings when drawing TH1K like in `tutorials/hist/hksimple.C` - any zoom operation makes:. ```. Warning in <TH1K::RetrieveBinContent>: this method must be overridden! ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12324
https://github.com/root-project/root/issues/12326:745,availability,failur,failure,745,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:1169,availability,Error,Error,1169,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:1381,availability,Operat,Operating,1381,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:1456,availability,down,download,1456,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:7,deployability,manag,manager,7,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:71,deployability,modul,module,71,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:85,deployability,build,build,85,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:580,deployability,modul,module,580,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:745,deployability,fail,failure,745,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:1005,deployability,build,build,1005,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:1139,deployability,Modul,Module,1139,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:1369,deployability,version,version,1369,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:1438,deployability,instal,install,1438,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:7,energy efficiency,manag,manager,7,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:558,energy efficiency,load,load,558,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:1125,energy efficiency,Load,LoadPlugin,1125,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:1187,energy efficiency,Load,LoadPCM,1187,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:1321,energy efficiency,Load,LoadPCM,1321,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:1369,integrability,version,version,1369,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:0,interoperability,Plug,Plugin,0,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:567,interoperability,plug,plugin,567,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:71,modifiability,modul,module,71,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:580,modifiability,modul,module,580,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:1139,modifiability,Modul,Module,1139,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:1369,modifiability,version,version,1369,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:558,performance,load,load,558,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:745,performance,failur,failure,745,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:1125,performance,Load,LoadPlugin,1125,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:1169,performance,Error,Error,1169,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:1187,performance,Load,LoadPCM,1187,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:1321,performance,Load,LoadPCM,1321,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:745,reliability,fail,failure,745,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:1273,reliability,doe,does,1273,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:7,safety,manag,manager,7,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:71,safety,modul,module,71,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:580,safety,modul,module,580,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:959,safety,input,input,959,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:1139,safety,Modul,Module,1139,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:1169,safety,Error,Error,1169,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:1495,safety,Test,Tested,1495,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:1495,testability,Test,Tested,1495,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:1594,testability,context,context,1594,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:1623,testability,context,context,1623,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:482,usability,clear,clear,482,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:530,usability,behavi,behavior,530,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:649,usability,behavi,behavior,649,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:667,usability,clear,clear,667,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:814,usability,behavi,behavior,814,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:959,usability,input,input,959,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:1169,usability,Error,Error,1169,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/issues/12326:1207,usability,User,Users,1207,"Plugin manager returns 0 on MacBook Air M1 even when the corresponding module is not build; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. Trying to load the plugin for a module that was not compiled returns 0 (success value). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. Return the failure value (-1 ?). ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```. root [1] gROOT->GetPluginManager()->FindHandler(""TVirtualGeoConverter"")->LoadPlugin(). Module ConverterVG not found. Error in <TCling::LoadPCM>: ROOT PCM /Users/agheata/root/root_install/lib/libConverterVG_rdict.pcm file does not exist. ... long list of PCM's tried by LoadPCM. (int) 0. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Tested with master branch on Monterey MacBook Air (M1, 2020), compiled from source. ### Additional context. <!--. Add any other context about the problem here. -->. The same code on my Ubuntu 22.04 returns correctly -1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12326
https://github.com/root-project/root/pull/12327:180,deployability,updat,updated,180,"[cmake] macOS: export DYLD_LIBRARY_PATH, not LD_LIBRARY_PATH.; Co-authored-by: sa35. # This Pull request:. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes #10062.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12327
https://github.com/root-project/root/pull/12327:150,safety,test,tested,150,"[cmake] macOS: export DYLD_LIBRARY_PATH, not LD_LIBRARY_PATH.; Co-authored-by: sa35. # This Pull request:. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes #10062.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12327
https://github.com/root-project/root/pull/12327:180,safety,updat,updated,180,"[cmake] macOS: export DYLD_LIBRARY_PATH, not LD_LIBRARY_PATH.; Co-authored-by: sa35. # This Pull request:. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes #10062.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12327
https://github.com/root-project/root/pull/12327:66,security,auth,authored-by,66,"[cmake] macOS: export DYLD_LIBRARY_PATH, not LD_LIBRARY_PATH.; Co-authored-by: sa35. # This Pull request:. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes #10062.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12327
https://github.com/root-project/root/pull/12327:180,security,updat,updated,180,"[cmake] macOS: export DYLD_LIBRARY_PATH, not LD_LIBRARY_PATH.; Co-authored-by: sa35. # This Pull request:. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes #10062.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12327
https://github.com/root-project/root/pull/12327:150,testability,test,tested,150,"[cmake] macOS: export DYLD_LIBRARY_PATH, not LD_LIBRARY_PATH.; Co-authored-by: sa35. # This Pull request:. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes #10062.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12327
https://github.com/root-project/root/pull/12328:43,availability,error,error,43,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:123,availability,error,error,123,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:194,availability,error,error,194,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:302,availability,error,error,302,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:349,availability,error,error,349,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:487,availability,error,errors,487,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:129,deployability,log,logging,129,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:49,integrability,messag,messages,49,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:200,integrability,messag,messages,200,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:49,interoperability,messag,messages,49,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:200,interoperability,messag,messages,200,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:11,performance,overhead,overhead,11,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:43,performance,error,error,43,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:123,performance,error,error,123,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:194,performance,error,error,194,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:245,performance,overhead,overhead,245,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:302,performance,error,error,302,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:349,performance,error,error,349,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:487,performance,error,errors,487,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:5,safety,Avoid,Avoid,5,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:43,safety,error,error,43,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:123,safety,error,error,123,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:129,safety,log,logging,129,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:194,safety,error,error,194,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:264,safety,compl,completely,264,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:302,safety,error,error,302,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:349,safety,error,error,349,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:487,safety,error,errors,487,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:519,safety,test,testNaNPacker,519,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:534,safety,test,tests,534,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:129,security,log,logging,129,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:264,security,compl,completely,264,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:129,testability,log,logging,129,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:519,testability,test,testNaNPacker,519,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:534,testability,test,tests,534,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:43,usability,error,error,43,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:83,usability,minim,minimization,83,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:123,usability,error,error,123,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:194,usability,error,error,194,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:302,usability,error,error,302,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:349,usability,error,error,349,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/pull/12328:487,usability,error,errors,487,"[RF] Avoid overhead of tracking evaluation error messages when not needed; For the minimization, the RooMinimizer sets the error logging mode. temporarily to `CollectErrors`, which collects all error messages in. strings. This results in a HUGE overhead, which is completely. unnecessary if evaluation error printing is disabled. In that case, the. error evaluation mode should be set to counting only, which is what this. commit implements. This speeds up fits with frequent evaluation errors a lot, for example. the `testNaNPacker` tests are sped up by 25x.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12328
https://github.com/root-project/root/issues/12329:352,energy efficiency,load,load,352,"[RF] Writing copy of RooWorkspace messes up proxies; Take this workspace here:. [workspace.root.txt](https://github.com/root-project/root/files/10746822/workspace.root.txt). Now run this reproducer code:. ```C++. void repro() {. {. std::unique_ptr<TFile> f{TFile::Open(""workspace.root"")};. RooWorkspace* combined = f->Get<RooWorkspace>(""combined""); // load the original. cout << combined->function(""gaus_x1y1_OSeMmuP_fakeOverall"")->getProxy(0) << std::endl; // this is non-zero. combined->writeToFile(""another.root""); // supposed to create a nice copy. }. std::unique_ptr<TFile> f{TFile::Open(""another.root"")};. RooWorkspace* w = f->Get<RooWorkspace>(""combined""); // load the copy. cout << w->function(""gaus_x1y1_OSeMmuP_fakeOverall"")->getProxy(0) << std::endl; // this is zero ??? }. ```. The output will be:. ```. 0x55925a4e95c0. 0. ```. That's not good. When copying a workspace, the proxies should not be set to zero! Note that the `.txt` suffix has to be removed from the input file. It's just there to be able to upload the workspace to GitHub. Thanks to @will-cern for reporting this.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12329
https://github.com/root-project/root/issues/12329:667,energy efficiency,load,load,667,"[RF] Writing copy of RooWorkspace messes up proxies; Take this workspace here:. [workspace.root.txt](https://github.com/root-project/root/files/10746822/workspace.root.txt). Now run this reproducer code:. ```C++. void repro() {. {. std::unique_ptr<TFile> f{TFile::Open(""workspace.root"")};. RooWorkspace* combined = f->Get<RooWorkspace>(""combined""); // load the original. cout << combined->function(""gaus_x1y1_OSeMmuP_fakeOverall"")->getProxy(0) << std::endl; // this is non-zero. combined->writeToFile(""another.root""); // supposed to create a nice copy. }. std::unique_ptr<TFile> f{TFile::Open(""another.root"")};. RooWorkspace* w = f->Get<RooWorkspace>(""combined""); // load the copy. cout << w->function(""gaus_x1y1_OSeMmuP_fakeOverall"")->getProxy(0) << std::endl; // this is zero ??? }. ```. The output will be:. ```. 0x55925a4e95c0. 0. ```. That's not good. When copying a workspace, the proxies should not be set to zero! Note that the `.txt` suffix has to be removed from the input file. It's just there to be able to upload the workspace to GitHub. Thanks to @will-cern for reporting this.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12329
https://github.com/root-project/root/issues/12329:44,interoperability,prox,proxies,44,"[RF] Writing copy of RooWorkspace messes up proxies; Take this workspace here:. [workspace.root.txt](https://github.com/root-project/root/files/10746822/workspace.root.txt). Now run this reproducer code:. ```C++. void repro() {. {. std::unique_ptr<TFile> f{TFile::Open(""workspace.root"")};. RooWorkspace* combined = f->Get<RooWorkspace>(""combined""); // load the original. cout << combined->function(""gaus_x1y1_OSeMmuP_fakeOverall"")->getProxy(0) << std::endl; // this is non-zero. combined->writeToFile(""another.root""); // supposed to create a nice copy. }. std::unique_ptr<TFile> f{TFile::Open(""another.root"")};. RooWorkspace* w = f->Get<RooWorkspace>(""combined""); // load the copy. cout << w->function(""gaus_x1y1_OSeMmuP_fakeOverall"")->getProxy(0) << std::endl; // this is zero ??? }. ```. The output will be:. ```. 0x55925a4e95c0. 0. ```. That's not good. When copying a workspace, the proxies should not be set to zero! Note that the `.txt` suffix has to be removed from the input file. It's just there to be able to upload the workspace to GitHub. Thanks to @will-cern for reporting this.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12329
https://github.com/root-project/root/issues/12329:887,interoperability,prox,proxies,887,"[RF] Writing copy of RooWorkspace messes up proxies; Take this workspace here:. [workspace.root.txt](https://github.com/root-project/root/files/10746822/workspace.root.txt). Now run this reproducer code:. ```C++. void repro() {. {. std::unique_ptr<TFile> f{TFile::Open(""workspace.root"")};. RooWorkspace* combined = f->Get<RooWorkspace>(""combined""); // load the original. cout << combined->function(""gaus_x1y1_OSeMmuP_fakeOverall"")->getProxy(0) << std::endl; // this is non-zero. combined->writeToFile(""another.root""); // supposed to create a nice copy. }. std::unique_ptr<TFile> f{TFile::Open(""another.root"")};. RooWorkspace* w = f->Get<RooWorkspace>(""combined""); // load the copy. cout << w->function(""gaus_x1y1_OSeMmuP_fakeOverall"")->getProxy(0) << std::endl; // this is zero ??? }. ```. The output will be:. ```. 0x55925a4e95c0. 0. ```. That's not good. When copying a workspace, the proxies should not be set to zero! Note that the `.txt` suffix has to be removed from the input file. It's just there to be able to upload the workspace to GitHub. Thanks to @will-cern for reporting this.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12329
https://github.com/root-project/root/issues/12329:352,performance,load,load,352,"[RF] Writing copy of RooWorkspace messes up proxies; Take this workspace here:. [workspace.root.txt](https://github.com/root-project/root/files/10746822/workspace.root.txt). Now run this reproducer code:. ```C++. void repro() {. {. std::unique_ptr<TFile> f{TFile::Open(""workspace.root"")};. RooWorkspace* combined = f->Get<RooWorkspace>(""combined""); // load the original. cout << combined->function(""gaus_x1y1_OSeMmuP_fakeOverall"")->getProxy(0) << std::endl; // this is non-zero. combined->writeToFile(""another.root""); // supposed to create a nice copy. }. std::unique_ptr<TFile> f{TFile::Open(""another.root"")};. RooWorkspace* w = f->Get<RooWorkspace>(""combined""); // load the copy. cout << w->function(""gaus_x1y1_OSeMmuP_fakeOverall"")->getProxy(0) << std::endl; // this is zero ??? }. ```. The output will be:. ```. 0x55925a4e95c0. 0. ```. That's not good. When copying a workspace, the proxies should not be set to zero! Note that the `.txt` suffix has to be removed from the input file. It's just there to be able to upload the workspace to GitHub. Thanks to @will-cern for reporting this.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12329
https://github.com/root-project/root/issues/12329:667,performance,load,load,667,"[RF] Writing copy of RooWorkspace messes up proxies; Take this workspace here:. [workspace.root.txt](https://github.com/root-project/root/files/10746822/workspace.root.txt). Now run this reproducer code:. ```C++. void repro() {. {. std::unique_ptr<TFile> f{TFile::Open(""workspace.root"")};. RooWorkspace* combined = f->Get<RooWorkspace>(""combined""); // load the original. cout << combined->function(""gaus_x1y1_OSeMmuP_fakeOverall"")->getProxy(0) << std::endl; // this is non-zero. combined->writeToFile(""another.root""); // supposed to create a nice copy. }. std::unique_ptr<TFile> f{TFile::Open(""another.root"")};. RooWorkspace* w = f->Get<RooWorkspace>(""combined""); // load the copy. cout << w->function(""gaus_x1y1_OSeMmuP_fakeOverall"")->getProxy(0) << std::endl; // this is zero ??? }. ```. The output will be:. ```. 0x55925a4e95c0. 0. ```. That's not good. When copying a workspace, the proxies should not be set to zero! Note that the `.txt` suffix has to be removed from the input file. It's just there to be able to upload the workspace to GitHub. Thanks to @will-cern for reporting this.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12329
https://github.com/root-project/root/issues/12329:977,safety,input,input,977,"[RF] Writing copy of RooWorkspace messes up proxies; Take this workspace here:. [workspace.root.txt](https://github.com/root-project/root/files/10746822/workspace.root.txt). Now run this reproducer code:. ```C++. void repro() {. {. std::unique_ptr<TFile> f{TFile::Open(""workspace.root"")};. RooWorkspace* combined = f->Get<RooWorkspace>(""combined""); // load the original. cout << combined->function(""gaus_x1y1_OSeMmuP_fakeOverall"")->getProxy(0) << std::endl; // this is non-zero. combined->writeToFile(""another.root""); // supposed to create a nice copy. }. std::unique_ptr<TFile> f{TFile::Open(""another.root"")};. RooWorkspace* w = f->Get<RooWorkspace>(""combined""); // load the copy. cout << w->function(""gaus_x1y1_OSeMmuP_fakeOverall"")->getProxy(0) << std::endl; // this is zero ??? }. ```. The output will be:. ```. 0x55925a4e95c0. 0. ```. That's not good. When copying a workspace, the proxies should not be set to zero! Note that the `.txt` suffix has to be removed from the input file. It's just there to be able to upload the workspace to GitHub. Thanks to @will-cern for reporting this.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12329
https://github.com/root-project/root/issues/12329:977,usability,input,input,977,"[RF] Writing copy of RooWorkspace messes up proxies; Take this workspace here:. [workspace.root.txt](https://github.com/root-project/root/files/10746822/workspace.root.txt). Now run this reproducer code:. ```C++. void repro() {. {. std::unique_ptr<TFile> f{TFile::Open(""workspace.root"")};. RooWorkspace* combined = f->Get<RooWorkspace>(""combined""); // load the original. cout << combined->function(""gaus_x1y1_OSeMmuP_fakeOverall"")->getProxy(0) << std::endl; // this is non-zero. combined->writeToFile(""another.root""); // supposed to create a nice copy. }. std::unique_ptr<TFile> f{TFile::Open(""another.root"")};. RooWorkspace* w = f->Get<RooWorkspace>(""combined""); // load the copy. cout << w->function(""gaus_x1y1_OSeMmuP_fakeOverall"")->getProxy(0) << std::endl; // this is zero ??? }. ```. The output will be:. ```. 0x55925a4e95c0. 0. ```. That's not good. When copying a workspace, the proxies should not be set to zero! Note that the `.txt` suffix has to be removed from the input file. It's just there to be able to upload the workspace to GitHub. Thanks to @will-cern for reporting this.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12329
https://github.com/root-project/root/pull/12330:218,integrability,Batch,BatchMode,218,"[RF] Clearly mark `RooFit::CloneData()` as deprecated; Marking the `CloneData()` argument for createNLL explicitly as deprecated and noting in the docs that it is ignored. There is no reason to support it now. The new BatchMode doesn't clone the data anyway, the new test statistics with multiprocessing need to clone the data for each process anyway, and the old test statistics classes will be deprecated at some point. Closes the following Jira ticket:. https://sft.its.cern.ch/jira/browse/ROOT-10372",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12330
https://github.com/root-project/root/pull/12330:218,performance,Batch,BatchMode,218,"[RF] Clearly mark `RooFit::CloneData()` as deprecated; Marking the `CloneData()` argument for createNLL explicitly as deprecated and noting in the docs that it is ignored. There is no reason to support it now. The new BatchMode doesn't clone the data anyway, the new test statistics with multiprocessing need to clone the data for each process anyway, and the old test statistics classes will be deprecated at some point. Closes the following Jira ticket:. https://sft.its.cern.ch/jira/browse/ROOT-10372",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12330
https://github.com/root-project/root/pull/12330:228,reliability,doe,doesn,228,"[RF] Clearly mark `RooFit::CloneData()` as deprecated; Marking the `CloneData()` argument for createNLL explicitly as deprecated and noting in the docs that it is ignored. There is no reason to support it now. The new BatchMode doesn't clone the data anyway, the new test statistics with multiprocessing need to clone the data for each process anyway, and the old test statistics classes will be deprecated at some point. Closes the following Jira ticket:. https://sft.its.cern.ch/jira/browse/ROOT-10372",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12330
https://github.com/root-project/root/pull/12330:267,safety,test,test,267,"[RF] Clearly mark `RooFit::CloneData()` as deprecated; Marking the `CloneData()` argument for createNLL explicitly as deprecated and noting in the docs that it is ignored. There is no reason to support it now. The new BatchMode doesn't clone the data anyway, the new test statistics with multiprocessing need to clone the data for each process anyway, and the old test statistics classes will be deprecated at some point. Closes the following Jira ticket:. https://sft.its.cern.ch/jira/browse/ROOT-10372",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12330
https://github.com/root-project/root/pull/12330:364,safety,test,test,364,"[RF] Clearly mark `RooFit::CloneData()` as deprecated; Marking the `CloneData()` argument for createNLL explicitly as deprecated and noting in the docs that it is ignored. There is no reason to support it now. The new BatchMode doesn't clone the data anyway, the new test statistics with multiprocessing need to clone the data for each process anyway, and the old test statistics classes will be deprecated at some point. Closes the following Jira ticket:. https://sft.its.cern.ch/jira/browse/ROOT-10372",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12330
https://github.com/root-project/root/pull/12330:267,testability,test,test,267,"[RF] Clearly mark `RooFit::CloneData()` as deprecated; Marking the `CloneData()` argument for createNLL explicitly as deprecated and noting in the docs that it is ignored. There is no reason to support it now. The new BatchMode doesn't clone the data anyway, the new test statistics with multiprocessing need to clone the data for each process anyway, and the old test statistics classes will be deprecated at some point. Closes the following Jira ticket:. https://sft.its.cern.ch/jira/browse/ROOT-10372",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12330
https://github.com/root-project/root/pull/12330:364,testability,test,test,364,"[RF] Clearly mark `RooFit::CloneData()` as deprecated; Marking the `CloneData()` argument for createNLL explicitly as deprecated and noting in the docs that it is ignored. There is no reason to support it now. The new BatchMode doesn't clone the data anyway, the new test statistics with multiprocessing need to clone the data for each process anyway, and the old test statistics classes will be deprecated at some point. Closes the following Jira ticket:. https://sft.its.cern.ch/jira/browse/ROOT-10372",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12330
https://github.com/root-project/root/pull/12330:5,usability,Clear,Clearly,5,"[RF] Clearly mark `RooFit::CloneData()` as deprecated; Marking the `CloneData()` argument for createNLL explicitly as deprecated and noting in the docs that it is ignored. There is no reason to support it now. The new BatchMode doesn't clone the data anyway, the new test statistics with multiprocessing need to clone the data for each process anyway, and the old test statistics classes will be deprecated at some point. Closes the following Jira ticket:. https://sft.its.cern.ch/jira/browse/ROOT-10372",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12330
https://github.com/root-project/root/pull/12330:194,usability,support,support,194,"[RF] Clearly mark `RooFit::CloneData()` as deprecated; Marking the `CloneData()` argument for createNLL explicitly as deprecated and noting in the docs that it is ignored. There is no reason to support it now. The new BatchMode doesn't clone the data anyway, the new test statistics with multiprocessing need to clone the data for each process anyway, and the old test statistics classes will be deprecated at some point. Closes the following Jira ticket:. https://sft.its.cern.ch/jira/browse/ROOT-10372",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12330
https://github.com/root-project/root/pull/12330:422,usability,Close,Closes,422,"[RF] Clearly mark `RooFit::CloneData()` as deprecated; Marking the `CloneData()` argument for createNLL explicitly as deprecated and noting in the docs that it is ignored. There is no reason to support it now. The new BatchMode doesn't clone the data anyway, the new test statistics with multiprocessing need to clone the data for each process anyway, and the old test statistics classes will be deprecated at some point. Closes the following Jira ticket:. https://sft.its.cern.ch/jira/browse/ROOT-10372",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12330
https://github.com/root-project/root/pull/12331:277,availability,cluster,clusters,277,"[ntuple] Bump in-memory representation of offsets to 64bit; In preparation of adding support for the `SplitIndex[32|64]` and `Index64` column types, this PR bumps `RClusterSize_t` from 32bit to 64bit. On-disk representation stays as is, 32bit. This change makes sure that ""big clusters"" (>512MB) with 64bit offset columns will be properly supported.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:277,deployability,cluster,clusters,277,"[ntuple] Bump in-memory representation of offsets to 64bit; In preparation of adding support for the `SplitIndex[32|64]` and `Index64` column types, this PR bumps `RClusterSize_t` from 32bit to 64bit. On-disk representation stays as is, 32bit. This change makes sure that ""big clusters"" (>512MB) with 64bit offset columns will be properly supported.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:17,performance,memor,memory,17,"[ntuple] Bump in-memory representation of offsets to 64bit; In preparation of adding support for the `SplitIndex[32|64]` and `Index64` column types, this PR bumps `RClusterSize_t` from 32bit to 64bit. On-disk representation stays as is, 32bit. This change makes sure that ""big clusters"" (>512MB) with 64bit offset columns will be properly supported.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:204,performance,disk,disk,204,"[ntuple] Bump in-memory representation of offsets to 64bit; In preparation of adding support for the `SplitIndex[32|64]` and `Index64` column types, this PR bumps `RClusterSize_t` from 32bit to 64bit. On-disk representation stays as is, 32bit. This change makes sure that ""big clusters"" (>512MB) with 64bit offset columns will be properly supported.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:17,usability,memor,memory,17,"[ntuple] Bump in-memory representation of offsets to 64bit; In preparation of adding support for the `SplitIndex[32|64]` and `Index64` column types, this PR bumps `RClusterSize_t` from 32bit to 64bit. On-disk representation stays as is, 32bit. This change makes sure that ""big clusters"" (>512MB) with 64bit offset columns will be properly supported.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:85,usability,support,support,85,"[ntuple] Bump in-memory representation of offsets to 64bit; In preparation of adding support for the `SplitIndex[32|64]` and `Index64` column types, this PR bumps `RClusterSize_t` from 32bit to 64bit. On-disk representation stays as is, 32bit. This change makes sure that ""big clusters"" (>512MB) with 64bit offset columns will be properly supported.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12331:339,usability,support,supported,339,"[ntuple] Bump in-memory representation of offsets to 64bit; In preparation of adding support for the `SplitIndex[32|64]` and `Index64` column types, this PR bumps `RClusterSize_t` from 32bit to 64bit. On-disk representation stays as is, 32bit. This change makes sure that ""big clusters"" (>512MB) with 64bit offset columns will be properly supported.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12331
https://github.com/root-project/root/pull/12332:94,integrability,repositor,repository,94,[CI] skip root-ci on forks; # This Pull request:. Makes `root-ci` get skipped on forks of the repository.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12332
https://github.com/root-project/root/pull/12332:94,interoperability,repositor,repository,94,[CI] skip root-ci on forks; # This Pull request:. Makes `root-ci` get skipped on forks of the repository.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12332
https://github.com/root-project/root/pull/12333:15,deployability,instal,install,15,"Revert ""Do not install {Clang,Cling}Config.cmake in the project lib dir""; This reverts commit 2b283ccf3a624f70dab3e8783d361d25c13e2c65. It might not be needed, see https://github.com/root-project/root/pull/12153#issuecomment-1411591339. FYI @stephanlachnit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12333
https://github.com/root-project/root/issues/12334:426,availability,failur,failure,426,"TTreeReader fails to read `T<Double_32>` as `T<double>`; First reported on the forum at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639 . Minimal reproducer:. ```cpp. #include <Math/Vector4D.h>. #include <ROOT/RDataFrame.hxx>. float TakeMVector(ROOT::Math::PtEtaPhiMVector &) { return 4.2; }. int main() {. ROOT::RDataFrame df(""Tree"", ""example_file.root"");. df.Define(""unused"", ""L""); // the failure disappears if this is commented out, even if ""unused"" is never used. auto dff4 = df.Define(""x"", TakeMVector, {""L""});. dff4.Max<float>(""x"").GetValue();. }. ```. with the input file at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639/3?u=eguiraud . The program errors out with:. ```. The branch L contains data of type ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<Double32_t> >. It cannot be accessed by a TTreeReaderValue<ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<double> >>. ```. (so TTreeReaderValue cannot read a `LorentzVector<PtEtaPhiM4D<Double32_t>>` as a `LorentzVector<PtEtaPhiM4D<double>>`). The following patch by @Axel-Naumann seems to fix the problem:. ```diff. diff --git a/tree/treeplayer/src/TTreeReaderValue.cxx b/tree/treeplayer/src/TTreeReaderValue.cxx. index 2323cffee4..6d938f1b14 100644. --- a/tree/treeplayer/src/TTreeReaderValue.cxx. +++ b/tree/treeplayer/src/TTreeReaderValue.cxx. @@ -554,7 +554,8 @@ void ROOT::Internal::TTreeReaderValueBase::CreateProxy() {. auto branchActualTypeAsClass = dynamic_cast<TClass*>(branchActualType);. auto inheritance = dictAsClass && branchActualTypeAsClass && branchActualTypeAsClass->InheritsFrom(dictAsClass);. - if (fDict != branchActualType && !inheritance) {. + if (fDict != branchActualType && !inheritance. + && dictAsClass->GetTypeInfo() != branchActualTypeAsClass->GetTypeInfo()) {. TDataType *dictdt = dynamic_cast<TDataType*>(fDict);. TDataType *actualdt = dynamic_cast<TDataType*>(branchActualType);. bool complainAboutMismatch = true;. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12334
https://github.com/root-project/root/issues/12334:727,availability,error,errors,727,"TTreeReader fails to read `T<Double_32>` as `T<double>`; First reported on the forum at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639 . Minimal reproducer:. ```cpp. #include <Math/Vector4D.h>. #include <ROOT/RDataFrame.hxx>. float TakeMVector(ROOT::Math::PtEtaPhiMVector &) { return 4.2; }. int main() {. ROOT::RDataFrame df(""Tree"", ""example_file.root"");. df.Define(""unused"", ""L""); // the failure disappears if this is commented out, even if ""unused"" is never used. auto dff4 = df.Define(""x"", TakeMVector, {""L""});. dff4.Max<float>(""x"").GetValue();. }. ```. with the input file at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639/3?u=eguiraud . The program errors out with:. ```. The branch L contains data of type ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<Double32_t> >. It cannot be accessed by a TTreeReaderValue<ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<double> >>. ```. (so TTreeReaderValue cannot read a `LorentzVector<PtEtaPhiM4D<Double32_t>>` as a `LorentzVector<PtEtaPhiM4D<double>>`). The following patch by @Axel-Naumann seems to fix the problem:. ```diff. diff --git a/tree/treeplayer/src/TTreeReaderValue.cxx b/tree/treeplayer/src/TTreeReaderValue.cxx. index 2323cffee4..6d938f1b14 100644. --- a/tree/treeplayer/src/TTreeReaderValue.cxx. +++ b/tree/treeplayer/src/TTreeReaderValue.cxx. @@ -554,7 +554,8 @@ void ROOT::Internal::TTreeReaderValueBase::CreateProxy() {. auto branchActualTypeAsClass = dynamic_cast<TClass*>(branchActualType);. auto inheritance = dictAsClass && branchActualTypeAsClass && branchActualTypeAsClass->InheritsFrom(dictAsClass);. - if (fDict != branchActualType && !inheritance) {. + if (fDict != branchActualType && !inheritance. + && dictAsClass->GetTypeInfo() != branchActualTypeAsClass->GetTypeInfo()) {. TDataType *dictdt = dynamic_cast<TDataType*>(fDict);. TDataType *actualdt = dynamic_cast<TDataType*>(branchActualType);. bool complainAboutMismatch = true;. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12334
https://github.com/root-project/root/issues/12334:12,deployability,fail,fails,12,"TTreeReader fails to read `T<Double_32>` as `T<double>`; First reported on the forum at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639 . Minimal reproducer:. ```cpp. #include <Math/Vector4D.h>. #include <ROOT/RDataFrame.hxx>. float TakeMVector(ROOT::Math::PtEtaPhiMVector &) { return 4.2; }. int main() {. ROOT::RDataFrame df(""Tree"", ""example_file.root"");. df.Define(""unused"", ""L""); // the failure disappears if this is commented out, even if ""unused"" is never used. auto dff4 = df.Define(""x"", TakeMVector, {""L""});. dff4.Max<float>(""x"").GetValue();. }. ```. with the input file at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639/3?u=eguiraud . The program errors out with:. ```. The branch L contains data of type ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<Double32_t> >. It cannot be accessed by a TTreeReaderValue<ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<double> >>. ```. (so TTreeReaderValue cannot read a `LorentzVector<PtEtaPhiM4D<Double32_t>>` as a `LorentzVector<PtEtaPhiM4D<double>>`). The following patch by @Axel-Naumann seems to fix the problem:. ```diff. diff --git a/tree/treeplayer/src/TTreeReaderValue.cxx b/tree/treeplayer/src/TTreeReaderValue.cxx. index 2323cffee4..6d938f1b14 100644. --- a/tree/treeplayer/src/TTreeReaderValue.cxx. +++ b/tree/treeplayer/src/TTreeReaderValue.cxx. @@ -554,7 +554,8 @@ void ROOT::Internal::TTreeReaderValueBase::CreateProxy() {. auto branchActualTypeAsClass = dynamic_cast<TClass*>(branchActualType);. auto inheritance = dictAsClass && branchActualTypeAsClass && branchActualTypeAsClass->InheritsFrom(dictAsClass);. - if (fDict != branchActualType && !inheritance) {. + if (fDict != branchActualType && !inheritance. + && dictAsClass->GetTypeInfo() != branchActualTypeAsClass->GetTypeInfo()) {. TDataType *dictdt = dynamic_cast<TDataType*>(fDict);. TDataType *actualdt = dynamic_cast<TDataType*>(branchActualType);. bool complainAboutMismatch = true;. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12334
https://github.com/root-project/root/issues/12334:426,deployability,fail,failure,426,"TTreeReader fails to read `T<Double_32>` as `T<double>`; First reported on the forum at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639 . Minimal reproducer:. ```cpp. #include <Math/Vector4D.h>. #include <ROOT/RDataFrame.hxx>. float TakeMVector(ROOT::Math::PtEtaPhiMVector &) { return 4.2; }. int main() {. ROOT::RDataFrame df(""Tree"", ""example_file.root"");. df.Define(""unused"", ""L""); // the failure disappears if this is commented out, even if ""unused"" is never used. auto dff4 = df.Define(""x"", TakeMVector, {""L""});. dff4.Max<float>(""x"").GetValue();. }. ```. with the input file at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639/3?u=eguiraud . The program errors out with:. ```. The branch L contains data of type ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<Double32_t> >. It cannot be accessed by a TTreeReaderValue<ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<double> >>. ```. (so TTreeReaderValue cannot read a `LorentzVector<PtEtaPhiM4D<Double32_t>>` as a `LorentzVector<PtEtaPhiM4D<double>>`). The following patch by @Axel-Naumann seems to fix the problem:. ```diff. diff --git a/tree/treeplayer/src/TTreeReaderValue.cxx b/tree/treeplayer/src/TTreeReaderValue.cxx. index 2323cffee4..6d938f1b14 100644. --- a/tree/treeplayer/src/TTreeReaderValue.cxx. +++ b/tree/treeplayer/src/TTreeReaderValue.cxx. @@ -554,7 +554,8 @@ void ROOT::Internal::TTreeReaderValueBase::CreateProxy() {. auto branchActualTypeAsClass = dynamic_cast<TClass*>(branchActualType);. auto inheritance = dictAsClass && branchActualTypeAsClass && branchActualTypeAsClass->InheritsFrom(dictAsClass);. - if (fDict != branchActualType && !inheritance) {. + if (fDict != branchActualType && !inheritance. + && dictAsClass->GetTypeInfo() != branchActualTypeAsClass->GetTypeInfo()) {. TDataType *dictdt = dynamic_cast<TDataType*>(fDict);. TDataType *actualdt = dynamic_cast<TDataType*>(branchActualType);. bool complainAboutMismatch = true;. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12334
https://github.com/root-project/root/issues/12334:763,deployability,contain,contains,763,"TTreeReader fails to read `T<Double_32>` as `T<double>`; First reported on the forum at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639 . Minimal reproducer:. ```cpp. #include <Math/Vector4D.h>. #include <ROOT/RDataFrame.hxx>. float TakeMVector(ROOT::Math::PtEtaPhiMVector &) { return 4.2; }. int main() {. ROOT::RDataFrame df(""Tree"", ""example_file.root"");. df.Define(""unused"", ""L""); // the failure disappears if this is commented out, even if ""unused"" is never used. auto dff4 = df.Define(""x"", TakeMVector, {""L""});. dff4.Max<float>(""x"").GetValue();. }. ```. with the input file at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639/3?u=eguiraud . The program errors out with:. ```. The branch L contains data of type ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<Double32_t> >. It cannot be accessed by a TTreeReaderValue<ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<double> >>. ```. (so TTreeReaderValue cannot read a `LorentzVector<PtEtaPhiM4D<Double32_t>>` as a `LorentzVector<PtEtaPhiM4D<double>>`). The following patch by @Axel-Naumann seems to fix the problem:. ```diff. diff --git a/tree/treeplayer/src/TTreeReaderValue.cxx b/tree/treeplayer/src/TTreeReaderValue.cxx. index 2323cffee4..6d938f1b14 100644. --- a/tree/treeplayer/src/TTreeReaderValue.cxx. +++ b/tree/treeplayer/src/TTreeReaderValue.cxx. @@ -554,7 +554,8 @@ void ROOT::Internal::TTreeReaderValueBase::CreateProxy() {. auto branchActualTypeAsClass = dynamic_cast<TClass*>(branchActualType);. auto inheritance = dictAsClass && branchActualTypeAsClass && branchActualTypeAsClass->InheritsFrom(dictAsClass);. - if (fDict != branchActualType && !inheritance) {. + if (fDict != branchActualType && !inheritance. + && dictAsClass->GetTypeInfo() != branchActualTypeAsClass->GetTypeInfo()) {. TDataType *dictdt = dynamic_cast<TDataType*>(fDict);. TDataType *actualdt = dynamic_cast<TDataType*>(branchActualType);. bool complainAboutMismatch = true;. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12334
https://github.com/root-project/root/issues/12334:1095,deployability,patch,patch,1095,"TTreeReader fails to read `T<Double_32>` as `T<double>`; First reported on the forum at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639 . Minimal reproducer:. ```cpp. #include <Math/Vector4D.h>. #include <ROOT/RDataFrame.hxx>. float TakeMVector(ROOT::Math::PtEtaPhiMVector &) { return 4.2; }. int main() {. ROOT::RDataFrame df(""Tree"", ""example_file.root"");. df.Define(""unused"", ""L""); // the failure disappears if this is commented out, even if ""unused"" is never used. auto dff4 = df.Define(""x"", TakeMVector, {""L""});. dff4.Max<float>(""x"").GetValue();. }. ```. with the input file at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639/3?u=eguiraud . The program errors out with:. ```. The branch L contains data of type ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<Double32_t> >. It cannot be accessed by a TTreeReaderValue<ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<double> >>. ```. (so TTreeReaderValue cannot read a `LorentzVector<PtEtaPhiM4D<Double32_t>>` as a `LorentzVector<PtEtaPhiM4D<double>>`). The following patch by @Axel-Naumann seems to fix the problem:. ```diff. diff --git a/tree/treeplayer/src/TTreeReaderValue.cxx b/tree/treeplayer/src/TTreeReaderValue.cxx. index 2323cffee4..6d938f1b14 100644. --- a/tree/treeplayer/src/TTreeReaderValue.cxx. +++ b/tree/treeplayer/src/TTreeReaderValue.cxx. @@ -554,7 +554,8 @@ void ROOT::Internal::TTreeReaderValueBase::CreateProxy() {. auto branchActualTypeAsClass = dynamic_cast<TClass*>(branchActualType);. auto inheritance = dictAsClass && branchActualTypeAsClass && branchActualTypeAsClass->InheritsFrom(dictAsClass);. - if (fDict != branchActualType && !inheritance) {. + if (fDict != branchActualType && !inheritance. + && dictAsClass->GetTypeInfo() != branchActualTypeAsClass->GetTypeInfo()) {. TDataType *dictdt = dynamic_cast<TDataType*>(fDict);. TDataType *actualdt = dynamic_cast<TDataType*>(branchActualType);. bool complainAboutMismatch = true;. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12334
https://github.com/root-project/root/issues/12334:135,interoperability,convers,conversion-for-lorentz-vector,135,"TTreeReader fails to read `T<Double_32>` as `T<double>`; First reported on the forum at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639 . Minimal reproducer:. ```cpp. #include <Math/Vector4D.h>. #include <ROOT/RDataFrame.hxx>. float TakeMVector(ROOT::Math::PtEtaPhiMVector &) { return 4.2; }. int main() {. ROOT::RDataFrame df(""Tree"", ""example_file.root"");. df.Define(""unused"", ""L""); // the failure disappears if this is commented out, even if ""unused"" is never used. auto dff4 = df.Define(""x"", TakeMVector, {""L""});. dff4.Max<float>(""x"").GetValue();. }. ```. with the input file at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639/3?u=eguiraud . The program errors out with:. ```. The branch L contains data of type ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<Double32_t> >. It cannot be accessed by a TTreeReaderValue<ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<double> >>. ```. (so TTreeReaderValue cannot read a `LorentzVector<PtEtaPhiM4D<Double32_t>>` as a `LorentzVector<PtEtaPhiM4D<double>>`). The following patch by @Axel-Naumann seems to fix the problem:. ```diff. diff --git a/tree/treeplayer/src/TTreeReaderValue.cxx b/tree/treeplayer/src/TTreeReaderValue.cxx. index 2323cffee4..6d938f1b14 100644. --- a/tree/treeplayer/src/TTreeReaderValue.cxx. +++ b/tree/treeplayer/src/TTreeReaderValue.cxx. @@ -554,7 +554,8 @@ void ROOT::Internal::TTreeReaderValueBase::CreateProxy() {. auto branchActualTypeAsClass = dynamic_cast<TClass*>(branchActualType);. auto inheritance = dictAsClass && branchActualTypeAsClass && branchActualTypeAsClass->InheritsFrom(dictAsClass);. - if (fDict != branchActualType && !inheritance) {. + if (fDict != branchActualType && !inheritance. + && dictAsClass->GetTypeInfo() != branchActualTypeAsClass->GetTypeInfo()) {. TDataType *dictdt = dynamic_cast<TDataType*>(fDict);. TDataType *actualdt = dynamic_cast<TDataType*>(branchActualType);. bool complainAboutMismatch = true;. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12334
https://github.com/root-project/root/issues/12334:664,interoperability,convers,conversion-for-lorentz-vector,664,"TTreeReader fails to read `T<Double_32>` as `T<double>`; First reported on the forum at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639 . Minimal reproducer:. ```cpp. #include <Math/Vector4D.h>. #include <ROOT/RDataFrame.hxx>. float TakeMVector(ROOT::Math::PtEtaPhiMVector &) { return 4.2; }. int main() {. ROOT::RDataFrame df(""Tree"", ""example_file.root"");. df.Define(""unused"", ""L""); // the failure disappears if this is commented out, even if ""unused"" is never used. auto dff4 = df.Define(""x"", TakeMVector, {""L""});. dff4.Max<float>(""x"").GetValue();. }. ```. with the input file at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639/3?u=eguiraud . The program errors out with:. ```. The branch L contains data of type ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<Double32_t> >. It cannot be accessed by a TTreeReaderValue<ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<double> >>. ```. (so TTreeReaderValue cannot read a `LorentzVector<PtEtaPhiM4D<Double32_t>>` as a `LorentzVector<PtEtaPhiM4D<double>>`). The following patch by @Axel-Naumann seems to fix the problem:. ```diff. diff --git a/tree/treeplayer/src/TTreeReaderValue.cxx b/tree/treeplayer/src/TTreeReaderValue.cxx. index 2323cffee4..6d938f1b14 100644. --- a/tree/treeplayer/src/TTreeReaderValue.cxx. +++ b/tree/treeplayer/src/TTreeReaderValue.cxx. @@ -554,7 +554,8 @@ void ROOT::Internal::TTreeReaderValueBase::CreateProxy() {. auto branchActualTypeAsClass = dynamic_cast<TClass*>(branchActualType);. auto inheritance = dictAsClass && branchActualTypeAsClass && branchActualTypeAsClass->InheritsFrom(dictAsClass);. - if (fDict != branchActualType && !inheritance) {. + if (fDict != branchActualType && !inheritance. + && dictAsClass->GetTypeInfo() != branchActualTypeAsClass->GetTypeInfo()) {. TDataType *dictdt = dynamic_cast<TDataType*>(fDict);. TDataType *actualdt = dynamic_cast<TDataType*>(branchActualType);. bool complainAboutMismatch = true;. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12334
https://github.com/root-project/root/issues/12334:1543,modifiability,inherit,inheritance,1543,"TTreeReader fails to read `T<Double_32>` as `T<double>`; First reported on the forum at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639 . Minimal reproducer:. ```cpp. #include <Math/Vector4D.h>. #include <ROOT/RDataFrame.hxx>. float TakeMVector(ROOT::Math::PtEtaPhiMVector &) { return 4.2; }. int main() {. ROOT::RDataFrame df(""Tree"", ""example_file.root"");. df.Define(""unused"", ""L""); // the failure disappears if this is commented out, even if ""unused"" is never used. auto dff4 = df.Define(""x"", TakeMVector, {""L""});. dff4.Max<float>(""x"").GetValue();. }. ```. with the input file at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639/3?u=eguiraud . The program errors out with:. ```. The branch L contains data of type ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<Double32_t> >. It cannot be accessed by a TTreeReaderValue<ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<double> >>. ```. (so TTreeReaderValue cannot read a `LorentzVector<PtEtaPhiM4D<Double32_t>>` as a `LorentzVector<PtEtaPhiM4D<double>>`). The following patch by @Axel-Naumann seems to fix the problem:. ```diff. diff --git a/tree/treeplayer/src/TTreeReaderValue.cxx b/tree/treeplayer/src/TTreeReaderValue.cxx. index 2323cffee4..6d938f1b14 100644. --- a/tree/treeplayer/src/TTreeReaderValue.cxx. +++ b/tree/treeplayer/src/TTreeReaderValue.cxx. @@ -554,7 +554,8 @@ void ROOT::Internal::TTreeReaderValueBase::CreateProxy() {. auto branchActualTypeAsClass = dynamic_cast<TClass*>(branchActualType);. auto inheritance = dictAsClass && branchActualTypeAsClass && branchActualTypeAsClass->InheritsFrom(dictAsClass);. - if (fDict != branchActualType && !inheritance) {. + if (fDict != branchActualType && !inheritance. + && dictAsClass->GetTypeInfo() != branchActualTypeAsClass->GetTypeInfo()) {. TDataType *dictdt = dynamic_cast<TDataType*>(fDict);. TDataType *actualdt = dynamic_cast<TDataType*>(branchActualType);. bool complainAboutMismatch = true;. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12334
https://github.com/root-project/root/issues/12334:1624,modifiability,Inherit,InheritsFrom,1624,"TTreeReader fails to read `T<Double_32>` as `T<double>`; First reported on the forum at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639 . Minimal reproducer:. ```cpp. #include <Math/Vector4D.h>. #include <ROOT/RDataFrame.hxx>. float TakeMVector(ROOT::Math::PtEtaPhiMVector &) { return 4.2; }. int main() {. ROOT::RDataFrame df(""Tree"", ""example_file.root"");. df.Define(""unused"", ""L""); // the failure disappears if this is commented out, even if ""unused"" is never used. auto dff4 = df.Define(""x"", TakeMVector, {""L""});. dff4.Max<float>(""x"").GetValue();. }. ```. with the input file at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639/3?u=eguiraud . The program errors out with:. ```. The branch L contains data of type ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<Double32_t> >. It cannot be accessed by a TTreeReaderValue<ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<double> >>. ```. (so TTreeReaderValue cannot read a `LorentzVector<PtEtaPhiM4D<Double32_t>>` as a `LorentzVector<PtEtaPhiM4D<double>>`). The following patch by @Axel-Naumann seems to fix the problem:. ```diff. diff --git a/tree/treeplayer/src/TTreeReaderValue.cxx b/tree/treeplayer/src/TTreeReaderValue.cxx. index 2323cffee4..6d938f1b14 100644. --- a/tree/treeplayer/src/TTreeReaderValue.cxx. +++ b/tree/treeplayer/src/TTreeReaderValue.cxx. @@ -554,7 +554,8 @@ void ROOT::Internal::TTreeReaderValueBase::CreateProxy() {. auto branchActualTypeAsClass = dynamic_cast<TClass*>(branchActualType);. auto inheritance = dictAsClass && branchActualTypeAsClass && branchActualTypeAsClass->InheritsFrom(dictAsClass);. - if (fDict != branchActualType && !inheritance) {. + if (fDict != branchActualType && !inheritance. + && dictAsClass->GetTypeInfo() != branchActualTypeAsClass->GetTypeInfo()) {. TDataType *dictdt = dynamic_cast<TDataType*>(fDict);. TDataType *actualdt = dynamic_cast<TDataType*>(branchActualType);. bool complainAboutMismatch = true;. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12334
https://github.com/root-project/root/issues/12334:1688,modifiability,inherit,inheritance,1688,"TTreeReader fails to read `T<Double_32>` as `T<double>`; First reported on the forum at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639 . Minimal reproducer:. ```cpp. #include <Math/Vector4D.h>. #include <ROOT/RDataFrame.hxx>. float TakeMVector(ROOT::Math::PtEtaPhiMVector &) { return 4.2; }. int main() {. ROOT::RDataFrame df(""Tree"", ""example_file.root"");. df.Define(""unused"", ""L""); // the failure disappears if this is commented out, even if ""unused"" is never used. auto dff4 = df.Define(""x"", TakeMVector, {""L""});. dff4.Max<float>(""x"").GetValue();. }. ```. with the input file at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639/3?u=eguiraud . The program errors out with:. ```. The branch L contains data of type ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<Double32_t> >. It cannot be accessed by a TTreeReaderValue<ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<double> >>. ```. (so TTreeReaderValue cannot read a `LorentzVector<PtEtaPhiM4D<Double32_t>>` as a `LorentzVector<PtEtaPhiM4D<double>>`). The following patch by @Axel-Naumann seems to fix the problem:. ```diff. diff --git a/tree/treeplayer/src/TTreeReaderValue.cxx b/tree/treeplayer/src/TTreeReaderValue.cxx. index 2323cffee4..6d938f1b14 100644. --- a/tree/treeplayer/src/TTreeReaderValue.cxx. +++ b/tree/treeplayer/src/TTreeReaderValue.cxx. @@ -554,7 +554,8 @@ void ROOT::Internal::TTreeReaderValueBase::CreateProxy() {. auto branchActualTypeAsClass = dynamic_cast<TClass*>(branchActualType);. auto inheritance = dictAsClass && branchActualTypeAsClass && branchActualTypeAsClass->InheritsFrom(dictAsClass);. - if (fDict != branchActualType && !inheritance) {. + if (fDict != branchActualType && !inheritance. + && dictAsClass->GetTypeInfo() != branchActualTypeAsClass->GetTypeInfo()) {. TDataType *dictdt = dynamic_cast<TDataType*>(fDict);. TDataType *actualdt = dynamic_cast<TDataType*>(branchActualType);. bool complainAboutMismatch = true;. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12334
https://github.com/root-project/root/issues/12334:1740,modifiability,inherit,inheritance,1740,"TTreeReader fails to read `T<Double_32>` as `T<double>`; First reported on the forum at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639 . Minimal reproducer:. ```cpp. #include <Math/Vector4D.h>. #include <ROOT/RDataFrame.hxx>. float TakeMVector(ROOT::Math::PtEtaPhiMVector &) { return 4.2; }. int main() {. ROOT::RDataFrame df(""Tree"", ""example_file.root"");. df.Define(""unused"", ""L""); // the failure disappears if this is commented out, even if ""unused"" is never used. auto dff4 = df.Define(""x"", TakeMVector, {""L""});. dff4.Max<float>(""x"").GetValue();. }. ```. with the input file at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639/3?u=eguiraud . The program errors out with:. ```. The branch L contains data of type ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<Double32_t> >. It cannot be accessed by a TTreeReaderValue<ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<double> >>. ```. (so TTreeReaderValue cannot read a `LorentzVector<PtEtaPhiM4D<Double32_t>>` as a `LorentzVector<PtEtaPhiM4D<double>>`). The following patch by @Axel-Naumann seems to fix the problem:. ```diff. diff --git a/tree/treeplayer/src/TTreeReaderValue.cxx b/tree/treeplayer/src/TTreeReaderValue.cxx. index 2323cffee4..6d938f1b14 100644. --- a/tree/treeplayer/src/TTreeReaderValue.cxx. +++ b/tree/treeplayer/src/TTreeReaderValue.cxx. @@ -554,7 +554,8 @@ void ROOT::Internal::TTreeReaderValueBase::CreateProxy() {. auto branchActualTypeAsClass = dynamic_cast<TClass*>(branchActualType);. auto inheritance = dictAsClass && branchActualTypeAsClass && branchActualTypeAsClass->InheritsFrom(dictAsClass);. - if (fDict != branchActualType && !inheritance) {. + if (fDict != branchActualType && !inheritance. + && dictAsClass->GetTypeInfo() != branchActualTypeAsClass->GetTypeInfo()) {. TDataType *dictdt = dynamic_cast<TDataType*>(fDict);. TDataType *actualdt = dynamic_cast<TDataType*>(branchActualType);. bool complainAboutMismatch = true;. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12334
https://github.com/root-project/root/issues/12334:426,performance,failur,failure,426,"TTreeReader fails to read `T<Double_32>` as `T<double>`; First reported on the forum at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639 . Minimal reproducer:. ```cpp. #include <Math/Vector4D.h>. #include <ROOT/RDataFrame.hxx>. float TakeMVector(ROOT::Math::PtEtaPhiMVector &) { return 4.2; }. int main() {. ROOT::RDataFrame df(""Tree"", ""example_file.root"");. df.Define(""unused"", ""L""); // the failure disappears if this is commented out, even if ""unused"" is never used. auto dff4 = df.Define(""x"", TakeMVector, {""L""});. dff4.Max<float>(""x"").GetValue();. }. ```. with the input file at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639/3?u=eguiraud . The program errors out with:. ```. The branch L contains data of type ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<Double32_t> >. It cannot be accessed by a TTreeReaderValue<ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<double> >>. ```. (so TTreeReaderValue cannot read a `LorentzVector<PtEtaPhiM4D<Double32_t>>` as a `LorentzVector<PtEtaPhiM4D<double>>`). The following patch by @Axel-Naumann seems to fix the problem:. ```diff. diff --git a/tree/treeplayer/src/TTreeReaderValue.cxx b/tree/treeplayer/src/TTreeReaderValue.cxx. index 2323cffee4..6d938f1b14 100644. --- a/tree/treeplayer/src/TTreeReaderValue.cxx. +++ b/tree/treeplayer/src/TTreeReaderValue.cxx. @@ -554,7 +554,8 @@ void ROOT::Internal::TTreeReaderValueBase::CreateProxy() {. auto branchActualTypeAsClass = dynamic_cast<TClass*>(branchActualType);. auto inheritance = dictAsClass && branchActualTypeAsClass && branchActualTypeAsClass->InheritsFrom(dictAsClass);. - if (fDict != branchActualType && !inheritance) {. + if (fDict != branchActualType && !inheritance. + && dictAsClass->GetTypeInfo() != branchActualTypeAsClass->GetTypeInfo()) {. TDataType *dictdt = dynamic_cast<TDataType*>(fDict);. TDataType *actualdt = dynamic_cast<TDataType*>(branchActualType);. bool complainAboutMismatch = true;. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12334
https://github.com/root-project/root/issues/12334:727,performance,error,errors,727,"TTreeReader fails to read `T<Double_32>` as `T<double>`; First reported on the forum at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639 . Minimal reproducer:. ```cpp. #include <Math/Vector4D.h>. #include <ROOT/RDataFrame.hxx>. float TakeMVector(ROOT::Math::PtEtaPhiMVector &) { return 4.2; }. int main() {. ROOT::RDataFrame df(""Tree"", ""example_file.root"");. df.Define(""unused"", ""L""); // the failure disappears if this is commented out, even if ""unused"" is never used. auto dff4 = df.Define(""x"", TakeMVector, {""L""});. dff4.Max<float>(""x"").GetValue();. }. ```. with the input file at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639/3?u=eguiraud . The program errors out with:. ```. The branch L contains data of type ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<Double32_t> >. It cannot be accessed by a TTreeReaderValue<ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<double> >>. ```. (so TTreeReaderValue cannot read a `LorentzVector<PtEtaPhiM4D<Double32_t>>` as a `LorentzVector<PtEtaPhiM4D<double>>`). The following patch by @Axel-Naumann seems to fix the problem:. ```diff. diff --git a/tree/treeplayer/src/TTreeReaderValue.cxx b/tree/treeplayer/src/TTreeReaderValue.cxx. index 2323cffee4..6d938f1b14 100644. --- a/tree/treeplayer/src/TTreeReaderValue.cxx. +++ b/tree/treeplayer/src/TTreeReaderValue.cxx. @@ -554,7 +554,8 @@ void ROOT::Internal::TTreeReaderValueBase::CreateProxy() {. auto branchActualTypeAsClass = dynamic_cast<TClass*>(branchActualType);. auto inheritance = dictAsClass && branchActualTypeAsClass && branchActualTypeAsClass->InheritsFrom(dictAsClass);. - if (fDict != branchActualType && !inheritance) {. + if (fDict != branchActualType && !inheritance. + && dictAsClass->GetTypeInfo() != branchActualTypeAsClass->GetTypeInfo()) {. TDataType *dictdt = dynamic_cast<TDataType*>(fDict);. TDataType *actualdt = dynamic_cast<TDataType*>(branchActualType);. bool complainAboutMismatch = true;. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12334
https://github.com/root-project/root/issues/12334:12,reliability,fail,fails,12,"TTreeReader fails to read `T<Double_32>` as `T<double>`; First reported on the forum at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639 . Minimal reproducer:. ```cpp. #include <Math/Vector4D.h>. #include <ROOT/RDataFrame.hxx>. float TakeMVector(ROOT::Math::PtEtaPhiMVector &) { return 4.2; }. int main() {. ROOT::RDataFrame df(""Tree"", ""example_file.root"");. df.Define(""unused"", ""L""); // the failure disappears if this is commented out, even if ""unused"" is never used. auto dff4 = df.Define(""x"", TakeMVector, {""L""});. dff4.Max<float>(""x"").GetValue();. }. ```. with the input file at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639/3?u=eguiraud . The program errors out with:. ```. The branch L contains data of type ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<Double32_t> >. It cannot be accessed by a TTreeReaderValue<ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<double> >>. ```. (so TTreeReaderValue cannot read a `LorentzVector<PtEtaPhiM4D<Double32_t>>` as a `LorentzVector<PtEtaPhiM4D<double>>`). The following patch by @Axel-Naumann seems to fix the problem:. ```diff. diff --git a/tree/treeplayer/src/TTreeReaderValue.cxx b/tree/treeplayer/src/TTreeReaderValue.cxx. index 2323cffee4..6d938f1b14 100644. --- a/tree/treeplayer/src/TTreeReaderValue.cxx. +++ b/tree/treeplayer/src/TTreeReaderValue.cxx. @@ -554,7 +554,8 @@ void ROOT::Internal::TTreeReaderValueBase::CreateProxy() {. auto branchActualTypeAsClass = dynamic_cast<TClass*>(branchActualType);. auto inheritance = dictAsClass && branchActualTypeAsClass && branchActualTypeAsClass->InheritsFrom(dictAsClass);. - if (fDict != branchActualType && !inheritance) {. + if (fDict != branchActualType && !inheritance. + && dictAsClass->GetTypeInfo() != branchActualTypeAsClass->GetTypeInfo()) {. TDataType *dictdt = dynamic_cast<TDataType*>(fDict);. TDataType *actualdt = dynamic_cast<TDataType*>(branchActualType);. bool complainAboutMismatch = true;. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12334
https://github.com/root-project/root/issues/12334:426,reliability,fail,failure,426,"TTreeReader fails to read `T<Double_32>` as `T<double>`; First reported on the forum at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639 . Minimal reproducer:. ```cpp. #include <Math/Vector4D.h>. #include <ROOT/RDataFrame.hxx>. float TakeMVector(ROOT::Math::PtEtaPhiMVector &) { return 4.2; }. int main() {. ROOT::RDataFrame df(""Tree"", ""example_file.root"");. df.Define(""unused"", ""L""); // the failure disappears if this is commented out, even if ""unused"" is never used. auto dff4 = df.Define(""x"", TakeMVector, {""L""});. dff4.Max<float>(""x"").GetValue();. }. ```. with the input file at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639/3?u=eguiraud . The program errors out with:. ```. The branch L contains data of type ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<Double32_t> >. It cannot be accessed by a TTreeReaderValue<ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<double> >>. ```. (so TTreeReaderValue cannot read a `LorentzVector<PtEtaPhiM4D<Double32_t>>` as a `LorentzVector<PtEtaPhiM4D<double>>`). The following patch by @Axel-Naumann seems to fix the problem:. ```diff. diff --git a/tree/treeplayer/src/TTreeReaderValue.cxx b/tree/treeplayer/src/TTreeReaderValue.cxx. index 2323cffee4..6d938f1b14 100644. --- a/tree/treeplayer/src/TTreeReaderValue.cxx. +++ b/tree/treeplayer/src/TTreeReaderValue.cxx. @@ -554,7 +554,8 @@ void ROOT::Internal::TTreeReaderValueBase::CreateProxy() {. auto branchActualTypeAsClass = dynamic_cast<TClass*>(branchActualType);. auto inheritance = dictAsClass && branchActualTypeAsClass && branchActualTypeAsClass->InheritsFrom(dictAsClass);. - if (fDict != branchActualType && !inheritance) {. + if (fDict != branchActualType && !inheritance. + && dictAsClass->GetTypeInfo() != branchActualTypeAsClass->GetTypeInfo()) {. TDataType *dictdt = dynamic_cast<TDataType*>(fDict);. TDataType *actualdt = dynamic_cast<TDataType*>(branchActualType);. bool complainAboutMismatch = true;. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12334
https://github.com/root-project/root/issues/12334:603,safety,input,input,603,"TTreeReader fails to read `T<Double_32>` as `T<double>`; First reported on the forum at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639 . Minimal reproducer:. ```cpp. #include <Math/Vector4D.h>. #include <ROOT/RDataFrame.hxx>. float TakeMVector(ROOT::Math::PtEtaPhiMVector &) { return 4.2; }. int main() {. ROOT::RDataFrame df(""Tree"", ""example_file.root"");. df.Define(""unused"", ""L""); // the failure disappears if this is commented out, even if ""unused"" is never used. auto dff4 = df.Define(""x"", TakeMVector, {""L""});. dff4.Max<float>(""x"").GetValue();. }. ```. with the input file at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639/3?u=eguiraud . The program errors out with:. ```. The branch L contains data of type ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<Double32_t> >. It cannot be accessed by a TTreeReaderValue<ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<double> >>. ```. (so TTreeReaderValue cannot read a `LorentzVector<PtEtaPhiM4D<Double32_t>>` as a `LorentzVector<PtEtaPhiM4D<double>>`). The following patch by @Axel-Naumann seems to fix the problem:. ```diff. diff --git a/tree/treeplayer/src/TTreeReaderValue.cxx b/tree/treeplayer/src/TTreeReaderValue.cxx. index 2323cffee4..6d938f1b14 100644. --- a/tree/treeplayer/src/TTreeReaderValue.cxx. +++ b/tree/treeplayer/src/TTreeReaderValue.cxx. @@ -554,7 +554,8 @@ void ROOT::Internal::TTreeReaderValueBase::CreateProxy() {. auto branchActualTypeAsClass = dynamic_cast<TClass*>(branchActualType);. auto inheritance = dictAsClass && branchActualTypeAsClass && branchActualTypeAsClass->InheritsFrom(dictAsClass);. - if (fDict != branchActualType && !inheritance) {. + if (fDict != branchActualType && !inheritance. + && dictAsClass->GetTypeInfo() != branchActualTypeAsClass->GetTypeInfo()) {. TDataType *dictdt = dynamic_cast<TDataType*>(fDict);. TDataType *actualdt = dynamic_cast<TDataType*>(branchActualType);. bool complainAboutMismatch = true;. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12334
https://github.com/root-project/root/issues/12334:727,safety,error,errors,727,"TTreeReader fails to read `T<Double_32>` as `T<double>`; First reported on the forum at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639 . Minimal reproducer:. ```cpp. #include <Math/Vector4D.h>. #include <ROOT/RDataFrame.hxx>. float TakeMVector(ROOT::Math::PtEtaPhiMVector &) { return 4.2; }. int main() {. ROOT::RDataFrame df(""Tree"", ""example_file.root"");. df.Define(""unused"", ""L""); // the failure disappears if this is commented out, even if ""unused"" is never used. auto dff4 = df.Define(""x"", TakeMVector, {""L""});. dff4.Max<float>(""x"").GetValue();. }. ```. with the input file at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639/3?u=eguiraud . The program errors out with:. ```. The branch L contains data of type ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<Double32_t> >. It cannot be accessed by a TTreeReaderValue<ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<double> >>. ```. (so TTreeReaderValue cannot read a `LorentzVector<PtEtaPhiM4D<Double32_t>>` as a `LorentzVector<PtEtaPhiM4D<double>>`). The following patch by @Axel-Naumann seems to fix the problem:. ```diff. diff --git a/tree/treeplayer/src/TTreeReaderValue.cxx b/tree/treeplayer/src/TTreeReaderValue.cxx. index 2323cffee4..6d938f1b14 100644. --- a/tree/treeplayer/src/TTreeReaderValue.cxx. +++ b/tree/treeplayer/src/TTreeReaderValue.cxx. @@ -554,7 +554,8 @@ void ROOT::Internal::TTreeReaderValueBase::CreateProxy() {. auto branchActualTypeAsClass = dynamic_cast<TClass*>(branchActualType);. auto inheritance = dictAsClass && branchActualTypeAsClass && branchActualTypeAsClass->InheritsFrom(dictAsClass);. - if (fDict != branchActualType && !inheritance) {. + if (fDict != branchActualType && !inheritance. + && dictAsClass->GetTypeInfo() != branchActualTypeAsClass->GetTypeInfo()) {. TDataType *dictdt = dynamic_cast<TDataType*>(fDict);. TDataType *actualdt = dynamic_cast<TDataType*>(branchActualType);. bool complainAboutMismatch = true;. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12334
https://github.com/root-project/root/issues/12334:1095,safety,patch,patch,1095,"TTreeReader fails to read `T<Double_32>` as `T<double>`; First reported on the forum at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639 . Minimal reproducer:. ```cpp. #include <Math/Vector4D.h>. #include <ROOT/RDataFrame.hxx>. float TakeMVector(ROOT::Math::PtEtaPhiMVector &) { return 4.2; }. int main() {. ROOT::RDataFrame df(""Tree"", ""example_file.root"");. df.Define(""unused"", ""L""); // the failure disappears if this is commented out, even if ""unused"" is never used. auto dff4 = df.Define(""x"", TakeMVector, {""L""});. dff4.Max<float>(""x"").GetValue();. }. ```. with the input file at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639/3?u=eguiraud . The program errors out with:. ```. The branch L contains data of type ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<Double32_t> >. It cannot be accessed by a TTreeReaderValue<ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<double> >>. ```. (so TTreeReaderValue cannot read a `LorentzVector<PtEtaPhiM4D<Double32_t>>` as a `LorentzVector<PtEtaPhiM4D<double>>`). The following patch by @Axel-Naumann seems to fix the problem:. ```diff. diff --git a/tree/treeplayer/src/TTreeReaderValue.cxx b/tree/treeplayer/src/TTreeReaderValue.cxx. index 2323cffee4..6d938f1b14 100644. --- a/tree/treeplayer/src/TTreeReaderValue.cxx. +++ b/tree/treeplayer/src/TTreeReaderValue.cxx. @@ -554,7 +554,8 @@ void ROOT::Internal::TTreeReaderValueBase::CreateProxy() {. auto branchActualTypeAsClass = dynamic_cast<TClass*>(branchActualType);. auto inheritance = dictAsClass && branchActualTypeAsClass && branchActualTypeAsClass->InheritsFrom(dictAsClass);. - if (fDict != branchActualType && !inheritance) {. + if (fDict != branchActualType && !inheritance. + && dictAsClass->GetTypeInfo() != branchActualTypeAsClass->GetTypeInfo()) {. TDataType *dictdt = dynamic_cast<TDataType*>(fDict);. TDataType *actualdt = dynamic_cast<TDataType*>(branchActualType);. bool complainAboutMismatch = true;. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12334
https://github.com/root-project/root/issues/12334:1957,safety,compl,complainAboutMismatch,1957,"TTreeReader fails to read `T<Double_32>` as `T<double>`; First reported on the forum at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639 . Minimal reproducer:. ```cpp. #include <Math/Vector4D.h>. #include <ROOT/RDataFrame.hxx>. float TakeMVector(ROOT::Math::PtEtaPhiMVector &) { return 4.2; }. int main() {. ROOT::RDataFrame df(""Tree"", ""example_file.root"");. df.Define(""unused"", ""L""); // the failure disappears if this is commented out, even if ""unused"" is never used. auto dff4 = df.Define(""x"", TakeMVector, {""L""});. dff4.Max<float>(""x"").GetValue();. }. ```. with the input file at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639/3?u=eguiraud . The program errors out with:. ```. The branch L contains data of type ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<Double32_t> >. It cannot be accessed by a TTreeReaderValue<ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<double> >>. ```. (so TTreeReaderValue cannot read a `LorentzVector<PtEtaPhiM4D<Double32_t>>` as a `LorentzVector<PtEtaPhiM4D<double>>`). The following patch by @Axel-Naumann seems to fix the problem:. ```diff. diff --git a/tree/treeplayer/src/TTreeReaderValue.cxx b/tree/treeplayer/src/TTreeReaderValue.cxx. index 2323cffee4..6d938f1b14 100644. --- a/tree/treeplayer/src/TTreeReaderValue.cxx. +++ b/tree/treeplayer/src/TTreeReaderValue.cxx. @@ -554,7 +554,8 @@ void ROOT::Internal::TTreeReaderValueBase::CreateProxy() {. auto branchActualTypeAsClass = dynamic_cast<TClass*>(branchActualType);. auto inheritance = dictAsClass && branchActualTypeAsClass && branchActualTypeAsClass->InheritsFrom(dictAsClass);. - if (fDict != branchActualType && !inheritance) {. + if (fDict != branchActualType && !inheritance. + && dictAsClass->GetTypeInfo() != branchActualTypeAsClass->GetTypeInfo()) {. TDataType *dictdt = dynamic_cast<TDataType*>(fDict);. TDataType *actualdt = dynamic_cast<TDataType*>(branchActualType);. bool complainAboutMismatch = true;. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12334
https://github.com/root-project/root/issues/12334:863,security,access,accessed,863,"TTreeReader fails to read `T<Double_32>` as `T<double>`; First reported on the forum at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639 . Minimal reproducer:. ```cpp. #include <Math/Vector4D.h>. #include <ROOT/RDataFrame.hxx>. float TakeMVector(ROOT::Math::PtEtaPhiMVector &) { return 4.2; }. int main() {. ROOT::RDataFrame df(""Tree"", ""example_file.root"");. df.Define(""unused"", ""L""); // the failure disappears if this is commented out, even if ""unused"" is never used. auto dff4 = df.Define(""x"", TakeMVector, {""L""});. dff4.Max<float>(""x"").GetValue();. }. ```. with the input file at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639/3?u=eguiraud . The program errors out with:. ```. The branch L contains data of type ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<Double32_t> >. It cannot be accessed by a TTreeReaderValue<ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<double> >>. ```. (so TTreeReaderValue cannot read a `LorentzVector<PtEtaPhiM4D<Double32_t>>` as a `LorentzVector<PtEtaPhiM4D<double>>`). The following patch by @Axel-Naumann seems to fix the problem:. ```diff. diff --git a/tree/treeplayer/src/TTreeReaderValue.cxx b/tree/treeplayer/src/TTreeReaderValue.cxx. index 2323cffee4..6d938f1b14 100644. --- a/tree/treeplayer/src/TTreeReaderValue.cxx. +++ b/tree/treeplayer/src/TTreeReaderValue.cxx. @@ -554,7 +554,8 @@ void ROOT::Internal::TTreeReaderValueBase::CreateProxy() {. auto branchActualTypeAsClass = dynamic_cast<TClass*>(branchActualType);. auto inheritance = dictAsClass && branchActualTypeAsClass && branchActualTypeAsClass->InheritsFrom(dictAsClass);. - if (fDict != branchActualType && !inheritance) {. + if (fDict != branchActualType && !inheritance. + && dictAsClass->GetTypeInfo() != branchActualTypeAsClass->GetTypeInfo()) {. TDataType *dictdt = dynamic_cast<TDataType*>(fDict);. TDataType *actualdt = dynamic_cast<TDataType*>(branchActualType);. bool complainAboutMismatch = true;. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12334
https://github.com/root-project/root/issues/12334:1095,security,patch,patch,1095,"TTreeReader fails to read `T<Double_32>` as `T<double>`; First reported on the forum at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639 . Minimal reproducer:. ```cpp. #include <Math/Vector4D.h>. #include <ROOT/RDataFrame.hxx>. float TakeMVector(ROOT::Math::PtEtaPhiMVector &) { return 4.2; }. int main() {. ROOT::RDataFrame df(""Tree"", ""example_file.root"");. df.Define(""unused"", ""L""); // the failure disappears if this is commented out, even if ""unused"" is never used. auto dff4 = df.Define(""x"", TakeMVector, {""L""});. dff4.Max<float>(""x"").GetValue();. }. ```. with the input file at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639/3?u=eguiraud . The program errors out with:. ```. The branch L contains data of type ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<Double32_t> >. It cannot be accessed by a TTreeReaderValue<ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<double> >>. ```. (so TTreeReaderValue cannot read a `LorentzVector<PtEtaPhiM4D<Double32_t>>` as a `LorentzVector<PtEtaPhiM4D<double>>`). The following patch by @Axel-Naumann seems to fix the problem:. ```diff. diff --git a/tree/treeplayer/src/TTreeReaderValue.cxx b/tree/treeplayer/src/TTreeReaderValue.cxx. index 2323cffee4..6d938f1b14 100644. --- a/tree/treeplayer/src/TTreeReaderValue.cxx. +++ b/tree/treeplayer/src/TTreeReaderValue.cxx. @@ -554,7 +554,8 @@ void ROOT::Internal::TTreeReaderValueBase::CreateProxy() {. auto branchActualTypeAsClass = dynamic_cast<TClass*>(branchActualType);. auto inheritance = dictAsClass && branchActualTypeAsClass && branchActualTypeAsClass->InheritsFrom(dictAsClass);. - if (fDict != branchActualType && !inheritance) {. + if (fDict != branchActualType && !inheritance. + && dictAsClass->GetTypeInfo() != branchActualTypeAsClass->GetTypeInfo()) {. TDataType *dictdt = dynamic_cast<TDataType*>(fDict);. TDataType *actualdt = dynamic_cast<TDataType*>(branchActualType);. bool complainAboutMismatch = true;. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12334
https://github.com/root-project/root/issues/12334:1957,security,compl,complainAboutMismatch,1957,"TTreeReader fails to read `T<Double_32>` as `T<double>`; First reported on the forum at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639 . Minimal reproducer:. ```cpp. #include <Math/Vector4D.h>. #include <ROOT/RDataFrame.hxx>. float TakeMVector(ROOT::Math::PtEtaPhiMVector &) { return 4.2; }. int main() {. ROOT::RDataFrame df(""Tree"", ""example_file.root"");. df.Define(""unused"", ""L""); // the failure disappears if this is commented out, even if ""unused"" is never used. auto dff4 = df.Define(""x"", TakeMVector, {""L""});. dff4.Max<float>(""x"").GetValue();. }. ```. with the input file at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639/3?u=eguiraud . The program errors out with:. ```. The branch L contains data of type ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<Double32_t> >. It cannot be accessed by a TTreeReaderValue<ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<double> >>. ```. (so TTreeReaderValue cannot read a `LorentzVector<PtEtaPhiM4D<Double32_t>>` as a `LorentzVector<PtEtaPhiM4D<double>>`). The following patch by @Axel-Naumann seems to fix the problem:. ```diff. diff --git a/tree/treeplayer/src/TTreeReaderValue.cxx b/tree/treeplayer/src/TTreeReaderValue.cxx. index 2323cffee4..6d938f1b14 100644. --- a/tree/treeplayer/src/TTreeReaderValue.cxx. +++ b/tree/treeplayer/src/TTreeReaderValue.cxx. @@ -554,7 +554,8 @@ void ROOT::Internal::TTreeReaderValueBase::CreateProxy() {. auto branchActualTypeAsClass = dynamic_cast<TClass*>(branchActualType);. auto inheritance = dictAsClass && branchActualTypeAsClass && branchActualTypeAsClass->InheritsFrom(dictAsClass);. - if (fDict != branchActualType && !inheritance) {. + if (fDict != branchActualType && !inheritance. + && dictAsClass->GetTypeInfo() != branchActualTypeAsClass->GetTypeInfo()) {. TDataType *dictdt = dynamic_cast<TDataType*>(fDict);. TDataType *actualdt = dynamic_cast<TDataType*>(branchActualType);. bool complainAboutMismatch = true;. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12334
https://github.com/root-project/root/issues/12334:173,usability,Minim,Minimal,173,"TTreeReader fails to read `T<Double_32>` as `T<double>`; First reported on the forum at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639 . Minimal reproducer:. ```cpp. #include <Math/Vector4D.h>. #include <ROOT/RDataFrame.hxx>. float TakeMVector(ROOT::Math::PtEtaPhiMVector &) { return 4.2; }. int main() {. ROOT::RDataFrame df(""Tree"", ""example_file.root"");. df.Define(""unused"", ""L""); // the failure disappears if this is commented out, even if ""unused"" is never used. auto dff4 = df.Define(""x"", TakeMVector, {""L""});. dff4.Max<float>(""x"").GetValue();. }. ```. with the input file at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639/3?u=eguiraud . The program errors out with:. ```. The branch L contains data of type ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<Double32_t> >. It cannot be accessed by a TTreeReaderValue<ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<double> >>. ```. (so TTreeReaderValue cannot read a `LorentzVector<PtEtaPhiM4D<Double32_t>>` as a `LorentzVector<PtEtaPhiM4D<double>>`). The following patch by @Axel-Naumann seems to fix the problem:. ```diff. diff --git a/tree/treeplayer/src/TTreeReaderValue.cxx b/tree/treeplayer/src/TTreeReaderValue.cxx. index 2323cffee4..6d938f1b14 100644. --- a/tree/treeplayer/src/TTreeReaderValue.cxx. +++ b/tree/treeplayer/src/TTreeReaderValue.cxx. @@ -554,7 +554,8 @@ void ROOT::Internal::TTreeReaderValueBase::CreateProxy() {. auto branchActualTypeAsClass = dynamic_cast<TClass*>(branchActualType);. auto inheritance = dictAsClass && branchActualTypeAsClass && branchActualTypeAsClass->InheritsFrom(dictAsClass);. - if (fDict != branchActualType && !inheritance) {. + if (fDict != branchActualType && !inheritance. + && dictAsClass->GetTypeInfo() != branchActualTypeAsClass->GetTypeInfo()) {. TDataType *dictdt = dynamic_cast<TDataType*>(fDict);. TDataType *actualdt = dynamic_cast<TDataType*>(branchActualType);. bool complainAboutMismatch = true;. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12334
https://github.com/root-project/root/issues/12334:603,usability,input,input,603,"TTreeReader fails to read `T<Double_32>` as `T<double>`; First reported on the forum at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639 . Minimal reproducer:. ```cpp. #include <Math/Vector4D.h>. #include <ROOT/RDataFrame.hxx>. float TakeMVector(ROOT::Math::PtEtaPhiMVector &) { return 4.2; }. int main() {. ROOT::RDataFrame df(""Tree"", ""example_file.root"");. df.Define(""unused"", ""L""); // the failure disappears if this is commented out, even if ""unused"" is never used. auto dff4 = df.Define(""x"", TakeMVector, {""L""});. dff4.Max<float>(""x"").GetValue();. }. ```. with the input file at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639/3?u=eguiraud . The program errors out with:. ```. The branch L contains data of type ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<Double32_t> >. It cannot be accessed by a TTreeReaderValue<ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<double> >>. ```. (so TTreeReaderValue cannot read a `LorentzVector<PtEtaPhiM4D<Double32_t>>` as a `LorentzVector<PtEtaPhiM4D<double>>`). The following patch by @Axel-Naumann seems to fix the problem:. ```diff. diff --git a/tree/treeplayer/src/TTreeReaderValue.cxx b/tree/treeplayer/src/TTreeReaderValue.cxx. index 2323cffee4..6d938f1b14 100644. --- a/tree/treeplayer/src/TTreeReaderValue.cxx. +++ b/tree/treeplayer/src/TTreeReaderValue.cxx. @@ -554,7 +554,8 @@ void ROOT::Internal::TTreeReaderValueBase::CreateProxy() {. auto branchActualTypeAsClass = dynamic_cast<TClass*>(branchActualType);. auto inheritance = dictAsClass && branchActualTypeAsClass && branchActualTypeAsClass->InheritsFrom(dictAsClass);. - if (fDict != branchActualType && !inheritance) {. + if (fDict != branchActualType && !inheritance. + && dictAsClass->GetTypeInfo() != branchActualTypeAsClass->GetTypeInfo()) {. TDataType *dictdt = dynamic_cast<TDataType*>(fDict);. TDataType *actualdt = dynamic_cast<TDataType*>(branchActualType);. bool complainAboutMismatch = true;. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12334
https://github.com/root-project/root/issues/12334:727,usability,error,errors,727,"TTreeReader fails to read `T<Double_32>` as `T<double>`; First reported on the forum at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639 . Minimal reproducer:. ```cpp. #include <Math/Vector4D.h>. #include <ROOT/RDataFrame.hxx>. float TakeMVector(ROOT::Math::PtEtaPhiMVector &) { return 4.2; }. int main() {. ROOT::RDataFrame df(""Tree"", ""example_file.root"");. df.Define(""unused"", ""L""); // the failure disappears if this is commented out, even if ""unused"" is never used. auto dff4 = df.Define(""x"", TakeMVector, {""L""});. dff4.Max<float>(""x"").GetValue();. }. ```. with the input file at https://root-forum.cern.ch/t/problem-with-type-conversion-for-lorentz-vector/53639/3?u=eguiraud . The program errors out with:. ```. The branch L contains data of type ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<Double32_t> >. It cannot be accessed by a TTreeReaderValue<ROOT::Math::LorentzVector<ROOT::Math::PtEtaPhiM4D<double> >>. ```. (so TTreeReaderValue cannot read a `LorentzVector<PtEtaPhiM4D<Double32_t>>` as a `LorentzVector<PtEtaPhiM4D<double>>`). The following patch by @Axel-Naumann seems to fix the problem:. ```diff. diff --git a/tree/treeplayer/src/TTreeReaderValue.cxx b/tree/treeplayer/src/TTreeReaderValue.cxx. index 2323cffee4..6d938f1b14 100644. --- a/tree/treeplayer/src/TTreeReaderValue.cxx. +++ b/tree/treeplayer/src/TTreeReaderValue.cxx. @@ -554,7 +554,8 @@ void ROOT::Internal::TTreeReaderValueBase::CreateProxy() {. auto branchActualTypeAsClass = dynamic_cast<TClass*>(branchActualType);. auto inheritance = dictAsClass && branchActualTypeAsClass && branchActualTypeAsClass->InheritsFrom(dictAsClass);. - if (fDict != branchActualType && !inheritance) {. + if (fDict != branchActualType && !inheritance. + && dictAsClass->GetTypeInfo() != branchActualTypeAsClass->GetTypeInfo()) {. TDataType *dictdt = dynamic_cast<TDataType*>(fDict);. TDataType *actualdt = dynamic_cast<TDataType*>(branchActualType);. bool complainAboutMismatch = true;. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12334
https://github.com/root-project/root/issues/12338:39,availability,error,error,39,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:238,availability,error,error,238,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:437,availability,error,error,437,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:1990,availability,error,error,1990,"* x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Warning in <Minuit2>: MnHesse Analytical calculator 	[ -0.0001327679869]	 numerical 	[ -0.0001327679869]	 g2 	[ 4999.999999]	. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273383488941203e-12. Edm = 1.76273383508741455e-12. Nfcn = 17",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:3120,availability,error,error,3120,"int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Warning in <Minuit2>: MnHesse Analytical calculator 	[ -0.0001327679869]	 numerical 	[ -0.0001327679869]	 g2 	[ 4999.999999]	. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273383488941203e-12. Edm = 1.76273383508741455e-12. Nfcn = 17. x	 = -1.32768e-06	 +/- 0.999933	(limited). ```. Only swapping the calls to `SetFunction()` and `SetErrorDef()` will make the error for the second case with the `MyGradFunc` correctly respect the error level.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:3190,availability,error,error,3190,"int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Warning in <Minuit2>: MnHesse Analytical calculator 	[ -0.0001327679869]	 numerical 	[ -0.0001327679869]	 g2 	[ 4999.999999]	. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273383488941203e-12. Edm = 1.76273383508741455e-12. Nfcn = 17. x	 = -1.32768e-06	 +/- 0.999933	(limited). ```. Only swapping the calls to `SetFunction()` and `SetErrorDef()` will make the error for the second case with the `MyGradFunc` correctly respect the error level.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:835,deployability,configurat,configuration,835,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:835,integrability,configur,configuration,835,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:1066,integrability,pub,public,1066,"unction in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warn",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:1106,integrability,pub,public,1106,"nt; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two l",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:1346,integrability,pub,public,1346,"etely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(My",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:1387,integrability,pub,public,1387,"ixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:180,modifiability,inherit,inheriting,180,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:835,modifiability,configur,configuration,835,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:39,performance,error,error,39,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:238,performance,error,error,238,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:437,performance,error,error,437,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:1990,performance,error,error,1990,"* x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Warning in <Minuit2>: MnHesse Analytical calculator 	[ -0.0001327679869]	 numerical 	[ -0.0001327679869]	 g2 	[ 4999.999999]	. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273383488941203e-12. Edm = 1.76273383508741455e-12. Nfcn = 17",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:3120,performance,error,error,3120,"int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Warning in <Minuit2>: MnHesse Analytical calculator 	[ -0.0001327679869]	 numerical 	[ -0.0001327679869]	 g2 	[ 4999.999999]	. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273383488941203e-12. Edm = 1.76273383508741455e-12. Nfcn = 17. x	 = -1.32768e-06	 +/- 0.999933	(limited). ```. Only swapping the calls to `SetFunction()` and `SetErrorDef()` will make the error for the second case with the `MyGradFunc` correctly respect the error level.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:3190,performance,error,error,3190,"int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Warning in <Minuit2>: MnHesse Analytical calculator 	[ -0.0001327679869]	 numerical 	[ -0.0001327679869]	 g2 	[ 4999.999999]	. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273383488941203e-12. Edm = 1.76273383508741455e-12. Nfcn = 17. x	 = -1.32768e-06	 +/- 0.999933	(limited). ```. Only swapping the calls to `SetFunction()` and `SetErrorDef()` will make the error for the second case with the `MyGradFunc` correctly respect the error level.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:1260,reliability,DoE,DoEval,1260,"dered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:1541,reliability,DoE,DoEval,1541," out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:2176,reliability,doe,does,2176,"new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Warning in <Minuit2>: MnHesse Analytical calculator 	[ -0.0001327679869]	 numerical 	[ -0.0001327679869]	 g2 	[ 4999.999999]	. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273383488941203e-12. Edm = 1.76273383508741455e-12. Nfcn = 17. x	 = -1.32768e-06	 +/- 0.999933	(limited). ```. Only swapping the calls to `SetFunction()` and `SetErrorDef()` will make the error for the second case with the `MyGradFunc` correctly ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:39,safety,error,error,39,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:238,safety,error,error,238,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:344,safety,compl,completely,344,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:437,safety,error,error,437,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:1990,safety,error,error,1990,"* x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Warning in <Minuit2>: MnHesse Analytical calculator 	[ -0.0001327679869]	 numerical 	[ -0.0001327679869]	 g2 	[ 4999.999999]	. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273383488941203e-12. Edm = 1.76273383508741455e-12. Nfcn = 17",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:2517,safety,Valid,Valid,2517,"int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Warning in <Minuit2>: MnHesse Analytical calculator 	[ -0.0001327679869]	 numerical 	[ -0.0001327679869]	 g2 	[ 4999.999999]	. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273383488941203e-12. Edm = 1.76273383508741455e-12. Nfcn = 17. x	 = -1.32768e-06	 +/- 0.999933	(limited). ```. Only swapping the calls to `SetFunction()` and `SetErrorDef()` will make the error for the second case with the `MyGradFunc` correctly respect the error level.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:2893,safety,Valid,Valid,2893,"int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Warning in <Minuit2>: MnHesse Analytical calculator 	[ -0.0001327679869]	 numerical 	[ -0.0001327679869]	 g2 	[ 4999.999999]	. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273383488941203e-12. Edm = 1.76273383508741455e-12. Nfcn = 17. x	 = -1.32768e-06	 +/- 0.999933	(limited). ```. Only swapping the calls to `SetFunction()` and `SetErrorDef()` will make the error for the second case with the `MyGradFunc` correctly respect the error level.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:3120,safety,error,error,3120,"int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Warning in <Minuit2>: MnHesse Analytical calculator 	[ -0.0001327679869]	 numerical 	[ -0.0001327679869]	 g2 	[ 4999.999999]	. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273383488941203e-12. Edm = 1.76273383508741455e-12. Nfcn = 17. x	 = -1.32768e-06	 +/- 0.999933	(limited). ```. Only swapping the calls to `SetFunction()` and `SetErrorDef()` will make the error for the second case with the `MyGradFunc` correctly respect the error level.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:3190,safety,error,error,3190,"int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Warning in <Minuit2>: MnHesse Analytical calculator 	[ -0.0001327679869]	 numerical 	[ -0.0001327679869]	 g2 	[ 4999.999999]	. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273383488941203e-12. Edm = 1.76273383508741455e-12. Nfcn = 17. x	 = -1.32768e-06	 +/- 0.999933	(limited). ```. Only swapping the calls to `SetFunction()` and `SetErrorDef()` will make the error for the second case with the `MyGradFunc` correctly respect the error level.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:344,security,compl,completely,344,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:835,security,configur,configuration,835,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:644,testability,understand,understand,644,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:828,testability,simpl,simple,828,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:934,testability,simpl,simple,934,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:20,usability,Minim,Minimizer,20,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:39,usability,error,error,39,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:122,usability,user,user,122,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:165,usability,Minim,Minimizer,165,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:238,usability,error,error,238,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:420,usability,minim,minimizer,420,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:437,usability,error,error,437,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:606,usability,minim,minimizer,606,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:780,usability,minim,minimizer,780,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:828,usability,simpl,simple,828,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:921,usability,minim,minimum,921,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:934,usability,simpl,simple,934,"[math] `ROOT::Math::Minimizer` ignores error level if set after the function in the case of analytical gradient; When the user passes a gradient to the `ROOT::Math::Minimizer` via inheriting from the `ROOT::Math::IMultiGradFunction`, the error level is only considered correctly if `SetFunction()` is **called after** `SetErrorDef()`, which is completely unexpected. This should either be fixed, or if not possible, the minimizer should error out if you try to set the function too early. This bug is the reason why it took me so long to figure out to use the analytical gradient provided by `clad` in the minimizer for RooFit: I just couldn't understand why the uncertainties were wrong and until now thought it was because the gradient was wrong or not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error leve",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:1746,usability,minim,minimize,1746," not handled correctly by the minimizer. But in the end, it was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. War",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:1805,usability,Minim,Minimizer,1805,"was all just this simple configuration problem. This code reproduces the issue with the example of finding the minimum of a simple parabola:. ```C++. double eval(double x) { return x * x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Warning in <Minuit2>: MnHesse Analytical calculator 	[ -0.00013",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:1990,usability,error,error,1990,"* x; }. double evalDerivative(double x) {return 2 * x; }. class MyFunc : public ROOT::Math::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Warning in <Minuit2>: MnHesse Analytical calculator 	[ -0.0001327679869]	 numerical 	[ -0.0001327679869]	 g2 	[ 4999.999999]	. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273383488941203e-12. Edm = 1.76273383508741455e-12. Nfcn = 17",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:2080,usability,user,user,2080,"h::IMultiGenFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Warning in <Minuit2>: MnHesse Analytical calculator 	[ -0.0001327679869]	 numerical 	[ -0.0001327679869]	 g2 	[ 4999.999999]	. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273383488941203e-12. Edm = 1.76273383508741455e-12. Nfcn = 17. x	 = -1.32768e-06	 +/- 0.999933	(limited). ```. Only swapping the calls to `SetFunction",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:2161,usability,minim,minimizer,2161,"de { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Warning in <Minuit2>: MnHesse Analytical calculator 	[ -0.0001327679869]	 numerical 	[ -0.0001327679869]	 g2 	[ 4999.999999]	. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273383488941203e-12. Edm = 1.76273383508741455e-12. Nfcn = 17. x	 = -1.32768e-06	 +/- 0.999933	(limited). ```. Only swapping the calls to `SetFunction()` and `SetErrorDef()` will make the error for the second case with the `MyGradFunc",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:2287,usability,Minim,Minimize,2287,"int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Warning in <Minuit2>: MnHesse Analytical calculator 	[ -0.0001327679869]	 numerical 	[ -0.0001327679869]	 g2 	[ 4999.999999]	. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273383488941203e-12. Edm = 1.76273383508741455e-12. Nfcn = 17. x	 = -1.32768e-06	 +/- 0.999933	(limited). ```. Only swapping the calls to `SetFunction()` and `SetErrorDef()` will make the error for the second case with the `MyGradFunc` correctly respect the error level.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:2338,usability,minim,minimize,2338,"int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Warning in <Minuit2>: MnHesse Analytical calculator 	[ -0.0001327679869]	 numerical 	[ -0.0001327679869]	 g2 	[ 4999.999999]	. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273383488941203e-12. Edm = 1.76273383508741455e-12. Nfcn = 17. x	 = -1.32768e-06	 +/- 0.999933	(limited). ```. Only swapping the calls to `SetFunction()` and `SetErrorDef()` will make the error for the second case with the `MyGradFunc` correctly respect the error level.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:2359,usability,minim,minimize,2359,"int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Warning in <Minuit2>: MnHesse Analytical calculator 	[ -0.0001327679869]	 numerical 	[ -0.0001327679869]	 g2 	[ 4999.999999]	. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273383488941203e-12. Edm = 1.76273383508741455e-12. Nfcn = 17. x	 = -1.32768e-06	 +/- 0.999933	(limited). ```. Only swapping the calls to `SetFunction()` and `SetErrorDef()` will make the error for the second case with the `MyGradFunc` correctly respect the error level.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:2431,usability,Minim,Minimize,2431,"int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Warning in <Minuit2>: MnHesse Analytical calculator 	[ -0.0001327679869]	 numerical 	[ -0.0001327679869]	 g2 	[ 4999.999999]	. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273383488941203e-12. Edm = 1.76273383508741455e-12. Nfcn = 17. x	 = -1.32768e-06	 +/- 0.999933	(limited). ```. Only swapping the calls to `SetFunction()` and `SetErrorDef()` will make the error for the second case with the `MyGradFunc` correctly respect the error level.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:2523,usability,minim,minimum,2523,"int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Warning in <Minuit2>: MnHesse Analytical calculator 	[ -0.0001327679869]	 numerical 	[ -0.0001327679869]	 g2 	[ 4999.999999]	. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273383488941203e-12. Edm = 1.76273383508741455e-12. Nfcn = 17. x	 = -1.32768e-06	 +/- 0.999933	(limited). ```. Only swapping the calls to `SetFunction()` and `SetErrorDef()` will make the error for the second case with the `MyGradFunc` correctly respect the error level.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:2533,usability,statu,status,2533,"int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Warning in <Minuit2>: MnHesse Analytical calculator 	[ -0.0001327679869]	 numerical 	[ -0.0001327679869]	 g2 	[ 4999.999999]	. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273383488941203e-12. Edm = 1.76273383508741455e-12. Nfcn = 17. x	 = -1.32768e-06	 +/- 0.999933	(limited). ```. Only swapping the calls to `SetFunction()` and `SetErrorDef()` will make the error for the second case with the `MyGradFunc` correctly respect the error level.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:2680,usability,Minim,Minimize,2680,"int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Warning in <Minuit2>: MnHesse Analytical calculator 	[ -0.0001327679869]	 numerical 	[ -0.0001327679869]	 g2 	[ 4999.999999]	. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273383488941203e-12. Edm = 1.76273383508741455e-12. Nfcn = 17. x	 = -1.32768e-06	 +/- 0.999933	(limited). ```. Only swapping the calls to `SetFunction()` and `SetErrorDef()` will make the error for the second case with the `MyGradFunc` correctly respect the error level.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:2899,usability,minim,minimum,2899,"int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Warning in <Minuit2>: MnHesse Analytical calculator 	[ -0.0001327679869]	 numerical 	[ -0.0001327679869]	 g2 	[ 4999.999999]	. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273383488941203e-12. Edm = 1.76273383508741455e-12. Nfcn = 17. x	 = -1.32768e-06	 +/- 0.999933	(limited). ```. Only swapping the calls to `SetFunction()` and `SetErrorDef()` will make the error for the second case with the `MyGradFunc` correctly respect the error level.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:2909,usability,statu,status,2909,"int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Warning in <Minuit2>: MnHesse Analytical calculator 	[ -0.0001327679869]	 numerical 	[ -0.0001327679869]	 g2 	[ 4999.999999]	. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273383488941203e-12. Edm = 1.76273383508741455e-12. Nfcn = 17. x	 = -1.32768e-06	 +/- 0.999933	(limited). ```. Only swapping the calls to `SetFunction()` and `SetErrorDef()` will make the error for the second case with the `MyGradFunc` correctly respect the error level.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:3120,usability,error,error,3120,"int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Warning in <Minuit2>: MnHesse Analytical calculator 	[ -0.0001327679869]	 numerical 	[ -0.0001327679869]	 g2 	[ 4999.999999]	. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273383488941203e-12. Edm = 1.76273383508741455e-12. Nfcn = 17. x	 = -1.32768e-06	 +/- 0.999933	(limited). ```. Only swapping the calls to `SetFunction()` and `SetErrorDef()` will make the error for the second case with the `MyGradFunc` correctly respect the error level.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/issues/12338:3190,usability,error,error,3190,"int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. };. class MyGradFunc : public ROOT::Math::IMultiGradFunction {. public:. ROOT::Math::IMultiGenFunction *Clone() const override { return new MyFunc; }. unsigned int NDim() const override { return 1; }. private:. double DoEval(const double *x) const override { return eval(x[0]); }. double DoDerivative(const double *x, unsigned int /*icoord*/) const override { return evalDerivative(x[0]); }. };. template<class Func>. void minimize(Func const& func). {. std::unique_ptr<ROOT::Math::Minimizer> m{ROOT::Math::Factory::CreateMinimizer(""Minuit2"")};. m->SetPrintLevel(1);. // Set initial value, step size, and range. m->SetLimitedVariable(0, ""x"", 10, 1, -50, 50);. // The error level will be ignored in the IMultiGradFunction case without. // any warning to the user! Swapping the next two lines fixes it, but it's. // very dangerous that the minimizer only does the right thing if you call. // things in a secret order! m->SetFunction(func);. m->SetErrorDef(0.5);. m->Minimize();. }. void reproduceMinimizerIssue(). {. minimize(MyFunc{});. minimize(MyGradFunc{});. }. ```. The output is:. ```. Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273540829637293e-12. Edm = 1.76273540831862199e-12. Nfcn = 19. x	 = -1.32768e-06	 +/- 0.707083	(limited). Minuit2Minimizer: Minimize with max-calls 305 convergence for edm < 0.01 strategy 1. Warning in <Minuit2>: MnHesse Analytical calculator 	[ -0.0001327679869]	 numerical 	[ -0.0001327679869]	 g2 	[ 4999.999999]	. Minuit2Minimizer : Valid minimum - status = 0. FVAL = 1.76273383488941203e-12. Edm = 1.76273383508741455e-12. Nfcn = 17. x	 = -1.32768e-06	 +/- 0.999933	(limited). ```. Only swapping the calls to `SetFunction()` and `SetErrorDef()` will make the error for the second case with the `MyGradFunc` correctly respect the error level.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12338
https://github.com/root-project/root/pull/12339:219,availability,Error,ErrorDef,219,[math][minuit] Add missing SetErrorDef for the Minuit2 gradient function; SetErrorDef was not implemented for the FCNGradAdapter used to wrap the user functions in the Minuit interface. This causes that the current set ErrorDef was not used when minimizing but the one set when constructed the function. This fixes issue #12338.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12339
https://github.com/root-project/root/pull/12339:207,energy efficiency,current,current,207,[math][minuit] Add missing SetErrorDef for the Minuit2 gradient function; SetErrorDef was not implemented for the FCNGradAdapter used to wrap the user functions in the Minuit interface. This causes that the current set ErrorDef was not used when minimizing but the one set when constructed the function. This fixes issue #12338.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12339
https://github.com/root-project/root/pull/12339:137,integrability,wrap,wrap,137,[math][minuit] Add missing SetErrorDef for the Minuit2 gradient function; SetErrorDef was not implemented for the FCNGradAdapter used to wrap the user functions in the Minuit interface. This causes that the current set ErrorDef was not used when minimizing but the one set when constructed the function. This fixes issue #12338.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12339
https://github.com/root-project/root/pull/12339:175,integrability,interfac,interface,175,[math][minuit] Add missing SetErrorDef for the Minuit2 gradient function; SetErrorDef was not implemented for the FCNGradAdapter used to wrap the user functions in the Minuit interface. This causes that the current set ErrorDef was not used when minimizing but the one set when constructed the function. This fixes issue #12338.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12339
https://github.com/root-project/root/pull/12339:175,interoperability,interfac,interface,175,[math][minuit] Add missing SetErrorDef for the Minuit2 gradient function; SetErrorDef was not implemented for the FCNGradAdapter used to wrap the user functions in the Minuit interface. This causes that the current set ErrorDef was not used when minimizing but the one set when constructed the function. This fixes issue #12338.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12339
https://github.com/root-project/root/pull/12339:175,modifiability,interfac,interface,175,[math][minuit] Add missing SetErrorDef for the Minuit2 gradient function; SetErrorDef was not implemented for the FCNGradAdapter used to wrap the user functions in the Minuit interface. This causes that the current set ErrorDef was not used when minimizing but the one set when constructed the function. This fixes issue #12338.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12339
https://github.com/root-project/root/pull/12339:219,performance,Error,ErrorDef,219,[math][minuit] Add missing SetErrorDef for the Minuit2 gradient function; SetErrorDef was not implemented for the FCNGradAdapter used to wrap the user functions in the Minuit interface. This causes that the current set ErrorDef was not used when minimizing but the one set when constructed the function. This fixes issue #12338.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12339
https://github.com/root-project/root/pull/12339:219,safety,Error,ErrorDef,219,[math][minuit] Add missing SetErrorDef for the Minuit2 gradient function; SetErrorDef was not implemented for the FCNGradAdapter used to wrap the user functions in the Minuit interface. This causes that the current set ErrorDef was not used when minimizing but the one set when constructed the function. This fixes issue #12338.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12339
https://github.com/root-project/root/pull/12339:146,usability,user,user,146,[math][minuit] Add missing SetErrorDef for the Minuit2 gradient function; SetErrorDef was not implemented for the FCNGradAdapter used to wrap the user functions in the Minuit interface. This causes that the current set ErrorDef was not used when minimizing but the one set when constructed the function. This fixes issue #12338.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12339
https://github.com/root-project/root/pull/12339:219,usability,Error,ErrorDef,219,[math][minuit] Add missing SetErrorDef for the Minuit2 gradient function; SetErrorDef was not implemented for the FCNGradAdapter used to wrap the user functions in the Minuit interface. This causes that the current set ErrorDef was not used when minimizing but the one set when constructed the function. This fixes issue #12338.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12339
https://github.com/root-project/root/pull/12339:246,usability,minim,minimizing,246,[math][minuit] Add missing SetErrorDef for the Minuit2 gradient function; SetErrorDef was not implemented for the FCNGradAdapter used to wrap the user functions in the Minuit interface. This causes that the current set ErrorDef was not used when minimizing but the one set when constructed the function. This fixes issue #12338.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12339
https://github.com/root-project/root/pull/12340:5,deployability,Updat,Update,5,[RF] Update the HS3 HistFactory implementation; # This Pull request:. ## Changes or fixes:. The HistFactory implementation of HS3 is updated to conform with the latest draft of the standardization document. A turnaround of a plain histfactory example in the new style is possible. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12340:133,deployability,updat,updated,133,[RF] Update the HS3 HistFactory implementation; # This Pull request:. ## Changes or fixes:. The HistFactory implementation of HS3 is updated to conform with the latest draft of the standardization document. A turnaround of a plain histfactory example in the new style is possible. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12340:332,deployability,updat,updated,332,[RF] Update the HS3 HistFactory implementation; # This Pull request:. ## Changes or fixes:. The HistFactory implementation of HS3 is updated to conform with the latest draft of the standardization document. A turnaround of a plain histfactory example in the new style is possible. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12340:181,integrability,standardiz,standardization,181,[RF] Update the HS3 HistFactory implementation; # This Pull request:. ## Changes or fixes:. The HistFactory implementation of HS3 is updated to conform with the latest draft of the standardization document. A turnaround of a plain histfactory example in the new style is possible. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12340:181,interoperability,standard,standardization,181,[RF] Update the HS3 HistFactory implementation; # This Pull request:. ## Changes or fixes:. The HistFactory implementation of HS3 is updated to conform with the latest draft of the standardization document. A turnaround of a plain histfactory example in the new style is possible. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12340:5,safety,Updat,Update,5,[RF] Update the HS3 HistFactory implementation; # This Pull request:. ## Changes or fixes:. The HistFactory implementation of HS3 is updated to conform with the latest draft of the standardization document. A turnaround of a plain histfactory example in the new style is possible. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12340:133,safety,updat,updated,133,[RF] Update the HS3 HistFactory implementation; # This Pull request:. ## Changes or fixes:. The HistFactory implementation of HS3 is updated to conform with the latest draft of the standardization document. A turnaround of a plain histfactory example in the new style is possible. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12340:302,safety,test,tested,302,[RF] Update the HS3 HistFactory implementation; # This Pull request:. ## Changes or fixes:. The HistFactory implementation of HS3 is updated to conform with the latest draft of the standardization document. A turnaround of a plain histfactory example in the new style is possible. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12340:332,safety,updat,updated,332,[RF] Update the HS3 HistFactory implementation; # This Pull request:. ## Changes or fixes:. The HistFactory implementation of HS3 is updated to conform with the latest draft of the standardization document. A turnaround of a plain histfactory example in the new style is possible. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12340:5,security,Updat,Update,5,[RF] Update the HS3 HistFactory implementation; # This Pull request:. ## Changes or fixes:. The HistFactory implementation of HS3 is updated to conform with the latest draft of the standardization document. A turnaround of a plain histfactory example in the new style is possible. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12340:133,security,updat,updated,133,[RF] Update the HS3 HistFactory implementation; # This Pull request:. ## Changes or fixes:. The HistFactory implementation of HS3 is updated to conform with the latest draft of the standardization document. A turnaround of a plain histfactory example in the new style is possible. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12340:332,security,updat,updated,332,[RF] Update the HS3 HistFactory implementation; # This Pull request:. ## Changes or fixes:. The HistFactory implementation of HS3 is updated to conform with the latest draft of the standardization document. A turnaround of a plain histfactory example in the new style is possible. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12340:302,testability,test,tested,302,[RF] Update the HS3 HistFactory implementation; # This Pull request:. ## Changes or fixes:. The HistFactory implementation of HS3 is updated to conform with the latest draft of the standardization document. A turnaround of a plain histfactory example in the new style is possible. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12340:197,usability,document,document,197,[RF] Update the HS3 HistFactory implementation; # This Pull request:. ## Changes or fixes:. The HistFactory implementation of HS3 is updated to conform with the latest draft of the standardization document. A turnaround of a plain histfactory example in the new style is possible. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12340
https://github.com/root-project/root/pull/12342:84,interoperability,conflict,conflicts,84,[DF][tree] Backport fix for MT RDF + TTreeIndex (v6.28); To avoid the largest merge conflicts this PR also backports some refactoring of RFriendInfo and TTreeProcessorMT. Fixes #12260 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12342
https://github.com/root-project/root/pull/12342:122,modifiability,refact,refactoring,122,[DF][tree] Backport fix for MT RDF + TTreeIndex (v6.28); To avoid the largest merge conflicts this PR also backports some refactoring of RFriendInfo and TTreeProcessorMT. Fixes #12260 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12342
https://github.com/root-project/root/pull/12342:122,performance,refactor,refactoring,122,[DF][tree] Backport fix for MT RDF + TTreeIndex (v6.28); To avoid the largest merge conflicts this PR also backports some refactoring of RFriendInfo and TTreeProcessorMT. Fixes #12260 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12342
https://github.com/root-project/root/pull/12342:60,safety,avoid,avoid,60,[DF][tree] Backport fix for MT RDF + TTreeIndex (v6.28); To avoid the largest merge conflicts this PR also backports some refactoring of RFriendInfo and TTreeProcessorMT. Fixes #12260 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12342
https://github.com/root-project/root/pull/12343:297,availability,error,error,297,Stressgraphics ref; Test 25 had a minor difference in size compared to the reference value stored. in the reference file. This is a simple ratio plot example. All the other formats are. ok. A pdf comparison with a previous version shows that the two pdf files are the. same. So we give a bit more error margin.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12343
https://github.com/root-project/root/pull/12343:223,deployability,version,version,223,Stressgraphics ref; Test 25 had a minor difference in size compared to the reference value stored. in the reference file. This is a simple ratio plot example. All the other formats are. ok. A pdf comparison with a previous version shows that the two pdf files are the. same. So we give a bit more error margin.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12343
https://github.com/root-project/root/pull/12343:223,integrability,version,version,223,Stressgraphics ref; Test 25 had a minor difference in size compared to the reference value stored. in the reference file. This is a simple ratio plot example. All the other formats are. ok. A pdf comparison with a previous version shows that the two pdf files are the. same. So we give a bit more error margin.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12343
https://github.com/root-project/root/pull/12343:173,interoperability,format,formats,173,Stressgraphics ref; Test 25 had a minor difference in size compared to the reference value stored. in the reference file. This is a simple ratio plot example. All the other formats are. ok. A pdf comparison with a previous version shows that the two pdf files are the. same. So we give a bit more error margin.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12343
https://github.com/root-project/root/pull/12343:223,modifiability,version,version,223,Stressgraphics ref; Test 25 had a minor difference in size compared to the reference value stored. in the reference file. This is a simple ratio plot example. All the other formats are. ok. A pdf comparison with a previous version shows that the two pdf files are the. same. So we give a bit more error margin.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12343
https://github.com/root-project/root/pull/12343:297,performance,error,error,297,Stressgraphics ref; Test 25 had a minor difference in size compared to the reference value stored. in the reference file. This is a simple ratio plot example. All the other formats are. ok. A pdf comparison with a previous version shows that the two pdf files are the. same. So we give a bit more error margin.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12343
https://github.com/root-project/root/pull/12343:20,safety,Test,Test,20,Stressgraphics ref; Test 25 had a minor difference in size compared to the reference value stored. in the reference file. This is a simple ratio plot example. All the other formats are. ok. A pdf comparison with a previous version shows that the two pdf files are the. same. So we give a bit more error margin.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12343
https://github.com/root-project/root/pull/12343:297,safety,error,error,297,Stressgraphics ref; Test 25 had a minor difference in size compared to the reference value stored. in the reference file. This is a simple ratio plot example. All the other formats are. ok. A pdf comparison with a previous version shows that the two pdf files are the. same. So we give a bit more error margin.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12343
https://github.com/root-project/root/pull/12343:20,testability,Test,Test,20,Stressgraphics ref; Test 25 had a minor difference in size compared to the reference value stored. in the reference file. This is a simple ratio plot example. All the other formats are. ok. A pdf comparison with a previous version shows that the two pdf files are the. same. So we give a bit more error margin.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12343
https://github.com/root-project/root/pull/12343:132,testability,simpl,simple,132,Stressgraphics ref; Test 25 had a minor difference in size compared to the reference value stored. in the reference file. This is a simple ratio plot example. All the other formats are. ok. A pdf comparison with a previous version shows that the two pdf files are the. same. So we give a bit more error margin.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12343
https://github.com/root-project/root/pull/12343:132,usability,simpl,simple,132,Stressgraphics ref; Test 25 had a minor difference in size compared to the reference value stored. in the reference file. This is a simple ratio plot example. All the other formats are. ok. A pdf comparison with a previous version shows that the two pdf files are the. same. So we give a bit more error margin.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12343
https://github.com/root-project/root/pull/12343:297,usability,error,error,297,Stressgraphics ref; Test 25 had a minor difference in size compared to the reference value stored. in the reference file. This is a simple ratio plot example. All the other formats are. ok. A pdf comparison with a previous version shows that the two pdf files are the. same. So we give a bit more error margin.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12343
https://github.com/root-project/root/pull/12344:309,availability,error,error,309,Modify stressGraphics ref file; Test 25 had a minor difference in size compared to the reference value stored. in the reference file. This is a simple ratio plot example. All the other formats are. ok. A pdf comparison with a previous version shows that the two pdf files are the. same. So we give a bit more error margin.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12344
https://github.com/root-project/root/pull/12344:235,deployability,version,version,235,Modify stressGraphics ref file; Test 25 had a minor difference in size compared to the reference value stored. in the reference file. This is a simple ratio plot example. All the other formats are. ok. A pdf comparison with a previous version shows that the two pdf files are the. same. So we give a bit more error margin.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12344
https://github.com/root-project/root/pull/12344:235,integrability,version,version,235,Modify stressGraphics ref file; Test 25 had a minor difference in size compared to the reference value stored. in the reference file. This is a simple ratio plot example. All the other formats are. ok. A pdf comparison with a previous version shows that the two pdf files are the. same. So we give a bit more error margin.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12344
https://github.com/root-project/root/pull/12344:185,interoperability,format,formats,185,Modify stressGraphics ref file; Test 25 had a minor difference in size compared to the reference value stored. in the reference file. This is a simple ratio plot example. All the other formats are. ok. A pdf comparison with a previous version shows that the two pdf files are the. same. So we give a bit more error margin.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12344
https://github.com/root-project/root/pull/12344:235,modifiability,version,version,235,Modify stressGraphics ref file; Test 25 had a minor difference in size compared to the reference value stored. in the reference file. This is a simple ratio plot example. All the other formats are. ok. A pdf comparison with a previous version shows that the two pdf files are the. same. So we give a bit more error margin.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12344
https://github.com/root-project/root/pull/12344:309,performance,error,error,309,Modify stressGraphics ref file; Test 25 had a minor difference in size compared to the reference value stored. in the reference file. This is a simple ratio plot example. All the other formats are. ok. A pdf comparison with a previous version shows that the two pdf files are the. same. So we give a bit more error margin.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12344
https://github.com/root-project/root/pull/12344:32,safety,Test,Test,32,Modify stressGraphics ref file; Test 25 had a minor difference in size compared to the reference value stored. in the reference file. This is a simple ratio plot example. All the other formats are. ok. A pdf comparison with a previous version shows that the two pdf files are the. same. So we give a bit more error margin.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12344
https://github.com/root-project/root/pull/12344:309,safety,error,error,309,Modify stressGraphics ref file; Test 25 had a minor difference in size compared to the reference value stored. in the reference file. This is a simple ratio plot example. All the other formats are. ok. A pdf comparison with a previous version shows that the two pdf files are the. same. So we give a bit more error margin.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12344
https://github.com/root-project/root/pull/12344:0,security,Modif,Modify,0,Modify stressGraphics ref file; Test 25 had a minor difference in size compared to the reference value stored. in the reference file. This is a simple ratio plot example. All the other formats are. ok. A pdf comparison with a previous version shows that the two pdf files are the. same. So we give a bit more error margin.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12344
https://github.com/root-project/root/pull/12344:32,testability,Test,Test,32,Modify stressGraphics ref file; Test 25 had a minor difference in size compared to the reference value stored. in the reference file. This is a simple ratio plot example. All the other formats are. ok. A pdf comparison with a previous version shows that the two pdf files are the. same. So we give a bit more error margin.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12344
https://github.com/root-project/root/pull/12344:144,testability,simpl,simple,144,Modify stressGraphics ref file; Test 25 had a minor difference in size compared to the reference value stored. in the reference file. This is a simple ratio plot example. All the other formats are. ok. A pdf comparison with a previous version shows that the two pdf files are the. same. So we give a bit more error margin.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12344
https://github.com/root-project/root/pull/12344:144,usability,simpl,simple,144,Modify stressGraphics ref file; Test 25 had a minor difference in size compared to the reference value stored. in the reference file. This is a simple ratio plot example. All the other formats are. ok. A pdf comparison with a previous version shows that the two pdf files are the. same. So we give a bit more error margin.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12344
https://github.com/root-project/root/pull/12344:309,usability,error,error,309,Modify stressGraphics ref file; Test 25 had a minor difference in size compared to the reference value stored. in the reference file. This is a simple ratio plot example. All the other formats are. ok. A pdf comparison with a previous version shows that the two pdf files are the. same. So we give a bit more error margin.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12344
https://github.com/root-project/root/pull/12345:56,security,token,token,56,[tree][DF] Backport fix for globbing with `?#` treename token (v6.28); Fixes https://github.com/root-project/root/issues/11483 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12345
https://github.com/root-project/root/pull/12346:170,integrability,event,event,170,[tmva] Remove veto on Keras-Regression tutorial; No need to veto now these tutorials since they can run now much faster after a previous fix speeding up the Keras single event evaluation.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12346
https://github.com/root-project/root/pull/12346:28,testability,Regress,Regression,28,[tmva] Remove veto on Keras-Regression tutorial; No need to veto now these tutorials since they can run now much faster after a previous fix speeding up the Keras single event evaluation.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12346
https://github.com/root-project/root/pull/12347:108,deployability,manag,management,108,"[math] Fixup to commit that added HasGradient() to ROOT::Math functions; Because of a mistake in git commit management, merged 4bfa7c58e to master but it was missing a fixup for the `TMinuitMinimizer`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12347
https://github.com/root-project/root/pull/12347:108,energy efficiency,manag,management,108,"[math] Fixup to commit that added HasGradient() to ROOT::Math functions; Because of a mistake in git commit management, merged 4bfa7c58e to master but it was missing a fixup for the `TMinuitMinimizer`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12347
https://github.com/root-project/root/pull/12347:108,safety,manag,management,108,"[math] Fixup to commit that added HasGradient() to ROOT::Math functions; Because of a mistake in git commit management, merged 4bfa7c58e to master but it was missing a fixup for the `TMinuitMinimizer`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12347
https://github.com/root-project/root/pull/12348:5,deployability,Compos,Composition,5,"[RF] Composition over inheritance in RooAbsMinimizerFcn implementations; This results in more modular code that is also safer: the `ROOT::Fit::Fitter` has no access to the RooAbsMinimizerFcn anymore, only to the member that is a lightweight adapter. This means the `RooAbsMinimizerFcn` also doesn't get cloned unexpectedly, so we don't need extra checks in the RooMinimizer to account for that!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:94,deployability,modul,modular,94,"[RF] Composition over inheritance in RooAbsMinimizerFcn implementations; This results in more modular code that is also safer: the `ROOT::Fit::Fitter` has no access to the RooAbsMinimizerFcn anymore, only to the member that is a lightweight adapter. This means the `RooAbsMinimizerFcn` also doesn't get cloned unexpectedly, so we don't need extra checks in the RooMinimizer to account for that!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:241,energy efficiency,adapt,adapter,241,"[RF] Composition over inheritance in RooAbsMinimizerFcn implementations; This results in more modular code that is also safer: the `ROOT::Fit::Fitter` has no access to the RooAbsMinimizerFcn anymore, only to the member that is a lightweight adapter. This means the `RooAbsMinimizerFcn` also doesn't get cloned unexpectedly, so we don't need extra checks in the RooMinimizer to account for that!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:94,integrability,modular,modular,94,"[RF] Composition over inheritance in RooAbsMinimizerFcn implementations; This results in more modular code that is also safer: the `ROOT::Fit::Fitter` has no access to the RooAbsMinimizerFcn anymore, only to the member that is a lightweight adapter. This means the `RooAbsMinimizerFcn` also doesn't get cloned unexpectedly, so we don't need extra checks in the RooMinimizer to account for that!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:241,integrability,adapt,adapter,241,"[RF] Composition over inheritance in RooAbsMinimizerFcn implementations; This results in more modular code that is also safer: the `ROOT::Fit::Fitter` has no access to the RooAbsMinimizerFcn anymore, only to the member that is a lightweight adapter. This means the `RooAbsMinimizerFcn` also doesn't get cloned unexpectedly, so we don't need extra checks in the RooMinimizer to account for that!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:241,interoperability,adapt,adapter,241,"[RF] Composition over inheritance in RooAbsMinimizerFcn implementations; This results in more modular code that is also safer: the `ROOT::Fit::Fitter` has no access to the RooAbsMinimizerFcn anymore, only to the member that is a lightweight adapter. This means the `RooAbsMinimizerFcn` also doesn't get cloned unexpectedly, so we don't need extra checks in the RooMinimizer to account for that!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:5,modifiability,Compos,Composition,5,"[RF] Composition over inheritance in RooAbsMinimizerFcn implementations; This results in more modular code that is also safer: the `ROOT::Fit::Fitter` has no access to the RooAbsMinimizerFcn anymore, only to the member that is a lightweight adapter. This means the `RooAbsMinimizerFcn` also doesn't get cloned unexpectedly, so we don't need extra checks in the RooMinimizer to account for that!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:22,modifiability,inherit,inheritance,22,"[RF] Composition over inheritance in RooAbsMinimizerFcn implementations; This results in more modular code that is also safer: the `ROOT::Fit::Fitter` has no access to the RooAbsMinimizerFcn anymore, only to the member that is a lightweight adapter. This means the `RooAbsMinimizerFcn` also doesn't get cloned unexpectedly, so we don't need extra checks in the RooMinimizer to account for that!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:94,modifiability,modul,modular,94,"[RF] Composition over inheritance in RooAbsMinimizerFcn implementations; This results in more modular code that is also safer: the `ROOT::Fit::Fitter` has no access to the RooAbsMinimizerFcn anymore, only to the member that is a lightweight adapter. This means the `RooAbsMinimizerFcn` also doesn't get cloned unexpectedly, so we don't need extra checks in the RooMinimizer to account for that!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:241,modifiability,adapt,adapter,241,"[RF] Composition over inheritance in RooAbsMinimizerFcn implementations; This results in more modular code that is also safer: the `ROOT::Fit::Fitter` has no access to the RooAbsMinimizerFcn anymore, only to the member that is a lightweight adapter. This means the `RooAbsMinimizerFcn` also doesn't get cloned unexpectedly, so we don't need extra checks in the RooMinimizer to account for that!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:291,reliability,doe,doesn,291,"[RF] Composition over inheritance in RooAbsMinimizerFcn implementations; This results in more modular code that is also safer: the `ROOT::Fit::Fitter` has no access to the RooAbsMinimizerFcn anymore, only to the member that is a lightweight adapter. This means the `RooAbsMinimizerFcn` also doesn't get cloned unexpectedly, so we don't need extra checks in the RooMinimizer to account for that!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:94,safety,modul,modular,94,"[RF] Composition over inheritance in RooAbsMinimizerFcn implementations; This results in more modular code that is also safer: the `ROOT::Fit::Fitter` has no access to the RooAbsMinimizerFcn anymore, only to the member that is a lightweight adapter. This means the `RooAbsMinimizerFcn` also doesn't get cloned unexpectedly, so we don't need extra checks in the RooMinimizer to account for that!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:120,safety,safe,safer,120,"[RF] Composition over inheritance in RooAbsMinimizerFcn implementations; This results in more modular code that is also safer: the `ROOT::Fit::Fitter` has no access to the RooAbsMinimizerFcn anymore, only to the member that is a lightweight adapter. This means the `RooAbsMinimizerFcn` also doesn't get cloned unexpectedly, so we don't need extra checks in the RooMinimizer to account for that!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:158,security,access,access,158,"[RF] Composition over inheritance in RooAbsMinimizerFcn implementations; This results in more modular code that is also safer: the `ROOT::Fit::Fitter` has no access to the RooAbsMinimizerFcn anymore, only to the member that is a lightweight adapter. This means the `RooAbsMinimizerFcn` also doesn't get cloned unexpectedly, so we don't need extra checks in the RooMinimizer to account for that!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12348:94,testability,modula,modular,94,"[RF] Composition over inheritance in RooAbsMinimizerFcn implementations; This results in more modular code that is also safer: the `ROOT::Fit::Fitter` has no access to the RooAbsMinimizerFcn anymore, only to the member that is a lightweight adapter. This means the `RooAbsMinimizerFcn` also doesn't get cloned unexpectedly, so we don't need extra checks in the RooMinimizer to account for that!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12348
https://github.com/root-project/root/pull/12349:301,availability,error,error,301,"Fix issue of multiple declaration of same objects in the saved C macros; # This Pull request:. `TRatioPlot` defines three pads named `upper_pad`, `lower_pad` and `top_pad`. If single canvas contains two or more `TRatioPlot`s, the saved C macro declares same object variable names resulting in runtime error. This fix adds counter suffix to pads (like for histograms) resulting in unique pad names. ## Changes or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:1540,availability,error,error,1540,"or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition is here. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:359:10: error: redefinition of 'top_pad'. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:159:10: note: previous definition is here. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. root [1] . ```. Proposed changes fix this.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:1828,availability,error,error,1828,"or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition is here. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:359:10: error: redefinition of 'top_pad'. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:159:10: note: previous definition is here. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. root [1] . ```. Proposed changes fix this.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:2117,availability,error,error,2117,"or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition is here. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:359:10: error: redefinition of 'top_pad'. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:159:10: note: previous definition is here. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. root [1] . ```. Proposed changes fix this.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:190,deployability,contain,contains,190,"Fix issue of multiple declaration of same objects in the saved C macros; # This Pull request:. `TRatioPlot` defines three pads named `upper_pad`, `lower_pad` and `top_pad`. If single canvas contains two or more `TRatioPlot`s, the saved C macro declares same object variable names resulting in runtime error. This fix adds counter suffix to pads (like for histograms) resulting in unique pad names. ## Changes or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:601,deployability,updat,updated,601,"Fix issue of multiple declaration of same objects in the saved C macros; # This Pull request:. `TRatioPlot` defines three pads named `upper_pad`, `lower_pad` and `top_pad`. If single canvas contains two or more `TRatioPlot`s, the saved C macro declares same object variable names resulting in runtime error. This fix adds counter suffix to pads (like for histograms) resulting in unique pad names. ## Changes or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:984,energy efficiency,Draw,Draw,984,"Fix issue of multiple declaration of same objects in the saved C macros; # This Pull request:. `TRatioPlot` defines three pads named `upper_pad`, `lower_pad` and `top_pad`. If single canvas contains two or more `TRatioPlot`s, the saved C macro declares same object variable names resulting in runtime error. This fix adds counter suffix to pads (like for histograms) resulting in unique pad names. ## Changes or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:1039,energy efficiency,Draw,Draw,1039," objects in the saved C macros; # This Pull request:. `TRatioPlot` defines three pads named `upper_pad`, `lower_pad` and `top_pad`. If single canvas contains two or more `TRatioPlot`s, the saved C macro declares same object variable names resulting in runtime error. This fix adds counter suffix to pads (like for histograms) resulting in unique pad names. ## Changes or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition is here. TPad *lower_pad = new TPad(""lower",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:1120,energy efficiency,Draw,Draw,1120,"pads named `upper_pad`, `lower_pad` and `top_pad`. If single canvas contains two or more `TRatioPlot`s, the saved C macro declares same object variable names resulting in runtime error. This fix adds counter suffix to pads (like for histograms) resulting in unique pad names. ## Changes or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition is here. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:359:10: error",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:1175,energy efficiency,Draw,Draw,1175,"ingle canvas contains two or more `TRatioPlot`s, the saved C macro declares same object variable names resulting in runtime error. This fix adds counter suffix to pads (like for histograms) resulting in unique pad names. ## Changes or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition is here. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:359:10: error: redefinition of 'top_pad'. TPad *top_pad = new TPad(""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:1256,energy efficiency,Draw,Draw,1256,"object variable names resulting in runtime error. This fix adds counter suffix to pads (like for histograms) resulting in unique pad names. ## Changes or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition is here. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:359:10: error: redefinition of 'top_pad'. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:159:10:",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:1280,energy efficiency,Draw,Draw,1280,"sulting in runtime error. This fix adds counter suffix to pads (like for histograms) resulting in unique pad names. ## Changes or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition is here. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:359:10: error: redefinition of 'top_pad'. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:159:10: note: previous definiti",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:1293,energy efficiency,Draw,Draw,1293,"ntime error. This fix adds counter suffix to pads (like for histograms) resulting in unique pad names. ## Changes or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition is here. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:359:10: error: redefinition of 'top_pad'. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:159:10: note: previous definition is here. T",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:1313,energy efficiency,Draw,Draw,1313,"x adds counter suffix to pads (like for histograms) resulting in unique pad names. ## Changes or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition is here. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:359:10: error: redefinition of 'top_pad'. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:159:10: note: previous definition is here. TPad *top_pad = new T",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:265,modifiability,variab,variable,265,"Fix issue of multiple declaration of same objects in the saved C macros; # This Pull request:. `TRatioPlot` defines three pads named `upper_pad`, `lower_pad` and `top_pad`. If single canvas contains two or more `TRatioPlot`s, the saved C macro declares same object variable names resulting in runtime error. This fix adds counter suffix to pads (like for histograms) resulting in unique pad names. ## Changes or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:534,modifiability,variab,variable,534,"Fix issue of multiple declaration of same objects in the saved C macros; # This Pull request:. `TRatioPlot` defines three pads named `upper_pad`, `lower_pad` and `top_pad`. If single canvas contains two or more `TRatioPlot`s, the saved C macro declares same object variable names resulting in runtime error. This fix adds counter suffix to pads (like for histograms) resulting in unique pad names. ## Changes or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:301,performance,error,error,301,"Fix issue of multiple declaration of same objects in the saved C macros; # This Pull request:. `TRatioPlot` defines three pads named `upper_pad`, `lower_pad` and `top_pad`. If single canvas contains two or more `TRatioPlot`s, the saved C macro declares same object variable names resulting in runtime error. This fix adds counter suffix to pads (like for histograms) resulting in unique pad names. ## Changes or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:1540,performance,error,error,1540,"or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition is here. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:359:10: error: redefinition of 'top_pad'. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:159:10: note: previous definition is here. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. root [1] . ```. Proposed changes fix this.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:1828,performance,error,error,1828,"or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition is here. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:359:10: error: redefinition of 'top_pad'. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:159:10: note: previous definition is here. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. root [1] . ```. Proposed changes fix this.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:2117,performance,error,error,2117,"or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition is here. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:359:10: error: redefinition of 'top_pad'. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:159:10: note: previous definition is here. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. root [1] . ```. Proposed changes fix this.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:301,safety,error,error,301,"Fix issue of multiple declaration of same objects in the saved C macros; # This Pull request:. `TRatioPlot` defines three pads named `upper_pad`, `lower_pad` and `top_pad`. If single canvas contains two or more `TRatioPlot`s, the saved C macro declares same object variable names resulting in runtime error. This fix adds counter suffix to pads (like for histograms) resulting in unique pad names. ## Changes or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:571,safety,test,tested,571,"Fix issue of multiple declaration of same objects in the saved C macros; # This Pull request:. `TRatioPlot` defines three pads named `upper_pad`, `lower_pad` and `top_pad`. If single canvas contains two or more `TRatioPlot`s, the saved C macro declares same object variable names resulting in runtime error. This fix adds counter suffix to pads (like for histograms) resulting in unique pad names. ## Changes or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:601,safety,updat,updated,601,"Fix issue of multiple declaration of same objects in the saved C macros; # This Pull request:. `TRatioPlot` defines three pads named `upper_pad`, `lower_pad` and `top_pad`. If single canvas contains two or more `TRatioPlot`s, the saved C macro declares same object variable names resulting in runtime error. This fix adds counter suffix to pads (like for histograms) resulting in unique pad names. ## Changes or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:1540,safety,error,error,1540,"or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition is here. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:359:10: error: redefinition of 'top_pad'. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:159:10: note: previous definition is here. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. root [1] . ```. Proposed changes fix this.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:1828,safety,error,error,1828,"or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition is here. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:359:10: error: redefinition of 'top_pad'. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:159:10: note: previous definition is here. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. root [1] . ```. Proposed changes fix this.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:2117,safety,error,error,2117,"or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition is here. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:359:10: error: redefinition of 'top_pad'. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:159:10: note: previous definition is here. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. root [1] . ```. Proposed changes fix this.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:420,security,Modif,Modifications,420,"Fix issue of multiple declaration of same objects in the saved C macros; # This Pull request:. `TRatioPlot` defines three pads named `upper_pad`, `lower_pad` and `top_pad`. If single canvas contains two or more `TRatioPlot`s, the saved C macro declares same object variable names resulting in runtime error. This fix adds counter suffix to pads (like for histograms) resulting in unique pad names. ## Changes or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:601,security,updat,updated,601,"Fix issue of multiple declaration of same objects in the saved C macros; # This Pull request:. `TRatioPlot` defines three pads named `upper_pad`, `lower_pad` and `top_pad`. If single canvas contains two or more `TRatioPlot`s, the saved C macro declares same object variable names resulting in runtime error. This fix adds counter suffix to pads (like for histograms) resulting in unique pad names. ## Changes or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:571,testability,test,tested,571,"Fix issue of multiple declaration of same objects in the saved C macros; # This Pull request:. `TRatioPlot` defines three pads named `upper_pad`, `lower_pad` and `top_pad`. If single canvas contains two or more `TRatioPlot`s, the saved C macro declares same object variable names resulting in runtime error. This fix adds counter suffix to pads (like for histograms) resulting in unique pad names. ## Changes or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:301,usability,error,error,301,"Fix issue of multiple declaration of same objects in the saved C macros; # This Pull request:. `TRatioPlot` defines three pads named `upper_pad`, `lower_pad` and `top_pad`. If single canvas contains two or more `TRatioPlot`s, the saved C macro declares same object variable names resulting in runtime error. This fix adds counter suffix to pads (like for histograms) resulting in unique pad names. ## Changes or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition i",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:1540,usability,error,error,1540,"or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition is here. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:359:10: error: redefinition of 'top_pad'. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:159:10: note: previous definition is here. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. root [1] . ```. Proposed changes fix this.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:1828,usability,error,error,1828,"or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition is here. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:359:10: error: redefinition of 'top_pad'. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:159:10: note: previous definition is here. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. root [1] . ```. Proposed changes fix this.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/pull/12349:2117,usability,error,error,2117,"or fixes:. Modifications to `SavePrimitive` members of `TPad` and `TCanvas` to count instances and renumerate written object variable names. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # . ### Example. Consider MWE. ```c++. {. TH1I * h1 = new TH1I(""h1"", ""h1"", 10, -5, 5);. TH1I * h2 = new TH1I(""h2"", ""h2"", 10, -5, 5);. h1->FillRandom(""gaus"", 1000);. h2->FillRandom(""gaus"", 1000);. TCanvas * can = new TCanvas(""c_pads_test"", ""c_pads_test"", 800, 400);. can->cd(0);. TPad * p1 = new TPad(""p1"", ""p1"", 0, 0.3, 0.5, 1.0);. p1->Draw();. p1->cd();. TRatioPlot ratio1(h1, h2);. ratio1.Draw();. can->cd(0);. TPad * p2 = new TPad(""p2"", ""p2"", 0.5, 0.3, 1.0, 1.0);. p2->Draw();. p2->cd();. TRatioPlot ratio2(h2, h1);. ratio2.Draw();. can->cd(0);. TPad * p3 = new TPad(""p3"", ""p3"", 0.0, 0.0, 1.0, 0.3);. p3->Draw();. p3->cd();. h1->Draw();. h2->Draw(""same"");. can->Draw();. can->SaveAs("".C"");. }. ```. Run the macro and then try to run resulting `c_pads_test.C`. The output will be:. ```. Processing c_pads_test.C... In file included from input_line_10:1:. /home/rlalik/c_pads_test.C:229:10: error: redefinition of 'upper_pad'. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:27:10: note: previous definition is here. TPad *upper_pad = new TPad(""upper_pad"", """",0.0035,0.3,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:303:10: error: redefinition of 'lower_pad'. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:103:10: note: previous definition is here. TPad *lower_pad = new TPad(""lower_pad"", """",0.0035,0.0025,0.9965,0.3);. ^. /home/rlalik/c_pads_test.C:359:10: error: redefinition of 'top_pad'. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. /home/rlalik/c_pads_test.C:159:10: note: previous definition is here. TPad *top_pad = new TPad(""top_pad"", """",0.0035,0.0025,0.9965,0.9975);. ^. root [1] . ```. Proposed changes fix this.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12349
https://github.com/root-project/root/issues/12350:3833,availability,Operat,Operating,3833," dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSystemFile *>(tsysfChildRaw); std::cout << ""baseName: "" << tsysfChild->GetName() << "" dirPath: "" << tsysfChild->GetTitle() << "" isDirectory: "" << tsysfChild->IsDirectory() << std::endl; }. baseName: . dirPath: foodir isDirectory: 1. baseName: .. dirPath: foodir/.. isDirectory: 1. baseName: bar dirPath: foodir isDirectory: 1. baseName: foo dirPath: foodir isDirectory: 0. ```. ### Setup. 1. ROOT Version: 6.26/08. 2. Operating system: NixOS, x86_64-linux, gcc. 3. ROOT obtained from Nixpkgs channel `nixos-22.11`. ### Additional context. Previous `TSystemDirectory` bug:. https://sft.its.cern.ch/jira/browse/ROOT-4040",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2990,deployability,build,build,2990,"| Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSystemFile *>(tsysfChildRaw); std::cout << ""baseName: "" << tsysfChild->GetName() << "" dirPath: "" << tsysfChild->GetTitle() << "" isDirectory: "" << tsysfChild->IsDirectory() << std::endl; }. baseName: . dirPath: foodir isDirectory: 1. baseName: .. dirPath: foodir/.. isDirectory: 1. baseName: bar dirPath: foodir isDirectory: 1. baseName: foo dirPath: foodir isDirectory: 0. ```. ### Setup. 1. ROOT Version: 6.26/08. 2. Operating system: NixOS, x86_64-linux, gcc. 3. ROOT obtained from Nixpkgs channel `nixos-22.11`. ### Additional context. Previous `TSystemDirectory` bug:. https",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:3812,deployability,Version,Version,3812," dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSystemFile *>(tsysfChildRaw); std::cout << ""baseName: "" << tsysfChild->GetName() << "" dirPath: "" << tsysfChild->GetTitle() << "" isDirectory: "" << tsysfChild->IsDirectory() << std::endl; }. baseName: . dirPath: foodir isDirectory: 1. baseName: .. dirPath: foodir/.. isDirectory: 1. baseName: bar dirPath: foodir isDirectory: 1. baseName: foo dirPath: foodir isDirectory: 0. ```. ### Setup. 1. ROOT Version: 6.26/08. 2. Operating system: NixOS, x86_64-linux, gcc. 3. ROOT obtained from Nixpkgs channel `nixos-22.11`. ### Additional context. Previous `TSystemDirectory` bug:. https://sft.its.cern.ch/jira/browse/ROOT-4040",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:1316,energy efficiency,current,current,1316,"h/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. The behavior of methods in `TSystemFile` and `TSystemDirectory` is inconsistent:. * `TSystemFile` stores the path solely in its `fName`. * `TSystemDirectory` set the path to its `fName` and `fTitle`. * `TSystemDirectory::GetListOfFiles()` gets the path of the directory from its title (`fTitle`), and returns a `TList *`, each element in which represents the child item (with basename `file` and path `sdirpath`) inside the directory the following ways:. * If the element is a directory, it would be `new TDirectory(file, sdirpath)`. * If the element is a file, it would be `new TFile(file, fTitle)`. Which results in the following bugs:. * If an element of `TSystemDirectory::GetListOfFiles()` is a file, its `IsDirectory()` will try to look for the file basename in the *current working directory* and produce the wrong result. * As its perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:1756,integrability,interfac,interface,1756,"y::GetListOfFiles()` gets the path of the directory from its title (`fTitle`), and returns a `TList *`, each element in which represents the child item (with basename `file` and path `sdirpath`) inside the directory the following ways:. * If the element is a directory, it would be `new TDirectory(file, sdirpath)`. * If the element is a file, it would be `new TFile(file, fTitle)`. Which results in the following bugs:. * If an element of `TSystemDirectory::GetListOfFiles()` is a file, its `IsDirectory()` will try to look for the file basename in the *current working directory* and produce the wrong result. * As its perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:1864,integrability,interfac,interface,1864," element in which represents the child item (with basename `file` and path `sdirpath`) inside the directory the following ways:. * If the element is a directory, it would be `new TDirectory(file, sdirpath)`. * If the element is a file, it would be `new TFile(file, fTitle)`. Which results in the following bugs:. * If an element of `TSystemDirectory::GetListOfFiles()` is a file, its `IsDirectory()` will try to look for the file basename in the *current working directory* and produce the wrong result. * As its perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; idea",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:1935,integrability,interfac,interface,1935,"ath `sdirpath`) inside the directory the following ways:. * If the element is a directory, it would be `new TDirectory(file, sdirpath)`. * If the element is a file, it would be `new TFile(file, fTitle)`. Which results in the following bugs:. * If an element of `TSystemDirectory::GetListOfFiles()` is a file, its `IsDirectory()` will try to look for the file basename in the *current working directory* and produce the wrong result. * As its perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the requi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2199,integrability,interfac,interfaces,2199,"ystemDirectory::GetListOfFiles()` is a file, its `IsDirectory()` will try to look for the file basename in the *current working directory* and produce the wrong result. * As its perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├─",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2280,integrability,interfac,interface,2280," for the file basename in the *current working directory* and produce the wrong result. * As its perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2340,integrability,interfac,interface,2340,"d produce the wrong result. * As its perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"",",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2414,integrability,interfac,interface,2414,"tory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSyst",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2474,integrability,interfac,interface,2474,"ame ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSystemFile *>(tsysfChildRaw); std::cout << ""baseName: "" << tsysf",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2549,integrability,interfac,interface,2549,"* A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSystemFile *>(tsysfChildRaw); std::cout << ""baseName: "" << tsysfChild->GetName() << "" dirPath: "" << tsysfChild->GetTitle() << "" isDirectory",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2609,integrability,interfac,interface,2609,"nce of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSystemFile *>(tsysfChildRaw); std::cout << ""baseName: "" << tsysfChild->GetName() << "" dirPath: "" << tsysfChild->GetTitle() << "" isDirectory: "" << tsysfChild->IsDirectory() << std::endl; }. baseName: ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2708,integrability,interfac,interfaces,2708,"ou expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSystemFile *>(tsysfChildRaw); std::cout << ""baseName: "" << tsysfChild->GetName() << "" dirPath: "" << tsysfChild->GetTitle() << "" isDirectory: "" << tsysfChild->IsDirectory() << std::endl; }. baseName: . dirPath: foodir isDirectory: 1. baseName: .. dirPath: foodir/.. isDirectory: 1. baseName: bar dir",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:3812,integrability,Version,Version,3812," dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSystemFile *>(tsysfChildRaw); std::cout << ""baseName: "" << tsysfChild->GetName() << "" dirPath: "" << tsysfChild->GetTitle() << "" isDirectory: "" << tsysfChild->IsDirectory() << std::endl; }. baseName: . dirPath: foodir isDirectory: 1. baseName: .. dirPath: foodir/.. isDirectory: 1. baseName: bar dirPath: foodir isDirectory: 1. baseName: foo dirPath: foodir isDirectory: 0. ```. ### Setup. 1. ROOT Version: 6.26/08. 2. Operating system: NixOS, x86_64-linux, gcc. 3. ROOT obtained from Nixpkgs channel `nixos-22.11`. ### Additional context. Previous `TSystemDirectory` bug:. https://sft.its.cern.ch/jira/browse/ROOT-4040",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:1756,interoperability,interfac,interface,1756,"y::GetListOfFiles()` gets the path of the directory from its title (`fTitle`), and returns a `TList *`, each element in which represents the child item (with basename `file` and path `sdirpath`) inside the directory the following ways:. * If the element is a directory, it would be `new TDirectory(file, sdirpath)`. * If the element is a file, it would be `new TFile(file, fTitle)`. Which results in the following bugs:. * If an element of `TSystemDirectory::GetListOfFiles()` is a file, its `IsDirectory()` will try to look for the file basename in the *current working directory* and produce the wrong result. * As its perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:1864,interoperability,interfac,interface,1864," element in which represents the child item (with basename `file` and path `sdirpath`) inside the directory the following ways:. * If the element is a directory, it would be `new TDirectory(file, sdirpath)`. * If the element is a file, it would be `new TFile(file, fTitle)`. Which results in the following bugs:. * If an element of `TSystemDirectory::GetListOfFiles()` is a file, its `IsDirectory()` will try to look for the file basename in the *current working directory* and produce the wrong result. * As its perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; idea",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:1901,interoperability,compatib,compatible,1901,"d item (with basename `file` and path `sdirpath`) inside the directory the following ways:. * If the element is a directory, it would be `new TDirectory(file, sdirpath)`. * If the element is a file, it would be `new TFile(file, fTitle)`. Which results in the following bugs:. * If an element of `TSystemDirectory::GetListOfFiles()` is a file, its `IsDirectory()` will try to look for the file basename in the *current working directory* and produce the wrong result. * As its perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:1935,interoperability,interfac,interface,1935,"ath `sdirpath`) inside the directory the following ways:. * If the element is a directory, it would be `new TDirectory(file, sdirpath)`. * If the element is a file, it would be `new TFile(file, fTitle)`. Which results in the following bugs:. * If an element of `TSystemDirectory::GetListOfFiles()` is a file, its `IsDirectory()` will try to look for the file basename in the *current working directory* and produce the wrong result. * As its perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the requi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2133,interoperability,incompatib,incompatible,2133,"e)`. Which results in the following bugs:. * If an element of `TSystemDirectory::GetListOfFiles()` is a file, its `IsDirectory()` will try to look for the file basename in the *current working directory* and produce the wrong result. * As its perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ m",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2199,interoperability,interfac,interfaces,2199,"ystemDirectory::GetListOfFiles()` is a file, its `IsDirectory()` will try to look for the file basename in the *current working directory* and produce the wrong result. * As its perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├─",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2280,interoperability,interfac,interface,2280," for the file basename in the *current working directory* and produce the wrong result. * As its perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2292,interoperability,incompatib,incompatible,2292," basename in the *current working directory* and produce the wrong result. * As its perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const au",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2340,interoperability,interfac,interface,2340,"d produce the wrong result. * As its perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"",",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2414,interoperability,interfac,interface,2414,"tory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSyst",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2426,interoperability,incompatib,incompatible,2426,"SystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSystemFile *>(tsy",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2474,interoperability,interfac,interface,2474,"ame ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSystemFile *>(tsysfChildRaw); std::cout << ""baseName: "" << tsysf",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2549,interoperability,interfac,interface,2549,"* A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSystemFile *>(tsysfChildRaw); std::cout << ""baseName: "" << tsysfChild->GetName() << "" dirPath: "" << tsysfChild->GetTitle() << "" isDirectory",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2561,interoperability,incompatib,incompatible,2561," with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSystemFile *>(tsysfChildRaw); std::cout << ""baseName: "" << tsysfChild->GetName() << "" dirPath: "" << tsysfChild->GetTitle() << "" isDirectory: "" << tsysfC",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2609,interoperability,interfac,interface,2609,"nce of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSystemFile *>(tsysfChildRaw); std::cout << ""baseName: "" << tsysfChild->GetName() << "" dirPath: "" << tsysfChild->GetTitle() << "" isDirectory: "" << tsysfChild->IsDirectory() << std::endl; }. baseName: ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2708,interoperability,interfac,interfaces,2708,"ou expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSystemFile *>(tsysfChildRaw); std::cout << ""baseName: "" << tsysfChild->GetName() << "" dirPath: "" << tsysfChild->GetTitle() << "" isDirectory: "" << tsysfChild->IsDirectory() << std::endl; }. baseName: . dirPath: foodir isDirectory: 1. baseName: .. dirPath: foodir/.. isDirectory: 1. baseName: bar dir",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:1756,modifiability,interfac,interface,1756,"y::GetListOfFiles()` gets the path of the directory from its title (`fTitle`), and returns a `TList *`, each element in which represents the child item (with basename `file` and path `sdirpath`) inside the directory the following ways:. * If the element is a directory, it would be `new TDirectory(file, sdirpath)`. * If the element is a file, it would be `new TFile(file, fTitle)`. Which results in the following bugs:. * If an element of `TSystemDirectory::GetListOfFiles()` is a file, its `IsDirectory()` will try to look for the file basename in the *current working directory* and produce the wrong result. * As its perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Re",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:1864,modifiability,interfac,interface,1864," element in which represents the child item (with basename `file` and path `sdirpath`) inside the directory the following ways:. * If the element is a directory, it would be `new TDirectory(file, sdirpath)`. * If the element is a file, it would be `new TFile(file, fTitle)`. Which results in the following bugs:. * If an element of `TSystemDirectory::GetListOfFiles()` is a file, its `IsDirectory()` will try to look for the file basename in the *current working directory* and produce the wrong result. * As its perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; idea",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:1935,modifiability,interfac,interface,1935,"ath `sdirpath`) inside the directory the following ways:. * If the element is a directory, it would be `new TDirectory(file, sdirpath)`. * If the element is a file, it would be `new TFile(file, fTitle)`. Which results in the following bugs:. * If an element of `TSystemDirectory::GetListOfFiles()` is a file, its `IsDirectory()` will try to look for the file basename in the *current working directory* and produce the wrong result. * As its perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the requi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2199,modifiability,interfac,interfaces,2199,"ystemDirectory::GetListOfFiles()` is a file, its `IsDirectory()` will try to look for the file basename in the *current working directory* and produce the wrong result. * As its perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├─",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2280,modifiability,interfac,interface,2280," for the file basename in the *current working directory* and produce the wrong result. * As its perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2340,modifiability,interfac,interface,2340,"d produce the wrong result. * As its perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"",",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2414,modifiability,interfac,interface,2414,"tory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSyst",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2474,modifiability,interfac,interface,2474,"ame ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSystemFile *>(tsysfChildRaw); std::cout << ""baseName: "" << tsysf",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2549,modifiability,interfac,interface,2549,"* A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSystemFile *>(tsysfChildRaw); std::cout << ""baseName: "" << tsysfChild->GetName() << "" dirPath: "" << tsysfChild->GetTitle() << "" isDirectory",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2609,modifiability,interfac,interface,2609,"nce of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSystemFile *>(tsysfChildRaw); std::cout << ""baseName: "" << tsysfChild->GetName() << "" dirPath: "" << tsysfChild->GetTitle() << "" isDirectory: "" << tsysfChild->IsDirectory() << std::endl; }. baseName: ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2708,modifiability,interfac,interfaces,2708,"ou expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSystemFile *>(tsysfChildRaw); std::cout << ""baseName: "" << tsysfChild->GetName() << "" dirPath: "" << tsysfChild->GetTitle() << "" isDirectory: "" << tsysfChild->IsDirectory() << std::endl; }. baseName: . dirPath: foodir isDirectory: 1. baseName: .. dirPath: foodir/.. isDirectory: 1. baseName: bar dir",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:3812,modifiability,Version,Version,3812," dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSystemFile *>(tsysfChildRaw); std::cout << ""baseName: "" << tsysfChild->GetName() << "" dirPath: "" << tsysfChild->GetTitle() << "" isDirectory: "" << tsysfChild->IsDirectory() << std::endl; }. baseName: . dirPath: foodir isDirectory: 1. baseName: .. dirPath: foodir/.. isDirectory: 1. baseName: bar dirPath: foodir isDirectory: 1. baseName: foo dirPath: foodir isDirectory: 0. ```. ### Setup. 1. ROOT Version: 6.26/08. 2. Operating system: NixOS, x86_64-linux, gcc. 3. ROOT obtained from Nixpkgs channel `nixos-22.11`. ### Additional context. Previous `TSystemDirectory` bug:. https://sft.its.cern.ch/jira/browse/ROOT-4040",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2944,safety,input,input,2944,"uld be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSystemFile *>(tsysfChildRaw); std::cout << ""baseName: "" << tsysfChild->GetName() << "" dirPath: "" << tsysfChild->GetTitle() << "" isDirectory: "" << tsysfChild->IsDirectory() << std::endl; }. baseName: . dirPath: foodir isDirectory: 1. baseName: .. dirPath: foodir/.. isDirectory: 1. baseName: bar dirPath: foodir isDirectory: 1. baseName: foo dirPath: foodir isDirectory: 0. ```. ### Setup. 1. ROOT Version: 6.26/08. 2. Operating system: NixOS, x86_64-linux, gcc. 3. ROOT obtained from Nixpkgs channel `nixos-22.11`. ### Additional co",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:3945,testability,context,context,3945," dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSystemFile *>(tsysfChildRaw); std::cout << ""baseName: "" << tsysfChild->GetName() << "" dirPath: "" << tsysfChild->GetTitle() << "" isDirectory: "" << tsysfChild->IsDirectory() << std::endl; }. baseName: . dirPath: foodir isDirectory: 1. baseName: .. dirPath: foodir/.. isDirectory: 1. baseName: bar dirPath: foodir isDirectory: 1. baseName: foo dirPath: foodir isDirectory: 0. ```. ### Setup. 1. ROOT Version: 6.26/08. 2. Operating system: NixOS, x86_64-linux, gcc. 3. ROOT obtained from Nixpkgs channel `nixos-22.11`. ### Additional context. Previous `TSystemDirectory` bug:. https://sft.its.cern.ch/jira/browse/ROOT-4040",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:547,usability,behavi,behavior,547,"Inconsistency between `TSystemFile` and `TSystemDirectory` causes the elements of `TSystemDirectory::GetListOfFiles()` to produce wrong `IsDirectory()` results; - [X] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. The behavior of methods in `TSystemFile` and `TSystemDirectory` is inconsistent:. * `TSystemFile` stores the path solely in its `fName`. * `TSystemDirectory` set the path to its `fName` and `fTitle`. * `TSystemDirectory::GetListOfFiles()` gets the path of the directory from its title (`fTitle`), and returns a `TList *`, each element in which represents the child item (with basename `file` and path `sdirpath`) inside the directory the following ways:. * If the element is a directory, it would be `new TDirectory(file, sdirpath)`. * If the element is a file, it would be `new TFile(file, fTitle)`. Which results in the following bugs:. * If an element of `TSystemDirectory::GetListOfFiles()` is a file, its `IsDirectory()` will try to look for the file basename in the *current working directory* and produce the wrong result. * As its perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:1656,usability,behavi,behavior,1656,"ely in its `fName`. * `TSystemDirectory` set the path to its `fName` and `fTitle`. * `TSystemDirectory::GetListOfFiles()` gets the path of the directory from its title (`fTitle`), and returns a `TList *`, each element in which represents the child item (with basename `file` and path `sdirpath`) inside the directory the following ways:. * If the element is a directory, it would be `new TDirectory(file, sdirpath)`. * If the element is a file, it would be `new TFile(file, fTitle)`. Which results in the following bugs:. * If an element of `TSystemDirectory::GetListOfFiles()` is a file, its `IsDirectory()` will try to look for the file basename in the *current working directory* and produce the wrong result. * As its perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to th",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:1674,usability,clear,clear,1674,"`. * `TSystemDirectory` set the path to its `fName` and `fTitle`. * `TSystemDirectory::GetListOfFiles()` gets the path of the directory from its title (`fTitle`), and returns a `TList *`, each element in which represents the child item (with basename `file` and path `sdirpath`) inside the directory the following ways:. * If the element is a directory, it would be `new TDirectory(file, sdirpath)`. * If the element is a file, it would be `new TFile(file, fTitle)`. Which results in the following bugs:. * If an element of `TSystemDirectory::GetListOfFiles()` is a file, its `IsDirectory()` will try to look for the file basename in the *current working directory* and produce the wrong result. * As its perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSyst",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2083,usability,close,closer,2083,"element is a file, it would be `new TFile(file, fTitle)`. Which results in the following bugs:. * If an element of `TSystemDirectory::GetListOfFiles()` is a file, its `IsDirectory()` will try to look for the file basename in the *current working directory* and produce the wrong result. * As its perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::Get",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2238,usability,close,closer,2238,"a file, its `IsDirectory()` will try to look for the file basename in the *current working directory* and produce the wrong result. * As its perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2377,usability,close,closer,2377,"s perfectly legal to cast `TSystemDirectory *` to `TSystemFile *`, a `TSystemFile *tsysfFoo` with name ""foo"" and title ""foo"" could mean either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSys",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2512,usability,close,closer,2512," either. * A file with path `foo/foo`. * A directory with path `foo`, which was originally an instance of `TSystemDirectory *`. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSystemFile *>(tsysfChildRaw); std::cout << ""baseName: "" << tsysfChild->GetName() << "" dirPath: "" << ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2648,usability,close,closer,2648,"cted behavior. <!--. A clear and concise description of what you expected to happen. -->. The name-title interface of both `TSystemFile` and `TSystemDirectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSystemFile *>(tsysfChildRaw); std::cout << ""baseName: "" << tsysfChild->GetName() << "" dirPath: "" << tsysfChild->GetTitle() << "" isDirectory: "" << tsysfChild->IsDirectory() << std::endl; }. baseName: . dirPath: foodir isDirectory: 1. bas",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2799,usability,behavi,behavior,2799,"ectory` is unified. Due to the inconsistency of the original interface, there's no fully-backward-compatible solution. The possible interface would be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSystemFile *>(tsysfChildRaw); std::cout << ""baseName: "" << tsysfChild->GetName() << "" dirPath: "" << tsysfChild->GetTitle() << "" isDirectory: "" << tsysfChild->IsDirectory() << std::endl; }. baseName: . dirPath: foodir isDirectory: 1. baseName: .. dirPath: foodir/.. isDirectory: 1. baseName: bar dirPath: foodir isDirectory: 1. baseName: foo dirPath: foodir isDirectory: 0. ```. ### Setup.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/issues/12350:2944,usability,input,input,2944,"uld be one of the followings:. | Name | Title | Pros | Cons |. |-|-|-|-|. | basename | dirname | the most informative and good-looking; closer to what GetListOfFiles() tries to output | incompatible to the original `TSystemFile` and `TSystemDirectory` interfaces |. | basename | full path | closer to the original `TSystemDirectory` interface | incompatible to the original `TSystemDirectory` interface |. | full path | dirname | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | basename | closer to the original `TSystemFile` interface | incompatible to the original `TSystemDirectory` interface |. | full path | full path | closer to the original `TSystemFile` and `TSystemDirectory` interfaces | carry the least information |. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 4. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. #### Wrong `IsDirectory()` from `TSystemDirectory::GetListOfFiles()` elements. ```console. $ mkdir bar. $ mkdir foodir. $ touch foodir/foo. $ touch foodir/bar. $ tree. . ├── bar. └── foodir. ├── bar. └── foo. 2 directories, 2 files. $ root -l. root [0] for (const auto &&tsysfChildRaw: *TSystemDirectory(""foodir"", ""foodir"").GetListOfFiles()) { TSystemFile *tsysfChild = static_cast<TSystemFile *>(tsysfChildRaw); std::cout << ""baseName: "" << tsysfChild->GetName() << "" dirPath: "" << tsysfChild->GetTitle() << "" isDirectory: "" << tsysfChild->IsDirectory() << std::endl; }. baseName: . dirPath: foodir isDirectory: 1. baseName: .. dirPath: foodir/.. isDirectory: 1. baseName: bar dirPath: foodir isDirectory: 1. baseName: foo dirPath: foodir isDirectory: 0. ```. ### Setup. 1. ROOT Version: 6.26/08. 2. Operating system: NixOS, x86_64-linux, gcc. 3. ROOT obtained from Nixpkgs channel `nixos-22.11`. ### Additional co",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/12350
https://github.com/root-project/root/pull/12351:337,availability,avail,available,337,"Add initial support for RISC-V; This pull request contains the changes to add initial support for RISC-V. It was developed during the past months on a StarFive VisionFive v1 that was kindly provided to me as part of the [RISC-V Developer Boards Program](https://riscv.org/risc-v-developer-boards/). More details about the challenges are available in the form of a [blog post on my website](https://www.hahnjo.de/blog/2023/01/28/riscv-higgs.html), a [presentation at the CaaS meeting in January](https://compiler-research.org/meetings/#caas_12Jan2023), and a [recording of that talk](https://youtu.be/3PWeLGrF41g). Please note that this PR only contains the necessary changes to the build system and ROOT's configuration files and utilities. Making the interpreter actually functional requires a number of backports to ROOT's copy of LLVM 13, that are available separately in a branch (https://github.com/hahnjo/root/tree/riscv-backports).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12351
https://github.com/root-project/root/pull/12351:851,availability,avail,available,851,"Add initial support for RISC-V; This pull request contains the changes to add initial support for RISC-V. It was developed during the past months on a StarFive VisionFive v1 that was kindly provided to me as part of the [RISC-V Developer Boards Program](https://riscv.org/risc-v-developer-boards/). More details about the challenges are available in the form of a [blog post on my website](https://www.hahnjo.de/blog/2023/01/28/riscv-higgs.html), a [presentation at the CaaS meeting in January](https://compiler-research.org/meetings/#caas_12Jan2023), and a [recording of that talk](https://youtu.be/3PWeLGrF41g). Please note that this PR only contains the necessary changes to the build system and ROOT's configuration files and utilities. Making the interpreter actually functional requires a number of backports to ROOT's copy of LLVM 13, that are available separately in a branch (https://github.com/hahnjo/root/tree/riscv-backports).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12351
https://github.com/root-project/root/pull/12351:50,deployability,contain,contains,50,"Add initial support for RISC-V; This pull request contains the changes to add initial support for RISC-V. It was developed during the past months on a StarFive VisionFive v1 that was kindly provided to me as part of the [RISC-V Developer Boards Program](https://riscv.org/risc-v-developer-boards/). More details about the challenges are available in the form of a [blog post on my website](https://www.hahnjo.de/blog/2023/01/28/riscv-higgs.html), a [presentation at the CaaS meeting in January](https://compiler-research.org/meetings/#caas_12Jan2023), and a [recording of that talk](https://youtu.be/3PWeLGrF41g). Please note that this PR only contains the necessary changes to the build system and ROOT's configuration files and utilities. Making the interpreter actually functional requires a number of backports to ROOT's copy of LLVM 13, that are available separately in a branch (https://github.com/hahnjo/root/tree/riscv-backports).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12351
https://github.com/root-project/root/pull/12351:644,deployability,contain,contains,644,"Add initial support for RISC-V; This pull request contains the changes to add initial support for RISC-V. It was developed during the past months on a StarFive VisionFive v1 that was kindly provided to me as part of the [RISC-V Developer Boards Program](https://riscv.org/risc-v-developer-boards/). More details about the challenges are available in the form of a [blog post on my website](https://www.hahnjo.de/blog/2023/01/28/riscv-higgs.html), a [presentation at the CaaS meeting in January](https://compiler-research.org/meetings/#caas_12Jan2023), and a [recording of that talk](https://youtu.be/3PWeLGrF41g). Please note that this PR only contains the necessary changes to the build system and ROOT's configuration files and utilities. Making the interpreter actually functional requires a number of backports to ROOT's copy of LLVM 13, that are available separately in a branch (https://github.com/hahnjo/root/tree/riscv-backports).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12351
https://github.com/root-project/root/pull/12351:682,deployability,build,build,682,"Add initial support for RISC-V; This pull request contains the changes to add initial support for RISC-V. It was developed during the past months on a StarFive VisionFive v1 that was kindly provided to me as part of the [RISC-V Developer Boards Program](https://riscv.org/risc-v-developer-boards/). More details about the challenges are available in the form of a [blog post on my website](https://www.hahnjo.de/blog/2023/01/28/riscv-higgs.html), a [presentation at the CaaS meeting in January](https://compiler-research.org/meetings/#caas_12Jan2023), and a [recording of that talk](https://youtu.be/3PWeLGrF41g). Please note that this PR only contains the necessary changes to the build system and ROOT's configuration files and utilities. Making the interpreter actually functional requires a number of backports to ROOT's copy of LLVM 13, that are available separately in a branch (https://github.com/hahnjo/root/tree/riscv-backports).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12351
https://github.com/root-project/root/pull/12351:706,deployability,configurat,configuration,706,"Add initial support for RISC-V; This pull request contains the changes to add initial support for RISC-V. It was developed during the past months on a StarFive VisionFive v1 that was kindly provided to me as part of the [RISC-V Developer Boards Program](https://riscv.org/risc-v-developer-boards/). More details about the challenges are available in the form of a [blog post on my website](https://www.hahnjo.de/blog/2023/01/28/riscv-higgs.html), a [presentation at the CaaS meeting in January](https://compiler-research.org/meetings/#caas_12Jan2023), and a [recording of that talk](https://youtu.be/3PWeLGrF41g). Please note that this PR only contains the necessary changes to the build system and ROOT's configuration files and utilities. Making the interpreter actually functional requires a number of backports to ROOT's copy of LLVM 13, that are available separately in a branch (https://github.com/hahnjo/root/tree/riscv-backports).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12351
https://github.com/root-project/root/pull/12351:706,integrability,configur,configuration,706,"Add initial support for RISC-V; This pull request contains the changes to add initial support for RISC-V. It was developed during the past months on a StarFive VisionFive v1 that was kindly provided to me as part of the [RISC-V Developer Boards Program](https://riscv.org/risc-v-developer-boards/). More details about the challenges are available in the form of a [blog post on my website](https://www.hahnjo.de/blog/2023/01/28/riscv-higgs.html), a [presentation at the CaaS meeting in January](https://compiler-research.org/meetings/#caas_12Jan2023), and a [recording of that talk](https://youtu.be/3PWeLGrF41g). Please note that this PR only contains the necessary changes to the build system and ROOT's configuration files and utilities. Making the interpreter actually functional requires a number of backports to ROOT's copy of LLVM 13, that are available separately in a branch (https://github.com/hahnjo/root/tree/riscv-backports).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12351
https://github.com/root-project/root/pull/12351:706,modifiability,configur,configuration,706,"Add initial support for RISC-V; This pull request contains the changes to add initial support for RISC-V. It was developed during the past months on a StarFive VisionFive v1 that was kindly provided to me as part of the [RISC-V Developer Boards Program](https://riscv.org/risc-v-developer-boards/). More details about the challenges are available in the form of a [blog post on my website](https://www.hahnjo.de/blog/2023/01/28/riscv-higgs.html), a [presentation at the CaaS meeting in January](https://compiler-research.org/meetings/#caas_12Jan2023), and a [recording of that talk](https://youtu.be/3PWeLGrF41g). Please note that this PR only contains the necessary changes to the build system and ROOT's configuration files and utilities. Making the interpreter actually functional requires a number of backports to ROOT's copy of LLVM 13, that are available separately in a branch (https://github.com/hahnjo/root/tree/riscv-backports).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12351
https://github.com/root-project/root/pull/12351:337,reliability,availab,available,337,"Add initial support for RISC-V; This pull request contains the changes to add initial support for RISC-V. It was developed during the past months on a StarFive VisionFive v1 that was kindly provided to me as part of the [RISC-V Developer Boards Program](https://riscv.org/risc-v-developer-boards/). More details about the challenges are available in the form of a [blog post on my website](https://www.hahnjo.de/blog/2023/01/28/riscv-higgs.html), a [presentation at the CaaS meeting in January](https://compiler-research.org/meetings/#caas_12Jan2023), and a [recording of that talk](https://youtu.be/3PWeLGrF41g). Please note that this PR only contains the necessary changes to the build system and ROOT's configuration files and utilities. Making the interpreter actually functional requires a number of backports to ROOT's copy of LLVM 13, that are available separately in a branch (https://github.com/hahnjo/root/tree/riscv-backports).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12351
https://github.com/root-project/root/pull/12351:851,reliability,availab,available,851,"Add initial support for RISC-V; This pull request contains the changes to add initial support for RISC-V. It was developed during the past months on a StarFive VisionFive v1 that was kindly provided to me as part of the [RISC-V Developer Boards Program](https://riscv.org/risc-v-developer-boards/). More details about the challenges are available in the form of a [blog post on my website](https://www.hahnjo.de/blog/2023/01/28/riscv-higgs.html), a [presentation at the CaaS meeting in January](https://compiler-research.org/meetings/#caas_12Jan2023), and a [recording of that talk](https://youtu.be/3PWeLGrF41g). Please note that this PR only contains the necessary changes to the build system and ROOT's configuration files and utilities. Making the interpreter actually functional requires a number of backports to ROOT's copy of LLVM 13, that are available separately in a branch (https://github.com/hahnjo/root/tree/riscv-backports).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12351
https://github.com/root-project/root/pull/12351:337,safety,avail,available,337,"Add initial support for RISC-V; This pull request contains the changes to add initial support for RISC-V. It was developed during the past months on a StarFive VisionFive v1 that was kindly provided to me as part of the [RISC-V Developer Boards Program](https://riscv.org/risc-v-developer-boards/). More details about the challenges are available in the form of a [blog post on my website](https://www.hahnjo.de/blog/2023/01/28/riscv-higgs.html), a [presentation at the CaaS meeting in January](https://compiler-research.org/meetings/#caas_12Jan2023), and a [recording of that talk](https://youtu.be/3PWeLGrF41g). Please note that this PR only contains the necessary changes to the build system and ROOT's configuration files and utilities. Making the interpreter actually functional requires a number of backports to ROOT's copy of LLVM 13, that are available separately in a branch (https://github.com/hahnjo/root/tree/riscv-backports).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12351
https://github.com/root-project/root/pull/12351:851,safety,avail,available,851,"Add initial support for RISC-V; This pull request contains the changes to add initial support for RISC-V. It was developed during the past months on a StarFive VisionFive v1 that was kindly provided to me as part of the [RISC-V Developer Boards Program](https://riscv.org/risc-v-developer-boards/). More details about the challenges are available in the form of a [blog post on my website](https://www.hahnjo.de/blog/2023/01/28/riscv-higgs.html), a [presentation at the CaaS meeting in January](https://compiler-research.org/meetings/#caas_12Jan2023), and a [recording of that talk](https://youtu.be/3PWeLGrF41g). Please note that this PR only contains the necessary changes to the build system and ROOT's configuration files and utilities. Making the interpreter actually functional requires a number of backports to ROOT's copy of LLVM 13, that are available separately in a branch (https://github.com/hahnjo/root/tree/riscv-backports).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12351
https://github.com/root-project/root/pull/12351:337,security,availab,available,337,"Add initial support for RISC-V; This pull request contains the changes to add initial support for RISC-V. It was developed during the past months on a StarFive VisionFive v1 that was kindly provided to me as part of the [RISC-V Developer Boards Program](https://riscv.org/risc-v-developer-boards/). More details about the challenges are available in the form of a [blog post on my website](https://www.hahnjo.de/blog/2023/01/28/riscv-higgs.html), a [presentation at the CaaS meeting in January](https://compiler-research.org/meetings/#caas_12Jan2023), and a [recording of that talk](https://youtu.be/3PWeLGrF41g). Please note that this PR only contains the necessary changes to the build system and ROOT's configuration files and utilities. Making the interpreter actually functional requires a number of backports to ROOT's copy of LLVM 13, that are available separately in a branch (https://github.com/hahnjo/root/tree/riscv-backports).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12351
https://github.com/root-project/root/pull/12351:706,security,configur,configuration,706,"Add initial support for RISC-V; This pull request contains the changes to add initial support for RISC-V. It was developed during the past months on a StarFive VisionFive v1 that was kindly provided to me as part of the [RISC-V Developer Boards Program](https://riscv.org/risc-v-developer-boards/). More details about the challenges are available in the form of a [blog post on my website](https://www.hahnjo.de/blog/2023/01/28/riscv-higgs.html), a [presentation at the CaaS meeting in January](https://compiler-research.org/meetings/#caas_12Jan2023), and a [recording of that talk](https://youtu.be/3PWeLGrF41g). Please note that this PR only contains the necessary changes to the build system and ROOT's configuration files and utilities. Making the interpreter actually functional requires a number of backports to ROOT's copy of LLVM 13, that are available separately in a branch (https://github.com/hahnjo/root/tree/riscv-backports).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12351
https://github.com/root-project/root/pull/12351:851,security,availab,available,851,"Add initial support for RISC-V; This pull request contains the changes to add initial support for RISC-V. It was developed during the past months on a StarFive VisionFive v1 that was kindly provided to me as part of the [RISC-V Developer Boards Program](https://riscv.org/risc-v-developer-boards/). More details about the challenges are available in the form of a [blog post on my website](https://www.hahnjo.de/blog/2023/01/28/riscv-higgs.html), a [presentation at the CaaS meeting in January](https://compiler-research.org/meetings/#caas_12Jan2023), and a [recording of that talk](https://youtu.be/3PWeLGrF41g). Please note that this PR only contains the necessary changes to the build system and ROOT's configuration files and utilities. Making the interpreter actually functional requires a number of backports to ROOT's copy of LLVM 13, that are available separately in a branch (https://github.com/hahnjo/root/tree/riscv-backports).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12351
https://github.com/root-project/root/pull/12351:12,usability,support,support,12,"Add initial support for RISC-V; This pull request contains the changes to add initial support for RISC-V. It was developed during the past months on a StarFive VisionFive v1 that was kindly provided to me as part of the [RISC-V Developer Boards Program](https://riscv.org/risc-v-developer-boards/). More details about the challenges are available in the form of a [blog post on my website](https://www.hahnjo.de/blog/2023/01/28/riscv-higgs.html), a [presentation at the CaaS meeting in January](https://compiler-research.org/meetings/#caas_12Jan2023), and a [recording of that talk](https://youtu.be/3PWeLGrF41g). Please note that this PR only contains the necessary changes to the build system and ROOT's configuration files and utilities. Making the interpreter actually functional requires a number of backports to ROOT's copy of LLVM 13, that are available separately in a branch (https://github.com/hahnjo/root/tree/riscv-backports).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12351
https://github.com/root-project/root/pull/12351:86,usability,support,support,86,"Add initial support for RISC-V; This pull request contains the changes to add initial support for RISC-V. It was developed during the past months on a StarFive VisionFive v1 that was kindly provided to me as part of the [RISC-V Developer Boards Program](https://riscv.org/risc-v-developer-boards/). More details about the challenges are available in the form of a [blog post on my website](https://www.hahnjo.de/blog/2023/01/28/riscv-higgs.html), a [presentation at the CaaS meeting in January](https://compiler-research.org/meetings/#caas_12Jan2023), and a [recording of that talk](https://youtu.be/3PWeLGrF41g). Please note that this PR only contains the necessary changes to the build system and ROOT's configuration files and utilities. Making the interpreter actually functional requires a number of backports to ROOT's copy of LLVM 13, that are available separately in a branch (https://github.com/hahnjo/root/tree/riscv-backports).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12351
https://github.com/root-project/root/pull/12352:116,availability,error,errors,116,"[tree] Avoid odr-using TTree::kMaxEntries; In C++14, this would require a definition. This should solve the linking errors about ""undefined reference""s in the incrementals.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12352
https://github.com/root-project/root/pull/12352:116,performance,error,errors,116,"[tree] Avoid odr-using TTree::kMaxEntries; In C++14, this would require a definition. This should solve the linking errors about ""undefined reference""s in the incrementals.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12352
https://github.com/root-project/root/pull/12352:7,safety,Avoid,Avoid,7,"[tree] Avoid odr-using TTree::kMaxEntries; In C++14, this would require a definition. This should solve the linking errors about ""undefined reference""s in the incrementals.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12352
https://github.com/root-project/root/pull/12352:116,safety,error,errors,116,"[tree] Avoid odr-using TTree::kMaxEntries; In C++14, this would require a definition. This should solve the linking errors about ""undefined reference""s in the incrementals.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12352
https://github.com/root-project/root/pull/12352:116,usability,error,errors,116,"[tree] Avoid odr-using TTree::kMaxEntries; In C++14, this would require a definition. This should solve the linking errors about ""undefined reference""s in the incrementals.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12352
https://github.com/root-project/root/pull/12353:48,integrability,rout,routines,48,"[cling] Disable outline-atomics on AArch64; The routines `__aarch64_*` are defined in the static library libgcc.a and not necessarily included in libCling or otherwise present in the process, so the interpreter has a hard time finding them. Fixes #12294",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12353
https://github.com/root-project/root/pull/12353:222,performance,time,time,222,"[cling] Disable outline-atomics on AArch64; The routines `__aarch64_*` are defined in the static library libgcc.a and not necessarily included in libCling or otherwise present in the process, so the interpreter has a hard time finding them. Fixes #12294",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12353
https://github.com/root-project/root/pull/12354:75,deployability,Updat,Update,75,[webgui] improve browser resize; Also new features. - TLegend autoplace. - Update stats box entries on server. - Better SVG bezier paremeters - more smooth curves,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12354
https://github.com/root-project/root/pull/12354:75,safety,Updat,Update,75,[webgui] improve browser resize; Also new features. - TLegend autoplace. - Update stats box entries on server. - Better SVG bezier paremeters - more smooth curves,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12354
https://github.com/root-project/root/pull/12354:75,security,Updat,Update,75,[webgui] improve browser resize; Also new features. - TLegend autoplace. - Update stats box entries on server. - Better SVG bezier paremeters - more smooth curves,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12354
https://github.com/root-project/root/pull/12355:177,modifiability,inherit,inheritance,177,[math] Rewrite `ROOT::Math::Functor` and friends completely using `std::function`s; This makes the code much simpler and avoids using virtual implemetation classes with dubious inheritance chains.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12355
https://github.com/root-project/root/pull/12355:49,safety,compl,completely,49,[math] Rewrite `ROOT::Math::Functor` and friends completely using `std::function`s; This makes the code much simpler and avoids using virtual implemetation classes with dubious inheritance chains.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12355
https://github.com/root-project/root/pull/12355:121,safety,avoid,avoids,121,[math] Rewrite `ROOT::Math::Functor` and friends completely using `std::function`s; This makes the code much simpler and avoids using virtual implemetation classes with dubious inheritance chains.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/12355
